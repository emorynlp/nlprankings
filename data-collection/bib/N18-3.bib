@proceedings{naacl-2018-2018-north-american,
    title = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    author = "Bangalore, Srinivas  and
      Chu-Carroll, Jennifer  and
      Li, Yunyao",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3000",
    doi = "10.18653/v1/N18-3",
}
@inproceedings{amoia-etal-2018-scalable,
    title = "Scalable Wide and Deep Learning for Computer Assisted Coding",
    author = "Amoia, Marilisa  and
      Diehl, Frank  and
      Gimenez, Jesus  and
      Pinto, Joel  and
      Schumann, Raphael  and
      Stemmer, Fabian  and
      Vozila, Paul  and
      Zhang, Yi",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3001",
    doi = "10.18653/v1/N18-3001",
    pages = "1--7",
    abstract = "In recent years the use of electronic medical records has accelerated resulting in large volumes of medical data when a patient visits a healthcare facility. As a first step towards reimbursement healthcare institutions need to associate ICD-10 billing codes to these documents. This is done by trained clinical coders who may use a computer assisted solution for shortlisting of codes. In this work, we present our work to build a machine learning based scalable system for predicting ICD-10 codes from electronic medical records. We address data imbalance issues by implementing two system architectures using convolutional neural networks and logistic regression models. We illustrate the pros and cons of those system designs and show that the best performance can be achieved by leveraging the advantages of both using a system combination approach.",
}
@inproceedings{shah-etal-2018-neural,
    title = "Neural Network based Extreme Classification and Similarity Models for Product Matching",
    author = "Shah, Kashif  and
      Kopru, Selcuk  and
      Ruvini, Jean-David",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3002",
    doi = "10.18653/v1/N18-3002",
    pages = "8--15",
    abstract = "Matching a seller listed item to an appropriate product has become a fundamental and one of the most significant step for e-commerce platforms for product based experience. It has a huge impact on making the search effective, search engine optimization, providing product reviews and product price estimation etc. along with many other advantages for a better user experience. As significant and vital it has become, the challenge to tackle the complexity has become huge with the exponential growth of individual and business sellers trading millions of products everyday. We explored two approaches; classification based on shallow neural network and similarity based on deep siamese network. These models outperform the baseline by more than 5{\%} in term of accuracy and are capable of extremely efficient training and inference.",
}
@inproceedings{kim-etal-2018-scalable,
    title = "A Scalable Neural Shortlisting-Reranking Approach for Large-Scale Domain Classification in Natural Language Understanding",
    author = "Kim, Young-Bum  and
      Kim, Dongchan  and
      Kim, Joo-Kyung  and
      Sarikaya, Ruhi",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3003",
    doi = "10.18653/v1/N18-3003",
    pages = "16--24",
    abstract = "Intelligent personal digital assistants (IPDAs), a popular real-life application with spoken language understanding capabilities, can cover potentially thousands of overlapping domains for natural language understanding, and the task of finding the best domain to handle an utterance becomes a challenging problem on a large scale. In this paper, we propose a set of efficient and scalable shortlisting-reranking neural models for effective large-scale domain classification for IPDAs. The shortlisting stage focuses on efficiently trimming all domains down to a list of k-best candidate domains, and the reranking stage performs a list-wise reranking of the initial k-best domains with additional contextual information. We show the effectiveness of our approach with extensive experiments on 1,500 IPDA domains.",
}
@inproceedings{gangadharaiah-etal-2018-need,
    title = "What we need to learn if we want to do and not just talk",
    author = "Gangadharaiah, Rashmi  and
      Narayanaswamy, Balakrishnan  and
      Elkan, Charles",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3004",
    doi = "10.18653/v1/N18-3004",
    pages = "25--32",
    abstract = "In task-oriented dialog, agents need to generate both fluent natural language responses and correct external actions like database queries and updates. Our paper makes the first attempt at evaluating state of the art models on a large real world task with human users. We show that methods that achieve state of the art performance on synthetic datasets, perform poorly in real world dialog tasks. We propose a hybrid model, where nearest neighbor is used to generate fluent responses and Seq2Seq type models ensure dialogue coherency and generate accurate external actions. The hybrid model on the customer support data achieves a 78{\%} relative improvement in fluency, and a 200{\%} improvement in accuracy of external calls.",
}
@inproceedings{kang-etal-2018-data,
    title = "Data Collection for Dialogue System: A Startup Perspective",
    author = "Kang, Yiping  and
      Zhang, Yunqi  and
      Kummerfeld, Jonathan K.  and
      Tang, Lingjia  and
      Mars, Jason",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3005",
    doi = "10.18653/v1/N18-3005",
    pages = "33--40",
    abstract = "Industrial dialogue systems such as Apple Siri and Google Now rely on large scale diverse and robust training data to enable their sophisticated conversation capability. Crowdsourcing provides a scalable and inexpensive way of data collection but collecting high quality data efficiently requires thoughtful orchestration of the crowdsourcing jobs. Prior study of this topic have focused on tasks only in the academia settings with limited scope or only provide intrinsic dataset analysis, lacking indication on how it affects the trained model performance. In this paper, we present a study of crowdsourcing methods for a user intent classification task in our deployed dialogue system. Our task requires classification of 47 possible user intents and contains many intent pairs with subtle differences. We consider different crowdsourcing job types and job prompts and analyze quantitatively the quality of the collected data and the downstream model performance on a test set of real user queries from production logs. Our observation provides insights into designing efficient crowdsourcing jobs and provide recommendations for future dialogue system data collection process.",
}
@inproceedings{shah-etal-2018-bootstrapping,
    title = "Bootstrapping a Neural Conversational Agent with Dialogue Self-Play, Crowdsourcing and On-Line Reinforcement Learning",
    author = {Shah, Pararth  and
      Hakkani-T{\"u}r, Dilek  and
      Liu, Bing  and
      T{\"u}r, Gokhan},
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3006",
    doi = "10.18653/v1/N18-3006",
    pages = "41--51",
    abstract = "End-to-end neural models show great promise towards building conversational agents that are trained from data and on-line experience using supervised and reinforcement learning. However, these models require a large corpus of dialogues to learn effectively. For goal-oriented dialogues, such datasets are expensive to collect and annotate, since each task involves a separate schema and database of entities. Further, the Wizard-of-Oz approach commonly used for dialogue collection does not provide sufficient coverage of salient dialogue flows, which is critical for guaranteeing an acceptable task completion rate in consumer-facing conversational agents. In this paper, we study a recently proposed approach for building an agent for arbitrary tasks by combining dialogue self-play and crowd-sourcing to generate fully-annotated dialogues with diverse and natural utterances. We discuss the advantages of this approach for industry applications of conversational agents, wherein an agent can be rapidly bootstrapped to deploy in front of users and further optimized via interactive learning from actual users of the system.",
}
@inproceedings{ueffing-etal-2018-quality,
    title = "Quality Estimation for Automatically Generated Titles of e{C}ommerce Browse Pages",
    author = "Ueffing, Nicola  and
      C. de Souza, Jos{\'e} G.  and
      Leusch, Gregor",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3007",
    doi = "10.18653/v1/N18-3007",
    pages = "52--59",
    abstract = "At eBay, we are automatically generating a large amount of natural language titles for eCommerce browse pages using machine translation (MT) technology. While automatic approaches can generate millions of titles very fast, they are prone to errors. We therefore develop quality estimation (QE) methods which can automatically detect titles with low quality in order to prevent them from going live. In this paper, we present different approaches: The first one is a Random Forest (RF) model that explores hand-crafted, robust features, which are a mix of established features commonly used in Machine Translation Quality Estimation (MTQE) and new features developed specifically for our task. The second model is based on Siamese Networks (SNs) which embed the metadata input sequence and the generated title in the same space and do not require hand-crafted features at all. We thoroughly evaluate and compare those approaches on in-house data. While the RF models are competitive for scenarios with smaller amounts of training data and somewhat more robust, they are clearly outperformed by the SN models when the amount of training data is larger.",
}
@inproceedings{yoon-etal-2018-atypical,
    title = "Atypical Inputs in Educational Applications",
    author = "Yoon, Su-Youn  and
      Cahill, Aoife  and
      Loukina, Anastassia  and
      Zechner, Klaus  and
      Riordan, Brian  and
      Madnani, Nitin",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3008",
    doi = "10.18653/v1/N18-3008",
    pages = "60--67",
    abstract = "In large-scale educational assessments, the use of automated scoring has recently become quite common. While the majority of student responses can be processed and scored without difficulty, there are a small number of responses that have atypical characteristics that make it difficult for an automated scoring system to assign a correct score. We describe a pipeline that detects and processes these kinds of responses at run-time. We present the most frequent kinds of what are called non-scorable responses along with effective filtering models based on various NLP and speech processing technologies. We give an overview of two operational automated scoring systems {---}one for essay scoring and one for speech scoring{---} and describe the filtering models they use. Finally, we present an evaluation and analysis of filtering models used for spoken responses in an assessment of language proficiency.",
}
@inproceedings{mitcheltree-etal-2018-using,
    title = "Using Aspect Extraction Approaches to Generate Review Summaries and User Profiles",
    author = "Mitcheltree, Christopher  and
      Wharton, Veronica  and
      Saluja, Avneesh",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3009",
    doi = "10.18653/v1/N18-3009",
    pages = "68--75",
    abstract = "Reviews of products or services on Internet marketplace websites contain a rich amount of information. Users often wish to survey reviews or review snippets from the perspective of a certain aspect, which has resulted in a large body of work on aspect identification and extraction from such corpora. In this work, we evaluate a newly-proposed neural model for aspect extraction on two practical tasks. The first is to extract canonical sentences of various aspects from reviews, and is judged by human evaluators against alternatives. A $k$-means baseline does remarkably well in this setting. The second experiment focuses on the suitability of the recovered aspect distributions to represent users by the reviews they have written. Through a set of review reranking experiments, we find that aspect-based profiles can largely capture notions of user preferences, by showing that divergent users generate markedly different review rankings.",
}
@inproceedings{chiticariu-etal-2018-systemt,
    title = "{S}ystem{T}: Declarative Text Understanding for Enterprise",
    author = "Chiticariu, Laura  and
      Danilevsky, Marina  and
      Li, Yunyao  and
      Reiss, Frederick  and
      Zhu, Huaiyu",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3010",
    doi = "10.18653/v1/N18-3010",
    pages = "76--83",
    abstract = "The rise of enterprise applications over unstructured and semi-structured documents poses new challenges to text understanding systems across multiple dimensions. We present SystemT, a declarative text understanding system that addresses these challenges and has been deployed in a wide range of enterprise applications. We highlight the design considerations and decisions behind SystemT in addressing the needs of the enterprise setting. We also summarize the impact of SystemT on business and education.",
}
@inproceedings{ammar-etal-2018-construction,
    title = "Construction of the Literature Graph in Semantic Scholar",
    author = "Ammar, Waleed  and
      Groeneveld, Dirk  and
      Bhagavatula, Chandra  and
      Beltagy, Iz  and
      Crawford, Miles  and
      Downey, Doug  and
      Dunkelberger, Jason  and
      Elgohary, Ahmed  and
      Feldman, Sergey  and
      Ha, Vu  and
      Kinney, Rodney  and
      Kohlmeier, Sebastian  and
      Lo, Kyle  and
      Murray, Tyler  and
      Ooi, Hsu-Han  and
      Peters, Matthew  and
      Power, Joanna  and
      Skjonsberg, Sam  and
      Wang, Lucy  and
      Wilhelm, Chris  and
      Yuan, Zheng  and
      van Zuylen, Madeleine  and
      Etzioni, Oren",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3011",
    doi = "10.18653/v1/N18-3011",
    pages = "84--91",
    abstract = "We describe a deployed scalable system for organizing published scientific literature into a heterogeneous graph to facilitate algorithmic manipulation and discovery. The resulting literature graph consists of more than 280M nodes, representing papers, authors, entities and various interactions between them (e.g., authorships, citations, entity mentions). We reduce literature graph construction into familiar NLP tasks (e.g., entity extraction and linking), point out research challenges due to differences from standard formulations of these tasks, and report empirical results for each task. The methods described in this paper are used to enable semantic features in \url{www.semanticscholar.org}.",
}
@inproceedings{kreutzer-etal-2018-neural,
    title = "Can Neural Machine Translation be Improved with User Feedback?",
    author = "Kreutzer, Julia  and
      Khadivi, Shahram  and
      Matusov, Evgeny  and
      Riezler, Stefan",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3012",
    doi = "10.18653/v1/N18-3012",
    pages = "92--105",
    abstract = "We present the first real-world application of methods for improving neural machine translation (NMT) with human reinforcement, based on explicit and implicit user feedback collected on the eBay e-commerce platform. Previous work has been confined to simulation experiments, whereas in this paper we work with real logged feedback for offline bandit learning of NMT parameters. We conduct a thorough analysis of the available explicit user judgments{---}five-star ratings of translation quality{---}and show that they are not reliable enough to yield significant improvements in bandit learning. In contrast, we successfully utilize implicit task-based feedback collected in a cross-lingual search task to improve task-specific and machine translation quality metrics.",
}
@inproceedings{iglesias-etal-2018-accelerating,
    title = "Accelerating {NMT} Batched Beam Decoding with {LMBR} Posteriors for Deployment",
    author = "Iglesias, Gonzalo  and
      Tambellini, William  and
      De Gispert, Adri{\`a}  and
      Hasler, Eva  and
      Byrne, Bill",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3013",
    doi = "10.18653/v1/N18-3013",
    pages = "106--113",
    abstract = "We describe a batched beam decoding algorithm for NMT with LMBR n-gram posteriors, showing that LMBR techniques still yield gains on top of the best recently reported results with Transformers. We also discuss acceleration strategies for deployment, and the effect of the beam size and batching on memory and speed.",
}
@inproceedings{quinn-ballesteros-2018-pieces,
    title = "Pieces of Eight: 8-bit Neural Machine Translation",
    author = "Quinn, Jerry  and
      Ballesteros, Miguel",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3014",
    doi = "10.18653/v1/N18-3014",
    pages = "114--120",
    abstract = "Neural machine translation has achieved levels of fluency and adequacy that would have been surprising a short time ago. Output quality is extremely relevant for industry purposes, however it is equally important to produce results in the shortest time possible, mainly for latency-sensitive applications and to control cloud hosting costs. In this paper we show the effectiveness of translating with 8-bit quantization for models that have been trained using 32-bit floating point values. Results show that 8-bit translation makes a non-negligible impact in terms of speed with no degradation in accuracy and adequacy.",
}
@inproceedings{finley-etal-2018-dictations,
    title = "From dictations to clinical reports using machine translation",
    author = "Finley, Gregory  and
      Salloum, Wael  and
      Sadoughi, Najmeh  and
      Edwards, Erik  and
      Robinson, Amanda  and
      Axtmann, Nico  and
      Brenndoerfer, Michael  and
      Miller, Mark  and
      Suendermann-Oeft, David",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3015",
    doi = "10.18653/v1/N18-3015",
    pages = "121--128",
    abstract = "A typical workflow to document clinical encounters entails dictating a summary, running speech recognition, and post-processing the resulting text into a formatted letter. Post-processing entails a host of transformations including punctuation restoration, truecasing, marking sections and headers, converting dates and numerical expressions, parsing lists, etc. In conventional implementations, most of these tasks are accomplished by individual modules. We introduce a novel holistic approach to post-processing that relies on machine callytranslation. We show how this technique outperforms an alternative conventional system{---}even learning to correct speech recognition errors during post-processing{---}while being much simpler to maintain.",
}
@inproceedings{pivovarova-etal-2018-benchmarks,
    title = "Benchmarks and models for entity-oriented polarity detection",
    author = "Pivovarova, Lidia  and
      Klami, Arto  and
      Yangarber, Roman",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3016",
    doi = "10.18653/v1/N18-3016",
    pages = "129--136",
    abstract = "We address the problem of determining entity-oriented polarity in business news. This can be viewed as classifying the polarity of the sentiment expressed toward a given mention of a company in a news article. We present a complete, end-to-end approach to the problem. We introduce a new dataset of over 17,000 manually labeled documents, which is substantially larger than any currently available resources. We propose a benchmark solution based on convolutional neural networks for classifying entity-oriented polarity. Although our dataset is much larger than those currently available, it is small on the scale of datasets commonly used for training robust neural network models. To compensate for this, we use transfer learning{---}pre-train the model on a much larger dataset, annotated for a related but different classification task, in order to learn a good representation for business text, and then fine-tune it on the smaller polarity dataset.",
}
@inproceedings{gaspers-etal-2018-selecting,
    title = "Selecting Machine-Translated Data for Quick Bootstrapping of a Natural Language Understanding System",
    author = "Gaspers, Judith  and
      Karanasou, Penny  and
      Chatterjee, Rajen",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3017",
    doi = "10.18653/v1/N18-3017",
    pages = "137--144",
    abstract = "This paper investigates the use of Machine Translation (MT) to bootstrap a Natural Language Understanding (NLU) system for a new language for the use case of a large-scale voice-controlled device. The goal is to decrease the cost and time needed to get an annotated corpus for the new language, while still having a large enough coverage of user requests. Different methods of filtering MT data in order to keep utterances that improve NLU performance and language-specific post-processing methods are investigated. These methods are tested in a large-scale NLU task with translating around 10 millions training utterances from English to German. The results show a large improvement for using MT data over a grammar-based and over an in-house data collection baseline, while reducing the manual effort greatly. Both filtering and post-processing approaches improve results further.",
}
@inproceedings{goyal-etal-2018-fast,
    title = "Fast and Scalable Expansion of Natural Language Understanding Functionality for Intelligent Agents",
    author = "Goyal, Anuj Kumar  and
      Metallinou, Angeliki  and
      Matsoukas, Spyros",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3018",
    doi = "10.18653/v1/N18-3018",
    pages = "145--152",
    abstract = "Fast expansion of natural language functionality of intelligent virtual agents is critical for achieving engaging and informative interactions. However, developing accurate models for new natural language domains is a time and data intensive process. We propose efficient deep neural network architectures that maximally re-use available resources through transfer learning. Our methods are applied for expanding the understanding capabilities of a popular commercial agent and are evaluated on hundreds of new domains, designed by internal or external developers. We demonstrate that our proposed methods significantly increase accuracy in low resource settings and enable rapid development of accurate models with less data.",
}
@inproceedings{jha-etal-2018-bag,
    title = "Bag of Experts Architectures for Model Reuse in Conversational Language Understanding",
    author = "Jha, Rahul  and
      Marin, Alex  and
      Shivaprasad, Suvamsh  and
      Zitouni, Imed",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3019",
    doi = "10.18653/v1/N18-3019",
    pages = "153--161",
    abstract = "Slot tagging, the task of detecting entities in input user utterances, is a key component of natural language understanding systems for personal digital assistants. Since each new domain requires a different set of slots, the annotation costs for labeling data for training slot tagging models increases rapidly as the number of domains grow. To tackle this, we describe Bag of Experts (BoE) architectures for model reuse for both LSTM and CRF based models. Extensive experimentation over a dataset of 10 domains drawn from data relevant to our commercial personal digital assistant shows that our BoE models outperform the baseline models with a statistically significant average margin of 5.06{\%} in absolute F1-score when training with 2000 instances per domain, and achieve an even higher improvement of 12.16{\%} when only 25{\%} of the training data is used.",
}
@inproceedings{mathur-etal-2018-multi,
    title = "Multi-lingual neural title generation for e-Commerce browse pages",
    author = "Mathur, Prashant  and
      Ueffing, Nicola  and
      Leusch, Gregor",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3020",
    doi = "10.18653/v1/N18-3020",
    pages = "162--169",
    abstract = "To provide better access of the inventory to buyers and better search engine optimization, e-Commerce websites are automatically generating millions of browse pages. A browse page consists of a set of slot name/value pairs within a given category, grouping multiple items which share some characteristics. These browse pages require a title describing the content of the page. Since the number of browse pages are huge, manual creation of these titles is infeasible. Previous statistical and neural approaches depend heavily on the availability of large amounts of data in a language. In this research, we apply sequence-to-sequence models to generate titles for high-resource as well as low-resource languages by leveraging transfer learning. We train these models on multi-lingual data, thereby creating one joint model which can generate titles in various different languages. Performance of the title generation system is evaluated on three different languages; English, German, and French, with a particular focus on low-resourced French language.",
}
@inproceedings{niraula-etal-2018-novel,
    title = "A Novel Approach to Part Name Discovery in Noisy Text",
    author = "Niraula, Nobal Bikram  and
      Whyatt, Daniel  and
      Kao, Anne",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3021",
    doi = "10.18653/v1/N18-3021",
    pages = "170--176",
    abstract = "As a specialized example of information extraction, part name extraction is an area that presents unique challenges. Part names are typically multi-word terms longer than two words. There is little consistency in how terms are described in noisy free text, with variations spawned by typos, ad hoc abbreviations, acronyms, and incomplete names. This makes search and analyses of parts in these data extremely challenging. In this paper, we present our algorithm, PANDA (Part Name Discovery Analytics), based on a unique method that exploits statistical, linguistic and machine learning techniques to discover part names in noisy text such as that in manufacturing quality documentation, supply chain management records, service communication logs, and maintenance reports. Experiments show that PANDA is scalable and outperforms existing techniques significantly.",
}
@inproceedings{kollar-etal-2018-alexa,
    title = "The {A}lexa Meaning Representation Language",
    author = "Kollar, Thomas  and
      Berry, Danielle  and
      Stuart, Lauren  and
      Owczarzak, Karolina  and
      Chung, Tagyoung  and
      Mathias, Lambert  and
      Kayser, Michael  and
      Snow, Bradford  and
      Matsoukas, Spyros",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3022",
    doi = "10.18653/v1/N18-3022",
    pages = "177--184",
    abstract = "This paper introduces a meaning representation for spoken language understanding. The Alexa meaning representation language (AMRL), unlike previous approaches, which factor spoken utterances into domains, provides a common representation for how people communicate in spoken language. AMRL is a rooted graph, links to a large-scale ontology, supports cross-domain queries, fine-grained types, complex utterances and composition. A spoken language dataset has been collected for Alexa, which contains âˆ¼20k examples across eight domains. A version of this meaning representation was released to developers at a trade show in 2016.",
}
@inproceedings{mehrabani-etal-2018-practical,
    title = "Practical Application of Domain Dependent Confidence Measurement for Spoken Language Understanding Systems",
    author = "Mehrabani, Mahnoosh  and
      Thomson, David  and
      Stern, Benjamin",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3023",
    doi = "10.18653/v1/N18-3023",
    pages = "185--192",
    abstract = "Spoken Language Understanding (SLU), which extracts semantic information from speech, is not flawless, specially in practical applications. The reliability of the output of an SLU system can be evaluated using a semantic confidence measure. Confidence measures are a solution to improve the quality of spoken dialogue systems, by rejecting low-confidence SLU results. In this study we discuss real-world applications of confidence scoring in a customer service scenario. We build confidence models for three major types of dialogue states that are considered as different domains: how may I help you, number capture, and confirmation. Practical challenges to train domain-dependent confidence models, including data limitations, are discussed, and it is shown that feature engineering plays an important role to improve performance. We explore a wide variety of predictor features based on speech recognition, intent classification, and high-level domain knowledge, and find the combined feature set with the best rejection performance for each application.",
}
@inproceedings{ambroselli-etal-2018-prediction,
    title = "Prediction for the Newsroom: Which Articles Will Get the Most Comments?",
    author = "Ambroselli, Carl  and
      Risch, Julian  and
      Krestel, Ralf  and
      Loos, Andreas",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3024",
    doi = "10.18653/v1/N18-3024",
    pages = "193--199",
    abstract = "The overwhelming success of the Web and mobile technologies has enabled millions to share their opinions publicly at any time. But the same success also endangers this freedom of speech due to closing down of participatory sites misused by individuals or interest groups. We propose to support manual moderation by proactively drawing the attention of our moderators to article discussions that most likely need their intervention. To this end, we predict which articles will receive a high number of comments. In contrast to existing work, we enrich the article with metadata, extract semantic and linguistic features, and exploit annotated data from a foreign language corpus. Our logistic regression model improves F1-scores by over 80{\%} in comparison to state-of-the-art approaches.",
}
@inproceedings{hopkinson-etal-2018-demand,
    title = "Demand-Weighted Completeness Prediction for a Knowledge Base",
    author = "Hopkinson, Andrew  and
      Gurdasani, Amit  and
      Palfrey, Dave  and
      Mittal, Arpit",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3025",
    doi = "10.18653/v1/N18-3025",
    pages = "200--207",
    abstract = "In this paper we introduce the notion of Demand-Weighted Completeness, allowing estimation of the completeness of a knowledge base with respect to how it is used. Defining an entity by its classes, we employ usage data to predict the distribution over relations for that entity. For example, instances of person in a knowledge base may require a birth date, name and nationality to be considered complete. These predicted relation distributions enable detection of important gaps in the knowledge base, and define the required facts for unseen entities. Such characterisation of the knowledge base can also quantify how usage and completeness change over time. We demonstrate a method to measure Demand-Weighted Completeness, and show that a simple neural network model performs well at this prediction task.",
}
@inproceedings{fiorini-lu-2018-personalized,
    title = "Personalized neural language models for real-world query auto completion",
    author = "Fiorini, Nicolas  and
      Lu, Zhiyong",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3026",
    doi = "10.18653/v1/N18-3026",
    pages = "208--215",
    abstract = "Query auto completion (QAC) systems are a standard part of search engines in industry, helping users formulate their query. Such systems update their suggestions after the user types each character, predicting the user{'}s intent using various signals {--} one of the most common being popularity. Recently, deep learning approaches have been proposed for the QAC task, to specifically address the main limitation of previous popularity-based methods: the inability to predict unseen queries. In this work we improve previous methods based on neural language modeling, with the goal of building an end-to-end system. We particularly focus on using real-world data by integrating user information for personalized suggestions when possible. We also make use of time information and study how to increase diversity in the suggestions while studying the impact on scalability. Our empirical results demonstrate a marked improvement on two separate datasets over previous best methods in both accuracy and scalability, making a step towards neural query auto-completion in production search engines.",
}
@inproceedings{elsafty-etal-2018-document,
    title = "Document-based Recommender System for Job Postings using Dense Representations",
    author = "Elsafty, Ahmed  and
      Riedl, Martin  and
      Biemann, Chris",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans - Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-3027",
    doi = "10.18653/v1/N18-3027",
    pages = "216--224",
    abstract = "Job boards and professional social networks heavily use recommender systems in order to better support users in exploring job advertisements. Detecting the similarity between job advertisements is important for job recommendation systems as it allows, for example, the application of item-to-item based recommendations. In this work, we research the usage of dense vector representations to enhance a large-scale job recommendation system and to rank German job advertisements regarding their similarity. We follow a two-folded evaluation scheme: (1) we exploit historic user interactions to automatically create a dataset of similar jobs that enables an offline evaluation. (2) In addition, we conduct an online A/B test and evaluate the best performing method on our platform reaching more than 1 million users. We achieve the best results by combining job titles with full-text job descriptions. In particular, this method builds dense document representation using words of the titles to weigh the importance of words of the full-text description. In the online evaluation, this approach allows us to increase the click-through rate on job recommendations for active users by 8.0{\%}.",
}
