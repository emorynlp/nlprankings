



















































Structured Lexical Similarity via Convolution Kernels on Dependency Trees


Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1034–1046,
Edinburgh, Scotland, UK, July 27–31, 2011. c©2011 Association for Computational Linguistics

Structured Lexical Similarity via Convolution Kernels on Dependency Trees

Danilo Croce
DII

University of Tor Vergata
00133 Roma, Italy

croce@info.uniroma2.it

Alessandro Moschitti
DISI

University of Trento
38123 Povo (TN), Italy

moschitti@disi.unitn.it

Roberto Basili
DII

University of Tor Vergata
00133 Roma, Italy

basili@info.uniroma2.it

Abstract

A central topic in natural language process-
ing is the design of lexical and syntactic fea-
tures suitable for the target application. In this
paper, we study convolution dependency tree
kernels for automatic engineering of syntactic
and semantic patterns exploiting lexical simi-
larities. We define efficient and powerful ker-
nels for measuring the similarity between de-
pendency structures, whose surface forms of
the lexical nodes are in part or completely dif-
ferent. The experiments with such kernels for
question classification show an unprecedented
results, e.g. 41% of error reduction of the for-
mer state-of-the-art. Additionally, semantic
role classification confirms the benefit of se-
mantic smoothing for dependency kernels.

1 Introduction
A central topic in Natural Language Processing is
the design of lexical and syntactic features suitable
for the target application. The selection of effective
patterns composed of syntactic dependencies and
lexical constraints is typically a complex task.

Additionally, the availability of training data is
usually scarce. This requires the development of
generalized features or the definition of seman-
tic similarities between them, e.g. as proposed in
(Resnik, 1995; Jiang and Conrath, 1997; Schtze,
1998; Pedersen et al., 2004a; Bloehdorn and Mos-
chitti, 2007b; Davis et al., 2007) or in semi-
supervised settings, e.g. (Chapelle et al., 2006).
A semantic similarity can be defined at structural
level over a graph, e.g. (Freeman, 1977; Bunke and
Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as
well as combining structural and lexical similarity

over semantic networks, e.g. (Cowie et al., 1992; Wu
and Palmer, 1994; Resnik, 1995; Jiang and Conrath,
1997; Schtze, 1998; Leacock and Chodorow, 1998;
Pedersen et al., 2004a; Budanitsky and Hirst, 2006).
More recent research also focuses on mechanisms
to define if two structures, e.g. graphs, are enough
similar, as explored in (Mihalcea, 2005; Zhao et al.,
2009; Fürstenau and Lapata, 2009; Navigli and La-
pata, 2010).

On one hand, previous work shows that there is
a substantial lack of automatic methods for engi-
neering lexical/syntactic features (or more in gen-
eral syntactic/semantic similarity). On the other
hand, automatic feature engineering of syntactic or
shallow semantic structures has been carried out
by means of structural kernels, e.g. (Collins and
Duffy, 2002; Kudo and Matsumoto, 2003; Cumby
and Roth, 2003; Cancedda et al., 2003; Daumé III
and Marcu, 2004; Toutanova et al., 2004; Shen et al.,
2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov
and Henderson, 2006; Zelenko et al., 2002; Bunescu
and Mooney, 2005; Zhang et al., 2006). The main
idea of structural kernels is to generate structures
that in turn represent syntactic or shallow semantic
features. Most notably, the work in (Bloehdorn and
Moschitti, 2007b) encodes lexical similarity in such
kernels. This is essentially the syntactic tree ker-
nel (STK) proposed in (Collins and Duffy, 2002) in
which syntactic fragments from constituency trees
can be matched even if they only differ in the leaf
nodes (i.e. they have different surface forms). This
implies matching scores lower than 1, depending on
the semantic similarity of the corresponding leaves
in the syntactic fragments.

Although this kernel achieves state-of-the-art per-
formance in NLP tasks, such as Question Classifica-

1034



tion (Bloehdorn and Moschitti, 2007b) and Textual
Entailment (Mehdad et al., 2010), it offers clearly
possibility of improvement: (i) better possibility to
exploit semantic smoothing since, e.g., trivially STK
only matches the syntactic structure apple/orange
when comparing the big beautiful apple to a nice
large orange; and (ii) STK cannot be effectively ap-
plied to dependency structures, e.g. see experiments
and motivation in (Moschitti, 2006a). Additionally,
to our knowledge, there is no previous study that
clearly describes how dependency structures should
be converted in trees to be fully and effectively ex-
ploitable by convolution kernels. Indeed, although
the work in (Culotta and Sorensen, 2004) defines a
dependency tree also using node similarity, it is not
a convolution kernel: this results in a much poorer
feature space.

In this paper, we propose a study of convolution
kernels for dependency structures aiming at jointly
modeling syntactic and lexical semantic similarity.
More precisely, we define several dependency trees
exploitable by the Partial Tree Kernel (PTK) (Mos-
chitti, 2006a) and compared them with STK over
constituency trees. Most importantly, we define
an innovative and efficient class of kernels, i.e. the
Smoothed Partial Tree Kernels (SPTKs), which can
measure the similarity of structural similar trees
whose nodes are associated with different but re-
lated lexicals. Given the convolution nature of such
kernels any possible node path of lexicals provide
a contribution smoothed by the similarity accounted
by its nodes.

The extensive experimentation on two datasets of
question classification (QC) and semantic role label-
ing (SRL), shows that: (i) PTK applied to our depen-
dency trees outperforms STK, demonstrating that
dependency parsers are fully exploitable for feature
engineering based on structural kernels; (ii) SPTK
outperforms any previous kernels achieving an un-
precedented result of 41% of error reduction with re-
spect to the former state-of-the-art on QC; and (iii)
the experiments on SRL confirm that the approach
can be applied to different tasks without any tuning
and again achieving state-of-the-art accuracy.

In the reminder of this paper, Section 2 provides
the background for structural and lexical similar-
ity kernels. Section 3 introduces SPTK. Section 4
provides our representation models for dependency

trees. Section 5 presents the experimental evaluation
for QC and SRL. Section 6 derives the conclusions.

2 Kernel Background

In kernel-based machines, both learning and classi-
fication algorithms only depend on the inner prod-
uct between instances. This in several cases can be
efficiently and implicitly computed by kernel func-
tions by exploiting the following dual formulation:∑

i=1..l yiαiφ(oi)φ(o) + b = 0, where oi and o are
two objects, φ is a mapping from the objects to fea-
ture vectors ~xi and φ(oi)φ(o) = K(oi, o) is a ker-
nel function implicitly defining such mapping. In
case of structural kernels,K determines the shape of
the substructures describing the objects above. The
most general kind of kernels used in NLP are string
kernels, e.g. (Shawe-Taylor and Cristianini, 2004),
the Syntactic Tree Kernels (Collins and Duffy, 2002)
and the Partial Tree Kernels (Moschitti, 2006a).

2.1 String Kernels
The String Kernels (SK) that we consider count
the number of subsequences shared by two strings
of symbols, s1 and s2. Some symbols during the
matching process can be skipped. This modifies
the weight associated with the target substrings as
shown by the following SK equation:

SK(s1, s2) =
∑

u∈Σ∗
φu(s1) · φu(s2) =

∑

u∈Σ∗

∑

~I1:u=s1[~I1]

∑

~I2:u=s2[~I2]

λd(
~I1)+d(~I2)

where, Σ∗ =
⋃∞
n=0 Σ

n is the set of all strings, ~I1 and
~I2 are two sequences of indexes ~I = (i1, ..., i|u|),
with 1 ≤ i1 < ... < i|u| ≤ |s|, such that u = si1 ..si|u| ,
d(~I) = i|u| − i1 + 1 (distance between the first and
last character) and λ ∈ [0, 1] is a decay factor.

It is worth noting that: (a) longer subsequences
receive lower weights; (b) some characters can be
omitted, i.e. gaps; (c) gaps determine a weight since
the exponent of λ is the number of characters and
gaps between the first and last character; and (c)
the complexity of the SK computation is O(mnp)
(Shawe-Taylor and Cristianini, 2004), where m and
n are the lengths of the two strings, respectively and
p is the length of the largest subsequence we want to
consider.

1035



2.2 Tree Kernels
Convolution Tree Kernels compute the number
of common substructures between two trees T1
and T2 without explicitly considering the whole
fragment space. For this purpose, let the set
F = {f1, f2, . . . , f|F|} be a tree fragment space and
χi(n) be an indicator function, equal to 1 if the
target fi is rooted at node n and equal to 0 oth-
erwise. A tree-kernel function over T1 and T2 is
TK(T1, T2) =

∑
n1∈NT1

∑
n2∈NT2

∆(n1, n2), NT1
and NT2 are the sets of the T1’s and T2’s nodes,
respectively and ∆(n1, n2) =

∑|F|
i=1 χi(n1)χi(n2).

The latter is equal to the number of common frag-
ments rooted in the n1 and n2 nodes. The ∆ func-
tion determines the richness of the kernel space and
thus different tree kernels. Hereafter, we consider
the equation to evaluate STK and PTK 1.

2.2.1 Syntactic Tree Kernels (STK)
To compute STK is enough to compute

∆STK(n1, n2) as follows (recalling that since
it is a syntactic tree kernels, each node can be
associated with a production rule): (i) if the
productions at n1 and n2 are different then
∆STK(n1, n2) = 0; (ii) if the productions at
n1 and n2 are the same, and n1 and n2 have
only leaf children then ∆STK(n1, n2) = λ; and
(iii) if the productions at n1 and n2 are the
same, and n1 and n2 are not pre-terminals then
∆STK(n1, n2) = λ

∏l(n1)
j=1 (1 + ∆STK(c

j
n1 , c

j
n2)),

where l(n1) is the number of children of n1 and c
j
n

is the j-th child of the node n. Note that, since the
productions are the same, l(n1) = l(n2) and the
computational complexity of STK is O(|NT1 ||NT2 |)
but the average running time tends to be linear,
i.e.O(|NT1 |+ |NT2 |), for natural language syntactic
trees (Moschitti, 2006a).

2.2.2 The Partial Tree Kernel (PTK)
The computation of PTK is carried out by the

following ∆PTK function: if the labels of n1
and n2 are different then ∆PTK(n1, n2) = 0; else
∆PTK(n1, n2) =

µ
(
λ2 +

∑

~I1,~I2,l(~I1)=l(~I2)

λd(
~I1)+d(

~I2)

l(~I1)∏

j=1

∆PTK(cn1(
~I1j), cn2(

~I2j))
)

1To have a similarity score between 0 and 1, a normalization
in the kernel space, i.e. TK(T1,T2)√

TK(T1,T1)×TK(T2,T2)
is applied.

where d(~I1) = ~I1l(~I1)−~I11+1 and d(~I2) = ~I2l(~I2)−
~I21 + 1. This way, we penalize both larger trees and
child subsequences with gaps. PTK is more general
than the STK as if we only consider the contribu-
tion of shared subsequences containing all children
of nodes, we implement the STK kernel. The com-
putational complexity of PTK is O(pρ2|NT1 ||NT2 |)
(Moschitti, 2006a), where p is the largest subse-
quence of children that we want consider and ρ is the
maximal outdegree observed in the two trees. How-
ever the average running time again tends to be lin-
ear for natural language syntactic trees (Moschitti,
2006a).

2.3 Lexical Semantic Kernel
Given two text fragments d1 and d2 ∈ D (the text
fragment set), a general lexical kernel (Basili et al.,
2005) defines their similarity as:

K(d1, d2) =
∑

w1∈d1,w2∈d2
(ω1ω2)× σ(w1, w2) (1)

where ω1 and ω2 are the weights of the words (fea-
tures) w1 and w2 in the documents d1 and d2, re-
spectively, and σ is a term similarity function, e.g.
(Pedersen et al., 2004b; Sahlgren, 2006; Corley and
Mihalcea, 2005; Mihalcea et al., 2005). Technically,
any σ can be used, provided that the resulting Gram
matrix, G = K(d1, d2) ∀d1, d2 ∈ D is positive
semi-definite (Shawe-Taylor and Cristianini, 2004)
(D is typically the training text set).

We determine the term similarity function through
distributional analysis (Pado and Lapata, 2007), ac-
cording to the idea that the meaning of a word can
be described by the set of textual contexts in which it
appears (Distributional Hypothesis, (Harris, 1964)).
The contexts are words appearing in a n-window
with target words: such a space models a generic
notion of semantic relatedness, i.e. two words
close in the space are likely to be either in paradig-
matic or syntagmatic relation as in (Sahlgren, 2006).
The original word-by-word context matrix M is de-
composed through Singular Value Decomposition
(SVD) (Golub and Kahan, 1965) into the product
of three new matrices: U , S, and V so that S is di-
agonal and M = USV T . M is approximated by
Ml = UlSlV

T
l in which only the first l columns of

U and V are used, and only the first l greatest singu-
lar values are considered. This approximation sup-
plies a way to project a generic term wi into the l-

1036



dimensional space using W = UlS
1/2
l , where each

row corresponds to the representation vectors ~wi.
Therefore, given two words w1 and w2, the term
similarity function σ is estimated as the cosine simi-
larity between the corresponding projections ~w1, ~w2,
i.e σ(w1, w2) = ~w1· ~w2‖ ~w1‖‖ ~w2‖ . The latent semantic ker-
nels (Siolas and d’Alch Buc, 2000; Cristianini et al.,
2001) derive G by applying LSA, resulting in a valid
kernel.

Another methods to design a valid kernel is to rep-
resent words as word vectors and compute σ as their
scalar product between such vectors. For example,
in (Bloehdorn et al., 2006), bag of hyponyms and
hypernyms (up to a certain level of WordNet hierar-
chy) were used to build such vectors. We will refer
to such similarity as WL (word list).

3 Smoothing Partial Tree Kernel (SPTK)
Combining lexical and structural kernels provides
clear advantages on all-vs-all words similarity,
which tends to semantically diverge. Indeed syn-
tax provides the necessary restrictions to com-
pute an effective semantic similarity. Following
this idea, Bloedhorn & Moschitti (2007a) mod-
ified step (i) of ∆STK computation as follows:
(i) if n1 and n2 are pre-terminal nodes with
the same number of children, ∆STK(n1, n2) =
λ
∏nc(n1)
j=1 σ(lex(n1), lex(n2)), where lex returns

the node label. This allows to match fragments hav-
ing same structure but different leaves by assigning a
score proportional to the product of the lexical sim-
ilarities of each leaf pair. Although it is an inter-
esting kernel, the fact that lexicals must belong to
the leaf nodes of exactly the same structures limits
its applications. Trivially, it cannot work on depen-
dency trees. Hereafter, we define a much more gen-
eral smoothed tree kernel that can be applied to any
tree and exploit any combination of lexical similari-
ties, respecting the syntax enforced by the tree.

3.1 SPTK Definition
If n1 and n2 are leaves then ∆σ(n1, n2) =
µλσ(n1, n2); else

∆σ(n1, n2) = µσ(n1, n2)×
(
λ2 +

∑

~I1,~I2,l(~I1)=l(~I2)

λd(
~I1)+d(~I2)

l(~I1)∏

j=1

∆σ(cn1(
~I1j), cn2(

~I2j))
)
, (2)

where σ is any similarity between nodes, e.g. be-
tween their lexical labels, and the other variables are
the same of PTK.

3.2 Soundness
A completely formal proof of the validity of the
Eq. 2 is beyond the purpose of this paper (mainly
due to space reason). Here we give a first sketch:
let us consider σ as a string matching between
node labels and λ = µ = 1. Each recursive
step of Eq. 2 can be seen as a summation of (1 +
∏l(~I1)
j=1 ∆STK(cn1(

~I1j), cn2(
~I2j))), i.e. the ∆STK

recursive equation (see Sec. 2.2.1), for all subse-
quences of children cn1(~I1j). In other words, PTK
is a summation of an exponential number of STKs,
which are valid kernels. It follows that PTK is a ker-
nel. Note that the multiplication by λ and µ elevated
to any power only depends on the target fragment.
Thus, it just gives an additional weight to the frag-
ment and does not violate the Mercer’s conditions.
In contrast, the multiplication by σ(n1, n2) does de-
pend on both comparing examples, i.e. on n1 and n2.
However, if the matrix

[
σ(n1, n2)

]
∀n1, n2 ∈ f ∈ F

is positive semi-definite, a decomposition exists
such that σ(n1, n2) = φ(n1)φ(n2) ⇒ ∆σ(n1, n2)
can be written as

∑|F|
i=1 φ(n1)χi(n1)φ(n2)χi(n2)

=
∑|F|

i=1 φσ(n1)φσ(n2) (see Section 2.2), which
proves SPTK to be a valid kernel.

3.3 Efficient Evaluation

We followed the idea in (Moschitti, 2006a) for effi-
ciently computing SPTK. We consider Eq. 2 evalu-
ated with respect to sequences of different length p;
it follows that

∆(n1, n2) = µσ(n1, n2)
(
λ2 +

m∑

p=1

∆p(cn1 , cn2)
)
,

where ∆p evaluates the number of common sub-
trees rooted in subsequences of exactly p children
(of n1 and n2) and m = min{l(cn1), l(cn2)}.
Given the two child sequences s1a = cn1 and
s2b = cn2 (a and b are the last children)

∆p(s1a, s2b) = ∆(a, b)×
|s1|∑

i=1

|s2|∑

r=1

λ|s1|−i+|s2|−r ×

×∆p−1(s1[1 : i], s2[1 : r])
where s1[1 : i] and s2[1 : r] are the child subse-
quences from 1 to i and from 1 to r of s1 and s2. If
we name the double summation term as Dp, we can

1037



S1

SBARQ

.

?::.

SQ

VP

NP

PP

NP

NN

field::n

NN

football::n

DT

a::d

IN

of::i

NP

NN

width::n

DT

the::d

AUX

be::v

WHNP

WP

what::w

Figure 1: Constituent Tree (CT)

rewrite the relation as:

∆p(s1a, s2b) =

{
∆(a, b)Dp(|s1|, |s2|) if σ(a, b) > 0;
0 otherwise.

Note that Dp satisfies the recursive relation:
Dp(k, l) = ∆p−1(s1[1 : k], s2[1 : l]) + λDp(k, l − 1)

+λDp(k − 1, l)− λ2Dp(k − 1, l − 1)
By means of the above relation, we can compute the
child subsequences of two sequences s1 and s2 in
O(p|s1||s2|). Thus the worst case complexity of the
SPTK is identical to PTK, i.e. O(pρ2|NT1 ||NT2 |),
where ρ is the maximum branching factor of the two
trees. The latter is very small in natural language
parse trees and we also avoid the computation of
node pairs with non similar labels.

We note that PTK generalizes both (i) SK, allow-
ing the similarity between sequences (node children)
structured in a tree and (ii) STK, allowing the com-
putation of STK over any possible pair of subtrees
extracted from the original tree. For this reason,
we do not dedicate additional space on the defini-
tion of the smoothed SK or smoothed STK, which
are in any case important corollary findings of our
research.

3.4 Innovative Features of SPTK
The most similar kernel to SPTK is the Syntactic
Semantic Tree Kernel (SSTK) proposed in (Bloe-
hdorn and Moschitti, 2007a; Bloehdorn and Mos-
chitti, 2007b). However, the following aspects show
the remarkable innovativeness of SPTK:

• SSTK can only work on constituency trees
and not on dependency trees (see (Moschitti,
2006a)).

• The lexical similarity in SSTK is only applied
to leaf nodes in exactly the same syntactic

constituents. Only complete matching of the
structure of subtrees is allowed: there is abso-
lutely no flexibility, e.g. the NP structure “ca-
ble television system” has no match with the
NP “video streaming system”. SPTK provides
matches between all possible relevant subparts,
e.g. ”television system” and ”video system” (so
also exploiting the meaningful similarity be-
tween “video” and “television”).

• The similarity in the PTK equation is added
such that SPTK still corresponds to a scalar
product in the semantic/structure space2.

• We have provided a fast evaluation of SPTK
with dynamic programming (otherwise the
computation would have required exponential
time).

4 Dependency Tree Structures
The feature space generated by the structural ker-
nels, presented in the previous section, obviously de-
pends on the input structures. In case of PTK and
SPTK different tree representations may lead to en-
gineer more or less effective syntactic/semantic fea-
ture spaces. The next two sections provide our repre-
sentation models for dependency trees and their dis-
cussion.

4.1 Proposed Computational Structures
Given the following sentence:

(s1) What is the width of a football field?

The representation tree for a phrase structure
paradigm leaves little room for variations as shown
by the constituency tree (CT) in Figure 1. We ap-
ply lemmatization to the lexicals to improve gener-
alization and, at the same time, we add a generalized
PoS-tag, i.e. noun (n::), verb (v::), adjective (::a), de-
terminer (::d) and so on, to them. This is useful to
measure similarity between lexicals belonging to the
same grammatical category.

In contrast, the conversion of dependency struc-
tures in computationally effective trees (for the
above kernels) is not straightforward. We need to
decide the role of lexicals, their grammatical func-
tions (GR), PoS-tags and dependencies. It is natural

2This is not trivial: for example if sigma is added in Eq. 2 by
only multiplying the λd1+d2 term, no valid space is generated.

1038



ROOT

VBZ

P

.

?::.

PRD

NN

NMOD

IN

PMOD

NN

field::nNMOD

NN

football::n

NMOD

DT

a::d

of::i

width::nNMOD

DT

the::d

be::vSBJ

WP

what::w

Figure 2: PoS-Tag Centered Tree (PCT)

ROOT

P

.

?::.

PRD

NMOD

PMOD

NN

field::n

NMOD

NN

football::n

NMOD

DT

a::d

IN

of::i

NN

width::n

NMOD

DT

the::d

VBZ

be::v

SBJ

WP

what::w

Figure 3: Grammatical Relation Centered Tree (GRCT)

be::v

VBZROOT?::.

.P

width::n

NNPRDof::i

INNMODfield::n

the::d

DTNMOD

what::w

WPSBJ

field::n

NNPMODfootball::n

NNNMOD

a::d

DTNMOD

Figure 4: Lexical Centered Tree (LCT)

to associate edges with dependencies but, since our
kernels cannot process labels on the arcs, they must
be associated with tree nodes. The basic idea of our
structures is to use (i) one of the three kinds of infor-
mation above as central node, from which depen-

be::v

?::.width::n

of::i

field::n

football::na::d

the::d

what::w

Figure 5: Lexical Only Centered Tree (LOCT)

TOP

.

?::.

NN

field::n

NN

football::n

DT

a::d

IN

of::i

NN

width::n

DT

the::d

VBZ

be::v

WP

what::w

Figure 6: Lexical and PoS-Tag Sequences Tree (LPST)

TOP

?::.field::nfootball::na::dof::iwidth::nthe::dbe::vwhat::w

Figure 7: Lexical Sequences Tree (LST)

dencies are drawn and (ii) all the other information
as features (in terms of additional nodes) attached to
the central nodes.

We define three main trees: the PoS-Tag Centered
Tree (PCT), e.g. see Figure 2, where the GR is added
as father and the lexical as a child; the GR Centered
Tree (GRCT), e.g. see Figure 3, where the PoS-Tags
are children of GR nodes and fathers of their associ-
ated lexicals; and the Lexical Centered Tree (LCT),
e.g. see Figure 4, in which both GR and PoS-Tag are
added as the rightmost children.

TOP

ROOT

P

.

?::.

PRD

NMOD

PMOD

NN

goal::n

NMOD

NN

hockey::n

NMOD

NN

ice::n

NMOD

DT

an::d

IN

of::i

NN

dimension::n

NMOD

DT

the::d

VBP

be::v

SBJ

WP

what::w

Figure 8: Grammatical Relation Centered Tree of (s2)

4.2 Comparative Structures
To better study the role of the above dependency
structures, especially from a performance perspec-
tive, we define additional structures: the Lexical
Only Centered Tree (LOCT), e.g. see Figure 5,
which is an LCT only containing lexical nodes; the
Lexical and PoS-Tag Sequences Tree (LPST), e.g.
see Figure 6, which ignores the syntactic structure
of the sentence being a simple sequence of PoS-Tag
nodes, where lexicals are simply added as children;
and the Lexical Sequence Tree (LST), where only
lexical items are leaves of a single root node. PTK

1039



and PSTK applied to it simulates a standard SK and
an SK with smoothing, respectively.
4.3 Structural Features
Section 2 has already described the kind of features
generated by SK, STK and PTK. However, it is
interesting to analyze what happens when SPTK is
applied. For example, given the following sentence
syntactically and semantically similar to s1:

(s2) What is the dimension of an ice hockey goal?

Figure 8 shows the corresponding GRCT, whose
largest PTK fragment shared with the GRTC of s1
(Fig. 3) is: (ROOT (SBJ (WP (what::w))) (PRD (NMOD
(DT (the::d))) (NN) (NMOD (IN (of::i)) (PMOD (NMOD (DT))

(NMOD (NN)) (NN)))) (P (. (?::.)))). If smoothing is ap-
plied the matching is almost total, i.e. also the chil-
dren: width::n/dimension::n, football::n/hockey::n
and field::n/goal::n will be matched (with a smooth-
ing equal to the product of their similarities).

The matching using LCT is very interesting:
without smoothing, the largest subtree is: (be::v
(what::w (SBJ) (WP)) (ROOT)); when smoothing is used
only the fragment (NMOD (NN (ice::n)) will not be part
of the match. This suggests that LCT will probably
receive the major benefit from smoothing. Addition-
ally, with respect to all the above structures, LCT is
the only one that can produce only lexical fragments,
i.e. paths only composed by similar lexical nodes
constrained by syntactic dependencies. All the other
trees produce fragments in which lexicals play the
role of features of GR or PoS-Tag nodes.

5 Experiments
The aim of the experiments is to analyze different
levels of representation, i.e. structure, for syntactic
dependency parses. At the same time, we compare
with the constituency trees and different kernels to
derive the best syntactic paradigm for convolution
kernels. Most importantly, the role of lexical simi-
larity embedded in syntactic structures will be inves-
tigated. For this purpose, we first carry out extensive
experiments on coarse and fine grained QC and then
we verify our findings on a completely different task,
i.e. Argument Classification in SRL.

5.1 General experimental setup
Tools: for SVM learning, we extended the SVM-
LightTK software3 (Moschitti, 2006a) (which in-

3http://disi.unitn.it/moschitti/Tree-Kernel.htm

cludes structural kernels in SVMLight (Joachims,
2000)) with the smooth match between tree nodes.
For generating constituency trees, we used the Char-
niak parser (Charniak, 2000) whereas we applied
LTH syntactic parser (described in (Johansson and
Nugues, 2008a)) to generate dependency trees.
Lexical Similarity: we used the Eq. 1 with ω1 =
ω2 = 1 and σ is derived with both approaches de-
scribed in Sec. 2.3. The first approach is LSA-based:
LSA was applied to ukWak (Baroni et al., 2009),
which is a large scale document collection made by
2 billion tokens. More specifically, to build the ma-
trix M, POS tagging is first applied to build rows
with pairs 〈lemma, ::POS〉, or lemma::POS in brief.
The contexts of such items are the columns of M
and are short windows of size [−3,+3], centered on
the items. This allows for better capturing syntactic
properties of words. The most frequent 20,000 items
are selected along with their 20k contexts. The en-
tries of M are the point-wise mutual information be-
tween them. The SVD reduction is then applied to
M, with a dimensionality cut of l = 250. The sec-
ond approach uses the similarity based on word list
(WL) as provided in (Li and Roth, 2002).
Models: SVM-LightTK is applied to the different
tree representations discussed in Section 4. Since
PTK and SPTK are typically used in our experi-
ments, to have a more compact acronym for each
model, we associate the latter with the name of the
structure, i.e. this indicates that PTK is applied to
it. Then the presence of the subscript WL and LSA
indicates that SPTK is applied along with the corre-
sponding similarity, e.g. LCTWL is the SPTK ker-
nel applied to LCT structure, using WL similarity.
We experiment with multi-classification, which we
model through one-vs-all scheme by selecting the
category associated with the maximum SVM mar-
gin. The quality of such classification is measured
with accuracy. We determine the statistical signi-
cance by using the model described in (Yeh, 2000)
and implemented in (Padó, 2006).
The parameterization of each classifier is carried on
a held-out set (30% of the training) and concerns
with the setting of the trade-off parameter (option -
c) and the Leaf Weight (LeW ) (see Sec. 5.2), which
is used to linearly scale the contribution of the leaf
nodes. In contrast, the cost-factor parameter of the
SVM-LightTK is set as the ratio between the num-

1040



80% 

82% 

84% 

86% 

88% 

90% 

92% 

0 1000 2000 3000 4000 5000 

A
cc

ur
ac

y 

Number of Examples 

PCT 

LPST 

CT 

LOCT 

GRCT 

LCT 

BOW 

Figure 9: Learning curves: comparison with no similarity

80% 

82% 

84% 

86% 

88% 

90% 

92% 

94% 

0 1000 2000 3000 4000 5000 

A
cc

ur
ac

y 

Number of Examples 

PCT-WL 

LPST-WL 

CT-WL 

LOCT-WL 

GRCT-WL 

LCT-WL 

PCT 

Figure 10: Learning curves: comparison with similarity

ber of negative and positive examples for attempting
to have a balanced Precision/Recall.

5.2 QC experiments
For these experiments, we used the UIUC dataset
(Li and Roth, 2002). It is composed by a training
set of 5,452 questions and a test set of 500 ques-
tions4. Question classes are organized in two levels:
6 coarse-grained classes (like ENTITY or HUMAN)
and 50 fine-grained sub-classes (e.g. Plant, Food
as subclasses of ENTITY).

The outcome of the several kernels applied to sev-
eral structures for the coarse and fine grained QC
is reported in Table 1. The first column shows
the experimented models, obtained by applying
PTK/SPTK to the structures described in Sec. 4. The
last two rows are: CT-STK, i.e. STK applied to a
constituency tree and BOW, which is a linear ker-

4http://cogcomp.cs.illinois.edu/Data/QA/QC/

nel applied to lexical vectors. Column 2, 3 and 4
report the accuracy using no, LSA and WL similar-
ity, where LeW is the amplifying parameter, i.e. a
weight associated with the leaves in the tree. The
last three columns refer to the fine grained task.

It is worth nothing that when no similarity is ap-
plied: (i) BOW produces high accuracy, i.e. 88.8%
but it is improved by STK (the current state-of-the-
art5 in QC (Zhang and Lee, 2003; Moschitti et al.,
2007)); (ii) PTK applied to the same tree of STK
produces a slightly lower value (non-statistically
significant difference); (iii) interestingly, when PTK
is instead applied to dependency structures, it im-
proves STK, i.e. 91.60% vs 91.40% (although not
significantly); and (iv) LCT, strongly based on lexi-
cal nodes, is the least accurate, i.e 90.80% since it is
obviously subject to data sparseness (fragments only
composed by lexicals are very sparse).

The very important results can be noted when lex-
ical similarity is used, i.e. SPTK is applied: (a) all
the syntactic-base structures using both LSA or WL
improve the classification accuracy. (b) CT gets the
lowest improvement whereas LCT achieves an im-
pressive result of 94.80%, i.e more than 41% of rel-
ative error reduction. It seems that the lexical similar
paths when driven by syntax produces accurate fea-
tures. Indeed, when syntax is missing such as for the
unstructured lexical path of LSTLSA, the accuracy
does not highly improve or may also decrease. Ad-
ditionally, the result of our best model is so high that
its errors only refer to questions like What did Jesse
Jackson organize ?, where the classifier selected En-
tity instead ofHuman category. These refer to clear
cases where a huge amount of background knowl-
edge is needed for deriving the exact solution.

Finally, on the fine grained experiments LCT
still produces the most accurate outcome again ex-
ceeding the state-of-the-art (Zhang and Lee, 2003),
where WL significantly improves on all models (CT
included).

5.3 Learning curves
It is interesting to study the impact of syntac-
tic/semantic kernels on the learning generalization.
For this purpose, Fig. 9 reports the learning curve

5Note that in (Bloehdorn and Moschitti, 2007b), higher ac-
curacy values for smoothed STK are shown for different param-
eters but the best according to a validation set is not highlighted.

1041



COARSE FINE
NO LSA WL NO LSA WL

LeW Acc. LeW Acc. LeW Acc. LeW Acc. LeW Acc. LeW Acc.
CT 4 90.80% 2 91.00% 5 92.20% 4 84.00% 5 83.00% 7 86.60%
GRCT 3 91.60% 4 92.60% 2 94.20% 3 83.80% 4 83.20% 2 85.00%
LCT 1 90.80% 1 94.80% 1 94.20% 0.33 85.40% 1 86.20% 0.33 87.40%
LOCT 1 89.20% 1 93.20% 1 91.80% 1 85.40% 1 86.80% 1 87.00%
LST 1 88.20% 1 85.80% 1 89.60% 1 84.00% 1 80.00% 1 85.00%
LPST 3 89.40% 1 89.60% 1 92.40% 3 84.20% 4 82.20% 1 84.60%
PCT 4 91.20% 4 92.20% 5 93.40% 4 84.80% 5 84.00% 5 85.20%
CT-STK - 91.20% - - - - - 82.20% - - - -
BOW - 88.80% - - - - - 83.20% - - - -

Table 1: Accuracy of structural several kernels on different structures for coarse and fine grained QC

y = 0.051x2.005 

y = 0.030x1.609 

y = 0.068x1.213 

y = 0.081x1.705 

0 

20 

40 

60 

80 

100 

120 

0 10 20 30 40 50 60 

m
ic

ro
se

co
nd

s 

Number of Nodes 

LPST-WL 

GRCT-WL 

GRCT 

LCT-WL 

LCT 

LPST 

Figure 11: Micro-seconds for each kernel computation

of the previous models without lexical similarity
whereas Fig. 10 shows the complete SPTK behavior
through the different structures. We note that when
no similarity is used the dependency trees better
generalize than constituency trees or non-syntactic
structures like LPST or BOW. When WL is acti-
vated, all models outperform the best kernel of the
previous pool, i.e. PCT (see dashed line of Fig. 10
or the top curve in Fig. 9).

5.4 Kernel Efficiency
We plotted the average running time of each compu-
tation of PTK/SPTK applied to the different struc-
tures. We divided the examples from QC based
on the number of nodes in each example. Fig-
ure 11 shows the elapsed time in function of the
number of nodes for different tree representations.
We note that: (i) when the WL is not active, LCT
and GRCT are very fast as they impose hierarchical
matching of subtrees; (ii) when the similarity is ac-
tivated, LCTWL and GRCTWL tend to match many
more tree fragments thus their complexity increases.

However, the equations of the curve fit, shown in the
figure, suggests that the trend is sub-quadratic (x1.7).
Only LPSTWL, which has no structure, matches a
very large number of sequences of nodes, when the
similarity is active. This increases the complexity,
which results in an order higher than 2.
5.5 FrameNet Role Classification Experiments
To verify that our findings are general and that our
syntactic/semantic dependency kernels can be effec-
tively exploited for diverse NLP tasks, we experi-
mented with a completely different application, i.e.
FrameNet SRL classification (gold standard bound-
aries). We used the FrameNet version 1.3 with
the 90/10% split between training and test set (i.e
271,560 and 30,173 examples respectively), as de-
fined in (Johansson and Nugues, 2008b), one of the
best system for FrameNet parsing. We used the LTH
dependency parser. LSA was applied to the BNC
corpus, the source of the FrameNet annotations.

For each of 648 frames, we applied SVM along
with the best models for QC, i.e. GRCT and LCT, to
learn its associated binary role classifiers (RC) for
a total of 4,254 classifiers. For example, Figure 12
shows the LCT representation of the first two roles
of the following sentence:

[Bootleggers]CREATOR, then copy [the film]ORIGINAL
[onto hundreds of V HS tapes]GOAL

Table 2 shows the results of the different multi-
classifiers. GRCT and LCT show a large ac-
curacy, i.e. 87.60. This improves up to 88.74
by activating the LSA similarity. The combina-
tion GRCTLSA+LCTLSA significantly improves the
above model, achieving 88.91%. This is very close
to the state-of-the-art of SRL for classification (us-
ing a single classifier, i.e. no joint model), i.e.
89.6%, achieved in (Johansson and Nugues, 2008b).

1042



copy::v

VBPROOTbootlegger::n

NNSSBJ

copy::v

VBPROOTfilm::n

NNOBJthe::d

DTNMOD

Figure 12: LCT Examples for argument roles

Kernel Accuracy
GRCT 87.60%
GRCTLSA 88,61%
LCT 87.61%
LCTLSA 88.74%
GRCT + LCT 87.99%
GRCTLSA + LCTLSA 88.91%

Table 2: Argument Classification Accuracy

Finally, it should be noted that, to learn and test the
SELF MOTION multi-classifier, containing 14,584
examples, distributed on 22 roles, SVM-SPTK em-
ployed 1.5 h and 10 minutes, respectively6.

6 Final Remarks and Conclusion
In this paper, we have proposed a study on repre-
sentation of dependency structures for the design of
effective structural kernels. Most importantly, we
have defined a new class of kernel functions, i.e. SP-
TKs, that carry out syntactic and lexical similarities
on the above structures. SPTK exploits the latter
by providing generalization trough lexical similar-
ities constrained in them. This allows for automat-
ically generating feature spaces of generalized syn-
tactic/semantic dependency substructures.

To test our models, we carried out experiments
on QC and SRL. These show that by exploiting the
similarity between two sets of words carried out ac-
cording to their dependency structure leads to an un-
precedented result for QC, i.e. 94.8% of accuracy.
In contrast, when no structure is used the accuracy
does not significantly improves. We have also pro-
vided a fast algorithm for the computation of SPTK
and empirically shown that it can easily scale.

It should be noted that our models are not abso-
lutely restricted to QC and SRL. Indeed, since most
of the NLP applications are based on syntactic and
lexical representations, SPTK will have a major im-
pact in most of them, e.g.:

6Using one of the 8 processors of an Intel(R) Xeon(R) CPU
E5430 @ 2.66GHz machine, 32Gb Ram.

• Question Answering, the high results for QC
will positively impact on the overall task.

• SRL, SPTK alone reaches the state-of-the-art
(SOA) (only 0.7% less) in FrameNet role clas-
sification. This is very valuable as previous
work showed that tree kernels (TK) alone per-
form lower than models based on manually en-
gineered features for SRL tasks, e.g., (Mos-
chitti, 2004; Giuglea and Moschitti, 2004; Giu-
glea and Moschitti, 2006; Moschitti, 2006b;
Che et al., 2006; Moschitti et al., 2008). Thus
for the first time in an SRL task, a general
tree kernel reaches the same accuracy of heavy
manual feature design. This also suggests an
improvement when used in combinations with
manual feature vectors.

• Relation Extraction and Pronominal Corefer-
ence, whose state-of-the-art for some tasks is
achieved with the simple STK-CT (see (Zhang
et al., 2006) and (Yang et al., 2006; Versley et
al., 2008), respectively).

• In word sense disambiguation tasks, SPTK can
generalize context according to syntactic and
semantic constraints (selectional restrictions)
making very effective distributional semantic
approaches.

• In Opinion Mining SPTK will allow to match
sentiment words within their corresponding
syntactic counterparts and improve the state-
of-the-art (Johansson and Moschitti, 2010b; Jo-
hansson and Moschitti, 2010a).

• Experiments on Recognizing Textual Entail-
ment (RTE) tasks, the use of SSTK (in-
stead of STK-CT) improved the state-of-the-art
(Mehdad et al., 2010). SPTK may provide fur-
ther enhancement and innovative and effective
dependency models.

The above points also suggest many promising fu-
ture research directions, which we would like to ex-
plore.

Acknowledgements
This work has been partially supported by the EC
project FP247758: Trustworthy Eternal Systems via
Evolving Software, Data and Knowledge (EternalS).

1043



References
Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and

Eros Zanchetta. 2009. The wacky wide web: a
collection of very large linguistically processed web-
crawled corpora. Language Resources and Evalua-
tion, 43(3):209–226.

Roberto Basili, Marco Cammisa, and Alessandro Mos-
chitti. 2005. Effective use of WordNet semantics
via kernel-based learning. In Proceedings of CoNLL-
2005, pages 1–8, Ann Arbor, Michigan. Association
for Computational Linguistics.

Stephan Bloehdorn and Alessandro Moschitti. 2007a.
Combined syntactic and semantic kernels for text clas-
sification. In Proceedings of ECIR 2007, Rome, Italy.

Stephan Bloehdorn and Alessandro Moschitti. 2007b.
Structure and semantics for expressive text kernels. In
In Proceedings of CIKM ’07.

Stephan Bloehdorn, Roberto Basili, Marco Cammisa, and
Alessandro Moschitti. 2006. Semantic kernels for text
classification based on topological measures of feature
similarity. In Proceedings of ICDM 06, Hong Kong,
2006.

Ulrik Brandes. 2001. A Faster Algorithm for Between-
ness Centrality. Journal of Mathematical Sociology,
25:163–177.

Alexander Budanitsky and Graeme Hirst. 2006. Eval-
uating WordNet-based measures of semantic distance.
Computational Linguistics, 32(1):13–47.

Razvan Bunescu and Raymond Mooney. 2005. A short-
est path dependency kernel for relation extraction. In
Proceedings of HLT and EMNLP, pages 724–731,
Vancouver, British Columbia, Canada, October.

Horst Bunke and Kim Shearer. 1998. A graph distance
metric based on the maximal common subgraph. Pat-
tern Recogn. Lett., 19(3-4):255–259, March.

Nicola Cancedda, Eric Gaussier, Cyril Goutte, and
Jean Michel Renders. 2003. Word sequence kernels.
Journal of Machine Learning Research, 3:1059–1082.

O. Chapelle, B. Schlkopf, and A. Zien. 2006. Semi-
Supervised Learning. Adaptive computation and ma-
chine learning. MIT Press, Cambridge, MA, USA, 09.

Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of NAACL’00.

Wanxiang Che, Min Zhang, Ting Liu, and Sheng Li.
2006. A hybrid convolution tree kernel for semantic
role labeling. In Proceedings of the COLING/ACL on
Main conference poster sessions, COLING-ACL ’06,
pages 73–80, Stroudsburg, PA, USA. Association for
Computational Linguistics.

Michael Collins and Nigel Duffy. 2002. New Rank-
ing Algorithms for Parsing and Tagging: Kernels over
Discrete Structures, and the Voted Perceptron. In Pro-
ceedings of ACL’02.

Courtney Corley and Rada Mihalcea. 2005. Measur-
ing the semantic similarity of texts. In Proceedings of
the ACL Workshop on Empirical Modeling of Semantic
Equivalence and Entailment, pages 13–18, Ann Arbor,
Michigan, June. Association for Computational Lin-
guistics.

Jim Cowie, Joe Guthrie, and Louise Guthrie. 1992. Lex-
ical disambiguation using simulated annealing. In in
COLING, pages 359–365.

Nello Cristianini, John Shawe-Taylor, and Huma Lodhi.
2001. Latent semantic kernels. In Carla Brodley and
Andrea Danyluk, editors, Proceedings of ICML-01,
18th International Conference on Machine Learning,
pages 66–73, Williams College, US. Morgan Kauf-
mann Publishers, San Francisco, US.

Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In Proceedings of
ACL, pages 423–429, Barcelona, Spain, July.

Chad Cumby and Dan Roth. 2003. Kernel Methods for
Relational Learning. In Proceedings of ICML 2003.

Hal Daumé III and Daniel Marcu. 2004. Np bracketing
by maximum entropy tagging and SVM reranking. In
Proceedings of EMNLP’04.

Jason V. Davis, Brian Kulis, Prateek Jain, Suvrit Sra, and
Inderjit S. Dhillon. 2007. Information-theoretic met-
ric learning. In Proceedings of the 24th international
conference on Machine learning, ICML ’07, pages
209–216, New York, NY, USA. ACM.

Linton C. Freeman. 1977. A Set of Measures of Central-
ity Based on Betweenness. Sociometry, 40(1):35–41.

Hagen Fürstenau and Mirella Lapata. 2009. Graph align-
ment for semi-supervised semantic role labeling. In
In Proceedings of EMNLP ’09, pages 11–20, Morris-
town, NJ, USA.

Ana-Maria Giuglea and Alessandro Moschitti. 2004.
Knowledge Discovering using FrameNet, VerbNet and
PropBank. In In Proceedings of the Workshop on On-
tology and Knowledge Discovering at ECML 2004,
Pisa, Italy.

A.-M. Giuglea and A. Moschitti. 2006. Semantic role
labeling via framenet, verbnet and propbank. In Pro-
ceedings of ACL, Sydney, Australia.

Alfio Gliozzo, Claudio Giuliano, and Carlo Strapparava.
2005. Domain kernels for word sense disambiguation.
In Proceedings of ACL’05, pages 403–410.

G. Golub and W. Kahan. 1965. Calculating the singular
values and pseudo-inverse of a matrix. Journal of the
Society for Industrial and Applied Mathematics: Se-
ries B, Numerical Analysis, 2(2):pp. 205–224.

Zellig Harris. 1964. Distributional structure. In Jer-
rold J. Katz and Jerry A. Fodor, editors, The Philos-
ophy of Linguistics. Oxford University Press.

1044



J. J. Jiang and D. W. Conrath. 1997. Semantic Similarity
Based on Corpus Statistics and Lexical Taxonomy. In
International Conference Research on Computational
Linguistics (ROCLING X).

T. Joachims. 2000. Estimating the generalization per-
formance of a SVM efficiently. In Proceedings of
ICML’00.

Richard Johansson and Alessandro Moschitti. 2010a.
Reranking models in fine-grained opinion analysis. In
Proceedings of the 23rd International Conference of
Computational Linguistics (Coling 2010), pages 519–
527, Beijing, China.

Richard Johansson and Alessandro Moschitti. 2010b.
Syntactic and semantic structure for opinion expres-
sion detection. In Proceedings of the Fourteenth Con-
ference on Computational Natural Language Learn-
ing, pages 67–76, Uppsala, Sweden.

Richard Johansson and Pierre Nugues. 2008a.
Dependency-based syntactic–semantic analysis with
PropBank and NomBank. In CoNLL 2008: Proceed-
ings of the Twelfth Conference on Natural Language
Learning, pages 183–187, Manchester, United King-
dom.

Richard Johansson and Pierre Nugues. 2008b. The effect
of syntactic representation on semantic role labeling.
In Proceedings of COLING, Manchester, UK, August
18-22.

Taku Kudo and Yuji Matsumoto. 2003. Fast methods for
kernel-based text analysis. In Proceedings of ACL’03.

Taku Kudo, Jun Suzuki, and Hideki Isozaki. 2005.
Boosting-based parse reranking with subtree features.
In Proceedings of ACL’05.

Claudia Leacock and Martin Chodorow, 1998. Combin-
ing Local Context and WordNet Similarity for Word
Sense Identification, chapter 11, pages 265–283. The
MIT Press.

X. Li and D. Roth. 2002. Learning question classifiers.
In Proceedings of ACL’02.

Yashar Mehdad, Alessandro Moschitti, and Fabio Mas-
simo Zanzotto. 2010. Syntactic/semantic structures
for textual entailment recognition. In HLT-NAACL,
pages 1020–1028.

Rada Mihalcea, Courtney Corley, and Carlo Strappar-
ava. 2005. Corpus-based and knowledge-based mea-
sures of text semantic similarity. In Proceedings of the
American Association for Artificial Intelligence (AAAI
2006), Boston, July.

Rada Mihalcea. 2005. unsupervised large-vocabulary
word sense disambiguation with graph-based algo-
rithms for sequence data labeling. In In HLT/EMNLP
2005, pages 411–418.

Alessandro Moschitti, Silvia Quarteroni, Roberto Basili,
and Suresh Manandhar. 2007. Exploiting syntactic

and shallow semantic kernels for question/answer clas-
sification. In Proceedings of ACL’07.

Alessandro Moschitti, Daniele Pighin, and Roberto
Basili. 2008. Tree kernels for semantic role labeling.
Computational Linguistics, 34(2):193–224.

A. Moschitti. 2004. A study on convolution kernels
for shallow semantic parsing. In Proceedings of ACL,
Barcelona, Spain.

Alessandro Moschitti. 2006a. Efficient convolution ker-
nels for dependency and constituent syntactic trees. In
Proceedings of ECML’06, pages 318–329.

Alessandro Moschitti. 2006b. Making tree kernels prac-
tical for natural language learning. In Proccedings of
EACL’06.

Roberto Navigli and Mirella Lapata. 2010. An Experi-
mental Study of Graph Connectivity for Unsupervised
Word Sense Disambiguation. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 32(4):678–
692.

Sebastian Pado and Mirella Lapata. 2007. Dependency-
based construction of semantic space models. Compu-
tational Linguistics, 33(2).

Sebastian Padó, 2006. User’s guide to sigf: Signifi-
cance testing by approximate randomisation.

Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004a. WordNet::Similarity - Measuring the Re-
latedness of Concept. In Proc. of 5th NAACL, Boston,
MA.

Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004b. Wordnet::similarity - measuring the re-
latedness of concepts. In Daniel Marcu Susan Du-
mais and Salim Roukos, editors, HLT-NAACL 2004:
Demonstration Papers, pages 38–41, Boston, Mas-
sachusetts, USA, May 2 - May 7. Association for
Computational Linguistics.

Philip Resnik. 1995. Using information content to eval-
uate semantic similarity in a taxonomy. In In Proceed-
ings of the 14th International Joint Conference on Ar-
tificial Intelligence, pages 448–453.

Magnus Sahlgren. 2006. The Word-Space Model. Ph.D.
thesis, Stockholm University.

Hinrich Schtze. 1998. Automatic word sense discrimi-
nation. Journal of Computational Linguistics, 24:97–
123.

John Shawe-Taylor and Nello Cristianini. 2004. Kernel
Methods for Pattern Analysis. Cambridge University
Press.

Libin Shen, Anoop Sarkar, and Aravind k. Joshi. 2003.
Using LTAG Based Features in Parse Reranking. In
Empirical Methods for Natural Language Processing
(EMNLP), pages 89–96, Sapporo, Japan.

Georges Siolas and Florence d’Alch Buc. 2000. Sup-
port vector machines based on a semantic kernel for

1045



text categorization. In Proceedings of the IEEE-INNS-
ENNS International Joint Conference on Neural Net-
works (IJCNN’00)-Volume 5, page 5205. IEEE Com-
puter Society.

Ivan Titov and James Henderson. 2006. Porting statisti-
cal parsers with data-defined kernels. In Proceedings
of CoNLL-X.

Kristina Toutanova, Penka Markova, and Christopher
Manning. 2004. The Leaf Path Projection View of
Parse Trees: Exploring String Kernels for HPSG Parse
Selection. In Proceedings of EMNLP 2004.

Yannick Versley, Alessandro Moschitti, Massimo Poe-
sio, and Xiaofeng Yang. 2008. Coreference sys-
tems based on kernels methods. In The 22nd Interna-
tional Conference on Computational Linguistics (Col-
ing’08), Manchester, England.

Zhibiao Wu and Martha Palmer. 1994. Verb semantics
and lexical selection. In 32nd. Annual Meeting of the
Association for Computational Linguistics, pages 133
–138, New Mexico State University, Las Cruces, New
Mexico.

Xiaofeng Yang, Jian Su, and Chewlim Tan. 2006.
Kernel-based pronoun resolution with structured syn-
tactic knowledge. In Proc. COLING-ACL 06.

Alexander S. Yeh. 2000. More accurate tests for the sta-
tistical significance of result differences. In COLING,
pages 947–953.

Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2002. Kernel methods for relation
extraction. In Proceedings of EMNLP-ACL, pages
181–201.

Dell Zhang and Wee Sun Lee. 2003. Question classifica-
tion using support vector machines. In Proceedings of
the 26th annual international ACM SIGIR conference
on Research and development in informaion retrieval,
pages 26–32. ACM Press.

Min Zhang, Jie Zhang, and Jian Su. 2006. Explor-
ing Syntactic Features for Relation Extraction using a
Convolution tree kernel. In Proceedings of NAACL.

Peixiang Zhao, Jiawei Han, and Yizhou Sun. 2009. P-
Rank: a comprehensive structural similarity measure
over information networks. In CIKM ’09: Proceed-
ing of the 18th ACM conference on Information and
knowledge management, pages 553–562, New York,
NY, USA. ACM.

1046


