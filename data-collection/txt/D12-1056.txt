










































A Unified Approach to Transliteration-based Text Input with Online Spelling Correction


Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 609–618, Jeju Island, Korea, 12–14 July 2012. c©2012 Association for Computational Linguistics

A Unified Approach to Transliteration-based Text Input                     

with Online Spelling Correction 

 

Hisami Suzuki              Jianfeng Gao 
Microsoft Research 

One Microsoft Way, Redmond WA 98052 USA 

{hisamis,jfgao}@microsoft.com 

 

Abstract 

This paper presents an integrated, end-to-end 

approach to online spelling correction for text 

input. Online spelling correction refers to the 

spelling correction as you type, as opposed to 

post-editing. The online scenario is 

particularly important for languages that 

routinely use transliteration-based text input 

methods, such as Chinese and Japanese, 

because the desired target characters cannot 

be input at all unless they are in the list of 

candidates provided by an input method, and 

spelling errors prevent them from appearing 

in the list. For example, a user might type 

suesheng by mistake to mean xuesheng 学生 
'student' in Chinese; existing input methods 

fail to convert this misspelled input to the 

desired target Chinese characters. In this 

paper, we propose a unified approach to the 

problem of spelling correction and 

transliteration-based character conversion 

using an approach inspired by the phrase-

based statistical machine translation 

framework. At the phrase (substring) level, k 
most probable pinyin (Romanized Chinese) 

corrections are generated using a monotone 

decoder; at the sentence level, input pinyin 

strings are directly transliterated into target 

Chinese characters by a decoder using a log-

linear model that refer to the features of both 

levels. A new method of automatically 

deriving parallel training data from user 

keystroke logs is also presented. Experiments 

on Chinese pinyin conversion show that our 

integrated method reduces the character error 

rate by 20% (from 8.9% to 7.12%) over the 

previous state-of-the art based on a noisy 

channel model.  

1 Introduction 

This paper addresses the problem of online 

spelling correction, which tries to correct users' 

misspellings as they type, rather than post-editing 

them after they have already been input. This 

online scenario is particularly important for 

languages that routinely use transliteration-based 

text input methods, including Chinese and 

Japanese: in these languages, characters (called 

hanzi in Chinese and kanji/kana in Japanese) are 

typically input by typing how they are pronounced 

in Roman alphabet (called pinyin in Chinese, 

romaji in Japanese), and selecting a conversion 

candidate among those that are offered by an input 

method system, often referred to as IMEs or input 

method editors. One big challenge posed by 

spelling mistakes is that they prevent the desired 

candidates from appearing as conversion 

candidates, as in Figure 1: suesheng is likely to be 

a spelling error of xuesheng学生 'student', but it is 

not included as one of the candidates.  

                  

Figure 1: Spelling mistake prevents the desired output 

(学生) from appearing in the list of candidates 

This severely limits the utility of an IME, as 

spelling errors are extremely common. Speakers of 

a non-standard dialect and non-native speakers 

have a particularly hard time, because they may 

not know the standard pronunciation of the word to 

begin with, preventing them from inputting the 

word altogether. Error-tolerant word completion 

and next word prediction are also highly desirable 

features for text input on software (onscreen) 

keyboards for any language, making the current 

work relevant beyond Chinese and Japanese.  

In this paper, we propose a novel, unified 

system of text input with spelling correction, using 

609



Chinese pinyin-to-hanzi conversion as an example. 

We first formulate the task of pinyin spelling 

correction as a substring-based monotone 

translation problem, inspired by phrase-based 

statistical machine translation (SMT) systems 

(Koehn et al., 2003; Och and Ney, 2004): we 

consider the pinyin input (potentially with errors) 

as the source language and the error-corrected 

pinyin as the target, and build a log-linear model 

for spelling correction. In doing so, we also 

propose a novel, unsupervised method of 

collecting parallel training data from user input 

logs. We then build an integrated end-to-end text 

input system that directly converts a potentially 

erroneous input pinyin sequence into a desired 

hanzi sequence, also formulated as a monotone 

phrase-based SMT problem, in which the feature 

functions of the substring-based error correction 

component are integrated and jointly optimized 

with the sentence-level feature functions for 

character conversion  

Our method generalizes and improves over the 

previous state-of-the-art methods for the task of 

error correction and text input in several crucial 

respects. First, our error correction model is 

designed and implemented as a substring-based, 

fully trainable system based on a log-linear model, 

which has been shown effective for related tasks 

such as transliteration and letter-to-phone 

conversion, but has not been attempted for the task 

of spelling correction. Second, we build an end-to-

end pinyin-to-hanzi conversion system by 

combining all the feature functions used in the 

error correction and character conversion 

components in an SMT-style log-linear model, 

where the feature weights are trained 

discriminatively for the end-to-end task. This 

integration method generalizes the previous 

approach based on a noisy channel model (Chen 

and Lee, 2000; Zheng et al. 2011b), in which only 

the error model and the conversion model 

probabilities are used and combined with equal 

weights. Finally, like other statistical systems, the 

amount and quality of training data control the 

quality of the outcome; we thus propose a new, 

language-independent method of deriving parallel 

data for spelling correction from user keystroke 

logs.  

We performed experiments on various methods 

of integrating the error correction and character 

conversion sub-components. Our best system, a 

fully integrated SMT-based approach, reduces the 

character error rate by 35% on test data that is 

completely independent of the creation of error 

correction and character conversion models.  

In what follows, we first give the background of 

this research in Section 2. We then describe our 

approach to the spelling correction task (Section 3) 

and the end-to-end conversion task (Section 4). We 

summarize our contribution and conclude with 

remarks for future directions in Section 5.  

2 Related Work  

The current work builds on many previous works 

on the task of monotone substring-based 

transduction, including spelling correction, letter-

to-phone conversion and transliteration between 

different scripts. In particular, our substring-based 

approach to spelling correction is motivated by the 

success on transliteration (e.g., Sherif and Kondrak, 

2007; Cherry and Suzuki, 2009) and letter-to-

phoneme conversion (e.g., Jiampojamarn et al., 

2007; Rama et al., 2009). One big challenge of the 

spelling correction research is the general lack of 

naturally occurring paired data of contextual 

spelling errors and their correction. Previous work 

has therefore either focused on the task of 

correcting out-of-vocabulary words out of context 

(e.g., Brill and Moore, 2000; Toutanova and 

Moore, 2002), or has resorted to innovative 

methods of data collection. For example, Banko 

and Brill (2001) generate data artificially by 

substituting words from a confusion word set in 

text for building a contextual speller; Whitelaw et 

al. (2009) use word frequency and edit distance 

information to harvest error pairs from a web 

corpus in an unsupervised manner; Bertoldi et al. 

(2010) intentionally corrupt clean text by adding 

noise to the data. Another approach to spelling 

error data collection uses web search query logs, 

available in large quantity (albeit to limited 

institutions), and limit its focus on the task of 

correcting misspelled queries (e.g., Cucerzan and 

Brill, 2004; Gao et al., 2010; Sun et al., 2010; 

Duan and Hsu, 2011). The problem of data 

collection is particularly difficult for pinyin error 

correction, as pinyin is not a final form of text in 

Chinese, so it is not recorded in final text. Zheng et 

al. (2011a) study a log of pinyin input method and 

use the backspace key to learn the user mistyping 

behavior, but they do so only for the purpose of 

610



data analysis, and do not build a statistical model 

from this data.  

Text input methods have been commercially 

available for decades for inputting Chinese and 

Japanese, but have also recently become available 

for other non-Roman script languages including 

Arabic and the languages of India.
1
 Early research 

work on text input methods includes e.g., Mori et 

al. (1998), Chen and Lee (2000) and Gao et al. 

(2002), all of which approach the problem using a 

noisy channel model. Discriminative approaches 

have also been proposed, e.g., Suzuki and Gao 

(2005); Tokunaga et al. (2011). There is only a 

very limited amount of work that deals with 

spelling correction in the context of text input: 

Zheng et al. (2011b) represents a recent work 

based on a noisy channel model, which defines our 

baseline. Their work is strictly word-based and 

only handles the correction of out-of-vocabulary 

pinyin words into in-vocabulary pinyin words, 

while our substring-based model is not limited by 

these constraints.  

The current work also has an affinity to the task 

of speech translation in that the parallel data 

between the input (speech signal) and the output 

(text in foreign language) is not directly available, 

but is mediated by a corrected (transcribed) form 

of input. Zhang et al. (2011) is thus relevant to our 

study, though their approach differs from ours in 

that we build an integrated system that include the 

feature functions of both error correction and 

character conversion sub-systems.  

3 Substring-based Spelling Correction 

using a Log-linear Model 

In this section, we describe our approach to pinyin 

error correction within a log-linear framework. 

Though our current target is pinyin error correction, 

the method described in this section is applicable 

to any language of interest.  

The spelling correction problem has been 

standardly formulated within the framework of 

noisy channel model (e.g., Kernighan et al., 1990). 

Let A be the input phonetic string in pinyin. The 

task of spelling correction is to search for the best 

                                                           
1 A few examples include Google Transliterate 

(http://www.google.com/transliterate/) and Microsoft Maren 

(http://www.microsoft.com/middleeast/egypt/cmic/maren/) / 

ILIT (http://specials.msn.co.in/ilit/Hindi.aspx). Quillpad 

(http://quillpad.in/) is also popularly used in India. 

correction candidate in pinyin C* among all 

possible corrections for each potentially misspelled 

pinyin A: 

         
        

   |                                               

Applying Bayes' Rule and dropping the constant 

denominator, we have 

         
        

   |                                         

where the error model    |  models the 
translation probability from C to A, and the 

language model      models how likely the 
output C is a correctly spelled pinyin sequence. 

Many variations on the error model have been 

proposed, including substring-based (Brill and 

Moore, 2000) and pronunciation-based (Toutanova 

and Moore, 2002) models.  

Our model is inspired by the SMT framework, 

in which the error correction probability    |   of 
Equation (1) is directly modeled using a log-linear 

model of the following form:   

   |   
 

    
   ∑                               

 

 

where Z(A) is the normalization factor, hi is a 

feature function and λi is the feature weight. 

Similarly to phrase-based SMT, many feature 

functions are derived from the translation and 

language models, where the translation model-

derived features are trained using a parallel corpus 

of original pinyin and correction pairs. The argmax 

of Equation (1) defines the search operation: we 

use a left-to-right beam search decoder to seek for 

each input pinyin the best correction according to 

Equation (3).   
We first describe how the paired data for 

deriving the error model probabilities is generated 

from user logs in Section 3.1, and then how the 

models are trained and the model weights are 

learned in Section 3.2. We discuss the results of 

pinyin error correction as an independent task in 

Section 3.3.  

3.1 Generating error correction pairs from 

keystroke logs 

Unlike English text, which includes instances of 

misspelled words explicitly, pinyin spelling errors 

are not found in a corpus, because pinyin is used as 

a means of inputting text, and is not part of the 

611



final written form of the language. Therefore, 

pinyin error correction pairs must be created 

intentionally. We chose the method of 

implementing a version of an input method which 

records the keystrokes of users while they are 

asked to type a particular Chinese text in hanzi; in 

doing so, we captured each keystroke issued by the 

user behind the scene. Such keystroke logs include 

the use of the backspace key, from which we 

compute the pinyin strings after the usage of the 

backspace keys as well as the putative pinyin string 

had the user not corrected it using the backspace 

key.
2
 Table 1 shows a few examples of the entries 

in the keystroke log, along with the computed 

pinyin strings before and after correction. Each 

entry (or phrase) in the log represents the unit that 

corresponds to the sequence the user input at once, 

at the end of which the user committed to a 

conversion candidate, which typically consists of 

one or more words. While the post-correction 

string can be straightforwardly derived by deleting 

the same number of characters preceding the 

backspaces, the computation of the pre-correction 

string is trickier and ambiguous, because the 

backspace key is used for the purpose of both 

deletion and substitution (delete and replace) 

operations. In Table 1, a backspace usage is 

indicated by _ in the original keystroke sequence 

that is logged. In the second example, a deletion 

interpretation will generate zhonguo as a pre-

correction string, while substitution interpretation 

will generate zhonguoo. In order to recover the 

desired pre-correcting string, we compared the 

prefix of the backspace usage (zhonguo) with the 

substrings after error correction (zhong, zhongg, 

zhonggu…). We considered that the prefix was 

spell-corrected into the substring which is the 

longest and with the smallest edit distance: in this 

case, zhonguo is considered an error for 

zhongguo, therefore recovering the pre-correction 

string of the whole sequence as zhonguo. Note 

that this method of error data extraction is general 

                                                           
2 Zheng et al. (2011a) also uses the backspace key in the IME 

log to generate error-correction pairs, but they focus on the 

usage of a backspace after the desired hanzi characters have 

been input, i.e., the backspace key is used to delete one or 

more hanzi characters. In contrast, our method focuses on the 

use of backspace to delete one or more pinyin characters 

before conversion. This simulates the scenario of online error 

correction more truthfully, and can collect paired data in large 

quantity faster.  

and is language-independent. Since paired error 

correction data do not exist naturally and is 

expensive to collect for any language, we believe 

that the proposed method is useful beyond the case 

of Chinese text input and applicable to the data 

collection of the spelling correction task in general. 

In a related work (Baba and Suzuki, 2012), we 

collected such keystroke data using Amazon's 

Mechanical Turk for English and Japanese, and 

released the error-correction pairs for research 

purposes.
3
  

The extracted pairs are still quite noisy, because 

one error correction behavior might not completely 

eliminate the errors in typing a word. For example, 

in trying to type women 我们 'we', a user might 
first type wmen, hit the backspaces key four times, 

retype womeen, and commit to a conversion 

candidate by mistake. We extract the pair (wmen, 

womeen) from this log incorrectly, which is one of 

the causes of the noise in the data. Despite these 

remaining errors, we use the data without further 

cleaning, as we expect our approach to be robust 

against a certain amount of noise.  

Keystroke data was collected for three text 

domains (chat, blog and online forum) from 60 

users, resulting in 86,783 pairs after removing 

duplicates. The data includes the pairs with the 

same source and target, with about 41% 

representing the case of correction. We used 5,000 

pairs for testing, 1,000 pairs for tuning the log-

linear model weights (see the next subsection), and 

the remaining portion for training the error 

correction component.  

3.2 Training the log-linear model 

The translation model captures substring-based 

spelling error patterns and their transformation 

probabilities. The model is learned from large 

amounts of pinyin-correction pairs mined from 

user keystroke logs discussed above. Take the 

                                                           
3 Available at http://research.microsoft.com/en-

us/downloads/4eb8d4a0-9c4e-4891-8846-

7437d9dbd869/default.aspx.  

keystroke pre-

correction 

post-

correction 

n a n s _ r e n nansen nanren 

z h o n g u o _ _ g u o zhonguo 

(*zhonguoo) 

zhongguo 

Table 1: Computation of pre- and post-correction 

strings from keystroke log 

612



following pinyin-correction pair as an example, 

where the input pinyin and its correction are 

aligned at the character level: given a pair (A,C), 

we align the letters in A with those in C so as to 

minimize the edit distance between A and C based 

on single character insertions, deletions and 

substitutions. 

 
From this pair, we learn a set of error patterns that 

are consistent with the character alignment,
4
 each 

of which is a pair of substrings indicating how the 

spelling is transformed from one to another. Some 

examples of extracted phrases are (wanmian, 

waimian) and (andshi, andeshi). In our 

implementation, we extract all patterns with a 

substring length of up to 9 characters. We then 

learn the translation probabilities for each pair 

using maximum likelihood estimation (MLE). Let 

(a,c) denote a pair. For each pair, we learn the 

translation probabilities P(c|a) and P(a|c), 

estimated using MLE, as well as lexical weights in 

two directions following Koehn et al. (2003).  Our 

error correction model is completely substring-

based and does not use a word-based lexicon, 

which gives us the flexibility of generating unseen 

correction targets as well as supporting pinyin 

input consisting of multiple words at a time. For 

the language model, we use a character 9-gram 

model to capture the knowledge of correctly 

spelled pinyin words and phrases. We trained the 

language model using the target portion of the 

parallel data described in Section 3.1, though it is 

possible to train it with an arbitrary text in pinyin 

when such data is available.  

In addition to the feature functions derived from 

the error and language models, we also use word 

and phrase penalties as feature functions, which are 

commonly used in SMT. These features also make 

sense in the current context, as using fewer phrase 

means encouraging longer ones with more context, 

and the target character length can capture 

tendencies to delete or insert words in errors. 

                                                           
4 Consistency here implies two things. First, there must be at 

least one aligned character pair in the aligned phrase. Second, 

there must not be any alignments from characters inside the 

aligned phrase to characters outside the phrase. That is, we do 

not extract a phrase pair if there is an alignment from within 

the phrase pair to outside the phrase pair. 

Overall, the log-linear model uses 7 feature 

functions: 4 derived from the translation models, 

word and phrase penalties, and the language model. 

The model weights were trained using the 

minimum error rate training algorithm (MERT, 

Och, 2003). We tried MERT with two objective 

functions: one that uses the 4-gram BLEU score as 

straightforwardly adapted from SMT, and the other 

that minimizes the character error rate (CER). CER 

is based on the edit distance between the reference 

and system output, which is used for evaluating the 

IME accuracy (Section 4.3). It is more directly 

related with the word/phrase-level accuracy, which 

we used to evaluate the error correction module in 

isolation, than the BLEU metric. As we will show 

below, however, using different objective 

functions turned out to have only a minimal impact 

on the spelling correction accuracy.  

3.3 Experiments and results 

The performance of pinyin error correction was 

evaluated on two data sets: (1) log-test: the test set 

of the data in Section 3.1, which is derived in the 

same way as the training data but is noisy, 

consisting of 5,000 phrases of which 2,020 are 

misspelled; (2) CHIME: the gold standard from the 

CHIME data set made available by Zheng et al. 

(2011b),
5
 which is also used in the end-to-end 

evaluation in Section 4. This data set consists of 

2,000 sentence pairs of pinyin input with errors 

and the target hanzi characters, constructed by 

collecting actual user typing logs of the Lancaster 

corpus (McEnery and Xiao, 2004), which includes 

text from newspaper, fiction, and essays.
6

 The 

CHIME data set does not include the corrected 

pinyin string; we therefore generated this by 

running a text-to-pinyin utility,
7
 and created the 

pairs before and after error correction for 

evaluating our pinyin spelling correction module. 

The set contains 11,968 words of which 908 are 

misspelled. 

The results of the evaluation are given in Table 

2. They are for phrase/word-level accuracy, as the 

log-derived data set is for each phrase (a user-

                                                           
5 Available from http://chime.ics.uci.edu/ 
6 Details on the Lancaster corpus are found at 

http://www.lancs.ac.uk/fass/projects/corpus/LCMC/.  
7 We used an in-house tool, but many tools are available 

online. Unlike pinyin-to-hanzi, hanzi-to-pinyin is relatively 

straightforward as most characters have a unique 

pronunciation. 

613



defined unit of conversion, consisting of one to a 

few words), while the CHIME data set is word-

segmented. The baseline accuracy is the accuracy 

of not correcting any error, which is very strong in 

this task: 59.6% and 92.41% for the two data sets, 

respectively. The accuracy on the log-test data is 

generally much lower than the CHIME data, 

presumably because the latter is cleaner, contains 

less errors to begin with, and the unit of evaluation 

is smaller (word) than the log-test (phrase). 

Though CHIME is an out-of-domain data set, the 

proposed model works very well on this set, 

achieving more than 93% accuracy with the best 

output, significantly (at p<0.001 using McNemar's 

test) improving on the strong baseline of not 

correcting any error. The proposed log-linear 

approach is also compared against the noisy 

channel model baseline, which is simulated by 

only using one error model-derived feature 

function    |   and the language model, weighted 
equally, using the same beam search decoder. 

Somewhat surprisingly, the noisy channel model 

results fall below the baseline in both data sets, 

while the log-linear model improves over the 

baseline, especially on the 1-best accuracy: all 

differences between the noisy channel model and 

the log-linear model outputs are significant. Finally, 

regarding the effect of using the CER as the 

objective function of MERT, we only observe 

minimal impact: none of the differences in 

accuracy between the BLEU and CER objectives is 

statistically significant on either data set. For a 

monotone decoding task such as spelling 

correction, using either objective function therefore 

seems to suffice, even though BLEU is more 

indirect and redundant in capturing the phrase-

level accuracy.   

4 A Unified Model of Character 

Conversion with Spelling Correction  

In this section we describe our unified model of 

spelling correction and transliteration-based 

character conversion. Analogous to the spelling 

correction task, the character conversion problem 

can also be considered as a substring-based 

translation problem. The novelty of our approach 

lies in the fact that we take advantage of the 

parallelism between these tasks, and build an 

integrated model that performs spelling correction 

and character conversion at the same time, within 

the log-linear framework. This allows us to 

optimize the feature weights directly for the end 

goal, from which from we can expect a better 

overall conversion accuracy.  

4.1 Noisy channel model approach to 

incorporating error correction in 

character conversion 

The task of pinyin-to-hanzi conversion consists of 

converting the input phonetic strings provided by 

the user into the appropriate word string using 

ideographic characters. This has been formulated 

within the noisy channel model (Chen and Lee, 

2000), in exactly the same manner as the spelling 

correction, as describe in Equations (1) and (2) in 

Section 3. Given the pinyin input A, the task is to 

find the best output hanzi sequence W*: 

  

       
        

   |                                                     

       
        

       |   

In traditional conversion systems which do not 

consider spelling errors, P(A|W) is usually set to 1 

if the word is found in a dictionary of word-

pronunciation pairs, which also defines GEN(A). 

Therefore, the ranking of the candidates relies 

exclusively on the language model probability 

P(W).  

An extension of this formulation to handle 

spelling errors can be achieved by incorporating an 

actual error model P(A|W). Assuming a conditional 

independence of A and W given the error-corrected 

pinyin sequence C, Equation (4) can be re-written 

as: 

 1-best 3-best 20-best 

log-test: No correction  59.6   

log-test: Noisy Channel 49.5 67.86 84.8 

log-test: Proposed (BLEU) 62.46 74.58 86.66 

log-test: Proposed (CER) 62.82 75.06 86.8 

CHIME: No correction 92.41   

CHIME: Noisy Channel 91.29 95.75 98.82 

CHIME: Proposed (BLEU) 93.51 97.38 99.06 

CHIME: Proposed (CER) 93.49 97.29 99.08 

Table 2: Pinyin error correction accuracy (in %) 

614



         
 

   |  

       
 

∑   |     |                                      

 

       
 

∑   |         |  

 

 

Here, P(C|W) corresponds to the channel model of 

traditional input methods, P(W) the language 

model, and P(C|A) the pinyin error correction 

model. There have been attempts to use this 

formulation in text input: for example, Chen and 

Lee (2000) trained a syllable-based model for 

P(C|A) with user keystroke data,
8
 and Zheng et al. 

(2011b) used a model based on a weighted 

character edit distance whose weights are manually 

assigned. This noisy channel integration of error 

correction and character conversion is the state-of-

the-art in the task of error-correcting text input, 

and will serve as our baseline.  

4.2 Log-linear model for error-correcting 

character conversion 

 Similar to the formulation of our error correction 

model in Section 3, we adopt the log-linear model 

for modeling the character conversion probability 

in (4):  

   |   
 

    
   ∑         

 

 

where A = a1,…,an is a sequence of phrases in 

pinyin, and W = w1,…,wn is the corresponding 

sequence in hanzi. A unique challenge of the 

current task is that the parallel data for A and W do 

not exist directly. Therefore, we generated the 

translation phrase table offline by merging the 

                                                           
8 No detail of this data is available in Chen and Lee (2000).  

substring-based phrase table generated for the 

pinyin error correction task in Section 3 with the 

results of character conversion. This process is 

described in detail in Figure 2: k-best candidates 

for each input pinyin phrase a are generated by the 

error model in Section 3, which are then submitted 

offline to an IME system to obtain n-best 

conversion candidates with probabilities. For the 

IME system, we used an in-house conversion 

system, which only uses a word trigram language 

model for ranking. In the resulting translation table, 

defined for each (a, w) pair, the feature functions 

and their values are inherited from the pinyin error 

correction translation table mediated by the 

correction candidates c1…k for a, plus the function 

that defines the IME conversion probability for (cj, 

w). Note that in this final phrase table, the 

correction candidates for a are latent, only 

affecting the values of the feature functions.
9
 The 

final end-to-end system uses the following 11 

features:  

- 7 error correction model features at the phrase 
level  

- IME conversion probability at the phrase level 
- language model probability at the sentence level 
- word/phrase penalty features at the sentence 

level 

The language model at the sentence level is trained 

on a large monolingual corpus of Chinese in hanzi, 

consisting of about 13 million sentences (176 

million words). The IME conversion probability 

                                                           
9 The final phrase table needs to be unique for each phrase pair 

(a, w), though the process described here results in multiple 

entries with the same pair having different feature values, 

because the generation of (a, w) is mediated by multiple 

correction candidates c1…k. These entries need to be added up 

to remove duplicates; we used a heuristic approximation of 

taking the pair where a equals cj (i.e., no spelling correction) 

when multiple entries are found.  

c1  xuesheng f1 ... f7
c2  xueshereng   f1 ... f7
c3  xueshusheng  f1 ... f7
...

+
c1  xuesheng    w1 学生 1

c2  xueshereng w1 学社仍 0.103

        w2 学舌仍 0.101

        w3 学舍仍 0.101

             ...

c3  xueshusheng  w1 学术生 0.102 

            w2 学术声 0.101 

            w3 学术省 0.101

           ...

...

→
w11 xueshseng 学生 f1 ... f7 1

w21 xueshseng 学社仍 f1 ... f7 0.103

w22 xueshseng 学舌仍 f1 ... f7 0.101

w23 xueshseng 学舍仍 f1 ... f7 0.101

...

w31 xueshseng 学术生 f1 ... f7 0.102

w32 xueshseng 学术声 f1 ... f7 0.101

w33 xueshseng 学术省 f1 ... f7 0.101

...

k-best error correction candidates c1...k 
n-best IME conversion 

candidates w1...n for c1...k combined translation table w11...kn

 

Figure 2: Generation of integrated translation table for the pinyin input a = xueshseng 

615



also uses a word trigram model, but it is trained on 

a different data set which we did not have access 

to; we therefore used both of these models. The 

values for k and n can be determined empirically; 

we used 20 for both of them.
10

 This generates 

maximally 400 conversion candidates for each 

input pinyin.  

The feature weights of the log-linear model are 

tuned using MERT. As running MERT on a CER-

based target criterion on the similar, monotone 

translation task of spelling correction did not lead 

to a significant improvement (Section 3.3), we 

simply report the results of using the 4-gram 

BLEU as the training criterion in this task.  

4.3 Experiments and results 

For the evaluation of the end-to-end conversion 

task, we used the CHIME corpus mentioned above. 

In order to use the word trigram language model 

that is built in-house, we re-segmented the CHIME 

corpus using our word-breaker, resulting in 12,102 

words in 2,000 sentences. We then divided the 

sentences in the corpus randomly into two halves, 

and performed a two-fold cross validation 

evaluation. The development portion of the data is 

used to tune the weights of the feature functions in 

MERT-style training. We measured our results 

using character error rate (CER), which is based on 

the longest common subsequence match in 

characters between the reference and the best 

system output. This is a standard metric used in 

evaluating IME systems (e.g., Mori et al., 1998; 

Gao et al., 2002). Let NREF be the number of 

characters in a reference sentence, NSYS be the 

character length of a system output, and NLCS be 

the length of the longest common subsequence 

between them. Then the character-level recall is 

defined as NLCS/NREF, and the precision as NLCS/NSYS. 

The CER based on recall and on precision are then 

defined as 1 – recall and 1 – precision, respectively. 

We report the harmonic mean of these values, 

similarly to the widely used F1-measure. 

As our goal is to show the effectiveness of the 

unified approach, we used simpler methods of 

integrating pinyin error correction with character 

conversion to create baselines. The simplest 

                                                           
10 From Table 2, we observe that the accuracy of the 20-best 

output of the spelling correction component is over 99%. An 

offline run with the IME system on an independent data set 

also showed that the accuracy of the 20-best IME output is 

over 99%.  

baseline is a pre-processing approach: we use the 

pinyin error correction model to convert A into a 

single best candidate C, and run an IME system on 

C. Another more realistic baseline is the noisy 

channel integration discussed in Section 4.1. We 

approximated this integration method by re-

ranking all the candidates generated by the 

proposed log-linear model with only the channel 

and language model probabilities, equally 

weighted.  

The results are shown Table 3. 5-best results as 

well as the 1-best results are shown, because in an 

IME application, providing the correct candidate in 

the candidate list is particularly important even if it 

is not the best candidate. Let us first discuss the 1-

best results. The CER of this test corpus using the 

in-house IME system without correcting any errors 

is 10.91. The oracle CER, which is the result of 

applying the IME on the gold standard pinyin input 

derived from the reference text using a hanzi-to-

pinyin converter (as mentioned in Section 3.3), is 

4.08, which is the upper-bound imposed by the 

IME conversion accuracy. The simple pipeline 

approach of concatenating the pinyin correction 

component with the character conversion 

component improves the CER by 1% to 9.93. 

Assuming that there are on average 20 words in a 

sentence, and each word consists of 2 characters, 

1% CER reduction means one improvement every 

2.5 sentences. Noisy channel integration improves 

over this quite substantially, achieving a CER of 

7.92, demonstrating the power of the word 

language model in character conversion. 

Incidentally, the CER of the output by Zheng et al. 

(2011b)'s model is 8.90.
11

 Their results are not as 

good as our noisy channel integration, as their 

system uses a manually defined error model and a 

word bigram language model. With the use of 

additional feature functions weighted 

discriminatively for the final conversion task, the 

                                                           
11 Available at http://chime.ics.uci.edu/. 

 CER on 

1-best 

CER on 

5-best 

Baseline: No correction 10.91 7.76 

Baseline: Pre-processing 9.93 6.75 

Baseline: Zheng et al. (2011b) 8.90  

Baseline: Noisy channel 7.92 3.93 

Proposed: SMT model 7.12 3.63 

Oracle 4.08 1.51 

Table 3: CER results for the conversion task (%) 

616



proposed method outperforms all these baselines to 

reduce the CER to 7.12, a 35% relative error rate 

reduction compared with the no correction baseline, 

a 20% reduction against Zheng et al (2011b) and a 

10% reduction from our noisy channel baseline. 

The 5-best results follow the same trend of steady 

improvement as we use a more integrated system.  

In order to understand the characteristics of the 

errors and remaining issues, we ran an error 

analysis on the 1-best results of the proposed 

system. For each word in the test data (all 2,000 

sentences) for which the system output had an 

error, we classified the reasons of failure into one 

of the four categories: (1) character conversion 

error: correct pinyin was input to the IME but the 

conversion failed; (2) over-correction of pinyin 

input: the system corrected the pinyin input when 

it should not have; (3) under-correction of pinyin 

input: the system did not correct an error in the 

input pinyin when it should have; (4) wrong 

correction: input pinyin string had a spelling error 

but it was corrected incorrectly.   

Table 4 shows the results of the error analysis. 

We find that somewhat contrary to our expectation, 

over-correction of the spelling mistakes was not a 

conspicuous problem, even though the pinyin 

correction rate of the training data is much higher 

than that of the test data. We therefore conclude 

that the error correction model adapts very well to 

the characteristics of the test data in our integrated 

SMT-based approach, which trains the unified 

feature weights to optimize the end goal.  

5 Conclusion and Future Work 

In this paper we have presented a unified approach 

to error-tolerant text input, inspired by the phrase-

based SMT framework, and demonstrated its 

effectiveness over the traditional method based on 

the noisy channel model. We have also presented a 

new method of automatically collecting parallel 

data for spelling correction from user keystroke 

logs, and showed that the log-linear model works 

well on the task of spelling correction in isolation 

as well.  

In this study, we isolated the problem of spelling 

errors and studied the effectiveness of error 

correction over a basic IME system that does not 

include advanced features such as abbreviated 

input (e.g., typing only "py" for 朋友 pengyou 

'friend' or 拼音 pinyin in Chinese) and auto-

completion (e.g., typing only "ari" for ありがとう 

arigatou 'thank you' in Japanese). Integrating data-

driven error correction feature with these advanced 

features for the benefit of users is the challenge we 

face in the next step.  

Acknowledgements 

We are indebted to many colleagues at Microsoft 

and MSR for their help in conducting this research, 

particularly to Xi Chen, Pallavi Choudhury, Chris 

Quirk, Mei-Yuh Hwang and Kristina Toutanova. 

We are also grateful for the comments we received 

from the reviewers of this paper.  

References  

Baba, Y. and H. Suzuki. 2012. How are spelling errors 

generated and corrected? A study of corrected and 

uncorrected spelling errors using keystroke logs. In 

Proceedings of ACL. 

Banko, M. and E. Brill. 2001. Scaling to very very large 

corpora for natural language disambiguation. In 

Proceedings of ACL.  

Bertoldi, N., M. Cettolo, and M. Federico. 2010. 

Statistical machine translation of texts with 

misspelled words. In Proceedings of HLT-NAACL.  

Brill, E., and R. C. Moore. 2000. An improved error 

model for noisy channel spelling correction. In 

Proceedings of ACL.  

Chen, Z., and K. F. Lee. 2000. A new statistical 

approach to Chinese Pinyin input. In Proceedings of 

ACL.  

Cherry, C., and H. Suzuki. 2009. Discriminative 

substring decoding for transliteration. In Proceedings 

of EMNLP. 

Cucerzan, S., and E. Brill. 2004. Spelling correction as 

an iterative process that exploits the collective 

knowledge of web users. In Proceedings of EMNLP.  

Duan, H., and P. Hsu. 2011. Online spelling correction 

for query completion. In Proceedings of WWW.  

Gao, J., J. Goodman, M. Li and K.-F. Lee. 2002. 

Toward a unified approach to statistical language 

modeling for Chinese. In ACM Transactions on 

Overall errors (words) 1,074 / 12,102 

  Conversion 646 (60.14%) 

  Over-corrections 155 (14.43%) 

  Under-correction 161 (14.99%) 

  Wrong correction 112 (10.42%) 

Table 4: Classification of errors  

617



Asian Language Information Processing, Vol. 1, No. 

1, pp 3-33. 

Gao, J., X. Li, D. Micol, C. Quirk and X. Sun. 2010. A 

large scale ranker-based system for search query 

spelling correction. In Proceedings of COLING. 

Jiampojamarn, S., G. Kondrak and T. Sherif, 2007. 

Applying many-to-many alignments and hidden 

markov models to letter-to-phoneme conversion. In 

Proceedings of HLT/NAACL. 

Kernighan, M., K. Church, and W. Gale. 1990. A 

spelling correction program based on a noisy channel 

model. In Proceedings of COLING. 

Koehn, P., F. Och and D. Marcu. 2003. Statistical 

phrase-based translation. In Proceedings of HLT-

NAACL.  

McEnery, A. and Xiao, Z. 2004. The Lancaster Corpus 

of Mandarin Chinese: A Corpus for Monolingual and 

Contrastive Language Study. In Proceedings of 

LREC.  

Mori, S., M. Tsuchiya, O. Yamaji and M. Nagao. 1998. 

Kana-kanji conversion by a stochastic model. In 

Proceedings of Information Processing Society of 

Japan, SIG-NL-125-10 (in Japanese). 

Och, F. J. 2003. Minimum error rate training in 

statistical machine translation. In Proceedings of 

ACL.  

Och, F., and Ney, H. 2004. The alignment template 

approach to statistical machine translation. 

Computational Linguistics, 30(4): 417-449. 

Rama, T., A. K. Singh and S. Kolachina. 2009. 

Modeling letter-to-phoneme conversion as a phrase 

based statistical machine translation problem with 

minimum error rate training. In Proceedings of the 

NAACL HLT Student Research Workshop and 

Doctoral Consortium. 

Sherif, T. and G. Kondrak. 2007. Substring-based 

transliteration. In Proceedings of ACL. 

Sun, X., J. Gao, D. Micol and C. Quirk. 2010. Learning 

phrase-based spelling error models from clickthrough 

data. In Proceedings of ACL.  

Suzuki, H. and J. Gao. 2005. A comparative study on 

language model adaptation using new evaluation 

metrics. In Proceedings of EMNLP.  

Toutanova, K., and R. C. Moore. 2002. Pronunciation 

modeling for improved spelling correction. In 

Proceedings of ACL.  

Tokunaga, H., D. Okanohara and S. Mori. 2011. 

Discriminative method for Japanese kana-kanji input 

method. In Proceedings of the Workshop on 

Advances in Text Input Methods (WTIM 2011).  

Whitelaw, C., B. Hutchinson, G. Y. Chung, and G. 

Ellis. 2009. Using the web for language independent 

spellchecking and autocorrection. In Proceedings of 

ACL. 

Zhang, Y., L. Deng, X. He and A. Acero. 2011. A novel 

decision function and the associated decision-

feedback learning for speech translation. In 

Proceedings of ICASSP.  

Zheng, Y., L. Xie, Z. Liu, M. Sun. Y. Zhang and L. Ru. 

2011a. Why press backspace? Understanding user 

input behaviors in Chinese pinyin input method. In 

Proceedings of ACL.  

Zheng, Y., C. Li and M. Sun. 2011b. CHIME: An 

efficient error-tolerant Chinese pinyin input method. 

In Proceedings of IJCAI.  

 

618


