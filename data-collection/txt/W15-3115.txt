



















































A CRF Method of Identifying Prepositional Phrases in Chinese Patent Texts


Proceedings of the Eighth SIGHAN Workshop on Chinese Language Processing (SIGHAN-8), pages 86â€“90,
Beijing, China, July 30-31, 2015. cÂ©2015 Association for Computational Linguistics and Asian Federation of Natural Language Processing

A CRF Method of Identifying Prepositional Phrases in  

Chinese Patent Texts 

Hongzheng Li and Yaohong Jin 

 Institute of Chinese Information Processing, Beijing Normal University,  

Beijing, 100875, China 

CPIC-BNU Joint Laboratory of Machine Translation, Beijing Normal University, 

Beijing, 100875, China 
 lihongzheng@mail.bnu.edu.cn,jinyaohong@bnu.edu.cn 

 
 

Abstract 

This paper presents a Conditional Random 

Field (CRF) method of identifying preposi-

tional phrases (PP) in Chinese patent docu-

ments. By using the CRF model, the identifi-

cation process can be recognized as sequence 

labelling issue. After analyzing the character-

istics of PP chunks in large scale corpus, we 

design several essential and helpful features 

and feature templates for recognizing PP 

chunks, and then use a CRF toolkit to train the 

model to identify PPs. At last, some experi-

ments are conducted to justify the effects of 

the model, both the precision and recall rates 

are over 92%, higher than the baseline, indi-

cating the method is reasonable and effective. 

1 Introduction 

Prepositional phrases (PP), as a traditional im-

portant phrase type, are widely distributed in Chi-

nese patent documents. According to (Li, et al., 

2014), in 500 randomly extracted sample patent 

sentences, 226 sentences contained PP chunks, 

accounting for 45.2% of the sample. Compared 

with other Chinese domain texts, PP chunks in pa-

tent documents tend to have following more spe-

cific features.  

To begin with, they usually have more complex 

and longer structures with more words, they can 

be composed of prepositions (prep.) and noun 

phrases (NP), verb phrases (VP) or even clauses. 

Second, some preposition in PP are multi-cate-

gory words, the preposition may also serve as a 

noun, verb, conjunction etc. in various contexts. 

Last but not least, there also exists many parallel 

and nested PPs. While coordinate PPs means sev-

eral PPs appear together in a sentence, nested refer 

to those PPs composed of another PP and other 

ingredients. Following is an example in patent 

texts: 

è¯¥çœŸç©ºå·¥å…·[PP1é€šè¿‡[PP3åœ¨æ§åˆ¶å™¨ä¸­]è¿æ¥

è¿™äº›ç½‘ç»œç¯ç‰‡æ®µ][PP2 ä¸ºå®éªŒè£…ç½®]æä¾›ä¸€ä¸ª

ä½æ¸©æ³µã€‚(The vacuum tool can provide a pump 
for the experiment instrument by connecting the 

network ring parts in the controller.) 
As shown, the example contains three PPs, in 

which PP1 and PP2 are parallel, and in the long 

nested PP1 chunk â€œé€šè¿‡â€¦â€¦ç‰‡æ®µâ€, there exists 

another PP3 â€œåœ¨æ§åˆ¶å™¨ä¸­â€(in the controller). 
All these features result in more difficulties in 

identifying PPs. However, it is worth noting that, 

recognizing the PPs properly plays positive roles 

in various application fields of Natural Language 

Processing (NLP). 

Assuming in the Chinese sentence S=W1, W2, 

W3â€¦â€¦Wn, string Wi, Wi+1â€¦â€¦Wj is the supposed 

PP, the main task of PP identification is actually 

to identify Wi as left boundary word(LBW)and Wj 
as right boundary word(RBW) of the PP and then 

recognize the whole string as PP chunk. More spe-

cifically, since the LBW is the preposition itself, 

how to identify the RWB correctly is a key issue 

in the whole identification process.  

Considering the wide distribution of PPs in pa-

tent documents and its important impacts on pro-

cessing modules such as chunking and parsing in 

NLP, in this paper, we tried to apply the Condi-

tional Random Field (CRF) model to PP identifi-

cation in patent texts. By designing some features 

and labelling the PP sequences in corpus first and 

then training the features with the CRF toolkit, PP 

chunks can be identified. We also conducted ex-

periments to justify the effects of the method, and 

the experimental results showed the proposed ap-

proaches can improve the performance of identi-

fying Chinese PPs significantly. 

The rest of this paper are organized as follow. 
Section 2 discusses some related work, section 3 

presents the CRF-based identification method, 

section 4 conducts some experiments and gives 

86



related analysis, and the last section discusses the 

conclusion and future work. 

2 Related Work 

As a powerful statistical sequence modeling 

framework that combines the advantages of both 

the generative model and the classification model, 

CRF was first introduced into language pro-

cessing in (Lafferty, et al., 2001). Since then, the 

model has been applied to various NLP tasks such 

as word segmentation (Tseng, et al., 2005), Se-

mantic Role Labelling (Cohn and Blunsom, 2005) 

and parsing (Finkel, et al., 2008; Yoshimasa, et al., 

2009), gaining great achievement. And CRF has 

become increasingly popular in recent years. 

PP structures in sentences has been studied for 

long decades. However, differences in syntactic 

structures between Chinese and English have re-

sulted in various research strategies: for English 

PP, researchers mainly focus on PP attachment 

disambiguation based on statistic and corpus 

methods (Brill, et al., 1994; Pantel and Lin, 1998; 

Briscoe and Carroll, 1995; Schwartz, et al., 2003; 

McLauchlan, 2004). 

 On the other hand, for Chinese PP, mainly fo-

cus on identifying and parsing the PP chunks by 

using rule-based method (Liang, et al. 2013, Hu, 

2015) and popular statistical models, including 

HMM (Xi and Luo, 2007; Zhang, et al., 2011), 

SVM (Wen and Wu, 2009), Maximum Entropy 

(ME) Model (Lu, et al., 2010), and CRF models 

(Tan et al., 2005; Hu, 2008; Zhang, 2013). (Chen, 

et al.)(2005) proposed four models (SVMs, CRFs, 

TBL and MBL) to describe an empirical study of 

Chinese chunking on a corpus extracted from UP-

ENN Chinese Treebank-4 (CTB4). Some others 

(Fu and Li, 2010; Zan, et al., 2013) also presented 

hybrid methods to recognize PPs by combining 

rules with statistic methods. Generally, recogniz-

ing Chinese PPs belongs to the category of shal-

low parsing in NLP. 

While the CRF method has been usually ap-

plied to identifying Chinese PPs in common 

newswire texts, there exists few research on other 

specific domains. Thus, we decide to apply the 

method in patent documents. 

3 CRF Identification Model 

In this paper, we use the CRF++ toolkit (V0.53)1 

to train the model for identifying the PP chunks 

and test the trained sequences. 

                                                 
1 http://crfpp.googlecode.com/  

3.1 Sequential Labelling 

Chunking based on CRF method is usually recog-

nized as sequential labelling issue. Input X is a 

data sequence to be labelled, and Output Y is a 

corresponding labelled sequence, which is taken 

from a specific tag set. The probability assigned 

to a labelled sequence for a particular sequence of 

characters by a CRF model can be defined as fol-

low: 

 

ğ‘ƒ(ğ‘Œ|ğ‘‹) =
1

ğ‘(ğ‘‹)
ğ‘’ğ‘¥ğ‘(âˆ‘ ğœ†ğ‘˜ ğ‘“ğ‘˜ğ‘˜ )                     (1) 

 

Where Z(X) is the normalization factor, ğ‘“ğ‘˜ is a 
set of features, and ğœ†ğ‘˜ is the corresponding weight. 

We adopt the B-I-E-O scheme as tag sets to la-

bel PP chunks in the sentence. B-I-E refers to the 

Beginning, Intermediate and End elements of PP 

structure, and O for Outsides of the chunk. 

Here is an example in patent text: 

æœ¬å‘æ˜é€šè¿‡é‡‡ç”¨å…ˆè¿›æŠ€æœ¯è€Œæé«˜ç”Ÿäº§åŠ›ã€‚
(The invention improves the productivity by 

adopting advanced technology.) 

The italic string â€œé€šè¿‡â€¦â€¦æŠ€æœ¯â€is the PP 
chunk. After word segmentation processing, the 

sentence can be labelled as: 

æœ¬å‘æ˜ Oé€šè¿‡ Bé‡‡ç”¨ Iå…ˆè¿› IæŠ€æœ¯ Eè€Œ Oæ

é«˜ O ç”Ÿäº§åŠ› O ã€‚O 

Thus, Input X = {æœ¬å‘æ˜ é€šè¿‡ é‡‡ç”¨ å…ˆè¿› æŠ€æœ¯ 

è€Œ æé«˜ ç”Ÿäº§åŠ› ã€‚} 
Correspondingly, Output Y = {O B I I E O O O 

O} 

3.2 Features 

Features play a very important role in the CRF 

model. Although CRF can define features indefi-

nitely, the more features donâ€™t always means the 

better training result. After analyzing the struc-

tural and linguistic features of patent sentences in 

large scale corpus, we defined following five ef-

fective and representative features for the model. 

Each feature is composed of feature name and its 

value. 

Feature Value 

Word Each word itself in the sentence. 

POS 

POS of each word and punctua-

tions (marked as â€œpuncâ€) in the 

sentence. 

Candidate 

left bound-

ary (LB) 

From the current word, find for-

ward to find the prep. If the prep-

osition exists, the value is the 

preposition itself; otherwise "N". 

87



Candidate 

right 

boundary 

(RB) 

If current word can be RBW of 

PP, mark â€œYâ€; otherwise â€œNâ€. 

Candidate 

LW 

The word behind the RB, which 

is also helpful in the identifica-

tion, is defined as last word 

(LW). If current word is LW, 

then mark â€œYâ€; otherwise â€œNâ€. 

Table 1. Feature Sets of the Model 

After word segmentation, we manually label 

each patent sentence that includes PP chunks with 

above features.  

Table 2 shows a tagged sequence example in 

part 3.1. 

 

Words POS 

Candi-

date 

LBW 

Candi-

date 

RBW 

Candi-

date 

LW 

Tag 

Set 

æœ¬ 

å‘æ˜ 
n N N N O 

é€šè¿‡ prep é€šè¿‡ N N B 

é‡‡ç”¨ v é€šè¿‡ N N I 

å…ˆè¿› a é€šè¿‡ N N I 

æŠ€æœ¯ n é€šè¿‡ Y N E 

è€Œ conj é€šè¿‡ N Y O 

æé«˜ v é€šè¿‡ N N O 

ç”Ÿäº§

åŠ› 
n é€šè¿‡ N N O 

ã€‚ punc é€šè¿‡ N N O 

 

Table 2. A Tagged example  

 

The first five columns are designed features, 

and the last column represents tag set of the se-

quences. According to the format of the CRF 

toolkit, each column is separated by a separator, 

and each sentence sequence is separated by a line 

break. 

3.3 Feature Templates 

We also design essential feature templates for the 

model according to the defined feature sets. The 

model generates numerous feature functions, 

which will directly affect the performance of the 

model in turn. 

CRF models generally include atomic and com-

posite feature templates. Since alone atomic fea-

ture templates only show feature information of 

single locations, which is likely to cause greater 

deviations between expectations and actual results, 

leading to inaccurate estimation parameters. 

Therefore, in our paper, the atomic features are 

combined to form composite feature templates to 

describe dependencies between the characteristics 

of labelled units and contexts by defining window 

of each feature. 

The size of window in the sequences is defined 

as two. That means, we consider the features of 

current word (W0), next word (W1), second char-

acter back W0 (W2), previous character (W-1) and 

second character before W0 (W-2). All the tem-

plates are in the form of Unigram in the toolkit to 

train the data, and no Bigram templates are used. 

3.4 Architecture 

Hereâ€™s the basic architecture of the CRF model for 

identifying the PP chunks. 

 

 
 

Figure 1. CRF Model Architecture 

4 Experiment 

After training the model, in this part, we continue 

use the toolkit to test the identification effects. 

Precision rate (P), Recall rate (R) and F1, defined 

as follows, are three evaluation metrics of the ex-

periment. 

 

P =
ğ‘2

ğ‘1
Ã— 100%                                           (2) 

R =
ğ‘2

ğ‘
Ã— 100%                                           (3) 

F1 =
2Ã—ğ‘ƒÃ—ğ‘…

ğ‘ƒ+ğ‘…
Ã— 100%                                   (4) 

 

Where N refers to the total number of PP 

chunks in the test set, N1 refers to the identified 

number of PP by the model, and N2 refers to the 

correctly identified number of PP. 

88



4.1 Test Results 

We manually extracted 1017 sentences containing 

PP chunks as the final test set from the developing 

set of patent MT subtask in the NTCIR-9 work-

shop2 , which is composed of 2000 parallel Chi-

nese-English sentences.  

The experiment adopted the 5-fold cross vali-

dation method: the whole set was divided into five 

equal parts, in which four parts were used as train-

ing sets, and the other one as test set. Thus, we 

totally conducted five experiments, and the aver-

age data of the five experiments were considered 

as final results. Then, we compared the results 

with the baseline (Hu, 2015), which used the same 

test set and tested with a rule-based system (Zhu 

and Jin, 2012). 

Performances of the five experiments and com-

parison are shown in the following tables. 

 

Test P (%) R (%) F1 (%) 

Test1 94.36 91.09 92.70 

Test2 92.41 91.77 92.97 

Test3 93.10 95.30 94.19 

Test4 93.83 92.12 93.51 

Test5 91.68 93.22 92.44 

Average 93.08 92.71 93.16 

 

Table 3. Performances of the experiments 
 

 P (%) R (%) 
Baseline 90.81 86.64 

CRF 93.08 92.71 

Gain +2.27 +6.07 

 

Table 4. Comparison of Baseline and CRF 

4.2 Discussion 

In the experiments, the final metrics were all over 

92%, and were higher than baseline, clearly indi-

cating that the method performed well in identify-

ing the PP chunks. Different from other three tests, 

the reason why the recall rates in test 3 and test 5 

were higher than the precision rates lied in that the 

identified numbers of PP were more than the total 

numbers of PP in the two tests. 

 Since most experiments in previous related 

works employed newswire corpus as test set, to-

tally different from the patent texts, thus we sup-

pose that there may exist no necessary compari-

sons between our results with previous works. 

                                                 
2 http://research.nii.ac.jp/ntcir/ntcir-9/data.html  

After analyzing the results, we also concluded 

several following reasons accounting for error 

identifications: 

First, some prepositions almost did not appear 

in the training test, as a result, the model could not 

obtain their features, and consequently, while they 

appeared in the test set, they were more difficult 

to be correctly identified.  

Second, some PP chunks were ambiguous. Un-

der this condition, it was not easy to determine the 

right boundaries of the chunks. For example, in 

the sentence â€œé€šè¿‡æœ¬å‘æ˜çš„å¢¨æ°´ç€è‰²å‰‚å¯ä»¥æœ‰
æ•ˆåœ°ä½¿å®éªŒäº§å“æ²‰æ·€ã€‚â€, the italic noun â€œå¢¨æ°´

(ink)â€ is followed by another noun â€œç€è‰²å‰‚(col-
orants)â€, it is not really clear which noun should 

actually be the proper boundary of the PP chunk. 

If the two nouns represent a compound noun, then 

the boundary should be the second noun; on the 

contrary, if they are independent of each other, 

then the boundary should be the first noun, and the 

second noun will serve as subject of the sentence. 

Last, the model is quite sensitive to features in 

the sequences, during the label process, error and 

improper manually tagged information is inevita-

ble, which can also result in error identifications.  

5 Conclusion and Future Work 

In this paper, we presented a CRF-based method 

for identifying the Chinese PP chunks in patent 

texts. Based on analysis of large scale patent texts, 

we designed several essential features for the 

model according to various characteristics of Chi-

nese PPs, after labelling the sequences and train-

ing the model by using a CRF toolkit, we con-

ducted some experiments to justify the perfor-

mance of the method. Both final precision and re-

call rates were over 92%, and higher than the 

baseline, indicating the CRF-based method is ef-

fective and performs well in identifying PPs, alt-

hough there still existed some error identifications. 

In the future, we will pay more attention to the 

ambiguous PP chunks, consider more useful and 

effective features into the model, and continue to 

expand the size of patent corpus to be labelled, 

hoping to further improve the identification ef-

fects of PP chunks. 

 

Acknowledgements 

This work was supported by the National Hi-Tech 

Research and Development Program of China 

(2012AA011104).  

89



Reference 

Brill E. and Resnik P. 1994. A Rule-Based Approach 

to Prepositional Phrase Attachment Disambiguation. 

In Proceedings of the 15th Conference on Compu-

tational Linguistics, 1198-1204. 

Chaohua Lu, Guangjun Huang and Zhibing Guo. 2010. 

Identification of Chinese Prepositional Phrase 

Based on Maximum Entropy. Communications 

Technology, 43(5):181-183,186. 

Edward Briscoe and John Carroll. 1995. Developing 

and Evaluating a Probabilistic lr Parser of Part-of-

Speech and Punctuation Labels. In Proceedings of 

the IWPT, 48â€“58.  

Goto, I., Lu, B., Chow, K. P., Sumita, E., and Tsou, B. 

K. 2011. Overview of the Patent Machine Transla-

tion Task at the NTCIR-9 Workshop. In Proceed-

ings of NTCIR9, 559-578. 

Hefang Fu and Zhaoxia Li. 2010. Discussion on the In-

tegration of Statistical Learning Method and Artifi-

cial Rule Method for Prepositional Phrase Recogni-

tion. Modern Computers, 11:17-20. 

Hongzheng Li, Yun Zhu, Yang Yang and Yaohong Jin. 

2014. Reordering Adverbial Chunks in Chinese-

English Patent Machine Translation. In Proceeding 
of IEEE International Conference on Cloud Compu-

ting and Intelligence Systems, 375-379. 

Hongying Zan, Tengfei Zhang and Kunli Zhang. 2013. 

Automatic Recognition Research on Prepositionâ€™s 

Usages Based on Combination of Rules and Statis-

tics. Computer Engineering and Design, 

34(6):2152-2157. 

Jianqing Xi and Qiang Luo. 2009. Research on Auto-

matic Identification for Chinese Prepositional 

Phrase Based on HMM. Computer Engineering, 

33(3):172-173,182. 

Jie Zhang. 2013. Research on Chinese Prepositional 

Phrase Identification based on Multi-Layer Condi-

tional Random Fields. 

Jenny Rose Finkel, Alex Kleeman and Christopher D. 

Manning. 2008. Efficient, Feature-based, Condi-

tional Random Field Parsing. In Proceedings of ACL, 
959-967. 

Kunli Zhang, Yingjie Han, Hongying Zan and Ying-

cheng Yuan. 2011. Prepositional Phrase Boundary 

Identification Based on Statistical Models. Journal 

of Henan Normal University (Natural Science Edi-

tion), 41(6): 636-640. 

Lafferty, John, A. McCallum, and F. Pereira. 2001. 

Conditional Random Field: Probabilistic Models for 

Segmenting and Labeling Sequence Data. In Pro-

ceedings of the 18th International Conference on 

Machine Learning 2001, 282-289. 

Mark McLauchlan. 2004. Thesauruses for Preposi-

tional Phrase Attachment. In Proceedings of CoNLL, 

73-80. 

Mengjie Liang, Yu Song, Yingjie Han and Hongying 

Zan. 2013. Automatic Annotation Research on 

Preposition Usage Based on Sorting Rules. Journal 

of Henan Normal University (Natural Science Edi-

tion), 41(3):152-155. 

Miaomiao Wen and Yunfang Wu. 2009. Feature-rich 

Prepositional Phrase Boundary Identification Based 

on SVM. Journal of Chinese Information Pro-

cessing, 23(5):19-24. 

Pantel P, Lin D. 1998. An Unsupervised Approach to 

Prepositional Phrase Attachment Using Contextu-

ally Similar Words. In Proceedings of Association 

for Computational Linguistics, 101-108.  

Renfen Hu. 2015. on the Methods of Auto-Identifying 

Prepositional Phrases in Chinese-English Patent 

Machine Translation. Applied Linguistics, 136-144. 

Schwartz L, Aikawa T, Quirk C. 2003. Disambiguation 

of English PP Attachment Using Multilingual 

Aligned Data. In Proceedings of MT Summit IX. 

Silei Hu. 2008. Automatic Identification of Chinese 

Prepositional Phrase Based on CRF. 

Trevor Cohn and Philip Blunsom. 2005. Semantic Role 

Labelling with Tree Conditional Random Fields. In 

Proceedings of the 9th Conference on Computa-

tional Natural Language Learning (CoNLL), 169â€“

172. 

Tseng, H., Chang, P., Andrew, G., Jurafsky, D., and 

Manning, C. 2005. A Conditional Random Field 

Word Segmenter for SIGHAN Bakeoff 2005. In 

Proceedings of the fourth SIGHAN workshop on 

Chinese language Processing. 

Wenliang Chen, Yujie Zhang and Hitoshi Isahara. 

2006. An Empirical Study of Chinese Chunking. In 

Proceedings of the COLING/ACL 2006 Main Con-

ference Poster Sessions, 97â€“104. 

Yongmei Tan, Tianshun Yao, Qing Chen, and Jingbo 

Zhu. 2005. Applying Conditional Random Fields to 

Chinese Shallow Parsing. In Proceedings of CI-

CLing-2005, 167â€“176. 

Yoshimasa Tsuruoka, Junâ€™ichi Tsujii and Sophia Ana-

niadou. 2009. Fast Full Parsing by Linear-Chain 

Conditional Random Fields. In Proceedings of the 

12th Conference of the European Chapter of the 

ACL, 790â€“798. 

Yun Zhu and Yaohong Jin. 2012. A Chinese-English 

Patent Machine Translation System based on the 

Theory of Hierarchical Network of Concepts. The 

Journal of China Universities of Posts and Telecom-

munications, 140-146. 

90


