



















































DKPro Similarity: An Open Source Framework for Text Similarity


Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 121–126,
Sofia, Bulgaria, August 4-9 2013. c©2013 Association for Computational Linguistics

DKPro Similarity: An Open Source Framework for Text Similarity

Daniel Bär†, Torsten Zesch†‡, and Iryna Gurevych†‡
†Ubiquitous Knowledge Processing Lab (UKP-TUDA)

Department of Computer Science, Technische Universität Darmstadt
‡Ubiquitous Knowledge Processing Lab (UKP-DIPF)

German Institute for Educational Research and Educational Information
www.ukp.tu-darmstadt.de

Abstract

We present DKPro Similarity, an open
source framework for text similarity. Our
goal is to provide a comprehensive repos-
itory of text similarity measures which
are implemented using standardized inter-
faces. DKPro Similarity comprises a wide
variety of measures ranging from ones
based on simple n-grams and common
subsequences to high-dimensional vector
comparisons and structural, stylistic, and
phonetic measures. In order to promote
the reproducibility of experimental results
and to provide reliable, permanent ex-
perimental conditions for future studies,
DKPro Similarity additionally comes with
a set of full-featured experimental setups
which can be run out-of-the-box and be
used for future systems to built upon.

1 Introduction

Computing text similarity is key to several natu-
ral language processing applications such as au-
tomatic essay grading, paraphrase recognition, or
plagiarism detection. However, only a few text
similarity measures proposed in the literature are
released publicly, and those then typically do not
comply with any standardization. We are currently
not aware of any designated text similarity frame-
work which goes beyond simple lexical similarity
or contains more than a small number of measures,
even though related frameworks exist, which we
discuss in Section 6. This fact was also realized
by the organizers of the pilot Semantic Textual
Similarity Task at SemEval-2012 (see Section 5),
as they argue for the creation of an open source
framework for text similarity (Agirre et al., 2012).

In order to fill this gap, we present DKPro Sim-
ilarity, an open source framework for text simi-
larity. DKPro Similarity is designed to comple-

ment DKPro Core1, a collection of software com-
ponents for natural language processing based on
the Apache UIMA framework (Ferrucci and Lally,
2004). Our goal is to provide a comprehensive
repository of text similarity measures which are
implemented in a common framework using stan-
dardized interfaces. Besides the already available
measures, DKPro Similarity is easily extensible
and intended to allow for custom implementations,
for which it offers various templates and exam-
ples. The Java implementation is publicly avail-
able at Google Code2 under the Apache Software
License v2 and partly under GNU GPL v3.

2 Architecture

DKPro Similarity is designed to operate in ei-
ther of two modes: The stand-alone mode al-
lows to use text similarity measures as indepen-
dent components in any experimental setup, but
does not offer means for further language process-
ing, e.g. lemmatization. The UIMA-coupled mode
tightly integrates similarity computation with full-
fledged Apache UIMA-based language processing
pipelines. That way, it allows to perform any num-
ber of languge processing steps, e.g. coreference
or named-entitiy resolution, along with the text
similarity computation.

Stand-alone Mode In this mode, text similarity
measures can be used independently of any lan-
guage processing pipeline just by passing them a
pair of texts as (i) two strings, or (ii) two lists of
strings (e.g. already lemmatized texts). We there-
fore provide an API module, which contains Java
interfaces and abstract base classes for the mea-
sures. That way, DKPro Similarity allows for a
maximum flexibility in experimental design, as the
text similarity measures can easily be integrated
with any existing experimental setup:

1code.google.com/p/dkpro-core-asl
2code.google.com/p/dkpro-similarity-asl

121



1 TextSimilarityMeasure m =
new GreedyStringTiling();

2 double similarity =
m.getSimilarity(text1, text2);

The above code snippet instantiates the Greedy
String Tiling measure (Wise, 1996) and then com-
putes the text similarity between the given pair of
texts. The resulting similarity score is normal-
ized into [0, 1] where 0 means not similar at all,
and 1 corresponds to perfectly similar.3 By us-
ing the common TextSimilarityMeasure
interface, it is easy to replace Greedy String Tiling
with any measure of choice, such as Latent Se-
mantic Analysis (Landauer et al., 1998) or Explicit
Semantic Analysis (Gabrilovich and Markovitch,
2007). We give an overview of measures available
in DKPro Similarity in Section 3.

UIMA-coupled Mode In this mode, DKPro
Similarity allows text similarity computation to
be directly integrated with any UIMA-based lan-
guage processing pipeline. That way, it is easy to
use text similarity components in addition to other
UIMA-based components in the same pipeline.
For example, an experimental setup may require to
first compute text similarity scores and then to run
a classification algorithm on the resulting scores.

In Figure 1, we show a graphical overview of
the integration of text similarity measures (right)
with a UIMA-based pipeline (left). The pipeline
starts by reading a given dataset, then performs
any number of pre-processing steps such as to-
kenization, sentence splitting, lemmatization, or
stopword filtering, then runs the text similar-
ity computation, before executing any subsequent
post-processing steps and finally returning the pro-
cessed texts in a suitable format for evaluation or
manual inspection. As all text similarity measures
in DKPro Similarity conform to standardized in-
terfaces, they can be easily exchanged in the text
similarity computation step.

With DKPro Similarity, we offer various sub-
classes of the generic UIMA components which
are specifically tailored towards text similarity ex-
periments, e.g. corpus readers for standard eval-
uation datasets as well as evaluation components
for running typical evaluation metrics. By lever-
aging UIMA’s architecture, we also define an

3Some string distance measures such as the Levenshtein
distance (Levenshtein, 1966) return a raw distance score
where less distance corresponds to higher similarity. How-
ever, the score can easily be normalized, e.g. by text length.

UIMA-based Pipeline

Corpus Reader

Pre-processing

Text Similarity
Computation

Post-processing

Evaluation

Si
m

ila
ri

ty
Sc

or
er

Text Similarity Measures

Greedy String Tiling

Double Metaphone

..
.

Explicit Sem. Analysis

Figure 1: DKPro Similarity allows to integrate any
text similarity measure (right) which conforms to
standardized interfaces into a UIMA-based lan-
guage processing pipeline (left) by means of a
dedicated Similarity Scorer component (middle).

additional interface to text similarity measures:
The JCasTextSimilarityMeasure inherits
from TextSimilarityMeasure, and adds a
method for two JCas text representations:4

double getSimilarity
(JCas text1, JCas text2);

The additional interface allows to implement mea-
sures which have full access to UIMA’s document
structure. That way, it is possible to create text
similarity measures which can use any piece of in-
formation that has been annotated in the processed
documents, such as dependency trees or morpho-
logical information. We detail the new set of com-
ponents offered by DKPro Similarity in Section 4.

3 Text Similarity Measures

In this section, we give an overview of the text
similarity measures which are already available in
DKPro Similarity. While we provide new imple-
mentations for a multitude of measures, we rely on
specialized libraries such as the S-Space Package
(see Section 6) if available. Due to space limi-
tations and due to the fact that the framework is
actively under development, we do not provide an
exhaustive list here, but rather mention the most
interesting and most popular measures.

3.1 Simple String-based Measures
DKPro Similarity includes text similarity mea-
sures which operate on string sequences and
determine, for example, the longest common

4The JCas is an object-oriented Java interface to the
Common Analysis Structure (Ferrucci and Lally, 2004),
Apache UIMA’s internal document representation format.

122



(non-)contiguous sequence of characters. It also
contains Greedy String Tiling (Wise, 1996), a mea-
sure which allows to compare strings if parts have
been reordered. The framework also offers mea-
sures which compute sets of character and word
n-grams and compare them using different overlap
coefficients, e.g. the Jaccard index. It further in-
cludes popular string distance metrics such as the
Jaro-Winkler (Winkler, 1990), Monge and Elkan
(1997) and Levenshtein (1966) distance measures.

3.2 Semantic Similarity Measures

DKPro Similarity also contains several measures
which go beyond simple character sequences and
compute text similarity on a semantic level.

Pairwise Word Similarity These measures are
based on pairwise word similarity computations
which are then aggregated for the complete texts.
The measures typically operate on a graph-based
representation of words and the semantic relations
among them within a lexical-semantic resource.
DKPro Similarity therefore contains adapters for
WordNet, Wiktionary5, and Wikipedia, while the
framework can easily be extended to other data
sources that conform to a common interface
(Garoufi et al., 2008). Pairwise similarity mea-
sures in DKPro Similarity include Jiang and Con-
rath (1997) or Resnik (1995). The aggregation for
the complete texts can for example be done using
the strategy by Mihalcea et al. (2006).

Vector Space Models These text similarity
measures project texts onto high-dimensional vec-
tors which are then compared. Cosine similar-
ity, a basic measure often used in information re-
trieval, weights words according to their term fre-
quencies or tf-idf scores, and computes the co-
sine between two text vectors. Latent Seman-
tic Analysis (Landauer et al., 1998) alleviates the
inherent sparseness of a high-dimensional term-
document matrix by reducing it to one of reduced
rank. Explicit Semantic Analysis (Gabrilovich and
Markovitch, 2007) constructs the vector space on
corpora where the documents are assumed to de-
scribe natural concepts such as cat or dog. Orig-
inally, Wikipedia was proposed as the document
collection of choice.

DKPro Similarity goes beyond a single im-
plementation of these measures and comes with
highly customizable code which allows to set var-

5http://www.wiktionary.org

ious parameters for the construction of the vector
space and the comparison of the document vectors,
and further allows to construct the vector space for
arbitrary collections, e.g. domain-specific corpora.

3.3 Further Measures

Previous research (Bär et al., 2012b) has shown
promising results for the inclusion of measures
which go beyond textual content and compute
similarity along other text characteristics. Thus,
DKPro Similarity also includes measures for
structural, stylistic, and phonetic similarity.

Structural Similarity Structural similarity be-
tween texts can be computed, for example, by
comparing sets of stopword n-grams (Stamatatos,
2011). The idea here is that similar texts may pre-
serve syntactic similarity while exchanging only
content words. Other measures in DKPro Simi-
larity allow to compare texts by part-of-speech n-
grams, and order and distance features for pairs of
words (Hatzivassiloglou et al., 1999).

Stylistic Similarity DKPro Similarity includes,
for example, a measure which compares function
word frequencies (Dinu and Popescu, 2009) be-
tween two texts. The framework also includes a
set of measures which capture statistical properties
of texts such as the type-token ratio (TTR) and the
sequential TTR (McCarthy and Jarvis, 2010).

Phonetic Similarity DKPro Similarity also al-
lows to compute text similarity based on pair-
wise phonetic comparisons of words. It therefore
contains implementations of well-known phonetic
algorithms such as Double Metaphone (Philips,
2000) and Soundex (Knuth, 1973), which also con-
form to the common text similarity interface.

4 UIMA Components

In addition to a rich set of text similarity mea-
sures as partly described above, DKPro Similar-
ity includes components which allow to integrate
text similarity measures with any UIMA-based
pipeline, as outlined in Figure 1. In the following,
we introduce these components along with their
resources.

Readers & Datasets DKPro Similarity includes
corpus readers specifically tailored towards com-
bining the input texts in a number of ways, e.g.
all possible combinations, or each text paired with
n others by random. Standard datasets for which

123



readers come pre-packaged include, among oth-
ers, the SemEval-2012 STS data (Agirre et al.,
2012), the METER corpus (Clough et al., 2002),
or the RTE 1–5 data (Dagan et al., 2006). As far
as license terms allow redistribution, the datasets
themselves are integrated into the framework.

Similarity Scorer The Similarity Scorer allows
to integrate any text similarity measure (which is
decoupled from UIMA by default) into a UIMA-
based pipeline. It builds upon the standardized text
similarity interfaces and thus allows to easily ex-
change the text similarity measure as well as to
specify the data types the measure should operate
on, e.g. tokens or lemmas.

Machine Learning Previous research (Agirre et
al., 2012) has shown that different text similarity
measures can be combined using machine learning
classifiers. Such a combination shows improve-
ments over single measures due to the fact that dif-
ferent measures capture different text characteris-
tics. DKPro Similarity thus provides adapters for
the Weka framework (Hall et al., 2009) and allows
to first pre-compute sets of text similarity scores
which can then be used as features for various ma-
chine learning classifiers.

Evaluation Metrics In the final step of a UIMA
pipeline, the processed data is read by a dedicated
evaluation component. DKPro Similarity ships
with a set of components which for example com-
pute Pearson or Spearman correlation with human
judgments, or apply task-specific metrics such as
average precision as used in the RTE challenges.

5 Experimental Setups

DKPro Similarity further encourages the creation
and publication of complete experimental setups.
That way, we promote the reproducibility of ex-
perimental results, and provide reliable, perma-
nent experimental conditions which can benefit fu-
ture studies and help to stimulate the reuse of par-
ticular experimental steps and software modules.

The experimental setups are instantiations of
the generic UIMA-based language processing
pipeline depicted in Figure 1 and are designed to
precisely match the particular task at hand. They
thus come pre-configured with corpus readers for
the relevant input data, with a set of pre- and post-
processing as well as evaluation components, and
with a set of text similarity measures which are

well-suited for the particular task. The experimen-
tal setups are self-contained systems and can be
run out-of-the-box without further configuration.6

DKPro Similarity contains two major types of
experimental setups: (i) those for an intrinsic eval-
uation allow to evaluate the system performance in
an isolated setting by comparing the system results
with a human gold standard, and (ii) those for an
extrinsic evaluation allow to evaluate the system
with respect to a particular task at hand, where text
similarity is a means for solving a concrete prob-
lem, e.g. recognizing textual entailment.

Intrinsic Evaluation DKPro Similarity con-
tains the setup (Bär et al., 2012a) which partic-
ipated in the Semantic Textual Similarity (STS)
Task at SemEval-2012 (Agirre et al., 2012) and
which has become one of the recommended base-
line systems for the second task of this series.7

The system combines a multitude of text similar-
ity measures of varying complexity using a simple
log-linear regression model. The provided setup
allows to evaluate how well the system output re-
sembles human similarity judgments on short texts
which are taken from five different sources, e.g.
paraphrases of news texts or video descriptions.

Extrinsic Evaluation Our framework includes
two setups for an extrinsic evaluation: detecting
text reuse, and recognizing textual entailment.

For detecting text reuse (Clough et al., 2002),
the setup we provide (Bär et al., 2012b) combines
a multitude of text similarity measures along dif-
ferent text characteristics. Thereby, it not only
combines simple string-based and semantic sim-
ilarity measures (see Sections 3.1 and 3.2), but
makes extensive use of measures along structural
and stylistic text characteristics (see Section 3.3).
Across three standard evaluation datasets, the sys-
tem consistently outperforms all previous work.

For recognizing textual entailment, we provide
a setup which is similar in configuration to the one
described above, but contains corpus readers and
evaluation components precisely tailored towards
the RTE challenge series (Dagan et al., 2006). We
believe that our setup can be used for filtering
those text pairs which need further analysis by a
dedicated textual entailment system.

6A one-time setup of local lexical-semantic resources
such as WordNet may be necessary, though.

7In 2013, the STS Task is a shared task of the Second
Joint Conference on Lexical and Computational Semantics,
http://ixa2.si.ehu.es/sts

124



6 Related Frameworks

To the best of our knowledge, only a few general-
ized similarity frameworks exist at all. In the fol-
lowing, we discuss them and give insights where
DKPro Similarity uses implementations of these
existing libraries. That way, DKPro Similarity
brings together the scattered efforts by offering ac-
cess to all measures through common interfaces. It
goes far beyond the functionality of the original li-
braries as it generalizes the resources used, allows
a tight integration with any UIMA-based pipeline,
and comes with full-featured experimental setups
which are pre-configured stand-alone text similar-
ity systems that can be run out-of-the-box.

S-Space Package Even though no designated
text similarity library, the S-Space Package (Jur-
gens and Stevens, 2010)8 contains some text sim-
ilarity measures such as Latent Semantic Analysis
(LSA) and Explicit Semantic Analysis (see Sec-
tion 3.2). However, it is primarily focused on
word space models which operate on word distri-
butions in text. Besides such algorithms, it offers
a variety of interfaces, data structures, evaluation
datasets and metrics, and global operation utili-
ties e.g. for dimension reduction using Singular
Value Decomposition or randomized projections,
which are particularly useful with such distribu-
tional word space models. DKPro Similarity inte-
grates LSA based on the S-Space Package.

Semantic Vectors The Semantic Vectors pack-
age is a package for distributional semantics (Wid-
dows and Cohen, 2010)9 that contains measures
such as LSA and allows for comparing documents
within a given vector space. The main focus lies
on word space models with a number of dimension
reduction techniques, and applications on word
spaces such as automatic thesaurus generation.

WordNet::Similarity The open source package
by Pedersen et al. (2004)10 is a popular Perl li-
brary for the similarity computation on WordNet.
It comprises six word similarity measures that op-
erate on WordNet, e.g. Jiang and Conrath (1997)
or Resnik (1995). Unfortunately, no strategies
have been added to the package yet which aggre-
gate the word similarity scores for complete texts
in a similar manner as described in Section 3.2.

8code.google.com/p/airhead-research
9code.google.com/p/semanticvectors

10sourceforge.net/projects/wn-similarity

In DKPro Similarity, we offer native Java imple-
mentations of all measures contained in Word-
Net::Similarity, and allow to go beyond WordNet
and use the measures with any lexical-semantic re-
source of choice, e.g. Wiktionary or Wikipedia.

SimMetrics Library The Java library by Chap-
man et al. (2005)11 exclusively comprises text sim-
ilarity measures which compute lexical similar-
ity on string sequences and compare texts with-
out any semantic processing. It contains mea-
sures such as the Levenshtein (1966) or Monge and
Elkan (1997) distance metrics. In DKPro Similar-
ity, some string-based measures (see Section 3.1)
are based on implementations from this library.

SecondString Toolkit The freely available li-
brary by Cohen et al. (2003)12 is similar to Sim-
Metrics, and also implemented in Java. It also con-
tains several well-known text similarity measures
on string sequences, and includes many of the
measures which are also part of the SimMetrics
Library. Some string-based measures in DKPro
Similarity are based on the SecondString Toolkit.

7 Conclusions

We presented DKPro Similarity, an open source
framework designed to streamline the develop-
ment of text similarity measures. All measures
conform to standardized interfaces and can either
be used as stand-alone components in any ex-
perimental setup (e.g. an already existing system
which is not based on Apache UIMA), or can be
tightly coupled with a full-featured UIMA-based
language processing pipeline in order to allow for
advanced processing capabilities.

We would like to encourage other researchers
to participate in our efforts and invite them to ex-
plore our existing experimental setups as outlined
in Section 5, run modified versions of our setups,
and contribute own text similarity measures to
the framework. For that, DKPro Similarity also
comes with an example module for getting started,
which guides first-time users through both the
stand-alone and the UIMA-coupled modes.

Acknowledgements This work has been supported by the
Volkswagen Foundation as part of the Lichtenberg Profes-
sorship Program under grant No. I/82806, and by the Klaus
Tschira Foundation under project No. 00.133.2008. We thank
Richard Eckart de Castilho and all other contributors.

11sourceforge.net/projects/simmetrics
12sourceforge.net/projects/secondstring

125



References
Eneko Agirre, Daniel Cer, Mona Diab, and Aitor

Gonzalez-Agirre. 2012. SemEval-2012 Task 6: A
Pilot on Semantic Textual Similarity. In Proc. of the
6th Int’l Works. on Semantic Eval., pages 385–393.

Daniel Bär, Chris Biemann, Iryna Gurevych, and
Torsten Zesch. 2012a. UKP: Computing Semantic
Textual Similarity by Combining Multiple Content
Similarity Measures. In Proc. of the 6th Int’l Work-
shop on Semantic Evaluation, pages 435–440.

Daniel Bär, Torsten Zesch, and Iryna Gurevych. 2012b.
Text Reuse Detection Using a Composition of Text
Similarity Measures. In Proc. of the 24th Int’l Conf.
on Computational Linguistics, pages 167–184.

Sam Chapman, Barry Norton, and Fabio Ciravegna.
2005. Armadillo: Integrating Knowledge for the Se-
mantic Web. In Proceedings of the Dagstuhl Semi-
nar in Machine Learning for the Semantic Web.

Paul Clough, Robert Gaizauskas, Scott S.L. Piao, and
Yorick Wilks. 2002. METER: MEasuring TExt
Reuse. In Proceedings of ACL, pages 152–159.

William W. Cohen, Pradeep Ravikumar, and Stephen
Fienberg. 2003. A Comparison of String Metrics
for Matching Names and Records. In Proc. of KDD
Works. on Data Cleaning and Object Consolidation.

Ido Dagan, Oren Glickman, and Bernardo Magnini.
2006. The PASCAL Recognising Textual Entail-
ment Challenge. In Machine Learning Challenges,
Lecture Notes in Computer Science, pages 177–190.

Liviu P. Dinu and Marius Popescu. 2009. Ordinal mea-
sures in authorship identification. In Proceedings of
the 3rd PAN Workshop. Uncovering Plagiarism, Au-
thorship and Social Software Misuse, pages 62–66.

David Ferrucci and Adam Lally. 2004. UIMA: An
Architectural Approach to Unstructured Information
Processing in the Corporate Research Environment.
Natural Language Engineering, 10(3-4):327–348.

Evgeniy Gabrilovich and Shaul Markovitch. 2007.
Computing Semantic Relatedness using Wikipedia-
based Explicit Semantic Analysis. In Proceedings
of IJCAI, pages 1606–1611, Hyderabad, India.

Konstantina Garoufi, Torsten Zesch, and Iryna
Gurevych. 2008. Representational Interoperability
of Linguistic and Collaborative Knowledge Bases.
In Proceedings of the KONVENS Workshop on
Lexical-Semantic and Ontological Resources.

Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA Data Mining Software: An Up-
date. SIGKDD Explorations, 11(1):10–18.

Vasileios Hatzivassiloglou, Judith L. Klavans, and
Eleazar Eskin. 1999. Detecting text similarity over
short passages: Exploring linguistic feature com-
binations via machine learning. In Proceedings of
EMNLP/VLC, pages 203–212.

Jay J. Jiang and David W. Conrath. 1997. Semantic
similarity based on corpus statistics and lexical tax-
onomy. In Proceedings of ROCLING, pages 19–33.

David Jurgens and Keith Stevens. 2010. The S-Space
Package: An Open Source Package for Word Space
Models. In Proceedings of the ACL 2010 System
Demonstrations, pages 30–35, Uppsala, Sweden.

Donald E. Knuth. 1973. The Art of Computer
Programming: Volume 3, Sorting and Searching.
Addison-Wesley.

Thomas K. Landauer, Peter W. Foltz, and Darrell La-
ham. 1998. An Introduction to Latent Semantic
Analysis. Discourse Processes, 25(2):259–284.

Vladimir I. Levenshtein. 1966. Binary codes capa-
ble of correcting deletions, insertions, and reversals.
Soviet Physics Doklady, 10(8):707–710.

Philip M. McCarthy and Scott Jarvis. 2010. MTLD,
vocd-D, and HD-D: A validation study of sophis-
ticated approaches to lexical diversity assessment.
Behavior research methods, 42(2):381–392.

Rada Mihalcea, Courtney Corley, and Carlo Strappa-
rava. 2006. Corpus-based and Knowledge-based
Measures of Text Semantic Similarity. In Proceed-
ings of AAAI-06, pages 775–780, Boston, MA, USA.

Alvaro Monge and Charles Elkan. 1997. An ef-
ficient domain-independent algorithm for detecting
approximately duplicate database records. In Pro-
ceedings of the SIGMOD Workshop on Data Mining
and Knowledge Discovery, pages 23–29.

Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004. WordNet::Similarity - Measuring the
Relatedness of Concepts. In Proceedings of the
HLT-NAACL: Demonstration Papers, pages 38–41.

Lawrence Philips. 2000. The double metaphone
search algorithm. C/C++ Users Jour., 18(6):38–43.

Philip Resnik. 1995. Using Information Content to
Evaluate Semantic Similarity in a Taxonomy. In
Proceedings of the IJCAI, pages 448–453.

Efstathios Stamatatos. 2011. Plagiarism detection
using stopword n-grams. Journal of the Ameri-
can Society for Information Science and Technology,
62(12):2512–2527.

Dominic Widdows and Trevor Cohen. 2010. The Se-
mantic Vectors Package: New Algorithms and Pub-
lic Tools for Distributional Semantics. In Proceed-
ings of IEEE-ICSC, pages 9–15.

William E. Winkler. 1990. String Comparator Metrics
and Enhanced Decision Rules in the Fellegi-Sunter
Model of Record Linkage. In Proceedings of the
Survey Research Methods Section, pages 354–359.

Michael J. Wise. 1996. YAP3: Improved detection of
similarities in computer program and other texts. In
Proc. of the 27th SIGCSE Technical Symposium on
Computer Science Education, pages 130–134.

126


