



















































CLUSE: Cross-Lingual Unsupervised Sense Embeddings


Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 271â€“281
Brussels, Belgium, October 31 - November 4, 2018. cÂ©2018 Association for Computational Linguistics

271

CLUSE: Cross-Lingual Unsupervised Sense Embeddings

Ta-Chung Chi and Yun-Nung Chen
National Taiwan University, Taipei, Taiwan

r06922028@ntu.edu.tw y.v.chen@ieee.org

Abstract
This paper proposes a modularized sense in-
duction and representation learning model that
jointly learns bilingual sense embeddings that
align well in the vector space, where the cross-
lingual signal in the English-Chinese parallel
corpus is exploited to capture the collocation
and distributed characteristics in the language
pair. The model is evaluated on the Stanford
Contextual Word Similarity (SCWS) dataset to
ensure the quality of monolingual sense em-
beddings. In addition, we introduce Bilingual
Contextual Word Similarity (BCWS), a large
and high-quality dataset for evaluating cross-
lingual sense embeddings, which is the first
attempt of measuring whether the learned em-
beddings are indeed aligned well in the vector
space. The proposed approach shows the su-
perior quality of sense embeddings evaluated
in both monolingual and bilingual spaces.1

1 Introduction

Word embeddings have recently become the ba-
sic component in most NLP tasks for its ability
to capture semantic and distributed relationships
learned in an unsupervised manner. The higher
similarity between word vectors can indicate sim-
ilar meanings of words. Therefore, embeddings
that encode semantics have been shown to serve
as the good initialization and benefit several NLP
tasks. However, word embeddings do not allow
a word to have different meanings in different
contexts, which is a phenomenon known as pol-
ysemy. For example, â€œappleâ€ may have different
meanings in fruit and technology contexts. Sev-
eral attempts have been proposed to tackle this
problem by inferring multi-sense word representa-
tions (Reisinger and Mooney, 2010; Neelakantan
et al., 2014; Li and Jurafsky, 2015; Lee and Chen,
2017).

1The code and dataset are available at http://
github.com/MiuLab/CLUSE.

These approaches relied on the â€œone-sense per
collocationâ€ heuristic (Yarowsky, 1993), which
assumes that presence of nearby words correlates
with the sense of the word of interest. However,
this heuristic provides only a weak signal for dis-
criminating sense identities, and it requires a large
amount of training data to achieve competitive per-
formance.

Considering that different senses of a word may
be translated into different words in a foreign lan-
guage, Guo et al. (2014) and SÌŒuster et al. (2016)
proposed to learn multi-sense embeddings using
this additional signal. For example, â€œbankâ€ in
English can be translated into banc or banque in
French, depending on whether the sense is finan-
cial or geographical. Such information allows the
model to identify which sense a word belongs to.
However, the drawback of these models is that
the trained foreign language embeddings are not
aligned well with the original embeddings in the
vector space.

This paper addresses these limitations by
proposing a bilingual modularized sense induction
and representation learning system. Our learn-
ing framework is the first pure sense representa-
tion learning approach that allows us to utilize two
different languages to disambiguate words in En-
glish. To fully use the linguistic signals provided
by bilingual language pairs, it is necessary to en-
sure that the embeddings of each foreign language
are related to each other (i.e., they align well in
the vector space). We solve this by proposing an
algorithm that jointly learns sense representations
between languages. The contributions of this pa-
per are four-fold:
â€¢ We propose the first system that maintains

purely sense-level cross-lingual representa-
tion learning with linear-time sense decod-
ing.
â€¢ We are among the first to propose a single ob-

http://github.com/MiuLab/CLUSE
http://github.com/MiuLab/CLUSE


272

jective for modularized bilingual sense em-
bedding learning.
â€¢ We are the first to introduce a high-quality

dataset for directly evaluating bilingual sense
embeddings.
â€¢ Our experimental results show the state-of-

the-art performance for both monolingual
and bilingual contextual word similarities.

2 Related Work

There are a lot of prior works focusing on repre-
sentation learning, while this work mainly focuses
on bridging the work about sense embeddings and
cross-lingual embeddings and introducing a newly
collected bilingual data for better evaluation.

Sense Embeddings Reisinger and Mooney
(2010) first proposed multi-prototype embeddings
to address the lexical ambiguity when using a sin-
gle embedding to represent multiple meanings of
a word. Huang et al. (2012); Neelakantan et al.
(2014); Li and Jurafsky (2015); Bartunov et al.
(2016) utilized neural networks as well as the
Bayesian non-parametric method to learn sense
embeddings. Lee and Chen (2017) first utilized
a reinforcement learning approach and proposed a
modularized framework that separates learning of
senses from that of words. However, none of them
leverages the bilingual signal, which may be help-
ful for disambiguating senses.

Cross-Lingual Word Embeddings Klementiev
et al. (2012) first pointed out the importance of
learning cross-lingual word embeddings in the
same space and proposed the cross-lingual docu-
ment classification (CLDC) dataset for extrinsic
evaluation. Gouws et al. (2015) trained directly
on monolingual data and extracted a bilingual sig-
nal from a smaller set of parallel data. KocÌŒiskyÌ€
et al. (2014) used a probabilistic model that simul-
taneously learns alignments and distributed repre-
sentations for bilingual data by marginalizing over
word alignments. Hermann and Blunsom (2014)
learned word embeddings by minimizing the dis-
tances between compositional representations be-
tween parallel sentence pairs. SÌŒuster et al. (2016)
reconstructed the bag-of-words representation of
semantic equivalent sentence pairs to learn word
embeddings. Shi et al. (2015) proposed a training
algorithm in the form of matrix decomposition,
and induced cross-lingual constraints for simul-
taneously factorizing monolingual matrices. Lu-
ong et al. (2015) extended the skip-gram model to

bilingual corpora where contexts of bilingual word
pairs were jointly predicted. Wei and Deng (2017)
proposed a variational autoencoding approach that
explicitly models the underlying semantics of the
parallel sentence pairs and guided the generation
of the sentence pairs. Although the above ap-
proaches aimed to learn cross-lingual embeddings
jointly, they fused different meanings of a word in
one embedding, leading to lexical ambiguity in the
vector space model.

Cross-Lingual Sense Embeddings Guo et al.
(2014) adopted the heuristics where different
meanings of a polysemous word usually can be
represented by different words in another language
and clustered bilingual word embeddings to in-
duce senses. SÌŒuster et al. (2016) proposed an
encoder, which uses parallel corpora to choose a
sense for a given word, and a decoder that predicts
context words based on the chosen sense. Bansal
et al. (2012) proposed an unsupervised method for
clustering the translations of a word, such that the
translations in each cluster share a common se-
mantic sense. Upadhyay et al. (2017) leveraged
cross-lingual signals in more than two languages.
However, they either used pretrained embeddings
or learned only for the English side, which is un-
desirable since cross-lingual embeddings shall be
jointly learned such that they aligned well in the
embedding space.
Evaluation Datasets Several datasets can be
used to justify the performance of learned sense
embeddings. Huang et al. (2012) presented
SCWS, the first and only dataset that contains
word pairs and their sentential contexts for mea-
suring the quality of sense embeddings. However,
it is a monolingual dataset constructed in English,
so it cannot evaluate cross-lingual semantic word
similarity. On the other hand, while Camacho-
Collados et al. (2017) proposed a cross-lingual se-
mantic similarity dataset, it ignored the contextual
words but kept only word pairs, making it impos-
sible to judge sense-level similarity. In this paper,
we present an English-Chinese contextual word
similarity dataset in order to benchmark the exper-
iments about bilingual sense embeddings.

3 CLUSE: Cross-Lingual Unsupervised
Sense Embeddings

Our proposed model borrows the idea about mod-
ularization from Lee and Chen (2017), which
treats the sense induction and representation mod-



273

Bilingual Sense Induction (EN-ZH)

è˜‹æœ å…¬å¸ è¨­è¨ˆ ä¸–ç•Œ ä¸€æµçš„ æ‰‹æ©Ÿ

ğ‘(ğ‘§ğ‘–1|ğ‘ğ‘– , ğ‘ğ‘–
â€²)

ğ‘„ğ‘’ğ‘›

ğ‘ƒğ‘’ğ‘›

ğ‘(ğ‘§ğ‘–2|ğ‘ğ‘– , ğ‘ğ‘–
â€²)

ğ‘(ğ‘§ğ‘–3|ğ‘ğ‘– , ğ‘ğ‘–
â€²)

ğ‘ƒğ‘§â„

ğ‘ğ‘–

ğ‘ğ‘–
â€²

Bilingual Sense Induction (EN-ZH)

ğ‘(ğ‘§ğ‘–1|ğ‘ğ‘–)
ğ‘„ğ‘§â„

ğ‘(ğ‘§ğ‘–2|ğ‘ğ‘–)

ğ‘(ğ‘§ğ‘–3|ğ‘ğ‘–)

ğ‘ƒğ‘§â„

Monolingual Sense Induction (ZH)

Apple_2 :

ğ‘(ğ‘ ğ‘—|ğ‘ ğ‘–)

ğ‘(ğ‘ ğ‘˜|ğ‘ ğ‘–)

ğ‘‰ğ‘’ğ‘›

ğ‘ˆğ‘’ğ‘›

Monolingual Sense 
Representation Learning (EN)

:

ğ‘(ğ‘ ğ‘™
â€²|ğ‘ ğ‘–)

ğ‘(ğ‘ ğ‘˜
â€² |ğ‘ ğ‘–)

ğ‘‰ğ‘§â„

ğ‘ˆğ‘’ğ‘›

Bilingual Sense Representation 
Learning (EN-ZH)

æ‰‹æ©Ÿ_2
(cellphone_2)

company_1

Apple company designs the best 
cellphone in the world

Figure 1: Sense induction modules decide the senses of words, and two sense representation learning
modules optimize the sense collocated likelihood for learning sense embeddings within a language and
between two languages. Two languages are treated equally and optimized iteratively.

ules separately to avoid mixing word-level and
sense-level embeddings together.

Our model consists of four different modules il-
lustrated in Figure 1, where sense induction mod-
ules decide the senses of words, and two sense rep-
resentation learning modules optimize the sense
collocated likelihood for learning sense embed-
dings within a language and between two lan-
guages in a joint manner. All modules are detailed
below.

3.1 Notations

We denote our parallel corpus without word align-
mentC, whereCen is for the English part andCzh

is for the Chinese part. Our English vocabulary is
W en and Chinese vocabulary is W zh. Moreover,
Cent and C

zh
t are the t-th sentence-level parallel

sentences in English and Chinese respectively. In
the following sections, we treat English as the ma-
jor language and Chinese as an additional bilin-
gual signal, while their roles can be mutually ex-
changed. Specifically, English and Chinese itera-
tively become the major language during the train-
ing procedure.

3.2 Bilingual Sense Induction Module

The bilingual sense induction module takes a par-
allel sentence pair as input and determines which
sense identity a target word belongs to given the
bilingual contextual information. Formally, for the
t-th English sentence Cent , we aim to decode the
most probable sense zik âˆˆ Zi for the i-th word
wi âˆˆ W en in Cent , where Zi is the set of sense

candidates for wi and 1 â‰¤ k â‰¤ |Zi|. We assume
that the meaning of wi can be determined by its
surrounding words, or the so-called local context,
ci = {wiâˆ’m, Â· Â· Â· , wi+m}, where m is the size of
context window.

Aside from monolingual information, it is desir-
able to exploit the parallel sentences as additional
bilingual contexts to enable cross-lingual embed-
ding learning. Note that word alignment is not re-
quired in this work, so we consider the whole par-
allel bilingual sentence during training. Consider-
ing training efficiency, we sample M words in the
parallel bilingual sentence with their original rel-
ative order or pad it to M for those shorter than
M . Formally, given the t-th parallel bilingual sen-
tence Czht , the bilingual context of wi is therefore
câ€²i = {wâ€²0, Â· Â· Â· , wâ€²Mâˆ’1} and wâ€² âˆˆW zh.

To ensure efficiency, continuous bag-of-words
(CBOW) model is applied, where it takes word-
level input tokens and outputs sense-level identi-
ties. Specifically, given an English word embed-
ding matrix P en, the local context can be mod-
eled as the average of word embeddings from its
context, 1|ci|

âˆ‘
wjâˆˆci P

en
j . Similarly, we can model

the bilingual contextual information given Chinese
word embedding matrix P zh using the CBOW for-
mulation and obtain 1M

âˆ‘
wâ€²jâˆˆcâ€²i

P zhj . We linearly
combine the contextual information from different
languages as:

CÌ„ = Î± Â· 1
|ci|

âˆ‘
wjâˆˆci

P enj + (1âˆ’ Î±) Â·
1

M

âˆ‘
wâ€²jâˆˆcâ€²i

P zhj .

(1)



274

The likelihood of selecting each sense iden-
tity zik for wi can be formulated in the form
of Bernoulli distribution with a sigmoid function
Ïƒ(Â·):

p(zik | ci, câ€²i) = Ïƒ((Qenik )T CÌ„), (2)

where Qen is a 3-dimensional tensor with each
dimension denotes W en, zik for a specific word
i in W en, and the corresponding latent variable,
respectively. Therefore, Qenik will retrieve the la-
tent variable of k-th sense of i-th English word.
Finally, we can induce the sense identity, zâˆ—ik,
given the contexts of a word wi from different lan-
guages, ci and câ€²i.

zâˆ—ik = arg maxzik
p(zik | ci, câ€²i) (3)

In order to allow the module to explore other po-
tential sense identities, we apply an ï¿½-greedy al-
gorithm (Mnih et al., 2013) for exploration in the
training procedure.

3.3 Monolingual Sense Induction Module
This module is the degraded version of bilingual
sense induction module when Î± = 1, which oc-
curs where no parallel bilingual signal exists. In
other words, every bilingual sense induction mod-
ule will experience the degradation during the
training process presented in Algorithm 1. The
only difference is that it cannot access the bilin-
gual information. The purpose of this module is
to maintain the stability of sense induction and to
decode the sampled bilingual sense identity which
will later be used in the bilingual sense representa-
tion learning module. As shown in Figure 1, given
the monolingual context of a word, this module
selects its sense identity using (2) and (3) with
Î± = 1.

3.4 Monolingual Sense Representation
Learning Module

Given the decoded sense identities from the
sense induction module, the skip-gram architec-
ture (Mikolov et al., 2013) is applied consider-
ing that it only requires two decoded sense iden-
tities for stochastic training. We first create an in-
put English sense representation matrix U en and
an English collocation estimation matrix V en as
the learning targets. Given a target word wi and
its collocated word wj in the t-th English sen-
tence Cent , we map them to their sense identities
as zâˆ—ik = si and z

âˆ—
jl = sj by the sense induction

module and maximize the sense collocation likeli-
hood. The skip-gram objective can be formulated
as p(sj | si):

p(sj | si) =
exp((U ensi )

TV ensj )âˆ‘
sk

exp((U ensi )
TV ensk )

, (4)

where sk iterates over all possible English sense
identities in the denominator. This formulation
shares the same architecture as skip-gram but ex-
tends to rely on senses. Note that the Chinese
sense representation learning module is built sim-
ilarly.

3.5 Bilingual Sense Representation Learning
Module

To ensure sense embeddings of two different lan-
guages align well, we hypothesize that the target
sense identity si not only predicts the sense iden-
tity sj of wj in Cent but also one sampled sense
identity sâ€²l of w

â€²
l from the parallel sentence C

zh
t ,

where sâ€²l is decoded by the Chinese monolingual
sense induction module. Specifically, the bilin-
gual skip-gram objective can be formulated using
the English sense embedding matrix U en and the
bilingual collocation estimation matrix V zh as:

p(sâ€²l | si) =
exp((U ensi )

TV zhsâ€²l
)âˆ‘

sâ€²k
exp((U ensi )

TV zh
sâ€²k

)
, (5)

where sâ€²k iterates over all possible Chinese sense
identities in the denominator.

3.6 Joint Learning
In this learning framework, the gradient cannot
be back-propagated from the representation mod-
ule to the induction module due to the usage of
arg max operator. It is therefore desirable to con-
nect these two modules in a way such that they
can improve each other by their own estimations.
In one direction, forwarding the prediction of the
sense induction module to the sense representation
learning module is trivial, while in another direc-
tion, we treat the estimated collocation likelihood
as the reward for the induction module.

First note that calculating the partition func-
tion in the denominator of (4) and (5) is in-
tractable since it involves a computationally ex-
pensive summation over all sense identities. In
practice, we adopt the negative sampling strategy
technique (Mikolov et al., 2013) and rewrite (4)
and (5) as:



275

log p(sj | si) = log Ïƒ((U ensi )
TV ensj )+

Nâˆ‘
k=1

Eskâˆ¼pneg(s)[Ïƒ(âˆ’(U
en
si )

TV ensk )],

(6)

log p(sâ€²l | si) = log Ïƒ((U ensi )
TV zhsâ€²l

)+

Nâˆ‘
k=1

Esâ€²kâˆ¼pneg(sâ€²)[Ïƒ(âˆ’(U
en
si )

TV zhsâ€²k
)],

(7)

where pneg(s) and pneg(sâ€²) is the distribution over
all English senses and all Chinese senses for nega-
tive samples respectively, and N is the number of
negative sample. The rewritten objective for op-
timizing two sense representation learning mod-
ules is the same as maximizing (6) and (7). More-
over, we can utilize the probability of correctly
classifying the skip-gram sense pair as the reward
signal. The intuition is that a correctly decoded
sense identity is more likely to predict its neigh-
boring sense identity compared to incorrectly de-
coded ones.

This learning framework can now be viewed
as a reinforcement learning agent solving one-
step Markov Decision Process (Sutton and Barto,
1998; Lee and Chen, 2017). For bilingual mod-
ules, the state, action, and reward correspond to
bilingual context CÌ„, sense zik, and Ïƒ((U ensi )

TV zhsâ€²l
)

respectively. As for the monolingual modules, the
state, action, and reward correspond to monolin-
gual context ct, sense zik, and Ïƒ((U ensi )

TV ensj )).
Finally, we can optimize both bilingual and mono-
lingual sense induction modules (P and Q from
(2) by minimizing the cross entropy loss between
decoded sense probability and reward. We also in-
clude an entropy regularization term as suggested
in (SÌŒuster et al., 2016) to let the sense induction
module converge faster and make more confident
predictions. Formally,

minH(Ïƒ((U ensi )
TV zhsâ€²l

), p(zik | ci, câ€²i))

+ Î»E(p(zik | ci, câ€²i))
(8)

minH(Ïƒ((U ensi )
TV ensj ), p(zik | ci))

+ Î»E(p(zik | ci)) (9)

E is the entropy of selection probability weighted
by Î». Note that the major language is switched

Algorithm 1 Bilingual Sense Embedding Learn-
ing Algorithm

Input: Cen, Czh, W en, W zh
Output: P en, P zh, Qen, Qzh, Uen, Uzh, V en, V zh

1: loop until converge
2: MAIN(en, zh, 0.4) . 0.4 is just an example weight
3: MAIN(zh, en, 0.4)
4: end loop
5: function MAIN(maj, bi, Î±)
6: t, i, j, k, lâ† GETTRAINDATA(maj)
7: si, predi â† INDUCESENSE(maj, bi, t, i, Î±)
8: sj , â† INDUCESENSE(maj, bi, t, j, Î±)
9: sâ€²l, pred

â€²
l â† INDUCESENSE(bi, bi, t, k, 1.0)

10: sâ€²k, â† INDUCESENSE(bi, bi, t, l, 1.0)
11: r â† TRAINSRL(maj, maj, si, sj)
12: râ€² â†TRAINSRL(maj, bi, si, sâ€²l)
13: râ€²â€² â†TRAINSRL(bi, bi, sâ€²l, sâ€²k)
14: TRAINSI(maj, bi, r, predi)
15: TRAINSI(maj, bi, râ€², predi)
16: TRAINSI(bi, bi, râ€²â€², predâ€²l)
17: end function
18: function INDUCESENSE(maj, bi, t, i, Î±)
19: calculate Î±-weighted CÌ„ by (1)
20: select zâˆ—ik by (2) and (3)
21: return zâˆ—ik, p(zâˆ—ik | CÌ„)
22: end function
23: function TRAINSRL(maj, bi, si, sj)
24: if maj==bi then
25: optimize Umaj , V maj by (6) given si, sj
26: else
27: optimize Umaj , V bi by (7) given si, sj
28: end if
29: return collocation prob of (si, sj)
30: end function
31: function TRAINSI(maj, bi, r, pred)
32: if maj==bi then
33: optimize Pmaj , Qmaj by (9) given r, pred
34: else
35: optimize Pmaj , Qbi by (8) given r, pred
36: end if
37: end function

iteratively among two languages. Algorithm 1
presents the full learning procedure.

4 New Datasetâ€”Bilingual Contextual
Word Similarity (BCWS)

We propose a new dataset to measure the bilingual
contextual word similarity. English and Chinese
are chosen as our language pair for three reasons:

1. They are the top widely used languages in the
world.

2. English and Chinese belong to completely
different language families, making it inter-
esting to explore syntactic and semantic dif-
ference among them.

3. Chinese is a language that requires segmen-
tation, this dataset can also help researchers
experiment on different segmentation levels
and investigate how segmentation affects the



276

English Sentence Chinese Sentence Score
Judges must give both sides an equal æˆ‘éå¸¸å–œæ­¡é€™å€‹æ•…äº‹ï¼Œå®ƒ<å‘Šå‘Šå‘Šè¨´è¨´è¨´>æˆ‘å€‘ä¸€äº› 7.00
opportunity to <state> their cases. é‡è¦çš„å•Ÿç¤ºã€‚ (I like this story a lot, which

<tells> us some important inspiration.)
It was of negligible <importance> prior é»ƒæ–‘éƒ¨ç—…è®Šçš„é é˜²åŠæ—©æœŸæ²»ç™‚æ˜¯ç›¸ç•¶<é‡é‡é‡è¦è¦è¦> 6.94
to 1990, with antiquated weapons and çš„ã€‚ (The prevention and early treatment of
few members. macular lesions is very <important>.)
Due to the San Andreas Fault bisecting æ°´æœæ”¤è€é—†ä¼¼ä¹å¾ˆæ„å¤–çœŸæœ‰äººè²·é€™<å†·å†·å†·>è²¨ 3.70
the hill, one side has <cold> water, the ï¼Œéœ²å‡ºã€Œä½ çœŸå…§è¡Œã€çš„çœ¼ç¥èˆ‡æˆ‘èŠäº†å¹¾å¥ã€‚
other has hot. (The owner of the fruit stall seemed surprised

that someone bought this <unpopular> product,
talking me few words about â€œyou are such a proâ€.)

Table 1: Sentence pair examples and average annotated scores in BCWS.

sense similarity.
This dataset also provides a direct measure to
determine whether the two language embeddings
align well in the vector space. Note that we focus
on word-level, and this is different from (Klemen-
tiev et al., 2012), which also measured the cross-
lingual embedding similarity but rely on the am-
biguous document-level classification.

Our dataset contains 2093 question pairs, where
each pair consists of exactly one English and one
Chinese sentence; note that they are not parallel
but with their own sentential contexts shown in
Table 1. Eleven raters2 were recruited to anno-
tate this dataset. Each rater gives a score ranging
from 1.0 (different) to 10.0 (same) for each ques-
tion to indicate the semantic similarity of bilingual
word pairs based on sentential clues. The anno-
tated dataset shows very high intra-rater consis-
tency; we leave one rater out and calculate Spear-
man correlation between the rater and the average
of the rest, and the average number is about 0.83,
indicating the human-level performance (the aver-
age number in SCWS is 0.52).

We describe the construction of BCWS below.

Chinese Multi-Sense Word Extraction We uti-
lize the Chinese Wikipedia dump to extract the
most frequent 10000 Chinese words that are
nouns, adjective, and verb based on Chinese
Wordnet (Huang et al., 2010). In order to test
the sense-level representations, we discard single-
sense words to ensure that the selected words are
polysemous. Also, the words with more than 20
senses are deleted, since those senses are too fine-

2They are all Chinese native speaker whose scores are at
least 29 in the TOEFL reading section or 157 in the GRE
verbal section.

grained and even hard for human to disambiguate.
We denote the list of Chinese words lc.

English Candidate Word Extraction We have
to find an English counterpart for each Chinese
word in lc. We utilize BabelNet (Navigli and
Ponzetto, 2010), a free and open-sourced knowl-
edge resource, to serve as our bilingual dictionary.
To be more concrete, we first query the selected
Chinese word using the free API call provided by
Babelnet to retrieve all WordNet senses3. For ex-
ample, the Chinese word â€œåˆ¶æœâ€ has two major
meanings:

â€¢ a type of clothing worn by members of an or-
ganization
â€¢ force to submit or subdue.

Hence, we can obtain two candidate English
words â€œuniformâ€ and â€œsubjugateâ€. Each word in
lc retrieves its associated English candidate words
and obtain the dictionary D.

Enriching Semantic Relationship Note that D
is merely a simple translation mapping between
Chinese and English words. It is desirable that we
have a more complicated and interesting relation-
ship between bilingual word pairs. Hence, we tra-
verse D and for each English word we find its hy-
ponyms, hypernyms, holonyms and attributes, and
add the additional words into D. In our example,
we may obtain {åˆ¶æœ:[uniform, subjugate, livery,
clothing, repress, dominate, enslave, dragoon...]}.
We sample 2 English words if the number of En-
glish candidate words is more than 5, 3 English
words if more than 10, and 1 English word oth-

3BabelNet contains sense definitions from various re-
sources such as Wordnet, Wikitionary, Wikidata, etc



277

erwise to form the final bilingual pair. For ex-
ample, a bilingual word pair (åˆ¶æœ, enslave) can
be formed accordingly. After this step, we obtain
2093 bilingual word pairs P .

Adding Contextual Information Given the
bilingual word pairs P , appropriate contexts
should be found in order to form the full sentences
for human judgment. For each Chinese word, we
randomly sample one example sentence in Chi-
nese WordNet that matches the PoS tag we se-
lected in section 4. For each English word, we
traverse the whole English Wikipedia dump to find
the sentences that contain the target English word.
We then sample one sentence where the target
word is tagged as the matched PoS tag4.

5 Experiments

5.1 Experimental Setup
Two sets of parallel data are used in the ex-
periments, one for English-Chinese (EN-ZH)
and another for English-German (EN-DE). UM-
corpus (Tian et al.) is used for EN-ZH train-
ing, while Europarl corpus (Koehn, 2005) is
used for EN-DE training. UM-corpus contains
15,764,200 parallel sentences with 381,921,583
English words and 572,277,658 unsegmented Chi-
nese words. Europarl contains 1,920,209 par-
allel sentences with 44,548,491 German words
and 47,818,827 English words. We evaluate our
proposed model on the benchmark monolingual
dataset, SCWS, and on the bilingual dataset, our
proposed BCWS, where the evaluation metrics are
actually introduced in section 5.4.

5.2 Hyperparameter Settings
In our experiments, we use a mini-batch size of
512, context window size for major language is
set to m = 5 and we sample M = 20 words for
bilingual context. For the exploration of sense in-
duction module, we set ï¿½ = 0.05. The Î» of en-
tropy regularization is set to 1.5 For negative sam-
pling in (6) and (7), we pick N = 25. The fixed
learning rate is set to 0.025. The embedding di-
mension is 300 and the sense number per word is
set to 3 for both Chinese, German, and English
(|Zi| = 3). This setting is for a fair comparison
with prior works.

4We use the NLTK PoS tagger to obtain the tags.
5We tried different values of Î» = 0.001, 0.5, and the

model converges approximately 12, 5 times slower compared
to Î» = 1.

5.3 Baseline
The baselines for comparison can be categorized
into three:
â€¢ Monolingual sense embeddings: Lee and

Chen (2017) is the current state-of-the-art
model of monolingual sense embedding eval-
uated on SCWS. We re-train the sense em-
beddings using the same data but only in En-
glish for fair comparison.
â€¢ Cross-lingual word embeddings: Luong et al.

(2015) treated words from different lan-
guages the same and trained cross-lingual
embeddings in the same space. Conneau
et al. (2017) utilized adversarial training to
map pretrained word embeddings into an-
other language space.
â€¢ Cross-lingual sense embeddings: Upadhyay

et al. (2017) utilized more than two languages
to learn multilingual embeddings. We report
the number shown in the paper for compari-
son.

5.4 Evaluation Metric
Reisinger and Mooney (2010) introduced two
contextual similarity estimations, AvgSimC and
MaxSimC. AvgSimC is a soft measurement that
addresses the contextual information with a prob-
ability estimation:

AvgSimC(wi, CÌ„t, wj , CÌ„tâ€²) =
|Zi|âˆ‘
k=1

|Zj |âˆ‘
l=1

Ï€(zik|CÌ„t)Ï€(zjl|CÌ„tâ€²)d(zik, zjl),

AvgSimC weights the similarity measurement
of each sense pair zik and zjl by their probabil-
ity estimations. On the other hand, MaxSimC is
a hard measurement that only considers the most
probable senses:

MaxSimC(wi, CÌ„t, wj , CÌ„tâ€²) = d(zik, zjl),

zik = arg max
zikâ€²

Ï€(zikâ€² |CÌ„t),

zjl = arg max
zjlâ€²

Ï€(zjlâ€² |CÌ„tâ€²).

d(zik, zjl) refers to the cosine similarity between
Umajzik and U

bi
zjl

in the bilingual case (BCWS) and

Umajzik and U
maj
zjl in the monolingual case (SCWS).

5.5 Bilingual Embedding Evaluation
Cross-lingual sense embeddings are the main con-
tribution of this paper. Table 2 shows that all re-
sults from the proposed model are significantly



278

Model Î± EN-ZH EN-DEBilingual/BCWS Mono(EN)/SCWS Mono(EN)/SCWS
1) Monolingual Sense Embeddings
Lee and Chen (2017) 66.8 / 65.5 63.8 / 63.4
2) Cross-Lingual Word Embeddings
Luong et al. (2015) 49.2 61.1 62.1
Conneau et al. (2017) 52.5 65.5 64.0
3) Cross-Lingual Sense Embeddings
Upadhyay et al. (2017) - 45.0? -
Proposed 0.1 55.8 / 55.8 65.6 / 65.6 63.8 / 63.9

0.3 55.7 / 55.7 64.9 / 65.1 63.8 / 64.0
0.5 56.3 / 56.3 65.8 / 66.0 63.6 / 63.9
0.7 56.7 / 56.7 65.6 / 65.8 63.1 / 63.2
0.9 56.0 / 56.0 66.0 / 66.2 62.9 / 63.1

Table 2: Contextual similarity results evaluated on the SCWS/BCWS dataset, where the reported numbers
indicate Spearmanâ€™s rank correlation ÏÃ— 100 on AvgSimC / MaxSimC. ? indicates that Upadhyay et al.
(2017) trained the sense embeddings using a different parallel dataset.

better than the baselines that learn cross-lingual
word embeddings. It indicates that the sense-level
information is critical for precise vector represen-
tations. In addition, all results for AvgSimC and
MaxSimC are the same in the proposed model,
showing that the learned selection distribution is
reliable for sense decoding.

5.6 Monolingual Embedding Evaluation

Because our model considers multiple languages
and learns the embeddings jointly, the multilin-
gual objective makes learning more difficult due
to more noises. In order to ensure the quality of
the monolingual sense embeddings, we also eval-
uate our learned English sense embeddings on the
benchmark SCWS data. Comparing the results be-
tween training on EN-ZH and training on EN-DE,
all results using EN-ZH are better than ones us-
ing EN-DE. The probable reason is that the lan-
guage difference between English and Chinese is
larger than English and German; parallel Chinese
sentences therefore provide informative cues for
learning better sense embeddings. Furthermore,
our proposed model achieves comparable or supe-
rior performance than the current state-of-the-art
monolingual sense embeddings proposed by Lee
and Chen (2017) when trained on our monolingual
data.

5.7 Sensitivity of Bilingual Contexts

To investigate how much the bilingual sense in-
duction module relies on another language, the re-

Model EN2DE DE2EN
1) Sentence-Level Training
Hermann and Blunsom (2014) 83.7 71.4
AP et al. (2014) 91.8 72.8
Wei and Deng (2017) 91.0 80.4
2) Word-Level Training
Klementiev et al. (2012) 77.7 71.1
Gouws et al. (2015) 86.5 75.0
KocÌŒiskyÌ€ et al. (2014) 83.1 75.4
Shi et al. (2015) 91.3 77.2
Luong et al. (2015) 86.4 75.6
Conneau et al. (2017) 78.7 67.1
Proposed 81.8 76.0

Table 3: Accuracy on cross-lingual document clas-
sification (%).

sults with different Î± are shown in the table.
To justify the usefulness of utilizing bilingual

signal, we compare our model with Lee and Chen
(2017), which used monolingual signal in a sim-
ilar modular framework. Our method outper-
forms theirs in terms of MaxSimC on both EN-ZH
and EN-DE. However, this trend is not observed
on AvgSimC. The reason may be that bilingual
signal is indicative but noisy, which largely af-
fects AvgSimC due to its weighted sum operation.
MaxSimC only picks the most probable senses,
which makes it robust to noises.

In addition, our performance slightly degrades
as Î± increases for EN-DE, and the best perfor-
mance is obtained when Î± is small, indicating that



279

Target kNN Senses (EN) kNN Senses (ZH)
apple 0 fruit, cake, sweet è˜‹æœ,æ˜¥å¤©,è›‹ç³•, iphone,é›è›‹,å·§å…‹åŠ›,è‘¡è„

(apple, spring, cake, iphone, egg, chocolate, purples)
apple 1 iphone, cake, google, stores è˜‹æœ, iphone,å¾®è»Ÿ,ç«¶çˆ­å°æ‰‹,æ˜¥å¤©,è°·æ­Œ

(apple, iphone, microsoft, competitor, spring, google)
uniform 0 dressed, worn, tape, wearing, cloth å‡å‹»,å…‰æ»‘,è¡£æœ,é‹å­,ç©¿è‘—,æœè£

(even, smooth, clothes, shoes, wearing, clothing)
uniform 1 particle, computed, varying, gradient æ…‹,ç²‰æœ«,ç¸±å‘,ç­‰é›¢å­é«”,å‰ªåˆ‡,å‰›åº¦

(phase, powder, longitudinal, plasma, cut, stiffness)

Table 4: Words with similar senses obtained by kNN.

bilingual signal does help. However, this trend is
not observed on EN-ZH, because English is very
different from Chinese, such that it can benefit lit-
tle from Chinese than from German.

5.8 Extrinsic Evaluation

We further evaluate our bilingual sense embed-
dings using a downstream task, cross-lingual doc-
ument classification (CLDC), with a standard
setup (Klementiev et al., 2012). To be more con-
crete, a set of labeled documents in language A is
available to train a classifier, and we are interested
in classifying documents in another language B at
test time, which tests semantic transfer of informa-
tion across different languages. We use the aver-
aged sense embeddings as word embeddings for a
fair comparison.

The result is shown in Table 3. We can see that
our proposed model achieves comparable perfor-
mance or even superior performance to most prior
work on the DE2EN direction; however, the same
conclusion does not hold for the EN2DE direc-
tion. The reason may be that we test the model
that works best on BCWS and hence not able to
tune hyperparameters on the development set of
CLDC. In addition, we use the average of sense
vectors as input word embeddings, which may in-
duce some noises into the resulting vectors. In
sum, the comparable performance of the down-
stream task shows the practical usage and the po-
tential extension of the proposed model.

5.9 Qualitative Analysis

Some examples of our learned sense embeddings
are shown in Table 4. It is obvious to see that
the first sense of Apple is related to fruit and
things to eat, while the second one means the tech
company Apple Inc. Most English and Chinese
nearest neighbors match the meanings of the in-

duced senses, but there are still some noises that
are underlined. For example, cake should be the
neighbor of the first sense rather than the sec-
ond one. The same observation applies to iphone
and spring. In our second example for uniform,
the first sense is related to outfit and clothes, while
the second is related to engineering terms. How-
ever, even appears in the outfit and clothes sense,
which is incorrect. The reason may be that the
size of the parallel corpus is not large enough for
the model to accurately distinguish all senses via
unsupervised learning. Hence, utilizing external
resources such as bilingual dictionaries or design-
ing a new model that can use existing large mono-
lingual corpora like Wikipedia can be our future
work.

6 Conclusion

This paper is the first purely sense-level cross-
lingual representation learning model with effi-
cient sense induction, where several monolingual
and bilingual modules are jointly optimized. The
proposed model achieves superior performance on
both bilingual and monolingual evluation datasets.
A newly collected dataset for evaluating bilingual
contextual word similarity is presented, which
provides potential research directions for future
work.

Acknowledgement

We would like to thank reviewers for their insight-
ful comments on the paper. This work was finan-
cially supported from the Young Scholar Fellow-
ship Program by Ministry of Science and Technol-
ogy (MOST) in Taiwan, under Grant 107-2636-E-
002-004.



280

References
Sarath Chandar AP, Stanislas Lauly, Hugo Larochelle,

Mitesh Khapra, Balaraman Ravindran, Vikas C
Raykar, and Amrita Saha. 2014. An autoencoder
approach to learning bilingual word representations.
In Advances in Neural Information Processing Sys-
tems, pages 1853â€“1861.

Mohit Bansal, John DeNero, and Dekang Lin. 2012.
Unsupervised translation sense clustering. In Pro-
ceedings of the 2012 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
773â€“782. Association for Computational Linguis-
tics.

Sergey Bartunov, Dmitry Kondrashkin, Anton Osokin,
and Dmitry Vetrov. 2016. Breaking sticks and ambi-
guities with adaptive skip-gram. In Artificial Intelli-
gence and Statistics, pages 130â€“138.

Jose Camacho-Collados, Mohammad Taher Pilehvar,
Nigel Collier, and Roberto Navigli. 2017. Semeval-
2017 task 2: Multilingual and cross-lingual semantic
word similarity. In Proceedings of the 11th Interna-
tional Workshop on Semantic Evaluation (SemEval-
2017), pages 15â€“26.

Alexis Conneau, Guillaume Lample, Marcâ€™Aurelio
Ranzato, Ludovic Denoyer, and HerveÌ JeÌgou. 2017.
Word translation without parallel data. arXiv
preprint arXiv:1710.04087.

Stephan Gouws, Yoshua Bengio, and Greg Corrado.
2015. Bilbowa: Fast bilingual distributed represen-
tations without word alignments. In International
Conference on Machine Learning, pages 748â€“756.

Jiang Guo, Wanxiang Che, Haifeng Wang, and Ting
Liu. 2014. Learning sense-specific word embed-
dings by exploiting bilingual resources. In Pro-
ceedings of COLING 2014, the 25th International
Conference on Computational Linguistics: Techni-
cal Papers, pages 497â€“507.

Karl Moritz Hermann and Phil Blunsom. 2014. Multi-
lingual models for compositional distributed seman-
tics. arXiv preprint arXiv:1404.4641.

Chu-Ren Huang, Shu-Kai Hsieh, Jia-Fei Hong, Yun-
Zhu Chen, I-Li Su, Yong-Xiang Chen, and Sheng-
Wei Huang. 2010. Chinese wordnet: Design, im-
plementation, and application of an infrastructure
for cross-lingual knowledge processing. Journal of
Chinese Information Processing, 24(2):14â€“23.

Eric H. Huang, Richard Socher, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Improving Word
Representations via Global Context and Multiple
Word Prototypes. In Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL).

Alexandre Klementiev, Ivan Titov, and Binod Bhat-
tarai. 2012. Inducing crosslingual distributed repre-
sentations of words. Proceedings of COLING 2012,
pages 1459â€“1474.

TomaÌsÌŒ KocÌŒiskyÌ€, Karl Moritz Hermann, and Phil Blun-
som. 2014. Learning bilingual word representa-
tions by marginalizing alignments. arXiv preprint
arXiv:1405.0947.

Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In MT summit, vol-
ume 5, pages 79â€“86.

Guang-He Lee and Yun-Nung Chen. 2017. MUSE:
Modularizing unsupervised sense embeddings. In
Proceedings of the 2017 Conference on Empirical
Methods in Natural Language Processing, pages
327â€“337.

Jiwei Li and Dan Jurafsky. 2015. Do multi-sense em-
beddings improve natural language understanding?
Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing, pages
1722â€“1732.

Thang Luong, Hieu Pham, and Christopher D Man-
ning. 2015. Bilingual word representations with
monolingual quality in mind. In Proceedings of the
1st Workshop on Vector Space Modeling for Natural
Language Processing, pages 151â€“159.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proceedings of Advances in neural informa-
tion processing systems, pages 3111â€“3119.

Volodymyr Mnih, Koray Kavukcuoglu, David Silver,
Alex Graves, Ioannis Antonoglou, Daan Wierstra,
and Martin Riedmiller. 2013. Playing atari with
deep reinforcement learning. NIPS Deep Learning
Workshop.

Roberto Navigli and Simone Paolo Ponzetto. 2010.
Babelnet: Building a very large multilingual seman-
tic network. In Proceedings of the 48th annual meet-
ing of the association for computational linguistics,
pages 216â€“225. Association for Computational Lin-
guistics.

Arvind Neelakantan, Jeevan Shankar, Alexandre Pas-
sos, and Andrew McCallum. 2014. Efficient non-
parametric estimation of multiple embeddings per
word in vector space. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing.

Joseph Reisinger and Raymond J Mooney. 2010.
Multi-prototype vector-space models of word mean-
ing. In Human Language Technologies: The 2010
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 109â€“117. Association for Computational Lin-
guistics.

Tianze Shi, Zhiyuan Liu, Yang Liu, and Maosong Sun.
2015. Learning cross-lingual word embeddings via
matrix co-factorization. In Proceedings of the 53rd
Annual Meeting of the Association for Computa-
tional Linguistics and the 7th International Joint



281

Conference on Natural Language Processing (Vol-
ume 2: Short Papers), volume 2, pages 567â€“572.

Simon SÌŒuster, Ivan Titov, and Gertjan van Noord. 2016.
Bilingual learning of multi-sense embeddings with
discrete autoencoders. In Proceedings of NAACL-
HLT, pages 1346â€“1356.

Richard S Sutton and Andrew G Barto. 1998. Re-
inforcement learning: An introduction, volume 1.
MIT press Cambridge.

Liang Tian, Derek F Wong, Lidia S Chao, Paulo
Quaresma, and Francisco Oliveira. Um-corpus: A
large english-chinese parallel corpus for statistical
machine translation.

Shyam Upadhyay, Kai-Wei Chang, Matt Taddy, Adam
Kalai, and James Zou. 2017. Beyond bilingual:
Multi-sense word embeddings using multilingual
context. In Proceedings of the 2nd Workshop on
Representation Learning for NLP, pages 101â€“110.

Liangchen Wei and Zhi-Hong Deng. 2017. A vari-
ational autoencoding approach for inducing cross-
lingual word embeddings. In Proceedings of the
26th International Joint Conference on Artificial In-
telligence, pages 4165â€“4171. AAAI Press.

David Yarowsky. 1993. One sense per collocation. In
Proceedings of the workshop on Human Language
Technology, pages 266â€“271. Association for Com-
putational Linguistics.


