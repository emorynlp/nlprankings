










































Experiments with a Differential Semantics Annotation for WordNet 3.0


Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 19–27,
24 June, 2011, Portland, Oregon, USA c©2011 Association for Computational Linguistics

Experiments with a Differential Semantics Annotation for WordNet 3.0 

 
 

Dan Tufiş Dan  Ştefănescu 
Research Institute for Artificial Intelligence  

Romanian Academy 
Research Institute for Artificial Intelligence  

Romanian Academy 
Calea ”13 Septembrie”, no.13 Calea ”13 Septembrie”, no.13 
Bucharest 5, 050711, Romania Bucharest 5, 050711, Romania 

tufis@racai.ro danstef@racai.ro 
  

 

Abstract 

This article reports on the methodology and 
the development of a complementary 
information source for the meaning of the 
synsets of Princeton WordNet 3.0. This 
encoded information was built following 
the principles of the Osgoodian differential 
semantics theory and consists of numerical 
values which represent the scaling of the 
connotative meanings along the multiple 
dimensions defined by pairs of antonyms 
(factors). Depending on the selected 
factors, various facets of connotative 
meanings come under scrutiny and 
different types of textual subjective 
analysis may be conducted (opinion 
mining, sentiment analysis). 

1 Introduction 

According to “Semantic Differential” theory 
(Osgood et al., 1957), the connotative meaning of 
most adjectives can be, both qualitatively and 
quantitatively, differentiated along a scale, the ends 
of which are antonymic adjectives. Such a pair of 
antonymic adjectives is called a factor. The 
intensive experiments Osgood and his colleagues 
made with their students1 outlined that most of the 
variance in the text judgment was explained by 
only three major factors: the evaluative factor (e.g., 
good-bad), the potency factor (e.g., strong-weak), 
and the activity factor (e.g., active-passive).   
                                                           
1  The students were asked to rate the meaning of words, 

phrases, or texts on different scales defined in terms of pairs 
of bipolar adjectives such as good-bad, active-passive, 
strong-weak, optimistic-pessimistic, beautiful-ugly, etc.) 

Kamps and Marx (2002) implemented a 
WordNet-based method in the spirit of the theory 
of semantic differentials and proposed a method to 
assess the”attitude” of arbitrary texts. In their 
approach, a text unit is regarded as a bag of words 
and the overall scoring of the sentence is obtained 
by combining the scores for the individual words 
of the text. Depending on the selected factor, 
various facets of subjective meanings come under 
scrutiny.  

The inspiring work of Kamps and Marx still has 
several limitations. The majority of researchers 
working on subjectivity agree that the subjectivity 
load of a given word is dependent on the senses of 
the respective word (Andreevskaia and Bergler, 
2006), (Bentivogli et al., 2004), (Mihalcea et al., 
2007), (Valiutti et al., 2004) and many others.; yet, 
in Kamps and Marx’s model (KMM, henceforth), 
because they work with words and not word-
senses, the sense distinctions are lost, making it 
impossible to assign different scores to different 
senses of the word in case. Going up from the level 
of word to the level of sentence, paragraph or 
entire text, the bag of words approach can easily be 
fooled in the presence of valence shifters (Polanyi 
and Zaenen, 2006). In order to cope with this 
problem, the text under investigation needs a 
minimal level of sentence processing, required for 
the identification of the structures that could get 
under the scope of a valence shifter (Tufiş, 2008). 
For dealing with irony or sarcasm, processing 
requirements go beyond sentence level, and 
discourse structure of the text might be necessary. 

On the other hand, although the adjectives make 
up the obvious class of subjectivity words, the 
other open class categories have significant 
potential for expressing subjective meanings.  

19



In our models, unlike KMM, the building block 
is the word sense, thus making possible to assign 
different connotation values to different senses of a 
word. This was possible by using an additional 
source of information besides the WordNet itself, 
namely the SUMO/MILO ontology. Moreover, we 
considered all the word classes contained in 
WordNet, not only adjectives. 

From this point of view, our work, although 
through a different approach, shares objectives 
with other wordnet-based methods such as 
SentiWordNet (Esuli and Sebastiani, 2006) 
(Baccianella et al., 2010) and WordNet Affect 
(Valiuttti et al. 2004). 

2 Base Definitions 

Let us begin with some definitions, slightly 
modified, from KMM. We will progressively 
introduce new definitions to serve our extended 
approach. 

Definition 1: Two words wα and wβ are related 
if there exists a sequence of words (wα w1 
w2…wi… wβ) so that each pair of adjacent words 
in the sequence belong to the same synset. If the 
length of such a sequence is n+1 one says that wα 
and wβ are n-related. 

Two words may not be related at all or may be 
related by many different sequences, of various 
lengths. In the latter case, one would be interested 
in their minimal path-length. 

Definition 2: Let MPL(wi, wj) be the partial 
function: 

     
 otherwise    

related-n  are    wand  n when  wsmallest        the
),( ji





=
undefined

n
wwMPL ji

 

Kamps and Marx (2002) showed that MPL is a 
distance measure that can be used as a metric for 
the semantic relatedness of two words. Observing 
the properties of the MPL partial function, one can 
quantify the relatedness of an arbitrary word wi to 
one or the other word of a bipolar pair. To this end, 
KMM introduced another partial function as in 
Definition 3. 

Definition 3: Let TRI (wi, wα, wβ), with wα ≠ wβ 
be: 









=

 otherwise                               

  defined   MPLs  if  
,(

,(- ,(

),,(

undefined

)wwMPL

)wwMPL)wwMPL

wwwTRI
ii

i βα

βα

βα

 

When defined, TRI(wi, wαααα, wββββ) is a real number 
in the interval [-1, 1]. The words wα and wβ are the 

antonymic words of a factor, while wi is the word 
of interest for which TRI is computed. If one takes 
the negative values returned by the partial function 
TRI (wi, wαααα, wββββ) as an indication of wi being more 
similar to wα than to wβ and the positive values as 
an indication of wi being more similar to wβ than to 
wα, then a zero value could be interpreted as wi 
being neutrally related with respect to wα and wβ. 
This is different from being unrelated. 

Definition 4: If αααα-ββββ is a factor used for the 
computation of relatedness of wi to α and β, the 
proper function TRI*αααα-ββββ (wi) returns a value outside 
the interval [-1, 1] when wi is unrelated to the α-β 
factor: 





=−  otherwise                        2
defined  ),,(w TRI  iff   ),,(w TRI

)( ii*
βαβα

βα iwTRI

 
Given a factor α-β, for each word wi in 

WordNet that can be reached on a path from α to 
β, the function TRI*αααα-ββββ (wi)  computes a score 
number, which is a proportional to the distances 
from wi to α and to β. The set of these words 
defines the coverage of the factor – COV(α, β).  

Our experiments show that the coverage of the 
vast majority of the factors, corresponding to the 
same POS category, is the same. From now on, we 
will use LUC (Literal Unrestricted2 Coverage) to 
designate this common coverage. The table below 
gives coverage figures for each of the POS 
categories in Princeton WordNet 3.0 (PWN 3.0). 
 

Class Factors LUC 

Adjectives  199  4,402 (20.43%) 

Nouns  106 11,964 (10,05%) 

Verbs  223 6,534 (56,66%) 

Adverbs 199 1,291 (28,81%) 

Table 1: LUC Statistics According to the POS of 
the Literals in PWN 3.0  

The PWN structuring does not allow us to 
compute TRI* scores for adverbs using this 
approach, but, more than half of the total number 
of adverbs (63.11%) are derived from adjectives. 
For those adverbs, we transferred the score values 
from their correspondent adjectives in the LUC set 
and we used the adjectival factors. 

                                                           
2 In the following we will gradually introduce several 

restrictions, thus justifying the acronym used here. 

20



The results reported for adjectives by Kamps 
and Marx3  are consistent with our findings. The 
difference in numbers might be explained by the 
fact that the two compared experiments used 
different versions of the Princeton WordNet. 

3 Introducing Word-Sense Distinctions  

KMM defines a factor as a pair of words with 
antonymic senses. We generalize the notion of a 
factor to a pair of synsets. In the following, we will 
use the colon notation to specify the sense number 
of a literal that licenses the synonymy relation 
within a synset. Synonymy is a lexical relation that 
holds not between a pair of words but between 
specific senses of those words. That is, the notation 
{literal1:n1 literal2:n2 … literalk:nk} will mean that 
the meaning given by the sense number n1 of the 
literal1, the meaning given by sense number n2 of 
the literal2 and so on are all pair-wise synonymous. 
The term literal is used to denote the dictionary 
entry form of a word (lemma).  

The antonymy is also a lexical relation that 
holds between specific senses of a pair of words. 
The synonyms of the antonymic senses, taken 
pairwise, definitely express a semantic opposition. 
Take for instance the antonymic pair <rise:1 
fall:2>. These two words belong to the synsets 
{rise:1, lift:4, arise:5, move up:2, go up:1, come 
up:6, uprise:6} and {descend:1, fall:2, go down:1, 
come down:1}. The pair <rise:1 fall:2> is 
explicitly encoded as antonymic. However, there is 
a conceptual opposition between the synsets to 
which the two word senses belong, that is between 
any pair of the Cartesian product: {rise:1, lift:4, 
arise:5, move up:2, go up:1, come up:6, 
uprise:6}⊗{descend:1, fall:2, go down:1, come 
down:1}. This conceptual opposition is even more 
obvious in this example, as the pairs <go up:1 go 
down:1> and <come up:1 come down:1> are also 
explicitly marked as antonymic. 

Definition 5: An S-factor is a pair of synsets 
(Sα, Sβ) for which there exist ���: ��� ∊ �� and 
��

	: ��
	 ∊ �	 so that ���: ���  and ��

	: ��
	  are 

antonyms and 
�� ��� , ��
	� is defined. Sα and Sβ 

                                                           
3 They found 5410 adjectives that were in the coverage of the 

factors they investigated (WordNet 1.7). For PWN 2.0, the 
total number of covered adjectives is 5307. 

have opposite meanings, and we consider 

that 
����� , �	� = 
�� ��� , ��
	�.  

The previous example shows that the semantic 
opposition of two synsets may be reinforced by 
multiple antonymic pairs. Because of how MPL is 
defined, choosing different antonymic pairs might 
produce different values for 
����� , �	�. That is 
why, wherever is the case, we need to specify the 
antonymic pair which defines the S-factor. 

Based on the definition of the coverage of a 

factor < αiw ,
β
iw >, one may naturally introduce the 

notion of coverage of a S-factor - <Sα,Sβ>: the set 

of synsets containing the words in COV< αiw ,
β
iw >. 

The coverage of an S-factor <Sα,Sβ> will be 
onward denoted by SCOV<Sα, Sβ>.  

Since the word-relatedness and MPL definitions 
ignore the word senses, it might happen that the 
meaning of some synsets in the coverage of an S- 
factor have little (if anything) in common with the 
semantic field defined by the respective S-factor. 
More often than not, these outliers must be filtered 
out and, to this end, we further introduce the 
notions of semantic type of a synset, typed S-factor, 
and scoped synset with respect to a typed S-factor, 
which represent major deviations from KMM. 

 

Figure 1. Different levels of coverage (marked 
with cross hatching) for the S-factor <Sα-Sβ> 

Before that, we need to introduce the mapping 
between the WordNet synsets and the SUMO/ 
MILO concepts. The Suggested Upper Merged 
Ontology (SUMO), Mid-Level Ontology (MILO) 
and its domain ontologies form the largest formal 
public 4  ontology in existence today, containing 
roughly 20,000 terms and 70,000 axioms (when 

                                                           
4 http://www.ontologyportal.org/ 

21



SUMO, MILO, and domain ontologies are 
combined). One of the major attractions of this 
ontology (Niles and Pease, 2003) is that it has been 
mapped to the WordNet lexicon. Using this 
mapping, synsets are labeled with a SUMO/MILO 
concept which we will refer to as the synset’s 
semantic type. The hierarchical structure of 
SUMO/MILO induces a partial ordering of the S-
factors. 

Definition 6: An S-factor <Sα, Sβ> is said to be 
a typed S-factor if the types of the synsets Sα and 
Sβ are identical or they have a common ancestor. If 
this ancestor is the lowest common ancestor, it is 
called the 0-semantic type of the S-factor. The 
direct parent of the n-semantic type of an S-factor 
is the n+1-semantic type of the S-factor (Fig. 1). 

A typed S-factor is represented by indexing the 
S-factor with its type as in the examples below: 
<{unfairness:2…}, { fairness:1…}>NormativeAttribute  
<{discomfort:1…}, {comfort:1…}>StateOfMind  
<{distrust:2…}, {trust:3…}>TraitAttribute  
<{decrease:2… }, {increase:3…}>QuantityChange  

In the following, if not otherwise specified, by 
S-factors we mean typed S-factors. Unless there is 
ambiguity, the type of an S-factor will be omitted. 

Definition 7: A synset Si with the type L is n-
scoped relative to a typed S-factor <Sα, Sβ> if L is 
a node in a sub-tree of the SUMO/MILO hierarchy 
having as root the n-semantic type of the S-factor 
<Sα, Sβ>. We say that n defines the level of the 
scope coverage of the S-factor <Sα, Sβ> and that 
every synset in this coverage is n-scoped. 

We use the notation SCOVn<Sα, Sβ> for the 
scope coverage of level n of an S-factor <Sα, Sβ>. 
If the root of the tree has the semantic type γ, we 
will use also use the notation SCOVn<Sα, Sβ>γ or 
simply SCOV<Sα, Sβ>γ. In other words, 
SCOV<Sα, Sβ>γ is the set of synsets the semantic 
types of which are subsumed by γ. For the example 
in Fig. 1, only the synsets Sα1, Sα2 and Sβ1 are in the 
SCOV0<Sα, Sβ>. All depicted synsets are in 
SCOV1<Sα, Sβ>.  

It is easy to see that when the value of the scope 
coverage level is increased so as to reach the top of 
the ontology, SCOVn<Sα, Sβ>γ will be equal to the 
set of synsets containing the literals in LUC (see 
Table 1).  Let us call this set SUC (Synset 
Unrestricted Coverage). 

 
 

Class S-Factors SUC 
Adjectives  264 4,240 (23.35%) 
Nouns  118 11,704 (14.25%) 
Verbs  246  8,640 (62.75%) 
Adverbs 264 1,284 (35.45%) 

Table 2: SUC Statistics According to the POS of 
the Synsets in PWN 3.0  

From the differential semantics point of view, 
the S-factor <Sα, Sβ> quantitatively characterizes 
each synset in SCOVn<Sα, Sβ> by a TRI

*-like 
score (Definition 4). The synsets in SCOV0<Sα, 
Sβ> are best discriminated, meaning that their 
scores for the <Sα, Sβ> factor are the highest. For 
the synsets in SCOVn<Sα, Sβ> but not in SCOVn-
1<Sα, Sβ>, the scores are smaller and we say that 
the characterization of these synsets in terms of the 
<Sα, Sβ> factor is weaker. Our model captures this 
through a slight modification of the TRI function 
in Definition 3, where wα and wβ are the antonyms 
belonging to Sα and Sβ respectively, and wi is a 
literal of a synset Sj in SCOVn<Sα, Sβ> but not in 
SCOVn-1<Sα, Sβ>: 

Definition 8: The differential score for a literal 
wi occurring in a synset Sj in SCOVn<Sα, Sβ> but 
not in SCOVn-1<Sα, Sβ> is computed by the 
function TRI+: 

    
,(

,(- ,(
),,(

n)wwMPL

)wwMPL)wwMPL
SSwTRI iii +

=+
βα

βα
βα

 
Since we imposed the requirement that Sj be in 

SCOVn<Sα, Sβ>, ),,( βα SSwTRI i
+  is defined for 

all literals in Sj, thus for any ji Sw ∈ the value of 
),,( βα SSwTRI i

+ is in the [-1,1] interval. The 

scores computed for the synsets in SCOVn<Sα, Sβ> 
remained unchanged in SCOVn+k<Sα, Sβ> for any  
k≥0. The above modification of the TRI function 
insures that the score of a synset gets closer to zero 
(neutrality) with the increase of n.  

It is worth mentioning that using different 
antonymic literal pairs from the same opposed 
synsets does not have any impact on the sign of 
TRI+ scores, but their absolute values may differ.  

If one associates a semantic field with γ, the 
type of an S-factor <Sα, Sβ>, then all the synsets in 
SCOVn<Sα, Sβ>γ are supposed to belong to the 
semantic field associated with γ. This observation 
should clarify why different senses of a given word 

22



may belong to different semantic coverages and 
thus, may have different scores for the S-factor in 
case. 

Definition 9: The differential score of a synset 
Si in SCOVn<Sα, Sβ> with respect to the S-factor 
<Sα, Sβ> is given by the function TRIS (Si, Sα, Sβ), 
defined as the average of the TRI+ values 
associated with the m literals in the synset Si. 

m

SSwTRI

SSSTRIS

m

j
j

i

∑
=

+

= 1
),,(

),,(

βα

βα
 

4 Computing the S-Factors and the 
Differential Scores for Synsets 

In accordance with the equations in the previous 
definitions, we associated each synset Sk of 
WordNet 3.0 with an ordered vector <F1, F2… Fn> 
where Fi is a pair (score; level) with score and 
level representing the value of the ith S-factor and, 
respectively, the minimal S-factor coverage level 
in which Sk was found.  

For instance, let us assume that the first S-factor 
in the description of the adjectival synsets is:  
<{nice:3},{nasty:2 …}>SubjectiveAssesmentAtttribute 
then for the synset {fussy:1, crabby:1, grumpy:1, 
cross:2, grouchy:1, crabbed:1, bad-tempered:1, 
ill-tempered:1}SubjectiveAssesmentAtttribute the vector 
<F1,…> is <(0,66;0) ...> while for the synset 
{unplayful:1 serious:5 sober:4}SubjectiveAssesmentAtttribute 
the vector <F1,…> is    <(-0,166 ; 0) ...>. 

The values signify that the synset {fussy:1, 
crabby:1, grumpy:1, cross:2…}SubjectiveAssesment 
Atttribute is 0-scoped with respect to the S-factor 
<{nice:3}, {nasty:2 …}> and its connotative 
meaning is significantly closer to the meaning of 
nasty:2 (0,66). Similarly, the synset {unplayful:1 
serious:5 sober:4} is 0-scoped with respect to the 
considered  S-factor and its connotative meaning is 
closer to the meaning of nice:3 (-0,166) 

Our experiments showed that in order to ensure 
the same sets of synsets for all factors of a given 
part-of-speech we had to set the level of the 
semantic coverages to 7 (corresponding to the 
SUC). For each of the typed S-factors <Sα, Sβ> and 
for each synset Si in their respective semantic 
coverage SCOV<Sα, Sβ>γ we computed the 
TRIS��� , �α, �β�  score. Each synset from the 
coverage of each POS category was associated 
with a vector of scores, as described above. Since 

the number of S-factors depends on the POS 
category the lengths of each of the four type 
vectors is different. The cell values in a synset 
vector have uneven values, showing that factors 
have different discriminative power for a given 
meaning. Because we considered SUC, all S-
factors are relevant and the cells in any synset 
vector are filled with pairs (score; level).  

For the noun part of the PW3.0 we identified 
118 typed S-factors, all of them covering the same 
set of 11,898 noun literals (9.99%) with their 
senses clustered into 11,704 synsets (14.25%).  

For the verb part of the PWN 3.0, we identified 
246 typed S-factors, all of them covering the same 
set of 6,524 verb literals (56.57%) with their senses 
clustered into 8,640 synsets (62.75%).  

For the adjective part of the PWN 3.0, we 
identified 264 typed S-factors, all of them covering 
the same set of 4,383 literals (20.35%) with their 
senses clustered into 4,240 synsets (23.35%)5. As 
previously mentioned, the same factors were used 
for the adverbs derived from adjectives. In this 
way, a total of 1,287 adverbs (28.72%) clustered 
into 1,284 synsets (35.45%) were successfully 
annotated (see Table 2). 

Apparently, the cardinals of the factor sets in 
Table 2 should be identical with those in Table 1. 
The differences are due to the fact that a pair of 
opposed synsets may contain more than a single 
pair of antonymic senses each of them specifying a 
distinct S-factor. 

In case the user restricted the coverages to lower 
levels, the original maximal semantic coverages 
are split into different subsets for which several S-
factors become irrelevant. The cell values 
corresponding to these factors are filled in with a 
conventional value outside the interval [-1, 1].  

Thus, we have the following annotation cases: 
A synset of a certain POS is not in the 

corresponding SUC. This case signifies that the 
synset cannot be characterized in terms of the 
differential semantics methodology and we 
conventionally say that such a synset is “objective” 
(insensitive to any S-factor). Since this situation 
would require a factor vector with each cell having 
the same value (outside the [-1, 1] interval) and as 
                                                           
5 In PWN 2.0 the number of covered literals (and synsets) is 
with almost 20% higher (Tufiş and Ştefănescu, 2010). This 
difference is explained by the fact that 1081 adjectives (5%), 
mostly participial, from PWN 2.0 are not any more listed as 
adjectives in PWN 3.0.   

23



such a vector would be completely uninformative, 
we decided to leave the “objective” synsets un-
annotated. As one can deduce from Table 2, the 
majority of the synsets in PWN3.0 are in this 
category (89,556 synsets, i.e. 77.58%). 

 Any synset of a certain POS in the 
corresponding SUC will have an associated factor 
vector. There are 25,868 such synsets. The ith cell 
of such a vector will correspond to the ith S-factor 
<Sα, Sβ>. We may have the following sub-cases: 

(a) All cell scores are in the [-1,1] interval, and 
in this case all S-factors are relevant, that is, from 
any word in the synset one could construct a path 
to both words prompting an S-factor, irrespective 
of the S-factor itself. A negative score in the ith cell 
of the S-factor vector signifies that the current 
synset is more semantically related to Sα than to Sβ, 
while a positive score in the ith cell of the factor 
vector signifies that the synset is more 
semantically related to Sβ than to Sα. A zero score 
in the ith cell of the factor vector signifies that the 
synset is neutral with respect to the <Sα, Sβ> S-
factor. 

(b) Several cell scores are not in the interval [-1, 
1], say FV[i1]=FV[i2] … =FV[ik]=2. This signifies 
that the S-factors corresponding to those cells 
(<Sα1,Sβ1>,<Sα2,Sβ2>,…,<Sα3,Sβ3>) are irrelevant 
for the respective synset and that the current synset 
is not included in the scope of the above-
mentioned S-factors, owing to the selected scope 
level of the coverage6. We say that, at the given 
scope level, the synset became “objective” with 
respect to the S-factors FV[i1], FV[i2] …FV[ik]. 

There are various ways to select, for a given 
POS coverage, those S-factors which are most 
informative or more interesting from a specific 
point of view. The simplest criterion is based on 
the coverage level: for a specified coverage level, 
select only those S-factors the coverage of which 
contains the analyzed synsets. In general, the most 
restrictive condition is choosing the 0-level 
coverage. This condition is equivalent to saying 
that the S-factors and the analyzed synsets should 
be in the same semantic class as defined by the 
SUMO/MILO labeling.  For instance, assume that 
the synset under investigation is {good:1} with the 

                                                           
6 Remember that for the highest level (7) that corresponds to 
SUC, all factors are relevant. When the user selects coverages 
of lower levels some factors might become irrelevant for 
various synsets. 

definition “having desirable or positive qualities 
especially those suitable for a thing specified” and 
the semantic type SubjectiveAssessmentAttribute.  
Imposing the restriction that the semantic type of 
the selected factors should be the same with the 
semantic type of good:1, some relevant factors for 
estimating the various connotations of “good” from 
different perspectives are given below. In the 
shown factors, the words in bold face are those the 
meaning of which is closer to “good”. 
 
good 01123148-a (SubjectiveAssessmentAttribute) 
-------------------------------------------------------------- 
effective ineffective#00834198-a_00835609-a 
(SubjectiveAssessmentAttribute) -0,78 
reasonable unreasonable#01943406-a_01944660-a 
(SubjectiveAssessmentAttribute) -0,71 
rich lean#02026785-a_02027003-a 
(SubjectiveAssessmentAttribute) -0,63 
ample meager#00105746-a_00106456-a 
(SubjectiveAssessmentAttribute) -0,5 
safe dangerous#02057829-a_02058794-a 
(SubjectiveAssessmentAttribute) -0,33 
brave cowardly#00262792-a_00264776-a 
(SubjectiveAssessmentAttribute) -0,14 
distant close#00450606-a_00451510-a 
(SubjectiveAssessmentAttribute) 0,64 
busy idle#00292937-a_00294175-a 
(SubjectiveAssessmentAttribute) 0,63 
cursed blessed#00669478-a_00670741-a 
(SubjectiveAssessmentAttribute) 0,5 
old new#01638438-a_01640850-a 
(SubjectiveAssessmentAttribute) 0,45 
formal informal#01041916-a_01044240-a 
(SubjectiveAssessmentAttribute) 0,38 
 

These factors’ values should be clearer in the 
context of adequate examples: 
A good tool is an effective tool; 
A good excuse is a reasonable excuse; 
A good vein of copper is a reach vein of copper; 
A good resource is an ample resource; 
A good position is a safe position; 
A good attitude is a close attitude; 
A good soldier is a brave soldier 
A good time is an idle time; 
A good life is a blessed life; 
A good car is a new car; 
A good party is an informal party.  
 

From the definitions in the previous sections, 
one can easily see that the sign of a S-factor score 
depends on the order in which the semantically 
opposite pairs are considered. If one wishes to 
have a consistent interpretation of the factor scores 
(e.g. negative scores are “bad” and positive scores 
are “good”) the synset ordering in the S-factors is 

24



significant. We used a default ordering of 
antonyms in all factors, yet a text analyst could 
modify this ordering. For each POS, we selected a 
representative factor for which the synset order, 
from a subjective point of view, was very intuitive. 
For instance, for the adjective factors we selected 
the factor <good:1, bad:1>, for noun factors we 
selected the factor <order:5, disorder:2>, and for 
verb factors we selected the factor <succeed:1, 
fail:2>, the first word sense in each of the 
representative factors having a clear positive 
connotation. Then for each POS factor <Sα, Sβ> we 
computed the distance of its constituents to the 
synsets of the representative factor of the same 
POS. The one that was closer to the “positive” side 
of the reference factor was also considered 
“positive” and the order of the synsets was 
established accordingly. This empirical approach 
proved to be successful for most of the factors, 
except for a couple of them, which were manually 
ordered. 

We developed an application that allows text 
analysts to choose the S-factors they would like to 
work with. The interface allows the user to both 
select/deselect factors and to switch the order of 
the poles in any given factor.  Once the user 
decided on the relevant S-factors, the synsets are 
marked up according to the selected S-factors. This 
version of the WordNet can be saved and used as 
needed in the planned application. 

5 Extending the LUCs and SUCs  

Although the maximum semantic coverage of the 
S-factors for the adjectives contains more than 
28% of the PWN3.0 adjectival synsets, many 
adjectives with connotative potential are not in this 
coverage. This happens because the definition of 
the relatedness (Definition 1) implicitly assumes 
the existence of synonyms for one or more senses 
of a given word. Therefore from mono-semantic 
words in mono-literal synsets a path towards other 
synsets cannot be constructed anymore. Because of 
this, there are isolated “bubbles” of related synsets 
that are not connected with synsets in maximum 
semantic coverage. In order to assign values to at 
least a part of these synsets, we experimented with 
various strategies out of which the one described 
herein was considered the easiest to implement 
and, to some extent motivated, from a conceptual 
point of view. The approach is similar for all the 

synsets which are not in the SUCs, but the 
algorithms for extending these coverages slightly 
differ depending on the part of speech under 
consideration.  

Class E-LUCs E-SUCs 

Adjectives  7,124 (33.07%) 6,216 (34.23%) 

Nouns  27,614 (23.19%) 22,897 (27.88%) 

Verbs  8,910 (77.26%) 10,798 (78.43%) 

Adverbs 1,838 (41.01%) 1,787 (49.35%) 

Table 3: Extended LUCs and SUCs 

The basic idea is to transfer the vectors of the 
synsets in SUC to those in the complementary set 

SUC , provided they have “similar meanings”. We 

say that POS
POS
i SUCS ∈  and POSPOSj SUCS ∈  

have “similar meanings” if ��
�/
���(�����) =
��
�/
���(�����)  and �����  and �����  are 
directly linked by a semantic WordNet relation of a 
certain type. For adjectival synsets we consider the 
relations similar_to and also_see, for verbal 
synsets we consider the relations hyponym and 
also_see, and for the nominal synsets we take into 
account only the hyponymy. Consequently, the S-
factors coverage increased as shown in Table 3. 

6 A Preliminary Comparison with 
SentiWordnet 3.0  

SentiWordNet 3.0 (Baccianella, et al. 2010) is the 
only public resource we are aware of, which 
considers sense distinctions and covers all synsets 
in Princeton WordNet 3.0. Although in 
SentiWordNet (henceforth SWN3.0) only the 
Subjective-Objective dichotomy is marked-up, 
with a further distinction between Positive-
Subjectivity and Negative-Subjectivity, using it for 
the comparison with our annotations is meaningful 
and relevant for both approaches. First, the 
connotative meanings are subjective meanings.  
Then, while the SWN3.0 mark-up is based on ML 
techniques and various heuristics exploiting the 
structure of PWN3.0 and some other external 
resources, the differential semantics approach, as 
implemented here, is a deterministic one, 
considering only the content and structural 
information in PWN3.0 + SUMO/MILO. 
Identifying contradictions in the two annotations 
might reveal limitations in the ML techniques and 
heuristics used by SWN3.0 on one hand, and, on 

25



the other hand, flaws in our method, possible 
incompleteness or inconsistencies in PWN3.0+ 
SUMO/MILO. It has to be noted that the possible 
incompleteness or inconsistencies in PWN3.0 
would also affect the accuracy of the SWN3.0 
values. 

 

Synset SWN DSA Definition 
dangerous, 
grave 
grievous, 
serious, severe 
… 

-0,63 0,42 

causing fear or 
anxiety by threatening 
great harm 

live 
0,5 -0,5 

exerting force or 
containing energy 

bastardly, 
mean 

-0,5 0,5 
of no value or worth 

dangerous, 
unsafe -0,75 0,5 

involving or causing 
danger or risk; liable 
to hurt or harm 

delirious, 
excited,  
unrestrained,  
mad, 
frantic  

0,5 -0,5 

marked by un-
controlled excitement 
or emotion 

haunted 
0,5 -0,43 

showing emotional 
affliction or disquiet 

impeccable -0,63 0,8 not capable of sin 

evil, vicious 
0,5 -0,75 

having the nature of 
vice 

delectable, 
sexually 
attractive 

0,63 -0,5 
capable of arousing 
desire 

ordinary 
 

-0,5 0,75 

not exceptional in any 
way especially in 
quality or ability or 
size or degree 

serious 
 

-0,75 0,75 

requiring effort or 
concentration; 
complex and not easy 
to answer or solve 

excusable 
 

0,63 -0,4 
capable of being 
overlooked 

Table 4: Examples of divergent scores among the 
SWN3.0 and DSA 

For the partial comparison we selected the 
adjectives in SWN3.0 with Positive-Subjectivity or 
Negative-Subjectivity greater than or equal to 0.5. 
From our differential semantic (DSA) annotation 
we extracted all the adjectives which along the 
good-bad differential dimension had an absolute 
value greater than 0.4. Those adjectives closer to 
good were considered to be Subjective-Positive 
while the others were considered to be Subjective-
Negative. The threshold value was empirically 
selected, by observing that beyond the 0.4 and –0.4 
values the factorial annotation was closer to our 

intuition concerning the connotative load of the 
analyzed words. We computed the intersection of 
the two adjectival synsets extracted this way and 
retained only the synsets contradictorily annotated. 
We found only 150 differences, which by itself is a 
small difference, showing that, at least with respect 
to the good-bad factor, SWN3.0 and DSA 
annotations are to a large extent consistent. 

We manually checked-out the 150 synsets 
marked-up with contradictory scores and the 
authors and 6 MSc students negotiated the scores 
towards reaching the consensus. For 142 of these 
synsets the consensus was easily reached with 76 
considered to be correct in the DSA annotation and 
65 correct in the SWN3.0 annotation. Table 4 
shows some examples of synsets, the scores of 
which were correctly judged (in bold) either by 
SWN3.0 or DSA as well as some examples of non-
consensual annotations (in underlined italics). 

7 Conclusions  

Differential semantics annotation addresses the 
connotative meanings of the lexical stock, the 
denotative meanings of which are recorded in 
WordNet 3.0. We revised and improved our 
previous method (Tufiş and Ştefănescu, 2010). It 
generalizes the SWN3.0 subjectivity mark-up, 
according to a user-based multi-criteria differential 
semantics model.  

The partial comparison with SWN3.0 revealed 
specific limitations of our approach. The major one 
is due to the definitions of n-relatedness and the 
TRI relation. The problem resides in indiscriminate 
treatment of literals which have senses with 
different polarities with respect to a factor. If one 
of these senses is significantly closer to one of the 
poles of the factor, that sense might impose the 
sign for the rest of the senses. This risk is 
amplified when literals with high degrees of 
polysemy and/or high degrees of synonymy are 
reached on the way from the synset of interest to 
the synsets defining the S-factor (higher the 
polysemy/synonymy, higher the number of paths 
to the constituents of the S-factor). Most of the 
erroneous scores we noticed were explained by this 
drawback. We say that the words affected by this 
limitation of the current algorithm have a 
significant connotation shift potential (Tufiş, 
2009), (Ştefănescu, 2010). As such words could 
generate undesired implicatures, they should be 

26



avoided in formal texts and replaced by synonyms 
with less connotation shift potential.  

We also observed some inconsistencies 
regarding the association of SUMO/MILO (and the 
additional domain ontologies) concepts to PWN 
3.0 synsets. The semantic types of two opposable 
synsets (in the same semantic field) should be 
closely related, if not the same. However, for some 
S-factors, such as <agreement:3, disagreement:1> 
this does not happen. The semantic type of the 
synset {agreement:3…} is “Cooperation”, while 
the semantic type of {disagreement:1…} is 
“SubjectiveAssessmentAttribute”. “Cooperation” 
is a “Process” (subsumed by “Physical”) but, 
“SubjectiveAssessmentAttribute” is an “Attribute” 
(subsumed by “Abstract”). There are 9 such cases 
for nouns, 30 for verbs and 16 for adjectives. 

The current multi-factored annotation vectors 
for nominal, verbal, and adjectival synsets for 
PWN3.0, as well as an application to manage these 
annotations, can be freely downloaded from 
http://www.racai.ro/differentialsemantics/. 

Acknowledgments 

This research has been supported by the grant no. 
ID_1443, awarded by the Romanian Ministry for 
Education, Research, Youth and Sport. We thank 
also to SentiWordNet authors for making it public. 

References  

Andreevskaia Alina and Sabine Bergler. 2006. Mining 
WordNet for a fuzzy sentiment: Sentiment tag 
extraction from WordNet glosses. In Proceedings of 
the 11th Conference of the European Chapter of the 
Association for Computational Linguistics (EACL-
2006), Trento, Italy, pages 209–216.  

Stefano Baccianella, Andrea Esuli, and Fabrizio 
Sebastiani. 2010. SENTIWORDNET 3.0: An 
Enhanced Lexical Resource for Sentiment Analysis 
and Opinion Mining, in Proceedings of LREC2010, 
Malta, pp.2200-2204. 

Luisa Bentivogli, Pamela Forner, Bernardo Magnini, 
and Emanuele Pianta. 2004. Revising WordNet 
domains hierarchy: Semantics, coverage, and 
balancing. In Proceedings of COLING 2004 
Workshop on "Multilingual Linguistic Resources", 
Geneva, Switzerland, pages 101–108. 

Andrea Esuli, and Fabrizio Sebastiani. 2006. 
SENTIWORDNET: A publicly available lexical 
resource for opinion mining. In Proceedings of the 

5th Conference on Language Resources and 
Evaluation LREC-06, Genoa, Italy, pages 417–422. 
See also: http://sentiwordnet.isti.cnr.it/  

Christiane Fellbaum. 1998. WordNet: An Electronic 
Lexical Database. Academic Press, Cambridge, MA. 

Jaap Kamps and Maarten Marx. 2002. Words with 
attitude. In Proceedings of the 1st International 
WordNet Conference, Mysore, India, pages 332–341. 

Rada Mihalcea, Carmen Banea, and Janice Wiebe. 
2007. Learning multilingual subjective language via 
cross-lingual projections. In Proceedings of the 45th 
Annual Meeting of the Association of Computational 
Linguistics, Prague, Czech Republic, pages 976–983. 

Ian Niles and Adam Pease. 2003. Linking Lexicons and 
Ontologies: Mapping WordNet to the Suggested 
Upper Merged Ontology. In Proceedings of the 2003 
International Conference on Information and 
Knowledge Engineering (IKE 03), Las Vegas, pages 
23–26. 

Charles E. Osgood, George Suci and Percy 
Tannenbaum. 1957. The measurement of meaning, 
University of Illinois Press, Urbana IL. 

Bo Pang and Lillian Lee, 2008. Opinion mining and 
sentiment analysis. Foundations and Trends in 
Information Retrieval, 2(1–2): 1–135. 

Livia  Polanyi, and Annie Zaenen. 2006. Contextual 
valence shifters. In J. G. Shanahan, Y. Qu and J. 
Wiebe, editors, Computing Attitude and Affect in 
Text: Theory and Applications, The Information 
Retrieval Series, Vol. 20, Springer Verlag, 
Dordrecht, Netherlands, pages 1-10. 

Dan Ştefănescu. 2010. Intelligent Information Mining 
from Multilingual Corpora (in Romanian). PhD 
Thesis, Romanian Academy, Bucharest. 

Dan Tufiş. 2008. Mind your words! You might convey 
what you wouldn’t like to. Int. J. of Computers, 
Communications & Control, III, pages 139–143. 

Dan Tufiş. 2009. Playing with word meanings,.In Lotfi 
A. Zadeh, Dan Tufiş, Florin Gh. Filip and Ioan 
Dziţac, (editors) From Natural Language to Soft 
Computing: New Paradigms in Artificial 
Intelligence. Publishing House of the Romanian 
Academy, Bucharest, pages 211–223. 

Dan Tufiş, Dan Ştefănescu. 2010. A Differential 
Semantics Approach to the Annotation of the Synsets 
in WordNet. In Proceedings of LREC 2010, Malta, 
pages 3173-3180 

Alessandro Valitutti, Carlo Strapparava, and Oliviero 
Stock. 2004. Developing affective lexical resources, 
Psychology Journal, 2(1), pages 61–83. 

27


