



















































Opinion Mining and Topic Categorization with Novel Term Weighting


Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 84â€“89,
Baltimore, Maryland, USA. June 27, 2014. cÂ©2014 Association for Computational Linguistics

Opinion Mining and Topic Categorization with Novel Term Weighting 

 
 

Tatiana Gasanova 
Institute of Communications Engineer-

ing, Ulm University, Germany 
tatiana.gasanova@uni-

ulm.de 

Roman Sergienko 
Institute of Communications Engineer-

ing, Ulm University, Germany 
roman.sergienko@uni-ulm.de 

Shakhnaz Akhmedova 
Institute of Computer Science and 

Telecommunications, Siberian State 
Aerospace University, Russia 
shahnaz@inbox.ru  

Eugene Semenkin 
Institute of Computer Science and 

Telecommunications, Siberian State 
Aerospace University, Russia 

eugenesemenkin@yandex.com 

Wolfgang Minker 
Institute of Communications Engineer-

ing, Ulm University, Germany 
wolfgang.minker@uni-ulm.de 

 

  
 

 
 

Abstract 

In this paper we investigate the efficiency of 
the novel term weighting algorithm for opin-
ion mining and topic categorization of arti-
cles from newspapers and Internet. We com-
pare the novel term weighting technique with 
existing approaches such as TF-IDF and 
ConfWeight. The performance on the data 
from the text-mining campaigns DEFTâ€™07 
and DEFTâ€™08 shows that the proposed meth-
od can compete with existing information re-
trieval models in classification quality and 
that it is computationally faster. The pro-
posed text preprocessing method can be ap-
plied in large-scale information retrieval and 
data mining problems and it can be easily 
transported to different domains and different 
languages since it does not require any do-
main-related or linguistic information. 

1 Introduction 
Nowadays, Internet and social media generate a 
huge amount of textual information. It is in-
creasingly important to develop methods of text 
processing such as text classification. Text clas-
sification is very important for such problems 
as automatic opining mining (sentiment analy-
sis) and topic categorization of different articles 
from newspapers and Internet. 

Text classification can be considered to be a 
part of natural language understanding, where 
there is a set of predefined categories and the 
task is to automatically assign new documents 
to one of these categories. The method of text 
preprocessing and text representation influences 
the results that are obtained even with the same 
classification algorithms.  

The most popular model for text classifica-
tion is vector space model. In this case text cat-
egorization may be considered as a machine 
learning problem. Complexity of text categori-
zation with vector space model is compounded 
by the need to extract the numerical data from 
text information before applying machine learn-
ing methods. Therefore text categorization con-
sists of two parts: text preprocessing and classi-
fication using obtained numerical data. 

All text preprocessing methods are based on 
the idea that the category of the document de-
pends on the words or phrases from this docu-
ment. The simplest approach is to take each 
word of the document as a binary coordinate 
and the dimension of the feature space will be 
the number of words in our dictionary.  

There exist more advanced approaches for 
text preprocessing to overcome this problem 
such as TF-IDF (Salton and Buckley, 1988) and 
ConfWeight methods (Soucy and Mineau, 
2005). A novel term weighting method (Gasa-
nova et al., 2013) is also considered, which has 

84



some similarities with the ConfWeight method, 
but has improved computational efficiency. It is 
important to notice that we use no morphologi-
cal or stop-word filtering before text prepro-
cessing. It means that the text preprocessing can 
be performed without expert or linguistic 
knowledge and that the text preprocessing is 
language-independent. 

In this paper we have used k-nearest neigh-
bors algorithm, Bayes Classifier, support vector 
machine (SVM) generated and optimized with 
COBRA (Co-Operation of Biology Related Al-
gorithms) which has been proposed by 
Akhmedova and Semenkin (2013), Rocchio 
Classifier or Nearest Centroid Algorithm (Roc-
chio, 1971) and Neural Network as classifica-
tion methods. RapidMiner and Microsoft Visual 
Studio C++ 2010 have been used as implemen-
tation software. 

For the application of algorithms and com-
parison of the results we have used the DEFT 
(â€œDÃ©fi Fouille de Texteâ€) Evaluation Package 
2008 (Proceedings of the 4th DEFT Workshop, 
2008) which has been provided by ELRA and 
publically available corpora from DEFTâ€™07 
(Proceedings of the 3rd DEFT Workshop, 
2007).  

The main aim of this work is to evaluate the 
competitiveness of the novel term weighting 
(Gasanova et al., 2013) in comparison with the 
state-of-the-art techniques for opining mining 
and topic categorization. The criteria using in 
the evaluation are classification quality and 
computational efficiency. 

This paper is organized as follows: in Section 
2, we describe details of the corpora. Section 3 
presents text preprocessing methods. In Section 
4 we describe the classification algorithms 
which we have used to compare different text 
preprocessing techniques. Section 5 reports on 
the experimental results. Finally, we provide 
concluding remarks in Section 6. 

2 Corpora Description 
The focus of DEFT 2007 campaign is the sen-
timent analysis, also called opinion mining. We 
have used 3 publically available corpora: re-
views on books and movies (Books), reviews on 
video games (Games) and political debates 
about energy project (Debates). 

The topic of DEFT 2008 edition is related to 
the text classification by categories and genres. 
The data consists of two corpora (T1 and T2) 
containing articles of two genres: articles ex-

tracted from French daily newspaper Le Monde 
and encyclopedic articles from Wikipedia in 
French language. This paper reports on the re-
sults obtained using both tasks of the campaign 
and focuses on detecting the category. 
 
Corpus Size Classes 

Books Train size = 2074 
Test size = 1386 
Vocabulary = 52507 

0: negative,  
1: neutral,  
2: positive 

Games Train size = 2537 
Test size = 1694 
Vocabulary = 63144 

0: negative,  
1: neutral,  
2: positive 

Debates Train size = 17299 
Test size = 11533 
Vocabulary = 59615 

0: against,  
1: for 

Table 1. Corpora description (DEFTâ€™07) 
 

Corpus Size Classes 
T1 Train size = 15223 

Test size = 10596 
Vocabulary = 202979 

0: Sport,  
1: Economy,  
2: Art, 
3: Television 

T2 Train size = 23550 
Test size = 15693 
Vocabulary = 262400 

0: France,  
1: International,  
2: Literature, 
3: Science, 
4: Society 

Table 2. Corpora description (DEFTâ€™08) 
 

All databases are divided into a training 
(60% of the whole number of articles) and a test 
set (40%). To apply our algorithms we extract-
ed all words which appear in the training set 
regardless of the letter case and we also exclud-
ed dots, commas and other punctual signs. We 
have not used any additional filtering as exclud-
ing the stop or ignore words. 

3 Text Preprocessing Methods 

3.1 Binary preprocessing 
We take each word of the document as a binary 
coordinate and the size of the feature space will 
be the size of our vocabulary (â€œbag of wordsâ€). 

3.2 TF-IDF 
TF-IDF is a well-known approach for text pre-
processing based on multiplication of term fre-
quency tfij (ratio between the number of times 
the ith word occurs in the jth document and the 
document size) and inverse document frequen-
cy idfi. 
 ğ‘¡ğ‘“ğ‘–ğ‘— =

ğ‘¡ğ‘–ğ‘—
ğ‘‡ğ‘—

,  (1) 

   

85



where tij is the number of times the ith word oc-
curs in the jth document. Tj is the document size 
(number of the words in the document). 

There are different ways to calculate the 
weight of each word. In this paper we run clas-
sification algorithms with the following vari-
ants. 

1) TF-IDF 1 
 ğ‘–ğ‘‘ğ‘“ğ‘– = ğ‘™ğ‘œğ‘”

|ğ·|
ğ‘›ğ‘–

, (2) 

where |D| is the number of document in the 
training set and ğ‘›ğ‘– is the number of documents 
that have the ith word. 

2) TF-IDF 2 
The formula is given by equation (2) except 

ğ‘›ğ‘–  is calculated as the number of times ith word 
appears in all documents from the training set. 

3) TF-IDF 3 
 ğ‘–ğ‘‘ğ‘“ğ‘– = ï¿½

|ğ·|
ğ‘›ğ‘–
ï¿½
ğ›¼

,ğ›¼ âˆˆ (0,1), (3) 

where ğ‘›ğ‘– is calculated as in TF-IDF 1 and Î± is 
the parameter (in this paper we have tested Î± = 
0.1, 0.5, 0.9). 

4) TF-IDF 4 
The formula is given by equation (3) except 

ğ‘›ğ‘–  is calculated as in TF-IDF 4. 

3.3 ConfWeight 
Maximum Strength (Maxstr) is an alternative 
method to find the word weights. This approach 
has been proposed by Soucy and Mineau 
(2005). It implicitly does feature selection since 
all frequent words have zero weights. The main 
idea of the method is that the feature f has a 
non-zero weight in class c only if the f frequen-
cy in documents of the c class is greater than 
the f frequency in all other classes. 

The ConfWeight method uses Maxstr as an 
analog of IDF: 
ğ¶ğ‘œğ‘›ğ‘“ğ‘Šğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘–ğ‘— = ğ‘™ğ‘œğ‘”ï¿½ğ‘¡ğ‘“ğ‘–ğ‘— + 1ï¿½ âˆ— ğ‘€ğ‘ğ‘¥ğ‘ ğ‘¡ğ‘Ÿ(ğ‘–). 

Numerical experiments (Soucy and Mineau, 
2005) have shown that the ConfWeight method 
could be more effective than TF-IDF with SVM 
and k-NN as classification methods. The main 
drawback of the ConfWeight method is compu-
tational complexity. This method is more com-
putationally demanding than TF-IDF method 
because the ConfWeight method requires time-
consuming statistical calculations such as Stu-
dent distribution calculation and confidence 
interval definition for each word. 

3.4 Novel Term Weighting (TW) 
The main idea of the method (Gasanova et al., 
2013) is similar to ConfWeight but it is not so 

time-consuming. The idea is that every word 
that appears in the article has to contribute 
some value to the certain class and the class 
with the biggest value we define as a winner for 
this article. 

For each term we assign a real number term 
relevance that depends on the frequency in ut-
terances. Term weight is calculated using a 
modified formula of fuzzy rules relevance esti-
mation for fuzzy classifiers (Ishibuchi et al., 
1999). Membership function has been replaced 
by word frequency in the current class. The de-
tails of the procedure are the following: 

Let L be the number of classes; ni is the 
number of articles which belong to the ith class; 
Nij is the number of the jth word occurrence in 
all articles from the ith class; Tij = Nij / ni is the 
relative frequency of the jth word occurrence in 
the ith class. 
ğ‘…ğ‘— = maxğ‘– ğ‘‡ğ‘–ğ‘— , ğ‘†ğ‘— = arg (maxğ‘– ğ‘‡ğ‘–ğ‘—) is the 

number of class which we assign to the jth word; 
The term relevance, Cj, is given by 

 
).

1
1(1

1

1

âˆ‘
âˆ‘ â‰ =
=

âˆ’
âˆ’=

L

Si
i

ijjL

i
ji

j

j

T
L

R
T

C  
(4) 

Cj is higher if the word occurs more often in 
one class than if it appears in many classes. We 
use novel TW as an analog of IDF for text pre-
processing. 

The learning phase consists of counting the C 
values for each term; it means that this 
algorithm uses the statistical information 
obtained from the training set.  

4 Classification Methods 
We have considered 11 different text prepro-
cessing methods (4 modifications of TF-IDF, 
two of them with three different values of Î± 
parameter, binary representation, ConfWeight 
and the novel TW method) and compared them 
using different classification algorithms. The 
methods have been implemented using 
RapidMiner (Shafait, 2010) and Microsoft Vis-
ual Studio C++ 2010 for Rocchio classifier and 
SVM. The classification methods are: 

- k-nearest neighbors algorithm with dis-
tance weighting (we have varied k from 1 to 
15); 

- kernel Bayes classifier with Laplace cor-
rection; 

- neural network with error back propaga-
tion (standard setting in RapidMiner); 

- Rocchio classifier with different metrics 
and Î³ parameter; 

86



- support vector machine (SVM) generated 
and optimized with Co-Operation of Biology 
Related Algorithms (COBRA). 

Rocchio classifier (Rocchio, 1971) is a well-
known classifier based on the search of the 
nearest centroid. For each category we calculate 
a weighted centroid: 

ğ‘”ğ‘ =
1

|ğ‘£ğ‘|
âˆ‘ ğ‘‘ âˆ’ ğ›¾ 1

ï¿½ğ‘£ğ‘,ğ‘˜ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ğ‘‘âˆˆğ‘£ğ‘
âˆ‘ ğ‘‘ğ‘‘âˆˆğ‘£ğ‘,ğ‘˜ , 

where ğ‘£ğ‘ is a set of documents which belong to 
the class c; ğ‘£ğ‘,ğ‘˜ï¿½ï¿½ï¿½ï¿½ï¿½ are k documents which do not 
belong to the class c and which are close to the 
centroid 1|ğ‘£ğ‘|

âˆ‘ ğ‘‘;ğ‘‘âˆˆğ‘£ğ‘ ğ›¾ is parameter corresponds 
to relative importance of negative precedents. 
The given document is put to the class with the 
nearest centroid. In this work we have applied 
Rocchio classifier with ğ›¾ âˆˆ (0.1; 0.9) and with 
three different metrics: taxicab distance, 
Euclidean metric and cosine similarity. 

COBRA is a new meta-heuristic algorithm 
which has been proposed by Akhmedova and 
Semenkin (2013). It is based on cooperation of 
biology inspired algorithms such as Particle 
Swarm Optimization (Kennedy and Eberhart, 
1995), Wolf Pack Search Algorithm (Yang, 
2007), Firefly Algorithm (Yang, 2008), Cuckoo 
Search Algorithm (Yang and Deb, 2009) and 
Bat Algorithm (Yang, 2010). For generating 
SVM-machine the original COBRA is used: 
each individual in all populations represents a 
set of kernel functionâ€™s parameters .,, dÎ²Î±  
Then for each individual constrained modifica-
tion of COBRA is applied for finding vector w 
and shift factor b. And finally individual that 
showed the best classification rate is chosen as 
the designed classifier. 

5 Experimental Results 
The DEFT (â€œDÃ©fi Fouille de Texteâ€) Evaluation 
Package 2008 and publically available corpora 
from DEFTâ€™07 (Books, Games and Debates) 
have been used for algorithms application and 
results comparison. In order to evaluate ob-
tained results with the campaign participants we 
have to use the same measure of classification 
quality: precision, recall and F-score. 

Precision for each class i is calculated as the 
number of correctly classified articles for class i 
divided by the number of all articles which al-
gorithm assigned for this class. Recall is the 
number of correctly classified articles for class i 
divided by the number of articles that should 
have been in this class. Overall precision and 
recall are calculated as the arithmetic mean of 

the precisions and recalls for all classes (macro-
average). F-score is calculated as the harmonic 
mean of precision and recall. 

Tables 3-7 present the F-scores obtained on 
the test corpora. The best values for each prob-
lem are shown in bold. Results of the all classi-
fication algorithms are presented with the best 
parameters. We also present for each corpus 
only the best TF-IDF modification.  

 
Classification 
algorithm 

Binary  TF-
IDF 

Conf 
Weight 

Novel 
TW 

Bayes 0.489 0.506 0.238 0.437 
k-NN 0.488  0.517 0.559 0.488 
Rocchio 0.479  0.498 0.557 0.537 
SVM (CO-
BRA) 

0.558  0.580 0.588 0.619 

Neural network 0.475  0.505 0.570 0.493 
Table 3. Classification results for Books 

 
Classification 
algorithm 

Binary  TF-
IDF 

Conf 
Weight 

Novel 
TW 

Bayes 0.653  0.652 0.210 0.675 
k-NN 0.703  0.701 0.720 0.700 
Rocchio 0.659  0.678 0.717 0.712 
SVM (CO-
BRA) 

0.682  0.687 0.645 0.696 

Neural network 0.701  0.679 0.717 0.691 
Table 4. Classification results for Games 

 
Classification 
algorithm 

Binary  TF-
IDF 

Conf 
Weight 

Novel 
TW 

Bayes 0.555  0.645 0.363 0.616 
k-NN 0.645  0.648 0.695 0.695 
Rocchio 0.636  0.646 0.697 0.696 
SVM (CO-
BRA) 

0.673  0.669 0.714 0.700 

Neural network 0.656  0.647 0.705 0.697 
Table 5. Classification results for Debates 
 

Classification 
algorithm 

Binary  TF-
IDF 

Conf 
Weight 

Novel 
TW 

Bayes 0.501  0.690 0.837 0.794 
k-NN 0.800  0.816 0.855 0.837 
Rocchio 0.794  0.825 0.853 0.838 
SVM (CO-
BRA) 

0.788  0.827 0.840 0.856 

Neural network 0.783  0.830 0.853 0.854 
Table 6. Classification results for T1 

 
Classification 
algorithm 

Binary  TF-
IDF 

Conf 
Weight 

Novel 
TW 

Bayes 0.569  0.728 0.712 0.746 
k-NN 0.728  0.786 0.785 0.811 
Rocchio 0.765  0.825 0.803 0.834 
SVM (CO-
BRA) 

0.794  0.837 0.813 0.851 

Neural network 0.799  0.838 0.820 0.843 
Table 7. Classification results for T2 

 

87



We can see from the Tables 3-7 that the best 
F-scores have been obtained with either 
ConfWeight or novel Term Weighting prepro-
cessing. The algorithm performances on the 
Games and Debates corpora achieved the best 
results with ConfWeight; however, we can see 
that the F-scores obtained with novel Term 
Weighting preprocessing are very similar 
(0.712 and 0.720 for Games; 0.700 and 0.714 
for Debates). Almost all best results have been 
obtained with SVM except the Games database 
where we achieved the highest F-score with k-
NN algorithm. 

This paper focuses on the text preprocessing 
methods which do not require language or do-
main-related information; therefore, we have 
not tried to achieve the best possible classifica-
tion quality. However, the result obtained on 
Books corpus with novel TW preprocessing and 
SVM (generated using COBRA) as classifica-
tion algorithm has reached 0.619 F-score which 
is higher than the best known performance 
0.603 (Proceedings of the 3rd DEFT Workshop, 
2007). Performances on other corpora have 
achieved close F-score values to the best sub-
missions of the DEFTâ€™07 and DEFTâ€™08 partici-
pants. 

We have also measured computational effi-
ciency of each text preprocessing technique. 
We have run each method 20 times using the 
Baden-WÃ¼rttemberg Grid (bwGRiD) Cluster 
Ulm (Every blade comprehends two 4-Core 
Intel Harpertown CPUs with 2.83 GHz and 16 
GByte RAM). After that we calculated average 
values and checked statistical significance of 
the results. 

Figure 1 and Figure 2 compare average com-
putational time in minutes for different prepro-
cessing methods applied on DEFTâ€™07 and 
DEFTâ€™08 corpora. 

 
Figure 1. Computational efficiency of text pre-

processing methods (DEFTâ€™07) 

 
Figure 2. Computational efficiency of text pre-

processing methods (DEFTâ€™08) 
 
The average value for all TF-IDF modifica-

tions is presented because the time variation for 
the modifications is not significant. 

We can see in Figure 1 and Figure 2 that TF-
IDF and novel TW require almost the same 
computational time. The most time-consuming 
method is ConfWeight (CW). It requires ap-
proximately six times more time than TF-IDF 
and novel TW for DEFTâ€™08 corpora and about 
three-four times more time than TF-IDF and 
novel TW for DEFTâ€™07 databases. 

6 Conclusion 
This paper reported on text classification exper-
iments on 5 different corpora of opinion mining 
and topic categorization using several classifi-
cation methods with different text prepro-
cessing. We have used â€œbag of wordsâ€, TF-IDF 
modifications, ConfWeight and the novel term 
weighting approach as preprocessing tech-
niques. K-nearest neighbors algorithms, Bayes 
classifier, Rocchio classifier, support vector 
machine trained by COBRA and Neural Net-
work have been applied as classification algo-
rithms.  

The novel term weighting method gives simi-
lar or better classification quality than the 
ConfWeight method but it requires the same 
amount of time as TF-IDF. Almost all best re-
sults have been obtained with SVM generated 
and optimized with Co-Operation of Biology 
Related Algorithms (COBRA). 

We can conclude that numerical experiments 
have shown computational and classification 
efficiency of the proposed method (the novel 
TW) in comparison with existing text prepro-
cessing techniques for opinion mining and topic 
categorization. 

88



References  
Akhmedova Sh. and Semenkin E. 2013. Co-

Operation of Biology Related Algorithms. Pro-
ceedings of the IEEE Congress on Evolutionary 
Computation (CEC 2013):2207-2214. 

Association FranÃ§aise dâ€™Intelligence Artificielle. 
2007. Proceedings of the 3rd DEFT Workshop. 
DEFT '07. AFIA, Grenoble, France. 

Gasanova T., Sergienko R., Minker W., Semenkin 
E. and Zhukov E. 2013. A Semi-supervised Ap-
proach for Natural Language Call Routing. Pro-
ceedings of the SIGDIAL 2013 Conference:344-
348. 

Ishibuchi H., Nakashima T., and Murata T. 1999. 
Performance evaluation of fuzzy classifier sys-
tems for multidimensional pattern classification 
problems. IEEE Trans. on Systems, Man, and Cy-
bernetics, 29:601-618. 

Kennedy J. and Eberhart R. 1995. Particle Swarm 
Optimization. Proceedings of IEEE International 
Conference on Neural Networks:1942-1948.   

Le traitement automatique du langage naturel ou de 
la langue naturelle. 2008. Proceedings of the 4th 
DEFT Workshop. DEFT '08. TALN, Avignon, 
France. 

Salton G. and Buckley C. 1988. Term-Weighting 
Approaches in Automatic Text Retrieval.  Infor-
mation Processing and Management:513-523. 

Shafait F., Reif M., Kofler C., and Breuel T. M. 
2010. Pattern Recognition Engineering. 
RapidMiner Community Meeting and Conference, 
9. 

Soucy P. and Mineau G.W. 2005. Beyond TFIDF 
Weighting for Text Categorization in the Vector 
Space Model. Proceedings of the 19th Interna-
tional Joint Conference on Artificial Intelligence 
(IJCAI 2005):1130-1135. 

Rocchio J. 1971. Relevance Feedback in Infor-
mation Retrieval. The SMART Retrieval System-
Experiments in Automatic Document Processing, 
Prentice-Hall:313-323. 

Yang Ch. 2007. Algorithm of Marriage in Honey 
Bees Optimization Based on the Wolf Pack 
Search. Proceedings of International Conference 
on Intelligent Pervasive Computing:462-467. 

Yang X.S. 2008. Nature-Inspired Metaheuristic Al-
gorithms. 

Yang X.S. and Deb S. 2009. Cuckoo search via 
Levy flights. Proceedings of World Congress on 
Nature & Biologically Inspired Computing:210-
214. 

Yang X.S. 2010. A New Metaheuristic Bat-Inspired 
Algorithm. Proceedings of Nature Inspired Co-

operative Strategies for Optimization (NISCO 
2010):65-74. 

 
 

 
 

89


