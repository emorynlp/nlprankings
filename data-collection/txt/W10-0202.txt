










































Emotion Detection in Email Customer Care


Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 10–16,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

Emotion Detection in Email Customer Care

Narendra Gupta, Mazin Gilbert, and Giuseppe Di Fabbrizio

AT&T Labs - Research, Inc.

Florham Park, NJ 07932 - USA

{ngupta,mazin,pino}@research.att.com

Abstract

Prompt and knowledgeable responses to cus-

tomers’ emails are critical in maximizing cus-

tomer satisfaction. Such emails often con-

tain complaints about unfair treatment due to

negligence, incompetence, rigid protocols, un-

friendly systems, and unresponsive personnel.

In this paper, we refer to these emails as emo-

tional emails. They provide valuable feedback

to improve contact center processes and cus-

tomer care, as well as, to enhance customer re-

tention. This paper describes a method for ex-

tracting salient features and identifying emo-

tional emails in customer care. Salient fea-

tures reflect customer frustration, dissatisfac-

tion with the business, and threats to either

leave, take legal action and/or report to au-

thorities. Compared to a baseline system us-

ing word ngrams, our proposed approach with

salient features resulted in a 20% absolute F-

measure improvement.

1 Introduction

Emails are becoming the preferred communication

channel for customer service. For customers, it is a

way to avoid long hold times on call centers phone

calls and to keep a record of the information ex-

changes with the business. For businesses, it of-

fers an opportunity to best utilize customer service

representatives by evenly distributing the work load

over time, and for representatives, it allows time to

research the issue and respond to the customers in

a manner consistent with business policies. Busi-

nesses can further exploit the offline nature of this

channel by automatically routing the emails involv-

ing critical issues to specialized representatives. Be-

sides concerns related to products and services, busi-

nesses ensure that emails complaining about unfair

treatment due to negligence, incompetence, rigid

protocols and unfriendly systems, are always han-

dled with care. Such emails, referred to as emotional

emails, are critical to reduce the churn i.e., retain-

ing customers who otherwise would have taken their

business elsewhere, and, at the same time, they are a

valuable source of information for improving busi-

ness processes.

In recurring service oriented businesses, a large

number of customer emails may contain routine

complaints. While such complaints are important

and are addressed by customer service represen-

tatives, our purpose here is to identify emotional

emails where severity of the complaints and cus-

tomer dissatisfaction are relatively high. Emotional

emails may contain abusive and probably emotion-

ally charged language, but we are mainly interested

in identifying messages where, in addition to the

flames, the customer includes a concrete descrip-

tion of the problem experienced with the company

providing the service. In the context of customer

service, customers express their concerns in many

ways. Sometimes they convey a negative emotional

component articulated by phrases like disgusted

and you suck. In other cases, there is a minimum

emotional involvement by enumerating factual sen-

tences such as you overcharged, or take my

business elsewhere. In many cases, both

the emotional and factual components are actually

present. In this work, we have identified eight dif-

10



ferent ways that customers use to express their emo-

tions in emails. Throughout this paper, these ways

will be referred to as Salient Features. We cast the

identification of emotional email as a text classifi-

cation problem, and show that using salient features

we can significantly improve the identification ac-

curacy. Compared to a baseline system which uses

Boosting (Schapire, 1999) withnword n-grams fea-

tures, our proposed system using salient features re-

sulted in improvement in f-measure from 0.52 to

0.72.

In section 2, we provide a summary of previous

work and its relationship with our contribution. In

section 3, we describe our method for emotion de-

tection and extraction of salient features. A series of

experiments demonstrating improvement in classifi-

cation performance is presented in section 4. We

conclude the paper by highlighting the main contri-

bution of this work in section 5.

2 Previous Work

Extensive work has been done on emotion detec-

tion. In the context of human-computer dialogs, al-

though richer features including acoustic and intona-

tion are available, there is a general consensus (Lit-

man and Forbes-Riley, 2004b; Lee and Narayanan,

2005) about the use of lexical features to signifi-

cantly improve the accuracy of emotion detection.

Research has also been done in predicting ba-

sic emotions (also referred to as affects) within text

(Alm et al., 2005; Liu et al., 2003). To render speech

with prosodic contour conveying the emotional con-

tent of the text, one of 6 types of human emotions

(e.g., angry, disgusted, fearful, happy, sad, and sur-

prised) are identified for each sentence in the run-

ning text. Deducing such emotions from lexical con-

structs is a hard problem evidenced by little agree-

ment among humans. A Kappa value of 0.24-0.51

was shown in Alm et al. (2005). Liu et al. (2003)

have argued that the absence of affect laden surface

features i.e., key words, from the text does not imply

absence of emotions, therefore they have relied more

on common-sense knowledge. Instead of deducing

types emotions in each sentence, we are interested

in knowing if the entire email is emotional or not.

Additionally we are also interested in the intensity

and the cause of those emotions.

There is also a body of work in areas of creating

Semantic Orientation (SO) dictionaries (Hatzivas-

siloglou and McKeown, 1997; Turney and Littman,

2003; Esuli and Sebastiani, 2005) and their use in

identifying emotions laden sentences and polarity

(Yu and Hatzivassiloglou, 2003; Kim and Hovy,

2004; Hu and Liu, 2004) of those emotions. While

such dictionaries provide a useful starting point,

their use alone does not yield satisfactory results. In

Wilson et al. (2005), classification of phrases con-

taining positive, negative or neutral emotions is dis-

cussed. For this problem they show high agreement

among human annotators (Kappa of 0.84). They

also show that labeling phrases as positive, negative

or neutral only on the basis of presence of key word

from such dictionaries yields a classification accu-

racy of 48%. An obvious reason for this poor per-

formance is that semantic orientations of words are

context dependent.

Works reported in Wilson et al. (2005); Pang et al.

(2002) and Dave et al. (2003) have attempted to

mitigate this problem by using supervised meth-

ods. They report classification results using a num-

ber of different sets of features, including unigram

word features. Wilson et al. (2005) reports an im-

provement (63% to 65.7% accuracy) in performance

by using a host of features extracted from syntac-

tic dependencies. Similarly, Gamon (2004) shows

that the use of deep semantic features along with

word unigrams improve performances. Pang et al.

(2002) and Dave et al. (2003) on the other hand

confirmed that word unigrams provide the best clas-

sification results. This is in line with our experi-

ence as well and could be due to sparseness of the

data. We also used supervised methods to predict

emotional emails. To train predictive models we

used word ngrams (uni-, bi- and tri-grams) and a

number of binary features indicating the presence of

words/phrases from specific dictionaries.

Spertus (1997) discusses a system called Smoky

which recognizes hostile messages and is quite sim-

ilar to our work. While Smoky is interested in iden-

tifying messages that contain flames, our research

on emotional emails looks deeper to discover the

reasons for such flames. Besides word unigrams,

Smoky uses rules to derive additional features for

classification. These features are intended to cap-

ture different manifestations of the flames. Simi-

11



larly, in our work we also use rules (in our case im-

plemented as table look-up) to derive additional fea-

tures of emotional emails.

3 Emotion detection in emails

We use supervised machine learning techniques to

detect emotional emails. In particular, our emotion

detector is a statistical classifier model trained using

hand labeled training examples. For each example,

a set of salient features is extracted. The major com-

ponents of our system are described below.

3.1 Classifier

For detecting emotional emails we used Boostex-

ter as text classification. Our choice of machine

learning algorithm was not strategic and we have no

reason to believe that SVMs or maximum entropy–

based classifiers will not perform equally well.

Boostexter, which is based on the boosting family of

algorithms, was first proposed by Schapire (1999). It

has been applied successfully to numerous text clas-

sification applications (Gupta et al., 2005) at AT&T.

Boosting builds a highly accurate classifier by com-

bining many “weak” base classifiers, each one of

which may only be moderately accurate. Boost-

ing constructs the collection of base classifiers iter-

atively. On each iteration t, the boosting algorithm

supplies the base learner weighted training data and

the base learner generates a base classifier ht. Set

of nonnegative weights wt encode how important it

is that ht correctly classifies each email. Generally,

emails that were most often misclassified by the pre-

ceding base classifiers will be given the most weight

so as to force the base learner to focus on the “hard-

est” examples. As described in Schapire and Singer

(1999), Boostexter uses confidence rated base clas-

sifiers h that for every example x (in our case it is the

customer emails) output a real number h(x) whose
sign (-1 or +1) is interpreted as a prediction(+1 indi-

cates emotional email), and whose magnitude |h(x)|
is a measure of “confidence.” The output of the final

classifier f is f(x) =
∑T

t=1 ht(x), i.e., the sum of
confidence of all classifiers ht. The real-valued pre-

dictions of the final classifier f can be mapped onto a

confidence value between 0 and 1 by a logistic func-

tion;

conf(x = emotional email) =
1

1 + e−f(x)
.

The learning procedure in boosting minimizes the

negative conditional log likelihood of the training

data under this model, namely:

∑

i

ln(1 + e−yif(xi)).

Here i iterates over all training examples and yi is

the label of ith example.

3.2 Feature extraction

Emotional emails are a reaction to perceived exces-

sive loss of time and/or money by customers. Ex-

pressions of such reactions in emails are salient fea-

tures of emotional emails. For our data we have

identified the eight features listed below. While

many of these features are of general nature and can

be present in most customer service related emo-

tional emails, in this paper we make no claims about

their completeness.

1. Expression of negative emotions: Explic-

itly expressing customers affective states

by phrases like it upsets me, I am

frustrated;

2. Expression of negative opinions about

the company: by evaluative expres-

sions like dishonest dealings,

disrespectful. These could also be

insulting expressions like stink, suck,

idiots;

3. Threats to take their business elsewhere:

by expression like business elsewhere,

look for another provider. These

expressions are neither emotional or evaluative;

4. Threats to report to authorities: federal

agencies, consumer protection.

These are domain dependent names of agen-

cies. The mere presence of such names implies

customer threat;

5. Threats to take legal action: seek

retribution, lawsuit. These ex-

pressions may also not be emotional or

evaluative in nature;

6. Justification about why they should have been

treated better. A common way to do this is

12



to say things like long time customer,

loyal customer, etc. Semantic orienta-

tions of most phrases used to express this fea-

ture are positive;

7. Disassociate themselves from the company,

by using phrases like you people, your

service representative, etc. These

are analogous to rule class ”Noun Phrases used

as Appositions” in Spertus (1997).

8. State what was done wrong to them: grossly

overcharged, on hold for hours,

etc. These phrases may have negative or

neutral semantic orientations.

In addition to the word unigrams, salient features of

emotional emails are also used for training/testing

the emotional email classifier. While labeling the

training data, labelers look for salient features within

the email and also the severity of the loss perceived

by the customer. For example, email 1 in Fig. 1 is la-

beled as emotional because customer perception of

loss is severe to the point that the customer may can-

cel the service. On the other hand, email 2 is not

emotional because customer perceived loss is not se-

vere to the point of service cancellation. This cus-

tomer would be satisfied in this instant if he/she re-

ceives the requested information in a timely fashion.

To extract salient features from an email, eight

separate lists of phrases customers use to express

each of the salient features were manually created.

These lists were extracted from the training data

and can be considered as basic rules that identify

emotional emails. In the labeling guide for critical

emails labelers were instructed to look for salient

features in the email and keep a list of encountered

phrases. We further enriched these lists by: a) us-

ing general knowledge of English, we added vari-

ations to existing phrases and b) searching a large

body of email text (different from testing) for differ-

ent phrases in which key words from known phrases

participated. For example from the known phrase

lied to we used the word lied and found a

phrase blatantly lied. Using these lists we

extracted eight binary salient features for each email,

indicating presence/absence of phrases from the cor-

responding list in the email.

1. You are making this very difficult

for me. I was assured that

my <SERVICE> would remain at

<CURRENCY> per month. But you

raised it to <CURRENCY> per

month. If I had known you were

going to go back on your word,

I would have looked for another

Internet provider. Present

bill is <CURRENCY>, including

<CURRENCY> for <SERVICE>.

2. I cannot figure out my current

charges. I have called several

times to straighten out a problem

with my service for <PHONENO1>

and <PHONENO2>. I am tired of

being put on hold. I cannot get

the information from the automated

phone service.

Figure 1: Email samples: 1) emotional; 2) neutral

4 Experiments and evaluation

We performed several experiments to compare the

performance of our emotional email classifier with

that using a ngram based text classifier. For these

experiments we labeled 620 emails as training ex-

amples and 457 emails as test examples. Training

examples were labeled independently by two differ-

ent labelers1 with relatively high degree of agree-

ment among them. Kappa (Cohen, 1960) value of

0.814 was observed versus 0.5-0.7 reported for emo-

tion labeling tasks (Alm and Sproat, 2005; Litman

and Forbes-Riley, 2004a). Because of the relatively

high agreement among these labelers, with differ-

ent back ground, we did not feel the need to check

the agreement among more than 2 labelers. Table

1 shows that emotional emails are about 12-13% of

the total population.

Set Number of examples Critical Emails

Training 620 12%

Test 457 13%

Table 1: Distribution of emotional emails

1One of the labeler was one of the authors of this paper and

other had linguistic back ground.

13



Due to the limited size of the training data we

used cross validation (leave-one-out) technique on

the test set to evaluate outcomes of different exper-

iments. In this round robin approach, each example

from the test set is tested using a model trained on

all remaining 1076 (620 plus 456) examples. Test

results on all 457 test examples are averaged.

Throughout all of our experiments, we computed

the classification accuracy of detecting emotional

emails using precision, recall and F-measure. No-

tice for our test data a classifier with majority vote

has a classification accuracy of 87%, but since none

of the emotional emails are identified, recall and F-

measure are both zero. On the other hand, a clas-

sifier which generates many more false positives

for each true positive, will have a lower classifi-

cation accuracy but a higher (non-zero) F-measure

than the majority vote classifier. Fig. 2 shows pre-

cision/recall curves for different experiments. The

black circles represent the operating point corre-

sponding to the best F-measure for each curve. Ac-

tual values of these points are provided in Table 2.

As a baseline experiment we used word ngram

features to train a classifier model. The graph la-

beled as “ngram features” in Fig. 2 shows the per-

formance of this classifier. The best F-measure in

this case is only 0.52. Obviously this low perfor-

mance can be attributed to the small training set and

the large feature space formed by word ngrams.

Recall Prec. F-Mes.

Ngram Features 0.45 0.61 0.52

Rule based:

Threshholding on

Salient Features counts

≥ 4 0.41 0.93 0.57
≥ 3 0.63 0.74 0.68
≥ 2 0.81 0.53 0.63

Salient Features 0.77 0.65 0.70

ngram &

Salient Features 0.65 0.81 0.72

Ngram &

Random Features 0.57 0.67 0.61

Table 2: Recall and precision corresponding to best F-

measure for different classifier models

Figure 2: Precision/Recall curves for different experi-

ments. Large black circles indicate the operating point

with best F-Measure

4.1 Salient features

The baseline system was compared with a similar

system using salient features. First, we used a sim-

ple classification rule that we formulated by look-

ing at the training data. According to this rule, if

an email contained three or more salient features it

was classified as an emotional email. We classified

the test data using this rule and obtained and an F-

measure of 0.68 (see row labeled as ≥ 3 in Table 2).
Since no confidence thresholding can be used with

the deterministic rule, its performance is indicated

by a single point marked by the gray circle in Fig. 2.

This result clearly demonstrates high utility of our

salient features. To verify that the salient features

threshold count of 3 used in our simple classification

rule is the best, we also evaluated the performance of

the rule for the salient features with threshold count

of 2 and 4 (row labeled as ≥ 2 and ≥ 4 in Table 2).

In our next set experiments, we trained a clas-

sifier model using salient features alone and with

word ngrams. Corresponding cross validation re-

sults on the test data are annotated in Table 2 and in

14



Fig. 2 as “Salient Features” and “N-grams & Salient

Features”, respectively. Incremental improvement in

best F-measure clearly shows: a) BoosTexter is able

to learn better rules than the simple rule of identify-

ing three or more salient features. b) Even though

salient features provide a significant improvement

in performance, there is still discriminative informa-

tion in ngram features. A direct consequence of the

second observation is that the detection accuracy can

be further improved by extending/refining the phrase

lists and/or by using more labeled data so that to

exploit the discriminative information in the word

ngram features.

Salient Features of emotional emails are the con-

sequence of our knowledge of how customers react

to their excessive loss. To empirically demonstrate

that eight different salient features used in identifi-

cation of emotional emails do provide complemen-

tary evidence, we randomly distributed the phrases

in eight lists. We then used them to extract eight

binary features in the same manner as before. Best

F-measure for this experiment is shown in the last

row of Table 2, and labeled as “N-gram & Random

Features”. Degradation in performance of this ex-

periment clearly demonstrates that salient features

used by us provide complimentary and not redun-

dant information.

5 Conclusions

Customer emails complaining about unfair treat-

ment are often emotional and are critical for busi-

nesses. They provide valuable feedback for improv-

ing business processes and coaching agents. Fur-

thermore careful handling of such emails helps to

improve customer retention. In this paper, we pre-

sented a method for emotional email identification.

We introduced the notion of salient features for

emotional emails, and demonstrated high agreement

among two labelers in detecting emotional emails.

We also demonstrated that extracting salient fea-

tures from the email text and using them to train a

classifier model can significantly improve identifi-

cation accuracy. Compared to a baseline classifier

which uses only the word ngrams features, the addi-

tion of the salient features improved the F-measure

from 0.52 to 0.72. Our current research is focused

on improving the salient feature extraction process.

More specifically by leveraging publically available

Semantic orientation dictionaries, and by enriching

our dictionaries using phrases extracted from a large

corpus by matching syntactic patterns of some seed

phrases.

References

Alm, Cecilia and Richard Sproat. 2005. Emotional

sequencing and development in fairy tales. In

Proceedings of the First International Conference

on Affective Computing and Intelligent Interac-

tion.

Alm, Cecilia Ovesdotter, Dan Roth, and Richard

Sproat. 2005. Emotions from text: machine

learning for text-based emotion prediction. In

HLT ’05: Proceedings of the conference on Hu-

man Language Technology and Empirical Meth-

ods in Natural Language Processing. Association

for Computational Linguistics, Morristown, NJ,

USA, pages 579–586.

Cohen, J. 1960. A coefficient of agreement for nom-

inal scales. Educational and Psychological Mea-

surement 20(1):37–46.

Dave, Kushal, Steve Lawrence, and David M. Pen-

nock. 2003. Mining the peanut gallery: Opinion

extraction and semantic classification of product

reviews. In Proceedings of WWW. pages 519–

528.

Esuli, A. and F. Sebastiani. 2005. Determin-

ing the semantic orientation of terms through

gloss classificaion. In Proceedings of CIKM-05,

14th ACM International Conference on Informa-

tion and Knowledge Management. Bremen, DE.,

pages 617–624.

Gamon, M. 2004. Sentiment classification on cus-

tomer feedback data: Noisy data large feature

vectors and the role of linguistic analysis. In Pro-

ceedings of COLING 2004. Geneva, Switzerland,

pages 841–847.

Gupta, Narendra, Gokhan Tur, Dilek Hakkani-Tür,

Srinivas Banglore, Giuseppe Riccardi, and Mazin

Rahim. 2005. The AT&T Spoken Language

Understanding System. IEEE Transactions on

Speech and Audio Processing 14(1):213–222.

Hatzivassiloglou, Vasileios and Kathleen McKeown.

1997. Predicting the semantic orientation of ad-

15



jectives. In Proceedings of the Joint ACL/EACL

Conference. pages 174–181.

Hu, Minqing and Bing Liu. 2004. Mining and sum-

marizing customer reviews. In Proceedings of the

ACM SIGKDD Conference on Knowledge Dis-

covery and Data Mining (KDD). pages 168–177.

Kim, Soo-Min and Eduard Hovy. 2004. Determin-

ing the sentiment of opinions. In Proceedings of

the International Conference on Computational

Linguistics (COLING).

Lee, Chul Min and Shrikanth S. Narayanan. 2005.

Toward detecting emotions in spoken dialogs.

IEEE Transactions on Speech and Audio Process-

ing 13(2):293–303.

Litman, D. and K. Forbes-Riley. 2004a. Annotat-

ing student emotional states in spoken tutoring

dialogues. In Proceedings of the 5th SIGdial

Workshop on Discourse and Dialogue (SIGdial).

Boston, MA.

Litman, D. and K. Forbes-Riley. 2004b. Predicting

student emotions in computer-human tutoring di-

alogues. In Proceedings of the 42nd Annual Meet-

ing of the Association for Compuational Linguis-

tics (ACL). Barcelone, Spain.

Liu, Hugo, Henry Lieberman, and Ted Selker. 2003.

A model of textual affect sensing using real-world

knowledge. In IUI ’03: Proceedings of the 8th

international conference on Intelligent user inter-

faces. ACM Press, Miami, Florida, USA, pages

125–132.

Pang, Bo, Lillian Lee, and Shivakumar

Vaithyanathan. 2002. Thumbs up? Sentiment

classification using machine learning techniques.

In Proceedings of the 2002 Conference on Em-

pirical Methods in Natural Language Processing

(EMNLP). Philadelphia, Pennsylvania, pages

79–86.

Schapire, R.E. 1999. A brief introduction to boost-

ing. In Proceedings of IJCAI.

Schapire, R.E. and Y. Singer. 1999. Improved

boosting algorithms using confidence-rated pre-

dictions. Machine Learning 37(3):297–336.

Spertus, Ellen. 1997. Smokey: Automatic recogni-

tion of hostile messages. In In Proc. of Innova-

tive Applications of Artificial Intelligence. pages

1058–1065.

Turney, P. and M. Littman. 2003. Measuring praise

and criticism: Inference of semantic orientation

from association. ACM Transactions on Informa-

tion Systems 21(4):315–346.

Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann.

2005. Recognizing contextual polarity in phrase-

level sentiment analysis. In HLT ’05: Proceed-

ings of the conference on Human Language Tech-

nology and Empirical Methods in Natural Lan-

guage Processing. Association for Computational

Linguistics, Morristown, NJ, USA, pages 347–

354.

Yu, Hong and Vasileios Hatzivassiloglou. 2003. To-

wards answering opinion questions: Separating

facts from opinions and identifying the polarity of

opinion sentences. In Proceedings of the Confer-

ence on Empirical Methods in Natural Language

Processing (EMNLP).

16


