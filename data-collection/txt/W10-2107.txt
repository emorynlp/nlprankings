










































You Talking to Me? A Predictive Model for Zero Auxiliary Constructions


Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common Ground, ACL 2010, pages 43–51,
Uppsala, Sweden, 16 July 2010. c©2010 Association for Computational Linguistics

You talking to me? A predictive model for zero auxiliary constructions

Andrew Caines
Computation, Cognition & Language Group

RCEAL, University of Cambridge, UK

apc38@cam.ac.uk

Paula Buttery
Computation, Cognition & Language Group

RCEAL, University of Cambridge, UK

pjb48@cam.ac.uk

Abstract

As a consequence of the established prac-
tice to prefer training data obtained from
written sources, NLP tools encounter
problems in handling data from the spo-
ken domain. However, accurate models
of spoken data are increasingly in demand
for naturalistic speech generation and ma-
chine translations in speech-like contexts
(such as chat windows and SMS). There
is a widely held assumption in the lin-
guistic field that spoken language is an
impoverished form of written language.
However, we show that spoken data is
not unpredictably irregular and that lan-
guage models can benefit from detailed
consideration of spoken language features.
This paper considers one specific con-
struction which is largely restricted to the
spoken domain - the ZERO AUXILIARY -
and makes a predictive model of that con-
struction for native speakers of British En-
glish. The model can predict zero auxil-
iary occurrence in the BNC with 96.9%
accuracy. We will demonstrate how this
model can be integrated into existing pars-
ing tools, increasing the number of suc-
cessful parses for this zero auxiliary con-
struction by around 30%, and thus improv-
ing the performance of NLP applications
which rely on parsing.

1 Introduction

Up to this point, statistical Natural Language Pro-
cessing (NLP) tools have generally been trained
on corpora that are representative of written rather
than spoken language. A major factor behind this
decision to use written data is that it is far easier to
collect than spoken data. Newswire, for instance,
may be harvested readily and in abundance. Once

collected, written language requires relatively lit-
tle processing before it can be used for training a
statistical model.

Processing of spoken data, on the other hand,
involves at the very least transcription - which usu-
ally requires a human transcriber. Since transcrip-
tion is a slow and laborious task, the collection of
spoken data is highly resource intensive. But this
relative difficulty in collection is not the only rea-
son that spoken language data has been sidelined.
Had spoken data been considered to be crucial to
the production of NLP applications greater efforts
might have been made to obtain it. However, on
account of some of its characteristic features such
as hesitations, interruptions and ellipsis, spoken
language is often dismissed as nothing more than
a noisy approximation to ‘real’ or ‘intended’ lan-
guage.

In some forums, written language is held up
as an idealised form of language toward which
speakers aspire and onto which spoken lan-
guage should be retrofitted. This is an arte-
fact of the theoretical notion of a ’competence’-
’performance’ dichotomy (Chomsky 1965) with
the latter deemed irrelevant and ignored in main-
stream linguistic research.

The consequence of the established practice to
sideline spoken data is that NLP tools are inher-
ently error prone when handling data from the spo-
ken domain. With increasing calls for speech to be
considered the primary form of language and to be
treated as such (Sampson 2001: 7 1; Cermák 2009:
115 2; Haugh 2009: 74 3) and a growing trend for
NLP techniques to be integrated into cognitive and
neurolinguistic research as well as forensic appli-

1Speech is “unquestionably the more natural, basic mode
of language behaviour”.

2“From a linguistic point of view, spoken corpora should
be primary for research but that has not been the case so far”.

3Haugh observes that “spoken language and interaction
lie at the core of human experience” but bemoans the “relative
neglect of spoken language in corpora to date”.

43



cations, there are now compelling reasons to ex-
amine spoken data more closely. Accurate mod-
els of spoken data are increasingly in demand for
naturalistic speech generation and machine trans-
lations in speech-like contexts (such as human-
machine dialogue, chat windows and SMS).

The main research aim of our work is to show
that spoken data should not be considered error
prone and therefore unpredictably irregular. We
show that language models can be improved in in-
crements as we deepen our understanding of spo-
ken language features. We investigate ZERO AUX-
ILIARY progressive aspect constructions - those
which do not feature the supposedly obligatory
auxiliary verb, as in (1a) below (cf. 1b):

(1a) What you doing? Who you looking
for? You been working?

(1b) What are you doing? Who are you
looking for? Have you been working?

The zero auxiliary is a non-standard feature
which for the most part is known to be restricted
to speech. A corpus study of spoken British En-
glish indicates that in progressive aspect interroga-
tives with second person subjects (as in (1) above)
the auxiliary occurs in zero form in 27% of con-
structions found. The equivalent figure from the
written section of the corpus is just 5.4%. Con-
sequently, existing NLP techniques - since they
are based on written training data - are unlikely
to deal appropriately with zero auxiliary construc-
tions. We report below on the corpus study in full
and use the results of logistic regression to design
a predictive model of zero auxiliary occurrence
in spoken English. The model is based on con-
textual grammatical features and can predict zero
auxiliary occurrence in the British National Cor-
pus (BNC; 2007) with 96.9% accuracy. Finally,
we discuss how this model can be used to improve
the performance of NLP techniques in the spoken
domain, demonstrating its implementation in the
RASP system (Robust Accurate Statistical Pars-
ing; (Briscoe, Carroll and Watson, 2006)).

This paper underlines why awareness of non-
standard linguistic features matters. Targeted data
extraction from large corpus resources allows the
construction of more informed language models
which have been trained on naturalistic spoken
usage rather than standard and restricted rules of
written language. Such work has only been made
possible with the advent of large spoken language

corpora such as the BNC. Even so, the resource-
heavy nature of spoken data collection means that
speech transcriptions constitute only one tenth of
this 100 million word corpus 4. Nevertheless, it
is an invaluable resource made up of a range of
speech genres including spontaneous face-to-face
conversation, a fact which makes it unique among
corpora. Since conversational dialogue is the pre-
dominant language medium, the BNC offers the
best chance of modelling speech as it occurs natu-
rally.

This work has important implications for both
computational and theoretical linguistics. On the
one hand, we can improve various NLP techniques
with more informed language models, and on the
other hand we are reminded that the space of
grammatical possibility is not restricted and that
continued empirical investigation is key in order
to arrive at the fullest possible description of lan-
guage use.

2 Spoken and written language

In the modern mainstream fields of linguistic
research, based on Chomsky’s ‘ideal speaker-
listener’ (1965), spoken language has been all
too easily dismissed from consideration on the
grounds that it is more error-prone and less impor-
tant than written language. In this idealisation, the
speaker-listener is “unaffected by such grammati-
cally irrelevant conditions as memory limitations,
distractions, shifts of attention and interest, and er-
rors (random or characteristic)” (Chomsky, 1965).

The ‘errors’ Chomsky refers to are features of
speech production such as pauses, filled silence,
hesitation, repetition and elision, or of dialogue
such as backgrounding, overlap and truncation be-
tween speakers. Thus ‘error’ is essentially here de-
fined as that which is not normally found in well-
formed written data, that which is ‘noisy’ and ‘un-
predictable’. It is on these grounds - the gram-
matical rigidity of the written medium relative to
speech - that the divide between spoken and writ-
ten language modelling has grown up.

The opposing, usage-based view is that spoken
language is systematic and that it should be mod-
elled as it is rather than as a crude approximation
of the written form. On this view, the speech pro-
duction and dialogue features listed above are not

4Cermák estimates our experience with each language
medium is in fact this ratio in reverse - 90:10 spoken to writ-
ten (2009: 115).

44



considered mistakes but “regular products of the
system of spoken English” (Halliday, 1994). ‘Er-
ror’ is thus seen as a misnomer for these features
because they are in fact all regular in some way.
For example, the fact that people tend to put filler
pauses in specific places.

We propose a middle way: that which builds
on the NLP tools available, even though they are
trained on written data, and on top of these models
the features of spoken language as ‘noise’ in the
communicative channel. This is a pragmatic ap-
proach which recognises the considerable amount
of work underpinning existing NLP tools and sees
no value in discarding these and starting again
from scratch. We demonstrate that spoken lan-
guage is model-able and predictable, even with
a feature which would not be seen as ‘correct’
in written form. For practical purposes we need
to recognise the regularities in the apparently ‘in-
correct’ features of speech and build these into
the functioning language models we already have
through statistical analysis of corpus distributions
and appropriate adjustment to parser tools.

3 The zero auxiliary construction

According to standard grammatical rules, the aux-
iliary verb is an obligatory feature of progressive
aspect constructions. However, this rule is based
on norms of written language and is in fact not al-
ways adhered to in the production of speech. As a
result, some progressive constructions do not fea-
ture an auxiliary verb. These are termed ‘zero aux-
iliary’ constructions and have been previously ex-
amined in studies of dialect (Labov, 1969; Ander-
sen, 1995) and first language acquisition (Brown,
1973; Rizzi, 1993/1994; Wexler, 1994; Lieven et
al, 2003; Wilson, 2003; Theakston et al, 2005).

There are copious anecdotal examples of the
zero auxiliary:

(2) You talking to me? Travis Bickle in
Taxi Driver (1976).

(3) Where he going? Avon Barksdale
in The Wire, Season 1: ‘Game Day’
(2002).

(4) What you doing? Holly Golightly in
Breakfast at Tiffany’s (1961).

Natural language data taken from the spoken
section of the British National Corpus (sBNC)
shows that the zero auxiliary features in 1330

(27%) of the 4923 second person progressive in-
terrogative constructions; as in (1), (2), (4) above.
In first person singular declaratives (cf. (5a) and
(5b)), in contrast, the proportion of zero auxiliary
occurrence is just 0.9% (158 of 17,838 construc-
tions). This already indicates the way that the zero
auxiliary occurs in predictable contexts and how
grammatical properties will feature in the predic-
tive model.

(5a) What I saying? I annoying you?
Why I doing this?

(5b) What am I saying? Am I annoying
you? Why am I doing this?

Subject person, subject number, subject type
(pronoun or other noun) and clause type (declar-
ative or interrogative) are four of the eight syntac-
tic properties incorporated in the predictive model.
The four other properties are clause tense (6), per-
fect or non-perfect aspect (7), clause polarity (8)
and presence or absence of subject (9).

(6) You are debugging. You were de-
bugging.

(7) We have been looking for a present.
We are looking for a present.

(8) She is watching the grand prix. He
is not watching the grand prix.

(9) I am going to town in a minute. Go-
ing to town in a minute.

We employ logistic regression to investigate the
precise nature of the relationships between zero
auxiliary use and these various linguistic vari-
ables. This allows us to build a predictive model
of zero auxiliary occurrence in spoken language
which will be useful for several reasons relating
to parsing of natural spoken language. Firstly,
for automatic parsing of spoken data being able
to predict when a zero auxiliary is likely to oc-
cur enables the parser to relax its normal rules
which are based on written standards. Secondly,
as technology improves and interaction with com-
puters becomes more humanistic the need to repli-
cate human-like communication increases in im-
portance: by knowing in which contexts the aux-
iliary verb might be absent, researchers can build
a language model which is more realistic and so
the user experience is improved and made more
naturalistic. Thirdly, a missing auxiliary might be
problematic for machine translation since it could

45



result in the loss of tense and aspect information,
but with the ability to predict where a zero auxil-
iary might occur, the auxiliary can be restored so
that translation can be performed with appropriate
tense and aspect.

For all these reasons, the zero auxiliary in spo-
ken English is an appropriate case study for find-
ing the common ground between NLP and Lin-
guistics. Awareness of this particular linguis-
tic phenomenon through corpus study allows the
construction of more informed language models
which in turn enhance relevant NLP techniques.
The cross-pollination of research from NLP and
linguistics benefits both fields and ties in with the
emergence of linguistic theories that “conceive of
structure as gradient, malleable and probabilistic”
and incorporate “knowledge of the frequency and
probability of use of these categories in speakers’
experience” (Tily et al, 2009). These are collec-
tively known as ‘usage-based’ approaches to lan-
guage theory and are exerting a growing influ-
ence on the field (e.g. Barlow and Kemmer 2000;
Bybee and Hopper 2001; Bod, Hay and Jannedy
2003).

4 Corpus study

Training data was obtained through manual anno-
tation of progressive constructions in the British
National Corpus (2007). A preliminary study of
interrogatives with second person subjects con-
firmed that the zero auxiliary is more a feature
of the spoken rather than the written domain (Ta-
ble 1). Therefore a focus on the spoken section of
the corpus (sBNC) was justified and so we under-
took a comprehensive study of all progressive con-
structions in sBNC. The genres contained in sBNC
include a range of settings and levels of formality
- from academic lectures to radio programmes to
spontaneous, face-to-face conversation.

We extracted 93,253 sentences featuring a pro-
gressive construction from sBNC and each was
manually annotated for auxiliary realisation and
the eight syntactic properties described in Ta-
ble 2. In Table 3 the progressive constructions are
classified by auxiliary realisation. With approxi-
mately 4.2% occurrence in progressive construc-
tions, zero auxiliaries are a low frequency feature
of spoken language but ones which are significant
for the fact that existing NLP tools cannot suc-
cessfully parse them, thus one in twenty-five pro-
gressive constructions will not be fully parsed. We

Corpus Auxiliary
Full Contracted Zero

wBNC 3220 27 187
sBNC 3498 95 1330

Table 1: Auxiliary realisation in second person
progressive interrogatives in the BNC.

use the annotated corpus of these progressive con-
structions to design the predictive model described
below.

Properties Value encodings
Aux realisation
Zero auxiliary full(0), contracted(1), zero(2)
Variables
Subject person 1st(1), 2nd(2), 3rd(3)
Subject number singular(0), plural(1)
Subject type other noun(0), pronoun(1)
Subj supplied zero subj(0), subj supplied(1)
Clause type declarative(0), interrogative(1)
Clause tense present(0), past(1)
Perfect aspect non-perfect(0), perfect(1)
Polarity positive(0), negative(1)

Table 2: Syntactic features and their encodings in
the annotated sBNC Progressive Corpus

5 Model

To predict the zero auxiliary in spoken language
we use logistic regression. To train this model
we took a 90% sample from our corpus of 93,253
progressive constructions extracted from the spo-
ken section of the BNC, as described above and in
Caines 2010. The dataset was split into two cat-
egories: those sentences which exhibited the zero
auxiliary and those which did not5. A logistic re-
gression was then performed to ascertain the prob-
ability of category membership using the eight
previously described syntactic properties. Note
that subject person is arguably not a scalar vari-

5Contracted auxiliaries thus belong in the ‘not zero auxil-
iary’ category.

Corpus Full Contracted Zero
sBNC 38,015 51,295 3943

Table 3: Auxiliary realisation in progressive con-
structions in sBNC.

46



able and therefore is re-analysed as three boolean
variables with separate binary values for use of the
first, second and third person. However, the three
subject person variables are dependent (ie. If the
subject is not first or second person it will be in the
third). Thus the eight syntactic properties become
nine explanatory variables in the predictive model,
as reported in Table 4.

Corpus Predictor Coefficient
subject person: 1st 0.171
subject person: 2nd 1.280
plural subject -0.300
pronoun subject -0.470
zero subject 5.711
interrogative clause 2.139
past tense clause -4.852
perfect aspect -0.280
negated clause -1.163
constant -4.033

Table 4: Predictor coefficients for the presence of
a zero auxiliary construction.

5.1 Model Evaluation

The logistic function is defined by:

f(Z) =
1

1 + e−z
(1)

The variable z is representative of the set of pre-
dictors and is defined by:

z = β0 + β1x1 + β2x2 + . . .+ βkxk (2)

where β0, β1, β2 ... βk are the regression coeffi-
cients of predictors x1, x2 .. xk respectively. The
predictors explored in this paper are encodings of
the syntactic properties of the annotated sentences.
The predictors and their encodings are indicated in
Table 2.

The logistic function is constrained to values
between 0 and 1 and represents the probability
of membership of one of the two categories (zero
auxiliary or auxiliary supplied). In our case an
f(z) > 0.5 indicates that there is likely to be a
zero auxiliary.

The logistic function defined by the coefficients
in Table 4 is able to predict correct category mem-
bership for 96.9% of the sentences in the annotated
corpus. All coefficients are highly significant to

the logistic function (p<0.001) with the exception
of perfect aspect and first person subject - which
are both significant nevertheless (p<0.05).

For this model, positive coefficients indicate
that the associated syntactic properties raise the
probability of a zero auxiliary occurring. Large
coefficients more strongly influence the probabil-
ity of the zero auxiliary whereas near-zero coeffi-
cients have little influence. From the coefficients
in Table 4 we see that the strongest predictor of
a zero auxiliary is the occurrence of a zero sub-
ject (as in the utterance, ‘leaving now.’). An inter-
rogative utterance is also a good candidate, as is
the second person subject (e.g. ‘you eating those
olives?’). However, a past tense utterance is an un-
likely candidate for a zero auxiliary construction,
as is a negated utterance.

6 Discussion — using the predictive
model to aid parsing

As mentioned above, since parsers are trained on
written data they can often display poor perfor-
mance on text transcribed from the spoken do-
main. From the results of our corpus study we
know that the zero auxiliary occurs in approxi-
mately 4.2% of progressive constructions in spo-
ken language and we can extrapolate that it will
occur in less than 1% (approximately 0.8%) of
all progressive constructions in written language.
A statistical parser trained on written language
will therefore be prone to undergo parsing fail-
ure for every one in twenty-five progressive sen-
tences. This is no insignificant problem, espe-
cially when it is remarked that the progressive is
in high frequency usage (there are one thousand
ING-forms featuring in progressive constructions
for every one million words of sBNC) and that its
use is known to be spreading (Leech et al, 2009).

Compounded with those parser breakdowns
caused by other speech phenomena (for instance,
repetition and elision), high numbers of parse fail-
ures on progressive constructions will render NLP
accuracy on spoken language intolerable for any
applications which rely on accurate parsing as a
foundation. However, we have shown above that
features of spoken language such as the zero aux-
iliary should not be thought of as errors or as un-
predictable deviations from the written form, but
rather can be considered to be consistent and pre-
dictable events. In this section we illustrate how
our predictive model for zero auxiliary occurrence

47



(|relation| |head| |dependant|) (3)
(|ncsubj| |play + ing : V V G| |you : PPY |)(4)
(|obj| |play + ing : V V G| |what : DDQ|) (5)
(|aux| |play + ing : V V G| |be+ : V BR|) (6)
(|arg| |play + ing : V V G| |you : PPY |) (7)
(|relation| |verb : V V G| |dependant|) (8)

Figure 1: Example grammatical relations from
RASP.

may be integrated into a parser pipeline in order
to aid the parsing of spoken language. In this way
we build on the increasingly robust engineering of
statistical NLP tools trained on written language
by allowing them to adapt to the spoken domain
on the basis of the linguistic study of speech phe-
nomena.

In general the notion of ‘parsing’ an utterance
involves a chain of several processes: utterance
boundary detection, tokenization, part-of-speech
tagging, and then parsing. We suggest that when it
is known that the language to be parsed is from the
spoken domain the pipeline of processes should be
run in a SPEECH AWARE MODE. Extra functional-
ity would be incorporated into each of the stages
according to the findings of linguistic research into
spoken language. In other work we have adapted
the tokenization and tagging stages of the pipeline
based on predictors that indicate when interjec-
tions (e.g. ‘umm’, ‘err’ and ‘ah’) have been ‘used’
as punctuation or lexical items. We also incorpo-
rate intonation phrases as predictors for utterance
boundary detection (Buttery and Caines: in prepa-
ration). Here, we augment the parsing stage of the
pipeline by allowing an informed re-parse of ut-
terances in which a parse failure is likely to have
been caused by a zero auxiliary.

We present this section with reference to the
specific mechanics and output formats of the
RASP system but our algorithm is by no means
parser specific and could be adapted for other
parsers quite easily. Utterances parsed with
RASP may be expressed as ‘grammatical rela-
tions’. RASP’s grammatical relations are theory-
general, binary relations between lexical terms and
are expressed in the form of head-dependancy re-
lations as shown in (3), Figure 1.

Consider the utterance ‘what are you playing?’.

When we parse this with RASP we get grammati-
cal relations (4), (5) and (6) in Figure 1. The capi-
tal letter codes following the ‘:’ symbols are part-
of-speech tags (from the CLAWS-2 tagset (Gar-
side, 1987)) which have been assigned to the lexi-
cal tokens by the tagger of the RASP system. Here
PPY indicates the pronoun ‘you’; VVG indicates
the ING-form of lexical verb; VBR indicates ‘be’
in 3rd person present tense; and DDQ indicates
a wh-determiner. The relation (4) tells us that
‘you’ is the subject of ‘playing’; relation (5) tells
us that ‘what’ is taking the place of the object be-
ing played; and relation (6) tells us that there is an
auxiliary relationship between ‘are’ and ‘playing’.
This is much as we would expect. However, if we
try to parse ‘what you playing?’ the parse fails.
The single relation (4) is returned where ideally
we would like both (4) and (5), as we did when
the auxiliary was present.

For the utterance, ‘you playing?’ RASP returns
the under-specified grammatical relation (7) which
is simply indicating that ‘you’ is an argument of
‘playing’ but not which type of argument (whether
a subject, direct object, etc). Ideally we would
like to retrieve at least (4) as we would have if we
parsed the utterance ‘are you playing?’. For these
examples, we shall consider the failure to identify
the correct subject and object of the progressive
verb to be a parsing failure.

We integrate the zero auxiliary predictive model
with parsing technology to improve the parsing of
zero auxiliaries in spoken language. Note that we
use the RASP system but our algorithm is by no
means parser specific. The only prerequisite is
that the parser must be able to identify relations
of some kind between the subject noun and ING-
form (possibly via a parsing rule) and also be able
extract values for the predictors (through either a
rich tagset or from the identification of key speech
tokens). The illustrative method we discuss here
is integrated into the parsing pipeline in the event
of a parse failure but there are several alternative
methods that might also be considered.

For instance, by using the predictive model
earlier in the parsing system pipeline a modified
tagset could be used which updates the ING-form
tag with a new tag to indicate that there is also a
missing auxiliary. Another method might involve
altering rule probabilities or adding extra parser
rules so that parsing only has to occur once. Our
other work in this area suggests that the final deci-

48



sion on where to add the spoken language modifi-
cations within the parsing pipeline will largely de-
pend on the interaction of the phenomena in ques-
tion with other speech phenomena.6

With the proviso that it is a preliminary integra-
tion of the predictive model into a parsing system,
we propose the following algorithm for zero aux-
iliaries in spoken language. When ‘speech aware
mode’ is activated, if we encounter a parse failure
then we first check the part-of-speech tags of the
utterance to ascertain if the sentence contains the
ING-form requisite for a progressive construction:

• IF no ING-form is found: STOP. Our
model predicts zero auxiliaries in progressive
constructions—there is nothing more we can
do with the input.

• ELSE: An ING-form is found. Extract all
grammatical relations that were obtained by
the parse which contained the ING-form in
the head position (these would be grammat-
ical relations that have the general format
of (8) in Figure 1). We will refer to this set of
grammatical relations as GRS.

– IF there is an auxiliary relation
present in GRS: STOP. If at least one
of the extracted grammatical relations is
an auxiliary relation, similar to (6) in
Figure 1, an auxiliary is present—we do
not have a zero auxiliary construction.7

– ELSE: The utterance is a candidate for
zero auxiliary.

Having determined a possible candidate for zero
auxiliary we carry out the following steps:

1. Ascertain values for the zero auxiliary pre-
dictors (explained in more detail below).

2. Calculate the value of the logistic function
f(z) using the obtained predictor values with
their coefficients (shown in Table 4).

3. If f(z) > 0.5, assume an auxiliary is miss-
ing.

6Although, another major consideration is the overall
computational efficiency of the parsing system.

7This step is actually subtly more complicated—auxiliary
relations involving ‘been’ are allowed to be present in GRS
(this allows us to capture zero auxiliaries in the perfect such
as ‘been coming here long?’) but if there is any other auxil-
iary relation present in GRS then we STOP here.

4. Add the auxiliary to the sentence (choos-
ing which auxiliary based on the predictor
values—see below).

5. Re-parse the sentence.

6. Remove (or flag) the auxiliary grammatical
relation from the newly obtained parser out-
put.8

For step 1 above properties of the current utter-
ance have to be obtained. The subject person, plu-
ral subject, zero subject and pronoun subject prop-
erties are ascertained by looking at the part-of-
speech of the dependant noun/pronoun within any
subject relations occurring in the set GRS (gram-
matical relations headed by the ING-form). Sub-
ject relations would look similar to (4) in Figure 1.
If there is no subject grammatical relation, any un-
derspecified ‘arg’ relation (such as (7) in Figure 1)
are considered. If neither of these relations are
present in GRS then a zero subject is inferred.
The person and plurality of the subject noun is en-
coded within its CLAWS2 part-of-speech tag. For
instance, a PPHS1 tag, which is used to indicate
‘him’ or ‘her’ would tell us we have a third per-
son, singular pronoun.9

The other properties are all ascertained by the
presence or absence of a token within the utter-
ance: interrogative property is inferred when the
utterance ends with a question mark; the nega-
tion property when either ‘not’ or ‘n’t’ (which are
tagged XX) is present; the perfect is inferred from
the presence of the word ‘been’; and past tense is
ascertained from a set of temporal marker lexical
items (e.g. ‘yesterday, ‘before’). Once extracted
the properties are encoded as shown in Table 4 for
use as the predictor values in the logistic function.

In order to select the correct auxiliary and loca-
tion for insertion in step 4 the utterance values are
consulted. For instance, an interrogative utterance
in the present tense, not in perfect aspect, with a
second person singular subject will require inser-
tion of the auxiliary ‘are’ after the subject. A zero
subject zero auxiliary, on the other hand, requires
restoration of both subject and auxiliary. Where a
question mark indicates it has been used in an in-
terrogative clause the subject is assumed to be sec-

8We also remove (or flag) the subject relation in cases
where a subject also had to be added in step 4. This would
occur when the original utterance exhibited a zero subject.

9All common nouns are assumed to be 3rd person and all
instances of ‘you’ were considered to be singular (as was the
case during corpus annotation).

49



ond person - as is the case in most questions - and
so the auxiliary-subject combination ‘are you’ is
restored before the ING-form. Without a question
mark, the clause is assumed to be declarative and
so the first person singular subject-auxiliary com-
bination ‘I am’ is restored before the ING-form 10.

We withheld 10% of the zero auxiliary corpus
for test purposes. The integration of the predic-
tive model into the parser allowed us to success-
fully parse 31.4% of previously unparsable zero-
auxilaries. On cleaned spoken transcripts (i.e.
with speech phenomena other than the zero aux-
iliary, such as repetitions, removed) this algorithm
allows us to retrieve the correct subject-object re-
lations for an extra 1238 utterances within our
annotated corpus (which again accounts for ap-
proximately one third of the previously unparsable
zero-auxilaries). This is a significant step forward
for any applications building on top of a parsing
infrastructure.

7 Conclusion

We have shown how awareness of a specific
linguistic phenomenon enables improvements in
NLP techniques. The zero auxiliary is mainly a
feature of spoken language and so is not on the
whole handled successfully by existing parsers,
trained as they are on written data. As a so-
lution, rather than proposing the construction of
new models specifically designed for spoken lan-
guage, thereby doing away with all previous work
on NLP tools and starting again from scratch, we
demonstrated how new training data from a spo-
ken source could be applied to an existing parser
- RASP. We designed a predictive model of zero
auxiliary occurrence based on logistic regression
with nine syntactic variables. The data came from
an annotated corpus of 93,253 progressive con-
structions which showed zero auxiliary frequency
to be 4.2%. Without this new predictive informa-
tion in the parser, the status quo would continue
whereby one in twenty-five progressive construc-
tions would continue to be mis-parsed. We found
that instead the noise was regular and could be
modelled, and we illustrated how this specific lin-
guistic data could be integrated into existing NLP
technology. This is a case study of one specific
linguistic phenomenon. Our belief is that other

10A sample of one hundred zero subject declarative zero
auxiliaries indicates that the first person singular is the ap-
propriate subject type to restore on 60% of occasions.

such spoken language phenomena can be mod-
elled in the same way, given an appropriate corpus
resource, accurate annotation and implementation
into a parser.

By running in a ‘speech aware mode’ which
supplements existing parsing architecture we ben-
efit from the training that has already been under-
taken on a large scale based on written data and
complement it with specialized and predictable
linguistic properties of speech. Ideally, we would
like to train an entire parsing system on spoken
language but until spoken corpora become more
readily available this is not a practical option: the
resulting parser would suffer greatly from data
sparsity issues. Frustratingly, there is a circular
problem in generating corpora of an appropriate
size for training since until highly accurate mod-
els for spoken language are built we can not expect
speech-to-text systems to provide highly accurate
transcripts. But to build these highly accurate
models of spoken language in the first place a large
amount of data is required. Augmenting the ex-
isting statistical NLP tools trained on written lan-
guage with specialized linguistic knowledge from
the spoken domain is a pragmatic short-term fix
for this problem.

We should note that tailoring parsers to deal
with spoken language is by no means unheard of:
the RASP system itself, for example (which parses
using a probabilistic context-free grammar), al-
ready has several rules in its grammar which are
more appropriate for parsing spoken language.
However, use of these rules can contribute to much
over-generation and complexity in the parse for-
est (the parser internal structure which holds all
the possible parses for an utterance). In conse-
quence, the specialized rules have to be expertly
selected or deselected when configuring the parser.
This work - and our research program as a whole
- would instead allow parser configuration deci-
sions and algorithmic adaptions to be made non-
expertly and on-the-fly when running in ‘speech
aware mode’. All rule activations and algorithm
adaptions would be made based on predictions
constructed from expert linguistic analysis of the
spoken domain.

Acknowledgements

This work was supported by the AHRC. We thank
three anonymous reviewers for their comments,
Andrew Rice and Barbara Jones.

50



References
Gisle Andersen. 1995. Omission of the primary verbs

BE and HAVE in London teenage speech - a so-
ciolinguistic study. Hovedfag thesis, University of
Bergen, Norway.

Michael Barlow and Suzanne Kemmer. 2000. Usage-
based models of language. Chicago: CSLI.

Rens Bod, Jennifer Hay and Stefanie Jannedy (eds.).
2003. Probabilistic Linguistics. Cambridge, MA:
MIT Press.

Ted Briscoe, John Carroll and Rebecca Watson. 2007.
The second release of the RASP system. Proceed-
ings of the COLING/ACL on Interactive presenta-
tion sessions, July 17-18, 2006, Sydney, Australia.

The British National Corpus, version 3. 2007.
Distributed by Oxford University Computing Ser-
vices on behalf of the BNC Consortium. URL:
http://www.natcorp.ox.ac.uk/

Roger Brown. 1973. A First Language: the early
stages. London: George Allen and Unwin.

Paula Buttery and Andrew Caines. In preparation. An
Empirical Approach to First Language Acquisition.
Cambridge: Cambridge University Press.

Joan Bybee and Paul Hopper (eds.). 2001. Frequency
and the emergence of linguistic structure. Amster-
dam: John Benjamins.

Andrew Caines. 2010. You talking to me? Zero aux-
iliary constructions in British English. Ph.D thesis,
University of Cambridge.

Frantisek Cermák. 2009. Spoken corpora design.
Their constitutive parameters. International Journal
of Corpus Linguistics 14: 113-123.

Noam Chomsky. 1965. Aspects of the Theory of Syn-
tax. Cambridge, MA: MIT Press.

Roger Garside. 1987. The CLAWS Word-tagging Sys-
tem. In: Roger Garside, Geoffrey Leech and Ge-
offrey Sampson (eds.), The Computational Analy-
sis of English: A Corpus-based Approach. London:
Longman.

Michael A. K. Halliday. 1994. Spoken and Writ-
ten Modes of Meaning. In: David Graddol and
Oliver Boyd-Barrett (eds.), Media Texts: Authors
and Readers. Clevedon: Multilingual Matters.

Michael Haugh. 2009. Designing a Multimodal
Spoken Component of the Australian National Cor-
pus. In: Michael Haugh, Kate Burridge, Jean Mul-
der, and Pam Peters (eds.), Selected Proceedings of
the 2008 HCSNet Workshop on Designing the Aus-
tralian National Corpus. Somerville, MA: Cas-
cadilla Proceedings Project.

William Labov. 1969. Contraction, deletion, and in-
herent variability of the English copula. Language
45: 715-762.

Geoffrey Leech, Marianne Hundt, Christian Mair and
Nicholas Smith. 2009. Change in Contemporary
English: a grammatical study. Cambridge: Cam-
bridge University Press.

Elena Lieven, Heike Behrens, Jennifer Speares and
Michael Tomasello. 2003. Early syntactic creativ-
ity: a usage-based approach. Journal of Child Lan-
guage 30: 333-370.

Luigi Rizzi. 1993/1994. Some notes on linguistic the-
ory and language development: The case of root in-
finitives. Language Acquisition 3: 371-393.

Geoffrey Sampson. 2001. Empirical Linguistics. Lon-
don: Continuum.

Anna Theakston, Elena Lieven, Julian Pine and Caro-
line Rowland. 2005. The acquisition of auxiliary
syntax: BE and HAVE. Cognitive Linguistics 16:
247-277.

Harry Tily, Susanne Gahl, Inbal Arnon, Neal Snider,
Anubha Kothari and Joan Bresnan. 2009. Syntactic
probabilities affect pronunciation variation in spon-
taneous speech. Language and Cognition 1: 147-
165.

Kenneth Wexler. 1994. Optional Infinitives, head
movement and the economy of derivations. In:
David Lightfoot and Norbert Hornstein (eds.), Verb
Movement. Cambridge: Cambridge University
Press.

Stephen Wilson. 2003. Lexically specific construc-
tions in the acquisition of inflection in English.
Journal of Child Language 30: 75-115.

51


