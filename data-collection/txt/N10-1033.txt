










































Two monolingual parses are better than one (synchronous parse)


Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 263–266,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

Two monolingual parses are better than one (synchronous parse)∗

Chris Dyer
UMIACS Laboratory for Computational Linguistics and Information Processing

Department of Linguistics
University of Maryland, College Park, MD 20742, USA

redpony AT umd.edu

Abstract

We describe a synchronous parsing algorithm
that is based on two successive monolingual
parses of an input sentence pair. Although
the worst-case complexity of this algorithm
is and must be O(n6) for binary SCFGs,
its average-case run-time is far better. We
demonstrate that for a number of common
synchronous parsing problems, the two-parse
algorithm substantially outperforms alterna-
tive synchronous parsing strategies, making it
efficient enough to be utilized without resort-
ing to a pruned search.

1 Introduction

Synchronous context free grammars (SCFGs) gener-
alize monolingual context-free grammars to gener-
ate strings concurrently in pairs of languages (Lewis
and Stearns, 1968) in much the same way that fi-
nite state transducers (FSTs) generalize finite state
automata (FSAs).1 Synchronous parsing is the prob-
lem of finding the best derivation, or forest of deriva-
tions, of a source and target sentence pair 〈f, e〉 under
an SCFG, G.2 Solving this problem is necessary for
several applications, for example, optimizing how
well an SCFG translation model fits parallel train-
ing data. Wu (1997) describes a bottom-up O(n6)
synchronous parsing algorithm for ITGs, a binary
SCFG with a restricted form. For general grammars,
the situation is even worse: the problem has been
shown to be NP-hard (Satta and Peserico, 2005).
Even if we restrict ourselves to binary ITGs, the

∗This work was supported in part by the GALE program of
DARPA, Contract No. HR0011-06-2-001. The author wishes
to thank Philip Rensik, Adam Lopez, Phil Blunsom, and Jason
Eisner for helpful discussions.

1SCFGs have enjoyed a resurgence in popularity as the for-
mal basis for a number of statistical translation systems, e.g.
Chiang (2007). However, translation requires only the manipu-
lation of SCFGs using monolingual parsing algorithms.

2It is assumed that n = |f| ≈ |e|.

O(n6) run-time makes large-scale learning applica-
tions infeasible. The usual solution is to use a heuris-
tic search that avoids exploring edges that are likely
(but not guaranteed) to be low probability (Zhang et
al., 2008; Haghighi et al., 2009). In this paper, we
derive an alternative synchronous parsing algorithm
starting from a conception of parsing with SCFGs as
a composition of binary relations. This enables us
to factor the synchronous parsing problem into two
successive monolingual parses. Our algorithm runs
more efficiently than O(n6) with many grammars
(including those that required using heuristic search
with other parsers), making it possible to take ad-
vantage of synchronous parsing without developing
search heuristics; and the SCFGs are not required
to be in a normal form, making it possible to easily
parse with more complex SCFG types.

2 Synchronous parsing

Before presenting our algorithm, we review the
O(n6) synchronous parser for binary ITGs.3

2.1 ITG synchronous parsing algorithm
Wu (1997) describes a bottom-up synchronous pars-
ing algorithm that can be understood as a generaliza-
tion of the CKY algorithm. CKY defines a table con-
sisting of n2 cells, with each cell corresponding to a
span [i, j] in the input sentence; and the synchronous
variant defines a table in 4 dimensions, with cells
corresponding to a source span [s, t] and a target
span [u, v]. The bottom of the chart is initialized
first, and pairs of items are combined from bottom
to top. Since combining items from the n4 cells in-
volves considering two split points (one source, one
target), it is not hard to see that this algorithm runs
in time O(n6).

3Generalizing the algorithm to higher rank grammars is pos-
sible (Wu, 1997), as is converting a grammar to a weakly equiv-
alent binary form in some cases (Huang et al., 2009).

263



2.2 Parsing, intersection, and composition

We motivate an alternative conception of the syn-
chronous parsing problem as follows. It has long
been appreciated that monolingual parsing computes
the intersection of an FSA and a CFG (Bar-Hillel et
al., 1961; van Noord, 1995). That is, if S is an FSA
encoding some sentence s, intersection of S with a
CFG, G, results in a parse forest which contains all
and only derivations of s, that is L(S) ∩ L(G) ∈
{{s}, ∅}.4 Crucially for our purposes, the resulting
parse forest is also itself a CFG.5 Figure 1 illus-
trates, giving two equivalent representations of the
forest S∩G, once as a directed hypergraph and once
as a CFG. While S ∩ G appears similar to G, the
non-terminals (NTs) of the resulting CFG are a cross
product of pairs of states from S and NTs from G.6

Two parses are better than one (for synchronous parsing)

Chris Dyer
UMIACS Laboratory for Computational Linguistics and Information Processing

Department of Linguistics
University of Maryland, College Park, MD 20742, USA

redpony AT umd.edu

Abstract

We describe an alternative to the well-known
O(n6) synchronous parsing algorithm given
in Wu (1997). Although this algorithm, which
is based on two successive monolingual parses
of the input sentence pair, does not (and prov-
ably can not) improve the worst-case run-
time, its best-case performance is O(n3). We
show that for a number of common syn-
chronous parsing problems, the two-parse al-
gorithm performs efficiently enough to be uti-
lized, without pruning, in iterative learning al-
gorithms that rely on inside-outside inference.
The algorithm has further advantages: prun-
ing strategies that would be difficult to realize
in the original algorithm become feasible, and
certain kinds of discriminative training require
the results of both parses, making this algo-
rithm a natural fit when those training regimes
are required.

1 Introduction

Synchronous context free grammars (SCFGs) gener-
alize traditional context-free grammars to generate
strings concurrently in a pair of languages (Lewis
and Stearns, 1968), in much the same way that fi-
nite state transducers (FSTs) generalize finite state
automata. In recent years, SCFGs have enjoyed
a resurgence in popularity as the formal basis for
several of the best-performing statistical machine
translation systems (Chiang, 2007; Zollmann et al.,
2008). The translation task is a straightforward ma-
nipulation of SCFGs using standard monolingual al-
gorithms. To translate some f (a string of words in
the source language) into the target language, f is

parsed (with a monolingual parser), which, because
of the parallel structure of the rules, induces a forest
of translations in the target language.

Synchronous parsing, which is our focus for the
remainder of this paper, is the problem of finding
the best derivation, or the forest of derivations, of
a source and target sentence pair 〈f, e〉. This forest
is particularly useful in learning problems since it
can be used to compute and optimize statistics about
derivations of parallel training data. In the MT lit-
erature, this task is also known as “constrained de-
coding”. Wu (1997) describes a bottom-up algo-
rithm for constructing this forest given a sentence
pair 〈f, e〉 and grammar G that runs in O(|f|3|e|3)
since we will assume that n = |f| ≈ |e|, the run-
time is O(n6).

1.1 Parsing as composition

We motivate an alternative conception of the syn-
chronous parsing problem as follows. It has long
been appreciated that parsing computes the intersec-
tion of an FSA and a CFG (Bar-Hillel et al., 1961;
van Noord, 1995; Grune and Jacobs, 2008). That
is, parsing an FSA, S, with a CFG, G, results in a
parse forest which contains derivations of strings in
I = L(S) ∩ L(G),1 and which may be ∅. But, it is
helpful to keep in mind that the resulting parse for-
est is also itself a CFG (that exactly derives strings
in I). See Figure ?? for an example.

In the parallel parsing case, it’s helpful to think
in terms of an SCFG representing a context-free re-
lations and parallel parsing as being a composition

1In the familiar case, S is a deterministic linear chain FSA
representing a sentence.

0 1 2 43
i saw the forest

Two parses are better than one (for synchronous parsing)

Chris Dyer
UMIACS Laboratory for Computational Linguistics and Information Processing

Department of Linguistics
University of Maryland, College Park, MD 20742, USA

redpony AT umd.edu

Abstract

We describe an alternative to the well-known
O(n6) synchronous parsing algorithm given
in Wu (1997). Although this algorithm, which
is based on two successive monolingual parses
of the input sentence pair, does not (and prov-
ably can not) improve the worst-case run-
time, its best-case performance is O(n3). We
show that for a number of common syn-
chronous parsing problems, the two-parse al-
gorithm performs efficiently enough to be uti-
lized, without pruning, in iterative learning al-
gorithms that rely on inside-outside inference.
The algorithm has further advantages: prun-
ing strategies that would be difficult to realize
in the original algorithm become feasible, and
certain kinds of discriminative training require
the results of both parses, making this algo-
rithm a natural fit when those training regimes
are required.

1 Introduction

Synchronous context free grammars (SCFGs) gener-
alize traditional context-free grammars to generate
strings concurrently in a pair of languages (Lewis
and Stearns, 1968), in much the same way that fi-
nite state transducers (FSTs) generalize finite state
automata. In recent years, SCFGs have enjoyed
a resurgence in popularity as the formal basis for
several of the best-performing statistical machine
translation systems (Chiang, 2007; Zollmann et al.,
2008). The translation task is a straightforward ma-
nipulation of SCFGs using standard monolingual al-
gorithms. To translate some f (a string of words in
the source language) into the target language, f is

parsed (with a monolingual parser), which, because
of the parallel structure of the rules, induces a forest
of translations in the target language.

Synchronous parsing, which is our focus for the
remainder of this paper, is the problem of finding
the best derivation, or the forest of derivations, of
a source and target sentence pair 〈f, e〉. This forest
is particularly useful in learning problems since it
can be used to compute and optimize statistics about
derivations of parallel training data. In the MT lit-
erature, this task is also known as “constrained de-
coding”. Wu (1997) describes a bottom-up algo-
rithm for constructing this forest given a sentence
pair 〈f, e〉 and grammar G that runs in O(|f|3|e|3)
since we will assume that n = |f| ≈ |e|, the run-
time is O(n6).

1.1 Parsing as composition

We motivate an alternative conception of the syn-
chronous parsing problem as follows. It has long
been appreciated that parsing computes the intersec-
tion of an FSA and a CFG (Bar-Hillel et al., 1961;
van Noord, 1995; Grune and Jacobs, 2008). That
is, parsing an FSA, S, with a CFG, G, results in a
parse forest which contains derivations of strings in
I = L(S) ∩ L(G),1 and which may be ∅. But, it is
helpful to keep in mind that the resulting parse for-
est is also itself a CFG (that exactly derives strings
in I). See Figure ?? for an example.

In the parallel parsing case, it’s helpful to think
in terms of an SCFG representing a context-free re-
lations and parallel parsing as being a composition

1In the familiar case, S is a deterministic linear chain FSA
representing a sentence.

NP VPS

PRNNP

DT NNNP

V NPVP

theDT

aDT

forestNN

treeNN

iPRN

sawV

operation.2

S ∩ G (1)

2 Experiments

Figure 1 plots the average runtime of the algorithm
as a function of the Arabic sentence length on an
Arabic-English phrasal ITG alignment task.

3 Related work

Synchronous parsing has been widely used to com-
pute sufficient statistics for a variety of machine
learning models of synchronous trees; however,
since the naive algorithm is too slow to deal with
sentence sizes, most authors have proposed pruning
techniques. Zhang et al. (2008) suggest tic-tac-toe
pruning, which uses Model 1 posteriors to exclude
ranges of cells from being computed. Blunsom et al.
(2008) do a monolingual parse with of one language
but split the parser states by the string yielded by
the target derivations, pruning any nodes that yield
strings that do not exist in the target. Haghighi et al.
(2009) also describe a pruning heuristic that results
in average case runtime of O(n3).

References
Y. Bar-Hillel, M. Perles, and E. Shamir. 1961. On for-

mal properties of simple phrase structure grammars.
Zeitschrift für Phonetik, Sprachwissenschaft und Kom-
munikationsforschung, 14:143–172.

Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008.
A discriminative latent variable model for statistical
machine translation. In Proceedings of ACL-HTL.

David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201–228.

D. Grune and C.J. H. Jacobs. 2008. Parsing as intersec-
tion. Parsing Techniques, pages 425–442.

Aria Haghighi, John Blitzer, John DeNero, and Dan
Klein. 2009. Better word alignments with supervised
ITG models. In Proceedings of the Joint Conference
of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language
Processing of the AFNLP, pages 923–931, August.

P. M. Lewis, II and R. E. Stearns. 1968. Syntax-directed
transduction. J. ACM, 15(3):465–488.

2For a discussion of the equivalence of composition and
intersection in finite-state objects, refer to Mohri (2009). Al-
though necessity forces us to use different algorithms to realize
composition, the relationship still holds at the context-free level.

Figure 1: Synchronous parser runtime as a function of
(Arabic) sentence length on an Arabic-English corpus us-
ing a phrasal ITG.

Mehryar Mohri. 2009. Weighted automata algorithms.
In Manfred Droste, Werner Kuich, and Heiko Vogler,
editors, Handbook of Weighted Automata, Mono-
graphs in Theoretical Computer Science, pages 213–
254. Springer.

Gertjan van Noord. 1995. The intersection of finite state
automata and definite clause grammars. In Proceed-
ings of the 33rd Annual Meeting of the Assocation
for Computational Linguistics, pages 159–165, Cam-
bridge, MA.

Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–404, Sep.

Hao Zhang, Chris Quirk, Robert C. Moore, and
Daniel Gildea. 2008. Bayesian learning of non-
compositional phrases with synchronous parsing. In
Proceedings of ACL.

Andreas Zollmann, Ashish Venugopal, Franz Och, and
Jay Ponte. 2008. A systematic comparison of phrase-
based, hierarchical and syntax-augmented statistical
mt. In Proc. of 22nd International Conference on
Computational Linguistics (Coling), Manchester, U.K.

2DT3 3NN4

2NP4

1V2

1VP4

0S4

0NP1

0PRN1

i saw the forest

0NP1 1VP40S4

0PRN10NP1

2DT3 3NN42NP4

1V2 2NP41VP4

the2DT3
forest3NN4
i0PRN1
saw1V2

(a) (b)

Figure 1: A CFG, G, an FSA, S, encoding a sentence, and
two equivalent representations of the parse forest S ∩ G,
(a) as a directed hypergraph and (b) as a CFG.

When dealing with SCFGs, rather than intersec-

4L(x) denotes the set of strings generated by the gram-
mar/automaton x. In future mentions of intersection and com-
position operations, this will be implicit.

5The forest grammar derives only s, but using possibly many
derivations.

6Each pair of states from the FSA corresponds to a span [i, j]
in a CKY table.

tion, parsing computes a related operation, composi-
tion.7 The standard MT decoding-by-parsing task
can be understood as computing the composition
of an FST,8 F , which encodes the source sentence
f with the SCFG, G, representing the translation
model. The result is the translation forest, F ◦ G,
which encodes all translations of f licensed by the
translation model. While G can generate a poten-
tially infinite set of strings in the source and target
languages, F ◦ G generates only f in the source lan-
guage (albeit with possibly infinitely many deriva-
tions), but any number of different strings in the tar-
get language. It is not hard to see that a second com-
position operation of an FST, E, encoding the target
string e with the e-side of F ◦G (again using a mono-
lingual parsing algorithm), will result in a parse for-
est that exactly derives 〈f, e〉, which is the goal of
synchronous composition. Figure 2 shows an exam-
ple. In F ◦ G ◦ E the NTs (nodes) are the cross
product of pairs of states from E, the NTs from G,
and pairs of states in F .

Thus, synchronous parsing is the task of comput-
ing F ◦ G ◦E. Since composition is associative, we
can compute this quantity either as (F ◦ G) ◦ E or
F ◦ (G ◦E). Alternatively, we can use an algorithm
that performs 3-way composition directly.

2.3 The two-parse algorithm9

The two-parse algorithm refers to performing a syn-
chronous parse by computing either (F ◦ G) ◦ E or
F ◦ (G ◦ E). Each composition operation is carried
out using a standard monolingual parsing algorithm,
such as Earley’s or CKY. In the experiments below,
since we use �-free grammars, we use a variant of
CKY for unrestricted CFGs (Chiang, 2007).

Once the first composition is done, the resulting
parse forest must be converted into a CFG repre-
sentation that the second parser can utilize. This is
straightforward to do: each node becomes a unique
non-terminal symbol, with its incoming edges cor-
responding to different ways of rewriting it. Tails
of edges are non-terminal variables in the RHS of
these rewrites. A single bottom-up traversal of the
forest is sufficient to perform the conversion. Since

7Intersection is a special case of composition where the in-
put and output labels on the transducers are identical (Mohri,
2009).

8FSTs used to represent the source and target sentences have
identical input and output labels on every transition.

9Satta (submitted) has independently derived this algorithm.

264



Two parses are better than one (for synchronous parsing)

Chris Dyer
UMIACS Laboratory for Computational Linguistics and Information Processing

Department of Linguistics
University of Maryland, College Park, MD 20742, USA

redpony AT umd.edu

Abstract

We describe an alternative to the well-known
O(n6) synchronous parsing algorithm given
in Wu (1997). Although this algorithm, which
is based on two successive monolingual parses
of the input sentence pair, does not (and prov-
ably can not) improve the worst-case run-
time, its best-case performance is O(n3). We
show that for a number of common syn-
chronous parsing problems, the two-parse al-
gorithm performs efficiently enough to be uti-
lized, without pruning, in iterative learning al-
gorithms that rely on inside-outside inference.
The algorithm has further advantages: prun-
ing strategies that would be difficult to realize
in the original algorithm become feasible, and
certain kinds of discriminative training require
the results of both parses, making this algo-
rithm a natural fit when those training regimes
are required.

1 Introduction

Synchronous context free grammars (SCFGs) gener-
alize traditional context-free grammars to generate
strings concurrently in a pair of languages (Lewis
and Stearns, 1968), in much the same way that fi-
nite state transducers (FSTs) generalize finite state
automata. In recent years, SCFGs have enjoyed
a resurgence in popularity as the formal basis for
several of the best-performing statistical machine
translation systems (Chiang, 2007; Zollmann et al.,
2008). The translation task is a straightforward ma-
nipulation of SCFGs using standard monolingual al-
gorithms. To translate some f (a string of words in
the source language) into the target language, f is

parsed (with a monolingual parser), which, because
of the parallel structure of the rules, induces a forest
of translations in the target language.

Synchronous parsing, which is our focus for the
remainder of this paper, is the problem of finding
the best derivation, or the forest of derivations, of
a source and target sentence pair 〈f, e〉. This forest
is particularly useful in learning problems since it
can be used to compute and optimize statistics about
derivations of parallel training data. In the MT lit-
erature, this task is also known as “constrained de-
coding”. Wu (1997) describes a bottom-up algo-
rithm for constructing this forest given a sentence
pair 〈f, e〉 and grammar G that runs in O(|f|3|e|3)
since we will assume that n = |f| ≈ |e|, the run-
time is O(n6).

1.1 Parsing as composition

We motivate an alternative conception of the syn-
chronous parsing problem as follows. It has long
been appreciated that parsing computes the intersec-
tion of an FSA and a CFG (Bar-Hillel et al., 1961;
van Noord, 1995; Grune and Jacobs, 2008). That
is, parsing an FSA, S, with a CFG, G, results in a
parse forest which contains derivations of strings in
I = L(S) ∩ L(G),1 and which may be ∅. But, it is
helpful to keep in mind that the resulting parse for-
est is also itself a CFG (that exactly derives strings
in I). See Figure ?? for an example.

In the parallel parsing case, it’s helpful to think
in terms of an SCFG representing a context-free re-
lations and parallel parsing as being a composition

1In the familiar case, S is a deterministic linear chain FSA
representing a sentence.

< X , X >S

< X b , c X >X

< X b , X d >X

< a , c >X

< a , d >X
E

0 1 2
a b

F

0 1 2
c d

Figure 1: A CFG, G, an FSA, S, encoding a sentence,
and two reprsentations of the parse forest S ∩ G, (a) as
a directed hypergraph and (b) as a context-free rewrite
system.

(NTs) of the resulting CFG are a cross product of
pairs of states in the FSA and the NTs in the original
grammar.

When dealing with SCFGs, rather than intersec-
tion, parsing computes a related operation, compo-
sition.2 The standard MT decoding-by-parsing task
can be understood as computing the composition of
an FST, F , encoding a source sentence f with the
SCFG, G, representing the translation model. The
result is the so-called translation forest, F ◦G, which
encodes all translations of f licensed by the transla-
tion model. Now observe that while G can generate
a potentially infinite set of strings in both source lan-
guage and target language, F ◦G (as an SCFG) gen-
erates only f, albeit possibly via several derivations,
but different translations e. It is not hard to see that
a second composition operation with an E encoding

2Intersection is a special case of composition where the in-
put and output labels on the transducers are identical (Mohri,
2009).

a string e in the target will result in the will result in
a parse forest that exactly derives 〈f, e〉, which is the
goal of synchronous composition.

Thus, in synchronous parsing, we seek to com-
pute F ◦G ◦E. Since composition is associative, we
can compute this quantity either as (F ◦ G) ◦ E or
F ◦ (G ◦ E). Alternatively, we can use an algorithm
that performs 3-way composition directly, such as
Wu’s algorithm.3

F ◦ G (1)

1.2 Analysis

Monolingual parsing is commonly thought of as a
worst-case O(n3) algorithm, even the known algo-
rithms do have a grammar term that can contribute
significantly. However, since the grammar that a
parser will employ is generally assumed to be fixed,

2 Experiments

Figure 2 plots the average runtime of the algorithm
as a function of the Arabic sentence length on an
Arabic-English phrasal ITG alignment task.

3 Related work

Synchronous parsing has been widely used to com-
pute sufficient statistics for a variety of machine
learning models of synchronous trees; however,
since the naive algorithm is too slow to deal with
sentence sizes, most authors have proposed pruning
techniques. Zhang et al. (2008) suggest tic-tac-toe
pruning, which uses Model 1 posteriors to exclude
ranges of cells from being computed. Blunsom et al.
(2008) do a monolingual parse with of one language
but split the parser states by the string yielded by
the target derivations, pruning any nodes that yield
strings that do not exist in the target. Haghighi et al.
(2009) also describe a pruning heuristic that results
in average case runtime of O(n3).

References

Cyril Allauzen and Mehryar Mohri. 2008. 3-way
composition of weighted finite-state transducers. In

3Three-way composition algorithms that operate only on
FSTs have also been developed (Allauzen and Mohri, 2008).

a : c a : d

0X1

0S2

0X1 b : 0X1 d0X1 b : c 0X1

< 0X1 b , c 0X1 >0S2
< 0X1 b , 0X1 d >0S2
< a , c >0X1
< a , d >0X1

Figure 1: A CFG, G, an FSA, S, encoding a sentence,
and two reprsentations of the parse forest S ∩ G, (a) as
a directed hypergraph and (b) as a context-free rewrite
system.

(NTs) of the resulting CFG are a cross product of
pairs of states in the FSA and the NTs in the original
grammar.

When dealing with SCFGs, rather than intersec-
tion, parsing computes a related operation, compo-
sition.2 The standard MT decoding-by-parsing task
can be understood as computing the composition of
an FST, F , encoding a source sentence f with the
SCFG, G, representing the translation model. The
result is the so-called translation forest, F ◦G, which
encodes all translations of f licensed by the transla-
tion model. Now observe that while G can generate
a potentially infinite set of strings in both source lan-
guage and target language, F ◦G (as an SCFG) gen-
erates only f, albeit possibly via several derivations,
but different translations e. It is not hard to see that
a second composition operation with an E encoding

2Intersection is a special case of composition where the in-
put and output labels on the transducers are identical (Mohri,
2009).

a string e in the target will result in the will result in
a parse forest that exactly derives 〈f, e〉, which is the
goal of synchronous composition.

Thus, in synchronous parsing, we seek to com-
pute F ◦G ◦E. Since composition is associative, we
can compute this quantity either as (F ◦ G) ◦ E or
F ◦ (G ◦ E). Alternatively, we can use an algorithm
that performs 3-way composition directly, such as
Wu’s algorithm.3

F ◦ G ◦ E (1)

1.2 Analysis

Monolingual parsing is commonly thought of as a
worst-case O(n3) algorithm, even the known algo-
rithms do have a grammar term that can contribute
significantly. However, since the grammar that a
parser will employ is generally assumed to be fixed,

2 Experiments

Figure 2 plots the average runtime of the algorithm
as a function of the Arabic sentence length on an
Arabic-English phrasal ITG alignment task.

3 Related work

Synchronous parsing has been widely used to com-
pute sufficient statistics for a variety of machine
learning models of synchronous trees; however,
since the naive algorithm is too slow to deal with
sentence sizes, most authors have proposed pruning
techniques. Zhang et al. (2008) suggest tic-tac-toe
pruning, which uses Model 1 posteriors to exclude
ranges of cells from being computed. Blunsom et al.
(2008) do a monolingual parse with of one language
but split the parser states by the string yielded by
the target derivations, pruning any nodes that yield
strings that do not exist in the target. Haghighi et al.
(2009) also describe a pruning heuristic that results
in average case runtime of O(n3).

References

Cyril Allauzen and Mehryar Mohri. 2008. 3-way
composition of weighted finite-state transducers. In

3Three-way composition algorithms that operate only on
FSTs have also been developed (Allauzen and Mohri, 2008).

0S2
0 2

0X1 0X1
1 2 0 1

0X1 b : c 0X1 0X1 b : 0X1 d

a : d a : c

0 1 0 11 2 1 2

Figure 2: An SCFG, G, two FSAs, E and F , and two
equivalent representations of F ◦ G. The synchronous
parse forest of the pair 〈ab, cd〉 with G is given under F ◦
G ◦ E.

our parser operates more efficiently with a deter-
minized grammar, we left-factor the grammar dur-
ing this traversal as well.

Analysis. Monolingual parsing runs in worst case
O(|G| · n3) time, where n is the length of the in-
put being parsed and |G| is a measure of the size
of the grammar (Graham et al., 1980). Since the
grammar term is constant for most typical parsing
applications, it is generally not considered carefully;
however, in the two-parse algorithm, the size of the
grammar term for the second parse is not |G| but
|F ◦ G|, which clearly depends on the size of the in-
put F ; and so understanding the impact of this term
is key to understanding the algorithm’s run-time.

If G is an �-free SCFG with non-terminals N and
maximally two NTs in a rule’s right hand side, and
n is the number of states in F (corresponding to the
number of words in the f in a sentence pair 〈f, e〉),
then the number of nodes in the parse forest F ◦ G
will be O(|N | · n2). This can be shown easily since
by stipulation, we are able to use CKY+ to per-
form the parse, and there will be maximally as many

nodes in the forest as there are cells in the CKY chart
times the number of NTs. The number of edges will
be O(|N | · n3), which occurs when every node can
be derived from all possible splits. This bound on
the number of edges implies that |F ◦G| ∈ O(n3).10
Therefore, the worst case run-time of the two-parse
algorithm isO(|N | ·n3 ·n3+ |G|·n3) = O(|N | ·n6),
the same as the bound on the ITG algorithm. We
note that while the ITG algorithm requires that the
SCFGs be rank-2 and in a normal form, the two-
parse algorithm analysis holds as long as the gram-
mars are rank-2 and �-free.11

3 Experiments

We now describe two different synchronous parsing
applications, with different classes of SCFGs, and
compare the performance of the two-parse algorithm
with that of previously used algorithms.

Phrasal ITGs. Here we compare performance of
the two-parse algorithm and the O(n6) ITG parsing
algorithm on an Arabic-English phrasal ITG align-
ment task. We used a variant of the phrasal ITG de-
scribed by Zhang et al. (2008).12 Figure 3 plots the
average run-time of the two algorithms as a function
of the Arabic sentence length. The two-parse ap-
proach is far more efficient. In total, aligning the 80k
sentence pairs in the corpus completed in less than
4 hours with the two-parse algorithm but required
more than 1 week with the baseline algorithm.13

“Hiero” grammars. An alternative approach to
computing a synchronous parse forest is based on
cube pruning (Huang and Chiang, 2007). While
more commonly used to integrate a target m-gram
LM during decoding, Blunsom et al. (2008), who re-
quired synchronous parses to discriminatively train

10How tight these bounds are depends on the ambiguity in
the grammar w.r.t. the input: to generate n3 edges, every item
in every cell must be derivable by every combination of its sub-
spans. Most grammars are substantially less ambiguous.

11Since many widely used SCFGs meet these criteria, in-
cluding hierarchical phrase-based translation grammars (Chi-
ang, 2007), SAMT grammars (Zollmann and Venugopal, 2006),
and phrasal ITGs (Zhang et al., 2008), a detailed analysis of �-
containing and higher rank grammars is left to future work.

12The restriction that phrases contain exactly a single align-
ment point was relaxed, resulting in much larger and more am-
biguous grammars than those used in the original work.

13A note on implementation: our ITG aligner was minimal; it
only computed the probability of the sentence pair using the in-
side algorithm. With the two-parse aligner, we stored the com-
plete forest during both the first and second parses.

265



10 20 30 40 50 60
0

20

40

60

Wu (1997)
this work

Figure 3: Average synchronous parser run-time (in sec-
onds) as a function of Arabic sentence length (in words).

an SCFG translation model, repurposed this algo-
rithm to discard partial derivations during transla-
tion of f if the derivation yielded a target m-gram
not found in e (p.c.). We replicated their BTEC
Chinese-English baseline system and compared the
speed of their ‘cube-parsing’ technique and our two-
parse algorithm.14 The SCFG used here was ex-
tracted from a word-aligned corpus, as described in
Chiang (2007).15 The following table compares the
average per sentence synchronous parse time.

Algorithm avg. run-time (sec)
Blunsom et al. (2008) 7.31

this work 0.20

4 Discussion

Thinking of synchronous parsing as two composi-
tion operations has both conceptual and practical
benefits. The two-parse strategy can outperform
both the ITG parsing algorithm (Wu, 1997), as well
as the ‘cube-parsing’ technique (Blunsom et al.,
2008). The latter result points to a connection with
recent work showing that determinization of edges
before LM integration leads to fewer search errors
during decoding (Iglesias et al., 2009).

Our results are somewhat surprising in light of
work showing that 3-way composition algorithms
for FSTs operate far more efficiently than perform-
ing successive pairwise compositions (Allauzen and
Mohri, 2009). This is certainly because the 3-way
algorithm used here (the ITG algorithm) does an ex-

14To the extent possible, the two experiments were carried
out using the exact same code base, which was a C++ imple-
mentation of an SCFG-based decoder.

15Because of the mix of terminal and non-terminal symbols,
such grammars cannot be used by the ITG synchronous parsing
algorithm.

haustive search over all n4 span pairs without aware-
ness of any top-down constraints. This suggests that
faster composition algorithms that incorporate top-
down filtering may still be discovered.

References
C. Allauzen and M. Mohri. 2009. N-way composition of

weighted finite-state transducers. International Jour-
nal of Foundations of Comp. Sci., 20(4):613–627.

Y. Bar-Hillel, M. Perles, and E. Shamir. 1961. On for-
mal properties of simple phrase structure grammars.
Zeitschrift für Phonetik, Sprachwissenschaft und Kom-
munikationsforschung, 14:143–172.

P. Blunsom, T. Cohn, and M. Osborne. 2008. Probalistic
inference for machine translation. In EMNLP.

D. Chiang. 2007. Hierarchical phrase-based translation.
Computational Linguistics, 33(2):201–228.

S. L. Graham, W. L. Ruzzo, and M. Harrison. 1980. An
improved context-free recognizer. ACM Trans. Pro-
gram. Lang. Syst., 2(3):415–462.

A. Haghighi, J. Blitzer, J. DeNero, and D. Klein. 2009.
Better word alignments with supervised ITG models.
In Proc. of ACL/IJCNLP, pages 923–931.

L. Huang and D. Chiang. 2007. Forest rescoring: Faster
decoding with integrated language models. In ACL.

L. Huang, H. Zhang, D. Gildea, and K. Knight. 2009.
Binarization of synchronous context-free grammars.
Computational Linguistics, 35(4).

G. Iglesias, A. de Gispert, E. R. Banga, and W. Byrne.
2009. Hierarchical phrase-based translation with
weighted finite state transducers. In Proc. NAACL.

P. M. Lewis, II and R. E. Stearns. 1968. Syntax-directed
transduction. J. ACM, 15(3):465–488.

M. Mohri. 2009. Weighted automata algorithms. In
M. Droste, W. Kuich, and H. Vogler, editors, Hand-
book of Weighted Automata, Monographs in Theoreti-
cal Computer Science, pages 213–254. Springer.

G. Satta and E. Peserico. 2005. Some computational
complexity results for synchronous context-free gram-
mars. In Proceedings of NAACL.

G. Satta. submitted. Translation algorithms by means of
language intersection.

G. van Noord. 1995. The intersection of finite state au-
tomata and definite clause grammars. In Proc. of ACL.

D. Wu. 1997. Stochastic inversion transduction gram-
mars and bilingual parsing of parallel corpora. Com-
putational Linguistics, 23(3):377–404.

H. Zhang, C. Quirk, R. C. Moore, and D. Gildea. 2008.
Bayesian learning of non-compositional phrases with
synchronous parsing. In Proceedings of ACL.

A. Zollmann and A. Venugopal. 2006. Syntax aug-
mented machine translation via chart parsing. In Proc.
of the Workshop on SMT.

266


