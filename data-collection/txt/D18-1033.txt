




































Cross-lingual Lexical Sememe Prediction


Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 358–368
Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics

358

Cross-lingual Lexical Sememe Prediction
Fanchao Qi1∗ , Yankai Lin1∗, Maosong Sun1,2† , Hao Zhu1, Ruobing Xie3, Zhiyuan Liu1

1Department of Computer Science and Technology, Tsinghua University
Institute for Artificial Intelligence, Tsinghua University

State Key Lab on Intelligent Technology and Systems, Tsinghua University
2Jiangsu Collaborative Innovation Center for Language Ability, Jiangsu Normal University

3Search Product Center, WeChat Search Application Department, Tencent, China
{qfc17, linyk14}@mails.tsinghua.edu.cn, sms@tsinghua.edu.cn

zhuhao15@mails.tsinghua.edu.cn
xrbsnowing@163.com, liuzy@tsinghua.edu.cn

Abstract

Sememes are defined as the minimum seman-
tic units of human languages. As impor-
tant knowledge sources, sememe-based lin-
guistic knowledge bases have been widely
used in many NLP tasks. However, most lan-
guages still do not have sememe-based lin-
guistic knowledge bases. Thus we present
a task of cross-lingual lexical sememe pre-
diction, aiming to automatically predict se-
memes for words in other languages. We
propose a novel framework to model corre-
lations between sememes and multi-lingual
words in low-dimensional semantic space for
sememe prediction. Experimental results on
real-world datasets show that our proposed
model achieves consistent and significant im-
provements as compared to baseline methods
in cross-lingual sememe prediction. The codes
and data of this paper are available at https:
//github.com/thunlp/CL-SP.

1 Introduction

Words are regarded as the smallest meaningful unit
of speech or writing that can stand by themselves
in human languages, but not the smallest indivisi-
ble semantic unit of meaning. That is, the meaning
of a word can be represented as a set of semantic
components. For example, “Man = human + male
+ adult” and “Boy = human +male + child”. In lin-
guistics, the minimum semantic unit of meaning is
named sememe (Bloomfield, 1926). Some people
believe that semantic meanings of concepts such as
words can be composed of a limited closed set of
sememes. And sememes can help us comprehend
human languages better.
Unfortunately, the lexical sememes of words are

not explicit in most human languages. Hence, peo-
ple construct sememe-based linguistic knowledge

∗ Indicates equal contribution
† Corresponding author

apple

apple (brand)apple (fruit)

computerfruit

 
PatternValue able bring SpecificBrand

word

sense

sememe

Figure 1: An example of HowNet.

bases (KBs) via manually annotating every words
with a pre-defined closed set of sememes. HowNet
(Dong and Dong, 2003) is one of the most well-
known sememe-based linguistic KBs. Different
fromWordNet (Miller, 1995) which focuses on the
relations between senses, it annotates each word
with one or more relevant sememes. As illustrated
in Fig. 1, the word apple has two senses includ-
ing apple (fruit) and apple (brand) in HowNet.
The sense apple (fruit) has one sememe fruit, and
the sense apple (brand) has five sememes includ-
ing computer, PatternValue, able, bring and Speci-
ficBrand. There exist about 2, 000 sememes and
over 100 thousand labeled Chinese and English
words in HowNet. HowNet has been widely used
in various NLP applications such as word simi-
larity computation (Liu and Li, 2002), word sense
disambiguation (Zhang et al., 2005), question clas-
sification (Sun et al., 2007) and sentiment classifi-
cation (Dang and Zhang, 2010).
However, most languages do not have such

sememe-based linguistic KBs, which prevents us
understanding and utilizing human languages to
a greater extent. Therefore, it is important to
build sememe-based linguistic KBs for various
languages. Manual construction for sememe-
based linguistic KBs requires efforts of many
linguistic experts, which is time-consuming and

https://github.com/thunlp/CL-SP
https://github.com/thunlp/CL-SP


359

labor-intensive. For example, the construction of
HowNet has cost lots of Chinese linguistic experts
more than 10 years.
To address the issue of the high labor cost of

manual annotation, we propose a new task, cross-
lingual lexical sememe prediction (CLSP) which
aims to automatically predict lexical sememes for
words in other languages. CLSP aims to assist
in the annotation of linguistic experts. There are
two critical challenges for CLSP: (1) There is not
a consistent one-to-one match between words in
different languages. For example, English word
“beautiful” can refer to Chinese words of either
“美丽” or “漂亮”. Hence, we cannot simply trans-
late HowNet into another language. And how to
recognize the semantic meaning of a word in other
languages becomes a critical problem. (2) Since
there is a gap between the semantic meanings of
words and sememes, we need to build semantic
representations for words and sememes to capture
the semantic relatedness between them.
To tackle these challenges, in this paper, we pro-

pose a novel model for CLSP, which aims to trans-
fer sememe-based linguistic KBs from source lan-
guage to target language. Ourmodel contains three
modules including (1) monolingual word embed-
ding learning which is intended for learning se-
mantic representations of words for source and tar-
get languages respectively; (2) cross-lingual word
embedding alignment which aims to bridge the gap
between the semantic representations of words in
two languages; (3) sememe-based word embed-
ding learning whose objective is to incorporate se-
meme information into word representations. For
simplicity, we do not consider the hierarchy infor-
mation in HowNet in this paper.
In experiments, we take Chinese as source lan-

guage and English as target language to show the
effectiveness of our model. Experimental results
show that our proposed model could effectively
predict lexical sememes for words with differ-
ent frequencies in other languages. Our model
also has consistent improvements on two auxiliary
experiments including bilingual lexicon induction
and monolingual word similarity computation by
jointly learning the representations of sememes,
words in source and target languages.

2 Related Work

Since HowNet was published (Dong and Dong,
2003), it has attracted wide attention of re-

searchers. Most of related works focus on apply-
ing HowNet to specific NLP tasks (Liu and Li,
2002; Zhang et al., 2005; Sun et al., 2007; Dang
and Zhang, 2010; Fu et al., 2013; Niu et al., 2017;
Zeng et al., 2018; Gu et al., 2018). To the best of
our knowledge, only Xie et al. (2017) and Jin et al.
(2018) conduct studies of augmenting HowNet by
recommending sememes for new words. How-
ever, both of the two works are aimed to recom-
mend sememes for monolingual words and not ap-
plicable to cross-lingual circumstance. Accord-
ingly, our work is the first effort to automatically
perform cross-lingual sememe prediction to enrich
sememe-based linguistic KBs.
Our novel model adopts the method of word

representation learning (WRL). Recent years have
witnessed great advances in WRL. Models like
Skip-gram, CBOW (Mikolov et al., 2013a) and
GloVe (Pennington et al., 2014) are immensely
popular and achieve remarkable performance in
many NLP tasks. However, most WRL meth-
ods learn distributional information of words
from large corpora while the valuable information
contained in semantic lexicons are disregarded.
Therefore, some works try to inject semantic infor-
mation of KBs intoWRL (Faruqui et al., 2015; Liu
et al., 2015; Mrkšic et al., 2016; Bollegala et al.,
2016). Nevertheless, these works are all applied
to word-based KBs such as WordNet, few works
pay attention to how to incorporate the knowledge
from sememe-based linguistic KBs.
There also have been plenty of studies work-

ing on cross-lingual WRL (Upadhyay et al., 2016;
Ruder, 2017). Most of them require parallel cor-
pora (Zou et al., 2013; AP et al., 2014; Her-
mann and Blunsom, 2014; Kočiskỳ et al., 2014;
Gouws et al., 2015; Luong et al., 2015; Coulmance
et al., 2015). Some of them adopt unsupervised
or weakly supervised methods (Mikolov et al.,
2013b; Vulić and Moens, 2015; Conneau et al.,
2017; Artetxe et al., 2017). There are also some
works using a seed lexicon as the cross-lingual sig-
nal (Dinu et al., 2014; Faruqui and Dyer, 2014;
Lazaridou et al., 2015; Shi et al., 2015; Lu et al.,
2015; Gouws et al., 2015; Wick et al., 2016; Am-
mar et al., 2016; Duong et al., 2016; Vulić and Ko-
rhonen, 2016).
In terms of our cross-lingual sememe prediction

task, parallel data-based bilingual WRL methods
are unsuitable because most language pairs have
no large parallel corpora. Besides, unsupervised



360

methods are not appropriate either as they are gen-
erally hard to learn high-quality bilingual word
embeddings. Therefore, we choose the seed lex-
icon method in our model, and further introduce
matching mechanism that is inspired by Zhang
et al. (2017) to enhance its performance.

3 Methodology

In this section, we introduce our novel model for
CLSP. Here we define the language with sememe
annotations as source language and the language
without sememe annotations as target language.
The main idea of our model is to learn word em-
beddings of source and target languages jointly
in a unified semantic space, and then predict se-
memes for words in target language according
to the words with similar semantic meanings in
source language.
Ourmethod consists of three parts: monolingual

word representation learning, cross-lingual word
embedding alignment and sememe-based word
representation learning. Hence, we define the ob-
jective function of our method corresponding to
the three parts:

L = Lmono + Lcross + Lsememe. (1)

Here, the monolingual term Lmono is designed for
learning monolingual word embeddings from non-
parallel corpora for source and target languages re-
spectively. The cross-lingual term Lcross aims to
align cross-lingual word embeddings in a unified
semantic space. And Lsememe can draw sememe
information into word representation learning and
conduce to better word embeddings for sememe
prediction. In the following subsections, we intro-
duce the three parts in detail.

3.1 Monolingual Word Representation
Monolingual word representation is responsible
for explaining regularities in monolingual corpora
of source and target languages. Since the two cor-
pora are non-parallel,Lmono comprises twomono-
lingual sub-models that are independent of each
other:

Lmono = LSmono + LTmono, (2)

where the superscripts S and T denote source and
target languages respectively.
As a common practice, we choose the well es-

tablished Skip-gram model to obtain monolingual

word embeddings. Skip-gram model is aimed at
maximizing the predictive probability of context
words conditioned on the centered word. For-
mally, taking the source side for example, given a
trainingword sequence {wS1 , · · · , wSn}, Skip-gram
model intends to minimize:

LSmono = −
n−K∑

c=K+1

∑
−K≤k≤K,k ̸=0

logP (wSc+k|wSc ),

(3)
where K is the size of the sliding window.
P (wSc+k|wSc ) stands for the predictive probability
of one of the context words conditioned on the cen-
tered word wSc , formalized by the following soft-
max function:

P (wSc+k|wSc ) =
exp(wSc+k · wSc )∑

wSs ∈V S exp(w
S
s · wSc )

, (4)

in which V s indicates the word vocabulary of
source language. LTmono can be formulated simi-
larly.

3.2 Cross-lingual Word Embedding
Alignment

Cross-lingual word embedding alignment aims to
build a unified semantic space for the words in
source and target languages. Inspired by Zhang
et al. (2017), we align the cross-lingual word em-
beddings with signals of a seed lexicon and self-
matching.
Formally, Lcross is composed of two terms in-

cluding alignment by seed lexiconLseed and align-
ment by matching Lmatch:

Lcross = λsLseed + λmLmatch, (5)

where λs and λm are hyperparameters for control-
ling relative weightings of the two terms.

Alignment by Seed Lexicon
The seed lexicon term Lseed encourages word em-
beddings of translation pairs in a seed lexiconD to
be close, which can be achieved via a L2 regular-
izer:

Lseed =
∑

⟨wSs ,wTt ⟩∈D

∥wSs − wTt ∥2, (6)

in which wSs and wTt indicate the words in source
and target languages in the seed lexicon respec-
tively.



361

Alignment by Matching Mechanism
As for the matching process, it is founded on an as-
sumption that each target word should be matched
to a single source word or a special empty word,
and vice versa. The goal of the matching process
is to find the matched source (target) word for each
target (source) word and maximize the matching
probabilities for all the matched word pairs. The
loss of this part can be formulated as:

Lmatch = LT2Smatch + LS2Tmatch, (7)

where LT2Smatch is the term for target-to-source
matching and LS2Tmatch is the term for source-to-
target matching.
Next, we give a detailed explanation of

target-to-source matching, and the source-to-
target matching is defined in the same way.
We first introduce a latent variable mt ∈
{0, 1, · · · , |V S |} (t = 1, 2, · · · , |V T |) for each
target word wTt , where |V S | and |V T | indicate the
vocabulary size of source and target languages re-
spectively. Here, mt specifies the index of the
source word that wTt matches with, and mt = 0
signifies the empty word is matched. Then we
havem = {m1,m2, · · · ,m|V T |}, and can formal-
ize the target-to-source matching term:

LT2Smatch = − logP (CT |CS)

= − log
∑
m

P (CT ,m|CS), (8)

where CT and CS denote the target and source cor-
pus respectively. Here, we simply assume that the
matching processes of target words are indepen-
dent of each other. Therefore, we have:

P (CT ,m|CS) =
∏

wT∈CT
P (wT ,m|CS)

=

|V T |∏
t=1

P (wTt |wSmt)
c(wTt ),

(9)

where wSmt is the source word that w
T
t matches

with, and c(wTt ) is the number of times wTt occurs
in the target corpus.

3.3 Sememe-based Word Representation
Sememe-based word representation is intended for
improving word embeddings for sememe predic-
tion by introducing the information of sememe-
based linguistic KBs of source language. In this
section, we present two methods of sememe-based
word representation.

Word Relation-based Approach
A simple and intuitive method is to let words with
similar sememe annotations tend to have similar
word embeddings, which we name word relation-
based approach. To beginwith, we construct a syn-
onym list from sememe-based linguistic KBs of
source language, where we regard words sharing
a certain number of sememes as synonyms. Next,
we force synonyms to have closer word embed-
dings.
Formally, we let wSi be original word embed-

ding of wSi and ŵSi be its adjusted word embed-
ding. And let Syn(wSi ) denote the synonym set of
word wSi . Then the loss function is:

Lsememe =
∑

wSi ∈V S

[
αi∥wSi − ŵSi ∥2+

∑
wSj ∈Syn(wSi )

βij∥ŵSi − ŵSj ∥2
]
,

(10)

where α and β control the relative strengths
of the two terms. It should be noted that
the idea of forcing similar words to have close
word embeddings is similar to the state-of-the-
art retrofitting approach (Faruqui et al., 2015).
However, retrofitting approach cannot be applied
here because sememe-based linguistic KBs such
as HowNet cannot directly provide its needed syn-
onym list.

Sememe Embedding-based Approach
Simple and effective as the word relation-based
approach is, it cannot make full use of the infor-
mation of sememe-based linguistic KBs because it
disregards the complicated relations between se-
memes and words as well as relations between
different sememes. To address this limitation,
we propose sememe embedding-based approach,
which learns both sememe and word embeddings
jointly.
In this approach, we represent sememes with

distributed vectors as well and place them into the
same semantic space as words. Similar to SPSE
(Xie et al., 2017), which learns sememe embed-
dings by decomposing word-sememe matrix and
sememe-sememe matrix, our method utilizes se-
meme embeddings as regularizers to learn better
word embeddings. Different from SPSE, we do
not use pre-trained word embeddings. Instead, we
learn word embeddings and sememe embeddings
simultaneously.



362

More specifically, from HowNet we can ex-
tract a source-side word-sememe matrixMS with
MSsj = 1 indicating word wSs is annotated with
sememe xj , otherwise MSsj = 0. Hence by fac-
torizing MS , we can define the loss function as:

Lsememe =
∑

wSs ∈V S ,xj∈X

(wSs ·xj+bs+b′j−MSsj)2,

(11)
where bs and b′j are the biases of wSs and xj , and
X denotes sememe set.
In this approach, we obtain word and sememe

embeddings in a unified semantic space. The se-
meme embeddings bear all the information about
the relationships between words and sememes, and
they inject the information into word embeddings.
Therefore, the word embeddings are expected to
be more suitable for sememe prediction.

3.4 Training and Prediction
Training
When training monolingual word embeddings, we
use negative sampling following Mikolov et al.
(2013a). In the optimization of sememe part,
we adopt the iterative updating method following
Faruqui et al. (2015) for word relation-based ap-
proach and stochastic gradient descent (SGD) for
sememe embedding-based approach. As for the
optimization of the seed lexicon term of cross-
lingual part, we also apply SGD.
Nevertheless, due to the existence of the la-

tent variable, optimization of the matching process
in cross-lingual part poses a challenge. We set-
tle on Viterbi EM algorithm to address the prob-
lem. Next, we still take the target-to-source side
as an example and give a detailed description of
the training process using Viterbi EM algorithm.
Viterbi EM algorithm alternates between a

Viterbi E step and a subsequent M step. The
Viterbi E step aims to find the most probable
matched word pairs given the current parameters.
Considering the independence, we can seek the
match for each word individually:

m̂t = argmax
s∈{0,1,··· ,|V S |}

P (wTt |wSs ). (12)

As for the parametrization of the matching prob-
ability, there are various choices. For computa-
tional simplicity, we select cosine similarity:

P (wTt |wSs ) =

{
ϵ if s = 0,
cos(wTt ,wSs ) otherwise,

(13)

where ϵ is a hyperparameter indicating the proba-
bility of matching the empty word. Therefore, the
Viterbi E step computes matching by:

m̃t = argmax
s∈{1,··· ,|V S |}

cos(wTt ,wSs ), (14)

m̂t =

{
m̃t if cos(wTt ,wSm̃t) > ϵ,
0 otherwise.

(15)

From this, we can see that ϵ serves as a threshold
to keep out unreliable matched pairs.
The Viterbi M step performs maximization as if

the latent variable has been observed in the Viterbi
E step. Thus, we can treat the matched pairs as cor-
rect translations, and use a L2 regularizer as well.
Consequently, the M step computes:

(ŵS , ŵT ) = argmax
wS ,wT

M(wS ,wT ), (16)

whereM(wS ,wT ) is defined as:

M(wS ,wT ) = −
|V T |∑
t=1

I[m̃t ̸= 0]
c(wTt )

|CT |
∥wTt −wSm̃t∥

2.

(17)

Prediction
Since we assume that words with similar sememe
annotations are similar and similar words should
have similar sememes, which resembles collabora-
tive filtering in personalized recommendation, we
can recommend sememes for target words accord-
ing to their most similar source words.
Formally, we define the score function

P (xj |wTt ) of sememes xj given a target word wTt
as:

P (xj |wTt ) =
∑

wSs ∈V S
cos(wSs ,wTt )·MSsj ·crs , (18)

where rs is the descending rank of word simi-
larity cos(wSs ,wTt ) for the source word wSs , and
c ∈ (0, 1) is a hyperparameter. Thus, crs is a de-
clined confidence factor which can eliminate the
noise from irrelevant sourcewords and concentrate
on the most similar source words when predicting
sememes for target words.

4 Experiments

In this section, we first introduce the dataset used
in the experiments and then describe the experi-
mental settings of both baseline method and our



363

model. Next, we present the experimental results
of different methods on the task of cross-lingual
lexical sememe prediction. And then we con-
duct detailed analysis and exhaustive case stud-
ies. Following this, we investigate the effect of
word frequency on cross-lingual sememe predic-
tion results. Finally, we perform further quantita-
tive analysis through two sub-tasks including bilin-
gual lexicon induction and word similarity compu-
tation.

4.1 Dataset
We use sememe annotations in HowNet for se-
meme prediction. HowNet annotates sememes
for 118, 346 Chinese words and 104, 025 En-
glish words. The number of sememes in to-
tal is 1, 983. Since some sememes only appear
few times in HowNet, which are expected to be
unimportant, we filter out those low-frequency se-
memes. Specifically, the frequency threshold is 5,
and the final number of distinct sememes used in
our experiments is 1, 400.
In our experiments, Chinese is source language

and English is target language. To learn Chi-
nese and English monolingual word embeddings,
we extract about 2.0G text from Sogou-T1 and
Wikipedia2 respectively. And we use THULAC3
(Li and Sun, 2009) for Chineseword segmentation.
As for seed lexicon, we build it in a similar way

to Zhang et al. (2017). First, we employ Google
Translation API4 to translate the source side (Chi-
nese) vocabulary. Then the translations in the tar-
get language (English) are queried again in the re-
verse direction to translate back to the source lan-
guage (Chinese). And we only keep the translation
pairs whose back translated words match with the
original source words.
In the task of bilingual lexicon induction, we opt

for Chinese-English Translation Lexicon Version
3.05 to be the gold standard. In the task of word
similarity computation, we choose WordSim-240
and WordSim-297 (Jin and Wu, 2012) datasets
for Chinese, and WordSim-353 (Finkelstein et al.,
2002) and SimLex-999 (Hill et al., 2015) datasets
for English to evaluate the performance of our

1Sogou-T is a corpus of web pages provided by a Chinese
commercial search engine. https://www.sogou.com/
labs/resource/t.php

2https://dumps.wikimedia.org/
3http://thulac.thunlp.org/
4https://cloud.google.com/translate/
5https://catalog.ldc.upenn.edu/

LDC2002L27

model. These datasets contain word pairs as well
as human-assigned similarity scores. The word
vectors are evaluated by ranking the word pairs ac-
cording to their cosine similarities, and measuring
Spearman’s rank correlation coefficient with the
human ratings.

4.2 Experimental Settings

We empirically set the dimension of word and se-
meme embeddings to 200. And the embeddings
are all randomly initialized. In monolingual word
embedding learning, we follow the optimal param-
eter settings in Mikolov et al. (2013a). We set the
window sizeK to 5, down-sampling rate for high-
frequency words to 10−5, learning rate to 0.025
and the number of negative samples to 5. In cross-
lingual word embedding alignment, the seed lexi-
con term weight λs is 0.01, and the matching term
weight λm is 1, 000. In sememe-based word repre-
sentation, the number of shared sememes for syn-
onyms in the word relation-based approach is 2.
In the training of matching process, we set ϵ to 0.5
empirically. When predicting sememes for words
in target language, we only consider 100most sim-
ilar source words for each target word and the at-
tenuation parameter c is 0.8. The testing set for
cross-lingual lexical sememe prediction contains
2, 000 randomly selected English words from the
vocabulary.

4.3 Cross-lingual Lexical Sememe Prediction

We evaluate our model by recommending se-
memes for English words. In HowNet, many
words have multiple sememes, so that sememe
prediction can be regarded as a multi-label clas-
sification task. We use mean average precision
(MAP) and F1 score to evaluate the sememe pre-
diction results.
We compare our model that incorporates se-

meme information with word relation-based ap-
proach (named CLSP-WR) and our model which
jointly trains word and sememe embeddings
(named CLSP-SE) with a baseline method BiLex
(Zhang et al., 2017), a bilingual WRL model with-
out incorporation of sememe information. For
BiLex, we use its trained bilingual word embed-
dings to predict sememes for the words in target
language with our sememe prediction approach.
Table 1 exhibits the evaluation results of cross-

lingual lexical sememe prediction with different

https://www.sogou.com/labs/resource/t.php
https://www.sogou.com/labs/resource/t.php
https://dumps.wikimedia.org/
http://thulac.thunlp.org/
https://cloud.google.com/translate/
https://catalog.ldc.upenn.edu/LDC2002L27
https://catalog.ldc.upenn.edu/LDC2002L27


364

Method SeedLexicon
Sememe Prediction

MAP F1 Score

BiLex

1000 27.57 16.08
2000 33.79 22.33
4000 35.78 25.74
6000 38.29 28.71

CLSP-WR

1000 28.12 18.55
2000 33.78 23.64
4000 38.30 27.74
6000 41.23 30.64

CLSP-SE

1000 31.78 18.22
2000 37.70 24.31
4000 40.77 29.33
6000 43.16 32.49

Table 1: Evaluation results of cross-lingual lexi-
cal sememe prediction with different seed lexicon
sizes.

seed lexicon sizes in {1000, 2000, 4000, 60006}.
From the table, we can clearly see that:
(1) Our two models perform much better com-

pared with BiLex in all the seed lexicon size set-
tings. It indicates that incorporating sememe infor-
mation into word embeddings can effectively im-
prove the performance of predicting sememes for
target words. The reason is that both of our models
makewords with similar sememe annotations have
similar embeddings, and as a result, we can recom-
mend better sememes for target words according to
its related source words.
(2) CLSP-SE model achieves better results than

CLSP-WRmodel. The reason is that by represent-
ing sememes in a latent semantic space, CLSP-
SE model can further capture the relatedness be-
tween sememes as well as the relatedness between
words and sememes, which is helpful for model-
ing the representations of those words with similar
sememes.

4.4 Case Study

In case study, we conduct qualitative analysis to
explain the effectiveness of our models with de-
tailed cases. We show two examples of cross-
lingual word sememe prediction, in which we pre-
dict sememes for handcuffs and canoeist. Fig. 2
shows the embeddings of five closest Chinese and
English words to handcuffs and canoeist, and the
vector of each word is projected down to two di-
mensions using t-SNE (Maaten and Hinton, 2008).

6The largest seed lexicon size is 6000 because that is the
maximum number of translation word pairs that we can obtain
from the bilingual corpora.

noose

 (rope)

  (sports star)

canoeist

swimmer

medalist

rower

weightlifter

 (sprint)

 (canoe)

(kayak)

 (kayak)

skier

handcuffs
gunpoint

cuffs

burglars

handcuff

 (handcuffs)

 (screwdriver)
 (shackles)

 (tie)

Figure 2: Two examples of nearest English and
Chinese words.

Table 2 lists top-5 sememes we predict for the
two words and the sememes annotated for each
word in HowNet are in boldface. In the table,
we also exhibit the annotated sememes of the five
closest Chinese words.

In the first example, our model finds the best
translated word for handcuffs in Chinese ⼿ 铐
“handcuffs”, whose sememe annotations are ex-
actly the same as those of handcuffs. In addition,
the second closest Chinese word 镣 铐 “shack-
les” is a synonym for ⼿铐 “handcuffs” and also
has the same sememe annotations. Therefore, our
model predicts all the correct sememes success-
fully. From the prediction results of this exam-
ple, we notice that our model can accurately pre-
dict general sememes like 用具 “tool” and ⼈ “hu-
man”, which are supposed to be difficult to predict.

In the second example, accurate Chinese trans-
lated counterpart for canoeist does not exist, but
our model still hits all the three annotated sememes
in the top-5 predicted sememes. By observing the
most similar Chinese words, we can find that al-
though these words do not have the same meaning
as canoeist, they are related to canoeist in different
aspects. For example, 短跑 “sprint” and canoeist
are both in the sports domain so that they share the
sememes 锻炼 “exercise” and 体育 “sport”. 名将
“sports star” has the meaning of sports star and it
can provide the sememe ⼈ “human” in sememe
prediction. Furthermore, it is noteworthy that our
model predicts 船 “ship” due to the nearest Chi-
nese words 独⽊⾈ “canoe” and 皮艇 “kayak”,
whereas 船 “ship” is not annotated for canoeist in
HowNet. It is obvious that 船 “ship” is an appro-
priate sememe for canoeist. Since HowNet is man-
ually annotated by experts, misannotated words al-
ways exist inevitably, which in some cases under-
estimates our models.



365

Type Words Sememes

English Word handcuffs 用具 “tool”, “police”, “detain”,⼈ “human”, “guilty”

5 Nearest Chinese Words

⼿铐 “handcuffs” “guilty”, “police”,⼈ “human”, “detain”,用具 “tool”
镣铐 “shackles” “guilty”, “police”,⼈ “human”, “detain”,用具 “tool”

绑 “tie” 包扎 “wrap”
螺丝⼑ “screwdriver” 用具 “tool”, 放松 “loosen”, 勒紧 “tighten”

绳 “rope” 线 “linear”, 材料 “material”, 拴连 “fasten”

English Word canoeist 锻炼 “exercise”,⼈ “human”,体育 “sport”, 事情 “fact”, 船 “ship”

5 Nearest Chinese Words

短跑 “sprint” 事情 “fact”锻炼 “exercise”体育 “sport”
独⽊⾈ “canoe” 船 “ship”
皮艇 “kayak” 船 “ship”

名将 “sports star” 著名 “famous”,⼈ “human”, 官 “official”, 军 “military”
皮划艇 “kayak” 事情 “fact”,锻炼 “exercise”,体育 “sport”

Table 2: Two examples of cross-lingual lexical sememe prediction.

4.5 Effect of Word Frequency

To explore how frequencies of target words affect
cross-lingual sememe prediction results, we split
the testing set into four subsets according to word
frequency and then calculate the sememe predic-
tionMAP and F1 score for each subset. The results
are shown in Table 3.

Method WordFrequency
Sememe Prediction

MAP F1 Score

BiLex

<200 30.35 21.83
200 - 500 34.83 25.95
501 - 2500 40.21 28.62
>2500 47.56 35.80

CLSP-WR

<200 34.73 24.41
200 - 500 39.50 29.49
501 - 2500 43.92 33.87
>2500 47.33 34.99

CLSP-SE

<200 36.54 27.49
200 - 500 41.46 30.09
501 - 2500 45.35 35.01
>2500 49.34 37.16

Table 3: Evaluation results of cross-lingual lexical
sememe prediction with different word frequen-
cies. The number of words in each frequency range
is 497, 458, 522 and 523 respectively.

From the table we can see that: (1) The more
frequently a target word appears in the corpus, the
better its predicted sememes are. It is because
high-frequency words normally have better word
embeddings, which are crucial to sememe predic-
tion. (2) Our models evidently perform better than
BiLex in different word frequencies, especially in
low frequency. It indicates that by considering
external information of HowNet, our models are
more robust and can competently handle sparse

scenarios.

4.6 Further Quantitative Analysis
In this section, we conduct two typical auxiliary
experiments to further analyze the superiority of
our models quantitatively.

Bilingual Lexicon Induction
Our models learn bilingual word embeddings in
one unified semantic space. Here we use transla-
tion top-1 and top-5 average precision (P@1 and
P@5) to evaluate bilingual lexicon induction per-
formance of our models and BiLex. The seed lex-
icon size also varies in {1000, 2000, 4000, 6000}.

Method SeedLexicon
Lexicon Induction

P@1 P@5

BiLex

1000 6.48 10.78
2000 10.84 15.84
4000 19.48 23.96
6000 25.89 29.59

CLSP-WR

1000 6.89 11.28
2000 11.96 18.08
4000 19.50 25.78
6000 25.83 31.03

CLSP-SE

1000 6.60 11.04
2000 11.90 18.62
4000 19.26 25.11
6000 26.91 32.17

Table 4: Bilingual lexicon induction performance
with different seed lexicon sizes.

The results are shown in Table 4. From this ta-
ble, we observe that our models, especially CLSP-
SEmodel, enhance the performance of word trans-
lation compared to BiLex no matter how large the
seed lexicon is. It indicates that our models can
bind bilingual word embeddings better.



366

Word Similarity Computation
We also evaluate the task of monolingual word
similarity computation on WordSim-240 (WS-
240) and WordSim-297 (WS-297) datasets
for Chinese, and WordSim-353 (WS-353) and
SimLex-999 (SL-999) datasets for English.

Method
Chinese (source) English (target)

WS-240 WS-297 WS-353 SL-999

BiLex 60.36 62.17 60.46 27.22

CLSP-WR 61.27 65.25 60.46 27.22

CLSP-SE 60.84 65.62 62.47 28.79

Table 5: Performance on monolingual word simi-
larity computation with seed lexicon size 6000.

Table 5 shows the results of monolingual word
similarity computation on four datasets. From
the table, we find that: (1) Our models per-
form better than BiLex on both Chinese word
similarity datasets. It signifies incorporating se-
meme information helps learn better monolingual
embeddings; (2) CLSP-WR model does not en-
hance English word similarity results but CLSP-
SE model does. It is because CLSP-WR model
only post-processes Chineseword embeddings and
keeps English word embeddings unchanged while
CLSP-SE model undertakes bilingual alignment
and sememe information incorporation together,
which makes English word embeddings improve
with Chinese word embeddings.

5 Conclusion and Future Work

In this paper, we introduce a new task of cross-
lingual sememe prediction. This task is very im-
portant because the construction of sememe-based
linguistic knowledge bases in various languages
is beneficial to better understanding these lan-
guages. We propose a simple and effective model
for this task, including monolingual word repre-
sentation learning, cross-lingual word representa-
tion alignment and sememe-based word represen-
tation learning. Experimental results on real-world
datasets show that our model achieves consistent
and significant improvements compared to base-
line method in cross-lingual sememe prediction.
In the future, we will explore the following re-

search directions: (1) In this paper, for simplifi-
cation, we ignore the rich hierarchy information
in HowNet and also ignore the fact that a word
may have multiple senses. We will extend our

models to consider the structure information of se-
meme and multiple senses of words; (2) In fact,
our framework for cross-lingual lexical sememe
prediction can be transferred to other cross-lingual
tasks. We will explore the effectiveness of our
model in these tasks such as cross-lingual infor-
mation retrieval.

Acknowledgments

This research is funded by the National 973 project
(No. 2014CB340501). It is also partially sup-
ported by the NExT++ project, the National Re-
search Foundation, Prime Minister’s Office, Sin-
gapore under its IRC@Singapore Funding Initia-
tive. Hao Zhu is supported by Tsinghua University
Initiative Scientific Research Program. We also
thank the anonymous reviewers for their valuable
comments and suggestions.

References
Waleed Ammar, George Mulcaire, Yulia Tsvetkov,
Guillaume Lample, Chris Dyer, and Noah A Smith.
2016. Massively multilingual word embeddings.
arXiv preprint arXiv:1602.01925.

Sarath Chandar AP, Stanislas Lauly, Hugo Larochelle,
Mitesh Khapra, Balaraman Ravindran, Vikas C
Raykar, and Amrita Saha. 2014. An autoencoder ap-
proach to learning bilingual word representations. In
Proceedings of NIPS.

Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2017.
Learning bilingual word embeddings with (almost)
no bilingual data. In Proceedings of ACL.

Leonard Bloomfield. 1926. A set of postulates for the
science of language. Language, 2(3):153–164.

Danushka Bollegala, Mohammed Alsuhaibani,
Takanori Maehara, and Ken-ichi Kawarabayashi.
2016. Joint word representation learning using a
corpus and a semantic lexicon. In Proceedings of
AAAI.

Alexis Conneau, Guillaume Lample, Marc’Aurelio
Ranzato, Ludovic Denoyer, and Hervé Jégou. 2017.
Word translation without parallel data. arXiv
preprint arXiv:1710.04087.

Jocelyn Coulmance, Jean-Marc Marty, Guillaume
Wenzek, and Amine Benhalloum. 2015. Trans-
gram, fast cross-lingual word-embeddings. In Pro-
ceedings of EMNLP.

Lei Dang and Lei Zhang. 2010. Method of discriminant
for chinese sentence sentiment orientation based on
hownet. Application Research of Computers, 4:43.



367

Georgiana Dinu, Angeliki Lazaridou, and Marco Ba-
roni. 2014. Improving zero-shot learning by
mitigating the hubness problem. arXiv preprint
arXiv:1412.6568.

Zhendong Dong and Qiang Dong. 2003. Hownet-a hy-
brid language and knowledge resource. In Proceed-
ings of NLP-KE.

Long Duong, Hiroshi Kanayama, Tengfei Ma, Steven
Bird, and Trevor Cohn. 2016. Learning crosslingual
word embeddings without bilingual corpora. In Pro-
ceedings of EMNLP.

Manaal Faruqui, Jesse Dodge, Sujay Kumar Jauhar,
Chris Dyer, Eduard Hovy, and Noah A Smith. 2015.
Retrofitting word vectors to semantic lexicons. In
Proceedings of NAACL-HLT.

Manaal Faruqui and Chris Dyer. 2014. Improving vec-
tor space word representations using multilingual
correlation. In Proceedings of the EACL.

Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,
Ehud Rivlin, Zach Solan, Gadi Wolfman, and Ey-
tan Ruppin. 2002. Placing search in context: The
concept revisited. ACM Transactions on Informa-
tion Systems, 20(1):116–131.

Xianghua Fu, Guo Liu, Yanyan Guo, and Zhiqiang
Wang. 2013. Multi-aspect sentiment analysis for
chinese online social reviews based on topic model-
ing and hownet lexicon. Knowledge-Based Systems,
37:186–195.

Stephan Gouws, Yoshua Bengio, and Greg Corrado.
2015. Bilbowa: fast bilingual distributed represen-
tations without word alignments. In Proceedings of
ICML.

Yihong Gu, Jun Yan, Hao Zhu, Zhiyuan Liu, Ruobing
Xie, Maosong Sun, Fen Lin, and Leyu Lin. 2018.
Language modeling with sparse product of sememe
experts. In Proceedings of EMNLP.

Karl Moritz Hermann and Phil Blunsom. 2014. Mul-
tilingual distributed representations without word
alignment. In Proceedings of ICLR.

Felix Hill, Roi Reichart, and Anna Korhonen. 2015.
Simlex-999: Evaluating semantic models with (gen-
uine) similarity estimation. Computational Linguis-
tics, 41(4):665–695.

Huiming Jin, Hao Zhu, Zhiyuan Liu, Ruobing Xie,
Maosong Sun, Fen Lin, and Leyu Lin. 2018. In-
corporating chinese characters of words for lexical
sememe prediction. In Proceedings of ACL.

Peng Jin and Yunfang Wu. 2012. SemEval-2012 Task
4: Evaluating chinese word similarity. In Proced-
dings of *SEM.

Tomáš Kočiskỳ, Karl Moritz Hermann, and Phil Blun-
som. 2014. Learning bilingual word representa-
tions by marginalizing alignments. In Proceedings
of ACL.

Angeliki Lazaridou, Georgiana Dinu, and Marco Ba-
roni. 2015. Hubness and pollution: Delving into
cross-space mapping for zero-shot learning. In Pro-
ceedings of ACL-IJCNLP.

Zhongguo Li and Maosong Sun. 2009. Punctuation as
implicit annotations for chinese word segmentation.
Computational Linguistics, 35(4):505–512.

Quan Liu, Hui Jiang, Si Wei, Zhen-Hua Ling, and
Yu Hu. 2015. Learning semantic word embeddings
based on ordinal knowledge constraints. In Proceed-
ings of ACL-IJCNLP.

Qun Liu and Sujian Li. 2002. Word similarity comput-
ing based on hownet. International Journal of Com-
putational Linguistics&Chinese Language Process-
ing, 7(2):59–76.

Ang Lu, Weiran Wang, Mohit Bansal, Kevin Gimpel,
and Karen Livescu. 2015. Deep multilingual corre-
lation for improved word embeddings. In Proceed-
ings of NAANL-HLT.

Thang Luong, Hieu Pham, and Christopher DManning.
2015. Bilingual word representations with monolin-
gual quality in mind. In Proceedings of the 1st Work-
shop on Vector Space Modeling for Natural Lan-
guage Processing.

Laurens van der Maaten and Geoffrey E Hinton. 2008.
Visualizing data using t-sne. Journal of Machine
Learning Research, 9:2579–2605.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. In Proceedings of ICLR.

TomasMikolov, Quoc V Le, and Ilya Sutskever. 2013b.
Exploiting similarities among languages for machine
translation. arXiv preprint arXiv:1309.4168.

George AMiller. 1995. Wordnet: a lexical database for
english. Communications of the ACM, 38(11):39–
41.

Nikola Mrkšic, Diarmuid OSéaghdha, Blaise Thom-
son, Milica Gašic, Lina Rojas-Barahona, Pei-Hao
Su, David Vandyke, Tsung-Hsien Wen, and Steve
Young. 2016. Counter-fitting word vectors to lin-
guistic constraints. In Proceedings of NAACL-HLT.

Yilin Niu, Ruobing Xie, Zhiyuan Liu, and Maosong
Sun. 2017. Improved word representation learning
with sememes. In Proceedings of ACL.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word rep-
resentation. In Proceedings of EMNLP.

Sebastian Ruder. 2017. A survey of cross-lingual em-
bedding models. arXiv preprint arXiv:1706.04902.

Tianze Shi, Zhiyuan Liu, Yang Liu, and Maosong Sun.
2015. Learning cross-lingual word embeddings via
matrix co-factorization. In Proceedings of ACL-
IJCNLP.



368

Jingguang Sun, Dongfeng Cai, Dexin Lv, and Yanju
Dong. 2007. Hownet based chinese question auto-
matic classification. Journal of Chinese Information
Processing, 21(1):90–95.

Shyam Upadhyay, Manaal Faruqui, Chris Dyer, and
Dan Roth. 2016. Cross-lingual models of word em-
beddings: An empirical comparison. In Proceedings
of ACL.

Ivan Vulić and Anna Korhonen. 2016. On the role
of seed lexicons in learning bilingual word embed-
dings. In Proceedings of ACL.

Ivan Vulić and Marie-Francine Moens. 2015. Bilin-
gual word embeddings from non-parallel document-
aligned data applied to bilingual lexicon induction.
In Proceedings of ACL-IJCNLP.

Michael Wick, Pallika Kanani, and Adam Craig
Pocock. 2016. Minimally-constrained multilingual
embeddings via artificial code-switching. In Pro-
ceedings of AAAI.

Ruobing Xie, Xingchi Yuan, Zhiyuan Liu, and
Maosong Sun. 2017. Lexical sememe prediction via
word embeddings and matrix factorization. In Pro-
ceedings of AAAI.

Xiangkai Zeng, Cheng Yang, Cunchao Tu, Zhiyuan
Liu, and Maosong Sun. 2018. Chinese liwc lexicon
expansion via hierarchical classification of word em-
beddings with sememe attention. In Proceedings of
AAAI.

Meng Zhang, Haoruo Peng, Yang Liu, Huan-Bo Luan,
and Maosong Sun. 2017. Bilingual lexicon induc-
tion from non-parallel data with minimal supervi-
sion. In Proceedings of AAAI.

Yuntao Zhang, Ling Gong, and Yongcheng Wang.
2005. Chinese word sense disambiguation using
hownet. In Proceedings of International Conference
on Natural Computation.

Will Y Zou, Richard Socher, Daniel Cer, and Christo-
pher D Manning. 2013. Bilingual word embeddings
for phrase-based machine translation. In Proceed-
ings of EMNLP.


