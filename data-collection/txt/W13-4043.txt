Metz, France, 22-24 August 2013. c(cid:13)2013 Association for Computational Linguistics

Proceedings of the SIGDIAL 2013 Conference, pages 284–293,

284

A Four-Participant Group Facilitation Framework

for Conversational Robots

Yoichi Matsuyama,

Iwao Akiba, Akihiro Saito, Tetsunori Kobayashi

Department of Computer Science, Waseda University

27 Waseda, Shunjuku-ku, Tokyo, Japan

{matsuyama,akiba,saito}@pcl.cs.waseda.ac.jp

koba@waseda.jp

Abstract

robots that

In this paper, we propose a framework for
conversational
facilitates four-
participant groups.
In three-participant con-
versations, the minimum unit for multiparty
conversations, social imbalance, in which a
participant is left behind in the current conver-
sation, sometimes occurs. In such scenarios, a
conversational robot has the potential to facili-
tate situations as the fourth participant. Conse-
quently, we present model procedures for ob-
taining conversational initiatives in incremen-
tal steps to engage such four-participant con-
versations. During the procedures, a facilitator
must be aware of both the presence of dom-
inant participants leading the current conver-
sation and the status of any participant that is
left behind. We model and optimize these situ-
ations and procedures as a partially observable
Markov decision process. The results of ex-
periments conducted to evaluate the proposed
procedures show evidence of their acceptabil-
ity and feeling of groupness.

1 Introduction
We present a framework for conversational robots
that facilitates four-participant groups with proper pro-
Figure 1 (a) de-
cedures for obtaining initiatives.
picts a two-participant conversation.
In such sit-
uations, conversational contexts including ﬂoor ex-
changes are commonly grounded between two inter-
locutors. Many dialogue systems have dealt with
such two-participant situations (Raux and Eskenazi,
2009) (Chao and Thomaz, 2012). However, in three-
participant conversations, as is shown in Figure 1(b),
which is the minimum unit for multiparty conversation,
ﬂoor exchanges cannot always be identiﬁed among the
participants. Clark presented the participation struc-
ture model (Clark, 1996), drawing on Goffman’s work
(Goffman, 1981). In such three-participant situations,
interactions between two dominant participants out of
the three primarily occur (between participant A and B)
and the other participant, who cannot properly get the
ﬂoor to speak for a long while (cannot be promoted to
be either a speaker or an addressee) tends to get left be-

hind, even though all of them are “ratiﬁed participants”
considered by the current speaker.

In terms of engagement among conversational par-
ticipants, Martin et al., (Martin and White, 2005) pro-
posed the appraisal theory that encompasses three sub-
categories, namely Attitude, Engagement, and Gradu-
ation. Attitude deals with expressions of affect, judge-
ment, and appreciation. Engagement focuses on lan-
guage use by which speakers negotiate an interpersonal
space for their positions and the strategies which they
uses to either acknowledge, ignore, or curtail other
voices or points of view. Graduation focuses on the
resources by which sparkers regulate the impact of
these resources. Sidner et al., deﬁned engagement as
“the process by which two (or more) participants es-
tablish, maintain and end their perceived connection
during interactions they jointly undertake” (Sidner et
al., 2004). Based on these previous studies, we de-
ﬁne engagement as the process establishing connec-
tions among participants using dialogue actions so that
they can represent their own positions properly. So, the
three-participant model dictates the need for one more
participant who helps the participant who is left behind
to engage him/her in the conversation. Conversational
robots have the potential to participate in such conver-
sations as the fourth participant, as illustrated in Figure
1 (c-1). Figure 1 (c-2) gives an example of the partici-
pants’ speech activities in a certain duration. In this ex-
ample, participant C’s activity is relatively smaller than
that of the others, and so he/she is likely to get left be-
hind in the current conversational situation for a num-
ber of reasons. When a robot steps into the situation to
coordinate, there should be proper procedures in place
to obtain initiatives to control conversational contexts
and to give it back to the others. If a robot naively starts
to approach a participant who is left behind just after
a left-behind situation is detected, it could break the
current conversation. In order to coordinate situations,
a facilitator (robot) must take the following procedu-
ral steps: (1) Be aware of both the presence of domi-
nant participants leading the current conversation and
the status of a participant who is left behind, (2) Ob-
tain the initiative to control the situation and wait for
approval from the others, either explicitly or implicitly,
and (3) Give the ﬂoor to a suitable participant.

Research on specially situated facilitation agents in

285

Figure 1: Types of conversations according to number of participants (dashed arrows represent their gazes): (a)
Two-participant conversation model, which conventional dialogue systems have focused on. (b) Three-participant
conversation model, the minimum unit for a multiparty conversation. In such multiparty conversations, social
imbalance occasionally occurs.
(c-1) Four-participant conversation, with a robot that regulates the imbalance
situation, and (c-2) chart showing the unequal speech activities of the participants. In this case, participant C
appears to have less opportunity to take the ﬂoor to speak, hence, the robot is expected to help him.

multiparty conversations has been conducted by vari-
ous researchers. Matsusaka et al. pioneered the act of a
physical robot participating in multiparty conversations
(Matsusaka et al., 2003). We previously developed a
multiparty quiz-game type facilitation system for el-
derly care (Matsuyama et al., 2008) and reported on the
effectiveness of the existence of a robot (Matsuyama
et al., 2010). Dosaka et al. developed a thought-
evoking dialogue system for multiparty conversations
with a quiz game task (Dohsaka et al., 2009). They
reported that the existence of agents and empathic ex-
pressions are effective for user satisfaction and increase
the number of user utterances. Bohus modeled engage-
ment in multiparty conversations along Sinder’s deﬁni-
tion, namely open world dialogue (Bohus and Horvitz,
2009). In terms of facilitation, Benne et al. (Benne and
Sheats, 1948) and Bales (Bales, 1950) pioneered inves-
tigations into small group dynamics, including func-
tional facilitation roles. Kumar et al. designed a dia-
logue action selection model based on Bales’s Socio-
Emotional Interaction Categories for text-based char-
acter agents (Kumar et al., 2011).

In this paper, we propose a framework of proce-
dural facilitation process to increase the total engage-
ment of a group, with caring about side-effects of be-
haviors at the same time. The situations and proce-
dures are modeled and optimized as a partially observ-
able Markov decision process (POMDP), which is suit-
able for real-world sequential decision processes, in-
cluding dialogue systems (Williams and Young, 2007).
We begin by reviewing facilitation of small groups,
and summarize requirement speciﬁcations for facilita-
tion robots in the next section. In Section 3, we ﬁrst
describe representations of small group situations and
procedures for maintaining small groups, then we dis-
cuss how to model them as POMDP. In Section 4, we
give an overview of the architecture of our proposed
system. We then discuss two experiments conducted to

verify the efﬁcacy of the small group maintenance pro-
cedures. Finally, we summarize our work and conclude
this paper.

2 Facilitating Small Groups

2.1 Maintaining Small Groups
Benne et al. analyzed functional roles in small groups
to understand the activities of individuals in small
groups (Benne and Sheats, 1948). They categorized
functional roles in small groups into three classes:
Group task roles, Group building and maintenance
roles, and Individual roles. The Group task roles are
deﬁned as “related to the task which the group is de-
ciding to undertake or has undertaken.” Those roles ad-
dress concerns about the facilitation and coordination
activities for task accomplishment. The Group building
and maintenance roles are deﬁned as “oriented toward
the functioning of the group as a group.” They con-
tribute to social structures and interpersonal relations.
Finally, the Individual roles are directed toward the
individual satisfaction of each participant’s individual
needs. They deal with individual goals that are not rel-
evant either to the group task or to group maintenance.
Drawing on Benne’s work, Bales proposed interaction
process analysis (IPA), a framework for the classiﬁca-
tion of individual behavior in a two-dimensional role
space consisting of a Task area and a Socio-emotional
area (Bales, 1950). The roles related to the Task area
concern behavioral manifestations that impact the man-
agement and solution of problems that a group is ad-
dressing. Examples of task-oriented activities include
initiating the ﬂoor, giving information, and providing
suggestions regarding a task. The roles related to the
Socio-emotional area affect the interpersonal relation-
ships either by supporting, enforcing, or weakening
them. For instance, complementing another person to
increase group cohesion and mutual trust among mem-

286

bers is one example of positive socio-emotional behav-
ior. Benne’s typology of functional roles is evaluated
as valuable with remarkable accuracy.
In this paper,
we employ Benne’s Group building and maintenance
roles,1 which are related to Bales’s Socio-emotional
area, in order to arrange the following three abstract
functional roles of group maintenance:

1. Topic Maintenance Role: Maintaining for con-
ﬂict,
ideas, and topics. This person mediates
the difference between other members, attempts
to reconcile disagreements, and relieves tension
in conﬂict situations. This role inherits Compro-
miser, Harmonizer, and Standard setter.

the ﬂoor

2. Floor Maintenance Role: Maintaining the
chance for
in the group in a di-
rect/indirect way. This person encourages or asks
questions of the person who is not or could not get
engaged in conversations, and attempts to keep the
communication channel open. This role inherits
Gatekeeper, Expediter, and Encourager.

3. Observation Role: Overlooking the conversation
situation by ﬁnding appropriate topics, observing
the motivations and moods of the participants, and
comprehending the relations between participants
in conversations. This person follows the conver-
sation and comments and interprets the group’s
internal process. This role inherits Observer and
commentator and Encourager.

2.2 Procedures for Small Group Maintenance
In order that a participant who wants to claim an ini-
tiative (we call this participant a “claimant”) is trans-
ferred an initiative by the participant leading the current
conversation (we call this participant a “leader”), the
claimant must take procedural steps. First, the claimant
must participate in the current dominant conversation
the leader is leading, try to claim an initiative, and then
wait for either explicit or implicit approval from the
leader. Let us take the example shown in Figure 2. In
the ﬁgure, participants A and B are primarily leading
the current conversation. Participant C cannot get the
ﬂoor to speak, and so the robot desires to give the ﬂoor
to C. If the robot speaks to C directly, without being
aware of A and B, the conversation might be broken,
or separated into two (A-B and C-Robot), at best. In
order not to break the situation, the robot should par-
ticipate in the dominant conversation between A and B
ﬁrst, and set the stage such that the robot is approved
to initiate the next situation. In this paper, we deﬁne
such a state in which a person is participating in a dom-
inant conversation as a “Engaged” state, and the op-
posite state as “Unengaged”. Thus, in Clark’s partic-

1Benne’s Group building and maintenance roles are Com-
promiser, Harmonizer, Standard setter, Gatekeeper and ex-
pediter, Encourager, Observer and commentator, and Fol-
lower.

Figure 2: Four-participant conversational group. Four
participants, including a robot, are talking about a cer-
tain topic. Participants A and B are leading the con-
versation, and mainly keep the ﬂoor. The robot also
engages with A and B in line with the topic. C is an un-
engaged participant, who does not have many chances
to take the ﬂoor for a while. The dashed arrows indicate
the direction they are facing, assuming their gazes.

ipation structure, speaker and addressee are automat-
ically Engaged participants. Side-participants are di-
vided into Engaged and Unengaged participants based
on their situations.
In this paper, we assume that an
Unengaged participant needs to respond to a Engaged
participant’s adjacency pair part to be engaged. Adja-
cency pairs are minimal units of conversation that are
composed of two utterances by several speakers (Sche-
gloff and Sacks, 1973). The speaking of the ﬁrst ut-
terance (the ﬁrst part) provokes a responding utterance
(the second part), and sometimes a third response (the
third part). Understanding adjacency pairs is, therefore,
essential to detecting cut-in timing.

On the basis of our discussion above, we deﬁne the
following constraints for both Engaged and Unengaged
participants when they address and shift current topics:
1. Constraint of addressing: An unengaged partici-
pant must not address the other unengaged partic-
ipants directly.

2. Constraint of topic shifting: An engaged partic-
ipant must not shift the current topic when he/she
addresses the other unengaged participants.

The relationship between subjective and objective
participants that are permitted to approach in the two
constraints are shown in Tables 1 and 2. In the follow-
ing sections, we describe a computational model that
has the group maintenance functions discussed above.

3 Procedure Optimization
3.1 Representation of Engagement State
We assume only one speaker and one addressee exist
at each time-step and one or two side-participants may

Robot
(Addresee)

ENGAGED

Participant C 
(Side-Participant)

UN-ENGAGED

gaze

Participant A
(Side-Participant)

ENGAGED

Participant B
(Speaker)

ENGAGED

287

Table 1: Permission relationship between subjective
and objective participants for the constraint of address-
ing.
“Engaged” means a participant is assigned as
a speaker or an addressee or a side-participant, who
engages with the conversational group. ”Unengaged”
means a participant is assigned as an unengaged side-
participant.

XXXXXXXXXX

Objective

Subject

Engaged
Unengaged

Engaged

Unengaged

permitted
permitted NOT permitted

permitted

Table 2: Permission relationship for permission be-
tween subjective and objective participants in the con-
straint of topic shifting.

XXXXXXXXXX

Objective

Subject

Engaged
Unengaged

Engaged

Unengaged

permitted

NOT permitted
NOT permitted NOT permitted

exist in four-participant conversations. We deﬁne side-
participants as having two states: “Engaged” and “Un-
engaged”. In the scenario shown in Figure 2, partic-
ipant C may not be able to take the ﬂoor for a while.
The situation probably resolves itself when the current
topic is shifted. Hence, we deﬁne the depth of side-
participant DepthSPT as the duration that a participant
is assigned while the same topic continues, which rep-
resents the level of engagement.

DepthSPTi = DurationSPTi/Durationtopic j

(1)

UnengagedSPT ={ SPTi

none

if DepthSPTi > T hreshold
otherwise

(2)

The sufﬁx i represents a participant’s ID.
We also deﬁne an Un-Engaged participant’s motiva-
tion to speak on the current topic. Thus, this state af-
fects decision-making about topic maintenance. The
amount of motivation of a participant is calculated as
a linear sum of speech activities, smiling duration, and
nodding duration. Further, the motivations in our cur-
rent model are heuristically assumed to be binary vari-
ables.

Motivationi ={ 1

0

if MotivAmounti > T hreshold
otherwise

(3)

3.2 Procedure Optimization using POMDP
To optimize the procedures discussed above, we
model the task as a partially observable Markov deci-
sion process (POMDP) (Williams and Young, 2007).
Formally, a POMDP is deﬁned as a tuple β =

Figure 3:
Inﬂuence diagram representation of the
POMDP model. Circles represent random variables,
squares represent decision nodes, and diamonds repre-
sent utility nodes. Shaded circles indicate random vari-
ables, while unshaded circles represent observed vari-
ables. Solid directed arcs indicate casual effect, while
dashed directed arcs indicate that a distribution is used.

{S,A,T,R,O,Z,γ,b0}, where S is a set of states de-
scribing the agent’s world, A is a set of actions that
the agent may take, T deﬁnes a transition probabil-
ity P(s′|s,a), R deﬁnes the expected reward r(s,a), O
is a set of observations the agent can receive about
the world, and Z deﬁnes an observation probability,
P(o′|s′,a), γ is a geometric discount factor 0 < γ < 1,
and b0 is an initial belief state b0(s). At each time-step,
the belief state distribution b is updated as follows:

b′(s′) = γ· P(o′|s′,a)∑

s

P(s′|s,a)b(s)

(4)

In this paper, we assume S can be factored into three
components:
the participants’ engagement states Se,
the participants’ motivation states Sm, and the partic-
ipants’ actions Ap. Hence, the factored POMDP state S
is deﬁned as

s = (se,sm,ap)

(5)

and the belief state b becomes

b = b(se,sm,ap)

(6)

To compute the transition function and observation
function, a few intuitive assumptions are made:
P(s′|s,a) =P(s′e,s′m,a′p|se,sm,ap,as)

=P(s′e|sh,sm,ap,as)·
P(s′m|s′e,sh,sm,ap,as)·
P(a′p|s′m,s′e,se,sm,ap,as)

(7)

Figure 3 shows the inﬂuence diagram depiction of our
proposed model. We assume conditional independence
as follows: The ﬁrst term in (7), which we call the
participants’ engagement model TSe, indicates how the
robot engages in the current dominant conversation at

R

R’

Sh

Ap

S’h

A’p

Sm

As

’
Sm

A’s

O

O’

Timestamp t

Timestamp t + 1

288

each time-step. We assume that the participants’ en-
gagement state at each time-step depends only on the
previous engagement state, the participants’ action, and
the system action. In this paper, the participants’ en-
gagement model only contains the robot’s engagement
states because it is sufﬁcient for the obtaining initiatives
procedures . Table 3 shows the states of engagement.

TSe = P(s′e|se,ap,as)

(8)

In this paper, the probabilities of (8) were handcrafted,
based on the consideration in Section 2.2 and our expe-
riences. When the engagement state is the Un-Engaged
state and the robot is asked by a current speaker,
the state should be changed to the Pre-Engaged state,
where the robot is awaiting the speaker’s approval
for the Engaged state. We assume that any dialogue
acts from the speaker addressing the robot in the Pre-
Engaged are approvals. Otherwise, the state will be
back to the Un-Engaged. The Engaged state gradually
goes down to the Un-Engaged state in time-steps unless
the robot selects any dialogue acts.

We call the second term the participants’ motivation
model TSm. It indicates how an Un-Engaged participant
has the motivation to take the ﬂoor at each time-step.
This state implies that the participant who is left be-
hind (target person) has a motivation to speak on the
current topic. Thus, this state affects decision-making
about topic shift. We assume that a participant’s moti-
vation at each time-step depends only on the previous
system action. The motivations are deﬁned as an un-
engaged participant’s ID and a binary (true/false) vari-
able, which is calculated by (3) .

TSm = P(s′m|as)

(9)
We call the third term the participants’ action model
TAp. It indicates what actions the participants are likely
to take at each time-step. We assume the participants’
actions at each time-step depends on the previous par-
ticipant’s action, the previous system action, and the
current robot’s engagement state. As shown in Table
5, participants’ actions include adjacency pair types.
Understanding adjacency pairs is essential to detecting
cut-in timing. In this paper, we recognize the adjacency
pairs only by keyword matching using the results of
speech recognition.

TAp = P(a′p|s′h,ap,as)

(10)

The transition probabilities of adjacency pair types
are based on a corpus we collected. We recorded
two four-participant conversational groups (all partic-
ipants were human subjects), where they were talked
about movies. The total duration was around 60 min-
utes. Each utterance is segmented automatically by our
speech recognition. After the recording, adjacency pair
types were manually annotated for all speech segments.
We deﬁne the observation probability Z as follows:

Z = P(o′|s′,a) = P(o′|s′m,a′p,as)

(11)

Table 3: Engagement states Se

Engagement states Meaning
Un-Engaged
Pre-Engaged

Engaged

The robot is not engaging with the current conversation.
The robot is waiting for approval to engage with
the current conversation.
The robot is engaging with the current conversation.

Table 4: Motivation states Sm

Motivation states Meaning
Motivated

Not-Motivated

The participant who is left behind has a motivation to speak
on the current topic (interested in the current topic).
The participant who is left behind does not have any
motivation to speak (not interested in the current topic).

Given the deﬁnitions above, the belief state can be up-
dated at each time-step by substituting (8), (9), and (10)
into (4).
b′(s′m,a′p) =γ· P(o′|s′m,a′p,as)
|
}
∑
P(s′e|se,ap,as)
|
}
sh

·P(a′p|s′e,ap,as)
|
}

·P(s′m|as)
| {z }
·b(sm,ap)

{z
{z

participants’
action model

{z

engagement

observation

motivation

model

model

model

(12)

·

Table 6 shows the system actions. The system has
seven actions available.

On the basis of the consideration of the constraints in
Section 2.2, the reward measure includes components
for both the appropriateness and inappropriateness of
the robot’s behaviors.

As an optimization algorithm, we employed the
heuristic search value iteration (HSVI) algorithm pro-
posed by Smith et al., which is one of point-based al-
gorithms (Smith and Simmons, 2012).

4 System Architecture
Based on the studies on small group maintenance, we
propose an architecture for conversational robots that
has the capability to facilitate small groups, as shown
in Figure 4. The framework primarily comprises Sit-
uation Analysis, Dialogue Management, and Sentence
Generation processes.

4.1 Situation Analysis and Dialogue Management
Each time the system detects an endpoint of speech
from the automatic speech recognition (ASR) module,
it interprets the current situation. The Situation Analy-
sis process includes participation roles recognition, ad-
jacency pair part recognition, and question analysis.

Participation roles including a speaker, an addressee,
and side-participants are recognized by the results of
voice activity detection (VAD) and face directions
recognition. The face directions are captured by depth-
RGB cameras (Microsoft Kinect).
In this paper, we
use a hand-crafted role classiﬁer. The speaker classi-
ﬁcation accuracy is 75.1% and the addressee classiﬁ-

289

Figure 4: The architecture of the system primarily comprises the Situation Analysis, the Dialogue Management,
and the Sentence Generation processes. The Situation Analysis process receives sensory information from RGBD
cameras (Microsoft Kinect) and speech recognizers for each participant. The Dialogue Management process is
described in Section 3. The Answer Generation process has the capability of doing additional phrasing with the
robot’s own opinions.

Table 5: Participants’ actions Ap

Participants’ actions Meaning
ﬁrst-part
second-part
third-part
other
call

A participant made an adjacency part (question)
A participant made a second adjacency part (answer)
A participant made a third adjacency part
A participant asked or answered the other participant
A participant called the robot’s name

Table 6: System actions As

Meaning
Answering the current speaker’s question 　　　　　
Asking someone a question related to a new topic

System actions
answer
question-new-topic
question-current-topic Asking someone a question related to the current topic
trivia
simple-reaction
nod
none

Giving a trivia
Reacting simply
Nodding to the current speaker
Doing nothing

cation accuracy is 67.2% Adjacency pairs are recog-
nized by the results of the participation role recognion
and speech recognition. We use a hand-crafted adja-
cency pairs classiﬁer. The classiﬁcation accuracy is
around 60%, which mostly depends on the classiﬁca-
tion accuracy of addressing for a robot. In the ques-
tion analysis process, a speech utterance is interpreted
with question types (5W1H interrogatives: e.g., “who,”
“what,” “how,” etc.) and predicate (verbs and adjec-
tives). Questions are classiﬁed into two categories:
Factoid type questions and Non-factoid type questions.
In the Dialogue Management process, a dialog ac-
tion is selected based on abstracted conversational situ-
ation to maintain a small group, which we described in
Section 3.

4.2 Sentence Generation
The Sentence Generation process consists of two com-
ponents: Answer Generation and Question Genera-
tion. Based on the results of the Question Analysis
process, answers are classiﬁed into two types: Fac-
toid type answers and Non-factoid type answers (opin-
ions). Factoid answers are generated from a structured
database. In this research, we use Semantic Web tech-

nologies. After analyzing a question, it is interpreted
as a SPARQL query, a resource description framework
(RDF) format query language to search RDF databases.
We use DBpedia as an RDF database2.

The opinion (non-factoid type answers) generation
process refers opinion data automatically collected
from a large amount of reviews in the Web. The opinion
generation consists of four process: document collec-
tion, opinion extraction, sentence style conversion, and
sentence ranking. As an example task, we collected re-
view documents from the Yahoo! Japan Movie site 3.
The opinion extraction consists of two processes: ex-
traction of evaluative expressions and classiﬁcation of
their sentiment polarities (positive/negative). We elimi-
nate opinions with negative sentiments because the sys-
tem is expected to talk about positive contents in our
conversational task. Nakagawa et al. (Nakagawa et al.,
2008) used both a subjective evaluative dictionary (Hi-
gashiyama et al., 2008) and an evaluative noun dictio-
nary (Kobayashi et al., 2007). We use an evaluative
word dictionary we prepare based on their works. In
order to extract evaluative expressions which can ap-
pear at any position in a sentence, we use the IOB en-
coding method, which has been commonly used for
extent-identiﬁcation tasks (Breck et al., 2007). Using
IOB, each word is tagged as either (B)eginning an en-
tity, being (I)n an entity, or being (O)utside of an entity.
Based on the proposed method by Nakagawa et al, we
use linear-chain conditional random ﬁelds (CRF) for
the IBO encoding.

In order to preserve consistency of system’s charac-
ter, sentence styles are converted based on a hand-craft
rule we prepare. After Japanese morphological analy-
sis, punctuation marks and particular symbols and are
eliminated. Then the last morpheme is converted.

We propose three ranking algorithms in terms of
length and novelty: Short, Standard and Diverse. The
Short is short length ﬁrst algorithm. In this algorithm,

2http://ja.dbpedia.org/
3http://movies.yahoo.co.jp

Topic Estimation and Shifting

Factoid Typed

Non-Factoid Typed

Face Directions,
Facial Expressions,
and Nodding 
Recognition

Participation Role,
AP, and Question
Analysis

RGBD

ASR

Situation
Analysis

Topic

Management

Dialogue

Management

(POMDP)

Structured

Data

Opinion Data

Answer Generation

Question Generation

t
n
e
m
n
o
r
i
v
n
E

Speech

Mortor

t
n
e
m
n
o
r
i
v
n
E

Gaze Control

User Model

290

at ﬁrst, top 30% of sentences by TF-IDF score, which
consists of seven to ten morphemes, are extracted. We
assume top 30% of candidates is reasonably associated
with a current topic. For the Standard and Diverse
algorithms, at ﬁrst, top 30% of sentences by TF-IDF
score, which consists of ﬁfteen to twenty morphemes,
are extracted. The Standard algorithm is expected to
contain substantial opinions or reasons, which can ap-
peal to users about a certain topic. In this algorithm,
the list is sorted by adjective term frequency. The Di-
verse algorithm is expected to express opinions or rea-
sons with novel styles, which can be unpredictable or
sometimes serendipitous to users about a certain topic.
In this algorithm, the list is sorted in the inverse order
by adjective term frequency.

4.3 Question Generation and User Model
The Question Generation module has two main func-
tions: giving someone the ﬂoor and collecting users’
preferences and experiences for the User Model.

The User Model is preferred for topic maintenance.
A preferred new topic is decided using cosine similar-
ity of TF-IDF scores. The topic scores (TopicScore)
of all topics are calculated based on cosine similari-
ties of the current topic (CurrentTopic), a user’s topic
preferences of all topics (Pre f erenceTopic), and expe-
riences (ExperienceTopic) between the CurrentTopic
and each Topic.
TopicScorei = αcos(Topici ·CurrentTopic)

+β(∑
+γ(∑

m

n

cos(Topici · Pre f erenceTopicm))
cos(Topici · ExperienceTopicm))(13)

4.4 Experimental Platform
For our experimental platform, we used the multimodal

conversation robot ”SCHEMA([∫ e:ma]),” (Matsuyama

et al., 2009) shown in Figure 2. SCHEMA is approxi-
mately 1.2[m] in height, which is the same as the level
of the eyes of an adult male sitting down in a chair.
It has 10 degrees of freedom for right-left eyebrows,
eyelids, right-left eyes (roll and pitch) and neck (pitch
and yaw). It can express anxiousness and surprise us-
ing its eyelids and control its gaze using eyes, neck,
and autonomous turret. In addition, it has six degrees
of freedom for each arm, which can express gestures.
One degree of freedom is assigned to the mouth to in-
dicate explicitly whether the robot is speaking or not.
A computer is inside the belly to control the robot’s
actions, and an external computer sends commands to
execute various behaviors though a WiFi network. All
modules, including the ASRs and a speech synthesizer
are connected to each other though a middleware called
the Message-Oriented NEtworked-robot Architecture
(MONEA), which we earlier produced (Nakano et al.,
2006).

5 Experiments
We designed the following two experiments to eval-
uate the appropriateness and feeling of groupness of
our proposed procedures for multiparty conversations
(experiment 1), and the appropriateness of timing for
initiating procedures (experiment 2). In order to can-
cel the effects of recognition errors, we prepared video
recordings of four-participant situations (Human par-
ticipant A, B, C, and a robot), just like 2. We created the
following three conditions, all of which are optimized
as POMDP. All subjects were native Japanese speakers
recruited from Waseda University campus. They were
ﬁrst given a brief description of the purpose and the
procedure of the conversation. They were instructed
that A and B have a friendly relationship with each
other, C is coming in for the ﬁrst time and is feeling
nervous, therefore, C is left behind in the conversation,
and a robot is trying to maximize the total engagement
of this situation. We also explained “a engaged situ-
ation” meant “a situation in which all participant are
given their opportunities to speak something fairly.”

5.1 Experiment 1: Appropriateness and
Groupness by Usage of Procedures

A total of 35 subjects (23 males and 12 females) par-
ticipated in this experiment. The ages of the subjects
ranged between 20 and 25 years with an average age of
20.5 years. After they watched the videos, they were
asked to complete questionnaires about their feeling of
groupness (“For which condition did you feel a sense
of groupness?”) and free-form questionnaires. The fol-
lowing four conditions were videotaped, and the video
edited at around 30 s. All videos contained the same
topic (“Princess Mononoke”). The spatial arrangement
was the same as shown in Figure 2.

Condition 1: Without procedures (without topic
shifting). A robot directly asks a participant left be-
hind without procedures claiming an initiative. As is
shown in Figure 8, just after a sequence of interactions
between A and B, which is segmented by a third ad-
jacency pair part, a robot directly asks C. The topic is
still maintained (“Princess Mononoke”).

Condition 2: With procedures (without topic shift-
ing). A robot directly asks a participant left behind with
a procedure. As is shown in Figure 9, Just after a se-
quence of interactions between A and B, a robot asks
A with the ﬁrst pair part and waits for A’s response (the
second part). Then it ﬁnishes the interaction with A,
and asks C to give a ﬂoor. In this case, topic is still
maintained the current one (“Princess Mononoke”).

Condition 3: Without procedures + topic shifting. In
#6 question of Condition 1 (Figure 8), a robot initiates
a new topic (“From Up On Poppy Hill”) instead.

Condition 4: With procedures + topic shifting. In
#7 question of Condition 2 (Figure 9), a robot initiates
a new topic (“From Up On Poppy Hill”) instead.

After watching the movies, they were requested to
answer Likert 7-scaled questionnaires about (a) appro-

291

Figure 5: Result of experiment 1-a

Figure 6: Result of experiment 1-b

Figure 7: Result of experiment 2

priateness of procedures, (b) Feeling of groupness.

5.2 Experiment 2: Appropriateness of Timing of

Initiating Procedures

A total of 32 subjects (21 males and 11 females) par-
ticipated in this experiment. The ages of the sub-
jects ranged between 20 and 25 years with an aver-
age age of 20.5 years. After they watched the videos,
they were asked to complete questionnaires about the
timing of the initiating procedures (“Which video did
you feel was the most appropriate?”). The following
three conditions were videotaped, and edited at around
30 s. All videos contained the same topic (“Princess
Mononoke”). The spatial arrangement was the same as
shown in Figure 2. We created three conditions:

Condition 1 (ﬁrst part): Initiating a procedure just

after the ﬁrst adjacent pair part.

Condition 2 (second part): Initiating a procedure

just after the second adjacent pair part.

Condition 3 (No AP): Out of consideration of adja-

cency pairs.

In conditions 1 and 2, the robot initiated its proce-
dures just after the ﬁrst and second parts, respectively.
In condition 3, the robot initiated its procedure in the
middle of the adjacency pairs, which is intended to
show that the robot does not care about adjacency pairs.
We did not consider the timings of the third part of the
adjacency pair because we had already examined the
appropriateness of the timing of the third part in ex-
periment 1. After watching the movies, they were re-
quested to answer Likert 7-scaled questionnaires about
the robot’s appropriateness of behavior.

5.3 Results and Discussions
Figure 5 shows usages of procedures are appropriate to
approach a participant left behind either with or without
topic shifting. The t-test result shows a signiﬁcant dif-
ference between condition 1 and 2, as well as between
3 and 4 (p < 0.01). Figure 6 shows usages of proce-
dures generate feelings of groupness. The t-test result
also shows a signiﬁcant difference between condition 1
and 2, as well as between 3 and 4 (p < 0.01).

Figure 7 (a) shows initiating procedures without
topic shifting in timings of just after the second pair

parts is more appropriate than other conditions. The re-
sult of an analysis of variance (ANOVA) shows signif-
icant differences among conditions (F[2,26] = 34.46,
p < 0.01). The result of multiple comparisons with the
Tukey HSD method shows a signiﬁcant difference be-
tween condition 1 and 2, as well as between 2 and 3
(p < 0.01). Figure 7 (b) shows initiating procedures
with topic shifting in timings of just after the second
pair parts is more appropriate than other conditions.
The result of an analysis of variance (ANOVA) shows
signiﬁcant differences among conditions (F[2,26] =
42.52, p < 0.01). The result of multiple comparisons
with the Tukey HSD method shows a signiﬁcant differ-
ence between condition 1 and 2, as well as between 2
and 3 (p < 0.01).

From these results, usages of procedures obtaining
initiatives before approaching a participant left behind
showed evidences of acceptability as a participant’s be-
haviors, and feeling of groupness in a group. As for
timings, initiating the procedures just after the second
or third adjacency pair parts is felt more appropriate
than the ﬁrst pairs by participants.

6 Conclusions
We proposed a framework for conversational robots
facilitating four-participant groups. Based on a rep-
resentation of conversational situations, we presented
a model of procedures obtaining conversational initia-
tives in incremental steps to maximize total engage-
ment of such four-participant conversations. These sit-
uations and procedures were modeled and optimized
as a partially observable Markov decision process. As
the results of two experiments, usages of procedures
obtaining initiatives showed evidences of acceptability
as a participant’s behaviors, and feeling of groupness.
As for timings, initiating the procedures just after the
second or third adjacency pair parts is felt more appro-
priate than the ﬁrst pairs by participants.

research was

7 Acknowledgements
This
supported by the Grant-in-
Aid for scientiﬁc research WAKATE-B (23700239).
TOSHIBA corporation provided the speech synthesizer
customized for our spoken dialogue system.

(a) w/o topic shifting

(b) w/ topic shifting

p < 0.01*

p < 0.01*

7

5

4

2

0
(1) w/o procedure
(2) w/   procedure

7

5

4

2

0

(3) w/o procedure
(4) w/   procedure

(a) w/o topic shifting

(b) w/ topic shifting

p < 0.01*

p < 0.01*

7

5

4

2

0

7

5

4

2

0

(1) w/o procedure
(2) w/   procedure

(3) w/o procedure
(4) w/   procedure

(a) w/o topic shifting

(b) w/ topic shifting

ns

*

*

ns

*

*

7

5

4

2

0

7

5

4

2

0

(1) ﬁrst part

(2) second part

(3)NoAP
* : p < 0.01

292

References
Robert F Bales. 1950.

Cambridge, Mass.

Interaction process analysis.

Kenneth D Benne and Paul Sheats. 1948. Functional
roles of group members. Journal of social issues,
4(2):41–49.

Dan Bohus and Eric Horvitz. 2009. Models for multi-
party engagement in open-world dialog. In Proceed-
ings of the SIGDIAL 2009 Conference: The 10th An-
nual Meeting of the Special Interest Group on Dis-
course and Dialogue, pages 225–234. Association
for Computational Linguistics.

Eric Breck, Yejin Choi, and Claire Cardie. 2007. Iden-
tifying expressions of opinion in context.
In Pro-
ceedings of the 20th international joint conference
on Artiﬁcal intelligence, pages 2683–2688. Morgan
Kaufmann Publishers Inc.

Crystal Chao and Andrea Lockerd Thomaz.

2012.
Timing in multimodal turn-taking interactions: Con-
trol and analysis using timed petri nets. Journal of
Human-Robot Interaction, 1(1).

Herbert H Clark. 1996. Using language, volume 4.

Cambridge University Press Cambridge.

Kohji Dohsaka, Ryota Asai, Ryuichiro Higashinaka,
Yasuhiro Minami, and Eisaku Maeda. 2009. Ef-
fects of conversational agents on human communi-
cation in thought-evoking multi-party dialogues. In
Proceedings of the SIGDIAL 2009 Conference: The
10th Annual Meeting of the Special Interest Group
on Discourse and Dialogue, pages 217–224. Asso-
ciation for Computational Linguistics.

Erving Goffman. 1981. Forms of talk. University of

Pennsylvania Press.

Masahiko Higashiyama, Kentaro Inui, and Yuji Mat-
sumoto. 2008. Acquiring noun polarity knowledge
using selectional preferences. In Proceedings of the
14th Annual Meeting of the Association for Natural
Language Processing, pages 584–587.

Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.
2007. Opinion mining from web documents: Ex-
traction and structurization. Information and Media
Technologies, 2(1):326–337.

Rohit Kumar, Jack L Beuth, and Carolyn P Ros´e. 2011.
Conversational strategies that support idea genera-
tion productivity. In in Groups, 9 th Intl. Conf. on
Computer Supported Collaborative Learning, Hong
Kong 160 and Ros´e, 2010a) Rohit Kumar, Carolyn P.
Ros´e, 2010, Conversational Tutors with Rich Inter-
active Behaviors that support Collaborative Learn-
ing, Workshop on Opportunity. Citeseer.

James R Martin and Peter RR White.

2005. The
language of evaluation. Palgrave Macmillan Bas-
ingstoke and New York.

Yosuke Matsusaka, Tojo Tsuyoshi, and Tetsunori
Kobayashi. 2003. Conversation robot participating
in group conversation. IEICE transactions on infor-
mation and systems, 86(1):26–36.

Yoichi Matsuyama, Hikaru Taniyama, Shinya Fujie,
and Tetsunori Kobayashi. 2008. Designing commu-
nication activation system in group communication.
In Humanoid Robots, 2008. Humanoids 2008. 8th
IEEE-RAS International Conference on, pages 629–
634. IEEE.

Yoichi Matsuyama, Kosuke Hosoya, Hikaru Taniyama,
Hiroki Tsuboi, Shinya Fujie,
and Tetsunori
Kobayashi. 2009. Schema: multi-party interaction-
oriented humanoid robot.
In ACM SIGGRAPH
ASIA 2009 Art Gallery & Emerging Technologies:
Adaptation, pages 82–82. ACM.

Yoichi Matsuyama, Shinya Fujie, Hikaru Taniyama,
and Tetsunori Kobayashi. 2010. Psychological eval-
uation of a group communication activation robot in
a party game. In Eleventh Annual Conference of the
International Speech Communication Association.

Tetsuji Nakagawa, Takuya Kawada, Kentaro Inui, and
Sadao Kurohashi. 2008. Extracting subjective and
objective evaluative expressions from the web.
In
Universal Communication, 2008. ISUC’08. Second
International Symposium on, pages 251–258. IEEE.

Teppei Nakano,

Shinya Fujie,

and Tetsunori
2006. Monea: message-oriented
Kobayashi.
networked-robot architecture.
In Robotics and
Automation, 2006. ICRA 2006. Proceedings 2006
IEEE International Conference on, pages 194–199.
IEEE.

Antoine Raux and Maxine Eskenazi. 2009. A ﬁnite-
state turn-taking model for spoken dialog systems.
In Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 629–637. Association for Computa-
tional Linguistics.

Emanuel A Schegloff and Harvey Sacks. 1973. Open-

ing up closings. Semiotica, 8(4):289–327.

Candace L Sidner, Cory D Kidd, Christopher Lee, and
Neal Lesh. 2004. Where to look: a study of human-
robot engagement.
In Proceedings of the 9th in-
ternational conference on Intelligent user interfaces,
pages 78–84. ACM.

Trey Smith and Reid Simmons. 2012. Point-based
Improved analysis and imple-

pomdp algorithms:
mentation. arXiv preprint arXiv:1207.1412.

Jason Williams and Steve Young.

2007. Partially
observable markov decision processes for spoken
dialog systems. Computer Speech & Language,
21(2):393–422.

293

Sentences
Have you ever watched “Princess Mononoke”?

AP
1st

Sentences
Have you ever watched “Princess Mononoke”?

#
1
2
3
4
5
6

7

SPK → ADD

A→B
B→A
A→B
B→A
A→B
R→C
C→R

AP
First
Second Yes, I have
First
Second Yeah.
I see
Third
Have
you
First
Mononoke”?

Oh, you have?

Second Yes, I have

ever

watched

“Princess

Figure 8: Transcript of condition 1 (experiment 2)

#
1
2
3
4
5
6
7

8

SPK → ADD

A→B
B→A
A→B
R→A
A→B
B→A
R→C
C→R

Second Yes, I have
Third
First
Second Really?
Third
First

Yes.
Have
you
Mononoke”?

Second Yes, I have

I see.
It is one of my favorite movies among Ghibri’s

ever

watched

“Princess

Figure 9: Transcript of condition 2 (experiment 2)

Figure 10: Interaction scenes. The “AP” signiﬁes adjacency pair types. At #4, the system recognized A’s adjacency
third part and then generated a spontaneous opinion addressed to A (#5) as the ﬁrst part. At that point, the system
assumed the state of engagement (Se) had changed from Un-Engaged to Pre-Engaged. After the system observed
A’s second part at #8, it assumed it at gotten approval to obtain an initiative to control the context (Engaged). At
#10, the robot asked C a question in order to give him the ﬂoor.

1

4

#

1
2
3
4
5
6
7

8

9
10
11
12
13

A→B
A→B
B→A
A→B
R→A
A→R
R→A

A→R

R→A
R→C
C→R
A→C
C→A

2

5

3

6

1

SPK → ADD AP

Se

Sentences
(Topic: “007 Skyfall”)
Let’s talk about the “Skyfall.”

1st U n
1st U n Have you ever seen the latest one?
2nd U n Well, I’ve not seen that.
3rd U n Oh, really.
1st
2nd Pre
1st
Pre

Pre Well, I like the Bond Girl.

I see.
I think that movie is good because of the setting of the ”old age” for the 44-year
old James Bond.
Uh-huh.
(R is approved to obtain an initiative)
Yes.
Have you ever seen the ”Skyfall”?
No, I haven’t.
Oh, you haven’t seen it?
I never seen that before.

3

4

5

6

2nd

3rd
1st
2nd
1st
2nd

H

H

H

H

H

H

2

