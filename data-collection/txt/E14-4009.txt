



















































Tight Integration of Speech Disfluency Removal into SMT


Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 43–47,
Gothenburg, Sweden, April 26-30 2014. c©2014 Association for Computational Linguistics

Tight Integration of Speech Disfluency Removal into SMT

Eunah Cho Jan Niehues
Interactive Systems Lab

Institute of Anthropomatics
Karlsruhe Institute of Technology, Germany

{eunah.cho,jan.niehues,alex.waibel}@kit.edu

Alex Waibel

Abstract

Speech disfluencies are one of the main
challenges of spoken language processing.
Conventional disfluency detection systems
deploy a hard decision, which can have
a negative influence on subsequent appli-
cations such as machine translation. In
this paper we suggest a novel approach
in which disfluency detection is integrated
into the translation process.

We train a CRF model to obtain a disflu-
ency probability for each word. The SMT
decoder will then skip the potentially dis-
fluent word based on its disfluency prob-
ability. Using the suggested scheme, the
translation score of both the manual tran-
script and ASR output is improved by
around 0.35 BLEU points compared to the
CRF hard decision system.

1 Introduction

Disfluencies arise due to the spontaneous nature
of speech. There has been a great deal of effort to
detect disfluent words, remove them (Johnson and
Charniak, 2004; Fitzgerald et al., 2009) and use
the cleaned text for subsequent applications such
as machine translation (MT) (Wang et al., 2010;
Cho et al., 2013).

One potential drawback of conventional ap-
proaches is that the decision whether a token is
a disfluency or not is a hard decision. For an
MT system, this can pose a severe problem if the
removed token was not in fact a disfluency and
should have been kept for the correct translation.
Therefore, we pass the decision whether a word is
part of a disfluency or not on to the translation sys-
tem, so that we can use the additional knowledge
available in the translation system to make a more
reliable decision. In order to limit the complexity,

the search space is pruned prior to decoding and
represented in a word lattice.

2 Related Work

Disfluencies in spontaneous speech have been
studied from various points of view. In the noisy
channel model (Honal and Schultz, 2003), it is
assumed that clean text without any disfluencies
has passed through a noisy channel. The clean
string is retrieved based on language model (LM)
scores and five additional models. Another noisy
channel approach involves a phrase-level statisti-
cal MT system, where noisy tokens are translated
into clean tokens (Maskey et al., 2006). A tree ad-
joining grammar is combined with this noisy chan-
nel model in (Johnson and Charniak, 2004), using
a syntactic parser to build an LM.

Fitzgerald et al. (2009) present a method to de-
tect speech disfluencies using a conditional ran-
dom field (CRF) with lexical, LM, and parser
information features. While previous work has
been limited to the postprocessing step of the au-
tomatic speech recogition (ASR) system, further
approaches (Wang et al., 2010; Cho et al., 2013)
use extended CRF features or additional models
to clean manual speech transcripts and use them
as input for an MT system.

While ASR systems use lattices to encode hy-
potheses, lattices have been used for MT systems
with various purposes. Herrmann et al. (2013)
use lattices to encode different reordering variants.
Lattices have also been used as a segmentation tac-
tic for compound words (Dyer, 2009), where the
segmentation is encoded as input in the lattice.

One of the differences between our work and
previous work is that we integrate the disfluency
removal into an MT system. Our work is not lim-
ited to the preprocessing step of MT, instead we
use the translation model to detect and remove dis-
fluencies. Contrary to other systems where detec-
tion is limited on manual transcripts only, our sys-

43



tem shows translation performance improvements
on the ASR output as well.

3 Tight Integration using Lattices

In this chapter, we explain how the disfluency re-
moval is integrated into the MT process.

3.1 Model
The conventional translation of texts from sponta-
neous speech can be formulated as

ê = arg max
e
p(e| arg max

fc
p(fc|f)) (1)

with

p(fc|f) =
I∏

i=1

p(ci|fi) (2)

where fc denotes the clean string

fc = {f1, . . . , fI | ci = clean} (3)
for the disfluency decision class c of each token.

c ∈
{
clean
disfluent

(4)

Thus, using the conventional models, disfluency
removal is applied to the original, potentially noisy
string in order to obtain the cleaned string first.
This clean string is then translated.

The potential drawback of a conventional
speech translation system is caused by the rough
estimation in Equation 1, as disfluency removal
does not depend on maximizing the translation
quality itself. For example, we can consider the
sentence Use what you build, build what you use.
Due to its repetitive pattern in words and structure,
the first clause is often detected as a disfluency us-
ing automatic means. To avoid this, we can change
the scheme how the clean string is chosen as fol-
lows:

ê = arg max
e,fc

(p(e|fc) · p(fc|f)) (5)

This way a clean string which maximizes the
translation quality is chosen. Thus, no instant de-
cision is made whether a token is a disfluency or
not. Instead, the disfluency probability of the to-
ken will be passed on to the MT process, using
the log linear combination of the probabilities as
shown in Equation 5.

In this work, we use a CRF (Lafferty et al.,
2001) model to obtain the disfluency probability
of each token.

Since there are two possible classes for each to-
ken, the number of possible clean sentences is ex-
ponential with regard to the sentence length. Thus,
we restrict the search space by representing only
the most probable clean source sentences in a word
lattice.

3.2 CRF Model Training
In order to build the CRF model, we used the
open source toolkit CRF++ (Kudoh, 2007). As
unigram features, we use lexical and LM features
adopted from Fitzgerald et al. (2009), and addi-
tional semantics-based features discussed in (Cho
et al., 2013). In addition to the unigram features,
we also use a bigram feature to model first-order
dependencies between labels.

We train the CRF with four classes; FL for filler
words, RC for (rough) copy, NC for non-copy and
0 for clean tokens. The class FL includes obvious
filler words (e.g. uh, uhm) as well as other dis-
course markers (e.g. you know, well in English).
The RC class covers identical or roughly simi-
lar repetitions as well as lexically different words
with the same meaning. The NC class represents
the case where the speaker changes what to speak
about or reformulates the sentence and restarts the
speech fragments. The disfluency probability Pd
of each token is calculated as the sum of probabil-
ities of each class.

3.3 Lattice Implementation
We construct a word lattice which encodes long-
range reordering variants (Rottmann and Vogel,
2007; Niehues and Kolss, 2009). For translation
we extend this so that potentially disfluent words
can be skipped. A reordering lattice of the ex-
ample sentence Das sind die Vorteile, die sie uh
die sie haben. (En.gls: These are the advantages,
that you uh that you have.) is shown in Figure 1,
where words representing a disfluency are marked
in bold letters. In this sentence, the part die sie
uh was manually annotated as a disfluency, due to
repetition and usage of a filler word.

Table 1 shows the Pd obtained from the CRF
model for each token. As expected, the words die
sie uh obtain a high Pd from the CRF model.

In order to provide an option to avoid translating
a disfluent word, a new edge which skips the word
is introduced into the lattice when the word has a
higher Pd than a threshold θ. During decoding the
importance of this newly introduced edge is opti-
mized by weights based on the disfluency proba-

44



0

1 das 

2 sie 

3
 sie 

4 sind 

5 das 

6 das 

7 die 

8 sind 

9 sind 

10 Vorteile 

11 die 

12 die 

13 , 

14 Vorteile 

15 Vorteile 

16 die 

17 , 

18 , 

19

 sie 
20 haben 

 die 

21 die 

22 uh 

23 sie 

24 sie 

25 die 

26 uh 

27 uh 
28

 sie 
29 haben 
30 die 

 die 

31
 haben 

 sie 

 sie 

32 . 

Figure 1: Reordering lattice before adding alternative clean paths for an exemplary sentence

0

1 das 

2
 sie 

3
 sie 

5

 das 

4 sind 

 das 

6 das 

7 die 

8 sind 

9 sind 

10 Vorteile 

11 die 

12
 die 

13 , 

14 Vorteile 

15
 Vorteile 

16 die 

19 haben 

26
 die 

17 , 

18
 , 

 haben 

20
 sie 

 die 

 die 

 die 

21
 die 30

 die 

22 sie 
28

 die 

23 uh 

 die 

24
 sie 

 die 

25 uh 

 die 

 die 

27 uh 

 die 

 die 

29 haben 
 sie 

 die 

31

 sie 

 sie 
 haben 

32 . 

Figure 2: Extended lattice with alternative clean paths for an exemplary sentence

das 0.000732 sie 0.953126
sind 0.004445 uh 0.999579
die 0.013451 die 0.029010

Vorteile 0.008183 sie 0.001426
, 0.035408 haben 0.000108

die 0.651642 . 0.000033
Table 1: Disfluency probability of each word

bility and transition probability. The extended lat-
tice for the given sentence with θ = 0.5 is shown
in Figure 2, with alternative paths marked by a
dotted line. The optimal value of θ was manually
tuned on the development set.

4 System Description

The training data for our MT system consists of
1.76 million sentences of German-English paral-
lel data. Parallel TED talks1 are used as in-domain
data and our translation models are adapted to the
domain. Before training, we apply preprocess-
ing such as text normalization, tokenization, and
smartcasing. Additionally, German compound
words are split.

To build the phrase table we use the Moses
package (Koehn et al., 2007). An LM is trained
on 462 million words in English using the SRILM
Toolkit (Stolcke, 2002). In order to extend source
word context, we use a bilingual LM (Niehues et
al., 2011). We use an in-house decoder (Vogel,
2003) with minimum error rate training (Venu-
gopal et al., 2005) for optimization.

For training and testing the CRF model, we use
61k annotated words of manual transcripts of uni-

1http://www.ted.com

versity lectures in German. For tuning and testing
the MT system, the same data is used along with
its English reference translation. In order to make
the best use of the data, we split it into three parts
and perform three-fold cross validation. There-
fore, the train/development data consists of around
40k words, or 2k sentences, while the test data
consists of around 20k words, or 1k sentences.

5 Experiments

In order to compare the effect of the tight inte-
gration with other disfluency removal strategies,
we conduct different experiments on manual tran-
scripts as well as on the ASR output.

5.1 Manual Transcripts
As a baseline for manual transcripts, we use
the whole uncleaned data for development and
test. For “No uh”, we remove the obvious filler
words uh and uhm manually. In the CRF-hard
experiment, the token is removed if the label
output of the CRF model is a disfluency class.
The fourth experiment uses the tight integration
scheme, where new source paths which jump over
the potentially noisy words are inserted based on
the disfluency probabilities assigned by the CRF
model. In the next experiments, this method is
combined with other aforementioned approaches.
First, we apply the tight integration scheme after
we remove all obvious filler words. In the next
experiment, we first remove all words whose Pd
is higher than 0.9 as early pruning and then apply
the tight integration scheme. In a final experiment,
we conduct an oracle experiment, where all words
annotated as a disfluency are removed.

45



5.2 ASR Output
The same experiments are applied to the ASR out-
put. Since the ASR output does not contain re-
liable punctuation marks, there is a mismatch be-
tween the training data of the CRF model, which is
manual transcripts with all punctuation marks, and
the test data. Thus, we insert punctuation marks
and augment sentence boundaries in the ASR out-
put using the monolingual translation system (Cho
et al., 2012). As the sentence boundaries differ
from the reference translation, we use the Leven-
shtein minimum edit distance algorithm (Matusov
et al., 2005) to align hypothesis for evaluation.
No optimization is conducted, but the scaling fac-
tors obtained when using the correponding setup
of manual transcripts are used for testing.

5.3 Results
Table 2 shows the results of our experiments. The
scores are reported in case-sensitive BLEU (Pap-
ineni et al., 2002).

System Dev Text ASR
Baseline 23.45 22.70 14.50
No uh 25.09 24.04 15.10
CRF-hard 25.32 24.50 15.15
Tight int. 25.30 24.59 15.19
No uh + Tight int. 25.41 24.68 15.33
Pruning + Tight int. 25.38 24.84 15.51
Oracle 25.57 24.87 -

Table 2: Translation results for the investigated
disfluency removal strategies

Compared to the baseline where all disfluen-
cies are kept, the translation quality is improved
by 1.34 BLEU points for manual transcripts by
simply removing all obvious filler words. When
we take the output of the CRF as a hard deci-
sion, the performance is further improved by 0.46
BLEU points. When using the tight integration
scheme, we improve the translation quality around
0.1 BLEU points compared to the CRF-hard deci-
sion. The performance is further improved by re-
moving uh and uhm before applying the tight inte-
gration scheme. Finally the best score is achieved
by using the early pruning coupled with the tight
integration scheme. The translation score is 0.34
BLEU points higher than the CRF-hard decision.
This score is only 0.03 BLEU points less than the
oracle case, without all disfluencies.

Experiments on the ASR output also showed a
considerable improvement despite word errors and

consequently decreased accuracy of the CRF de-
tection. Compared to using only the CRF-hard de-
cision, using the coupled approach improved the
performance by 0.36 BLEU points, which is 1.0
BLEU point higher than the baseline.

System Precision Recall
CRF-hard 0.898 0.544
Pruning + Tight int. 0.937 0.521

Table 3: Detection performance comparison

Table 3 shows a comparison of the disfluency
detection performance on word tokens. While re-
call is slightly worse for the coupled approach,
precision is improved by 4% over the hard deci-
sion, indicating that the tight integration scheme
decides more accurately. Since deletions made by
a hard decision can not be recovered and losing a
meaningful word on the source side can be very
critical, we believe that precision is more impor-
tant for this task. Consequently we retain more
words on the source side with the tight integration
scheme, but the numbers of word tokens on the
translated target side are similar. The translation
model is able to leave out unnecessary words dur-
ing translation.

6 Conclusion

We presented a novel scheme to integrate disflu-
ency removal into the MT process. Using this
scheme, it is possible to consider disfluency prob-
abilities during decoding and therefore to choose
words which can lead to better translation perfor-
mance. The disfluency probability of each token
is obtained from a CRF model, and is encoded in
the word lattice. Additional edges are added in the
word lattice, to bypass the words potentially rep-
resenting speech disfluencies.

We achieve the best performance using the tight
integration method coupled with early pruning.
This method yields an improvement of 2.1 BLEU
points for manual transcripts and 1.0 BLEU point
improvement over the baseline for ASR output.

Although the translation of ASR output is im-
proved using the suggested scheme, there is still
room to improve. In future work, we would like to
improve performance of disfluency detection for
ASR output by including acoustic features in the
model.

46



Acknowledgements

The research leading to these results has received
funding from the European Union Seventh Frame-
work Programme (FP7/2007-2013) under grant
agreement n◦ 287658.

References
Eunah Cho, Jan Niehues, and Alex Waibel. 2012.

Segmentation and Punctuation Prediction in Speech
Language Translation using a Monolingual Trans-
lation System. In Proceedings of the Interna-
tional Workshop for Spoken Language Translation
(IWSLT), Hong Kong, China.

Eunah Cho, Thanh-Le Ha, and Alex Waibel. 2013.
CRF-based Disfluency Detection using Seman-
tic Features for German to English Spoken Lan-
guage Translation. In Proceedings of the Interna-
tional Workshop for Spoken Language Translation
(IWSLT), Heidelberg, Germany.

Chris Dyer. 2009. Using a Maximum Entropy Model
to Build Segmentation Lattices for MT. In Proceed-
ings of Human Language Technologies: The 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics, Boulder, Colorado, USA, June. Association for
Computational Linguistics.

Erin Fitzgerald, Kieth Hall, and Frederick Jelinek.
2009. Reconstructing False Start Errors in Sponta-
neous Speech Text. In Proceedings of the European
Association for Computational Linguistics (EACL),
Athens, Greece.

Teresa Herrmann, Jan Niehues, and Alex Waibel.
2013. Combining Word Reordering Methods on
different Linguistic Abstraction Levels for Statisti-
cal Machine Translation. In Proceedings of the Sev-
enth Workshop on Syntax, Semantics and Structure
in Statistical Translation, Altanta, Georgia, USA,
June. Association for Computational Linguistics.

Matthias Honal and Tanja Schultz. 2003. Correction of
Disfluencies in Spontaneous Speech using a Noisy-
Channel Approach. In Eurospeech, Geneva.

Mark Johnson and Eugene Charniak. 2004. A TAG-
based Noisy Channel Model of Speech Repairs. In
Proceedings of the Association for Computational
Linguistics (ACL).

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the Association for Computational
Linguistics (ACL), Demonstration Session, Prague,
Czech Republic, June.

Taku Kudoh. 2007. CRF++: Yet Another CRF
Toolkit.

John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional Random Fields: Prob-
abilitic Models for Segmenting and Labeling Se-
quence Data. In ICML, Massachusetts, USA.

Sameer Maskey, Bowen Zhou, and Yuqing Gao. 2006.
A Phrase-Level Machine Translation Approach for
Disfluency Detection using Weighted Finite State
Tranducers. In Interspeech, Pittsburgh, PA.

Evgeny Matusov, Gregor Leusch, Oliver Bender, and
Herrmann Ney. 2005. Evaluating Machine Trans-
lation Output with Automatic Sentence Segmenta-
tion. In Proceedings of the International Workshop
on Spoken Language Translation (IWSLT), Boulder,
Colorado, USA, October.

Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Proceedings of the 4th Workshop on Statistical Ma-
chine Translation, Athens, Greece.

Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Proceedings of the 6th Workshop on Statistical Ma-
chine Translation, Edinburgh, UK.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. Technical Re-
port RC22176 (W0109-022), IBM Research Divi-
sion, T. J. Watson Research Center.

Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In TMI, Skövde,
Sweden.

Andreas Stolcke. 2002. SRILM – An Extensible Lan-
guage Modeling Toolkit. Denver, Colorado, USA.

Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In WPT-
05, Ann Arbor, MI.

Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language
Processing and Knowledge Engineering, Beijing,
China.

Wen Wang, Gokhan Tur, Jing Zheng, and Necip Fazil
Ayan. 2010. Automatic Disfluency Removal for Im-
proving Spoken Language Translation. In Interna-
tional Conference on Acoustics, Speech, and Signal
Processing (ICASSP).

47


