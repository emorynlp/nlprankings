










































Improving Feature-Based Biomedical Event Extraction System by Integrating Argument Information


Proceedings of the BioNLP Shared Task 2013 Workshop, pages 109–115,
Sofia, Bulgaria, August 9 2013. c©2013 Association for Computational Linguistics

Improving Feature-Based Biomedical Event Extraction System by In-

tegrating Argument Information 

Lishuang Li, Yiwen Wang, Degen Huang 

School of Computer Science and Technology 

Dalian University of Technology 

116023 Dalian, China 
lilishuang314@163.com yeevanewong@gmail.com 

huangdg@dlut.edu.cn 

 

Abstract 

We describe a system for extracting biomedi-

cal events among genes and proteins from 

biomedical literature, using the corpus from 

the BioNLP’13 Shared Task on Event Extrac-

tion. The proposed system is characterized by 

a wide array of features based on dependency 

parse graphs and additional argument informa-

tion in the second trigger detection. Based on 

the Uturku system which is the best one in the 

BioNLP’09 Shared Task, we improve the per-

formance of biomedical event extraction by 

reducing illegal events and false positives in 

the second trigger detection and the second ar-

gument detection. On the development set of 

BioNLP’13, the system achieves an F-score of 

50.96% on the primary task. On the test set of 

BioNLP’13, it achieves an F-score of 47.56% 

on the primary task obtaining the 5th place in 

task 1, which is 1.78 percentage points higher 

than the baseline (following the Uturku sys-

tem), demonstrating that the proposed method 

is efficient. 

1 Introduction 

Extracting knowledge from unstructured text is 

one of the most important goals of Natural Lan-

guage Processing and Artificial Intelligence. Re-

sources in the internet are expanding at an expo-

nential speed, especially in the biomedical do-

main. Due to the astronomical growth of biomed-

ical scientific literature, it is very important and 

urgent to develop automatic methods for know-

ledge extraction system. 

In the past few years, most researchers in the 

field of Biomedical Natural Language Processing 

focused on extracting information with simple 

structure, such as named entity recognition 

(NER), protein-protein interactions (PPIs) (Air-

ola et al., 2008; Miwa et al., 2009) and disease-

gene association (Chun et al., 2006). While PPIs 

concern the flat relational schemas with no 

nested structures, bio-molecular events describe 

the detailed behavior of bio-molecules, which 

capture the biomedical phenomena from texts 

well. The BioNLP’09 shared task (Kim et al., 

2009) provides the first entry to bio-event extrac-

tion. As described in BioNLP’09, a bio-event 

consists of a trigger and one or more arguments, 

where a trigger is a contiguous textual string con-

taining one or more tokens and an argument is a 

participant (event or protein) with a correspond-

ing type. For example, in the snippet “interferon 

regulatory factor 4 gene expression”, the event 

trigger is “expression” which is tagged by the 

event type “Gene_expression” and the event ar-

gument is “interferon regulatory factor 4”. Not-

ably, bio-events may have arbitrary arguments 

and even contain other events as arguments, re-

sulting in nested events. 

The complex event structure makes this task 

particularly attractive, drawing initial interest 

from many researchers. Björne et al.'s (2009) 

system (referred to hereinafter as Uturku system) 

was the best pipeline system in BioNLP’09, 

achieving an F-score of 51.95% on the test data 

sets. After that, Miwa et al. (2010a, 2010b) com-

pared different parsers and dependency represen-

tations on bio-event extraction task and obtained 

an F-score of 57.79% on development data sets 

and 56.00% on test data sets with parser ensem-

ble. In contrast to the pipeline system which di-

vided the event process into three stages, triggers 

detection, arguments detection and post 

processing, Poon and Vanderwende’s (2010) and 

Riedel et al.’s (2009) joint models combined 

trigger recognition and argument detection by 

using a Markov logic network learning approach. 

After the BioNLP’09, the Genia event task (Bi-

oNLP’11 task 1, hereafter) in the BioNLP’11 

Shared Task (Kim et al., 2011) introduced a 

same event extraction task on a new dataset. 

There were still some pipeline systems applied to 

Genia task 1, e.g. Björne et al.’s (2011) system 

and Quirk et al.’s (2011) system. To the best of 

109



our knowledge, Miwa et al.’s (2012) pipeline 

system incorporating domain adaptation and co-

reference resolution, is the best biomedical event 

extraction system on BioNLP'11 task 1 so far. 

The Genia event extraction task (BioNLP'13 

task 1, hereafter) (Kim et al., 2013) in Bi-

oNLP'13 Shared Task is consistent with the Ge-

nia task in BioNLP'11 Shared task. Nevertheless, 

BioNLP'13 task 1 focuses on event extraction 

from full texts while BioNLP’11 task 1 contains 

abstracts and full texts. Furthermore, the corefe-

rence resolution task separated from event ex-

traction task in BioNLP'11 is integrated to Bi-

oNLP'13 task 1, and there are more event types 

in the BioNLP'13 task 1 than those in BioNLP'11 

task 1. The BioNLP’13 shared task contains 

three parts, the training corpus, the development 

corpus and the test corpus. The training corpus 

consists of 10 full texts containing 2792 events. 

The development corpus for optimizing the pa-

rameters involves 10 full texts containing 3184 

events, while the test corpus is composed of 14 

full texts including 3301 events. To avoid the 

researchers optimizing parameters on the test 

corpus, it is not published, and we have the per-

mission to combine the training corpus and the 

development corpus as training set. However, we 

extend BioNLP'13 training set by adding the ab-

stracts of training set and development set in Bi-

oNLP'11 task 1 rather than merging the devel-

opment set of BioNLP'13 into the training set.  

Our system generally follows the Uturku sys-

tem reported by Björne et al. (2009), and uses a 

simple but efficient way to reduce the cascading 

errors. The Uturku system was a pipeline of trig-

ger detection, argument detection and post-

processing. Each of its components was simple  

to implement by reducing event extraction task 

into independent classification of triggers and 

arguments. Moreover, the Uturku system devel-

oped rich features and made extensive use of 

syntactic dependency parse graphs, and the rules 

in the post-processing step were efficient and 

simple. However, the stages of the pipeline in-

troduced cascading errors, meaning that the trig-

ger missed in the trigger detection would never 

be recalled in the following stages. By changing 

the pipeline and adding argument information in 

trigger detection, we construct a model for ex-

tracting complex events using rich features and 

achieve better performance than the baseline sys-

tem implemented according to Björne et al.'s 

(2009) paper. 

2 Our Event Extraction System  

Fig.1 shows the overall architecture of the pro-

posed system. Since 97% of all annotated events 

are fully contained within a single sentence, our 

system deals with one sentence at a time, which 

does not incur a large performance penalty but 

greatly reduces the size and complexity of the 

machine learning problems (Björne et al., 2009). 

The system’s components are different from 

those of the Uturku system by adding a second 

trigger detection component and a second edge 

detection component (argument detection). Trig-

ger detection component is used to recognize the 

trigger words that signify the event, and edge 

detection component is used to identify the ar-

guments that undergo the change. Semantic post-

processing component generates events consis-

tent with the restrictions on event argument types 

and combinations defined in the shared task. 
 

Input data

Sentence splitting

Tokenization

Parsing

First Trigger 

detection

(multi-class SVM)

First Edge detection

(multi-class SVM)

Second Trigger 

detection

(multi-class SVM)

Second Edge 

detection

(multi-class SVM)

Semantic

 post-processing

(Rule based)

Output data

 

Figure 1. The flow chart of our system. 

In the following sections, we present the im-

plementation for these stages in our biomedical 

event extraction system in detail and evaluate our 

system on the BioNLP’13 data sets. 

2.1 Trigger Detection 

nuclear extracts showed decreased or absent p65 protein levels

Neg_reg Pro

Theme

 
Figure 2. An example of the trigger consisting of two 

head tokens 

Trigger detection assigns each token an event 

class or a negative class (if the token is not a 

trigger). The head token is chosen when the real 

trigger consists of several tokens, which does not

110



Type Feature 

Primary features The token 

Part-Of-Speech of the token 

Base form 

The rest part of the token, getting rid of the stem word 

Token feature Token has a capital letter 

Token has a first letter of the sentence 

Token has a number 

Token has a symbol like “-”,”/”,”\” 

N-grams (n = 2, 3) of characters 

Govern and Dependent feature Dependency type 

Part-Of-Speech (POS) of the other token 

Combine the POS and the dependency type 

The word form of the other token 

Frequency features Number of named entities in the sentence 

Bag-of-word counts of token texts in the sentence 

Shortest path Token features of the token in the path 

N-grams of dependencies (n =2, 3, 4) 

N-grams of words (base form + POS) (n =2, 3, 4) 

N-grams of consecutive words (base form + POS) representing 

Governor-dependent relationships (n =1, 2, 3) 

Table 1: Features for the first trigger detection 

Type Feature 

Path feature The token in the path 

The POS of the token in the path 

The dependency type of edges in the path 

(all these features are combined with direction, length and the entity type) 

Table 2: Added feature for the second trigger detection 

incur performance penalty with the approximate 

span matching/approximate recursive matching 

mode (Kim et al., 2009).  Two head tokens may 

be chosen from one trigger when the trigger con-

sists of two appositives. For example, for the 

snippets “decreased or absent p65 protein le-

vels”, both “decreased” and “absent” are the 

head token of the trigger “decreased or absent”, 

shown in Fig 2. Rich features are extracted for 

the first trigger detection, shown in Table 1. 

To remove the erroneous events and correct 

the event type assigned in the first trigger detec-

tion, a second trigger detection is added in our 

system. Thus the second trigger detection is dif-

ferent from the first one. Uturku system shows 

that the trigger information improves the edge 

detection because of the constraints on the type 

of arguments. Naturally, the edge information is 

helpful for trigger detection with the same reason. 

As a result, this method can improve the preci-

sion of trigger performance. 

In order to leverage the argument information, 

we explore a lot of features of the edges which 

are the arguments detected in the first edge de-

tection. The edge information concerns the fea-

tures of the edges attached to the token. In the 

second trigger detection, we add all the path fea-

tures between the candidate trigger and argu-

ments attached to the candidate trigger detected 

in the first edge detection. These features contain 

the entity information of the argument, the de-

pendency path between the trigger and the argu-

ment and so on. Specially, the added features 

cannot contain any trigger type information ob-

tained in the first trigger detection, or the added 

features cannot do any help. The reason is that 

SVM classifier will classify samples only relying 

on the label feature if it is in the feature set. The 

added features are shown in Table 2. 

 

 

111



Type Features 

N-grams N-grams of consecutive tokens(n=2,3,4) in the path 

N-grams of vertex walks 

Terminal node feature Token feature of the terminal nodes 

The entity type of the terminal nodes 

Re-normalized confidences of all event class 

Frequency feature The length of the path 

The number of entities in the sentence 

Edges feature in the path Dependency type of the edges in the path 

The POS of the tokens in the path 

The tokens in the path 

Table 3: Features for edge detection 

2.2 Edge Detection 

Similar to the trigger detector, the edge detector 

is based on a multi-class SVM classifier. An 

edge is from a trigger to a trigger or from a trig-

ger to a protein. The edge detector classifies each 

candidate edge as a theme, a cause, or a negative 

denoting the absence of an edge between the two 

nodes in the given direction. The features in edge 

detection are shown in Table 3. As the trigger 

information is helpful in edge detection, the ter-

minal node feature contains it. Additionally，the 
first edge detection is completely the same as the 

second one, that is, they share the same features 

and machine learning strategy. 

2.3 Semantic Post-processing 

After the trigger detection and edge detection, 

the biomedical event cannot be produced directly. 

Some simple events may be attached with sever-

al proteins, and complex events may form circles. 

We develop a custom rule-based method to gen-

erate events that are consistent with the restric-

tions on event argument types and combinations 

defined in the shared task. For details, Björne et 

al.’s (2009) paper can be referred to. 

3 Tools and Component Combination  

We use the support vector machine (SVM) mul-

ti-class classifier (Crammer and Singer (2002),  

Tsochantaridis et al. (2004)) in the trigger detec-

tion and edge detection. Besides, the dependency 

parser used in our system is McClosky-Charniak 

domain-adapted parser (McClosky and  Charniak 

(2008)) and the dependency parse was provided 

in the share task
1
. To optimize the precision-

recall trade-off, we introduce β that decreases the 

classifier confidence score given to the negative 

                                                 
1
 http://2013.bionlp-st.org/supporting-resources 

trigger class as formula (1) as the Uturku system 

does (2009).  

score = score-(1-β)*abs(score)       (1) 

where abs(score) means the absolute value of 

score and β∈[0,1]. 

4 Evaluations and Discussion 

4.1 Evaluations 

Firstly, our system is evaluated on the develop-

ment set. Table 4 compares the performance be-

tween our system and the baseline. The baseline 

is implemented based on Björne et al.’s (2009) 

paper. Compared to baseline, the precision of our 

system is 6.08 percentage points higher while the 

recall increases 0.91 percentage points. From 

Table 4 we can see that our system is 2.85 F-

score higher than the baseline system. 

 

 Recall  Precision F-score 

Baseline  43.15 54.37 48.12 

Ours 44.06 60.45 50.97 

Table 4: Performance comparison on the development 

set using approximate span and recursive matching 

Secondly, the performance of our system is 

evaluated on the test data set with online evalua-

tion
2
. Table 5 shows the results for the baseline 

and the proposed system with argument informa-

tion to evaluate the importance of argument in-

formation. Integrating argument information, our 

system archives 1.78% F-score improvement. 

Compared to the baseline, the performance for 

complex events is very encouraging with about 

7.5 percentage points improvement in the Phos-

phorylation events, 1.77 percentage points im-

provement in the regulation events, 2.91 percen- 

                                                 
2
 http://bionlp-st.dbcls.jp/GE/2013/eval-test/ 

112



Event type # Our system Baseline 

R/P/F-score R/P/F-score 

Gene_expression 619 77.54/82.76/80.07 79.48/78.10/78.78 

Transcription 101 49.50/65.79/56.50 53.47/62.79/57.75 

Protein_catabolism 14 78.57/55.00/64.71 78.57/45.83/57.89 

Localization 99 35.35/89.74/50.72 38.38/84.44/52.78 

=[SIMPLE ALL]= 833 69.15/80.56/74.42 71.43/75.80/73.55 

Binding 333 40.84/44.16/42.43 42.64/44.65/43.63 

Protein_modification 1 0.00/0.00/0.00 0.00/0.00/0.00 

Phosphorylation 160 75.00/77.42/76.19 69.38/68.10/68.73 

Ubiquitination 30 0.00/0.00/0.00 0.00/0.00/0.00 

Acetylation 0 0.00/0.00/0.00 0.00/0.00/0.00 

Deacetylation 0 0.00/0.00/0.00 0.00/0.00/0.00 

=[PROT-MOD ALL]= 191 62.83/77.42/69.36 58.12/68.10/62.71 

Regulation 288 15.28/42.72/22.51 14.58/35.90/20.74 

Positive_regulation 1130 29.20/44.47/35.26 26.11/42.51/32.35 

Negative_regulation 526 26.81/41.47/32.56 25.10/35.11/29.27 

=[REGULATION ALL]= 1944 26.49/43.46/32.92 24.13/39.51/29.96 

==[EVENT TOTAL]== 3301 40.81/57.00/47.56 39.90/53.69/45.78 

Table 5: Approximate span matching/approximate recursive matching on test data set. 

Th(E1)

Triggering of the human interleukin-6 gene by interferon-gamma and tumor necrosis factor-alpha 

Binding Pro Pro Pro

Th(E2) Th(E1)
Th(E2)

  
(a) 

Th(E1)

Triggering of the human interleukin-6 gene by interferon-gamma and tumor necrosis factor-alpha 

Pos-Reg Pro Pro Pro

Cause(E2) Cause(E1)
Th(E2)

 
(b) 

Figure 3: (a) A result of a fragment using the first trigger detection. (b) A result of a fragment using the second 

trigger detection. 

tage points improvement in the positive regula-

tion events and 3.29 percentage points increase 

in the negative regulation events, but not much 

loss in other events. As a consequence, the total 

F-score of our system is 47.56%, 1.78 percentage 

points higher than the baseline system and ob-

tains the 5th place in BioNLP'13 task 1. 

4.2 Discussion 

Our system achieves better performance than the 

baseline thanks to the second trigger detection. 

The second trigger detection improves the per-

formance of event extraction in two ways. Firstly, 

the triggers that cannot form events are directly 

deleted, and therefore the corresponding errone-

ous events are deleted. Secondly, since the erro-

neous triggers are deleted or the triggers recog-

nized in the first trigger detection are given the 

right types in the second trigger detection, the 

corresponding arguments are reconstructed to 

form right events. Fig.3 shows an example. In 

the first trigger detection, the trigger “triggering” 

is recognized as the illegal type of “binding” so 

that “interferon-gamma” and “tumor necrosis 

factor-alpha” are illegally detected as theme ar-

guments of “triggering”, resulting in erroneous 

events. However, in the second trigger detection, 

113



“triggering” is correctly revised as the type of 

positive regulation, so the arguments are recon-

structed, which makes the positive regulation 

events (E1 and E2) right. As a result, the preci-

sion of event detection increases as well as the 

recall. 

The proposed method is an efficient way to 

reduce cascading errors in pipeline system. 

Moreover, Riedel and McCallum (2011) pro-

posed a dual decomposition-based model, anoth-

er efficient method to get around cascading er-

rors. Following Riedel et al.’s (2011) paper, we 

implement a dual decomposition-based system 

using the same features in our system. Table 6 

shows the performance comparison on the devel-

opment set of BioNLP’09 between our system 

and dual decomposition-based system. The com-

parison indicates that the proposed method is 

comparable to the stat-of-the-art systems.  

 

 Recall  Precision F-score 

Dual Decom-

position 

50.08 63.66 56.06 

Ours 53.88 59.67 56.63 

Table 6: Performance comparison on the development 

set of BioNLP’09 using approximate span and recur-

sive matching based on different methods 

5 Conclusions 

We proposed a simple but effective method to 

improve event extraction by boosting the trigger 

detection. The added edge information in the 

second trigger detection improves the perfor-

mance of trigger detection. Features from the 

dependency parse graphs are the main features 

we use for event extraction. 

The future work includes: the first trigger de-

tection should classify a token into three classes: 

simple event type, complex event type and none 

event type; discovering some more helpful edge 

features in the second trigger detection; solving 

coreference problem with coreference resolution 

approach. Besides, the dual decomposition-based 

method will be improved and further compared 

with the pipeline system. 

 

Acknowledgments 
 

This work is supported by grant from the Nation-

al Natural Science Foundation of China (no. 

61173101, 61173100). 

References  

Antti Airola, Sampo Pyysalo, Jari Björne, Tapio Pa-

hikkala, Filip Ginter, and Tapio Salakoski. 2008. 

All-paths graph kernel for protein-protein interac-

tion extraction with evaluation of cross-corpus 

learning. BMC Bioinformatics, 9(Suppl 11):S2. 

Chris Quirk, Pallavi Choudhury, Michael Gamon, and 

Lucy Vanderwend. 2011. MSR-NLP Entry in Bi-

oNLP Shared Task 2011. In Proceedings of the Bi-

oNLP 2011 Workshop Companion Volume for 

Shared Task, Portland, Oregon, June. Association 

for Computational Linguistics. 

David McClosky and Eugene Charniak. 2008. Self-

training for biomedical parsing. In Proceedings of 

ACL-08: HLT, Short Papers, pages 101–104. Asso-

ciation for Computational Linguistics. 

Hoifung Poon, Lucy Vanderwende. 2010. Joint Infe-

rence for Knowledge Extraction from Biomedical 

Literature. In Proceedings of the North American 

Chapter of the Association for Computational Lin-

guistics-Human Language Technologies 2010 con-

ference. 

Hong-Woo Chun, Yoshimasa Tsuruoka, Jin-Dong 

Kim, Rie Shiba, Naoki Nagata, Teruyoshi Hishiki, 

and Jun’ichi Tsujii. 2006. Extraction of gene-

disease relations from medline using domain dic-

tionaries and machine learning. In Proceedings of 

the Pacific Symposium on Biocomputing (PSB’06), 

pages 4–15. 

Ioannis Tsochantaridis, Thomas Hofmann, Thorsten 

Joachims, and Yasemin Altun. 2004. Support vec-

tor machine learning for interdependent and struc-

tured output spaces. In Proceedings of the Twenty-

first International Conference on Machine Learn-

ing (ICML’04), pages 104–111. ACM. 

Jari Björne, Juho Heimonen, Filip Ginter, Antti Airola, 

Tapio Pahikkala, and Tapio Salakoski. 2009. Ex-

tracting complex biological events with rich graph-

based feature sets. In Proceedings of the BioNLP 

2009 Workshop Companion Volume for Shared 

Task, pages 10–18, Boulder, Colorado, June. Asso-

ciation for Computational Linguistics.  

Jari Björne and Tapio Salakoski. 2011. Generalizing 

biomedical event extraction. In Proceedings of the 

BioNLP 2011 Workshop Companion Volume for 

Shared Task, Portland, Oregon, June. Association 

for Computational Linguistics. 

Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yo-

shinobu Kano, and Junichi Tsujii. 2009. Overview 

of BioNLP’09 Shared Task on event extraction. In 

Proceedings of the NAACL-HLT 2009 Workshop 

on Natural Language Processing in Biomedicine 

(BioNLP’09). ACL. 

Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert 

Bossy, and Jun’ichi Tsujii. 2011. Overview of Bi-

114



oNLP Shared Task 2011. In Proceedings of the Bi-

oNLP 2011 Workshop Companion Volume for 

Shared Task, Portland, Oregon, June. Association 

for Computational Linguistics. 

Jin-Dong Kim, Yue Wang and Yamamoto Yasunori. 

2013. The Genia Event Extraction Shared Task, 

2013 Edition - Overview. In Proceedings of the Bi-

oNLP Shared Task 2013 Workshop, Sofia, Bulgaria, 

Aug. Association for Computational Linguistics. 

Koby Crammer and Yoram Singer. 2002. On the al-

gorithmic implementation of multiclass kernel-

based vector machines. Journal of Machine Learn-

ing Research, 2:265–292. 

Makoto Miwa, Rune Sætre, Yusuke Miyao, and-

Jun’ichi Tsujii. 2009. A rich feature vector for 

protein–protein interaction extraction from mul-

tiple corpora. In EMNLP’09: Proceedings of the 

2009 Conference on Empirical Methods in Natu-

ral Language Processing, pages 121–130, Morris-

town, NJ, USA. Association for Computational 

Linguistics. 

Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, and 

Jun’ichi Tsujii. 2010a . A comparative study of 

syntactic parsers for event extraction. In Proceed-

ings of BioNLP’10  p. 37–45. 

Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, and 

Jun’ichi Tsujii. 2010b. Evaluating dependency re-

presentation for event extraction. In Proceedings of 

the 23rd International Conference on Computa-

tional Linguistics, COLING ’10, Association for 

Computational Linguistics, 2010; p. 779–787. 

Makoto Miwa, Paul Thompson, and Sophia Anania-

dou. 2012. Boosting automatic event extraction 

from the literature using domain adaptation and co-

reference resolution. Bioinformatics.  

Sebastian Riedel, Hong-Woo Chun, Toshihisa Taka-

gi,and Jun’ichi Tsujii. 2009. A Markov logic ap-

proach to bio-molecular event extraction. In Bi-

oNLP’09: Proceedings of the Workshop on BioNLP, 

pages 41-49, Morristown, NJ, USA. Association 

for Computational Linguistics. 

Sebastian Riedel and Andrew McCallum. 2011. Ro-

bust Biomedical Event Extraction with Dual De-

composition and Minimal Domain Adaptation. In 

Proceedings of the BioNLP 2011 Workshop Com-

panion Volume for Shared Task, Portland, Oregon, 

June. Association for Computational Linguistics. 

115


