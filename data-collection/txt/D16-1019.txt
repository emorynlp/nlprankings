



















































Jointly Embedding Knowledge Graphs and Logical Rules


Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 192–202,
Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics

Jointly Embedding Knowledge Graphs and Logical Rules

Shu Guo†‡, Quan Wang†‡∗, Lihong Wang§, Bin Wang†‡, Li Guo†‡
†Institute of Information Engineering, Chinese Academy of Sciences, Beijing 100093, China

‡University of Chinese Academy of Sciences, Beijing 100049, China
{guoshu,wangquan,wangbin,guoli}@iie.ac.cn

§National Computer Network Emergency Response Technical Team
Coordination Center of China, Beijing 100029, China

wlh@isc.org.cn

Abstract

Embedding knowledge graphs into continuous
vector spaces has recently attracted increasing
interest. Most existing methods perform the
embedding task using only fact triples. Logi-
cal rules, although containing rich background
information, have not been well studied in this
task. This paper proposes a novel method of
jointly embedding knowledge graphs and log-
ical rules. The key idea is to represent and
model triples and rules in a unified framework.
Specifically, triples are represented as atomic
formulae and modeled by the translation as-
sumption, while rules represented as complex
formulae and modeled by t-norm fuzzy logic-
s. Embedding then amounts to minimizing a
global loss over both atomic and complex for-
mulae. In this manner, we learn embeddings
compatible not only with triples but also with
rules, which will certainly be more predictive
for knowledge acquisition and inference. We
evaluate our method with link prediction and
triple classification tasks. Experimental re-
sults show that joint embedding brings signif-
icant and consistent improvements over state-
of-the-art methods. Particularly, it enhances
the prediction of new facts which cannot even
be directly inferred by pure logical inference,
demonstrating the capability of our method to
learn more predictive embeddings.

1 Introduction

Knowledge graphs (KGs) provide rich structured in-
formation and have become extremely useful re-
sources for many NLP related applications like

∗Corresponding author: Quan Wang.

word sense disambiguation (Wasserman-Pritsker et
al., 2015) and information extraction (Hoffmann et
al., 2011). A typical KG represents knowledge as
multi-relational data, stored in triples of the for-
m (head entity, relation, tail entity), e.g., (Paris,
Capital-Of, France). Although powerful in
representing structured data, the symbolic nature of
such triples makes KGs, especially large-scale KGs,
hard to manipulate.

Recently, a promising approach, namely knowl-
edge graph embedding, has been proposed and suc-
cessfully applied to various KGs (Nickel et al., 2012;
Socher et al., 2013; Bordes et al., 2014). The key
idea is to embed components of a KG including en-
tities and relations into a continuous vector space,
so as to simplify the manipulation while preserving
the inherent structure of the KG. The embeddings
contain rich semantic information about entities and
relations, and can significantly enhance knowledge
acquisition and inference (Weston et al., 2013).

Most existing methods perform the embedding
task based solely on fact triples (Bordes et al., 2013;
Wang et al., 2014; Nickel et al., 2016). The only re-
quirement is that the learned embeddings should be
compatible with those facts. While logical rules con-
tain rich background information and are extreme-
ly useful for knowledge acquisition and inference
(Jiang et al., 2012; Pujara et al., 2013), they have not
been well studied in this task. Wang et al. (2015)
and Wei et al. (2015) tried to leverage both em-
bedding methods and logical rules for KG comple-
tion. In their work, however, rules are modeled sep-
arately from embedding methods, serving as post-
processing steps, and thus will not help to obtain

192



���������

	��
�

���������	�

����

����������	�

����

����������������������

�������������������

Figure 1: Simple illustration of KALE.

better embeddings. Rocktäschel et al. (2015) recent-
ly proposed a joint model which injects first-order
logic into embeddings. But it focuses on the rela-
tion extraction task, and creates vector embeddings
for entity pairs rather than individual entities. Since
entities do not have their own embeddings, relations
between unpaired entities cannot be effectively dis-
covered (Chang et al., 2014).

In this paper we introduce KALE, a new approach
that learns entity and relation Embeddings by joint-
ly modeling Knowledge And Logic. Knowledge
triples are taken as atoms and modeled by the trans-
lation assumption, i.e., relations act as translations
between head and tail entities (Bordes et al., 2013).
A triple (ei, rk, ej) is scored by ∥ei + rk − ej∥1,
where ei, rk, and ej are the vector embeddings for
entities and relations. The score is then mapped to
the unit interval [0, 1] to indicate the truth value of
that triple. Logical rules are taken as complex for-
mulae constructed by combining atoms with logical
connectives (e.g., ∧ and ⇒), and modeled by t-norm
fuzzy logics (Hájek, 1998). The truth value of a rule
is a composition of the truth values of the constituen-
t atoms, defined by specific logical connectives. In
this way, KALE represents triples and rules in a uni-
fied framework, as atomic and complex formulae re-
spectively. Figure 1 gives a simple illustration of the
framework. After unifying triples and rules, KALE
minimizes a global loss involving both of them to
obtain entity and relation embeddings. The learned
embeddings are therefore compatible not only with
triples but also with rules, which will definitely be
more predictive for knowledge acquisition and in-
ference.

The main contributions of this paper are summa-
rized as follows. (i) We devise a unified framework

that jointly models triples and rules to obtain more
predictive entity and relation embeddings. The new
framework KALE is general enough to handle any
type of rules that can be represented as first-order
logic formulae. (ii) We evaluate KALE with link
prediction and triple classification tasks on WordNet
(Miller, 1995) and Freebase (Bollacker et al., 2008).
Experimental results show significant and consistent
improvements over state-of-the-art methods. Partic-
ularly, joint embedding enhances the prediction of
new facts which cannot even be directly inferred by
pure logical inference, demonstrating the capability
of KALE to learn more predictive embeddings.

2 Related Work

Recent years have seen rapid growth in KG em-
bedding methods. Given a KG, such methods aim
to encode its entities and relations into a continu-
ous vector space, by using neural network architec-
tures (Socher et al., 2013; Bordes et al., 2013; Bor-
des et al., 2014), matrix/tensor factorization tech-
niques (Nickel et al., 2011; Riedel et al., 2013;
Chang et al., 2014), or Bayesian clustering strate-
gies (Kemp et al., 2006; Xu et al., 2006; Sutskever et
al., 2009). Among these methods, TransE (Bordes et
al., 2013), which models relations as translating op-
erations, achieves a good trade-off between predic-
tion accuracy and computational efficiency. Various
extensions like TransH (Wang et al., 2014) and Tran-
sR (Lin et al., 2015b) are later proposed to further
enhance the prediction accuracy of TransE. Most ex-
isting methods perform the embedding task based
solely on triples contained in a KG. Some recent
work tries to further incorporate other types of infor-
mation available, e.g., relation paths (Neelakantan et
al., 2015; Lin et al., 2015a; Luo et al., 2015), relation
type-constraints (Krompaßet al., 2015), entity type-
s (Guo et al., 2015), and entity descriptions (Zhong
et al., 2015), to learn better embeddings.

Logical rules have been widely studied in knowl-
edge acquisition and inference, usually on the basis
of Markov logic networks (Richardson and Domin-
gos, 2006; Bröcheler et al., 2010; Pujara et al., 2013;
Beltagy and Mooney, 2014). Recently, there has
been growing interest in combining logical rules and
embedding models. Wang et al. (2015) and Wei et
al. (2015) tried to utilize rules to refine predictions

193



made by embedding models, via integer linear pro-
gramming or Markov logic networks. In their work,
however, rules are modeled separately from embed-
ding models, and will not help obtain better embed-
dings. Rocktäschel et al. (2015) proposed a joint
model that injects first-order logic into embeddings.
But their work focuses on relation extraction, cre-
ating vector embeddings for entity pairs, and hence
fails to discover relations between unpaired entities.
This paper, in contrast, aims at learning more pre-
dictive embeddings by jointly modeling knowledge
and logic. Since each entity has its own embedding,
our approach can successfully make predictions be-
tween unpaired entities, providing greater flexibility
for knowledge acquisition and inference.

3 Jointly Embedding Knowledge and Logic

We first describe the formulation of joint embed-
ding. We are given a KG containing a set of triples
K = {(ei, rk, ej)}, with each triple composed of t-
wo entities ei, ej ∈ E and their relation rk ∈ R.
Here E is the entity vocabulary and R the relation
set. Besides the triples, we are given a set of logical
rules L, either specified manually or extracted auto-
matically. A logical rule is encoded, for example,
in the form of ∀x, y : (x, rs, y) ⇒ (x, rt, y), stat-
ing that any two entities linked by relation rs should
also be linked by relation rt. Entities and relations
are associated with vector embeddings, denoted by
e, r ∈ Rd, representing their latent semantics. The
proposed method, KALE, aims to learn these em-
beddings by jointly modeling knowledge triples K
and logical rules L.

3.1 Overview

To enable joint embedding, a key ingredient of
KALE is to unify triples and rules, in terms of first-
order logic (Rocktäschel et al., 2014; Rocktäschel et
al., 2015). A triple (ei, rk, ej) is taken as a ground
atom which applies a relation rk to a pair of entities
ei and ej . Given a logical rule, it is first instantiated
with concrete entities in the vocabulary E , resulting
in a set of ground rules. For example, a universal-
ly quantified rule ∀x, y : (x,Capital-Of, y) ⇒
(x,Located-In, y) might be instantiated with the
concrete entities of Paris and France, giving the
ground rule (Paris,Capital-Of,France) ⇒

(Paris,Located-In,France).1 A ground rule
can then be interpreted as a complex formula, con-
structed by combining ground atoms with logical
connectives (e.g. ∧ and ⇒).

Let F denote the set of training formulae, both
atomic (triples) and complex (ground rules). KALE
further employs a truth function I : F → [0, 1] to
assign a soft truth value to each formula, indicating
how likely a triple holds or to what degree a ground
rule is satisfied. The truth value of a triple is deter-
mined by the corresponding entity and relation em-
beddings. The truth value of a ground rule is deter-
mined by the truth values of the constituent triples,
via specific logical connectives. In this way, KALE
models triples and rules in a unified framework. See
Figure 1 for an overview. Finally, KALE minimizes
a global loss over the training formulae F to learn
entity and relation embeddings compatible with both
triples and rules. In what follows, we describe the
key components of KALE, including triple model-
ing, rule modeling, and joint learning.

3.2 Triple Modeling
To model triples we follow TransE (Bordes et al.,
2013), as it is simple and efficient while achieving
state-of-the-art predictive performance. Specifically,
given a triple (ei, rk, ej), we model the relation em-
bedding rk as a translation between the entity em-
beddings ei and ej , i.e., we want ei + rk ≈ ej when
the triple holds. The intuition here originates from
linguistic regularities such as France− Paris =
Germany − Berlin (Mikolov et al., 2013). In
relational data, such analogy holds because of the
certain relation Capital-Of, through which we
will get Paris + Capital-Of = France and
Berlin + Capital-Of = Germany. Then, we
score each triple on the basis of ∥ei + rk − ej∥1,
and define its soft truth value as

I (ei, rk, ej) = 1 −
1

3
√

d
∥ei + rk − ej∥1 , (1)

where d is the dimension of the embedding space.
It is easy to see that I (ei, rk, ej) ∈ [0, 1] with the
constraints ∥ei∥2 ≤ 1, ∥ej∥2 ≤ 1, and ∥rk∥2 ≤

1Our approach actually takes as input rules represented in
first-order logic, i.e., those with quantifiers such as ∀. But it
could be hard to deal with quantifiers, so we use ground rules,
i.e., propositional statements during learning.

194



1.2 I (ei, rk, ej) is expected to be large if the triple
holds, and small otherwise.

3.3 Rule Modeling
To model rules we use t-norm fuzzy logics (Hájek,
1998), which define the truth value of a complex for-
mula as a composition of the truth values of its con-
stituents, through specific t-norm based logical con-
nectives. We follow Rocktäschel et al. (2015) and
use the product t-norm. The compositions associat-
ed with logical conjunction (∧), disjunction (∨), and
negation (¬) are defined as follow:

I(f1 ∧ f2) = I(f1)·I(f2),
I(f1 ∨ f2) = I(f1) + I(f2) − I(f1)·I(f2),

I(¬f1) = 1 − I(f1),
where f1 and f2 are two constituent formulae, either
atomic or complex. Given these compositions, the
truth value of any complex formula can be calculat-
ed recursively, e.g.,

I(¬f1 ∧ f2) = I(f2) − I(f1)·I(f2),
I(f1 ⇒ f2) = I(f1)·I(f2) − I(f1) + 1.

This paper considers two types of rules. The first
type is ∀x, y : (x, rs, y)⇒(x, rt, y). Given a ground
rule f , (em, rs, en) ⇒ (em, rt, en), the truth value
is calculated as:

I(f)=I(em, rs, en)·I(em, rt, en)
−I(em, rs, en) + 1, (2)

where I(·,·,·) is the truth value of a constituent triple,
defined by Eq. (1). The second type is ∀x, y, z :
(x, rs1 , y) ∧ (y, rs2 , z) ⇒ (x, rt, z). Given a ground
rule f , (eℓ, rs1 , em)∧ (em, rs2 , en) ⇒ (eℓ, rt, en),
the truth value is:

I(f)=I(eℓ, rs1 , em)·I(em, rs2 , en)·I(eℓ, rt, en)
−I(eℓ, rs1 , em)·I(em, rs2 , en) + 1. (3)

The larger the truth values are, the better the ground
rules are satisfied. It is easy to see that besides these
two types of rules, the KALE framework is general
enough to handle any rules that can be represented
as first-order logic formulae. The investigation of
other types of rules will be left for future work.

2Note that 0 ≤ ∥ei + rk − ej∥1 ≤ ∥ei∥1 + ∥rk∥1 +
∥ej∥1 ≤ 3

√
d, where the last inequality holds because ∥x∥1 =∑

i |xi| ≤
√

d
∑

i x
2
i =

√
d ∥x∥2 for any x ∈ Rd, according

to the Cauchy-Schwarz inequality.

3.4 Joint Learning

After unifying triples and rules as atomic and com-
plex formulae, we minimize a global loss over this
general representation to learn entity and relation
embeddings. We first construct a training set F con-
taining all positive formulae, including (i) observed
triples, and (ii) ground rules in which at least one
constituent triple is observed. Then we minimize
a margin-based ranking loss, enforcing positive for-
mulae to have larger truth values than negative ones:

min
{e},{r}

∑

f+∈F

∑

f−∈Nf+

[
γ − I(f+) + I(f−)

]
+

,

s.t. ∥e∥2 ≤ 1,∀e ∈ E ; ∥r∥2 ≤ 1, ∀r ∈ R. (4)

Here f+ ∈ F is a positive formula, f− ∈ Nf+ a
negative one constructed for f+, γ a margin sepa-
rating positive and negative formulae, and [x]+ ,
max{0, x}. If f+ , (ei, rk, ej) is a triple, we con-
struct f− by replacing either ei or ej with a random
entity e ∈ E , and calculate its truth value according
to Eq. (1). For example, we might generate a neg-
ative instance (Paris,Capital-Of,Germany)
for the triple (Paris,Capital-Of,France). If
f+ , (em, rs, en) ⇒ (em, rt, en) or (eℓ, rs1 , em) ∧
(em, rs2 , en) ⇒ (eℓ, rt, en) is a ground rule, we con-
struct f− by replacing rt in the consequent with a
random relation r ∈ R, and calculate its truth value
according to Eq. (2) or Eq. (3). For example, given a
ground rule (Paris,Capital-Of,France) ⇒
(Paris,Located-In,France), a possible neg-
ative instance (Paris,Capital-Of,France)⇒
(Paris,Has-Spouse,France) could be gener-
ated. We believe that most instances (both triples
and ground rules) generated in this way are truly
negative. Stochastic gradient descent in mini-batch
mode is used to carry out the minimization. To satis-
fy the ℓ2-constraints, e and r are projected to the unit
ℓ2-ball before each mini-batch. Embeddings learned
in this way are required to be compatible with not
only triples but also rules.

3.5 Discussions

Complexity. We compare KALE with several state-
of-the-art embedding methods in space complexity
and time complexity (per iteration) during learning.
Table 1 shows the results, where d is the dimension

195



Method Complexity (Space/Time)

SE (Bordes et al., 2011) ned+2nrd2 O(ntd2)
LFM (Jenatton et al., 2012) ned+nrd2 O(ntd2)
TransE (Bordes et al., 2013) ned+nrd O(ntd)
TransH (Wang et al., 2014) ned+2nrd O(ntd)
TransR (Lin et al., 2015b) ned+nr(d2+d) O(ntd2)

KALE (this paper) ned+nrd O(ntd+ngd)

Table 1: Complexity of different embedding methods.

of the embedding space, and ne/nr/nt/ng is the num-
ber of entities/relations/triples/ground rules. The re-
sults indicate that incorporating additional rules will
not significantly increase the space or time complex-
ity of KALE, keeping the model complexity almost
the same as that of TransE (optimal among the meth-
ods listed in the table). But please note that KALE
needs to ground universally quantified rules before
learning, which further requires O(nunt/nr) in time
complexity. Here, nu is the number of universally
quantified rules, and nt/nr is the averaged number
of observed triples per relation. During grounding,
we select those ground rules with at least one triple
observed. Grounding is required only once before
learning, and is not included during the iterations.

Extensions. Actually, our approach is quite general.
(i) Besides TransE, a variety of embedding method-
s, e.g., those listed in Table 1, can be used for triple
modeling (Section 3.2), as long as we further define
a mapping f : R → [0, 1] to map original scores to
soft truth values. (ii) Besides the two types of rules
introduced in Section 3.3, other types of rules can
also be handled as long as they can be represented
as first-order logic formulae. (iii) Besides the prod-
uct t-norm, other types of t-norm based fuzzy logics
can be used for rule modeling (Section 3.3), e.g., the
Łukasiewicz t-norm used in probabilistic soft log-
ic (Bröcheler et al., 2010) and the minimum t-norm
used in fuzzy description logic (Stoilos et al., 2007).
(iv) Besides the pairwise ranking loss, other type-
s of loss functions can be designed for joint learn-
ing (Section 3.4), e.g., the pointwise squared loss or
the logarithmic loss (Rocktäschel et al., 2014; Rock-
täschel et al., 2015).

4 Experiments

We empirically evaluate KALE with two tasks: (i)
link prediction and (ii) triple classification.

Dataset # Ent # Rel # Train/Valid/Test-I/Test-II # Rule

FB122 9,738 122 91,638 9,595 5,057 6,186 78,488
WN18 40,943 18 141,442 5,000 1,394 3,606 119,222

Table 3: Statistics of datasets.

4.1 Experimental Setup

Datasets. We use two datasets: WN18 and FB122.
WN18 is a subgraph of WordNet containing 18 rela-
tions. FB122 is composed of 122 Freebase relations
regarding the topics of “people”, “location”, and “s-
ports”, extracted from FB15K. Both WN18 and F-
B15K are released by Bordes et al. (2013)3. Triples
on each dataset are split into training/validation/test
sets, used for model training, parameter tuning, and
evaluation respectively. For WN18 we use the o-
riginal data split, and for FB122 we extract triples
associated with the 122 relations from the training,
validation, and test sets of FB15K.

We further create logical rules for each dataset,
in the form of ∀x, y : (x, rs, y) ⇒ (x, rt, y) or
∀x, y, z : (x, rs1 , y) ∧ (y, rs2 , z) ⇒ (x, rt, z). To
do so, we first run TransE to get entity and relation
embeddings, and calculate the truth value for each
of such rules according to Eq. (2) or Eq. (3). Then
we rank all such rules by their truth values and man-
ually filter those ranked at the top. We finally create
47 rules on FB122, and 14 on WN18 (see Table 2 for
examples). The rules are then instantiated with con-
crete entities (grounding). Ground rules in which at
least one constituent triple is observed in the train-
ing set are used in joint learning.

Note that some of the test triples can be inferred
by directly applying these rules on the training set
(pure logical inference). On each dataset, we fur-
ther split the test set into two parts, test-I and test-II.
The former contains triples that cannot be directly
inferred by pure logical inference, and the latter the
remaining test triples. Table 3 gives some statistics
of the datasets, including the number of entities, re-
lations, triples in training/validation/test-I/test-II set,
and ground rules.

Comparison settings. As baselines we take the em-
bedding techniques of TransE, TransH, and Tran-
sR. TransE models relation embeddings as transla-
tion operations between entity embeddings. TransH

3https://everest.hds.utc.fr/doku.php?id=en:smemlj12

196



∀x, y : /sports/athlete/team(x, y) ⇒ /sports/sports team/player(y, x)
∀x, y : /location/country/capital(x, y) ⇒ /location/location/contains(x, y)
∀x, y, z : /people/person/nationality(x, y) ∧ /location/country/official language(y, z) ⇒ /people/person/languages(x, z)
∀x, y, z : /country/administrative divisions(x, y) ∧ /administrative division/capital(y, z) ⇒ /country/second level divisions(x, z)
∀x, y : hypernym(x, y) ⇒ hyponym(y, x)
∀x, y : instance hypernym(x, y) ⇒ instance hyponym(y, x)
∀x, y : synset domain topic of(x, y) ⇒ member of domain topic(y, x)

Table 2: Examples of rules created.

and TransR are extensions of TransE. They further
allow entities to have distinct embeddings when in-
volved in different relations, by introducing relation-
specific hyperplanes and projection matrices respec-
tively. All the three methods have been demonstrat-
ed to perform well on WordNet and Freebase data.

We further test our approach in three different sce-
narios. (i) KALE-Trip uses triples alone to perform
the embedding task, i.e., only the training triples are
included in the optimization Eq. (4). It is a linear-
ly transformed version of TransE. The only differ-
ence is that relation embeddings are normalized in
KALE-Trip, but not in TransE. (ii) KALE-Pre first
repeats pure logical inference on the training set and
adds inferred triples as additional training data, until
no further triples can be inferred. Both original and
inferred triples are then included in the optimization.
For example, given a logical rule ∀x, y : (x, rs, y)⇒
(x, rt, y), a new triple (ei, rt, ej) can be inferred if
(ei, rs, ej) is observed in the training set, and both
triples will be used as training instances for embed-
ding. (iii) KALE-Joint is the joint learning scenari-
o, which considers both training triples and ground
rules in the optimization. In the aforementioned
example, training triple (ei, rs, ej) and ground rule
(ei, rs, ej) ⇒ (ei, rt, ej) will be used in the train-
ing process of KALE-Joint, without explicitly in-
corporating triple (ei, rt, ej). Among the method-
s, TransE/TransH/TransR and KALE-Trip use only
triples, while KALE-Pre/KALE-Joint further incor-
porates rules, before or during embedding.

Implementation details. We use the code provid-
ed by Bordes et al. (2013) for TransE4, and the code
provided by Lin et al. (2015b) for TransH and Tran-
sR5. KALE is implemented in Java. Note that Lin
et al. (2015b) initialized TransR with the results of

4https://github.com/glorotxa/SME
5https://github.com/mrlyk423/relation extraction

TransE. However, to ensure fair comparison, we ran-
domly initialize all the methods in our experiments.
For all the methods, we create 100 mini-batches on
each dataset, and tune the embedding dimension d
in {20, 50, 100}. For TransE, TransH, and Tran-
sR which score a triple by a distance in R+, we
tune the learning rate η in {0.001, 0.01, 0.1}, and
the margin γ in {1, 2, 3, 4}. For KALE which s-
cores a triple (as well as a ground rule) by a soft
truth value in the unit interval [0, 1], we set the learn-
ing rate η in {0.01, 0.02, 0.05, 0.1}, and the mar-
gin γ in {0.1, 0.12, 0.15, 0.2}. KALE allows triples
and rules to have different weights, with the former
fixed to 1, and the latter (denoted by λ) selected in
{0.001, 0.01, 0.1, 1}.

4.2 Link Prediction
This task is to complete a triple (ei, rk, ej) with ei or
ej missing, i.e., predict ei given (rk, ej) or predict ej
given (ei, rk).

Evaluation protocol. We follow the same evalua-
tion protocol used in TransE (Bordes et al., 2013).
For each test triple (ei, rk, ej), we replace the head
entity ei by every entity e′i in the dictionary, and cal-
culate the truth value (or distance) for the corrupted
triple (e′i, rk, ej). Ranking the truth values in de-
scending order (or the distances in ascending order),
we get the rank of the correct entity ei. Similarly, we
can get another rank by corrupting the tail entity ej .
Aggregated over all the test triples, we report three
metrics: (i) the mean reciprocal rank (MRR), (ii) the
median of the ranks (MED), and (iii) the proportion
of ranks no larger than n (HITS@N). We do not re-
port the averaged rank (i.e., the “Mean Rank” metric
used by Bordes et al. (2013)), since it is usually sen-
sitive to outliers (Nickel et al., 2016).

Note that a corrupted triple may exist in KGs,
which should also be taken as a valid triple. Consid-
er a test triple (Paris,Located-In,France)

197



Test-I Test-II Test-ALL

MRR MED
HITS@N (%)

MRR MED
HITS@N (%)

MRR MED
HITS@N (%)

3 5 10 3 5 10 3 5 10

FB
12

2

TransE 0.220 29.0 25.7 32.4 40.6 0.296 5.0 40.0 50.8 57.8 0.262 10.0 33.6 42.5 50.0
TransH 0.218 29.0 25.0 31.3 39.2 0.297 6.0 37.5 48.5 56.3 0.249 12.0 31.9 40.7 48.6
TransR 0.219 31.0 24.7 30.8 38.9 0.273 9.0 32.4 42.8 51.6 0.261 15.0 28.9 37.4 45.9
KALE-Trip 0.201 25.0 23.9 31.6 40.1 0.309 5.0 40.9 51.3 58.0 0.261 11.0 33.3 42.4 50.0
KALE-Pre 0.203 25.0 24.1 31.7 40.2 0.368 4.0 47.3 55.4 61.4 0.294 9.0 36.9 44.8 51.9
KALE-Joint 0.229 21.0 26.3 33.8 42.2 0.357 4.0 44.0 53.0 59.3 0.299 9.0 36.1 44.3 51.6

W
N

18

TransE 0.248 4.0 40.9 60.6 77.0 0.363 3.0 59.4 70.8 81.4 0.331 3.0 54.3 67.9 80.2
TransH 0.242 4.0 39.2 60.1 75.9 0.482 2.0 63.5 70.8 79.3 0.415 3.0 56.7 67.8 78.3
TransR 0.240 4.0 40.1 57.7 71.6 0.449 3.0 55.7 64.5 74.3 0.391 3.0 51.3 62.6 73.5
KALE-Trip 0.250 4.0 40.6 62.3 78.1 0.393 2.0 61.9 71.2 80.6 0.353 3.0 56.0 68.7 79.9
KALE-Pre 0.248 4.0 40.4 61.5 78.2 0.451 3.0 69.6 77.5 85.3 0.395 3.0 61.4 73.0 83.3
KALE-Joint 0.260 4.0 43.6 64.1 79.2 0.563 2.0 67.6 73.8 81.0 0.478 2.0 60.9 71.1 80.5

Table 4: Link prediction results on the test-I, test-II, and test-all sets of FB122 and WN18 (raw setting).

Test-I Test-II Test-ALL

MRR MED
HITS@N (%)

MRR MED
HITS@N (%)

MRR MED
HITS@N (%)

3 5 10 3 5 10 3 5 10

FB
12

2

TransE 0.296 13.0 36.0 41.5 48.1 0.630 2.0 77.5 82.8 88.4 0.480 2.0 58.9 64.2 70.2
TransH 0.280 15.0 33.6 39.1 46.4 0.606 2.0 70.1 75.4 82.0 0.460 3.0 53.7 59.1 66.0
TransR 0.283 16.0 33.4 39.2 46.0 0.499 2.0 57.0 63.2 70.1 0.401 5.0 46.4 52.4 59.3
KALE-Trip 0.299 10.0 36.6 42.9 50.2 0.650 2.0 79.0 83.4 88.7 0.492 2.0 59.9 65.2 71.4
KALE-Pre 0.291 11.0 35.8 41.9 49.8 0.713 1.0 82.9 86.1 89.9 0.523 2.0 61.7 66.2 71.8
KALE-Joint 0.325 9.0 38.4 44.7 52.2 0.684 1.0 79.7 84.1 89.6 0.523 2.0 61.2 66.4 72.8

W
N

18

TransE 0.306 3.0 57.4 72.3 80.1 0.511 2.0 87.5 95.6 98.7 0.453 2.0 79.1 89.1 93.6
TransH 0.318 3.0 61.7 72.4 78.2 0.653 2.0 87.1 91.4 94.6 0.560 2.0 80.0 86.1 90.0
TransR 0.299 3.0 56.1 66.7 74.5 0.597 2.0 75.0 81.7 88.0 0.514 2.0 69.7 77.5 84.3
KALE-Trip 0.322 3.0 61.0 73.9 80.8 0.555 2.0 90.6 96.3 98.8 0.490 2.0 82.3 90.1 93.8
KALE-Pre 0.322 3.0 60.6 74.5 81.1 0.612 2.0 96.4 98.6 99.6 0.532 2.0 86.4 91.9 94.4
KALE-Joint 0.338 3.0 65.5 76.3 82.1 0.787 1.0 93.3 95.4 97.2 0.662 2.0 85.5 90.1 93.0

Table 5: Link prediction results on the test-I, test-II, and test-all sets of FB122 and WN18 (filtered setting).

and a possible corruption (Lyon,Located-In,
France). Both triples are valid. In this case, rank-
ing Lyon before the correct answer Paris should
not be counted as an error. To avoid such phenome-
na, we follow Bordes et al. (2013) and remove those
corrupted triples which exist in either the training,
validation, or test set before getting the ranks. That
means, we remove Lyon from the candidate list be-
fore getting the rank of Paris in the aforemen-
tioned example. We call the original setting “raw”
and the new setting “filtered”.

Optimal configurations. For each of the method-
s to be compared, we tune its hyperparameters in
the ranges specified in Section 4.1, and select a best
model that leads to the highest filtered MRR score
on the validation set (with a total of 500 epochs over

the training data). The optimal configurations for
KALE are: d = 100, η = 0.05, γ = 0.12, and λ = 1
on FB122; d=50, η =0.05, γ =0.2, and λ=0.1 on
WN18. To better see and understand the effects of
rules, we use the same configuration for KALE-Trip,
KALE-Pre, and KALE-Joint on each dataset.

Results. Table 4 and Table 5 show the results in the
raw setting and filtered setting respectively. On each
dataset we report the metrics on three sets: test-I,
test-II, and the whole test set (denoted by test-all).
Test-I contains test triples that cannot be directly in-
ferred by performing pure logical inference on the
training set, and hence might be intrinsically more d-
ifficult for the rules. The remaining test triples (i.e.,
the directly inferable ones) are included in Test-II.
These triples have either been used directly as train-

198



Raw Filtered

Test-Incl Test-Excl Test-Incl Test-Excl

MEAN / MED / HITS@10 MEAN / MED / HITS@10 MEAN / MED / HITS@10 MEAN / MED / HITS@10

FB
12

2 KALE-Trip 0.150 49.0 34.2 0.235 17.0 44.1 0.267 14.0 46.2 0.321 8.0 52.9
KALE-Joint 0.175 36.0 36.6 0.265 15.0 45.9 0.290 11.0 49.3 0.349 7.0 54.2

W
N

18 KALE-Trip 0.062 239.0 15.1 0.285 4.0 90.0 0.072 186.0 17.3 0.369 2.0 92.9
KALE-Joint 0.093 186.0 19.6 0.291 4.0 90.5 0.113 136.0 24.0 0.381 2.0 93.2

Table 6: Comparison between KALE-Trip and KALE-Joint on Test-Incl and Test-Excl of FB122 and WN18.

ing instances in KALE-Pre, or encoded explicitly in
training ground rules in KALE-Joint, making this set
trivial for the rules to some extent. From the result-
s, we can see that in both settings: (i) KALE-Pre
and KALE-Joint outperform (or at least perform as
well as) the other methods which use triples alone
on almost all the test sets, demonstrating the superi-
ority of incorporating logical rules. (ii) On the test-I
sets which contain triples beyond the scope of pure
logical inference, KALE-Joint performs significant-
ly better than KALE-Pre. On these sets KALE-Joint
can still beat all the baselines by a significant margin
in most cases, while KALE-Pre can hardly outper-
form KALE-Trip. It demonstrates the capability of
the joint embedding scenario to learn more predic-
tive embeddings, through which we can make better
predictions even beyond the scope of pure logical
inference. (iii) On the test-II sets which contain di-
rectly inferable triples, KALE-Pre can easily beat all
the baselines (even KALE-Joint). That means, for
triples covered by pure logical inference, it is trivial
to improve the performance by directly incorporat-
ing them as training instances.

To better understand how the joint embedding s-
cenario can learn more predictive embeddings, on
each dataset we further split the test-I set into two
parts. Given a triple (ei, rk, ej) in the test-I set, we
assign it to the first part if relation rk is covered by
the rules, and the second part otherwise. We call the
two parts Test-Incl and Test-Excl respectively. Ta-
ble 6 compares the performance of KALE-Trip and
KALE-Joint on the two parts. The results show that
KALE-Joint outperforms KALE-Trip on both parts,
but the improvements on Test-Incl are much more
significant than those on Test-Excl. Take the fil-
tered setting on WN18 as an example. On Test-Incl,
KALE-Joint increases the metric MRR by 55.7%,
decreases the metric MED by 26.9%, and increas-

es the metric HITS@10 by 38.2%. On Test-Excl,
however, MRR rises by 3.1%, MED remains the
same, and HITS@10 rises by only 0.3%. This obser-
vation indicates that jointly embedding triples and
rules helps to learn more predictive embeddings, es-
pecially for those relations that are used to construct
the rules. This might be the main reason that KALE-
Joint can make better predictions even beyond the
scope of pure logical inference.

4.3 Triple Classification
This task is to verify whether an unobserved triple
(ei, rk, ej) is correct or not.

Evaluation protocol. We take the following evalu-
ation protocol similar to that used in TransH (Wang
et al., 2014). We first create labeled data for evalua-
tion. For each triple in the test or validation set (i.e.,
a positive triple), we construct 10 negative triples
for it by randomly corrupting the entities, 5 at the
head position and the other 5 at the tail position.6 To
make the negative triples as difficult as possible, we
corrupt a position using only entities that have ap-
peared in that position, and further ensure that the
corrupted triples do not exist in either the training,
validation, or test set. We simply use the truth values
(or distances) to classify triples. Triples with large
truth values (or small distances) tend to be predict-
ed as positive. To evaluate, we first rank the triples
associated with each specific relation (in descending
order according to their truth values, or in ascending
order according to the distances), and calculate the
average precision for that relation. We then report
on the test sets the mean average precision (MAP)

6Previous work typically constructs only a single negative
case for each positive one. We empirically found such a bal-
anced classification task too simple for our datasets. So we con-
sider a highly unbalanced setting, with a positive-to-negative ra-
tio of 1:10, for which the previously used metric accuracy is no
longer suitable.

199



FB122 WN18

MAP (Test-I/II/ALL) MAP (Test-I/II/ALL)
TransE 0.552 0.852 0.634 0.592 0.993 0.958
TransH 0.576 0.758 0.641 0.604 0.978 0.947
TransR 0.572 0.699 0.619 0.412 0.854 0.836
KALE-Trip 0.578 0.829 0.652 0.618 0.995 0.953
KALE-Pre 0.575 0.916 0.668 0.620 0.997 0.964
KALE-Joint 0.599 0.870 0.677 0.627 0.997 0.961

Table 7: Triple classification results on the test-I, test-II, and
test-all sets of FB122 and WN18.

aggregated over different relations.

Optimal configurations. The hyperparameters of
each method are again tuned in the ranges specified
in Section 4.1, and the best models are selected by
maximizing MAP on the validation set. The optimal
configurations for KALE are: d=100, η =0.1, γ =
0.2, and λ = 0.1 on FB122; d = 100, η = 0.1, γ =
0.2, and λ = 0.001 on WN18. Again, we use the
same configuration for KALE-Trip, KALE-Pre, and
KALE-Joint on each dataset.

Results. Table 7 shows the results on the test-I, test-
II, and test-all sets of our datasets. From the results,
we can see that: (i) KALE-Pre and KALE-Joint out-
perform the other methods which use triples alone
on almost all the test sets, demonstrating the superi-
ority of incorporating logical rules. (ii) KALE-Joint
performs better than KALE-Pre on the test-I sets,
i.e., triples that cannot be directly inferred by per-
forming pure logical inference on the training set.
This observation is similar to that observed in the
link prediction task, demonstrating that the joint em-
bedding scenario can learn more predictive embed-
dings and make predictions beyond the capability of
pure logical inference.

5 Conclusion and Future Work

In this paper, we propose a new method for joint-
ly embedding knowledge graphs and logical rules,
referred to as KALE. The key idea is to represent
and model triples and rules in a unified framework.
Specifically, triples are represented as atomic for-
mulae and modeled by the translation assumption,
while rules as complex formulae and by the t-norm
fuzzy logics. A global loss on both atomic and com-
plex formulae is then minimized to perform the em-
bedding task. Embeddings learned in this way are

compatible not only with triples but also with rules,
which are certainly more useful for knowledge ac-
quisition and inference. We evaluate KALE with
the link prediction and triple classification tasks on
WordNet and Freebase data. Experimental result-
s show that joint embedding brings significant and
consistent improvements over state-of-the-art meth-
ods. More importantly, it can obtain more predic-
tive embeddings and make better predictions even
beyond the scope of pure logical inference.

For future work, we would like to (i) Investigate
the efficacy of incorporating other types of logical
rules such as ∀x, y, z : (x,Capital-Of, y) ⇒
¬(x,Capital-Of, z). (ii) Investigate the possibil-
ity of modeling logical rules using only relation em-
beddings as suggested by Demeester et al. (2016),
e.g., modeling the above rule using only the embed-
ding associated with Capital-Of. This avoids
grounding, which might be time and space ineffi-
cient especially for complicated rules. (iii) Inves-
tigate the use of automatically extracted rules which
are no longer hard rules and tolerant of uncertainty.

Acknowledgments

We would like to thank the anonymous reviewers for
their insightful comments and suggestions. This re-
search is supported by the National Natural Science
Foundation of China (grant No. 61402465) and the
Strategic Priority Research Program of the Chinese
Academy of Sciences (grant No. XDA06030200).

References

Islam Beltagy and Raymond J. Mooney. 2014. Efficient
markov logic inference for natural language semantics.
In Proceedings of the 28th AAAI Conference on Arti-
ficial Intelligence - Workshop on Statistical Relational
Artificial Intelligence, pages 9–14.

Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim S-
turge, and Jamie Taylor. 2008. Freebase: a collab-
oratively created graph database for structuring hu-
man knowledge. In Proceedings of the 2008 ACM
SIGMOD International Conference on Management of
Data, pages 1247–1250.

Antoine Bordes, Jason Weston, Ronan Collobert, and
Yoshua Bengio. 2011. Learning structured embed-
dings of knowledge bases. In Proceedings of the
25th AAAI Conference on Artificial Intelligence, pages
301–306.

200



Antoine Bordes, Nicolas Usunier, Alberto Garcia-Durán,
Jason Weston, and Oksana Yakhnenko. 2013. Trans-
lating embeddings for modeling multi-relational da-
ta. In Proceedings of the 27th Annual Conference on
Neural Information Processing Systems, pages 2787–
2795.

Antoine Bordes, Xavier Glorot, Jason Weston, and
Yoshua Bengio. 2014. A semantic matching energy
function for learning with multi-relational data. Ma-
chine Learning, 94(2):233–259.

Matthias Bröcheler, Lilyana Mihalkova, and Lise Getoor.
2010. Probabilistic similarity logic. In Proceedings of
the 26th Conference on Uncertainty in Artificial Intel-
ligence, pages 73–82.

Kai-wei Chang, Wen-tau Yih, Bishan Yang, and Christo-
pher Meek. 2014. Typed tensor decomposition of
knowledge bases for relation extraction. In Proceed-
ings of the 2014 Conference on Empirical Methods in
Natural Language Processing, pages 1568–1579.

Thomas Demeester, Tim Rocktäschel, and Sebastian
Riedel. 2016. Regularizing relation representations
by first-order implications. In Proceedings of the 2016
Conference of the North American Chapter of the As-
sociation for Computational Linguistics: Human Lan-
guage Technologies - Workshop on Automated Knowl-
edge Base Construction, pages 75–80.

Shu Guo, Quan Wang, Lihong Wang, Bin Wang, and
Li Guo. 2015. Semantically smooth knowledge graph
embedding. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural
Language Processing, pages 84–94.

Petr Hájek. 1998. The metamathematics of fuzzy logic.
Kluwer.

Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke
Zettlemoyer, and Daniel S. Weld. 2011. Knowledge-
based weak supervision for information extraction of
overlapping relations. In Proceedings of the 49th
Annual Meeting of the Association for Computation-
al Linguistics: Human Language Technologies, pages
541–550.

Rodolphe Jenatton, Nicolas L. Roux, Antoine Bordes,
and Guillaume R. Obozinski. 2012. A latent factor
model for highly multi-relational data. In Proceedings
of the 26th Annual Conference on Neural Information
Processing Systems, pages 3167–3175.

Shangpu Jiang, Daniel Lowd, and Dejing Dou. 2012.
Learning to refine an automatically extracted knowl-
edge base using markov logic. In Proceedings of 12th
IEEE International Conference on Data Mining, pages
912–917.

Charles Kemp, Joshua B. Tenenbaum, Thomas L. Grif-
fiths, Takeshi Yamada, and Naonori Ueda. 2006.

Learning systems of concepts with an infinite relation-
al model. In Proceedings of the 21st AAAI Conference
on Artificial Intelligence, pages 381–388.

Denis Krompaß, Stephan Baier, and Volker Tresp. 2015.
Type-constrained representation learning in knowl-
edge graphs. In Proceedings of the 14th International
Semantic Web Conference, pages 640–655.

Yankai Lin, Zhiyuan Liu, Huanbo Luan, Maosong Sun,
Siwei Rao, and Song Liu. 2015a. Modeling relation
paths for representation learning of knowledge bases.
In Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing, pages 705–
714.

Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and
Xuan Zhu. 2015b. Learning entity and relation em-
beddings for knowledge graph completion. In Pro-
ceedings of the 29th AAAI Conference on Artificial In-
telligence, pages 2181–2187.

Yuanfei Luo, Quan Wang, Bin Wang, and Li Guo.
2015. Context-dependent knowledge graph embed-
ding. In Proceedings of the 2015 Conference on
Empirical Methods in Natural Language Processing,
pages 1656–1661.

Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013. Linguistic regularities in continuous space word
representations. In Proceedings of the 2013 Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language
Technologies, pages 746–751.

George A. Miller. 1995. Wordnet: a lexical database for
english. Communications of the ACM, 38(11):39–41.

Arvind Neelakantan, Benjamin Roth, and Andrew Mc-
Callum. 2015. Compositional vector space model-
s for knowledge base completion. In Proceedings of
the 53rd Annual Meeting of the Association for Com-
putational Linguistics and the 7th International Join-
t Conference on Natural Language Processing, pages
156–166.

Maximilian Nickel, Volker Tresp, and Hans P. Kriegel.
2011. A three-way model for collective learning on
multi-relational data. In Proceedings of the 28th In-
ternational Conference on Machine Learning, pages
809–816.

Maximilian Nickel, Volker Tresp, and Hans P. Kriegel.
2012. Factorizing yago: Scalable machine learning for
linked data. In Proceedings of the 21st International
Conference on World Wide Web, pages 271–280.

Maximilian Nickel, Lorenzo Rosasco, and Tomaso Pog-
gio. 2016. Holographic embeddings of knowledge
graphs. In Proceedings of the 30th AAAI Conference
on Artificial Intelligence, pages 1955–1961.

Jay Pujara, Hui Miao, Lise Getoor, and William Cohen.
2013. Knowledge graph identification. In Proceed-

201



ings of the 12th International Semantic Web Confer-
ence, pages 542–557.

Matthew Richardson and Pedro Domingos. 2006.
Markov logic networks. Machine Learning, 62(1-
2):107–136.

Sebastian Riedel, Limin Yao, Andrew McCallum, and
Benjamin M. Marlin. 2013. Relation extraction with
matrix factorization and universal schemas. In Pro-
ceedings of the 2013 Conference on North American
Chapter of the Association for Computational Linguis-
tics: Human Language Technologies, pages 74–84.

Tim Rocktäschel, Matko Bošnjak, Sameer Singh, and Se-
bastian Riedel. 2014. Low-dimensional embeddings
of logic. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistics -
Workshop on Semantic Parsing, pages 45–49.

Tim Rocktäschel, Sameer Singh, and Sebastian Riedel.
2015. Injecting logical background knowledge into
embeddings for relation extraction. In Proceedings of
the 2015 Conference of the North American Chapter
of the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1119–1129.

Richard Socher, Danqi Chen, Christopher D. Manning,
and Andrew Y. Ng. 2013. Reasoning with neural ten-
sor networks for knowledge base completion. In Pro-
ceedings of the 27th Annual Conference on Neural In-
formation Processing Systems, pages 926–934.

Giorgos Stoilos, Giorgos B. Stamou, Jeff Z. Pan, Vassilis
Tzouvaras, and Ian Horrocks. 2007. Reasoning with
very expressive fuzzy description logics. Journal of
Artificial Intelligence Research, 30:273–320.

Ilya Sutskever, Joshua B. Tenenbaum, and Ruslan R.
Salakhutdinov. 2009. Modelling relational data using
bayesian clustered tensor factorization. In Proceed-
ings of the 23rd Annual Conference on Neural Infor-
mation Processing Systems, pages 1821–1828.

Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng
Chen. 2014. Knowledge graph embedding by
translating on hyperplanes. In Proceedings of the
28th AAAI Conference on Artificial Intelligence, pages
1112–1119.

Quan Wang, Bin Wang, and Li Guo. 2015. Knowledge
base completion using embeddings and rules. In Pro-
ceedings of the 24th International Joint Conference on
Artificial Intelligence, pages 1859–1865.

Evgenia Wasserman-Pritsker, William W. Cohen, and
Einat Minkov. 2015. Learning to identify the best
contexts for knowledge-based wsd. In Proceedings of
the 2015 Conference on Empirical Methods in Natural
Language Processing, pages 1662–1667.

Zhuoyu Wei, Jun Zhao, Kang Liu, Zhenyu Qi, Zhengya
Sun, and Guanhua Tian. 2015. Large-scale knowl-
edge base completion: inferring via grounding net-

work sampling over selected instances. In Proceed-
ings of the 24th ACM International on Conference
on Information and Knowledge Management, pages
1331–1340.

Jason Weston, Antoine Bordes, Oksana Yakhnenko, and
Nicolas Usunier. 2013. Connecting language and
knowledge bases with embedding models for relation
extraction. In Proceedings of the 2013 Conference on
Empirical Methods in Natural Language Processing,
pages 1366–1371.

Zhao Xu, Volker Tresp, Kai Yu, and Hanspeter Kriegel.
2006. Infinite hidden relational models. In Proceed-
ings of Proceedings of the 22nd Conference on Uncer-
tainty in Artificial Intelligence, pages 544–551.

Huaping Zhong, Jianwen Zhang, Zhen Wang, Hai Wan,
and Zheng Chen. 2015. Aligning knowledge and text
embeddings by entity descriptions. In Proceedings of
the 2015 Conference on Empirical Methods in Natural
Language Processing, pages 267–272.

202


