153

Coling 2010: Poster Volume, pages 153–161,

Beijing, August 2010

Acquisition of Unknown Word Paradigms for Large-Scale Grammars

Kostadin Cholakov

University of Groningen

The Netherlands

k.cholakov@rug.nl

Gertjan van Noord

University of Groningen

The Netherlands

g.j.m.van.noord@rug.nl

Abstract

Unknown words are a major issue for
large-scale grammars of natural language.
We propose a machine learning based al-
gorithm for acquiring lexical entries for
all forms in the paradigm of a given un-
known word. The main advantages of our
method are the usage of word paradigms
to obtain valuable morphological knowl-
edge, the consideration of different con-
texts which the unknown word and all
members of its paradigm occur in and
the employment of a full-blown syntactic
parser and the grammar we want to im-
prove to analyse these contexts and pro-
vide elaborate syntactic constraints. We
test our algorithm on a large-scale gram-
mar of Dutch and show that its application
leads to an improved parsing accuracy.

1 Introduction

In this paper, we present an efﬁcient machine
learning based method for automated lexical ac-
quisition (LA) which improves the performance
of large-scale computational grammars on real-
life tasks.

Our approach has three main advantages which
distinguish it from other methods applied to the
same task. First, it enables the acquisition of the
whole paradigm of a given unknown word while
other approaches are only concerned with the par-
ticular word form encountered in the data sub-
ject to LA. Second, we analyse different contexts
which the unknown word occurs in. Third, the
analysis of these contexts is provided by a full-
blown syntactic parser and the grammar we aim

to improve which gives the grammar the opportu-
nity to participate directly in the LA process.

Our method achieves an F-measure of 84.6%
on unknown words in experiments with the wide-
coverage Alpino grammar (van Noord, 2006) of
Dutch. The integration of this method in the
parser leads to a 4.2% error reduction in terms of
labelled dependencies.

To predict a lexical entry for a given unknown
word, we take into account two factors– its mor-
phology and the syntactic constraints imposed by
its context. As for the former, the acquisition of
the whole paradigm provides us with a valuable
source of morphological information. If we were
to deal with only one form of the unknown word,
this information would not be accessible.

Further, looking at different contexts of the un-
known word gives us the possibility to work with
linguistically diverse data and to incorporate more
syntactic information into the LA process. Cases
where this is particularly important include mor-
phologically ambiguous words and verbs which
subcategorize for various types of syntactic argu-
ments. We also consider contexts of the other
members of the paradigm of the unknown word
in order to increase the amount of linguistic data
our method has access to.

Finally,

the usage of a full-blown syntactic
parser and the grammar we want to acquire lex-
ical entries for has two advantages. First, LA
can beneﬁt from the high-quality analyses such
a parser produces and the elaborate syntactic in-
formation they provide. Second, this information
comes directly from the grammar, thus allowing
the LA process to make predictions based on what
the grammar considers to be best suited for it.

154

The remainder of the paper is organised as fol-
lows. Section 2 describes the basic steps in our
LA algorithm. Section 3 presents initial exper-
iments conducted with Alpino and shows that
the main problems our LA method encounters
are the acquisition of morphologically ambigu-
ous words, the learning of the proper subcate-
gorization frames for verbs and the acquisition
of particular types of adjectives.
In Section 4
we make extensive use of the paradigms of the
unknown words to develop speciﬁc solutions for
these problems. Section 5 describes experiments
with our LA method applied to a set of real un-
known words. Section 6 provides a comparison
between our approach and work previously done
on LA. This section also discusses the application
of our method to other systems and languages.

2 Basic Algorithm

The Alpino wide-coverage dependency parser is
based on a large stochastic attribute value gram-
mar. The grammar takes a ‘constructional’ ap-
proach, with rich lexical representations stored in
the lexicon and a large number of detailed, con-
struction speciﬁc rules (about 800). Currently, the
lexicon contains about 100K lexical entries and
a list of about 200K named entities. Each word
is assigned one or more lexical types. For ex-
ample, the verb amuseert (to amuse) is assigned
two lexical types– verb(hebben,sg3,intransitive)
and verb(hebben,sg3,transitive)– because it can
be used either transitively or intransitively. The
other type features indicate that it is a present third
person singular verb and it forms perfect tense
with the auxiliary verb hebben.

The goal of our LA method is to assign the cor-
rect lexical type(s) to a given unknown word. The
method takes into account only open-class lexical
types: nouns, adjectives and verbs, under the as-
sumption that the grammar is already able to han-
dle all closed-class cases. We call the types con-
sidered by our method universal types. The adjec-
tives can be used as adverbs in Dutch and thus, we
do not consider the latter to be an open class.

We employ a ME-based classiﬁer which, for
some unknown word, takes various morphological
and syntactic features as input and outputs lexical
types. The probability of a lexical type t, given an

unknown word and its context c is:

(1)

p(t|c) =

exp(Pi Θifi(t,c))
Pt′∈T exp(Pi Θifi(t′,c))

where fi(t, c) may encode arbitrary characteris-
tics of the context and < Θ1, Θ2, ... > can be eval-
uated by maximising the pseudo-likelihood on a
training corpus (Malouf, 2002).

Table 1 shows the features for the noun in-
spraakprocedures (consultation procedures). Row
(i) contains 4 separate features derived from the
preﬁx of the word and 4 other sufﬁx features are
given in row (ii). The two features in rows (iii)
and (iv) indicate whether the word starts with a
particle and if it contains a hyphen, respectively.

Another source of morphological features is the
paradigm of the unknown word which provides
information that is otherwise inaccessible. For ex-
ample, in Dutch, neuter nouns always take the het
deﬁnite article while all other noun forms are used
with the de article. Since the article is distinguish-
able only in the singular noun form, the correct
article of a word, assigned a plural noun type, can
be determined if we know its singular form.

We adopt the method presented in Cholakov
and van Noord (2009) where a ﬁnite state mor-
phology is applied to generate the paradigm(s) of
a given word. The morphology does not have ac-
cess to any additional linguistic information and
thus, it generates all possible paradigms allowed
by the word structure. Then,
the number of
search hits Yahoo returns for each form in a given
paradigm is combined with some simple heuris-
tics to determine the correct paradigm(s).

However, we make some modiﬁcations to this
method because it deals only with regular mor-
phological phenomena. Though all typical irreg-
ularities are included in the Alpino lexicon, there
are cases of irregular verbs composed with parti-
cles which are not listed there. One such example
is the irregular verb meevliegen (to ﬂy with some-
one) for which no paradigm would be generated.
To avoid this, we use a list of common parti-
cles to strip off any particle from a given unknown
word. Once we have removed a particle, we check
if what is left from the word is listed in the lexicon
as a verb (e.g. vliegen in the case of meevliegen).
If so, we extract all members of its paradigm from

155

Features
i) i, in, ins, insp
ii) s, es, res, ures
iii) particle yes #in this case in
iv) hyphen no
v) nounhde,pli
vi) noun(de,count,pl), tmp noun(de,count,sg)
vii) noun(de), noun(count), noun(pl), tmp noun(de)
tmp noun(count), tmp noun(sg)

Table 1: Features for inspraakprocedures

the lexicon and use them to build the paradigm of
the unknown word. All forms are validated by us-
ing the same web-based heuristics as in the origi-
nal model of Cholakov and van Noord (2009).

A single paradigm is generated for

in-
spraakprocedures indicating that this word is a
plural de noun. This information is explicitly used
as a feature in the classiﬁer which is shown in row
(v) of Table 1.

Next, we obtain syntactic features for

in-
spraakprocedures by extracting a number of sen-
tences which it occurs in from large corpora or
Internet. These sentences are parsed with a differ-
ent ‘mode’ of Alpino where this word is assigned
all universal types, i.e. it is treated as being maxi-
mally ambiguous. For each sentence only the best
parse is preserved. Then, the lexical type that has
been assigned to inspraakprocedures in this parse
is stored. During parsing, Alpino’s POS tagger
(Prins and van Noord, 2001) keeps ﬁltering im-
plausible type combinations. For example, if a de-
terminer occurs before the unknown word, all verb
types are typically not taken into consideration.
This heavily reduces the computational overload
and makes parsing with universal types computa-
tionally feasible. When all sentences have been
parsed, a list can be drawn up with the types that
have been used and their frequency:

(2)

noun(de,count,pl) 78
tmp noun(de,count,sg) 7
tmp noun(het,count,pl) 6
proper name(pl,’PER’) 5
proper name(pl,’ORG’) 3
verb(hebben,pl,vp) 1

The lexical types assigned to inspraakprocedures
in at least 80% of the parses are used as features
in the classiﬁer. These are the two features in row
(vi) of Table 1. Further, as illustrated in row (vii),

each attribute of the considered types is also taken
as a separate feature. By doing this, we let the
grammar decide which lexical type is best suited
for a given unknown word. This is a new and ef-
fective way to include the syntactic constraints of
the context in the LA process.

However, for the parsing method to work prop-
erly, the disambiguation model of the parser needs
to be adapted. The model heavily relies on the
lexicon and it has learnt preferences how to parse
certain phrases. For example, it has learnt a pref-
erence to parse prepositional phrases as verb com-
plements, if the verb includes such a subcatego-
rization frame. This is problematic when parsing
with universal types.
If the unknown word is a
verb and it occurs together with a PP, it would al-
ways get analysed as a verb which subcategorizes
for a PP.

To avoid this, the disambiguation model is re-
trained on a speciﬁc set of sentences meant to
make it more robust to input containing many un-
known words. We have selected words with low
frequency in large corpora and removed them tem-
porarily from the Alpino lexicon. Less frequent
words are typically not listed in the lexicon and
the selected words are meant to simulate their be-
haviour. Then, all sentences from the Alpino tree-
bank which contain these words are extracted and
used to retrain the disambiguation model.

3

Initial Experiments and Evaluation

To evaluate the performance of the classiﬁer, we
conduct an experiment with a target type inven-
tory of 611 universal types. A type is considered
universal only if it is assigned to at least 15 dis-
tinct words occurring in large Dutch newspaper
corpora (∼16M sentences) automatically parsed
with Alpino.
In order to train the classiﬁer, 2000 words are
temporarily removed from the Alpino lexicon.
The same is done for another 500 words which
are used as a test set. All words have between
50 and 100 occurrences in the corpora. This se-
lection is again meant to simulate the behaviour
of unknown words. Experiments with a minimum
lower than 50 occurrences have shown that this is
a reasonable threshold to ﬁlter out typos, words
written together, etc.

156

The classiﬁer yields a probability score for each
predicted type. Since a given unknown word can
have more than one correct type, we want to pre-
dict multiple types. However, the least frequent
types, accounting together for less than 5% of
probability mass, are discarded.

We evaluate the results in terms of precision
and recall. Precision indicates how many types
found by the method are correct and recall indi-
cates how many of the lexical types of a given
word are actually found. The presented results are
the average precision and recall for the 500 test
words.

Additionally, there are three baseline methods:
• Naive– each unknown word is assigned
type in the lexicon:

frequent

the most
noun(de,count,sg)

• POS tagger– the unknown word is given the
type most frequently assigned by the Alpino
POS tagger in the parsing stage

• Alpino– the unknown word is assigned the
most frequently used type in the parsing
stage

The overall results are given in Table 2. Table 3
shows the results for each POS in our model.

Model
Naive
POS tagger
Alpino
Our model

Precision(%) Recall(%)

F-measure(%)

19.60

30

44.60
86.59

18.77
26.21
37.59
78.62

19.17
27.98
40.80
82.41

Table 2: Overall experiment results

POS
Nouns
Adjectives
Verbs

Precision(%) Recall(%)

F-measure(%)

93.83
75.50
77.32

88.61
73.12
55.37

91.15
74.29
64.53

Table 3: Detailed results for our model

Our LA method clearly improves upon the
baselines. However, as we see in Table 3, adjec-
tives and especially verbs remain difﬁcult to pre-
dict.

The problems with the former are due to the fact
that Alpino employs a rather complicated adjec-
tive system. The classiﬁer has difﬁculties distin-
guishing between 3 kinds of adjectives: i) adjec-
tives which can attach to and modify verbs and

verbal phrases (VPs) (3-a), ii) adjectives which
can attach to verbs and VPs but modify one of
the complements of the verb, typically the sub-
ject (3-b) and iii) adjectives which cannot attach
to verbs and VPs (3-c).

(3)

a.

b.

c.

mooi.
nice

loopt
walks

loopt
walks

hardloper
runner

De
DET
‘The runner runs nicely = The runner has a
good running technique’
Hij
naar
he
to
‘He walks home drunk = He is walking home
while being drunk’
nederlandstalig.
*Hij
he
Dutch speaking
‘He walks Dutch speaking.’

dronken
drunk

loopt
walks

huis.
home

Each of these is marked by a special attribute in
the lexical type deﬁnitions– adv, padv and non-
adv, respectively. Since all three of them are seen
in ‘typical’ adjectival contexts where they modify
nouns, it is hard for the classiﬁer to make a distinc-
tion. The predictions appear to be arbitrary and
there are many cases where the unknown word is
classiﬁed both as a nonadv and an adv adjective. It
is even more difﬁcult to distinguish between padv
and adv adjectives since this is a solely semantic
distinction.

The main issue with verbs is the prediction of
the correct subcategorization frame. The classiﬁer
tends to predict mostly transitive and intransitive
verb types. As a result, it either fails to capture in-
frequent frames which decreases the recall or, in
cases where it is very uncertain what to predict, it
assigns a lot of types that differ only in the subcat
frame, thus damaging the precision. For example,
onderschrijf (‘to agree with’) has 2 correct sub-
cat frames but receives 8 predictions which differ
only in the subcat features.

One last issue is the prediction, in some rare
cases, of types of the wrong POS for morpholog-
ically ambiguous words. In most of these cases
adjectives are wrongly assigned a past partici-
ple type but also some nouns receive verb pre-
dictions. For instance, OESO-landen (‘countries
of the OESO organisation’) has one correct noun
type but because landen is also the Dutch verb for
‘to land’ the classiﬁer wrongly assigns a verb type
as well.

157

4 Improving LA

4.1 POS Correction

Since the vast majority of wrong POS predictions
has to do with the assignment of incorrect verb
types, we decided to explicitly use the generated
verb paradigms as a ﬁltering mechanism. For each
word which is assigned a verb type, we check if
there is a verb paradigm generated for it. If not, all
verb types predicted for the word are discarded.

In very rare cases a word is assigned only verb
types and therefore, it ends up with no predictions.
For such words, we examine the ranked list of pre-
dicted types yielded by the classiﬁer and the word
receives the non-verb lexical type with the high-
est probability score. If this type happens to be
an adjective one, we ﬁrst check whether there is
an adjective paradigm generated for the word in
question. If not, the word gets the noun type with
the highest probability score.

The same procedure is also applied to all words
which are assigned an adjective type. However,
it is not used for words predicted to be nouns be-
cause the classiﬁer is already very good at predict-
ing nouns. Further, the generated noun paradigms
are not reliable enough to be a ﬁltering mechanism
because there are mass nouns with no plural forms
and thus with no paradigms generated.

Another modiﬁcation we make to the classiﬁer
output has to do with the fact that past participles
(psp) in Dutch can also be used as adjectives. This
systematic ambiguity, however, is not treated as
such in Alpino. Each psp should also have a sep-
arate adjective lexical entry but this is not always
the case. That is why, in some cases, the classiﬁer
fails to capture the adjective type of a given psp.
To account for it, all words predicted to be past
participles but not adjectives are assigned two ad-
ditional adjective types– one with the nonadv and
one with the adv feature. For reasons explained
later on, a type with the padv feature is not added.
After the application of these techniques, all
cases of words wrongly predicted to be verbs or
adjectives have been eliminated.

4.2 Guessing Subcategorization Frames

Our next step is to guess the correct subcatego-
rization feature for verbs. Learning the proper

subcat frame is well studied (Brent, 1993; Man-
ning, 1993; Briscoe and Caroll, 1997; Kinyon and
Prolo, 2002; O’Donovan et al., 2005). Most of
the work follows the ‘classical’ Briscoe and Caroll
(1997) approach where the verb and the subcate-
gorized complements are extracted from the out-
put analyses of a probabilistic parser and stored as
syntactic patterns. Further, some statistical tech-
niques are applied to select the most probable
frames out of the proposed syntactic patterns.

Following the observations made in Korho-
nen et al. (2000), Lapata (1999) and Messiant
(2008), we employ a maximum likelihood es-
timate (MLE) from observed relative frequen-
cies with an empirical threshold to ﬁlter out low
probability frames. For each word predicted to
be a verb, we look up the verb types assigned
to it during the parsing with universal
types.
Then, the MLE for each subcat frame is deter-
mined and only frames with MLE of 0.2 and
above are considered.
jammert
(to moan.3SG.PRES) is assigned a single type–
verb(hebben,sg3,intransitive). However, the cor-
rect subcat features for it are intransitive and sbar.
Here is the list of all verb types assigned to jam-
mert during the parsing with universal types:

For example,

(4)

verb(hebben,sg3,intransitive) 48
verb(hebben,sg3,transitive) 15
verb(hebben,past(sg),np sbar) 3
verb(hebben,past(sg),tr sbar) 3
verb(zijn,sg3,intransitive) 2
verb(hebben,past(sg),ld pp) 2
verb(hebben,sg3,sbar) 1

The MLE for the intransitive subcat feature is 0.68
and for the transitive one– 0.2. All previously pre-
dicted verb types are discarded and each consid-
ered subcat frame is used to create a new lexi-
cal type. That is how jammert gets two types at
the end– the correct verb(hebben,sg3,intransitive)
and the incorrect verb(hebben,sg3,transitive). The
sbar frame is wrongly discarded.

To avoid such cases,

the generated word
paradigms are used to increase the number of con-
texts observed for a given verb. Up to 200 sen-
tences are extracted for each form in the paradigm
of a given word predicted to be a verb. These sen-
tences are again parsed with the universal types
and then, the MLE for each subcat frame is recal-

158

culated.

We evaluated the performance of our MLE-
based method on the 116 test words predicted to
be verbs. We extracted the subcat features from
their type deﬁnitions in the Alpino lexicon to cre-
ate a gold standard of subcat frames. Addition-
i) all
ally, we developed two baseline methods:
frames assigned during parsing are considered and
ii) each verb is taken to be both transitive and in-
transitive. Since most verbs have both or one of
these frames, the purpose of the second baseline is
to see if there is a simpler solution to the problem
of ﬁnding the correct subcat frame. The results
are given in Table 4.

Model
all frames
tr./intr.
our model

Precision(%)

Recall(%)

F-measure(%)

16.76
62.29
85.82

94.34
69.17
67.28

28.46
65.55
75.43

Table 4: Subcat frames guessing results

Our method signiﬁcantly outperforms both
baselines. It is able to correctly identify the transi-
tive and/or the intransitive frames. Since they are
the most frequent ones in the test data, this boosts
up the precision. However, the method is also able
to capture other, less frequent subcat frames. For
example, after parsing the additional sentences for
jammert, the sbar frame had enough occurrences
to get above the threshold. The MLE for the tran-
sitive one, on the other hand, fell below 0.2 and it
was correctly discarded.

4.3 Guessing Adjective Types

We follow a similar approach for ﬁnding the cor-
rect adjective type.
It should be noted that the
distinction among nonadv, adv and padv does
not exist for every adjective form. Most ad-
jectives in Dutch get an -e sufﬁx when used
attributively– de mooie/mooiere/mooiste jongen
(the nice/nicer/nicest boy). Since these inﬂected
forms can only occur before nouns, the distinction
we are dealing with is not relevant for them. Thus
we are only interested in the noninﬂected base,
comparative and superlative adjective forms.

One of the possible output formats of Alpino
is dependency triples. Here is the output for the
sentence in (3-a):

(5)

verb:loop|hd/su|noun:hardloper
noun:hardloper|hd/det|det:de
verb:loop|hd/mod|adj:mooi
verb:loop|–/–|punct:.

Each line is a single dependency triple. The line
contains three ﬁelds separated by the ‘|’ character.
The ﬁrst ﬁeld contains the root of the head word
and its POS, the second ﬁeld indicates the type of
the dependency relation and the third one contains
the root of the dependent word and its POS. The
third line in (5) shows that the adjective mooi is a
modiﬁer of the head, in this case the verb loopt.
Such a dependency relation indicates that this ad-
jective can modify a verb and therefore, it belongs
to the adv type.

As already mentioned, padv adjectives cannot
be distinguished from the ones of the adv kind.
That is why, if the classiﬁer has decided to assign
a padv type to a given unknown word, we discard
all other adjective types assigned to it (if any) and
do not apply the technique described below to this
word.

For each of the 59 words assigned an non-
inﬂected adjective type after the POS correction
stage, we extract up to 200 sentences for all non-
inﬂected forms in its paradigm. These sentences
are parsed with Alpino and the universal types and
the output is dependency triples. All triples where
the unknown word occurs as a dependent word in
a head modiﬁer dependency (hd/mod, as shown in
(5)) and its POS is adjective are extracted from the
parse output. We calculate the MLE of the cases
where the head word is a verb, i.e. where the un-
known word modiﬁes a verb. If the MLE is 0.05
or larger, the word is assigned an adv lexical type.

For example, the classiﬁer correctly identiﬁes
the word doortimmerd (solid) as being of the ad-
jective(no e(nonadv)) type but it also predicts the
adjective(no e(adv))1 type for it. Since we have
not found enough sentences where this word mod-
iﬁes a verb, the latter type is correctly discarded.
Our technique produced correct results for 53 out
of the 59 adjectives processed.

1The no e type attribute denotes a noninﬂected base ad-

jective form.

159

4.4

Improved Results and Discussion

5 Experiment with Real Unknown

Table 5 presents the results obtained after apply-
ing the improvement techniques described in this
section to the output of the classiﬁer (the ‘Model
2’ rows). For comparison, we also give the re-
sults from Table 3 again (the ‘Model 1’ rows).
The numbers for the nouns happen to remain un-
changed and that is why they are not shown in Ta-
ble 5.

POS

Adj

Verbs

Overall

Models
Model 1
Model 2
Model 1
Model 2
Model 1
Model 2

Prec.(%) Rec.(%)
75.50
85.16
77.32
80.56
86.59
89.08

73.12
80.16
55.37
56.24
78.62
80.52

F-meas.(%)
74.29
82.58
64.53
66.24
82.41
84.58

Table 5: Improved results

The automatic addition of adjective types for
past participles improved signiﬁcantly the recall
for adjectives and our method for choosing be-
tween adv and nonadv types caused a 10% in-
crease in precision.

However, these procedures also revealed some
incomplete lexical entries in Alpino. For example,
there are two past participles not listed as adjec-
tives in the lexicon though they should be. Thus
when our method correctly assigned them adjec-
tive types, it got punished since these types were
not in the gold standard.

We see in Table 5 that the increase in precision
for the verbs is small and recall remains practi-
cally unchanged. The unimproved recall shows
that we have not gained much from the subcat
frame heuristics. Even when the number of the
observed sentences was increased, less frequent
frames often remained unrecognisable from the
noise in the parsed data. This could be seen as
a proof that in the vast majority of cases verbs
are used transitively and/or intransitively. Since
the MLE method we employ proved to be good at
recognising these two frames and differentiating
between them, we have decided to continue using
it.

The overall F-score improved by only 2% be-
cause the modiﬁed verb and adjective predictions
are less than 30% of the total predictions made by
the classiﬁer.

Words

To investigate whether the proposed LA method
is also beneﬁcial for the parser, we observe how
parsing accuracy changes when the method is em-
ployed. Accuracy in Alpino is measured in terms
of labelled dependencies.

We have conducted an experiment with a test
set of 300 sentences which contain 188 real un-
known words. The sentences have been randomly
selected from the manually annotated LASSY
corpus (van Noord, 2009) which contains text
from various domains. The average sentence
length is 26.54 tokens.

The results are given in Table 6. The standard
Alpino model uses its guesser to assign types to
the unknown words. Model 1 employs the trained
ME-based classiﬁer to predict lexical entries for
the unknown words ofﬂine and then uses them
during parsing. Model 2 uses lexical entries modi-
ﬁed by applying the methods described in Section
4 to the output of the classiﬁer (Model 1).

Model
Alpino
Model 1
Model 2

Accuracy (%) msec/sentence

88.77
89.06
89.24

8658
8772
8906

Table 6: Results with real unknown words

Our LA system as a whole shows an error re-
duction rate of more than 4% with parse times re-
maining similar to those of the standard Alpino
version. It should also be noted that though much
of the unknown words are generally nouns, we see
from the results that it makes sense to also employ
the methods for improving the predictions for the
other POS types. A wrong verb or even adjec-
tive prediction can cause much more damage to
the analysis than a wrong noun one.

These results illustrate that the integration of
our method in the parser can improve its perfor-
mance on real-life data.

6 Discussion

6.1 Comparison to Previous Work

The performance of the LA method we presented
in this paper can be compared to the performance

160

of a number of other approaches previously ap-
plied to the same task.

Experiments with real unknown words have not
been performed.

Baldwin (2005) uses a set of binary classiﬁers
to learn lexical entries for a large-scale gram-
mar of English (ERG; (Copestake and Flickinger,
2000)). The main disadvantage of the method is
that it uses information obtained from secondary
language resources– POS taggers, chunkers, etc.
Therefore, the grammar takes no part in the LA
process and the method acquires lexical entries
based on incomplete linguistic information pro-
vided by the various resources. The highest F-
measure (about 65%) is achieved by using fea-
tures from a chunker but it is still 20% lower than
the results we report here. Further, no evalua-
tion is done on how the method affects the per-
formance of the ERG when the grammar is used
for parsing.

Zhang and Kordoni (2006) and Cholakov et
al. (2008), on the other hand, include features
from the grammar in a maximum entropy (ME)
classiﬁer to predict new lexical entries for the
ERG and a large German grammar (GG; (Crys-
mann, 2003)), respectively. The development data
for this method consist of linguistically annotated
sentences from treebanks and the grammar fea-
tures used in the classiﬁer are derived from this
annotation. However, when the method is applied
to open-text unannotated data, the grammar fea-
tures are replaced with POS tags. Therefore, the
grammar is no longer directly involved in the LA
process which affects the quality of the predic-
tions. Evaluation on sentences containing real un-
known words shows improvement of the coverage
for the GG when LA is employed but the accuracy
decreases by 2%. Such evaluation has not been
done for the ERG. The results on the development
data are not comparable with ours because evalu-
ation is done only in terms of precision while we
are also able to measure recall.

Statistical LA has previously been applied to
Alpino as well (van de Cruys, 2006). However,
his method employs less morphosyntactic features
in comparison to our approach and does not make
use of word paradigms. Further, though experi-
ments on development data are performed on a
smaller scale, the results in terms of F-measure are
10% lower than those reported in our case study.

Other, non-statistical LA methods also exist.
Cussens and Pulman (2000) describe a symbolic
approach which employs inductive logic program-
ming and Barg and Walther (1998) and Fouvry
(2003) follow a uniﬁcation-based approach. How-
ever, the generated lexical entries might be both
too general or too speciﬁc and it is doubtful if
these methods can be used on a large scale. They
have not been applied to broad-coverage gram-
mars and no evaluation is provided.

6.2 Application to Other Systems and

Languages

that

We stress the fact
the experiments with
Alpino represent only a case study. The proposed
LA method can be applied to other computational
grammars and languages providing that the fol-
lowing conditions are fulﬁlled.

First, words have to be mapped onto some ﬁ-
nite set of labels of which a subset of open-class
(universal) labels has to be selected. This subset
represents the labels which the ME-based classi-
ﬁer can predict for unknown words. Second, a
(large) corpus has to be available, so that various
sentences in which a given unknown word occurs
can be extracted. This is crucial for obtaining dif-
ferent contexts in which this word is found.

Next, we need a parser to analyse the extracted
sentences which allows for the syntactic con-
straints imposed by these contexts to be included
in the prediction process.

Finally, as for the paradigm generation, the idea
of combining a ﬁnite state morphology and web
heuristics is general enough to be implemented
for different languages.
It is also important to
note that the classiﬁer allows for arbitrary com-
binations of features and therefore, a researcher is
free to include any (language-speciﬁc) features he
or she considers useful for performing LA.

We have already started investigating the appli-
cability of our LA method to large-scale gram-
mars of German and French and the initial experi-
ments and results we have obtained are promising.

161

References
Baldwin, Tim. 2005. Bootstrapping deep lexical re-
sources: Resources for courses. In Proceedings of
the ACL-SIGLEX 2005 Workshop on Deep Lexical
Acquisition, Ann Arbor, USA.

Barg, Petra and Markus Walther. 1998. Processing un-
known words in HPSG. In Proceedings of the 36th
Conference of the ACL, Montreal, Quebec, Canada.

Brent, Michael R. 1993. From grammar to lexicon:
unsupervised learning of lexical syntax. Computa-
tional Linguistics, 19(2):243–262.

Briscoe, Ted and John Caroll. 1997. Automatic ex-
traction of subcategorization from corpora. In Pro-
ceedings of the 5th ACL Conference on Applied Nat-
ural Language Processing, Washington, DC.

Cholakov, Kostadin and Gertjan van Noord. 2009.
Combining ﬁnite state and corpus-based techniques
for unknown word prediction. In Proceedings of the
7th Recent Advances in Natural Language Process-
ing (RANLP) conference, Borovets, Bulgaria.

Cholakov, Kostadin, Valia Kordoni, and Yi Zhang.
2008. Towards domain-independent deep linguistic
processing: Ensuring portability and re-usability of
lexicalised grammars. In Proceedings of COLING
2008 Workshop on Grammar Engineering Across
Frameworks (GEAF08), Manchester, UK.

Copestake, Ann and Dan Flickinger.

2000. An
open-source grammar development environment
and broad-coverage English grammar using HPSG.
In Proceedings of the 2nd International Confer-
ence on Language Resource and Evaluation (LREC
2000), Athens, Greece.

Crysmann, Berthold. 2003. On the efﬁcient imple-
mentation of German verb placement in HPSG. In
Proceedings of RANLP 2003, Borovets, Bulgaria.

Cussens, James and Stephen Pulman. 2000.

Incor-
porating linguistic constraints into inductive logic
programming. In Proceedings of the Fourth Con-
ference on Computational Natural Language Learn-
ing.

Fouvry, Frederik. 2003. Lexicon acquisition with a
large-coverage uniﬁcation-based grammar. In Com-
panion to the 10th Conference of EACL, pages 87–
90, Budapest, Hungary.

Kinyon, Alexandra and Carlos A Prolo. 2002. Iden-
tifying verb arguments and their syntactic function
in the Penn Treebank. In Proceedings of the 3rd In-
ternational Conference on Language Resource and
Evaluation (LREC 2002), Las Palmas de Gran Ca-
naria, Spain.

Korhonen, Anna, Genevieve Gorell, and Diana Mc-
Carthy. 2000. Statistical ﬁltering and subcatego-
rization frame acquisition.
In Proceedings of the
Joint SIGDAT Conference on Empirical Methods in
Natural Language Processing and Very Large Cor-
pora, Hong Kong, China.

Lapata, Mirella. 1999. Acquiring lexical generaliza-
tions from corpora. A case study for diathesis alter-
nations. In Proceedings of the 37th Annual Meeting
of ACL, Maryland, USA.

Malouf, Robert. 2002. A comparison of algorithms
for maximum entropy parameter estimation. In Pro-
ceedings of the 6th conference on Natural Language
Learning (CoNLL-2002), pages 49–55, Taipei, Tai-
wan.

Manning, Christopher. 1993. Automatic acquisition
of a large subcategorization dictionary from cor-
pora.
In Proceedings of the 31st Annual Meeting
of ACL, Columbus, OH.

Messiant, Cedric. 2008. A subcategorization acquisi-
tion system for French verbs. In Proceedings of the
ACL 2008 Student Research Workshop, Columbus,
OH.

O’Donovan, Ruth, Michael Burke, Aoife Cahill, Josef
van Genabith, and Andy Way. 2005. Large-scale
induction and evaluation of lexical resources from
the Penn-II and Penn-III Treebanks. Computational
Linguistics, 31(3):329–365.

Prins, Robbert and Gertjan van Noord. 2001. Un-
supervised POS-tagging improves parcing accuracy
and parsing efﬁciency.
In Proceedings of IWPT,
Beijing, China.

van de Cruys, Tim. 2006. Automatically extending the
lexicon for parsing. In Huitnik, Janneje and Sophia
Katrenko, editors, Proceedings of the Eleventh ESS-
LLI Student Session, pages 180–189.

van Noord, Gertjan. 2006. At last parsing is now oper-
ational. In Proceedings of TALN, Leuven, Belgium.

van Noord, Gertjan. 2009. Huge parsed corpora in
LASSY.
In Proceedings of the Seventh Interna-
tional Workshop on Treebanks and Linguistic The-
ories (TLT 7), Groningen, The Netherlands.

Zhang, Yi and Valia Kordoni. 2006. Automated deep
lexical acquisition for robust open text processing.
In Proceedings of the Fifth International Confer-
ence on Language Resourses and Evaluation (LREC
2006), Genoa, Italy.

