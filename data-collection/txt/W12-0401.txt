










































Linguistic Cues to Deception Assessed by Computer Programs: A Meta-Analysis


Proceedings of the EACL 2012 Workshop on Computational Approaches to Deception Detection, pages 1–4,
Avignon, France, April 23 - 27 2012. c©2012 Association for Computational Linguistics

Linguistic Cues to Deception Assessed by Computer Programs:           
A Meta-Analysis 

 
Valerie Hauch, Iris Blandón-Gitlin, 

Justus-Liebig-University of Giessen, 
Germany 

California State University, Fullerton,     
USA 

Valerie.Hauch@psychol.uni-
giessen.de 

iblandon-gitlin@.fullerton.edu 

Jaume Masip, & Siegfried L. Sporer 
University of Salamanca,                        

Spain 
Justus-Liebig-University of Giessen, 

Germany 
jmasip@usal.es Sporer@psychol.uni-giessen.de 

 
 

Abstract 

Research syntheses suggest that verbal 
cues are more diagnostic of deception 
than other cues. Recently, to avoid 
human judgmental biases, researchers 
have sought to find faster and more 
reliable methods to perform automatic 
content analyses of statements. However, 
diversity of methods and inconsistent 
findings do not present a clear picture of 
effectiveness. We integrate and 
statistically synthesize this literature. Our 
meta-analyses revealed small, but 
significant effect-sizes on some linguistic 
categories. Liars use fewer exclusive 
words, self- and other-references, fewer 
time-related, but more space-related, 
negative and positive emotion words, and 
more motion verbs or negations than 
truth-tellers. 

1. Introduction 

Meta-analytic findings indicate that human 
judges are just slightly better than chance at 
discriminating between truths and lies (Bond, & 
DePaulo, 2006). Likewise, meta-analyses of 
training programs designed to teach lie detection 
have shown a small to medium effect size in 
improving judges' detection accuracy (e.g., 
Hauch, Sporer, Michael, & Meissner, 2010). 
Together, these findings suggest that there is a 
great need to better understand factors involved 
in deception and find ways to improve its 
detection. Attempts at these tasks have led 
researchers to use computer programs to analyze 

linguistic markers in truthful and deceptive 
statements. A number of verbal cues have been 
shown to differ in lies and truths (DePaulo, 
Lindsay, Malone, Muhlenbruck, Charlton, & 
Cooper, 2003; Sporer, 2004, Vrij, 2008), and 
teaching content cues has shown to improve 
detection more effectively than teaching 
nonverbal or paraverbal cues (Hauch et al., 
2010). 
The automatization of lie detection is appealing 
for at least two reasons. First, such systems can 
be considered more objective than human judges 
who are prone to biases (Levine, Park, & 
McCornack, 1999). Second, online judgments of 
various deception cues from videos or transcripts 
can tax the cognitive capacity of judges and lead 
to time delays and errors. Researchers have used 
different computer programs for the evaluation 
of the truth status. Computers can quickly 
analyze large amounts of text and provide more 
reliable data. Moreover, the linguistic categories 
evaluated across studies have varied. In some 
cases, the direction of the effect for the same 
linguistic categories has been opposite across 
studies, or opposite to theoretically-based 
predictions. 
These methodological differences and 
inconsistencies in findings calls for a quantitative 
analysis and integration of findings. This is the 
goal of the present meta-analytic review. 

2. Method 

After a thorough literature search (Social 
Sciences Citation Index, PsycInfo, Dissertation 
Abstracts, Google Scholar, and cited reference 
searches), a large number (k = 84) of published 

1



and unpublished studies were located. Studies 
were only included into the meta-analysis if they 
meet several inclusion criteria.  

2.1 Inclusion Criteria 

• Use of computer-based method/program 
to analyze transcripts in terms of specific 
linguistic categories; 

• Datasets of transcripts (from spoken or 
written language) which include 
deceptive and truthful accounts; 

• Independence of datasets; 
• Specific linguistic categories applied to 

predict truth status; 
• Sufficient statistical data (means and 

standard deviation separately for lies and 
truths) to calculate effect sizes (Cohen's 
d) for specific categories; 

• Sources written in English, Spanish, or 
German. 

2.2 Exclusion Criteria 

• Psychophysiological methods or use of 
subjective ratings; 

• Ground truth of real statements only 
established from verdicts or media 
commentaries (or not established); 

• Only computer-analysed linguistic 
variable is “word count”. 

 
Thirteen studies using the Linguistic Inquiry 
Word Count (LIWC) program (Newman, 
Pennebaker, Berry, & Richards, 2003) met the 
inclusion criteria. The initial statistical synopsis 
of these LIWC studies is presented below. The 
conference presentation will additionally include 
the meta-analysis of all other studies meeting the 
inclusion criteria (k = 16) using different 
computer programs (e.g., General Architecture 
for Text Extraction (GATE), Agent99-Analyzer, 
CohMetrix). 

2.3 Independent Variables Coded 

(a) number of senders, (b) number of linguistic 
categories used, (c) medium used by senders to 
provide accounts, (d) type of and valence of the 
event, (e) senders' motivation, (f) senders' 
preparation, (g) theory motivating the selection 
of categories, and (h) predictions for specific 
categories. 

2.4 Dependent Variables Coded 

(a) Effect sizes for each category in 
discriminating between truths and lies, (b) 

logistic regression or multiple discriminant 
analysis results for truths, lies, and overall 
classifications, and (c) reliability of each 
category. 

2.5 Effect Size Measure 

In order to compare the results from different 
studies, we computed the standardized mean 
difference as an effect size, which is referred to 
as Cohen’s d (1988). Formula for computation of 
Cohen’s d and for the entire meta-analytic 
procedure can be found in Cooper, Hedges, and 
Borenstein (2009), Hedges and Olkin (1985), or 
Lipsey and Wilson (2001). Cohen (1988) 
cautiously classified the effect size d into three 
categories of magnitude, with d = .20 defined as 
small, d = .50 defined as medium and d = .80 
defined as large effect sizes. If a specific 
linguistic cue was more often used during 
deception than in a true story, d becomes a 
negative sign. In case a linguistic cue occurred 
more often during a true than a deceptive story, d 
becomes a positive value. 

3. Results and Discussion 

3.1 Descriptive Analyses 

Results of k = 13 LIWC studies (from 9 sources; 
k = 5 published and k = 4 unpublished) revealed 
that most of the studies (k = 11) examined 
English transcripts, and two either Spanish or 
Dutch transcripts. In sum, 1143 transcripts were 
analyzed with a mean of 111 per study, which 
were given (handwritten or typed (k = 5), 
audiotaped or videotaped (k = 6) by 697 
individuals. Senders' task was to lie or tell the 
truth about different topics, and in 38.46% of 
cases the story's valence was negative. Senders 
were slightly motivated in 60% of the studies, 
either receiving a small amount of money or a 
short verbal instruction. 
Before analyzing the transcripts, they were 
corrected for errors (according to the manual) in 
9 studies, whereas the remaining 4 did not report 
on that. From 68 default linguistic LIWC-
categories, on average, 42 dimensions (k = 10) 
were analyzed at times with respect to a 
theoretical background (e.g., cognitive or 
emotional approaches, Reality Monitoring). 
Other categories were excluded due to a low base 
rate or due to nonsignificant findings. 
 
 

2



3.2 Meta-analytic results 

Effect sizes with negative signs indicate that liars 
used the linguistic categories at a higher rate. At 
this point, 15 categories were chosen with at least 
k = 5 each. Liars tend to use more words 
expressing negative emotions (d = -0.111, p = 
.041, k = 13,) and positive emotions (d = -0.201, 
p = .030, k = 5), more emotional words (Figure 1, 
d = -0.187, p = .046, k = 5), more motion verbs 
(d = -0.141, p = .011, k = 12), and more negation 
words (d = -0.188, p = .010, k = 4). 

 
Figure 1. Distribution of Individual Effect Sizes for 
Emotion Words. 
 
In contrast, truth-tellers make more use of self-
references than liars (d = 0.123, p = .044, k = 10), 
other-references (d = 0.138, p = .019, k = 10), 
exclusive words (Figure 2, d = 0.360, p = .000, k 
= 12), slightly more tentative words (d = 0.172, p 
= .071, k = 4) or time-related words (d = 0.177, p 
= .057, k = 5) than liars.  

Figure 2. Distribution of Individual Effect Sizes for 
Exclusive Words. 
 
No significant differences between liars and 
truth-tellers emerged for word count (Figure 3), 

the use of sensual and perceptual words, 
cognitive mechanisms or certainty words.  
 

Figure 3. Distribution of Individual Effect Sizes for 
Word Count. 
 
Although we found significant differences for 
some categories, we have to be aware of their 
general small magnitude (mean of all unweighted 
and absolute ds = 0.122, mean of all weighted 
and absolute ds = 0.137) and the small numbers 
of studies within each meta-analysis. 
While some linguistic categories included in 
LIWC studies do not appear to have empirical 
precedence (e.g., motion verbs), others do have 
support from cognitive and emotional theoretical 
approaches (Bond & Lee, 2005). It has been 
proposed that truth-tellers make more self-
references because they are more likely than liars 
to associate themselves with the communication. 
Similarly, whereas truth-tellers are believed to 
use more exclusive words, signaling more 
complex explanations of what occurred, liars are 
believed to engage less in such explanations. 
Time, affect, space-related, and sensory words 
are features in accounts based on experienced 
events as predicted by the Reality Monitoring 
framework (Mitchell & Johnson, 2000; Sporer, 
2004). Negative emotion words are predicted to 
be higher in deceptive than true statements due to 
guilt or anxiety associated with the act of 
deception (Vrij, 2008). These predictions were 
partially supported by the current meta-analysis.  
Further meta-analyses with other computer 
programs (e.g., Fuller, Biros, Burgoon, Adkins, 
& Twitchell, 2006; Humpherys, Moffitt, Burns, 
Burgoon, & Felix, 2011; Zhou, Burgoon, 
Nunamaker, & Twitchell, 2004) and theoretically 
driven moderator analyses (e.g., difference 
between children and adults, the effect of 
senders' motivation or preparation) will elucidate 
the linguistic pattern of truth-telling versus lying 
under specific conditions. 

3



4. References 

References marked with an asterisk are included 
in the meta-analysis. 
 
*Ali, M. & Levine, T. (2008). The language of 

truthful and deceptive denials and confessions. 
Communication Reports, 21, 82–91. 

Bond, C. F., & DePaulo, B. M. (2006). Accuracy of 
deception judgments. Personality and Social 
Psychology Review, 10, 214-234. 

*Bond, G. D., & Lee, A. Y. (2005). Language of lies 
in prison: Linguistic classification of prisoners' 
truthful and deceptive natural language. Applied 
Cognitive Psychology, 19, 313-329. 

*Brunet, M. K. (2009). Why bullying victims are not 
believed: Differentiating between children’s true 
and fabricated reports of stressful and non-
stressful events (Unpublished master’s thesis). 
University of Toronto, Toronto. 

Cohen, J. (1988). Statistical power analysis for the 
behavioural sciences (2nd ed.). Hillsdale, NJ: 
Erlbaum. 

Cooper, H., Hedges, L. V., & Valentine, J. C. (Eds.) 
(2009). The handbook of research synthesis and 
meta-analysis (2nd ed.). New York: Russell Sage 
Foundation. 

DePaulo, B. M., Lindsay, J. J., Malone, B. E., 
Muhlenbruck, L., Charlton, K., & Cooper, H. 
(2003). Cues to deception. Psychological Bulletin, 
129, 74-118. 

*Fuller, C., Biros, D. P., Burgoon, J. K., Adkins, M. 
Twitchell, D. P. (2006). An analysis of text-based 
deception detection tools, Proceedings of the 12th 
Americas Conference on Information Systems, 
Acapulco, Mexico. 

*Hancock, J. T., Curry, L. E., Goorha, S., & 
Woodworth, M. (2008). On lying and being lied to: 
A linguistic analysis of deception in computer-
mediated communication. Discourse Processes, 45, 
1-23. 

Hauch, V., Sporer, S. L., Michael, S. W., & Meissner, 
C. A. (2010, June). Does training improve 
detection of deception? A meta-analysis. Paper 
presented at the 20th Conference of the European 
Association of Psychology and Law, Gothenburg, 
Sweden. 

Hedges, L. V., & Olkin, I. (1985). Statistical methods 
for meta-analysis. New York: Academic Press. 

*Humpherys, S. L., Moffitt, K. C., Burns, M. B., 
Burgoon, J. K., Felix, W. F. (2011). Identification 
of fraudulent financial statements using linguistic 
credibility analysis. Decision Support Systems, 50, 
585–594. 

*Koyanagi, J. & Blandón-Gitlin, I. (2011, March). 
Analysis of Children’s Deception with the 
Linguistic Inquiry and Word Count Approach. 
Poster session presented at the 4th International 
Congress on Psychology and Law / 2011 Annual 
Meeting of the American Psychology-Law Society, 
Miami, Florida. 

Levine, T. R., Park, H. S., & McCornack, S. A. 
(1999). Accuracy in detecting truths and lies: 
Documenting the "veracity effect". Communication 
Monographs, 66, 125-144. 

Lipsey, M. W., & Wilson, D. B. (2001). Practical 
meta-analysis. Thousand Oaks: Sage Publications. 

*Masip, J., Bethencourt, M., Lucas, G., Sánchez-San 
Segundo, M., & Herrero, C. (2011). Deception 
detection from written accounts. Scandinavian 
Journal of Psychology. 

Meissner, C. A. & Kassin, S. M. (2002). "He's 
guilty!": Investigator bias in judgments of truth and 
deception. Law and Human Behavior, 26, 469-480. 

Mitchell, K. J., & Johnson, M. K. (2000). Source 
monitoring: Attributing mental experiences. In E. 
Tulving, & F. I. M. Craik (Eds.), The Oxford 
Handbook of Memory (pp. 179-195). New York: 
Oxford University Press. 

*Newman, M. L., Pennebaker, J. W., Berry, D. S., & 
Richards, J. M. (2003). Lying words: Predicting 
deception from linguistic styles. Personality and 
Social Psychology Bulletin, 29, 665–675. 

*Rowe, K. & Blandón-Gitlin, I. (2008, March). 
Discriminating true, suggested, and fabricated 
statements with the Linguistic Inquiry and Word 
Count approach. Poster session presented at the 
Annual Meeting of the American Psychology-Law 
Society, Jacksonville, Florida. 

*Schelleman-Offermans, K., & Merckelbach, H. 
(2010). Fantasy proneness as a confounder of 
verbal lie detection tools. Journal of Investigative 
Psychology and Offender Profiling, 7, 247-260. 

Sporer, S. L. (2004). Reality monitoring and the 
detection of deception. In P.-A. Granhag & L. 
Stromwall (Eds.), Deception detection in forensic 
contexts (pp. 64-102). Cambridge University Press. 

Vrij, A. (2008). Detecting lies and deceit: Pitfalls and 
opportunities. Chichester, England: Wiley. 

*Zhou, L., Burgoon, J. K., Nunamaker, J. F., & 
Twitchell, D. (2004). Automating linguistics-based 
cues for detecting deception in text-based 
asynchronous computer-mediated communication. 
Group Decision and Negotiation, 13, 81-106. 

 

4


