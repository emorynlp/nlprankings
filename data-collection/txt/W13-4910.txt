










































SPMRL'13 Shared Task System: The CADIM Arabic Dependency Parser


Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, pages 86–90,
Seattle, Washington, USA, 18 October 2013. c©2013 Association for Computational Linguistics

SPMRL’13 Shared Task System:
The CADIM Arabic Dependency Parser

Yuval Marton
Microsoft Corporation

City Center Plaza
Bellevue, WA, USA

Nizar Habash, Owen Rambow
CCLS

Columbia University
New York, NY, USA

cadim@ccls.columbia.edu

Sarah Alkuhlani
CS Department

Columbia University
New York, NY, USA

Abstract

We describe the submission from the
Columbia Arabic & Dialect Modeling
group (CADIM) for the Shared Task at
the Fourth Workshop on Statistical Pars-
ing of Morphologically Rich Languages
(SPMRL’2013). We participate in the
Arabic Dependency parsing task for pre-
dicted POS tags and features. Our system
is based on Marton et al. (2013).

1 Introduction

In this paper, we discuss the system that the
Columbia Arabic & Dialect Modeling group
(CADIM) submitted to the 2013 Shared Task on
Parsing Morphologically Rich Languages (Seddah
et al., 2013). We used a system for Arabic depen-
dency parsing which we had previously developed,
but retrained it on the training data splits used in this
task. We only participated in the Arabic dependency
parsing track, and in it, only optimized for predicted
(non-gold) POS tags and features.

We first summarize our previous work (Sec-
tion 2). We then discuss our submission and the re-
sults (Section 3).

2 Approach

In this section, we summarize Marton et al. (2013).
We first present some background information on
Arabic morphology and then discuss our method-
ology and main results. We present our best per-
forming set of features, which we also use in our
SPMRL’2013 submission.

2.1 Background

Morphology interacts with syntax in two ways:
agreement and assignment. In agreement, there is
coordination between the morphological features of
two words in a sentence based on their syntactic
configuration (e.g., subject-verb or noun-adjective
agreement in GENDER and/or NUMBER). In as-
signment, specific morphological feature values are
assigned in certain syntactic configurations (e.g.,
CASE assignment for the subject or direct object of
a verb).

The choice of optimal linguistic features for
a parser depends on three factors: relevance,
redundancy and accuracy. A feature has rel-
evance if it is useful in making an attach-
ment (or labeling) decision. A particular fea-
ture may or may not be relevant to parsing.
For example, the GENDER feature may help
parse the Arabic phrase �èYK
Ym.Ì'@/YK
Ym.Ì'@

�
èPAJ
Ë@ H. AK.

bAb AlsyArh̄ Aljdyd/Aljdydh̄1 ‘door the-car the-
newmasc.sg/fem.sg [lit.]’ using syntactic agreement:
if the-new is masculine (Aljdyd YK
Ym.Ì'@), it should at-
tach to the masculine door (bAb H. AK.), resulting in
the meaning ‘the car’s new door’; if the-new is fem-
inine (Aljdydh̄ �èYK
Ym.Ì'@), it should attach to the femi-
nine the-car (AlsyArh̄ �èPAJ
Ë@), resulting in ‘the door
of the new car’. In contrast, the ASPECT feature does

1Arabic orthographic transliteration is presented in the HSB
scheme (Habash et al., 2007): (in alphabetical order)
@ H.

�
H

�
H h. h p X

	
XP 	P 

�
 

	
  

	
  ¨

	
¨

	
¬

�
 ¼ È Ð

	
à è ð ø




A b t θ j H x d ð r z s š S D T Ď ς γ f q k l m n h w y

and the additional letters: ’ Z, Â

@, Ǎ @


, Ā

�
@, ŵ ð', ŷ Zø', h̄ �è, ý ø.

86



not constrain any syntactic decision.2 Even if rele-
vant, a feature may not necessarily contribute to op-
timal performance since it may be redundant with
other features that surpass it in relevance. For ex-
ample, the DET and STATE features alone both help
parsing because they help identify the idafa con-
struction (the modificiation of a nominal by a gen-
itive noun phrase), but they are redundant with each
other and the DET feature is more helpful since it
also helps with adjectival modification of nouns. Fi-
nally, the accuracy of automatically predicting the
feature values (ratio of correct predictions out of all
predictions) of course affects the value of a feature
on unseen text. Even if relevant and non-redundant,
a feature may be hard to predict with sufficient ac-
curacy by current technology, in which case it will
be of little or no help for parsing, even if helpful
when its gold values are provided. The CASE fea-
ture is very relevant and not redundant, but it cannot
be predicted with high accuracy and overall it is not
useful.

Different languages vary with respect to which
features may be most helpful given various tradeoffs
among these three factors. It has been shown pre-
viously that if the relevant morphological features
in assignment configurations can be recognized well
enough, then they contribute to parsing accuracy.
For example, modeling CASE in Czech improves
Czech parsing (Collins et al., 1999): CASE is rele-
vant, not redundant, and can be predicted with suf-
ficient accuracy. However, it had been more diffi-
cult showing that agreement morphology helps pars-
ing, with negative results for dependency parsing in
several languages (Nivre et al., 2008; Eryigit et al.,
2008; Nivre, 2009). In contrast to these negative re-
sults, Marton et al. (2013) showed positive results
for using agreement morphology for Arabic.

2.2 Methodology

In Marton et al. (2013), we investigated morphologi-
cal features for dependency parsing of Modern Stan-
dard Arabic (MSA). The goal was to find a set of rel-
evant, accurate and non-redundant features. We used
both the MaltParser (Nivre, 2008) and the Easy-First

2For more information on Arabic morphology in the con-
text of natural language processing see Habash (2010). For a
detailed analysis of morpho-syntactic agreement, see Alkuhlani
and Habash (2011).

Parser (Goldberg and Elhadad, 2010). Since the
Easy-First Parser performed better, we use it in all
experiments reported in this paper.

For MSA, the space of possible morphological
features is quite large. We determined which mor-
phological features help by performing a search
through the feature space. In order to do this, we
separated part-of-speech (POS) from the morpho-
logical features. We defined a core set of 12 POS
features, and then explored combinations of mor-
phological features in addition to this POS tagset.
This core set of POS tags is similar to those pro-
posed in cross-lingual work (Rambow et al., 2006;
Petrov et al., 2012). We performed this search inde-
pendently for Gold input features and predicted in-
put features. We used our MADA+TOKAN system
(Habash and Rambow, 2005; Habash et al., 2009;
Habash et al., 2012) for the prediction. As the Easy-
First Parser predicts links separately before labels,
we first optimized for unlabeled attachment score,
and then optimized the Easy-First Parser labeler for
label score.

As had been found in previous results, assignment
features, specifically CASE and STATE, are very
helpful in MSA. However, in MSA this is true only
under gold conditions: since CASE is rarely explicit
in the typically undiacritized written MSA, it has a
dismal accuracy rate, which makes it useless when
used in machine-predicted (real, non-gold) condi-
tion. In contrast with previous results, we showed
that agreement features are quite helpful in both gold
and predicted conditions. This is likely a result of
MSA having a rich agreement system, covering both
verb-subject and noun-adjective relations.

Additionally, almost all work to date in MSA
morphological analysis and part-of-speech (POS)
tagging has concentrated on the morphemic form of
the words. However, often the functional morphol-
ogy (which is relevant to agreement, and relates to
the meaning of the word) is at odds with the “sur-
face” (form-based) morphology; a well-known ex-
ample of this are the “broken” (irregular) plurals
of nominals, which often have singular-form mor-
phemes but are in fact plurals and show plural agree-
ment if the referent is rational. In Marton et al.
(2013), we showed that by modeling the functional
morphology rather than the form-based morphology,
we obtain a further increase in parsing performance

87



Feature Type Feature Explanation
Part-of-speech CORE12 12 tags for core parts-of-speech: verb, noun, adjective, adverb,

proper noun, pronoun, preposition, conjunction, relative pronoun,
particle, abbreviation, and punctuation

Inflectional features DET Presence of the determiner morpheme È@ Al
PERSON 1st, 2nd, or 3rd
FN*N Functional number: singular, dual, plural
FN*G Functional gender: masculine or feminine

Lexical features FN*R Rationality: rational, irrational, ambiguous, unknown or N/A
LMM Undiacritized lemma

Table 1: Features used in the CADIM submission with the Easy-First Parser (Goldberg and Elhadad, 2010).

Training Set Test Set LAS UAS LaS
5K (SPMRL’2013) dev ≤ 70 81.7 84.7 92.7
All (SPMRL’2013) dev ≤ 70 84.8 87.4 94.2
Marton et al. (2013) test (old split) ≤ 70 81.7 84.6 92.8
5K (SPMRL’2013) dev 81.1 84.2 92.7
All (SPMRL’2013) dev 84.0 86.6 94.1
5K (SPMRL’2013) test 80.5 83.5 92.7
All (SPMRL’2013) test 83.2 85.8 93.9
Marton et al. (2013) test (old split) 81.0 84.0 92.7

Table 2: Results of our system on Shared Task test data, Gold Tokenization, Predicted Morphological Tags; and for
reference also on the data splits used in our previous work (Marton et al., 2013); “≤ 70” refers to the test sentences
with 70 or fewer words.

Training Set Test Set Labeled Tedeval Score Unlabeled Tedeval Score
5K (SPMRL’2013) test ≤ 70 86.4 89.9
All (SPMRL’2013) test ≤ 70 87.8 90.8

Table 3: Results of our system on on Shared Task test data, Predicted Tokenization, Predicted Morphological Tags;
“≤ 70” refers to the test sentences with 70 or fewer words

(again, both when using gold and when using pre-
dicted POS and morphological features).

We also showed that for parsing with predicted
POS and morphological features, training on a com-
bination of gold and predicted POS and morpholog-
ical feature values outperforms the alternative train-
ing scenarios.

2.3 Best Performing Feature Set
The best performing set of features on non-gold in-
put, obtained in Marton et al. (2013), are shown in
Table 1. The features are clustered into three types.

• First is part-of-speech, represented using a

“core” 12-tag set.

• Second are the inflectional morphological fea-
tures: determiner clitic, person and functional
gender and number.

• Third are the rationality (humanness) feature,
which participates in morphosyntactic agree-
ment in Arabic (Alkuhlani and Habash, 2011),
and a form of the lemma, which abstract over
all inflectional morphology.

For the training corpus, we use a combination of
the gold and predicted features.

88



3 Our Submission

3.1 Data Preparation

The data split used in the shared task is different
from the data split we used in (Marton et al., 2013),
so we retrained our models on the new splits (Diab
et al., 2013). The data released for the Shared Task
showed inconsistent availability of lemmas across
gold and predicted input, so we used the ALMOR
analyzer (Habash, 2007) with the SAMA databases
(Graff et al., 2009) to determine a lemma given the
word form and the provided (gold or predicted) POS
tags. In addition to the lemmas, the ALMOR an-
alyzer also provides morphological features in the
feature-value representation our approach requires.
Finally, we ran our existing converter (Alkuhlani
and Habash, 2012) over this representation to obtain
functional number and gender, as well as the ratio-
nality feature.3 For simplicity reasons, we used the
MLE:W2+CATiB model (Alkuhlani and Habash,
2012), which was the best performing model on seen
words, as opposed to the combination system that
used a syntactic component with better results on
unseen words. We did not perform Alif or Ya nor-
malization on the data.

We trained two models: one on 5,000 sentences
of training data and one on the entire training data.

3.2 Results

Our performance in the Shared Task for Arabic De-
pendency, Gold Tokenization, Predicted Tags, is
shown in Table 2. Our performance in the Shared
Task for Arabic Dependency, Predicted Tokeniza-
tion, Predicted Tags, is shown in Table 3. For
predicted tokenization, only the IMS/Szeged sys-
tem which uses system combination (Run 2) out-
performed our parser on all measures; our parser
performed better than all other single-parser sys-
tems. For gold tokenization, our system is the sec-
ond best single-parser system after the IMS/Szeged
single system (Run 1). For gold tokenization and
predicted morphology (Table 2), we also give the
performance reported in our previous work (Mar-
ton et al., 2013). The increase over the previously

3The functional feature generator of (Alkuhlani and Habash,
2012) was trained on a different training set from the parser, but
the functional feature generator was not trained on any of the
test corpus for the Shared Task.

reported work may simply be due to the different
split for training and test, but it may also be due
to improvements to the functional feature prediction
(Alkuhlani and Habash, 2012), and the predicted
features provided by the Shared Task organizers.

References

Sarah Alkuhlani and Nizar Habash. 2011. A corpus for
modeling morpho-syntactic agreement in Arabic: gen-
der, number and rationality. In Proceedings of the 49th
Annual Meeting of the Association for Computational
Linguistics (ACL), Portland, Oregon, USA.

Sarah Alkuhlani and Nizar Habash. 2012. Identifying
broken plurals, irregular gender, and rationality in Ara-
bic text. In Proceedings of the 13th Conference of
the European Chapter of the Association for Compu-
tational Linguistics, pages 675–685. Association for
Computational Linguistics.

Michael Collins, Jan Hajic, Lance Ramshaw, and
Christoph Tillmann. 1999. A statistical parser for
Czech. In Proceedings of the 37th Annual Meeting of
the Association for Computational Linguistics (ACL),
pages 505–512, College Park, Maryland, USA, June.

Mona Diab, Nizar Habash, Owen Rambow, and Ryan
Roth. 2013. LDC Arabic Treebanks and Associated
Corpora: Data Divisions Manual. Technical Report
CCLS-13-02, Center for Computational Learning Sys-
tems, Columbia University.

Gülsen Eryigit, Joakim Nivre, and Kemal Oflazer. 2008.
Dependency parsing of Turkish. Computational Lin-
guistics, 34(3):357–389.

Yoav Goldberg and Michael Elhadad. 2010. An effi-
cient algorithm for easy-first non-directional depen-
dency parsing. In Proceedings of Human Language
Technology (HLT): the North American Chapter of the
Association for Computational Linguistics (NAACL),
pages 742–750, Los Angeles, California.

David Graff, Mohamed Maamouri, Basma Bouziri,
Sondos Krouna, Seth Kulick, and Tim Buckwal-
ter. 2009. Standard Arabic Morphological Analyzer
(SAMA) Version 3.1. Linguistic Data Consortium
LDC2009E73.

Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morphological
Disambiguation in One Fell Swoop. In Proceedings of
the 43rd Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 573–580, Ann Ar-
bor, Michigan.

Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.
2007. On Arabic Transliteration. In A. van den Bosch

89



and A. Soudi, editors, Arabic Computational Mor-
phology: Knowledge-based and Empirical Methods.
Springer.

Nizar Habash, Owen Rambow, and Ryan Roth. 2009.
MADA+TOKAN: A toolkit for Arabic tokenization,
diacritization, morphological disambiguation, POS
tagging, stemming and lemmatization. In Khalid
Choukri and Bente Maegaard, editors, Proceedings of
the Second International Conference on Arabic Lan-
guage Resources and Tools. The MEDAR Consortium,
April.

Nizar Habash, Owen Rambow, and Ryan Roth. 2012.
MADA+TOKAN Manual. Technical report, Techni-
cal Report CCLS-12-01, Columbia University.

Nizar Habash. 2007. Arabic Morphological Representa-
tions for Machine Translation. In Antal van den Bosch
and Abdelhadi Soudi, editors, Arabic Computational
Morphology: Knowledge-based and Empirical Meth-
ods. Kluwer/Springer.

Nizar Habash. 2010. Introduction to Arabic Natural
Language Processing. Morgan & Claypool Publish-
ers.

Yuval Marton, Nizar Habash, and Owen Rambow. 2013.
Dependency parsing of Modern Standard Arabic with
lexical and inflectional features. Computational Lin-
guistics, 39(1).

Joakim Nivre, Igor M. Boguslavsky, and Leonid K.
Iomdin. 2008. Parsing the SynTagRus Treebank of
Russian. In Proceedings of the 22nd International
Conference on Computational Linguistics (COLING),
pages 641–648.

Joakim Nivre. 2008. Algorithms for Deterministic Incre-
mental Dependency Parsing. Computational Linguis-
tics, 34(4).

Joakim Nivre. 2009. Parsing Indian languages with
MaltParser. In Proceedings of the ICON09 NLP Tools
Contest: Indian Language Dependency Parsing, pages
12–18.

Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proceedings of
the Conference on Language Resources and Evalua-
tion (LREC), May.

Owen Rambow, Bonnie Dorr, David Farwell, Rebecca
Green, Nizar Habash, Stephen Helmreich, Eduard
Hovy, Lori Levin, Keith J. Miller, Teruko Mitamura,
Florence Reeder, and Siddharthan Advaith. 2006. Par-
allel syntactic annotation of multiple languages. In
Proceedings of the Fifth Conference on Language Re-
sources and Evaluation (LREC), Genoa, Italy.

Djamé Seddah, Reut Tsarfaty, Sandra Kübler, Marie Can-
dito, Jinho Choi, Richárd Farkas, Jennifer Foster, Iakes
Goenaga, Koldo Gojenola, Yoav Goldberg, Spence
Green, Nizar Habash, Marco Kuhlmann, Wolfgang

Maier, Joakim Nivre, Adam Przepiorkowski, Ryan
Roth, Wolfgang Seeker, Yannick Versley, Veronika
Vincze, Marcin Woliński, Alina Wróblewska, and Eric
Villemonte de la Clérgerie. 2013. Overview of the
spmrl 2013 shared task: A cross-framework evalua-
tion of parsing morphologically rich languages. In
Proceedings of the 4th Workshop on Statistical Pars-
ing of Morphologically Rich Languages: Shared Task,
Seattle, WA.

90


