Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 143–151,

Beijing, August 2010

143

End-to-End Coreference Resolution via Hypergraph Partitioning

Jie Cai and Michael Strube

Natural Language Processing Group

Heidelberg Institute for Theoretical Studies gGmbH

(jie.cai|michael.strube)@h-its.org

Abstract

In constrast

We describe a novel approach to coref-
erence resolution which implements a
global decision via hypergraph partition-
ing.
to almost all previ-
ous approaches, we do not rely on sep-
arate classiﬁcation and clustering steps,
but perform coreference resolution glob-
ally in one step. Our hypergraph-based
global model implemented within an end-
to-end coreference resolution system out-
performs two strong baselines (Soon et al.,
2001; Bengtson & Roth, 2008) using sys-
tem mentions only.

1

Introduction

Coreference resolution is the task of grouping
mentions of entities into sets so that all mentions
in one set refer to the same entity. Most recent
approaches to coreference resolution divide this
task into two steps: (1) a classiﬁcation step which
determines whether a pair of mentions is corefer-
ent or which outputs a conﬁdence value, and (2)
a clustering step which groups mentions into enti-
ties based on the output of step 1.

The classiﬁcation steps of most approaches
vary in the choice of the classiﬁer (e.g. decision
tree classiﬁers (Soon et al., 2001), maximum en-
tropy classiﬁcation (Luo et al., 2004), SVM clas-
siﬁers (Rahman & Ng, 2009)) and the number of
features used (Soon et al. (2001) employ a set of
twelve simple but effective features while e.g., Ng
& Cardie (2002) and Bengtson & Roth (2008) de-
vise much richer feature sets).

The clustering step exhibits much more varia-
tion: Local variants utilize a closest-ﬁrst decision

(Soon et al., 2001), where a mention is resolved to
its closest possible antecedent, or a best-ﬁrst deci-
sion (Ng & Cardie, 2002), where a mention is re-
solved to its most conﬁdent antecedent (based on
the conﬁdence value returned by step 1). Global
variants attempt to consider all possible cluster-
ing possibilites by creating and searching a Bell
tree (Luo et al., 2004), by learning the optimal
search strategy itself (Daum´e III & Marcu, 2005),
by building a graph representation and applying
graph clustering techniques (Nicolae & Nicolae,
2006), or by employing integer linear program-
ming (Klenner, 2007; Denis & Baldridge, 2009).
Since these methods base their global clustering
step on a local pairwise model, some global infor-
mation which could have guided step 2 is already
lost. The twin-candidate model (Yang et al., 2008)
replaces the pairwise model by learning prefer-
ences between two antecedent candidates in step
1 and applies tournament schemes instead of the
clustering in step 2.

There is little work which deviates from this
two-step scheme. Culotta et al. (2007) introduce a
ﬁrst-order probabilistic model which implements
features over sets of mentions and thus operates
directly on entities.

In this paper we describe a novel approach to
coreference resolution which avoids the division
into two steps and instead performs a global deci-
sion in one step. We represent a document as a hy-
pergraph, where the vertices denote mentions and
the edges denote relational features between men-
tions. Coreference resolution is performed glob-
ally in one step by partitioning the hypergraph into
subhypergraphs so that all mentions in one subhy-
pergraph refer to the same entity. Our model out-

144

performs two strong baselines, Soon et al. (2001)
and Bengtson & Roth (2008).

Soon et al.

(2001) developed an end-to-end
coreference resolution system for the MUC data,
i.e., a system which processes raw documents
as input and produces annotated ones as output.
However, with the advent of the ACE data, many
systems either evaluated only true mentions, i.e.
mentions which are included in the annotation,
the so-called key, or even received true informa-
tion for mention boundaries, heads of mentions
and mention type (Culotta et al., 2007, inter alia).
While these papers report impressive results it has
been concluded that this experimental setup sim-
pliﬁes the task and leads to an unrealistic surro-
gate for the coreference resolution problem (Stoy-
anov et al., 2009, p.657, p660). We argue that
the ﬁeld should move towards a realistic setting
using system mentions, i.e. automatically deter-
mined mention boundaries and types. In this pa-
per we report results using our end-to-end coref-
erence resolution system, COPA, without relying
on unrealistic assumptions.

2 Related Work

Soon et al. (2001) transform the coreference res-
olution problem straightforwardly into a pairwise
classiﬁcation task making it accessible to standard
machine learning classiﬁers. They use a set of
twelve powerful features. Their system is based
solely on information of the mention pair anaphor
and antecedent. It does not take any information
of other mentions into account. However, it turned
out that it is difﬁcult to improve upon their re-
sults just by applying a more sophisticated learn-
ing method and without improving the features.
We use a reimplementation of their system as ﬁrst
baseline. Bengtson & Roth (2008) push this ap-
proach to the limit by devising a much more in-
formative feature set. They report the best results
to date on the ACE 2004 data using true mentions.
We use their system combined with our prepro-
cessing components as second baseline.

Luo et al.

(2004) perform the clustering step
within a Bell tree representation. Hence their
system theoretically has access to all possible
outcomes making it a potentially global system.
However, the classiﬁcation step is still based on

a pairwise model. Also since the search space in
the Bell tree is too large they have to apply search
heuristics. Hence, their approach loses much of
the power of a truly global approach.

Culotta et al.

(2007) introduce a ﬁrst-order
probabilistic model which implements features
over sets of mentions. They use four features for
their ﬁrst-order model. The ﬁrst is an enumeration
over pairs of noun phrases. The second is the out-
put of a pairwise model. The third is the cluster
size. The fourth counts mention type, number and
gender in each cluster. Still, their model is based
mostly on information about pairs of mentions.
They assume true mentions as input. It is not clear
whether the improvement in results translates to
system mentions.

Nicolae & Nicolae (2006) describe a graph-
based approach which superﬁcially resembles our
approach. However, they still implement a two
step coreference resolution approach and apply
the global graph-based model only to step 2. They
report considerable improvements over state-of-
the-art systems including Luo et al. (2004). How-
ever, since they not only change the clustering
strategy but also the features for step 1, it is not
clear whether the improvements are due to the
graph-based clustering technique. We, instead,
describe a graph-based approach which performs
classiﬁcation and clustering in one step. We com-
pare our approach with two competitive systems
using the same feature sets.

3 COPA: Coreference Partitioner

The COPA system consists of learning modules
which learn hyperedge weights from the training
data, and resolution modules which create a hy-
pergraph representation for the testing data and
perform partitioning to produce subhypergraphs,
each of which represents an entity. An example
analysis of a short document involving the two en-
tities, BARACK OBAMA and NICOLAS SARKOZY
illustrates how COPA works.

[US President Barack Obama] came to Toronto today.
[Obama] discussed the ﬁnancial crisis with [President
Sarkozy].
[He] talked to him [him] about the recent downturn of the
European markets.
[Barack Obama] will leave Toronto tomorrow.

145

A hypergraph (Figure (1a)) is built for this
document based on three features. Two hyper-
edges denote the feature partial string match,
{US President Barack Obama, Barack Obama,
Obama} and {US President Barack Obama, Pres-
ident Sarkozy}. One hyperedge denotes the fea-
ture pronoun match, {he, him}. Two hyperedges
denote the feature all speak, {Obama, he} and
{President Sarkozy, him}.
On this initial representation, a spectral clus-
tering technique is applied to ﬁnd two partitions
which have the strongest within-cluster connec-
tions and the weakest between-clusters relations.
The cut found is called Normalized Cut, which
avoids trivial partitions frequently output by the
min-cut algorithm. The two output subhyper-
graphs (Figure (1b)) correspond to two resolved
entities shown on both sides of the bold dashed
line.
In real cases, recursive cutting is applied
to all the subhypergraphs resulting from previous
steps, until a stopping criterion is reached.

weights which are calculated based on the train-
ing data as the percentage of the initial edges (as
illustrated in Figure (1a)) being in fact coreferent.
The weights for some of Soon et al. (2001)’s fea-
tures learned from the ACE 2004 training data are
given in Table 1.

Edge Name
Alias
StrMatch Pron
Appositive
StrMatch Npron
ContinuousDistAgree

Weight
0.777
0.702
0.568
0.657
0.403

Table 1: Hyperedge weights for ACE 2004 data

3.2 Coreference Resolution Modules
Unlike pairwise models, COPA processes a docu-
ment globally in one step, taking care of the pref-
erence information among all the mentions at the
same time and clustering them into sets directly.
A raw document is represented as a single hyper-
graph with multiple edges. The hypergraph re-
solver partitions the simple hypergraph into sev-
eral subhypergraphs, each corresponding to one
set of coreferent mentions (see e.g. Figure (1b)
which contains two subhypergraphs).

3.2.1 HGModelBuilder

A single document is represented in a hyper-
graph with basic relational features. Each hyper-
edge in a graph corresponds to an instance of one
of those features with the weight assigned by the
HyperEdgeLearner. Instead of connecting nodes
with the target relation as usually done in graph
models, COPA builds the graph directly out of a
set of low dimensional features without any as-
sumptions for a distance metric.

Figure 1: Hypergraph-based representation

3.2.2 HGResolver

3.1 HyperEdgeLearner
COPA needs training data only for computing the
hyperedge weights. Hyperedges represent fea-
tures. Each hyperedge corresponds to a feature
instance modeling a simple relation between two
or more mentions. This leads to initially overlap-
ping sets of mentions. Hyperedges are assigned

In order to partition the hypergraph we adopt
a spectral clustering algorithm. Spectral cluster-
ing techniques use information obtained from the
eigenvalues and eigenvectors of the graph Lapla-
cian to cluster the vertices. They are simple to im-
plement and reasonably fast and have been shown
to frequently outperform traditional clustering al-
gorithms such as k-means. These techniques have

146

Algorithm 1 R2 partitioner
Note: { L = I − Dv− 1
2 HW De−1H T Dv− 1
Note: { N cut(S) := vol∂S( 1
volSc )}
input: target hypergraph HG, predeﬁned α⋆
Given a HG, construct its Dv, H, W and De
Compute L for HG
Solve the L for the second smallest eigenvector V2
for each splitting point in V2 do

volS + 1

2 }

calculate N cuti

end for
Choose the splitting point with min
Generate two subHGs
if min

(N cuti) < α∗ then

i

i
for each subHG do

(N cuti)

Bi-partition the subHG with the R2 partitioner

end for

else

Output the current subHG

end if
output: partitioned HG

many applications, e.g. image segmentation (Shi
& Malik, 2000).

We adopt two variants of spectral clustering,
recursive 2-way partitioning (R2 partitioner) and
ﬂat-K partitioning. Since ﬂat-K partitioning did
not perform as well we focus here on recursive 2-
way partitioning. In contrast to ﬂat-K partitioning,
this method does not need any information about
the number of target sets. Instead a stopping cri-
terion α⋆ has to be provided. α⋆ is adjusted on
development data (see Algorithm 1).

In order to apply spectral clustering to hyper-
graphs we follow Agarwal et al. (2005). All ex-
perimental results are obtained using symmetric
Laplacians (Lsym) (von Luxburg, 2007).

Given a hypergraph HG, a set of matrices is
generated. Dv and De denote the diagonal matri-
ces containing the vertex and hyperedge degrees
|V | × |E| matrix H represents the
respectively.
HG with the entries h(v, e) = 1 if v ∈ e and 0
otherwise. H T is the transpose of H. W is the
diagonal matrix with the edge weights. S is one
of the subhypergraphs generated from a cut in the
HG, where N cut(S) is the cut’s value.

Using Normalized Cut does not generate sin-
gleton clusters, hence a heuristic singleton detec-
tion strategy is used in COPA. We apply a thresh-
old β to each node in the graph. If a node’s degree
is below the threshold, the node will be removed.

3.3 Complexity of HGResolver

Since edge weights are assigned using simple de-
scriptive statistics, the time HGResolver needs for
building the graph Laplacian matrix is insubstan-
tial. For eigensolving, we use an open source li-
brary provided by the Colt project1which imple-
ments a Householder-QL algorithm to solve the
eigenvalue decomposition. When applied to the
symmetric graph Laplacian, the complexity of the
eigensolving is given by O(n3), where n is the
number of mentions in a hypergraph. Since there
are only a few hundred mentions per document in
our data, this complexity is not an issue (spectral
clustering gets problematic when applied to mil-
lions of data points).

4 Features

The HGModelBuilder allows hyperedges with a
degree higher than two to grow throughout the
building process. This type of edge is mergeable.
Edges with a degree of two describe pairwise rela-
tions. Thus these edges are non-mergeable. This
way any kind of relational features can be incor-
porated into the hypergraph model.

Features are represented as types of hyperedges
(in Figure (1b) the two hyperedges marked by “–
··” are of the same type). Any realized edge is an
instance of the corresponding edge type. All in-
stances derived from the same type have the same
weight, but they may get reweighted by the dis-
tance feature (Section 4.4).

In the following Subsections we describe the
features used in our experiments. We use the en-
tire set for obtaining the ﬁnal results. We restrict
ourselves to Soon et al. (2001)’s features when we
compare our system with theirs in order to assess
the impact of our model regardless of features (we
use features 1., 2., 3., 6., 7., 11., 13.).

4.1 Hyperedges With a Degree > 2

High degree edges are the particular property of
the hypergraph which allows to include all types
of relational features into our model. The edges
are built through pairwise relations and, if consis-
tent, get incrementally merged into larger edges.

1http://acs.lbl.gov/˜hoschek/colt/

147

High degree edges are not sensitive to positional
information from the documents.

(1) StrMatch Npron & (2) StrMatch Pron:
After discarding stop words, if the strings of men-
tions completely match and are not pronouns, they
are put into edges of the StrMatch Npron type.
When the matched mentions are pronouns, they
are put into the StrMatch Pron type edges.

(3) Alias: After discarding stop words, if men-
tions are aliases of each other (i.e. proper names
with partial match, full names and acronyms of
organizations, etc.), they are put into edges of the
Alias type.

(4) Synonym: If, according to WordNet, men-
tions are synonymous, they are put into an edge of
the Synonym type.

(5) AllSpeak: Mentions which appear within a
window of two words of a verb meaning to say
form an edge of the AllSpeak type.

(6) Agreement: If mentions agree in Gender,
Number and Semantic Class they are put in edges
of the Agreement type. Because Gender, Num-
ber and Semantic Class are strong negative coref-
erence indicators – in contrast to e.g. StrMatch –
and hence weak positive features, they are com-
bined into the one feature Agreement.

4.2 Hyperedges With a Degree = 2

Features which have been used by pairwise mod-
els are easily integrated into the hypergraph model
by generating edges with only two vertices. Infor-
mation sensitive to relative distance is represented
by pairwise edges.

(7) Apposition & (8) RelativePronoun: If two
mentions are in a appositive structure, they are put
in an edge of type Apposition. If the latter mention
is a relative pronoun, the mentions are put in an
edge of type RelativePronoun.

(9) HeadModMatch: If the syntactic heads of
two mentions match, and if their modiﬁers do not
contradict each other, the mentions are put in an
edge of type HeadModMatch.

(10) SubString: If a mention is the substring
of another one, they are put into an edge of type
SubString.

4.3 MentionType and EntityType
In our model (11) mention type can only reason-
ably be used when it is conjoined with other fea-
tures, since mention type itself describes an at-
tribute of single mentions.
In COPA, it is con-
joined with other features to form hyperedges, e.g.
the StrMatch Pron edge. We use the same strat-
egy to represent (12) entity type.

4.4 Distance Weights

Our hypergraph model does not have any obvi-
ous means to encode distance information. How-
ever, the distance between two mentions plays
an important role in coreference resolution, es-
pecially for resolving pronouns. We do not en-
code distance as feature, because this would intro-
duce many two-degree-hyperedges which would
be computationally very expensive without much
gain in performance. Instead, we use distance to
reweight two-degree-hyperedges, which are sen-
sitive to positional information.

We experimented with two types of distance
weights: One is (13) sentence distance as used in
Soon et al. (2001)’s feature set, while the other is
(14) compatible mentions distance as introduced
by Bengtson & Roth (2008).

5 Experiments

We compare COPA’s performance with two im-
plementations of pairwise models. The ﬁrst base-
line is the BART (Versley et al., 2008) reimple-
mentation of Soon et al. (2001), with few but ef-
fective features. Our second baseline is Bengtson
& Roth (2008), which exploits a much larger fea-
ture set while keeping the machine learning ap-
proach simple. Bengtson & Roth (2008) show
that their system outperforms much more sophis-
ticated machine learning approaches such as Cu-
lotta et al. (2007), who reported the best results
on true mentions before Bengtson & Roth (2008).
Hence, Bengtson & Roth (2008) seems to be a rea-
sonable competitor for evaluating COPA.

In order to report realistic results, we neither
assume true mentions as input nor do we evalu-
ate only on true mentions. Instead, we use an in-
house mention tagger for automatically extracting
mentions.

148

5.1 Data
We use the MUC6 data (Chinchor & Sund-
heim, 2003) with standard training/testing divi-
sions (30/30) as well as the MUC7 data (Chin-
chor, 2001) (30/20). Since we do not have ac-
cess to the ofﬁcial ACE testing data (only avail-
able to ACE participants), we follow Bengtson &
Roth (2008) for dividing the ACE 2004 English
training data (Mitchell et al., 2004) into training,
development and testing partitions (268/76/107).
We randomly split the 252 ACE 2003 training
documents (Mitchell et al., 2003) using the same
proportions into training, development and testing
(151/38/63). The systems were tuned on develop-
ment and run only once on testing data.

5.2 Mention Tagger
We implement a classiﬁcation-based mention tag-
ger, which tags each NP chunk as ACE mention or
not, with neccessary post-processing for embed-
ded mentions. For the ACE 2004 testing data, we
cover 75.8% of the heads with 73.5% accuracy.

5.3 Evaluation Metrics
We evaluate COPA with three coreference resolu-
tion evaluation metrics: the B3-algorithm (Bagga
& Baldwin, 1998),
the CEAF-algorithm (Luo,
2005), and, for the sake of completeness,
the
MUC-score (Vilain et al., 1995).

Since the MUC-score does not evaluate single-
ton entities, it only partially evaluates the perfor-
mance for ACE data, which includes singleton
entities in the keys. The B3-algorithm (Bagga
& Baldwin, 1998) addresses this problem of the
MUC-score by conducting calculations based on
mentions instead of coreference relations. How-
ever, another problematic issue emerges when
system mentions have to be dealt with: B3 as-
sumes the mentions in the key and in the response
to be identical, which is unlikely when a men-
tion tagger is used to create system mentions.
The CEAF-algorithm aligns entities in key and
response by means of a similarity metric, which
is motivated by B3’s shortcoming of using one
entity multiple times (Luo, 2005). However, al-
though CEAF theoretically does not require to
have the same number of mentions in key and
response, the algorithm still cannot be directly

applied to end-to-end coreference resolution sys-
tems, because the similarity metric is inﬂuenced
by the number of mentions in key and response.

0. B3

all and B3

Hence, both the B3- and CEAF-algorithms
have to be extended to deal with system mentions
which are not in the key and true mentions not
extracted by the system, so called twinless men-
tions (Stoyanov et al., 2009). Two variants of
the B3-algorithm are proposed by Stoyanov et al.
(2009), B3
all tries to assign intu-
itive precision and recall to the twinless system
mentions and twinless key mentions, while keep-
ing the size of the system mention set and the key
mention set unchanged (which are different from
each other). For twinless mentions, B3
all discards
twinless key mentions for precision and twinless
system mentions for recall. Discarding parts of
the key mentions, however, makes the fair com-
parison of precision values difﬁcult. B3
0 produces
counter-intuitive precision by discarding all twin-
less system mentions. Although it penalizes the
recall of all twinless key mentions, so that the F-
scores are balanced, it is still too lenient (for fur-
ther analyses see Cai & Strube (2010)).

We devise two variants of the B3- and CEAF-
algorithms, namely B3
sys and CEAFsys. For com-
puting precision, the algorithms put all twinless
true mentions into the response even if they were
not extracted. All twinless system mentions which
were deemed not coreferent are discarded. Only
twinless system mentions which were mistakenly
resolved are put into the key. Hence, the system
is penalized for resolving mentions not found in
the key. For recall the algorithms only consider
mentions from the original key by discarding all
the twinless system mentions and putting twin-
less true mentions into the response as singletons
(algorithm details, simulations and comparison of
different systems and metrics are provided in Cai
& Strube (2010)). For CEAFsys, φ3 (Luo, 2005)
is used. B3
sys and CEAFsys report results for end-
to-end coreference resolution systems adequately.

5.4 Baselines

We compare COPA’s performance with two base-
lines: SOON – the BART (Versley et al., 2008)
reimplementation of Soon et al. (2001) – and

149

MUC

B3

sys

MUC6
MUC7
ACE 2003
ACE 2004
MUC6
MUC7
ACE 2003
ACE 2004

CEAFsys MUC6
MUC7
ACE 2003
ACE 2004

SOON

P

67.9
67.1
75.8
67.4
78.9
80.0
87.7
85.7
53.0
54.3
68.7
65.2

R
59.4
52.3
56.7
50.4
53.1
49.8
66.9
64.7
56.9
57.3
71.0
67.9

F

63.4
58.8
64.9
57.7
63.5
61.4
75.9
73.8
54.9
55.7
69.8
66.5

COPA with R2 partitioner

R
62.8
55.2
60.8
54.1
56.4
53.3
71.5
67.3
62.2
58.3
71.1
68.5

P

F

66.4
66.1
75.1
67.3
76.3
76.1
83.3
83.4
57.5
54.2
68.3
65.5

64.5
60.1
67.2
60.0
64.1
62.7
77.0
74.5
59.8
56.2
69.7
67.0

α⋆
0.08
0.05
0.07
0.05
0.08
0.05
0.07
0.07
0.08
0.06
0.07
0.07

β

0.03
0.01
0.03
0.04
0.03
0.01
0.03
0.03
0.03
0.01
0.03
0.03

Table 3: SOON vs. COPA R2 (SOON features, system mentions, bold indicates signiﬁcant improvement
in F-score over SOON according to a paired-t test with p < 0.05)

SOON

P

F

85.7

73.8

R
64.7

B&R
P

85.8

R
66.3

F

74.8

B3

sys

Table 2: Baselines on ACE 2004

B&R – Bengtson & Roth (2008)2. All systems
share BART’s preprocessing components and our
in-house ACE mention tagger.

In Table 2 we report the performance of SOON
and B&R on the ACE 2004 testing data using
the BART preprocessing components and our in-
house ACE mention tagger. For evaluation we use
B3
sys only, since Bengtson & Roth (2008)’s sys-
tem does not allow to easily integrate CEAF.

B&R considerably outperforms SOON (we can-
not compute statistical signiﬁcance, because we
do not have access to results for single documents
in B&R). The difference, however, is not as big
as we expected. Bengtson & Roth (2008) re-
ported very good results when using true men-
tions. For evaluating on system mentions, how-
ever, they were using a too lenient variant of B3
(Stoyanov et al., 2009) which discards all twinless
mentions. When replacing this with B3
sys the dif-
ference between SOON and B&R shrinks.

5.5 Results

In both comparisons, COPA uses the same fea-
tures as the corresponding baseline system.

2http://l2r.cs.uiuc.edu/˜cogcomp/

asoftware.php?skey=FLBJCOREF

5.5.1 COPA vs. SOON
In Table 3 we compare the SOON-baseline with
COPA using the R2 partitioner (parameters α⋆ and
β optimized on development data). Even though
COPA and SOON use the same features, COPA
consistently outperforms SOON on all data sets
using all evaluation metrics. With the exception of
the MUC7, the ACE 2003 and the ACE 2004 data
evaluated with CEAFsys, all of COPA’s improve-
ments are statistically signiﬁcant. When evaluated
using MUC and B3
sys, COPA with the R2 parti-
tioner boosts recall in all datasets while losing in
precision. This shows that global hypergraph par-
titioning models the coreference resolution task
more adequately than Soon et al. (2001)’s local
model – even when using the very same features.

5.5.2 COPA vs. B&R
In Table 4 we compare the B&R system (using our
preprocessing components and mention tagger),
and COPA with the R2 partitioner using B&R fea-
tures. COPA does not use the learned features
from B&R, as this would have implied to embed a
pairwise coreference resolution system in COPA.
We report results for ACE 2003 and ACE 2004.
The parameters are optimized on the ACE 2004
data. COPA with the R2 partitioner outperforms
B&R on both datasets (we cannot compute statisti-
cal signiﬁcance, because we do not have access to
results for single documents in B&R). Bengtson &
Roth (2008) developed their system on ACE 2004
data and never exposed it to ACE 2003 data. We
suspect that the relatively poor result of B&R on
ACE 2003 data is caused by overﬁtting to ACE

150

B3

sys ACE 2003
ACE 2004

B&R

P

97.3
85.8

F

71.4
74.8

R
56.4
66.3

P

COPA with R2 partitioner
R
70.3
68.4

86.5
84.4

77.5
75.6

F

Table 4: B&R vs. COPA R2 (B&R features, system mentions)

2004. Again, COPA gains in recall and loses
in precision. This shows that COPA is a highly
competetive system as it outperforms Bengtson &
Roth (2008)’s system which has been claimed to
have the best performance on the ACE 2004 data.

5.5.3 Running Time
On a machine with 2 AMD Opteron CPUs and 8
GB RAM, COPA ﬁnishes preprocessing, training
and partitioning the ACE 2004 dataset in 15 min-
utes, which is slightly faster than our duplicated
SOON baseline.

6 Discussion and Outlook

Most previous attempts to solve the coreference
resolution task globally have been hampered by
employing a local pairwise model in the classiﬁ-
cation step (step 1) while only the clustering step
realizes a global approach, e.g. Luo et al. (2004),
Nicolae & Nicolae (2006), Klenner (2007), De-
nis & Baldridge (2009), lesser so Culotta et al.
(2007). It has been also observed that improve-
ments in performance on true mentions do not
necessarily translate into performance improve-
ments on system mentions (Ng, 2008).

In this paper we describe a coreference reso-
lution system, COPA, which implements a global
decision in one step via hypergraph partitioning.
COPA looks at the whole graph at once which en-
ables it to outperform two strong baselines (Soon
et al., 2001; Bengtson & Roth, 2008). COPA’s
hypergraph-based strategy can be taken as a gen-
eral preference model, where the preference for
one mention depends on information on all other
mentions.

We follow Stoyanov et al.

(2009) and argue
that evaluating the performance of coreference
resolution systems on true mentions is unrealis-
tic. Hence we integrate an ACE mention tag-
ger into our system, tune the system towards the
real task, and evaluate only using system men-
tions. While Ng (2008) could not show that su-

perior models achieved superior results on sys-
tem mentions, COPA was able to outperform
Bengtson & Roth (2008)’s system which has been
claimed to achieve the best performance on the
ACE 2004 data (using true mentions, Bengtson &
Roth (2008) did not report any comparison with
other systems using system mentions).

An error analysis revealed that there were some
cluster-level inconsistencies in the COPA output.
Enforcing this consistency would require a global
strategy to propagate constraints, so that con-
straints can be included in the hypergraph parti-
tioning properly. We are currently exploring con-
strained clustering, a ﬁeld which has been very
active recently (Basu et al., 2009). Using con-
strained clustering methods may allow us to in-
tegrate negative information as constraints instead
of combining several weak positive features to one
which is still weak (e.g. our Agreement feature).
For an application of constrained clustering to the
related task of database record linkage, see Bhat-
tacharya & Getoor (2009).

Graph models cannot deal well with positional
information, such as distance between mentions
or the sequential ordering of mentions in a doc-
ument. We implemented distance as weights on
hyperedges which resulted in decent performance.
However, this is limited to pairwise relations and
thus does not exploit the power of the high de-
gree relations available in COPA. We expect fur-
ther improvements, once we manage to include
positional information directly.

has

Acknowledgements. This work
been
funded by the Klaus Tschira Foundation, Hei-
delberg, Germany. The ﬁrst author has been
supported by a HITS PhD. scholarship. We would
like to thank Byoung-Tak Zhang for bringing
hypergraphs to our attention and `Eva M´ujdricza-
Maydt
implementing the mention tagger.
Finally we would like to thank our colleagues in
the HITS NLP group for providing us with useful
comments.

for

151

References

Agarwal, Sameer, Jonwoo Lim, Lihi Zelnik-Manor, Pietro
Perona, David Kriegman & Serge Belongie (2005). Be-
yond pairwise clustering.
In Proceedings of the IEEE
Computer Society Conference on Computer Vision and
Pattern Recognition (CVPR’05), Vol. 2, pp. 838–845.

Bagga, Amit & Breck Baldwin (1998). Algorithms for scor-
ing coreference chains. In Proceedings of the 1st Inter-
national Conference on Language Resources and Evalu-
ation, Granada, Spain, 28–30 May 1998, pp. 563–566.

Basu, Sugato, Ian Davidson & Kiri L. Wagstaff (Eds.)
(2009). Constrained Clustering: Advances in Algorithms,
Theory, and Applications. Boca Raton, Flo.: CRC Press.
Bengtson, Eric & Dan Roth (2008). Understanding the value
of features for coreference resolution. In Proceedings of
the 2008 Conference on Empirical Methods in Natural
Language Processing, Waikiki, Honolulu, Hawaii, 25-27
October 2008, pp. 294–303.

Bhattacharya, Indrajit & Lise Getoor (2009). Collective re-
lational clustering. In S. Basu, I. Davidson & K. Wagstaff
(Eds.), Constrained Clustering: Advances in Algorithms,
Theory, and Applications, pp. 221–244. Boca Raton, Flo.:
CRC Press.

Cai, Jie & Michael Strube (2010). Evaluation metrics for
In Proceed-
end-to-end coreference resolution systems.
ings of the SIGdial 2010 Conference: The 11th Annual
Meeting of the Special Interest Group on Discourse and
Dialogue, Tokyo, Japan, 24–25 September 2010. To ap-
pear.

Chinchor, Nancy (2001). Message Understanding Confer-
ence (MUC) 7. LDC2001T02, Philadelphia, Penn: Lin-
guistic Data Consortium.

Chinchor, Nancy & Beth Sundheim (2003). Message Under-
standing Conference (MUC) 6. LDC2003T13, Philadel-
phia, Penn: Linguistic Data Consortium.

Culotta, Aron, Michael Wick & Andrew McCallum (2007).
First-order probabilistic models for coreference resolu-
tion.
In Proceedings of Human Language Technologies
2007: The Conference of the North American Chapter of
the Association for Computational Linguistics, Rochester,
N.Y., 22–27 April 2007, pp. 81–88.

Daum´e III, Hal & Daniel Marcu (2005). A large-scale ex-
ploration of effective global features for a joint entity de-
tection and tracking model. In Proceedings of the Human
Language Technology Conference and the 2005 Confer-
ence on Empirical Methods in Natural Language Process-
ing, Vancouver, B.C., Canada, 6–8 October 2005, pp. 97–
104.

Denis, Pascal & Jason Baldridge (2009). Global joint models
for coreference resolution and named entity classiﬁcation.
Procesamiento del Lenguaje Natural, 42:87–96.

Klenner, Manfred (2007). Enforcing consistency on coref-
erence sets. In Proceedings of the International Confer-
ence on Recent Advances in Natural Language Process-
ing, Borovets, Bulgaria, 27–29 September 2007, pp. 323–
328.

Luo, Xiaoqiang (2005). On coreference resolution perfor-
mance metrics. In Proceedings of the Human Language
Technology Conference and the 2005 Conference on Em-
pirical Methods in Natural Language Processing, Van-
couver, B.C., Canada, 6–8 October 2005, pp. 25–32.

Luo, Xiaoqiang, Abe Ittycheriah, Hongyan Jing, Nanda
Kambhatla & Salim Roukos (2004).
A mention-
synchronous coreference resolution algorithm based on

the Bell Tree. In Proceedings of the 42nd Annual Meet-
ing of the Association for Computational Linguistics,
Barcelona, Spain, 21–26 July 2004, pp. 136–143.

Mitchell, Alexis, Stephanie Strassel, Shudong Huang &
Ramez Zakhary (2004). ACE 2004 Multilingual Training
Corpus. LDC2005T09, Philadelphia, Penn.: Linguistic
Data Consortium.

Mitchell, Alexis, Stephanie Strassel, Mark Przybocki,
JK Davis, George Doddington, Ralph Grishman, Adam
Meyers, Ada Brunstain, Lisa Ferro & Beth Sundheim
(2003).
TIDES Extraction (ACE) 2003 Multilingual
Training Data. LDC2004T09, Philadelphia, Penn.: Lin-
guistic Data Consortium.

Ng, Vincent (2008). Unsupervised models for corefer-
ence resolution. In Proceedings of the 2008 Conference
on Empirical Methods in Natural Language Processing,
Waikiki, Honolulu, Hawaii, 25-27 October 2008, pp. 640–
649.

Ng, Vincent & Claire Cardie (2002).

Improving machine
learning approaches to coreference resolution.
In Pro-
ceedings of the 40th Annual Meeting of the Association
for Computational Linguistics, Philadelphia, Penn., 7–12
July 2002, pp. 104–111.

Nicolae, Cristina & Gabriel Nicolae (2006). BestCut: A
graph algorithm for coreference resolution. In Proceed-
ings of the 2006 Conference on Empirical Methods in Nat-
ural Language Processing, Sydney, Australia, 22–23 July
2006, pp. 275–283.

Rahman, Altaf & Vincent Ng (2009). Supervised models
for coreference resolution.
In Proceedings of the 2009
Conference on Empirical Methods in Natural Language
Processing, Singapore, 6-7 August 2009, pp. 968–977.

Shi, Jianbo & Jitendra Malik (2000). Normalized cuts and
image segmentation. IEEE Transactions on Pattern Anal-
ysis and Machine Intelligence, 22(8):888–905.

Soon, Wee Meng, Hwee Tou Ng & Daniel Chung Yong
Lim (2001). A machine learning approach to coreference
resolution of noun phrases. Computational Linguistics,
27(4):521–544.

Stoyanov, Veselin, Nathan Gilbert, Claire Cardie & Ellen
Riloff (2009). Conundrums in noun phrase coreference
resolution: Making sense of the state-of-the-art. In Pro-
ceedings of the Joint Conference of the 47th Annual Meet-
ing of the Association for Computational Linguistics and
the 4th International Joint Conference on Natural Lan-
guage Processing, Singapore, 2–7 August 2009, pp. 656–
664.

Versley, Yannick, Simone Paolo Ponzetto, Massimo Poesio,
Vladimir Eidelman, Alan Jern, Jason Smith, Xiaofeng
Yang & Alessandro Moschitti (2008). BART: A mod-
ular toolkit for coreference resolution.
In Companion
Volume to the Proceedings of the 46th Annual Meeting
of the Association for Computational Linguistics, Colum-
bus, Ohio, 15–20 June 2008, pp. 9–12.

Vilain, Marc, John Burger, John Aberdeen, Dennis Connolly
& Lynette Hirschman (1995). A model-theoretic corefer-
ence scoring scheme. In Proceedings of the 6th Message
Understanding Conference (MUC-6), pp. 45–52. San Ma-
teo, Cal.: Morgan Kaufmann.

von Luxburg, Ulrike (2007). A tutorial on spectral clustering.

Statistics and Computing, 17(4):395–416.

Yang, Xiaofeng, Jian Su & Chew Lim Tan (2008). A twin-
candidate model for learning-based anaphora resolution.
Computational Linguistics, 34(3):327–356.

