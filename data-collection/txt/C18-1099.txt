















































Adversarial Multi-lingual Neural Relation Extraction


Proceedings of the 27th International Conference on Computational Linguistics, pages 1156‚Äì1166
Santa Fe, New Mexico, USA, August 20-26, 2018.

1156

Adversarial Multi-lingual Neural Relation Extraction

Xiaozhi Wang1‚àó , Xu Han1‚àó, Yankai Lin1, Zhiyuan Liu1‚Ä†, Maosong Sun1,2
1Department of Computer Science and Technology,

State Key Lab on Intelligent Technology and Systems,
Beijing National Research Center for Information Science and Technology,

Tsinghua University, Beijing, China
2Beijing Advanced Innovation Center for Imaging Technology,

Capital Normal University, Beijing, China

Abstract

Multi-lingual relation extraction aims to find unknown relational facts from text in various lan-
guages. Existing models cannot well capture the consistency and diversity of relation patterns in
different languages. To address these issues, we propose an adversarial multi-lingual neural rela-
tion extraction (AMNRE) model, which builds both consistent and individual representations for
each sentence to consider the consistency and diversity among languages. Further, we adopt an
adversarial training strategy to ensure those consistent sentence representations could effectively
extract the language-consistent relation patterns. The experimental results on real-world datasets
demonstrate that our AMNRE model significantly outperforms the state-of-the-art models. The
source code of this paper can be obtained from https://github.com/thunlp/AMNRE.

1 Introduction

Relation extraction (RE) is a crucial task in NLP, which aims to extract semantic relations between entity
pairs from the sentences containing them. For example, given an entity pair (Bill Gates, Microsoft)
and a sentence ‚ÄúBill Gates is the co-founder and CEO of Microsoft‚Äù, we want to figure out the relation
Founder between the two entities. RE can potentially benefit many applications, such as knowledge
base construction (Zhong et al., 2015; Han et al., 2018) and question answering (Xiang et al., 2017).

Recently, neural models have shown their great abilities in RE. Zeng et al. (2014) introduce a convolu-
tional neural network (CNN) to extract relational facts with automatically learning features from text. To
address the issue of lack of data, Zeng et al. (2015) incorporate multi-instance learning with a piece-wise
convolutional neural network (PCNN) to extract relations in distantly supervised data. Because distant
supervision suffer from wrong labeling problems, Lin et al. (2016) further employ a sentence-level selec-
tive attention to filter out those noisy sentences in distantly supervised data and achieve state-of-the-art
performance. All these neural relation extraction (NRE) models merely focus on extracting relational
facts from mono-lingual data, ignoring the rich information in multi-lingual data.

Lin et al. (2017) propose a multi-lingual attention-based neural relation extraction (MNRE) model,
which considers the consistency and complementarity in multi-lingual data. MNRE builds a sentence
representation for each sentence in various languages and employs a multi-lingual attention to capture
the pattern consistency and complementarity among languages.

Although MNRE achieves great success in multi-lingual RE, it still has some problems. MNRE learns
a single representation for each sentence in various languages, which cannot well capture both the con-
sistency and diversity of relation patterns in different languages. Moreover, MNRE simply utilizes a
multi-lingual attention mechanism and a global relation predictor to capture the consistent relation pat-
terns among multiple languages. From the experimental data, we find that the sentence representations in
different languages are still far from each other and linearly separable. Therefore, it is hard for the multi-

‚àó indicates equal contribution
‚Ä† Corresponding author: Zhiyuan Liu (liuzy@tsinghua.edu.cn).

This work is licensed under a Creative Commons Attribution 4.0 International License. License details:
http://creativecommons.org/licenses/by/4.0/



1157

x1x
2

x1x
1  

 

 

      1 E
I

      1 E
I

      1 E
C

      1 E
C  

 

x
2
x2 x

1
x2 

 

 

 E
I

      2 E
C

      2 E
C

      2  E
I

      2

 
 

ùíö 1
2 

 

ùíö1
1 

 

ùíö1
2 

 

ùíö2
2 

 

ùíö2
1  

 

   

s1  ùíî   s2

Language 1 Language 2

Individual Semantic Space 

(Language1)

Individual Semantic Space 

(Language2)
Consistent Semantic Space 

Textual Relation 

Representation

Multi-lingual Attention

Sentence Embedding

Sentence Encoder

Input Embedding

D

ùíö 1
1 

 

ùíö 2
2 

 

ùíö 2
1  

 

Figure 1: Overall architecture of our adversarial multi-lingual neural relation extraction (AMNRE) which
contains two languages.

lingual attention mechanism and global relation predictor to extract relation consistency from distinct
sentence representations.

To address these issues, we propose an adversarial multi-lingual NRE (AMNRE) model. As shown
in Figure 1, for an entity pair, we encode its corresponding sentences in various languages through
neural sentence encoders. For each sentence, we build an individual representation to grasp its indi-
vidual language features and a consistent representation to encode its substantially consistent features
among languages. Further, we adopt an adversarial training strategy to ensure AMNRE can extract the
language-consistent relation patterns from the consistent representations. Orthogonality constraints are
also adopted to enhance differences between individual representations and consistent representations
for each language.

In experiments, we take Chinese and English to show the effectiveness of AMNRE. The experimen-
tal results show that AMNRE outperforms all baseline models significantly by explicitly encoding the
consistency and diversity among languages. And we further give a case study and an ablation study to
demonstrate the adversarial training strategy could help AMNRE to capture language-consistent relation
patterns.

2 Related Works

2.1 Relation Extraction

Traditional supervised RE models (Zelenko et al., 2003; Socher et al., 2012; Santos et al., 2015) heavily
rely on abundant amounts of high-quality annotated data. Hence, Mintz et al. (2009) propose a distantly
supervised model for RE. Distant supervision aligns knowledge bases (KBs) and text to automatically
annotate data, and thus distantly supervised models inevitably suffer from wrong labeling problems.

To alleviate the noise issue, Riedel et al. (2010) and Hoffmann et al. (2011) propose multi-instance
learning (MIL) mechanisms for single-label and multi-label problems respectively. Then, Zeng et al.
(2015) attempt to integrate neural models into distant supervision. Lin et al. (2016) further propose
a sentence-level attention to jointly consider all sentences containing same entity pairs for RE. The
attention-based neural relation extraction (NRE) model has become a foundation for some recent works
(Ji et al., 2017; Zeng et al., 2017; Liu et al., 2017b; Wu et al., 2017; Feng et al., 2018; Zeng et al., 2018).

Most existing RE models are devoted to extracting relations from mono-lingual data and ignore in-
formation lying in text of multiple languages. Faruqui and Kumar (2015) and Verga et al. (2016) first
attempt to adopt multi-lingual transfer learning for RE. However, both of these works learn predictive



1158

models on a new language for existing KBs, without fully leveraging semantic information in text. Then,
Lin et al. (2017) construct a multi-lingual NRE (MNRE) model to jointly represent text of multiple
languages to enhance RE. In this paper, we propose a novel multi-lingual NRE framework to explic-
itly encode language consistency and diversity into different semantic spaces, which can achieve more
effective representations for RE.

2.2 Adversarial Training

Goodfellow et al. (2015) propose adversarial training for image classification tasks. Afterwards, Good-
fellow et al. (2014) propose a mature adversarial training framework and use the framework to train
generative models. Adversarial networks have recently been used as methods to narrow probability dis-
tributions and proven effective in some tasks. In domain adaptation, Ganin et al. (2016) and Bousmalis
et al. (2016) adopt adverarial training strategies to transfer the features of one source domain to its cor-
responding target domain.

Inspired by Ganin et al. (2016), adversarial training has also been explored in some typical NLP tasks
for multi-feature fusion. Park and Im (2016) propose a multi-modal representation learning model based
on adversarial training. Then, Liu et al. (2017a) employ adversarial training to construct a multi-task
learning model for text classification by extending the original binary adversarial training to the multi-
class version. And a similar adversarial framework is also adapted by Chen et al. (2017) to learn features
from different datasets for chinese word segmentation. In this paper, we adopt adversarial training to
boost feature fusion to grasp the consistency among different languages.

3 Methodology

In this section, we introduce the overall framework of our proposed AMNRE in detail. As shown in
Figure 1, for each entity pair, AMNRE encodes its corresponding sentences in different languages into
several semantic spaces to grasp their individual language patterns. Meanwhile, a unified space is also set
up to encode consistent features among languages. By explicitly encoding the consistency and diversity
among languages, AMNRE can achieve better extraction results in the multi-lingual scenario.

For each given entity pair, we define its corresponding sentences in n different languages as T =
{S1, . . . ,Sn}, where Sj = {x1j , . . . , x

|Sj |
j } denotes the sentence set in the j-th language. All these

sentences are labeled with the relation r ‚àà R by heuristical labeling algorithms in distant supervision
(Mintz et al., 2009). Our model aims to learn a relation extractor by maximizing the conditional proba-
bility p(r|T ) with the following three components:

Sentence Encoder. Given a sentence and its target entity pair, we employ neural networks to encode
the sentence into a embedding. In this paper, we implement the sentence encoder with both convolutional
(CNN) and recurrent (RNN) architectures. Specifically, we set the encoders EIj and E

C
j to encode each

sentence in the j-th language into its individual and consistent embeddings respectively, and expect these
embeddings to capture the diversity and consistency among languages.

Multi-lingual Attention. Since not all sentences are labeled correctly in distant supervision, we
adopt multi-lingual attention mechanisms to capture those informative sentences. In practice, we ap-
ply language-individual and language-consistent attentions to compute local and global textual relation
representations respectively for final prediction.

Adversarial Training. Under the framework of AMNRE, we encode the sentences in various lan-
guages into a unified consistent semantic space. We further adopt adversarial training to ensure these
sentences are well fused in the unified space after encoding so that our model can effectively extract the
language-consistent relation patterns.

We will introduce the three components in detail as follows.

3.1 Sentence Encoder

Given a sentence x = {w1, w2, . . .} containing two entities, we apply neural architectures including both
CNN and RNN to encode the sentence into a continuous low-dimensional space to capture its implicit
semantics.



1159

3.1.1 Input Layer
The input layer transforms all input words in the sentence into corresponding input embeddings by
concatenating their word embeddings and position embeddings. The word embeddings are pre-trained
by Skip-Gram (Mikolov et al., 2013). The position embeddings are a widely-used technique in RE
proposed by Zeng et al. (2014), representing each word‚Äôs relative distances to the two entities into two
kp-dimensional vectors. The input layer represents the input sentence as a ki-dimensional embedding
sequence x = {w1,w2, . . .}, where ki = kw+kp√ó2, kw and kp are the dimensions of word embeddings
and position embeddings respectively.

3.1.2 Encoding Layer
After representing the input sentence as a ki-dimensional embedding sequence, we select both CNN
(Zeng et al., 2014) and RNN (Zhang and Wang, 2015) to encode the input embedding sequence x =
{w1,w2, . . .} to its sentence embedding.

CNN slides a convolution kernel with the window size m to extract the kh-dimensional local features,

hi = CNN
(
w
i‚àím‚àí1

2
, . . . ,w

i+m‚àí1
2

)
. (1)

A max-pooling is then adopted to obtain the final sentence embedding y as follows,

[y]j = max{[h1]j , . . . , [hn]j}. (2)

RNN is mainly designed for modeling sequential data. In this paper, we adopt bidirectional RNN
(Bi-RNN) to incorporate information from both sides of the sentence sequence as follows,

‚àí‚Üí
h i = RNNf (xi,

‚àí‚Üí
h i‚àí1),

‚Üê‚àí
h i = RNNb(xi,

‚Üê‚àí
h i+1), (3)

where
‚àí‚Üí
h i and

‚Üê‚àí
h i are the kh-dimensional hidden states at the position i of the forward and backward

RNN respectively. RNN(¬∑) is the recurrent unit and we select gated recurrent unit (GRU) (Cho et al.,
2014) as the recurrent unit in this paper. We concatenate both the forward and backward hidden states as
the sentence embedding y,

y = [
‚àí‚Üí
h n;
‚Üê‚àí
h 1]. (4)

For simplicity, we denote such a sentence encoding operation as the following equation,

y = E(x). (5)

For each sentence xij ‚àà Sj , we adopt the individual sentence encoder EIj and the consistent sentence
encoder ECj to embed the sentence into its individual and consistent representations respectively,

{y1j ,y2j , . . .} = {EIj (x1j ),EIj (x2j ), . . .}, {yÃÑ1j , yÃÑ2j , . . .} = {ECj (x1j ),ECj (x2j ), . . .}. (6)

3.2 Multi-lingual Selective Attention
For each given entity pair, AMNRE adopts multi-lingual selective attention mechanisms to exploit in-
formative sentences in T . We explicitly encode languages‚Äô consistency and diversity into individual and
consistent representations, thus our attentions are more simple than those proposed in Lin et al. (2017).

3.2.1 Language-individual Attention
Since it is intuitive that each language has its own characteristic, we set language-individual attention
mechanisms for different languages. In the individual semantic space of the j-th language, we assign a
query vector rj to each relation r ‚àà R. The attention score for each sentence in Sj = {x1j , x2j , . . .} is
defined as follows,

Œ±ij =
exp(r>j y

i
j)‚àë|Sj |

k=1 exp(r
>
j y

k
j )
. (7)

The attention scores can be used to compute language-individual textual relation representations,

sj =

|Sj |‚àë
k=1

Œ±kjy
k
j . (8)



1160

3.2.2 Language-consistent Attention
Besides language-individual attention mechanisms, we also adopt a language-consistent attention to take
all sentences in all languages into consideration. In the consistent semantic space, we also assign a query
vector rÃÑ to each relation r ‚àà R and the attention score for each sentence is defined as follows,

Œ≤ij =
exp(rÃÑ>yÃÑij)‚àën

l=1

‚àë|Sl|
k=1 exp(rÃÑ

>yÃÑkl )
. (9)

The attention scores can be used to compute language-consistent textual relation representations,

sÃÑ =

n‚àë
l=1

|Sl|‚àë
k=1

Œ≤kl yÃÑ
k
l . (10)

3.3 Relation Prediction
With the language-individual textual relation representations {s1, s2, . . .} and the language-consistent
textual relation representation sÃÑ, we can estimate the probability p(r|T ) over each relation r ‚àà R,

p(r|T ) = p(r|ÃÑs)
n‚àè
j=1

p(r|sj). (11)

p(r|ÃÑs) and p(r|sj) can be defined as follows,

p(r|sj) = softmax[Rjsj + dj ], p(r|ÃÑs) = softmax[RÃÑsÃÑ + dÃÑ], (12)

where dj and dÃÑ are bias vectors, Rj is the specific relation matrix of the j-th language, and RÃÑ is the
consistent relation matrix. We define the objective function to train the relation extractor as follows,

min
Œ∏
Lnre(Œ∏) = ‚àí

‚àë
l

log p(rl|Tl), (13)

where Œ∏ is all parameters in the framework. In the training phase, p(r|T ) is computed using the labeled
relations as the attention queries. In the test phase, we need to use each possible relation as attention
queries to compute p(r|T ) for relation prediction since the relations are unknown in advance.

3.4 Adversarial Training
In our framework, we encode sentences of various languages into a consistent semantic space to grasp
the consistency among languages. One possible situation is that sentences of different languages are
aggregated in different places of the space and linearly separable. In this case, our purpose of mining
substantially consistent relation patterns in different languages is difficult to be reached. Inspired by
Ganin et al. (2016), we adopt adversarial training into our framework to address this problem.

In the adversarial training, we define a discriminator to estimate which kind of languages the sentences
from. The probability distributions over these sentences are formalized as follows,

D(ÃÑsij) = softmax(MLP(ÃÑs
i
j)), (14)

where MLP is a two-layer multilayer perceptron network.
Contrary to the discriminator, the consistent sentence encoders are expected to produce sentence em-

beddings that cannot be reliably predicted by the discriminator. Hence, the adversarial training process
is a min-max game and can be formalized as follows,

min
Œ∏CE

max
Œ∏D

n‚àë
j=1

|Sj |‚àë
i=1

log[D(ECj (x
i
j))]j , (15)

where [¬∑]j is the j-th value of the vector.
The formula means that given a sentence of any language, the corresponding sentence encoder of its

language generates the sentence embedding to confuse the discriminator. Meanwhile, the discriminator



1161

tries its best to predict the language of the sentence according to the sentence embedding. After sufficient
training, the encoders and the discriminator reach a balance, and sentences of different languages con-
taining similar semantic information can be well encoded into adjacent places of the space. In training,
we optimize the following loss functions instead of Eq. 15,

min
Œ∏CE

LEadv(Œ∏CE ) =
‚àë
l

‚àë
Sj‚ààTl

‚àë
xij‚ààSj

log[D(ECj (x
i
j))]j , min

Œ∏D
LDadv(Œ∏D) = ‚àí

‚àë
l

‚àë
Sj‚ààTl

‚àë
xij‚ààSj

log[D(ECj (x
i
j))]j , (16)

where Œ∏CE and Œ∏D are all parameters of the consistent sentence encoders and the discriminator.
We notice that language-individual semantics could be wrongly encoded into the consistent semantic

space, and may have negative effects on extracting language-consistent features. Inspired by Bousmalis
et al. (2016), we adopt orthogonality constraints to alleviate this issue. We minimize the following
penalty function:

min
Œ∏E
Lpenalty(Œ∏E) =

n‚àë
j=1

‚à•‚à•‚à•ITj Cj‚à•‚à•‚à•
F
, (17)

where Ij and Cj are two matrices whose row vectors are the embeddings of sentences in the j-th language
encoded by EIj and E

C
j respectively. Œ∏E is parameters of the all encoders. And ‚Äñ¬∑‚ÄñF is the squared

Frobenius norm.

3.5 Implementation Details

During training process, we combine the extraction and adversarial objective functions as follows,

L = Lnre(Œ∏) + Œª1LDadv(Œ∏D) + Œª2L
E
adv(Œ∏

C
E ) + Œª3Lpenalty(Œ∏E), (18)

where Œª1, Œª2, and Œª3 are harmonic factors. All models are optimized using stochastic gradient descent
(SGD). In practice, we integrate Œª1 and Œª2 into the alternating ratio among the loss functions, and we
calibrate a 1:1:5 ratio among Lnre(Œ∏) + Œª3Lpenalty(Œ∏E), LDadv(Œ∏D) and LEadv(Œ∏CE ). Œª3 is set as 0.02.

4 Experiments

4.1 Datasets and Evaluation

We evaluate our models on a multi-lingual relation extraction dataset developed by Lin et al. (2017).
The dataset consists of English and Chinese data, and has 176 relations including a special relation NA
indicating that there is no relation between entities. The whole dataset is divided into three parts for
training, validation and test. The statistics of the dataset are listed in Table 1.

Dataset #Rel #Sent #Fact Dataset #Rel #Sent #Fact

English
Training 176 1,022,239 47,638

Chinese
Training 176 940,595 42,536

Validation 176 80,191 2,192 Validation 176 82,699 2,192
Test 176 162,018 4,326 Test 176 167,224 4,326

Table 1: Statistics of the dataset

We evaluate all models by the held-out evaluation following previous works (Mintz et al., 2009; Lin et
al., 2017). In experiments, we report precision-recall curves of recall under 0.3 since we focus more on
the performance of those top-ranked results. To give a complete view of the performance, we also report
the area under the curve (AUC).

4.2 Experiment Settings

Following the settings of previous works, we use the pre-trained word embeddings learned by Skip-Gram
as the initial word embeddings. We implement the MNRE framework proposed by Lin et al. (2017) by
ourselves. For fair comparision, we set most of the hyperparameters following Lin et al. (2017). We list
the best setting of hyperparameters in Table 2.



1162

Batch Size B 160 Convolution Kernel Size m 3
Learning Rate Œ± 0.002 Dropout Probability p for CNN and RNN 0.5
Hidden Layer Dimension kh for CNN 230 Dropout Probability pd for the Discriminator 0.1
Hidden Layer Dimension kh for RNN 200 Word Dimension kw 50
Hidden Layer Dimension kd for the Discriminator 2048 Position Dimension kp 5

Table 2: Parameter settings.

0.00 0.05 0.10 0.15 0.20 0.25 0.30
Recall

0.5

0.6

0.7

0.8

0.9

1.0

Pr
ec

isi
on

AMNRE-CNN
MNRE-CNN
CNN-Joint
CNN-Share
CNN-CN
CNN-EN

0.00 0.05 0.10 0.15 0.20 0.25 0.30
Recall

0.5

0.6

0.7

0.8

0.9

1.0

Pr
ec

isi
on

AMNRE-RNN
MNRE-RNN
RNN-Joint
RNN-Share
RNN-CN
RNN-EN

Figure 2: The aggregated precision-recall curves for proposed models and various baseline models. Left:
models with CNN as sentence encoders. Right: models with RNN as sentence encoders.

4.3 Overall Evaluation Results

To evaluate the effectiveness of our proposed models AMNRE-CNN and AMNRE-RNN, we compare
the proposed models with various neural methods: MNRE-CNN and MNRE-RNN are multi-lingual
attention-based NRE models with CNN and RNN sentence encoders respectively (Lin et al., 2017);
CNN-EN and RNN-EN are vanilla selective-attention NRE models trained with English data, which are
the state-of-the-art models in mono-lingual RE (Lin et al., 2016); CNN-CN and RNN-CN are trained
with Chinese data; CNN-Joint and RNN-Joint are naive joint models which predict relations by directly
summing up ranking scores of both English and Chinese; CNN-Share and RNN-Share are another naive
joint models which train English and Chinese models with shared relation embeddings. The results of
precision-recall curves are shown in Figure 2 and the results of AUC are shown in Table 3.

From the results, we have the following observations:
(1) Both for CNN and RNN, the models jointly utilizing English and Chinese sentences outperform the

models only using mono-lingual sentences. This demonstrates that the rich information in multi-lingual
data is useful and can significantly enhance existing NRE models.

(2) The -Joint models achieve similar performance with the -Share models, and both of them under-
perform the MNRE and AMNRE models. They all benefit from the multi-lingual information, but the
models with multi-lingual attentions can better take advantage of multi-lingual data. It indicates that
designing targeted schemes to extract rich multi-lingual information is crucial.

(3) AMNRE achieves the best results among all the baseline models over the entire range of recall in
Figure 2, even as compared with MNRE. AMNRE also outperforms MNRE with 3 percentage points
increasing in the AUC results. It indicates our proposed framework which explicitly encodes language-
consistent and language-individual semantics better extract multi-lingual information, and therefore lead
to the significant improvement in RE performance.

Models CNN-EN CNN-CN CNN-Joint CNN-Share MNRE-CNN AMNRE-CNN
AUC 36.6 33.2 37.1 37.0 43.4 46.2
Models RNN-EN RNN-CN RNN-Joint RNN-Share MNRE-RNN AMNRE-RNN
AUC 34.5 34.4 36.5 37.6 44.2 47.3

Table 3: The AUC results of different models (%).



1163

0.00 0.05 0.10 0.15 0.20 0.25 0.30
Recall

0.5

0.6

0.7

0.8

0.9

1.0

Pr
ec
isi
on

AMNRE-CNN-EN
MNRE-CNN-EN
CNN-EN
AMNRE-CNN-CN
MNRE-CNN-CN
CNN-CN

0.00 0.05 0.10 0.15 0.20 0.25 0.30
Recall

0.5

0.6

0.7

0.8

0.9

1.0

Pr
ec
isi
on

AMNRE-RNN-EN
MNRE-RNN-EN
RNN-EN
AMNRE-RNN-CN
MNRE-RNN-CN
RNN-CN

Figure 3: The aggregated precision-recall curves for proposed models and various baseline models in
the mono-lingual scenario. Left: models with CNN as sentence encoders. Right: models with RNN as
sentence encoders.

Models CNN-EN MNRE-EN AMNRE-EN RNN-EN MNRE-EN AMNRE-EN
AUC 36.6 39.6 42.7 34.5 42.2 43.2
Models CNN-CN MNRE-CN AMNRE-CN RNN-CN MNRE-CN AMNRE-CN
AUC 33.2 34.6 37.9 33.5 34.8 36.4

Table 4: The AUC results of different models in the mono-lingual scenario (%).

4.4 Mono-lingual Evaluation Results
To further verify that every mono-lingual RE models can benefit from our proposed framework, which
explicitly consider language-consistent relation patterns, we train models with multi-lingual data and
evaluate the performance of these models in the mono-lingual RE scenario. To show the results clearly,
we report the precision-recall curves in Figure 3 and the AUC results in Table 4.

From the results, we can observe that:
(1) As compared with the models directly learned with the mono-lingual data, the models exploiting

the multi-lingual information perform better in the mono-lingual scenario. This demonstrates that there
is latent consistency among languages, and grasping this consistency from multi-lingual data can provide
additional information for models in each language to enhance their results in the mono-lingual scenario.

(2) Our proposed models achieve the best precision over the entire range of recall and also significantly
improve the AUC results as compared with both MNRE and mono-lingual RE models. It indicates that
due to the consistent semantic space in our framework, language-consistent information lying in the
multi-lingual data is better mined and serve the mono-lingual scenario.

4.5 Effectiveness of Adversarial Training and Orthogonality Constraints
We adopt an adversarial training strategy to fuse the features from different languages to extract consis-
tent relation patterns. Orthogonality constraints are also adopted to separate the consistent and individual
feature spaces. To measure the effectiveness of them, we conduct an ablation study which compares the
proposed models with the similar models but without adversarial training strategy (AMNRE-noA), with-
out orthogonality constraints (AMNRE-noO), and without both of them (AMNRE-noBoth). The AUC
results are shown in Table 5.

We can observe that both the adversarial training strategy and orthogonality constraints have sig-
nificant influence on the performance of our proposed model. This demonstrates the effectiveness of
adversarial training strategy and orthogonality constraints for multi-lingual RE. To give a more intuitive
picture of the effect of these two mechanisms, we visualize the distribution of sentence feature embed-
dings encoded by the individual and consistent encoders using t-SNE (Maaten and Hinton, 2008). The
results are shown in Figure 4.

Figure 4(a) shows that there are obvious differences between the feature embeddings encoded from
the same sentences by individual and consistent encoders. It indicates the orthogonality constraints are
effective to separate the individual and consistent latent spaces. From the comparison between Figure



1164

(a) The same English sentences en-
coded by the consistent encoder (yel-
low) and individual encoder (blue).

(b) The English sentences (yellow) and
the Chinese sentences (blue) encoded
by their own consistent encoders with-
out adversarial training.

(c) The English sentences (yellow) and
the Chinese sentences (blue) encoded
by their own consistent encoders with
adversarial training.

Figure 4: The visualization of sentence feature embeddings with different mechanisms.

Models AMNRE-CNN AMNRE-CNN-noA AMNRE-CNN-noO AMNRE-CNN-noBoth
AUC 46.2 44.1 43.9 41.3
Models AMNRE-RNN AMNRE-RNN-noA AMNRE-RNN-noO AMNRE-RNN-noBoth
AUC 47.3 43.5 43.5 42.2

Table 5: The AUC results of the proposed models and ablated models.(%)

4(b) and Figure 4(c), we can observe that the feature embeddings from different languages are well-
mixed due to the adversarial training strategy. We can more easily to grasp latent consistency among
languages after multi-feature fusion.

5 Case Study

To further show the effectiveness of our proposed model to extract the language-consistent semantic
information, we give an example in Table 6. We adopt the cosine similarity to measure the similarity
between sentence embeddings encoded by consistent encoders. The first sentence in the middle column is
the standard Chinese translation of the left sentence, thus they share the same semantic information. We
observe that in our proposed model, the feature embedding similarity between these two sentences are
significantly higher than the other English sentences sharing entity pair and relational fact but differing in
semantics. It indicates that sentences in different languages containing similar semantics can be indeed
encoded into adjacent places of the consistent space in our framework.

Relation : Located in Cosine Similarity
There are eighteen small

glaciers in the North Island
on Mount Ruapehu.

ÂåóÂåóÂåóÂ≤õÂ≤õÂ≤õÁöÑÈ≤ÅÈ≤ÅÈ≤ÅÈòøÈòøÈòø‰Ω©‰Ω©‰Ω©ËÉ°ËÉ°ËÉ°Â±±Â±±Â±±‰∏äÊúâÂçÅÂÖ´‰∏™Â∞èÂÜ∞Â∑ù„ÄÇ 0.584
. . . the bottom of the North Island of

New Zealand up to the area of Mount Ruapehu. 0.3538

It is located on the south-eastern North Island
volcanic plateau, . . . south-east of Mount Ruapehu. 0.342

Table 6: The example highlighting entities for the case study by measuring the cosine similarities be-
tween the sentence in the left column and each sentence in the middle column.

6 Conclusion and Future Work

In this paper, we introduce a novel adversarial multi-lingual neural relation extraction model (AMNRE).
AMNRE builds both individual and consistent representations for each sentence to consider the con-
sistency and diversity of relation patterns among languages. It also employs an adversarial training
strategy and orthogonality constraints to ensure the consistent representations could extract the language-
consistent features to extract relations. The experimental results on real-world datasets demonstrate that



1165

our AMNRE could effectively encode the consistency and diversity among languages, and achieves
state-of-the-art performance in relation extraction.

We will explore the following directions as our future work: (1) AMNRE can be also implemented
in the scenario of multiple languages, and this paper shows the effectiveness of AMNRE on the dataset
with two languages (English and Chinese). In the future, we will explore AMNRE in much more other
languages such as French, Spanish, and so on. (2) AMNRE simply aligns the sentences with similar
semantics in different languages with an adversarial training strategy. In fact, machine translation is
a typical approach to align sentences in various languages. In the future, we will combine machine
translation with our model to further improve the extraction performance.

Acknowledgments

We thank Jiacheng Zhang for his help. This work is supported by the National Natural Science Foun-
dation of China (NSFC No. 61621136008, 61772302) and Tsinghua University Initiative Scientific Re-
search Program (20151080406). This research is part of the NExT++ project, supported by the National
Research Foundation, Prime Minister‚Äôs Office, Singapore under its IRC@Singapore Funding Initiative.

References
Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and Dumitru Erhan. 2016. Do-

main separation networks. In Proceedings of NIPS, pages 343‚Äì351.

Xinchi Chen, Zhan Shi, Xipeng Qiu, and Xuanjing Huang. 2017. Adversarial multi-criteria learning for chinese
word segmentation. In Proceedings of ACL, pages 1193‚Äì1203.

Kyunghyun Cho, Bart Van MerrieÃànboer, Dzmitry Bahdanau, and Yoshua Bengio. 2014. On the properties of
neural machine translation: encoder-decoder approaches. In Proceedings of SSST-8.

Manaal Faruqui and Shankar Kumar. 2015. Multilingual open relation extraction using cross-lingual projection.
In Proceedings of NAACL, pages 1351‚Äì1356.

Jun Feng, Minlie Huang, Li Zhao, Yang Yang, and Xiaoyan Zhu. 2018. Reinforcement learning for relation
classification from noisy data. In Proceedings of AAAI.

Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Mario Marchand, and Victor
Lempitsky. 2016. Domain-adversarial training of neural networks. JMLR, 17(1):2096‚Äì2030.

Ian J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Proceedings of NIPS, pages 2672‚Äì2680.

Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and harnessing adversarial examples.
In Proceedings of ICML, pages 1‚Äì10.

Xu Han, Zhiyuan Liu, and Maosong Sun. 2018. Neural knowledge acquisition via mutual attention between
knowledge graph and text. In Proceedings of AAAI.

Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S. Weld. 2011. Knowledge-based
weak supervision for information extraction of overlapping relations. In Proceedings of ACL, pages 541‚Äì550.

Guoliang Ji, Kang Liu, Shizhu He, Jun Zhao, et al. 2017. Distant supervision for relation extraction with sentence-
level attention and entity descriptions. In Proceedings of AAAI, pages 3060‚Äì3066.

Yankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan, and Maosong Sun. 2016. Neural relation extraction with
selective attention over instances. In Proceedings of ACL, pages 2124‚Äì2133.

Yankai Lin, Zhiyuan Liu, and Maosong Sun. 2017. Neural relation extraction with multi-lingual attention. In
Proceedings of ACL, pages 34‚Äì43.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2017a. Adversarial multi-task learning for text classification. In
Proceedings of ACL, pages 1‚Äì10.

Tianyu Liu, Kexiang Wang, Baobao Chang, and Zhifang Sui. 2017b. A soft-label method for noise-tolerant
distantly supervised relation extraction. In Proceedings of EMNLP, pages 1790‚Äì1795.



1166

Laurens Van Der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-sne. JMLR, 9(12):2579‚Äì2605.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in
vector space. In Proceedings of ICLR, pages 1‚Äì12.

Mintz, Mike, Steven, Jurafsky, and Dan. 2009. Distant supervision for relation extraction without labeled data. In
Proceedings of ACL, pages 1003‚Äì1011.

Gwangbeen Park and Woobin Im. 2016. Image-text multi-modal representation learning by adversarial backprop-
agation. arXiv preprint arXiv:1612.08354.

Sebastian Riedel, Limin Yao, and Andrew Mccallum. 2010. Modeling relations and their mentions without labeled
text. In Proceedings of ECML-PKDD, pages 148‚Äì163.

Cicero Nogueira Dos Santos, Bing Xiang, and Bowen Zhou. 2015. Classifying relations by ranking with convo-
lutional neural networks. In Proceedings of ACL, pages 626‚Äì634.

Richard Socher, Brody Huval, Christopher D Manning, and Andrew Y Ng. 2012. Semantic compositionality
through recursive matrix-vector spaces. In Proceedings of EMNLP, pages 1201‚Äì1211.

Patrick Verga, David Belanger, Emma Strubell, Benjamin Roth, and Andrew Mccallum. 2016. Multilingual
relation extraction using compositional universal schema. In NAACL, pages 886‚Äì896.

Yi Wu, David Bamman, and Stuart Russell. 2017. Adversarial training for relation extraction. In Proceedings of
EMNLP, pages 1778‚Äì1783.

Yang Xiang, Qingcai Chen, Xiaolong Wang, and Yang Qin. 2017. Answer selection in community question
answering via attentive neural networks. IEEE SPL, 24(4):505‚Äì509.

Dmitry Zelenko, Chinatsu Aone, and Anthony Richardella. 2003. Kernel methods for relation extraction. JMLR,
3(2):1083‚Äì1106.

Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao. 2014. Relation classification via convolu-
tional deep neural network. In Proceedings of COLING, pages 2335‚Äì2344.

Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao. 2015. Distant supervision for relation extraction via piecewise
convolutional neural networks. In Proceedings of EMNLP, pages 1753‚Äì1762.

Wenyuan Zeng, Yankai Lin, Zhiyuan Liu, and Maosong Sun. 2017. Incorporating relation paths in neural relation
extraction. In Proceedings of EMNLP.

Xiangrong Zeng, Shizhu He, Kang Liu, and Jun Zhao. 2018. Large scaled relation extraction with reinforcement
learning. In Proceedings of AAAI.

Dongxu Zhang and Dong Wang. 2015. Relation classification via recurrent neural network. arXiv preprint
arXiv:1508.01006.

Huaping Zhong, Jianwen Zhang, Zhen Wang, Hai Wan, and Zheng Chen. 2015. Aligning knowledge and text
embeddings by entity descriptions. In Proceedings of EMNLP, pages 267‚Äì272.


