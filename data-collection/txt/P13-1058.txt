



















































Using subcategorization knowledge to improve case prediction for translation to German


Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 593–603,
Sofia, Bulgaria, August 4-9 2013. c©2013 Association for Computational Linguistics

Using subcategorization knowledge to improve case prediction
for translation to German

Marion Weller1 Alexander Fraser2 Sabine Schulte im Walde1

1Institut für Maschinelle 2Centrum für Informations-
Sprachverarbeitung und Sprachverarbeitung
Universität Stuttgart Ludwig-Maximilians-Universität München

{wellermn|schulte}@ims.uni-stuttgart.de fraser@cis.uni-muenchen.de

Abstract

This paper demonstrates the need and im-
pact of subcategorization information for
SMT. We combine (i) features on source-
side syntactic subcategorization and (ii)
an external knowledge base with quantita-
tive, dependency-based information about
target-side subcategorization frames. A
manual evaluation of an English-to-
German translation task shows that the
subcategorization information has a posi-
tive impact on translation quality through
better prediction of case.

1 Introduction

When translating from a morphologically poor
language to a morphologically rich language we
are faced with two major problems: (i) the rich-
ness of the target-language morphology causes
data sparsity problems, and (ii) information about
morphological features on the target side is not
sufficiently contained in the source language mor-
phology.

We address these two problems using a two-
step procedure. We first replace inflected forms
by their stems or lemmas: building a translation
system on a stemmed representation of the target
side leads to a simpler translation task, and the
morphological information contained in the source
and target language parts of the translation model
is more balanced. In the second step, the stemmed
output of the translation is then inflected: the mor-
phological features are predicted, and the inflected
forms are generated using the stem and predicted
morphological features.

In this paper, we focus on improving case pre-
diction for noun phrases (NPs) in German trans-
lations. The NP feature case is extremely dif-
ficult to predict in German: while the NP fea-
tures gender and number are part of the stem or

can be derived from the source-side input, respec-
tively, the prediction of case requires information
about the subcategorization of the entire clause.
This is due to German being a less configurational
language than English, which encodes grammati-
cal relations (e.g. subject-hood, object-hood, etc.)
through the position of constituents. German sen-
tences exhibit a freer constituent order, and thus
case is an important indicator of the grammatical
functions of noun phrases. Correct case predic-
tion is a crucial factor for the adequacy of SMT
output, cf. the example in table 1 providing an
erroneously inflected output (this is taken from a
baseline “simple inflection prediction” system, cf.
section 5.2). The translation of the English input
sentence in terms of stems is perfectly acceptable;
after the inflection step, however, the translation
of NP4 ongoing military actions represents a geni-
tive modifier of the subject NP2, instead of a direct
object NP of the verb anordnen (to order). The
meaning is thus why the government of the ongo-
ing military actions ordered, which has only one
NP and is completely wrong.

The translation in table 1 needs verb subcatego-
rization information. This is demonstrated by the
invented examples (1) and (2):

(1) [Der Mitarbeiter]NPnom hat [den Bericht]NPacc [dem
Kollegen]NPdat gegeben.

[The employee]NPnom gave [his colleague]NPdat [the
report]NPacc

(2) [Der Mitarbeiter]NPnom hat [dem Bericht]NPdat [des
Kollegen]NPgen zugestimmt.

[The employee]NPnom agreed [on the report]PP [of
his colleague]PP

Both inflected sentences rely on the stem sequence
[d Mitarbeiter] [d Bericht] [d Kollege] 〈verb〉,

so the case assignment can only be determined by
the verb: While geben ( to give) has a strong pref-
erence for selecting a ditransitive subcategoriza-
tion frame1, including an agentive subject (nomi-

1A ditransitive verb takes a subject and two objects.

593



input [why]1 [the government]2 [ordered]3 [the ongoing military actions]4
output stemmed [warum]1 [d Regierung]2 [d anhaltend militärisch Aktion]4 [angeordnet]3inflected [warum]1 [die Regierung]2 [der anhaltenden militärischen Aktionen]4 [angeordnet]3

Table 1: Example for case confusion in SMT output when using a simple prediction system.

native case), a benefactive (dative case) and a pa-
tient (accusative case), zustimmen (to agree) has
a strong preference for only selecting an agentive
subject (nominative case) and an indirect object
theme (dative case). So in the latter case the NP
[d Kollege] cannot receive case from the verb and
is instead the genitive modifier of the dative NP.

While for examples (1) and (2) knowledge
about the syntactic verb subcategorization func-
tions is sufficient to correctly predict the NP cases,
examples (3) to (6) require subcategorization in-
formation at the syntax-semantic interface.

(3) [Der Mitarbeiter]NPnom hat [dem Kollegen]NPdat
[den Bericht]NPacc gegeben.

(4) [Der Mitarbeiter]NPnom hat [den Bericht]NPacc [dem
Kollegen]NPdat gegeben.

(5) [Dem Kollegen]NPdat hat [der Mitarbeiter]NPnom
[den Bericht]NPacc gegeben.

(6) [Den Bericht]NPacc hat [der Mitarbeiter]NPnom [dem
Kollegen]NPdat gegeben.

In all four examples, the verb and the participat-
ing noun phrases Mitarbeiter (employee), Kollege
(colleague) and Bericht (report) are identical, and
the noun phrases are assigned the same case. How-
ever, given that the stemmed output of the trans-
lation does not tell us anything about case fea-
tures, in order to predict the appropriate cases of
the three noun phrases, we either rely on ordering
heuristics (such that the nominative NP is more
likely to be in the beginning of the sentence (the
German Vorfeld) than the accusative or dative NP,
even though all three of these would be grammati-
cal), or we need fine-grained subcategorization in-
formation beyond pure syntax. For example, both
Mitarbeiter and Kollege would satisfy the agentive
subject role of the verb geben better than Bericht,
and Bericht is more likely to be the patient of
geben.

The contribution of this paper is to improve the
prediction of case in our SMT system by imple-
menting and combining two alternative routes to
integrate subcategorization information from the
syntax-semantic interface: (i) We regard the trans-
lation as a function of the source language in-
put, and project the syntactic functions of the En-
glish nouns to their German translations in the

SMT output. This subcategorization model is nec-
essary when there are several plausible solutions
for the syntactic functions of a noun in combina-
tion with a verb. For example, both Mitarbeiter
and Kollege are plausible subjects and direct ob-
jects of the verb geben, so the information about
these nouns’ roles in the input sentence allows
for disambiguation. (ii) The case of an NP is de-
rived from an external knowledge base comprising
quantitative, dependency-based information about
German verb subcategorization frames and noun
modification. The verb subcategorization infor-
mation is not restricted to syntactic noun func-
tions but models association strength for verb–
noun pairs with regard to the entire subcatego-
rization frame plus the syntactic functions of the
nouns. For example, the database can tell us that
while the verb geben is very likely to subcatego-
rize a ditransitive frame, the verb zustimmen is
very likely to subcategorize only a direct object,
next to the obligatory subject (subcat frame pre-
diction). Furthermore, we can retrieve the infor-
mation that the noun Bericht is less likely to ap-
pear as subject of geben than the nouns Mitar-
beiter and Kollege (verb–noun subcat case pre-
diction). And we can look up that the noun Aktion
is very unlikely to be a genitive modification of
Regierung (cf. table 1), while Kollege is a plausi-
ble genitive modification of Bericht (noun–noun
modification case prediction, cf. example (2)).

In summary, model (i) applies when there are no
obvious preferences concerning verb–noun sub-
categorization or noun–noun modification. Model
(ii) predicts case relying on the subcategoriza-
tion and modification preferences. The combina-
tion of our two models approaches a simplified
level of semantic role definition but only relies on
dependency information that is considerably eas-
ier and cheaper to define and obtain than a very
high quality semantic parser and/or a corpus an-
notated with semantic role information. Integrat-
ing semantic role information into SMT has been
demonstrated by various researchers to improve
translation quality (cf. Wu and Fung (2009a), Wu
and Fung (2009b), Liu and Gildea (2008), Liu
and Gildea (2010)). Our approach is in line with

594



Wu and Fung (2009b) who demonstrated that on
the one hand 84% of verb syntactic functions in
a 50-sentence test corpus projected from Chinese
to English, and that on the other hand about 15%
of the subjects were not translated into subjects,
but their semantic roles were preserved across lan-
guage. These two findings correspond to the ex-
pected uses of our models (i) and (ii), respectively.

2 Previous work

Previous work has already introduced the idea of
generating inflected forms as a post-processing
step for a translation system that has been
stripped of (most) target-language-specific fea-
tures. Toutanova et al. (2008) and Jeong et al.
(2010) built translation systems that predict in-
flected word forms based on a large array of mor-
phological and syntactic features, obtained from
both source and target side. Kholy and Habash
(2012) and Green and DeNero (2012) work on En-
glish to Arabic translation and model gender, num-
ber and definiteness, focusing primarily on im-
proving fluency.

Fraser et al. (2012) used a phrase-based system
to transfer stems and generated inflected forms
based on the stems and their morphological fea-
tures. For case prediction, they trained a CRF with
access to lemmas and POS-tags within a given
window. We re-implemented the system by Fraser
et al. as a hierarchical machine translation system
using a string-to-tree setup. In contrast to the flat
phrase-based setting of Fraser et al. (2012), syn-
tactic trees on the SMT output allow us to work
with verb–noun structures, which are relevant for
case prediction. While the CRF used for case pre-
diction in Fraser et al. (2012) has access to lexi-
cal information, it is limited to a certain window
size and has no direct information about the rela-
tion of verb–noun pairs occurring in the sentence.
Using a window of a limited size is particularly
problematic for German, as there can be large gaps
between the verb and its subcategorized nouns; in-
troducing information about the relation of verbs
and nouns helps to bridge such gaps. Furthermore,
that model was not able to make effective use of
source-side features.

One of the objectives of using an inflection
prediction model is morphologically well-formed
output. Kirchhoff et al. (2012) evaluated user re-
actions to different error types in machine trans-
lation and came to the result that morphological

well-formedness has only a marginal impact on
the comprehensibility of SMT output in the case
of English-Spanish translation. As already dis-
cussed, German case is essential to the meaning
of the sentence, so this result will not hold for Ger-
man output.

3 Translation pipeline

This section presents an overview of our two-step
translation process. In the first step, English in-
put is translated to German stems. In the sec-
ond step, morphological features are predicted and
inflected forms are generated based on the word
stems and the morphological features. In subsec-
tions 3.1 to 3.4, we present the simple version of
the inflection prediction system; our new features
are described in sections 4.2 and 4.3.

3.1 Stemmed representation/feature markup

We first parse the German side of the parallel
training data with BitPar (Schmid, 2004). This
maps each surface form appearing in normal text
to a stem and morphological features (case, gen-
der, number). We use this representation to create
the stemmed representation for training the trans-
lation model. With the exception of stem-markup
(discussed below), all morphological features are
removed from the stemmed representation. The
stem markup is used as part of the input to the fea-
ture prediction; the basic idea is that the given fea-
ture values are picked up by the prediction model
and then propagated over the phrase.

Nouns, as the head of NPs and PPs, are anno-
tated with gender and number. We consider gen-
der as part of the stem, whereas the value for num-
ber is derived from the source-side: if marked for
number, singular/plural nouns are distinguished
during word alignment and then translated accord-
ingly. Prepositions are also annotated with case;
many prepositions are restricted to only one case,
some are ambiguous and allow for either dative
or accusative. Other words which are subject to
feature prediction (e.g. adjectives, articles) are re-
duced to their stems with no feature markup, as
are all remaining words. As sole exception, we
keep the inflected forms of verbs (verbal inflec-
tion is not modelled). In addition to the transla-
tion model, the target-side language model, as well
as the reference data for parameter tuning use this
representation.

595



3.2 Building a stemmed translation model

We use a hierarchical translation system. Instead
of translating phrases, a hierarchical system ex-
tracts translation rules (Galley et al., 2004) which
allow the decoder to provide a tree spanning over
the translated sentence. In order to avoid sparsity
during rule extraction, we use a string-to-tree
setup, where only the target-side part of the data
is parsed. Translation rules are of the following
form:
[X]1 allows [X]2 → [NP]1 [NP]2 erlaubt
[X]1 allows [X]2 → [NP]1 erlaubt [NP]2

This example illustrates how rules can cover the
different word ordering possibilities in German.

PP nodes are annotated with their respective
case, as well as with the lemma of the preposition
they contain. In our experiments, this enriched an-
notation has small improvements over the simpler
setting with only head categories (details omit-
ted). This outcome, in particular that adding the
lemma of the preposition to the PP node helps to
improve translation quality, has been observed be-
fore in tree restructuring work for improving trans-
lation (Huang and Knight, 2006).

3.3 Feature prediction and generation of
inflected forms

In this section we discuss our focus, which is pre-
diction of case, but also the prediction of num-
ber, gender and strong/weak adjectival inflection.
The latter feature is German-specific; its values2

(strong/weak) depend on the combination of the
other features, as well as on the type of determiner
(e.g. definite/indefinite/none).

Morphological features are predicted on four
separate CRF models, one for each feature. The
models for case, number and gender are indepen-
dent of another, whereas the model for adjecti-
val inflection requires information about these fea-
tures, and is thus the last one to be computed, tak-
ing the output of the 3 other models as part of its
input. In contrast, the adjectival inflection model
in Fraser et al. (2012) is independent from the
other features. Each model has access to stems,
POS-tags and the feature to be modelled within a
window of four positions to the right and the left
of the current position3.

2Note that the values for strong/weak inflection are not
always the same over the phrase, but follow a certain pattern
depending on the settings of case, number and gender.

3Preliminary experiments showed that larger windows do
not improve translation quality.

Table 2 illustrates the different steps of the in-
flection process: the markup (number and gender
on nouns) in the stemmed output of the SMT sys-
tem is part of the input to the respective feature
prediction. For gender and number, the values
given on the stems of the nouns are then propa-
gated over the phrase. While the case of prepo-
sitional phrases is determined by the case annota-
tion on prepositions, the case of nominal phrases
is computed only based on the respective contexts.
After predicting all morphological features, the in-
formation required to generate inflected forms is
complete: based on the stems and the features, we
use the morphological tool SMOR (Schmid et al.,
2004) for the generation of inflected forms.

One general problem with feature-prediction is
that the ill-formed SMT output is not well repre-
sented by the training data which consists of well-
formed sentences. This problem was also men-
tioned by Stymne and Cancedda (2011) and Kholy
and Habash (2012). They deal with this problem
by translating the training data and annotating it
with the respective features, and then adding this
new data set to the original training data. As
this method comes with its own problems, such as
transferring the morphological annotation to not
necessarily isomorphically translated text, we do
not use translated data as part of the training data.
Instead, we limit the power of the CRF model
through experimenting with the removal of fea-
tures, until we had a system that was robust to this
problem.

3.4 Dealing with word formation issues

To reduce data sparsity, we split portmanteau
prepositions. Portmanteaus are compounds of
prepositions and articles, e.g. zur = zu der (to the).
Being components of nominal phrases, they have
to agree in all morphological features with the rest
of the phrase. As only some combinations of arti-
cles and prepositions can form a portmanteau, the
decision of whether to merge prepositions and ar-
ticles is made after feature prediction. Since our
focus is case prediction, we do not do special mod-
elling of German compounds.

4 Using subcategorization information

Within the area of (automatic) lexical acquisition,
the definition of lexical verb information has been
a major focus, because verbs play a central role
for the structure and the meaning of sentences and

596



SMT output predicted features inflected forms gloss
beeinflussen<VVFIN> – beeinflussen influence
d<ART> Fem.Acc.Sg.St die the
politisch<ADJ> Fem.Acc.Sg.Wk politische political
Stabilität<NN><Fem><Sg> Fem.Acc.Sg.Wk Stabilität stability

Table 2: Overview of the inflection process: the stem markup is highlighted in the SMT output.

discourse. On the one hand, this has led to a range
of manually or semi-automatically developed lex-
ical resources focusing on verb information, such
as the Levin classes (Levin, 1993), VerbNet (Kip-
per Schuler, 2006), FrameNet4 (Fillmore et al.,
2003), and PropBank (Palmer et al., 2005). On the
other hand, we find automatic approaches to the
induction of verb subcategorization information at
the syntax-semantics interface for a large num-
ber of languages, e.g. Briscoe and Carroll (1997)
for English; Sarkar and Zeman (2000) for Czech;
Schulte im Walde (2002a) for German; Messiant
(2008) for French. This basic kind of verb knowl-
edge has been shown to be useful in many NLP
tasks such as information extraction (Surdeanu et
al., 2003; Venturi1 et al., 2009), parsing (Carroll et
al., 1998; Carroll and Fang, 2004) and word sense
disambiguation (Kohomban and Lee, 2005; Mc-
Carthy et al., 2007).

4.1 Extracting subcategorization information
As described in the introductory section, we make
use of two5 major kinds of subcategorization in-
formation. Verb–noun tuples referring to spe-
cific syntactic functions within verb subcatego-
rization (verb–noun subcat case prediction) are
integrated with an associated probability for ac-
cusative (direct object), dative (indirect object)
and nominative (subject).6 Further to the sub-
ject and object noun phrases, the subcategoriza-
tion information provides quantitative triples for
verb–preposition–noun pairs, thus predicting the
case of NPs within prepositional phrases (we do
this only when the prepositions are ambiguious,
i.e., they could subcategorize either a dative or
an accusative NP). In addition to modelling sub-
categorization information, it is also important to
differentiate between subcategorized noun phrases
(such as object or subject), and noun phrases

4Even though the FrameNets approach does not only in-
clude knowledge about verbal predicates, the actual lexicons
are skewed towards verb behaviour.

5The third kind of information, subcat frame prediction
is implicit, since verb–noun tuples rely on specific frames.

6Genitive objects can also occur in German verb subcate-
gorization frames, but this is extremely rare and verb-specific
and thus not considered in our model.

V-SUBJ V-OBJAcc V-OBJDat
EP 454,350 332,847 53,711
HGC 712,717 329,830 160,377
Both 1,089,492 607,541 206,764

Table 3: Number of verb-noun types extracted
from Europarl (EP) and newspaper data (HGC).

that modify nouns (noun–noun modification case
prediction). Typically, these NP modifiers are
genitive NPs. To this end, we integrate noun-
nounGen tuples with their respective frequencies.
These preferences for a certain function (i.e. sub-
ject, object or modifier) are passed on to the sys-
tem at the level of nouns and integrated into the
CRF through the derived probabilities.

The tuples and triples are obtained from
dependency-parsed data by extracting all occur-
rences of the respective relations; table 3 gives an
overview of the number of extracted tuple types.
For the subcategorization information, the verb-
noun tuples (verb-subject, verb-objectAcc, verb-
objectDat) are then grouped as follows:

tuple gloss Acc Dat Nom
SchemaN folgenV pattern follow 0 322 19

We compute the probabilities for the verb-noun tu-
ple to occur in the respective functions based on
the relative frequencies. In the case of SchemaN
folgenV , we find that the function of Schema as da-
tive object is predominant (to follow a pattern), but
it can also occur in the subject position (the pat-
tern follows). The fact that two functions are pos-
sible for this noun are reflected in their probabili-
ties. The probabilities are discretized into 5 buck-
ets (Bp=0, B0<p≤0.25, B0.25<p≤0.5, B0.5<p≤0.75,
B0.75<p≤1). In contrast, noun modification in
noun-nounGen construction is represented by co-
occurrence frequencies.7

7The frequencies are bucketed to the powers of ten, i.e.
f = 1, 2 ≤ f ≤ 10, 11 ≤ f ≤ 100 , etc. and also f = 0:
this representation allows for a more fine-grained distinction
in the low-to-mid frequency range, providing a good basis
for the decision of whether a given noun-noun pair is a true
noun-nounGen structure or just a random co-occurrence of
two nouns.

597



Gloss Stem Tag Acc Dat Nom Verb Gen N1 Gold
1 companies Unternehmen<NN> NN 0.00 0.00 1.00 erhalten – – Nom
2 should sollten<VVFIN> VVFIN – – – – – – –
3 financial finanziell<ADJ> ADJ – – – – – – Acc
4 funding Mittel<NN> NN 1.00 0.00 0.00 erhalten – – Acc
5 for für APPR<Acc> PRP – – – – – – –
6 the d<ART> ART – – – – – – Acc
7 introduction Einführung<NN> NN – – – – – – Acc
8 new neu<ADJ> ADJ – – – – – – Gen
9 technologies Technologie<NN> NN – – – – 100 Einführung<NN> Gen
10 obtain erhalten<VVINF> VVINF – – – – – – –

Table 4: Adding subcategorization information into SMT output. (EN input: companies should obtain
financial funding for the introduction of new technologies). On the right, the correct labels are given.

4.2 Integrating subcategorization knowledge

There are two possibilities to integrate subcat-
egorization information into the case prediction
model: (i) It can be integrated into the data set
using the tree-structure provided by the decoder.
Here, verb-noun tuples are extracted from VP and
S structures, and then the probabilities for the dif-
ferent functions are looked up. Similarly, for two
adjacent NPs, the occurrence frequencies of the
respective two nouns are looked up in the list of
noun-nounGen constructions. (ii) The subcatego-
rization information can be integrated based on
the verb-noun tuples obtained by using tuples ob-
tained from source-side dependencies.

The classification task of the CRF consists in
predicting a sequence of labels: case values for
NPs/PPs or no value otherwise, cf. table 4. The
model has access to the basic features stem and
tag, as well as the new features based on subcat-
egorizaion information (explained below), using
unigrams within a window of up to four positions
to the right and the left of the current position, as
well as bigrams and trigrams for stems and tags
(current item + left and/or right item).

An example for integrating subcategorization
features is given in table 4. The first word Un-
ternehmen (companies) is annotated as subject of
erhalten (obtain) with probability 1, and Mittel
(funding) is annotated as direct object of erhal-
ten with probability 1. The word Technologie
(technology) has been marked as a candidate for
a genitive in a noun-nounGen construction8; the
co-occurrence frequency of the tuple Einführung-
Technologie (introduction - technology) lies in the
bucket 11. . . 100.

In addition to the probability/frequency of the
respective functions, we also provide the CRF
with bigrams containing the two parts of the tuple,

8There is no annotation on Einführung as the preposition
für is always in accusative case.

DE stemmed output

warum<PWAV>
die<ART>
Regierung<NN><Sg><Fem>
die<ART>
anhaltend<ADJ>
militärisch<ADJ>
Aktion<NN><Pl><Fem>
angeordnet<VVFIN>

derived features

SUBJ  V:anordnen

OBJ  V:anordnen

SUBJ

OBJ

EN input

why
the 
government
ordered
the
ongoing
military
actions

Figure 1: Deriving features from dependency-
parsed English data via the word alignment.

i.e. verb+noun or the two nouns of possible noun-
nounGen constructions. As can be seen in the ex-
ample in table 4, the subject (line 1) and the verb
(line 10) are far apart from each other. By pro-
viding the parts of the tuple as unigrams, bigrams
or trigrams to the CRF, all relevant information
is available: verb, noun and the probabilities for
the potential functions of the noun in the sentence.
In addition to bridging the long distance between
verbs and subcategorized nouns, a very common
problem for German, this type of precise informa-
tion also helps to close the gap between the well-
formed training data and the broken SMT-output
as it replaces to a certain extent the target-language
context information (n-grams of stems or lemmas
within a small window).

4.3 Integrating source-side features

For predicting case in SMT output, information
about an NP’s function in the input sentence is
essential. Syntax-semantic functions can be iso-
morphic (e.g., English subjects and objects may
have the same function in a German translation),
but this is not necessarily the case. Despite this,
an important advantage of integrating source-side
features is that the well-formed source-side text
can be reliably parsed, whereas SMT output is of-
ten disfluent and cannot be reliably parsed.

The English features are obtained from
dependency-parsed data (Choi and Palmer, 2012).
The relevant annotation of the parser is transferred

598



to the SMT output via word alignment. We focus
on English subjects, direct objects and noun-of-
noun structures (often equivalent to noun-nounGen
phrases on the German side): these structures
are generally likely to correspond to each other
within source and target language. In contrast
to the subcategorization-based information, the
difference between well-formed training data and
disfluent SMT output tends to work to our benefit
here: while the parallel sentences of the training
data were manually translated with the objective
to produce good target-language sentences, the
syntactic structures of the source and target
sentences are often diverging. In contrast, the
SMT system often produces more isomorphic
translations, which is helpful for annotating
source-side features on the target language.

Figure 1 shows the process of integrating
source-side features: for each German noun that
is aligned with an English noun labelled as subject
or direct object, this annotation is transferred to the
target-side. Using the English dependency struc-
tures, the verb subcategorizing the respective noun
is identified, and via the alignment, the equivalent
German verb is obtained. Similarly, candidates for
noun-nounGen structures are identified by extract-
ing and aligning English noun-of-noun phrases.

5 Experiments and evaluation

In this section, we present experiments using dif-
ferent feature combinations. We also present a
manual evaluation of our best system which shows
that the new features improve translation quality.

5.1 Data and experimental setup

We use the hierarchical translation system that
comes with the Moses SMT-package and GIZA++
to compute the word alignment, using the “grow-
diag-final-and” heuristics. The rule table was
computed with the default parameter setting for
GHKM extraction (Galley et al., 2004) in the im-
plementation by Williams and Koehn (2012).

Our training data contains 1,485,059 parallel
sentences9; the German part of the parallel data
is used as the target-side language model. The dev
and test sets (1025/1026 lines) are wmt-2009-a/b.

For predicting the grammatical features, we
used the Wapiti Toolkit (Lavergne et al., 2010).10

9English/German data released for the 2009 ACL Work-
shop on Machine Translation shared task.

10To eliminate irrelevant features, we use L1 regulariza-

We train four CRFs on data prepared as shown
in section 3. The corpora used for the extrac-
tion of subcategorization tuples were Europarl and
German newspaper data (200 million words). We
choose this particular data combination in order to
provide data that matches the training data, as well
as to add new data of the test set’s domain (news).
The German part of Europarl was dependency-
parsed with Bohnet (2010), and subcategorization
information was extracted as described in Scheible
et al. (2013); the newspaper data (HGC - Huge
German Corpus) was parsed with Schmid (2000),
and subcategorization information was extracted
as described in Schulte im Walde (2002b).

5.2 Results

We report results of two types of systems (ta-
ble 5): first, a regular translation system built on
surface forms (i.e., normal text) and second, four
inflection prediction systems. The first inflection
prediction system (1) uses a simple case predic-
tion model, whereas the remaining systems are
enriched with (2) subcategorization information
(cf. section 4.2), (3) source-side features (cf. sec-
tion 4.3), and (4) both source-side features and
subcategorization information. In (2) and (4), the
subcategorization information was included using
tuples obtained from source-side dependencies11.
The simple prediction system corresponds to that
presented in section 3; for all inflection predic-
tion systems, the same SMT output and models for
number, gender and strong/weak inflection were
used; thus the only difference with the simple pre-
diction system is the model for case prediction.

We present three types of evaluation: BLEU
scores (Papineni et al., 2001), prediction accuracy
on clean data and a manual evaluation of the best
system in section 5.3.

Table 5 gives results in case-insensitive BLEU.
While the inflection prediction systems (1-4) are
significantly12 better than the surface-form sys-
tem (0), the different versions of the inflection sys-
tems are not distinguishable in terms of BLEU;
however, our manual evaluation shows that the
new features have a positive impact on translation
quality.

tion; the regularization parameter is optimized on held out
data.

11Using tuples extracted from the target-side parse tree
(produced by the decoder) results in a BLEU score of 14.00.

12We used Kevin Gimpel’s implementation of pairwise
bootstrap resampling with 1000 samples.

599



0 1 2 3 4
surface simple subcat. features source-side source-side
system prediction (tuples from EN side) features + subcat. featues

BLEU 13.43 14.02 14.05 14.10 14.17
Clean – 85.05 % 85.65 % 85.61 % 85.81 %

Table 5: Results of the simple prediction vs. three systems enriched with extra features.

One problem with using BLEU as an evalua-
tion metric is that it is a precision-oriented met-
ric and tends to reward fluency rather than ade-
quacy (see (Wu and Fung, 2009a; Liu and Gildea,
2010)). As we are working on improving ade-
quacy, this will not be fully reflected by BLEU.
Furthermore, not all components of an NP do nec-
essarily change their inflection with a new case
value; it might happen that the only indicator for
the case of an NP is the determiner: er sieht [den
alten Mann]NPacc (he sees the old man) vs. er
folgt [dem alten Mann]NPdat (he follows the old
man). While the case marking of NPs is essential
for comprehensibility, one changed word per noun
phrase is hardly enough to be reflected by BLEU.

An alternative to study the effectiveness of the
case prediction model is to evaluate the prediction
accuracy on parsed clean data, i.e. not on SMT
output. In this case, we measure (using the dev
set) how often the case of an NP is predicted cor-
rectly13. In all cases, the prediction accuracy is
better for the enriched systems. This shows that
the additional features improve the model, but also
that a gain in prediction accuracy on clean data is
not necessarily related to a gain in BLEU. We ob-
served that the more complex the model, the less
robust it is to differences between the test data
and the training data. Related to this problem,
we observed that high-order n-gram POS/lemma-
based features in the simple prediction (sequences
of lemmas and tags) are given too much weight in
training and thus make it difficult for the new fea-
tures to have a larger impact, so we restricted the
n-gram order of this type of feature to trigrams.

5.3 Manual evaluation of the best system

In order to provide a better understanding of the
impact of the presented features, in particular to
see whether there is an improvement in adequacy,
we carried out a manual evaluation comparing sys-

13The numbers in table 5 are artificially high and downplay
the difference as they also include cases which are very easy
to predict, such as nouns in PPs where only one value for case
is possible. We measure how many case labels were correctly
predicted, not correct inflected forms.

enriched simple equal
preferred preferred

person 1 23 11 12
(a) person 2 21 8 17

person 3 26 11 9
person 1 23 5 18

(b) person 2 21 11 14
person 3 29 8 9

(c) agreement 17 2 6

Table 6: Manual evaluation of 46 sentences: with-
out (a) and with (b) access to EN input, and the
annotators’ agreement in the second part (c).

tem (4) with the simple prediction system (1).
From the set of different sentences between the
simple prediction system and the enriched system
(144 of 1026), we evaluated those where the En-
glish input sentence was between 8 and 25 words
long (46 sentences in total). We specifically re-
stricted the test set in order to provide sentences
which are less difficult to annotate, as longer sen-
tences are often very disfluent and too hard to rate.
Most of the sentences in the evaluation set differ
only in the realization of one NP. For comparing
the two systems, the sentences were presented in
random order to 3 native speakers of German.

The evaluation consists of two parts: first, the
participants were asked to decide which sentence
is better without being given the English input
(this measures fluency). In the second part, they
should to mark that sentence which better repro-
duces the content of the English input sentence
(this measures adequacy). The test set is the same
for both tasks, the only difference being that the
English input is given in the second part. The re-
sults are given in table 6. Summarizing we can
say that the participants prefer the enriched sys-
tem over the simple system in both parts; there is a
high agreement (17 cases) in decisions over those
sentences which were rated as enriched better.

When looking at the pairwise inter-annotator
agreement for the task of annotating the test-set
with the 3 possible labels enriched preferred, sim-
ple preferred and no preference, we find that the
annotators P1 and P2 have a substantial agreement

600



input hundreds of policemen were on alert , and [a helicopter]Subj circled the area with searchlights .
1 simple Hunderte von Polizisten auf Trab , und [einen Helikopter]Acc eingekreist das Gebiet mit searchlights .

enriched Hunderte von Polizisten auf Trab , und [ein Helikopter]Nom eingekreist das Gebiet mit searchlights .
input while 38 %percent put [their trust]Obj in viktor orbán .

2 simple während 38 % [ihres Vertrauens]Gen schenken in Viktor Orbán .
enriched während 38 % [ihr Vertrauen]Acc schenken in Viktor Orbán .
input more than $ 100 billion will enter [the monetary markets]Obj by means of public sales .

3 simple mehr als 100 Milliarden Dollar werden durch öffentlichen Verkauf [der Geldmärkte]Gen treten .
enriched mehr als 100 Milliarden Dollar werden durch öffentlichen Verkauf [die Geldmärkte]Acc treten .

Table 7: Output from the simple system (1) and the enriched system (4).

in terms of Kappa (κ = 0.6184), whereas the agree-
ment of P3 with P1/P2 respectively leads to lower
scores (κ = 0.4467 and κ = 0.3596). However, the
annotators tend to agree well on sentences with
the label enriched preferred, but largely disagree
on sentences labelled as either simple preferred or
no preference. The number of decisions where all
three annotators agree on a label when given the
English input is listed in table 6(c): for example,
only two sentences were given the label baseline is
better by all three annotators. This outcome shows
how difficult it is to rate disfluent SMT output. For
evaluating the case prediction system, the distinc-
tion between enriched preferred and enriched dis-
preferred is the most important question to answer.
Redefining the annotation task to annotating only
two values by grouping the labels simple preferred
and no preference into one annotation possibility
leads to κ = 0.7391, κ = 0.4048 and κ = 0.5652.

5.4 Examples

Table 7 shows some examples for output from the
simple system and the system using source-side
and subcategorization features. In the first sen-
tence, the subject NP a helicopter was inflected
as a direct object in the simple system, but as a
subject in the enriched system, which was pre-
ferred by all three annotators. In the second sen-
tence, the NP their trust, i.e. a direct object of put,
was incorrectly predicted as genitive-modifier of
38 % (i.e. 38 % of their trust) in the simple sys-
tem. The enriched system made use of the prefer-
ence for accusative for the pair Vertrauen schenken
(place trust), correctly inflecting this NP as di-
rect object. Interestingly, only two annotators pre-
ferred the enriched system, whereas one was unde-
cided. The third sentence illustrates how difficult
it is to rate case marking on disfluent SMT output:
there are two possibilities to translate enter the
money market; the direct equivalent of the English
phrase (den GeldmarktAcc betreten), or via the use

of a prepositional phrase (auf den GeldmarktAcc
treten: “to step into the money market”). The
SMT-output contains a mix of both, i.e. the verb
treten (instead of betreten), but without the prepo-
sition, which cannot lead to a fully correct inflec-
tion. While the inflection of the simple system (a
genitive construction meaning the public sales of
the money market) is definitely wrong, the inflec-
tion obtained in the enriched system is not use-
ful either, due to the structure of the translation14.
This difficulty is also reflected by the annotators,
who gave twice the label no preference and once
the label enriched better.

6 Conclusion

We illustrated the necessity of using external
knowledge sources like subcategorization infor-
mation for modelling case for English to Ger-
man translation. We presented a translation sys-
tem making use of a subcategorization database
together with source-side features. Our method
is language-independent with regard to the source
language; furthermore, no language-specific high-
quality semantic annotation is needed for the tar-
get language, but the data required to model the
subcategorization preferences can be obtained us-
ing standard NLP techniques. We showed in a
manual evaluation that the proposed features have
a positive impact on translation quality.

Acknowledgements

This work was funded by the DFG Research
Project Distributional Approaches to Semantic Re-
latedness (Marion Weller), the DFG Heisenberg
Fellowship SCHU-2580/1-1 (Sabine Schulte im
Walde), as well as by the Deutsche Forschungsge-
meinschaft grant Models of Morphosyntax for Sta-
tistical Machine Translation (Alexander Fraser).

14Furthermore, with treten being polysemous, die
Geldmärkte treten can also mean to kick the money markets.

601



References
Bernd Bohnet. 2010. Top Accuracy and Fast Depen-

dency Parsing is not a Contradiction. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics (COLING) 2010, pages 89–
97, Beijing, August.

Ted Briscoe and John Carroll. 1997. Automatic Ex-
traction of Subcategorization from Corpora. In Pro-
ceedings of the 5th ACL Conference on Applied Nat-
ural Language Processing, pages 356–363, Wash-
ington, DC.

John Carroll and Alex C. Fang. 2004. The Auto-
matic Acquisition of Verb Subcategorisations and
their Impact on the Performance of an HPSG Parser.
In Proceedings of the 1st International Joint Confer-
ence on Natural Language Processing, pages 107–
114, Sanya City, China.

John Carroll, Guido Minnen, and Ted Briscoe. 1998.
Can Subcategorisation Probabilities Help a Sta-
tistical Parser? In Proceedings of the 6th
ACL/SIGDAT Workshop on Very Large Corpora,
Montreal, Canada.

Jinho D. Choi and Martha Palmer. 2012. Getting the
Most out of Transition-Based Dependency Parsing.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies.

Charles J. Fillmore, Christopher R. Johnson, and
Miriam R.L. Petruck. 2003. Background to
FrameNet. International Journal of Lexicography,
16:235–250.

Alexander Fraser, Marion Weller, Aoife Cahill, and Fa-
bienne Cap. 2012. Modeling Inflection and Word-
Formation in SMT. In Proceedings of the the Euro-
pean Chapter of the Association for Computational
Linguistics (EACL), Avignon, France.

Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What’s in a Translation Rule?
In Proceedings of the Human Language Technology
and North American Association for Computational
Linguistics Conference (HLT-NAACL).

Spence Green and John DeNero. 2012. A Class-
Based Agreement Model for Generating Accurately
Inflected Translations. pages 146–155.

Bryant Huang and Kevin Knight. 2006. Relabel-
ing Syntax Trees to Improve Syntax-Based Machine
Translation Quality. In Proceedings of the Hu-
man Language Technology Conference of the North
American Chapter of the ACL.

Minwoo Jeong, Kristina Toutanova, Hisami Suzuki,
and Chris Quirk. 2010. A Discriminative Lexicon
Model for Complex Morphology. In Proceedings of
the Ninth Conference of the Association for Machine
Translation in the Americas (AMTA 2010).

Ahmed El Kholy and Nizar Habash. 2012. Translate,
Predict or Generate: Modeling Rich Morphology in
Statistical Machine Translation. In European Asso-
ciation for Machine Translation.

Karin Kipper Schuler. 2006. VerbNet: A Broad-
Coverage, Comprehensive Verb Lexicon. Ph.D. the-
sis, University of Pennsylvania, Computer and In-
formation Science.

Katrin Kirchhoff, Daniel Capurro, and Anne Turner.
2012. Evaluating User Preferences in Machine
Translation Using Conjoint Analysis. In European
Association for Machine Translation.

Upali S. Kohomban and Wee Sun Lee. 2005. Learning
Semantic Classes for Word Sense Disambiguation.
In Proceedings of the 43rd Annual Meeting on Asso-
ciation for Computational Linguistics, pages 34–41,
Ann Arbor, MI.

Thomas Lavergne, Olivier Cappé, and François Yvon.
2010. Practical very large scale CRFs. In Proceed-
ings the 48th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 504–513.
Association for Computational Linguistics, July.

Beth Levin. 1993. English Verb Classes and Alterna-
tions. The University of Chicago Press.

Ding Liu and Daniel Gildea. 2008. Improved Tree-
to-String Transducers for Machine Translation. In
ACL Workshop on Statistical Machine Translation.

Ding Liu and Daniel Gildea. 2010. Semantic Role
Features for Machine Translation. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics (COLING) 2010.

Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2007. Unsupervised Acquisition of Pre-
dominant Word Senses. Computational Linguistics,
33(4):553–590.

Cédric Messiant. 2008. A Subcategorization Acqui-
sition System for French Verbs. In Proceedings of
the Student Research Workshop at the 46th Annual
Meeting of the Association for Computational Lin-
guistics, pages 55–60, Columbus, OH.

Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An annotated Re-
source of Semantic Roles. Computational Linguis-
tics, 31(1):71–106.

Kishore A. Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2001. BLEU: a Method for Auto-
matic Evaluation of Machine Translation. Technical
Report RC22176 (W0109-022), IBM Research Di-
vision, Thomas J. Watson Research Center.

Anoop Sarkar and Daniel Zeman. 2000. Automatic
Extraction of Subcategorization Frames for Czech.
In Proceedings of the 18th International Conference
on Computational Linguistics, Saarbrücken, Ger-
many.

602



Silke Scheible, Sabine Schulte im Walde, Marion
Weller, and Max Kisselew. 2013. A Compact but
Linguistically Detailed Database for German Verb
Subcategorisation relying on Dependency Parses
from a Web Corpus. In Proceedings of the 8th Web
as Corpus Workshop, Lancaster, UK. To appear.

Helmut Schmid, Arne Fitschen, and Ulrich Heid.
2004. SMOR: a German Computational Morphol-
ogy Covering Derivation, Composition, and Inflec-
tion. In Proceedings of the Fourth International
Conference on Language Resources and Evaluation
(LREC).

Helmut Schmid. 2000. LoPar: Design and Imple-
mentation. Arbeitspapiere des Sonderforschungs-
bereichs 340 ‘Linguistic Theory and the Foun-
dations of Computational Linguistics’ 149, Insti-
tut für Maschinelle Sprachverarbeitung, Universität
Stuttgart.

Helmut Schmid. 2004. Efficient Parsing of Highly
Ambiguous Context-Free Grammars with Bit Vec-
tors.

Sabine Schulte im Walde. 2002a. A Subcategorisa-
tion Lexicon for German Verbs induced from a Lex-
icalised PCFG. In Proceedings of the 3rd Confer-
ence on Language Resources and Evaluation, vol-
ume IV, pages 1351–1357, Las Palmas de Gran Ca-
naria, Spain.

Sabine Schulte im Walde. 2002b. A Subcategorisa-
tion Lexicon for German Verbs induced from a Lex-
icalised PCFG. In Proceedings of the 3rd Confer-
ence on Language Resources and Evaluation, vol-
ume IV, pages 1351–1357, Las Palmas de Gran Ca-
naria, Spain.

Sara Stymne and Nicola Cancedda. 2011. Productive
Generation of Compound Words in Statistical Ma-
chine Translation. In Proceedings of the Sixth Work-
shop on Machine Translation.

Mihai Surdeanu, Sanda Harabagiu, John Williams, and
Paul Aarseth. 2003. Using Predicate-Argument
Structures for Information Extraction. In Proceed-
ings of the 41st Annual Meeting of the Association
for Computational Linguistics, pages 8–15, Sap-
poro, Japan.

Kristina Toutanova, Hisami Suzuki, and Achim Ruopp.
2008. Applying Morphology Generation Models to
Machine Translation. In Proceedings of the 46th An-
nual Meeting of the Association for Computational
Linguistics (ACL): Human Language Technologies.

Giulia Venturi1, Simonetta Montemagni, Simone
Marchi, Yutaka Sasaki, Paul Thompson, John Mc-
Naught, and Sophia Ananiadou. 2009. Bootstrap-
ping a Verb Lexicon for Biomedical Information
Extraction. In Alexander Gelbukh, editor, Linguis-
tics and Intelligent Text Processing, pages 137–148.
Springer, Heidelberg.

Philip Williams and Phillipp Koehn. 2012. GHKM-
Rule Extraction and Scope-3 Parsing in Moses. In
Proceedings of the 7th Workshop on Statistical Ma-
chine Translation, ACL.

Dekai Wu and Pascale Fung. 2009a. Can Semantic
Role Labeling Improve SMT? In Proceedings of the
13th Annual Conference of the European Associa-
tion for Machine Translation (EAMT).

Dekai Wu and Pascale Fung. 2009b. Semantic Roles
for SMT: A Hybrid two-pass Model. In Proceed-
ings of the North American Chapter of the Associa-
tion for Computational Linguistics and Human Lan-
guage Technologies Conference (NAACL-HLT).

603


