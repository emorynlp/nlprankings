



















































Everyone Likes Shopping! Multi-class Product Categorization for e-Commerce


Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1329–1333,
Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics

Everyone Likes Shopping!
Multi-class Product Categorization for e-Commerce

Zornitsa Kozareva
Yahoo! Labs

701 First Avenue
Sunnyvale, CA 94089

zornitsa@kozareva.com

Abstract

Online shopping caters the needs of millions
of users on a daily basis. To build an accurate
system that can retrieve relevant products for
a query like “MB252 with travel bags” one
requires product and query categorization
mechanisms, which classify the text as
Home&Garden>Kitchen&Dining>Kitchen
Appliances>Blenders. One of the biggest
challenges in e-Commerce is that providers
like Amazon, e-Bay, Google, Yahoo! and
Walmart organize products into different
product taxonomies making it hard and
time-consuming for sellers to categorize
goods for each shopping platform.

To address this challenge, we propose an
automatic product categorization mechanism,
which for a given product title assigns the cor-
rect product category from a taxonomy. We
conducted an empirical evaluation on 445, 408
product titles and used a rich product taxon-
omy of 319 categories organized into 6 lev-
els. We compared performance against mul-
tiple algorithms and found that the best per-
forming system reaches .88 f-score.

1 Introduction and Related Work

Over the past decade, e-Commerce has rapidly
grown enabling customers to purchase any product
with a click of a button. A key component for the
success of such online shopping platforms is their
ability to quickly and accurately retrieve the desired
products for the customers. To be able to do so,
shopping platforms use taxonomies (Kanagal et al.,
2012), which hierarchically organize products from
general to more specific classes. Taxonomies sup-
port keyword search and guarantee consistency of

the categorization of similar products, which fur-
ther enables product recommendation (Ziegler et al.,
2004; Weng et al., 2008) and duplicate removal.

Shopping platforms like Amazon, e-Bay, Google,
Yahoo!, Walmart among others use different tax-
onomies to organize products making it hard and
labor-intensive for sellers to categorize the products.
Sometimes sellers are encouraged to find similar
products to those they sell and adopt this category
to their products. However, this mechanism leads to
two main problems: (1) it takes a lot of time for a
merchant to categorize items and (2) such taggings
can be inconsistent since different sellers might cat-
egorize the same product differently. To solve these
problems, ideally one would like to have an auto-
mated procedure, which can classify any product ti-
tle into a product taxonomy. Such process will both
alleviate human labor and further improve product
categorization consistency in e-Commerce websites.

Recently, a lot of interest has been developed
around the induction of taxonomies using hierarchal
LDA models (Zhang et al., 2014) and the categoriza-
tion of products using product descriptions (Chen
and Warren, 2013). Despite these efforts, yet no
study focuses on classifying products using only ti-
tles. The question we address in this paper is: Given
a product title and a product taxonomy, can we ac-
curately identify the corresponding category (root-
to-leaf path in the taxonomy) that the title belongs
to?

The main contributions of the paper are:

• We built multi-class classification algorithm
that classifies product titles into 319 distinct
classes organized in 6 levels.
• We conducted an empirical evaluation with

445, 408 product titles and reach .88 f-score.

1329



• During the error analysis we found out that
our algorithm predicted more specific and fine-
grained categories compared to those provided
by humans.

2 Product Categorization Task Definition

We define our task as:

Task Definition: Given a set of titles describing prod-
ucts and a product taxonomy of 319 nodes organized
into 6 levels, the goal is to build a multi-class classi-
fier, which can accurately predict the product category
of a new unlabeled product title.

The algorithm takes as input a product title “MB22B
22 piece with bonus travel/storage bag” and re-
turns as output the whole product category hierarchy
“Home and Garden >Kitchen&Dining>Kitchen
Appliances>Blenders” as illustrated in Figure 1.

!!!!!!!!!!!!!!!!!!!MB22B!22!Piece!With!Bonus!Travel!/Storage!Bag!

Home%&%Garden%>%%
%Kitchen%&%Dining%>%%
% %Kitchen%Appliances%>%
% % % %Blenders%

product((
categoriza.on(

Figure 1: Example of Product Title Categorization.

3 Classification Methods

We model the product categorization task as classi-
fication problem, where for a given collection of la-
beled training examples P , the objective is to learn
a classification function f : pi → ci. Here, pi is a
product title and ci ∈ {1, ...,K} is its corresponding
category (one of 319 product taxonomy classes).

We learn a linear classifier model f (parametrized
by a weight vector w) that minimizes the mis-
classification error on the training corpus P :

min
w

∑
pi∈P

δ(ci 6= f(w, pi)) + λ||w||22
where, δ(.) is an indicator function which is 1 iff the
prediction matches the true class and λ is a regular-
ization parameter.

For our experiments, we used two multi-
classification algorithms from the large scale ma-
chine learning toolkit Vowpal Wabbit (Beygelzimer

et al., 2009): one-against-all (OAA) and error cor-
rection tournament (ECT). OAA reduces the K-
way multi-classification problem into multiple bi-
nary classification tasks by iteratively classifying
each product title for category K and comparing
it against all other categories. ECT also reduces
the problem to binary classification but employs a
single-elimination tournament strategy to compare
a set of K players and repeats this process for
O(logK) rounds to determine the multi-class label.

4 Feature Modeling

Next we describe the set of features we used to train
our model.

4.1 Lexical Information

N-grams are commonly used features in text classi-
fication. As a baseline system, we use unigram and
bigram features.

4.2 Mutual Information Dictionary

Lexical features require very large amount of train-
ing data to produce accurate predictions. To gen-
eralize the categorization models, we use seman-
tic dictionaries, which capture the presence of a
term with a product category. Ideally, we would
like to use existing dictionaries for each product
category, however such information is not avail-
able. For instance, WordNet provides at most syn-
onyms/hyponyms/hypernyms for a given category
name, but it does not provide products, brand names
and the meaning of abbreviations.

We decided to generate our own dictionaries, by
taking all product titles and estimating the mutual in-
formation MI(w,Ci) = log

f(w,Ci)
(f(w,∗).f(∗,Ci) of every

word w and product category Ci. For the dictionary,
we keep all word-category pairs with MI above 5.
During feature generation, for each title we estimate
the percentage of words found with each categoryCi
according to our automatically generated dictionary.
The dimensions of the feature vector is equal to the
total number of categories. The size of the generated
lexicon is 34, 337 word-category pairs.

4.3 LDA Topics

We also incorporate latent information associated
with product titles using topic modeling techniques.

1330



We learn latent topics corresponding to terms oc-
curring in the titles using Latent Dirichlet Alloca-
tion (David Blei and Jordan, 2003). We capture the
meaning of a title using the learned topic distribu-
tion. For our experimental setting, we use the MAL-
LET (McCallum, 2002) implementation of LDA and
build it in the following manner.
Method: Given a set of titles and descriptions D
of products from different categories, find K la-
tent topics. The generative story is modeled as fol-
lows:

for each product category sk where k ∈ {1, ...,K} do
Generate βsk according to Dir(η)

end for
for each title i in the corpus D do

Choose θi ∼ Dir(α)
for each word wi,j where j ∈ {1, ..., Ni} do

Choose a topic zi,j ∼Multinomial(θi)
Choose a word wi,j ∼Multinomial(βzi,j )

end for
end for

Inference: We perform inference on this model us-
ing collapsed Gibbs sampling, where each of the
hidden sense variables zi,j are sampled conditioned
on an assignment for all other variables, while inte-
grating over all possible parameter settings (Griffiths
and Steyvers, 2002). We set the hyperparameter η to
the default value of 0.01 and α=50. During feature
generation, we take all words in the title and estimate
the percentage of words associated with each topic
sk. The topic-word mapping is constructed from the
word distribution learnt for a given topic. The num-
ber of features is equal to the number of topics.

Figure 2 shows an example of the different topics
associated with the word bag for different product
titles.

T"Sac&Disposable&Paper&Filter&Tea&Bags,&Size&2,&100"Count&

SKB&Mixer&Bag&for&Powered&Mackie&mixers&&

NauEca&Baby"Girls&Infant&Printed&Paper&Bag&Waist&Dress&&

t22'

t13'

t59'

Figure 2: Learnt Topic Assignments for bag.

4.4 Neural Network Embeddings

While LDA allows us to capture the latent topics
of the product titles, recent advances in unsuper-

vised algorithms have demonstrated that deep neu-
ral network architectures can be effective in learning
semantic representation of words and phrases from
large unlabeled corpora.

To model the semantic representations of product
titles, we learn embeddings over the corpus P using
the technique of (Mikolov et al., 2013a; Mikolov et
al., 2013b). We use a feedforward neural network
architecture in which the training objective is to find
word (vector) representations that are useful for pre-
dicting the current word in a product title based on
the context. Formally, given a sequence of training
words w1, w2, ..., wT the objective is to maximize
the average log probability

1
T

T∑
t=1

∑
−n≤j≤n,j 6=0

log p(wt|wt+j)

where n is the size of the training context and
p(wt|wt+j) predicts the current position wt using
the surrounding context words wt+j and learned
with hierarchical softmax algorithm.

Since word2vec provides embeddings only for
words or at most two word phrases, to represent a
product title p containing a sequence of M word to-
kens (w1, ..., wM ), we retrieve the embeddings of all
words and take the average score.

p = [e1, ..., ed]

where, ei =
1
M

M∑
j=1

eiwj

Here, d is the embedding vector size, ei and eiwj
are the vector values at position i for the product p
and word wj in p, respectively.

To build the embeddings, we use a vector size of
200 and context of 5 consecutive words in our exper-
iments. We then use the new vector representation
[e1, ..., ed] (d features per title) to train and test the
machine learning model.

5 Data Description

To conduct our experimental studies, we have used
and manually annotated product titles from Yahoo’s
shopping platform. For each title, we asked two an-
notators to provide the whole product category from
the root to the leaf and used these annotations as a
gold standard.

We split the data into a training set of 353, 809
examples and a test set of 91, 599 examples. Our

1331



product taxonomy consists of 6 hierarchical levels.
Figure 3 shows the total number of categories per
level. The highest density is at levels 3 and 4.

!!!8! ! ! !1!
!!31! ! !2!
!!93! ! !3!
!137! ! !4!
!!49! ! !5!
!!!1!! ! !6!

!!!8! ! ! !1!
!!31! ! !2!
!!93! ! !3!
!137! ! !4!
!!49! ! !5!
!!!1!! ! !6!

levels! #categories!

Figure 3: Product Taxonomy.

6 Experiments and Results

In this section, we describe the evaluation metric and
the sets of experiments we have conducted.

6.1 Evaluation Metric

To evaluate the performance of the product catego-
rization algorithms, we calculate f-score on the test
set. The results are on exact match from top-to-leaf
path of the gold and predicted categories.

6.2 Results

Table 1 shows the obtained results. For each fea-
ture we report the performance of the two machine
learning algorithms one-against-all (OAA) and error
correcting tournament (ECT).

features OAA ECT
unigram .72 .63

unigram+bigram .67 .58
MI Dictionary .85 .77

LDA Dictionary .79 .67
NN-Embeddings .88 .80

Table 1: Results on Product Categorization.

The highest performance is achieved with the neu-
ral network embedding representation. Between the
two classifiers one-against-all consistently achieved
the highest scores for all different feature sets. We
also studied various feature combinations, however
embeddings reached the highest performance.

6.3 Error Analysis

We analyzed the produced outputs and noticed that
sometimes the predicted category could be different
from the gold one, but often the predicted category
was semantically similar or more descriptive than

•  flat$slat$sleigh$crib$espresso$8022n$

furniture(>(baby(&(toddler(furniture(>(cribs(&(toddler(beds(

baby(&(toddler(GOLD(

PREDICTED(

•  angel$line$flat$slat$sleigh$changer$w/drawer$$
natural$8583$

furniture(>(baby(&(toddler(furniture(>(cribs(&(toddler(beds(GOLD(

•  cabela's()pped(berber(camo(comfy(cup(

•  carolina(pet(company(large(faux(suede(&(
)pped(berber(round(comfy(cup(green(

animals'&'pet'supplies'>'pet'supplies'>'small'animal'supplies'>'small'animal'bedding'GOLD'

animals'&'pet'supplies'>'pet'supplies'>'dog'supplies'>'dog'beds'GOLD'

PREDICTED'
animals'&'pet'supplies'>'pet'supplies'>'small'animal'supplies'>'small'animal'bedding'

•  aprica&side&carrier&bou-que&pink&

•  julie&brown&girl's&jersey&tunic/pink&9&pink&
apparel&&&accessories&>&clothing&>&shirts&&&tops&GOLD&

baby&&&toddler&>&baby&transport&>&baby&carriers&GOLD&

apparel&&&accessories&>&clothing&>&shirts&&&tops&PREDICTED&

Figure 4: Examples of Categorized Products.

those provided by humans. Figure 4 shows some
examples of the errors we discovered.

For instance, the title cabela’s tipped beer como
comfy cup was classified as Small Animal Bedding,
while the gold standard category was Dog Beds. In
our case we penalized such predictions, but still the
two top level categories of Animals and Pet Sup-
plies are similar. The major difference between the
prediction and gold label is that the humans anno-
tated bed as belonging to Dog Beds, while our al-
gorithm predicted it as Small Animal Bedding. Dur-
ing manual inspection, we also noticed that often our
classifier produces more descriptive categories com-
pared to humans. For example, flat slat sleigh crib
espresso 8022n had gold category Baby & Toddler,
while our algorithm correctly identified the more de-
scriptive category Cribs and Toddler Beds.

7 Conclusions

In this paper we have presented the first product cat-
egorization algorithm which operates on product ti-
tle level. We classified products into a taxonomy
of 319 categories organized into a 6 level taxon-
omy. We collected data for our experiments and
conducted multiple empirical evaluations to study
the effect of various features. Our experiments
showed that neural network embeddings lead to the
best performance reaching .88 f-score. We man-
ually inspected the produced classification outputs
and found that often the predicted categories are
more specific and fine-grained compared to those
provided by humans.

1332



Acknowledgments

We would like to thank the anonymous reviewers for
their useful feedback and suggestions.

References
Alina Beygelzimer, John Langford, and Pradeep Raviku-

mar. 2009. Error-correcting tournaments. In Proceed-
ings of the 20th International Conference on Algorith-
mic Learning Theory, ALT’09, pages 247–262.

Jianfu Chen and David Warren. 2013. Cost-sensitive
learning for large-scale hierarchical classification. In
Proceedings of the 22Nd ACM International Confer-
ence on Conference on Information &#38; Knowledge
Management, CIKM ’13, pages 1351–1360.

Andrew Ng David Blei and Michael Jordan. 2003. La-
tent dirichlet allocation. Journal of Machine Leaning,
3:993–1022.

Thomas L Griffiths and Mark Steyvers. 2002. A prob-
abilistic approach to semantic representation. In Pro-
ceedings of the Twenty-Fourth Annual Conference of
Cognitive Science Society.

Bhargav Kanagal, Amr Ahmed, Sandeep Pandey,
Vanja Josifovski, Jeff Yuan, and Lluis Garcia-Pueyo.
2012. Supercharging recommender systems using tax-
onomies for learning user purchase behavior. Proc.
VLDB Endow., 5(10):956–967, June.

Andrew Kachites McCallum. 2002. Mal-
let: A machine learning for language toolkit.
http://mallet.cs.umass.edu.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeff Dean.
2013a. Efficient estimation of word representations in
vector space. CoRR.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013b. Distributed represen-
tations of words and phrases and their compositional-
ity. CoRR, abs/1310.4546.

Li-Tung Weng, Yue Xu, Yuefeng Li, and Richi Nayak.
2008. Exploiting item taxonomy for solving cold-start
problem in recommendation making. In ICTAI (2),
pages 113–120. IEEE Computer Society.

Yuchen Zhang, Amr Ahmed, Vanja Josifovski, and
Alexander Smola. 2014. Taxonomy discovery for
personalized recommendation. In Proceedings of the
7th ACM International Conference on Web Search and
Data Mining, WSDM ’14, pages 243–252.

Cai-Nicolas Ziegler, Georg Lausen, and Lars Schmidt-
Thieme. 2004. Taxonomy-driven computation of
product recommendations. In Proceedings of the Thir-
teenth ACM International Conference on Information
and Knowledge Management, CIKM ’04, pages 406–
415.

1333


