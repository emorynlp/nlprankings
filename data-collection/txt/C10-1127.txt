Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1128–1136,

Beijing, August 2010

1128

Efﬁcient Statement Identiﬁcation for Automatic Market Forecasting

Henning Wachsmuth
Universit¨at Paderborn
Software Quality Lab

Peter Prettenhofer and Benno Stein

Bauhaus-Universit¨at Weimar

Web Technology & Information Systems

hwachsmuth@slab.upb.de

benno.stein@uni-weimar.de

Abstract

Strategic business decision making in-
volves the analysis of market forecasts.
Today, the identiﬁcation and aggregation
of relevant market statements is done by
human experts, often by analyzing doc-
uments from the World Wide Web. We
present an efﬁcient
information extrac-
tion chain to automate this complex nat-
ural language processing task and show
results for the identiﬁcation part. Based
on time and money extraction, we iden-
tify sentences that represent statements on
revenue using support vector classiﬁca-
tion. We provide a corpus with German
online news articles, in which more than
2,000 such sentences are annotated by do-
main experts from the industry. On the
test data, our statement identiﬁcation al-
gorithm achieves an overall precision and
recall of 0.86 and 0.87 respectively.

1 Introduction

Touch screen market to hit $9B by 2015. 50 sup-
pliers provide multi-touch screens, and that num-
ber is likely to rise.1

Strategic business decision making is a highly
complex process that requires experience as well
as an overall view of economics, politics, and
technological developments. Clearly, for the time
being this process cannot be done by a computer at
the level of a human expert. However, important
tasks may be automated such as market forecast-
ing, which relies on identifying and aggregating
relevant information from the World Wide Web
(Berekoven et. al., 2001). An analyst who inter-
prets the respective data can get a reasonable idea
about the future market volume, for example. The

1Adapted from http://industry.bnet.com.

problem is that a manually conducted Web search
is time-consuming and usually far from being ex-
haustive. With our research we seek to develop
an efﬁcient system that ﬁnds and analyzes market
forecast information with retrieval, extraction and
natural language processing (NLP) techniques.

We contribute to the following situation. For a
given product, technology, or industry sector we
identify and aggregate statements on its market
development found on relevant websites. In par-
ticular, we extract time information (“by 2015”)
and money information (“$9B”) and use support
vector classiﬁcation to identify sentences that rep-
resent market statements. The statements’ sub-
jects (“touch screen”) are found by relating recog-
nized named entities to the time and money infor-
mation, which we then normalize and aggregate.
In this paper we report on results for the statement
identiﬁcation. To the best of our knowledge no
data for the investigation of such market analysis
tasks has been made publicly available until now.
We provide such a corpus with statements on rev-
enue annotated in news articles from the Web; the
corpus was created in close collaboration with our
industry partner Resolto Informatik GmbH.

We pursue two objectives, namely, to support
human experts with respect to the effectiveness
and completeness of their analysis, and to estab-
lish a technological basis upon which more intri-
cate analysis tasks can be automated. To summa-
rize, the main contributions of this paper are:

1. We show how to decompose the identiﬁ-
cation and aggregation of forecasts into re-
trieval, extraction, and normalization tasks.

2. We introduce a manually annotated German
corpus for computational linguistics research
on market information.

3. We offer empirical evidence that classiﬁca-
tion and extraction techniques can be com-

1129

bined to precisely identify statements on rev-
enue.

proﬁt, and the like. The ambitious overall task that
we want to solve is as follows:

1.1 Related Work

Stein et. al. (2005) were among the ﬁrst to con-
sider information extraction for automatic mar-
ket forecasting. Unlike us, the authors put much
emphasis on retrieval aspects and applied depen-
dency grammar parsing to identify market state-
ments. As a consequence their approach suffers
from the limitation to a small number of prede-
ﬁned sentence structures.

While we obtain market forecasts by extract-
ing expert statements from the Web, related ap-
proaches derive them from past market behavior
and quantitative news data. Koppel and Shtrim-
berg (2004) studied the effect of news on ﬁnan-
cial markets. Lavrenko et al. (2000) used time-
series analysis and language models to predict
stock market prices and, similarly, Lerman et al.
(2008) proposed a system for forecasting public
opinion based on concurrent modeling of news ar-
ticles and market history. Another related ﬁeld is
opinion mining in the sense that it relies on the ag-
gregation of individual statements. Glance et al.
(2005) inferred marketing intelligence from opin-
ions in online discussions. Liu et al. (2007) exam-
ined the effect of Weblogs on box ofﬁce revenues
and combined time-series with sentiment analysis
to predict the sales performance of movies.

The mentioned approaches are intended to re-
ﬂect or to predict present developments and,
therefore, primarily help for operative decision
making. In contrast, we aim at predicting long-
term market developments, which are essential for
strategic decision making.

2 The Problem

Market forecasts depend on two parameters, the
topic of interest and the criterion to look at. A
topic is either an organization or a market. Under
a market we unite branches, products, and tech-
nologies, because the distinction between these is
not clear in general (e.g., for semiconductors). In
contrast, we deﬁne a criterion to be a metric at-
tribute that can be measured over time. Here we
are interested in ﬁnancial criteria such as revenue,

Task description: Given a topic τ and a ﬁnan-
cial criterion χ, ﬁnd information for τ on the de-
velopment of χ. Aggregate the found values on χ
with respect to time.

We omit the limitation to forecasts because we

could miss useful information otherwise:

(1) In 2008, the Egyptian automobile industry

achieved US$9.96bn in sales.

(2) Egypt’s automotive sales will rise by 97%

from 2008 to 2013.

Both sentences have the same topic. In Particu-
lar, the 2008 amount of money from example (1)
can be aggregated with the forecast in (2) to infer
the predicted amount in 2013.

As in these examples, market information can
often only be found in running text; the major
source for this is the Web. Thus, we seek to
ﬁnd web pages with sentences that represent state-
ments on a ﬁnancial criterion χ and to make
these statements processable. Conceptually, such
a statement is a 5-tuple Sχ = (S, g, T, M, td),
where S is the topical subject, which may have a
geographic scope g, T is a period of time, M con-
sists of a growth rate and/or an amount of money
to be achieved during T with respect to χ, and td
is the statement time, i.e., the point in time when
the statement was made.

3 Approach

Our goal is to ﬁnd and aggregate statements on
a criterion χ for a topic τ . In close collaboration
with two companies from the semantic technology
ﬁeld, we identiﬁed eight high-level subtasks in the
overall process as explained in the following. An
overview is given in Table 1.

3.1 Find Candidate Documents
To ﬁnd web pages that are likely to contain state-
ments on χ and τ , we propose to perform a meta-
search by starting from a set of characteristic
terms of the domain and then using query expan-
sion techniques such as local context analysis (Xu
and Croft, 2000). As Stein et. al. (2005) describe,

1130

Subtask

Applied technologies

1 Find candidate documents
2 Preprocess content
3 Extract entities
4 Identify statements
5 Determine statement type
6 Fill statement templates
7 Normalize values
8 Aggregate information

meta-search, query expansion, genre analysis
content extraction, sentence splitting, tokenization, POS tagging and chunking
time and money extraction, named entity recognition of organizations and markets
statistical classiﬁcation based on lexical and distance features
relation extraction based on dependency parse trees, matching of word lists
template ﬁlling, anaphora resolution, matching of word lists
time and money normalization, coreference resolution
chronological merging and averaging, inference from subtopic to topic

Table 1: Subtasks of the identiﬁcation and aggregation of market statements for a speciﬁed topic.
Experiments in this paper cover the subtasks written in black.

a genre analysis, which classiﬁes a document with
respect to its form, style, and targeted audience,
may be deployed afterwards to further improve
the quality of the result list efﬁciently. In this way,
we only maintain candidate documents that look
promising on the surface.

3.2 Preprocess Content
Preprocessing is needed for accurate access to the
document text. Our overall task incorporates re-
lating information from different document areas,
so mixing up a web page’s main frame and side-
bars should be avoided. We choose Document
Slope Curve (DSC) for content detection, which
looks for plateaus in the HTML tag distribution.
Gottron (2007) has offered evidence that DSC
is currently the best algorithm in terms of pre-
cision. Afterwards, the sentences are split with
rules that consider the speciﬁc characteristics of
reports, press releases and the like, such as head-
lines between short paragraphs.
In succeeding
subtasks, tokens as well as their Part-of-Speech
and chunk tags are also used, but we see no point
in not relying on standard algorithms here.

3.3 Extract Entities
The key to identify a statement Sχ on a ﬁnan-
cial criterion χ is the extraction of temporal and
monetary entities. Recent works report that sta-
tistical approaches to this task can compete with
hand-crafted rules (Ahn et. al., 2005; Cramer et.
al., 2007). In the ﬁnancial domain, however, the
focus is only on dates and periods as time infor-
mation, along with currency numbers, currency
terms, or fractions as money information. We
found that with regular expressions, which rep-

resent the complex but ﬁnite structures of such
phrases, we can achieve nearly perfect recall in
recognition (see Section 5).

We apply named entity recognition (NER) of
organizations and markets in this stage, too, so we
can relate statements to the appropriate subjects,
later on. Note that market names do not follow a
unique naming scheme, but we observed that they
often involve similar phrase patterns that can be
exploited as features. NER is usually done by se-
quence labeling, and we use heuristic beam search
due to our effort to design a highly efﬁcient overall
system. Ratinov and Roth (2009) have shown for
the CoNLL-2003 shared task that Greedy decod-
ing (i.e., beam search of width 1) is competitive
to the widely used Viterbi algorithm while being
over 100 times faster at the same time.

3.4

Identify Statements

Based on time and money information, sentences
that represent a statement Sχ can be identiﬁed.
Such a sentence gives us valuable hints on which
temporal and monetary entity stick together and
how to interpret them in relation. Additionally,
it serves as evidence for the statement’s correct-
ness (or incorrectness). Every sentence with at
least one temporal and one monetary entity is a
candidate. Criteria such as revenue usually imply
small core vocabularies Lpos, which indicate that
a sentence is on that criterion or which often ap-
pear close to it. On the contrary, there are sets of
words Lneg that suggest a different criterion. For
a given text collection with known statements on
χ, both Lpos and Lneg can be found by computing
the most discriminant terms with respect to χ. A
reasonable ﬁrst approach is then to ﬁlter sentences

1131

that contain terms from Lpos and lack terms from
Lneg, but problems arise when terms from differ-
ent vocabularies co-occur or statements on differ-
ent criteria are attached to one another.

Instead, we propose a statistical learning ap-
proach. Support Vector Machines (SVMs) have
been proven to yield very good performance in
both general classiﬁcation and sentence extraction
while being immune to overﬁtting (Steinwart and
Christmann, 2008; Hirao et. al., 2001). For our
candidates, we compute lexical and distance fea-
tures based on Lpos, Lneg, and the time and money
information. Then we let an SVM use these fea-
tures to distinguish between sentences with state-
ments on χ and others. At least for online news
articles, this works reasonably well as we demon-
strate in Section 5. Note that classiﬁcation is not
used to match the right entities, but to ﬁlter the
small set of sentences on χ.

3.5 Determine Statement Type

The statement type implies what information we
can process. If a sentence contains more than one
temporal or monetary entity, we need to relate the
correct T and M to each Sχ, now. The type of Sχ
then depends on the available money information,
its trend and the time direction.

We consider four types of money information.
χ refers to a period of time that results in a new
amount A of money in contrast to its preceding
amount Ap. The difference between A and Ap
may be speciﬁed as an incremental amount ∆A
or as a relative growth rate r. M can span any
combination of A, Ap, ∆A and r, and at least A
and r constitute a reasonable entity on their own.
Sometimes the trend of r (i.e. decreasing or in-
creasing) cannot be derived from the given val-
ues. However, this information can mostly be ob-
tained from a nearby indicator word (e.g. “plus” or
“decreased”) and, therefore, we address this prob-
lem with appropriate word lists. Once the trend is
known, any two types imply the others.

Though we are predominantly interested in
forecasts, statements also often represent a decla-
ration on achieved results. This distinction is es-
sential and can be based on time-directional indi-
cators (e.g. “next”) and the tense of leading verbs.
For this, we test both feature and kernel methods

on dependency parse trees, thereby determining T
and M at the same time. We only parse the iden-
tiﬁed sentences, though. Hence, we avoid running
into efﬁciency problems.

3.6 Fill Statement Templates

The remaining subtasks are ongoing work, so we
only present basic concepts here.

Besides T and M, the subject S and the state-
ment time td have to be determined. S may be
found within the previously extracted named enti-
ties using the dependency parse tree from Section
3.5 or by anaphora resolution. Possible limitations
to a geographic scope g can be recognized with
word lists.
In market analysis, the approximate
td sufﬁces, and for most news articles td is simi-
lar to their release date. Thus, if no date is in the
parse tree, we search the extracted temporal enti-
ties for the release date, which is often mentioned
at the beginning or end of the document’s content.
We ﬁll one template (S, g, T, M, td) for each Sχ
where we have at least S, T , and M.

3.7 Normalize Values

Since we base the extraction on regular expres-
sions, we can normalize most monetary entities
with a predeﬁned set of rules. Section 3.5 implies
that M∗ = (A∗, r∗) is a reasonable normalized
form where A∗ is A speciﬁed in million US-$ and
r∗ is r as percentage with a ﬁxed number of deci-
mals.2 Time normalization is more complex. Any
period should be transformed to T ∗ = (t∗s, t∗e)
consisting of the start date t∗s and end date t∗e.
Following Ahn et. al. (2005), we consider fully
qualiﬁed, deictic and anaphoric periods. While
normalization of fully qualiﬁed periods like “from
Apr to Jun 1999” is straightforward, deictic (e.g.
“since 2005”, “next year”) and anaphoric men-
tions (e.g. “in the reported time”) require a refer-
ence time. Approaches to resolve such references
rely on dates or fully qualiﬁed periods in the pre-
ceding text (Saquete et. al., 2003; Mani and Wil-
son, 2000).3

2Translating the currency requires exchange rates at state-
ment time. We need access to such information or omit the
translation if only one currency is relevant.

3References to ﬁscal years even involve a whole search

problem if no look-up table on such data is available.

1132

4

2

0

4

2

0

mill.US-$

A

Ap=A’p

A’

t

mill.US-$

4

2

0

with interference

mill.US-$

A’

A

Ap

A’p

t

mill.US-$

4

2

0

without interference

t

t

Figure 1: Example for merging monetary values.

Statements

Total Forecasts

Declarations

Complete corpus

Training set
Validation set
Test set

2075

1366
362
347

523 (25.2%)

1552 (74.8%)

306 (22.4%)
113 (31.2%)
104 (30.0%)

1060 (77.6%)
249 (68.8%)
243 (70.0%)

Table 2: Statements on revenue in the corpus.

information on a market, but only receive state-
ments on companies. Approaches to this relation
may rely e.g. on the web page co-occurrence and
term frequencies of the markets and companies.

11

mill.US-$

10

9

A

A’

A’’

10%

r

0%

t

-10%

Altogether, we return the aggregated values
linked to the sentences in which we found them.
In this way, we make the results veriﬁable and,
thereby, compensate for possible inaccuracies.

t

Figure 2: Example for the inference of relative in-
formation from absolute values.

4 Corpus

If we cannot normalize M or T , we discard the
corresponding statement templates. For the oth-
ers, we have to resolve synonymous co-references
(e.g. “Loewe AG” and “Loewe”) before we can
proceed to the last step.

3.8 Aggregate Information

We can aggregate the normalized values in either
two or three dimensions depending on whether
to separate statements with respect to td. Aggre-
gation then incorporates two challenges, namely,
how to merge values and how to infer information
on a topic from values of a subtopic.

We say that two statements on the same topic
τ and criterion χ interfere if the contained peri-
ods of time intersect and the according monetary
values do not coincide.
In case of declarations,
this means that we extracted incorrect values or
extracted values incorrectly. For forecasts, on the
contrary, we are exactly onto such information.
In both cases, an intuitive solution is to compute
the average (or median) and deviations. Figure 1
graphically illustrates such merging. The subtopic
challenge is based on the assumption that a mean-
ingful number of statements on a certain subtopic
of τ implies relative information on τ , as shown in
Figure 2. One of the most interesting relations are
organizations as subtopics of markets they pro-
duce for, because it is quite usual to search for

To evaluate the given and related tasks, we built
a manually annotated corpus with online news ar-
ticles on the revenues of organizations and mar-
kets. The compilation aims at being representa-
tive for target documents, a search engine returns
to queries on revenue. The purpose of the corpus
is to investigate both the structure of sentences on
ﬁnancial criteria and the distribution of associated
information over the text.

The corpus consists of 1,128 German news ar-
ticles from the years 2003 to 2009, which were
taken from 29 news websites like www.spiegel.de
or www.capital.de. The content of each document
comes as unicode plain text with appended URL
for access to the HTML source code. Annotations
are given in a standard XMI ﬁle preformatted for
the Unstructured Information Management Archi-
tecture (Ferrucci and Lally, 2004). We created a
split, in which 2/3 of the documents constitute the
training set and each 1/6 refers to the validation
and test set. To simulate real conditions, the train-
ing documents were randomly chosen from only
the seven most represented websites, while the
validation and test data both cover all 29 sources.
Table 2 shows some corpus statistics, which give
a hint that the validation and test set differ sig-
niﬁcantly from the training set. The corpus is
free for scientiﬁc use and can be downloaded at
http://infexba.upb.de.

1133

Loewe AG: Vorl¨auﬁge Neun-Monats-Zahlen
Kronach, [6. November 2007]REF — Das Ergebnis vor
Zinsen und Steuern (EBIT) des Loewe Konzerns konnte
in den ersten 9 Monaten 2007 um 41% gesteigert wer-
den. Vor diesem Hintergrund hebt die [Loewe AG]ORG
ihre EBIT-Prognose f¨ur das laufende Gesch¨aftsjahr auf
20 Mio. Euro an. Beim Umsatz strebt Konzernchef
[Rainer Hecker]AU T H [f¨ur das Gesamtjahr]T IM E ein
h¨oher als urspr¨unglich geplantes [Wachstum]T REND
[von 10% auf ca. 380 Mio. Euro]M ONEY an. (...)

Figure 3: An annotated document in the corpus.
The text is taken from www.boerse-online.de, but
has been modiﬁed for clariﬁcation.

4.1 Annotations

In each document, every sentence that includes a
temporal entity T and a monetary entity M and
that represents a forecast or declaration on the
revenue of an organization or market is marked
as such. T and M are annotated themselves and
linked to the sentence. Accordingly, the subject
is tagged (and linked) within the sentence bound-
aries if available, otherwise its last mention in the
preceding text. The same holds for optional en-
tities, namely a reference time, a trend indicator
and the author of a statement. Altogether, 2,075
statements are tagged in this way. As in Figure
3, only information that refers to a statement on
revenue (typed in bold face) is annotated. These
annotations may be spread across the text.

The source documents were manually selected
and prepared by our industrial partners, and two
of their employees annotated the plain document
text. With respect to the statement annotations,
a preceding pilot study yielded substantial inter-
annotator agreement, as indicated by the value
κ = 0.79 of the conservative measure Cohen’s
Kappa (Carletta, 1996). Additionally, we per-
formed a manual correction process for each an-
notated document to improve consistency.

5 Experiments

We now present experiments for the statement
identiﬁcation, which were conducted on our cor-
pus. The goal was to evaluate whether our com-
bined extraction and classiﬁcation approach suc-
ceeds in the precise identiﬁcation of sentences that

comprise a statement on revenue, while keeping
recall high. Only exact matches of the annotated
text spans were considered to be correct identiﬁ-
cations. Unlike in Section 3, we only worked on
plain text, though.

5.1 Experimental Setup
To ﬁnd candidate sentences, we implemented a
sentence splitter that can handle article elements
such as subheadings, URLs, or bracketed sen-
tences. We then constructed sophisticated, but
efﬁcient regular expressions for time and money.
They do not represent correct language, in gen-
eral, but model the structure of temporal and mon-
etary entities, and use word lists provided by do-
main experts on the lowest level.4 For feature
computation, we assumed that the closest pair of
temporal and monetary entity refers to the enclos-
ing candidate sentence.5 Since only positive in-
stances IP of statements on revenue are annotated
in our corpus, we declared all candidates, which
have no counterpart in the annotated data, to con-
stitute the negative class IN , and balanced IP and
IN by “randomly” (seed 42) removing instances
from IN .6

For the vocabularies Lpos = {P1, P2} we ﬁrst
counted the frequencies of all words in the unbal-
anced sets IP and IN . From these, we deleted
named entities, numbers and adjectives. If the pre-
ﬁx (e.g. “Umsatz”) of a word (“Umsatzplus”) oc-
curred, we only kept the preﬁx. We then ﬁltered
all terms that appeared in at least 1.25% of the in-
stances in IP and more than 3.5 times as much in
IP as in IN . The remaining words were manually
partitioned into two lists:

P1 = {umgesetzt, Umsatz, Ums¨atze, setzte} (all

of these are terms for revenue)

P2 = {Billionen, meldet, Mitarbeiter, Verband}
(trillions, announce, employee, association)

Lneg = {N1, N2} was built accordingly. In ad-
dition, we set up a list G1 with genitive pronouns

4More details are given at http://infexba.upb.de.
555% of the candidate sentences in the training set con-
tain more than one temporal and/or monetary entity, so this
assumption may lead to errors.

6We both tested undersampling and oversampling tech-

niques but saw no effective differences in the results.

1134

and determiners. Based on Lpos, Lneg and G1,
we computed the following 43 features for every
candidate sentence s:

Recall

Training

Validation Test

Sentences
Temporal entities 0.97 (0.95)
Monetary entities 0.96 (0.96)

0.98

0.96

0.98
0.97 (0.94) 0.98 (0.96)
0.96 (0.96) 0.95 (0.94)

• 1-8: Number of terms from P1 (N1) in s as
well as in the two preceding sentences and in
the following sentence.

• 9-10: Number of terms from P2 (N2) in s.
• 11: Occurrence of term from G1 next to the

monetary entity.

• 12-19: Forward (backward) distance in to-
kens between the monetary (temporal) entity
in s and a term from P1 (N1).

• 20-27: Forward (backward) distance in num-
ber of symbols from O1 = {‘.’,‘?’,‘!’} be-
tween the monetary (temporal) entity in s
and a term from P1 (N1).

• 28-43: Same as 20-27 for O2 = {‘:’,‘;’} and

O3 = {‘,’}, respectively.

We trained a linear SVM with cost parameter
C = 0.3 (selected during validation) on these fea-
tures using the Weka integration of LibSVM (Hall
et. al., 2009; Fan et. al., 2001). Further features
were evaluated, e.g. occurrences of contraposi-
tions or comparisons, but they did not improve the
classiﬁer. Instead, we noticed that we can avoid
some complex cases when we apply two rules af-
ter entity extraction:

R1: Delete temporal and monetary entities that

are directly surrounded by brackets.

R2: Delete temporal entities that contain the

word “Vorjahr” (“preceding year”).

Now, we evaluated the following ﬁve statement

identiﬁcation algorithms:

• Na¨ıve: Simply return all candidate sentences
(to estimate the relative frequency of state-
ments on revenue in the corpus).

• Baseline: Return all candidate sentences that

contain a term from the list P1.

• NEG: Use the results from Baseline. Return

all sentences that lack terms from N1.

Table 3: Recall of sentence and entity extraction.
In brackets: Recall after applying R1 and R2.

• RB: Filter candidates using R1 and R2. Then

apply NEG.

• SVM: Filter candidates using R1 and R2.

Then classify sentences with the SVM.

5.2 Results
Table 3 shows that we found at least 95% of the
sentences, time and money information, which re-
fer to a statement on revenue, in all datasets.7 We
could not measure precision for these since not all
sentences and entities are annotated in the corpus,
as mentioned in Section 4.

Results for the statement

identiﬁcation are
given in Figure 4. Generally, the test values are
somewhat lower than the validation values, but
analog in distribution. Nearly all statements were
recognized by the Na¨ıve algorithm, but only with
a precision of 0.35. In contrast, both for Baseline
and NEG already around 80% of the found state-
ments were correct. The latter paid a small gain in
precision with a signiﬁcant loss in recall. While
RB and SVM both achieved 86% precision on the
test set, SVM tends to be a little more precise as
suggested by the validation results. In terms of re-
call, SVM clearly outperformed RB with values
of 89% and 87% and was only a little worse than
the Baseline. Altogether, the F1-Measure values
show that SVM was the best performing algorithm
in our evaluation.

5.3 Error Analysis
To assess the inﬂuence of the sentence, time and
money extraction, we compared precision and re-
call of the classiﬁer on the manually annotated and
the extracted data, respectively. Table 4 shows

7We intentionally did not search for unusual entities like
“am 1. Handelstag nach dem Erntedankfest” (“the 1st trading
day after Thanksgiving”) in order not to develop techniques
that are tailored to individual cases. Also, money amounts
that lack a currency term were not recognized.

1135

0,9

0,8

0,7

0,6

0,5

0,4

0,3

.89 .90

.86 .86

.79

.77

e
v
ï
a
N

e
n

i
l

e
s
a
B

G
E
N

M
V
S

B
R

Validation

e
v
ï
a
N

e
n

i
l

e
s
a
B

G
E
N

M
V
S

B
R

Test

Precision

1,00

0,95

0,90

0,85

0,80

0,75

.92

.89

.89

e
n

i
l

e
s
a
B

e
v
ï
a
N

.83

G
E
N

M
V
S

B
R

.87

.83

G
E
N

M
V
S

B
R

e
n

i
l

e
s
a
B

e
v
ï
a
N

Validation

Test

Recall

0,9

0,8

0,7

0,6

0,5

.89

.85

.86

.86

.84

.83

e
v
ï
a
N

e
n

i
l

e
s
a
B

G
E
N

M
V
S

B
R

e
n

i
l

e
s
a
B

e
v
ï
a
N

G
E
N

M
V
S

B
R

Validation

Test

F1-Measure

Figure 4: Precision, recall and F1-Measure of the ﬁve evaluated statement identiﬁcation algorithms.
SVM is best in precision both on validation and test data and outperforms RB in recall signiﬁcantly.

that only recall differs signiﬁcantly. We found that
false statement identiﬁcations referred to the fol-
lowing noteworthy error cases.

False match: Most false positives result from
matchings of temporal and monetary entities that
actually do not refer to the same statement.

Missing criterion: Some texts describe the de-
velopment of revenue without ever mentioning
revenue. Surrogate words like “market” may be
used, but they are not discriminative enough.

Multiple criteria: Though we aimed at dis-
carding sentences, in which revenue is mentioned
without comprising a statement on it, in some
cases our features did not work out, mainly due
to intricate sentence structure.

Traps: Some sentences contain numeric values
on revenue, but not the ones looked for, as in “10%
of the revenue”. We tackled these cases, but had
still some false classiﬁcations left.

Hidden boundaries: Finally, we did not ﬁnd
all correct sentence boundaries, which can lead to
both false positives and false negatives. The pre-
dominant problem was to separate headlines from
paragraph beginnings and is partly caused by the
missing access to markup tags.

5.4 Efﬁciency

We ran the identiﬁcation algorithm on the whole
corpus using a 2 GHz Intel Core 2 Duo MacBook
with 4 GB RAM. The 1,128 corpus documents
contain 33,370 sentences as counted by our algo-
rithm itself. Tokenization, sentence splitting, time
and money extraction took only 55.2 seconds, i.e.,
more than 20 documents or 600 sentences each
second. Since our feature computation is not op-
timized yet, the complete identiﬁcation process is
a little less efﬁcient with 7.35 documents or 218

Candidates

Data

Precision

Recall

Annotated

Extracted

validation data
test data

validation data
test data

0.91
0.87

0.90
0.86

0.94
0.93

0.89
0.87

Table 4: Precision and recall of the statement
identiﬁcation on manually annotated data and on
automatically extracted data, respectively.

sentences per second. However, it is fast enough
to be used in online applications, which was our
goal in the end.

6 Conclusion

We presented a multi-stage approach for the au-
tomatic identiﬁcation and aggregation of market
statements and introduced a manually annotated
German corpus for related tasks. The approach
has been inﬂuenced by industry and is oriented
towards practical applications, but is, in general,
not speciﬁc to the German language. It relies on
efﬁcient retrieval, extraction and NLP techniques.
By now, we can precisely identify most sentences
that represent statements on revenue. This already
allows for the support of strategists, e.g. by high-
lighting such sentences in web pages, which we
currently implement as a Firefox extension. The
overall problem is complex, though, and we are
aware that human experts can do better at present.
Nevertheless, time-consuming tasks can be auto-
mated and, in this respect, the results on our cor-
pus are very promising.

Acknowledgement: This work was funded by
the project “InfexBA” of the German Federal Min-
istry of Education and Research (BMBF) under
contract number 01IS08007A.

1136

References
Ahn, David, Sisay F. Adafre, and Maarten de Rijke.
2005. Extracting Temporal Information from Open
Domain Text: A Comparative Exploration. Journal
of Digital Information Management, 3(1): 14–20.

Berekoven, Ludwig, Werner Eckert, and Peter El-
lenrieder.
2001. Marktforschung: Methodische
Grundlagen und praktische Anwendung, 9th Edi-
tion, Gabler, Wiesbaden, Germany.

Carletta, Jean. 1996. Assessing Agreement on Classi-
ﬁcation Tasks: The Kappa Statistic. Computational
Linguistics, 22: 249–254.

Lavrenko, Victor, Matt Schmill, Dawn Lawrie, Paul
2000.
Ogilvie, David Jensen, and James Allan.
In
Mining of Concurrent Text and Time Series.
Proceedings of
the 6th ACM SIGKDD Interna-
tional Conference on Knowledge Discovery and
Data Mining Workshop on Text Mining, pages 37–
44.

Lerman, Kevin, Ari Gilder, Mark Dredze, and Fer-
nando Pereira. 2008. Reading the Markets: Fore-
casting Public Opinion of Political Candidates by
News Analysis. In Proceedings of the 22nd Inter-
national Conference on Computational Linguistics,
pages 473–480.

Cramer,

Irene M., Stefan Schacht, and Andreas
Merkel. 2007. Classifying Number Expressions in
German Corpora.
In Proceedings of the 31st An-
nual Conference of the German Classiﬁcation Soci-
ety on Data Analysis, Machine Learning, and Appli-
cations, pages 553–560.

Liu, Yang, Xiangji Huang, Aijun An, and Xiaohui Yu.
2007. Arsa: A Sentiment-Aware Model for Predict-
ing Sales Performance Using Blogs. In Proceedings
of the 30th Annual International ACM SIGIR Con-
ference on Research and Development in Informa-
tion Retrieval, pages 607–614.

Mani, Inderjeet and George Wilson.

2000. Ro-
bust Temporal Processing of News. In Proceedings
of the 38th Annual Meeting of the Association for
Computational Linguistics, pages 69–76.

Ratinov, Lev and Dan Roth. 2009. Design Chal-
lenges and Misconceptions in Named Entity Recog-
nition.
In Proceedings of the Thirteenth Confer-
ence on Computational Natural Language Learn-
ing, pages 147–155.

Saquete, Estela, Rafael Mu˜noz, and Patricio Mart´ınez-
Barco. 2003. TERSEO: Temporal Expression Res-
olution System Applied to Event Ordering. Text,
Speech and Dialogue, Springer, Berlin / Heidelberg,
Germany, pages 220–228.

Stein, Benno, Sven Meyer zu Eissen, Gernot Gr¨afe,
and Frank Wissbrock. 2005. Automating Market
Forecast Summarization from Internet Data. Fourth
International Conference on WWW/Internet, pages
395–402.

Steinwart, Ingo and Andreas Christmann. 2008. Sup-

port Vector Machines, Springer, New York, NY.

Xu, Jinxi and Bruce W. Croft 2000. Improving the ef-
fectiveness of information retrieval with local con-
text analysis. ACM Transactions on Information
Systems, 18(1): 79-112.

Fan, Rong-En, Pai-Hsuen Chen, and Chih-Jen Lin.
2001. Working Set Selection Using Second Order
Information for Training Support Vector Machines.
Journal of Machine Learning Research, 6: 1889–
1918.

Ferrucci, David and Adam Lally.

2004. UIMA:
An Architectural Approach to Unstructured Infor-
mation Processing in the Corporate Research Envi-
ronment. Natural Language Engineering, 10(3–4):
pages 327–348.

Glance, Natalie, Matthew Hurst, Kamal Nigam,
Matthew Siegler, Robert Stockton, and Takashi
Tomokiyo. 2005. Deriving Marketing Intelligence
from Online Discussion.
In Proceedings of the
Eleventh International Conference on Knowledge
Discovery in Data Mining, pages 419–428.

Gottron, Thomas. 2007. Evaluating Content Extrac-
tion on HTML Documents. In Proceedings of the
2nd International Conference on Internet Technolo-
gies and Applications, pages 123–132.

Hall, Mark, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA Data Mining Software: An Up-
date. SIGKDD Explorations, 11(1).

Hirao, Tsutomu, Hideki Isozaki, Eisaku Maeda and
Yuji Matsumoto. 2002. Extracting Important Sen-
tences with Support Vector Machines. In Proceed-
ings of the 19th International Conference on Com-
putational linguistics, pages 342–348.

Koppel, Moshe and Itai Shtrimberg. 2004. Good
News or Bad News? Let the Market Decide. In Pro-
ceedings of the AAAI Spring Symposium on Explor-
ing Attitude and Affect in Text: Theories and Appli-
cations, pages 86–88.

