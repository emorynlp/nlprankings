



















































Acquisition of Phrase Correspondences Using Natural Deduction Proofs


Proceedings of NAACL-HLT 2018, pages 756–766
New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics

Acquisition of Phrase Correspondences using Natural Deduction Proofs
Hitomi Yanaka1

hitomiyanaka@g.ecc.u-tokyo.ac.jp
Koji Mineshima2

mineshima.koji@ocha.ac.jp

Pascual Martı́nez-Gómez3
pascual.mg@aist.go.jp

Daisuke Bekki2
bekki@is.ocha.ac.jp

1The University of Tokyo
2Ochanomizu University

3Artificial Intelligence Research Center, AIST
Tokyo, Japan

Abstract

How to identify, extract, and use phrasal
knowledge is a crucial problem for the
task of Recognizing Textual Entailment
(RTE). To solve this problem, we pro-
pose a method for detecting paraphrases
via natural deduction proofs of semantic
relations between sentence pairs. Our so-
lution relies on a graph reformulation of
partial variable unifications and an algo-
rithm that induces subgraph alignments
between meaning representations. Experi-
ments show that our method can automat-
ically detect various paraphrases that are
absent from existing paraphrase databases.
In addition, the detection of paraphrases
using proof information improves the ac-
curacy of RTE tasks.

1 Introduction

Recognizing Textual Entailment (RTE) is a chal-
lenging natural language processing task that aims
to judge whether one text fragment logically fol-
lows from another text fragment (Dagan et al.,
2013). Logic-based approaches have been suc-
cessful in representing the meanings of complex
sentences, ultimately having a positive impact on
RTE (Bjerva et al., 2014; Beltagy et al., 2014;
Mineshima et al., 2015, 2016; Abzianidze, 2015,
2016). Although logic-based approaches succeed
in capturing the meanings of functional or logi-
cal words, it is difficult to capture the meanings
of content words or phrases using genuine logical
inference alone. This remains a crucial problem
in accounting for lexical relations between content
words or phrases via logical inference. To solve
this problem, previous logic-based approaches use
knowledge databases such as WordNet (Miller,
1995) to identify lexical relations within a sen-

tence pair. While this solution has been success-
ful in handling word-level paraphrases, its exten-
sion to phrase-level semantic relations is still an
unsolved problem. There are three main difficul-
ties that prevent an effective identification and use
of phrasal linguistic knowledge.

The first difficulty is the presence of out-of-
context phrase relations in popular databases such
as the Paraphrase Database (PPDB) (Ganitkevitch
et al., 2013). PPDB may suggest paraphrases that
do not adhere to the context of our relevant text
segments nor to their semantic structure, which
might be problematic.

The second difficulty is finding semantic phrase
correspondences between the relevant text seg-
ments. Typical approaches only rely on sur-
face (Beltagy et al., 2013) or syntactic correspon-
dences (Arase and Tsujii, 2017), often producing
inaccurate alignments that significantly impact our
inference capabilities. Instead, a mechanism to
compute semantic phrase correspondences could
potentially produce, if available, more coherent
phrase pairs and solve the recurring issue of dis-
continuity.

The third difficulty is the intrinsic lack of cov-
erage of databases for logical inference despite
their large size. Whereas there is a relatively
small number of possible word-to-word corre-
spondences and thus their semantic relations can
be enumerated, the same is not true for all phrase
pairs that might be of interest. One alternative is to
use functions of infinite domain (e.g., cosine simi-
larity) between phrase representations (Tian et al.,
2016), but these techniques are still under devel-
opment, and we have not seen definitive successful
applications when combined with logic systems.

In this study, we tackle these three problems.
The contributions of this paper are summarized
as follows: First, we propose a new method of
detecting phrase correspondences through natu-

756



ral deduction proofs of semantic relations for a
given sentence pair. Second, we show that our
method automatically extracts various paraphrases
that compensate for a shortage in previous para-
phrase databases. Experiments show that ex-
tracted paraphrases using proof information im-
prove the accuracy of RTE tasks.

2 Related Work

In this section, we review previous logical in-
ference systems that are combined with lexi-
cal knowledge. The RTE system developed by
Abzianidze (2016) uses WordNet as axioms and
adds missing knowledge manually from the train-
ing dataset; however, this technique requires con-
siderable human effort and is not extended to han-
dle phrasal knowledge.

Martı́nez-Gómez et al. (2017) proposed an RTE
system with an on-the-fly axiom injection mech-
anism guided by a natural deduction theorem
prover. Pairs of unprovable sub-goals and plau-
sible single premises are identified by means of
a variable unification routine and then linguis-
tic relations between their logical predicates are
checked using lexical knowledge such as Word-
Net and VerbOcean (Chklovski and Pantel, 2004).
However, this mechanism is limited to capturing
word-to-word relations within a sentence pair.

Bjerva et al. (2014) proposes an RTE system
where WordNet relations are used as axioms for
word-to-word knowledge in theorem proving. For
phrasal knowledge, PPDB is used to rephrase an
input sentence pair instead of translating para-
phrases into axioms. However, this solution ig-
nores logical contexts that might be necessary
when applying phrasal knowledge. Moreover, it
does not apply to discontinuous phrases.

Beltagy et al. (2016) uses WordNet and PPDB
as lexical knowledge in the RTE system. To in-
crease their coverage of phrasal knowledge, the
system combines a resolution strategy to align
clauses and literals in a sentence pair and a sta-
tistical classifier to identify their semantic relation.
However, this strategy only considers one possible
set of alignments between fragments of a sentence
pair, possibly causing inaccuracies when there are
repetitions of content words and meta-predicates.

In our research, we propose an automatic phrase
abduction mechanism to inject phrasal knowledge
during the proof construction process. In addition,
we consider multiple alignments by backtracking

the decisions on variable and predicate unifica-
tions, which is a more flexible strategy. We rep-
resent logical formulas using graphs, since this is
a general formalism that is easy to visualize and
analyze. However, we use natural deduction (see
Section 3.2) as a proof system instead of Markov
Logic Networks for inference. Some research has
investigated graph operations for semantic pars-
ing (Reddy et al., 2014, 2016) and abstractive sum-
marization (Liu et al., 2015); we contribute to
these ideas by proposing a subgraph mapping al-
gorithm that is useful for performing natural lan-
guage inferences.

Considerable research efforts have been focused
on the identification and extraction of paraphrases.
One successful technique is associated with bilin-
gual pivoting (Bannard and Callison-Burch, 2005;
Zhao et al., 2008), in which alternative phrase
translations are used as paraphrases at a certain
probability. However, this technique requires
large bilingual parallel corpora; moreover, word
alignment errors likely cause noisy paraphrases.
Another strategy is to extract phrase pairs from
a monolingual paraphrase corpus using align-
ments between syntactic trees, guided by a lin-
guistically motivated grammar (Arase and Tsujii,
2017). The main difference between these stud-
ies and ours is that they typically attempt align-
ment between words or syntactic trees, whereas
we perform alignments between meaning repre-
sentations, which enables the acquisition of more
general paraphrases by distinguishing functional
words from content words. This point is impor-
tant in distinguishing among different semantic re-
lations (e.g., antonyms and synonyms). In addi-
tion, word and syntactic alignments potentially ig-
nore coreferences, making it difficult to find rela-
tions between many-to-many sentences. Semantic
alignments enable this because coreferences must
refer to the same variable as the original entity.

3 Logic-based Approach to RTE

3.1 Meaning representation

In logic-based approaches to RTE, a text T and a
hypothesisH are mapped onto logical formulas T ′

and H ′. To judge whether T entails H , we check
whether T ′ ⇒ H ′ is a theorem in a logical system.

For meaning representations, we use Neo-
Davidsonian event semantics (Parsons, 1990). In
this approach, a verb is analyzed as a one-place
predicate over events. Both the arguments of a

757



y1skip

x1 girl

x2 rope

x3 sidewalk

subj

obj

on

Figure 1: A graph for the basic formula (2).

verb and modifiers are linked to events by seman-
tic roles, and the entire sentence is closed by ex-
istential quantification over events. For example,
(1) is mapped onto (2).

(1) A girl is skipping rope on a sidewalk.

(2) ∃x1∃x2∃x3∃y1 (girl(x1) ∧ rope(x2)∧
sidewalk(x3) ∧ skip(y1) ∧ (subj(y1) = x1) ∧
(obj(y1)=x2) ∧ on(y1, x3))

We use xi as a variable for entities and yj for
events. In this semantics, we represent all con-
tent words (e.g., girl and skip) as one-place predi-
cates. Regarding functional words, we represent a
preposition like on as a two-place predicate, e.g.,
on(y1, x3). We also use a small set of semantic
roles such as subj and obj as a functional term
and use equality (=) to connect an event and its
participant, as in subj(y1)=x1.

To be precise, the set of atomic formulas A in
this event semantics is defined by the rule

A ::= F(t) | G(t, u) | t = u
where F(t) is a one-place predicate (for con-
tent words), G(t, u) is a two-place predicate (for
prepositions), t and u are a term. A term is de-
fined as a constant, a variable, or a functional term
of the form f(t) where f is a semantic role and t
is a term.

We call a formula constructed by conjunctions
and existential quantifiers a basic formula in event
semantics. Thus, a set of basic formulas ϕ in event
semantics is defined as:

ϕ ::= A | ϕ ∧ ϕ | ∃t ϕ
The formula in (2) is an instance of a basic
formula, which captures the predicate-argument
structure of a sentence.

On top of the system of basic formulas, we have
a full language of event semantics with negation
(¬), disjunction (∨), implication (→), and a uni-
versal quantifier (∀). These operators are used to
represent additional logical features.

There is a natural correspondence between ba-
sic formulas and directed acyclic graphs (DAGs).
Figure 1 shows an example1. In the graph rep-
resentation, constants and variables correspond to
vertices; both two-place predicates for preposi-
tions (e.g., on(y1, x1)) and functional terms for
semantic roles (e.g., subj(y1) = x1) are repre-
sented as edges. A one-place predicate F(t) in a
logical formula can be represented as a functional
relation isa(t,F), where isa is an expression re-
lating a term t and a predicate F represented as a
vertex. The isa edges are unlabeled for simplicity.

3.2 Natural deduction and word abduction

We use the system of natural deduction (Prawitz,
1965; Troelstra and Schwichtenberg, 2000) to cap-
ture phrase correspondences from a sentence pair
(T,H), following the strategies for word axiom
injection developed by Martı́nez-Gómez et al.
(2017) and Yanaka et al. (2017). The sentence
pair (T,H) is first mapped to a pair of formulas
(T ′, H ′). T ′ is initially set to the premise P , and
H ′ is set to the goal G to be proved.

If formulas P andG are basic formulas, then the
proving strategy is to decompose them into a set
of atomic formulas using inference rules for con-
junctions and existential quantifiers. The premise
P is decomposed into a pool of premises P =
{pi(θi) | i ∈ {1, . . . ,m}}, where each pi(θi) is
an atomic formula and θi is a list of terms appear-
ing in pi(θi). The goal G is also decomposed into
a set of sub-goals G = {gj(θ′j) | j ∈ {1, . . . , n}},
where θ′j is a list of terms appearing in gj(θ

′
j).

The proof is performed by searching for a
premise pi(θi) whose predicate matches that of a
sub-goal gj(θ′j). If such a premise is found, then
variables in θ′j are unified to those in θi and the
sub-goal gj(θ′j) can be removed from G. If all the
sub-goals can be removed, we prove T ′ → H ′.
In the presence of two or more variables with the
same predicate, there might be multiple possible
variable unifications. Modern theorem provers ex-
plore these multiple possibilities in search of a
configuration that proves a theorem.

Sub-goals may remain unproved when T log-
ically does not entail H i.e., when there are no
premise predicates pi that are matched with gj . In
this case, the system tries word axiom injection,
called word abduction. More specifically, if there

1See Jones (2016) for some variants of graphical repre-
sentations of logical formulas.

758



is a premise pi(θi) whose predicate has a linguis-
tic relation (according to linguistic knowledge2)
with that of a sub-goal gj(θ′j), then variables in θ

′
j

are unified with those in θi and the sub-goal gj(θ′j)
can be removed from G.

3.3 Graph illustration
Figure 2 shows an example to illustrate how the
system works. To begin with, the input sentence
pair (T,H) is mapped onto a pair of formulas,
(T ′, H ′). T ′ is initially placed to the premise P ,
and H ′ to the goal G. Note that these are basic
formulas, and they are thus decomposed to the fol-
lowing sets of formulas P and G, respectively:
P = {lady(x1),meat(x2), cut(y1),up(y1),

precisely(y1), subj(y1)=x1,obj(y1)=x2}
G = {woman(x3),meat(x4), cut(y2),piece(x5),

into(y2, x5), subj(y2)=x3,obj(y2)=x4}
Steps 1 to 3 in Figure 2 demonstrate the vari-

able unification routine and word axiom injection
using graphs. Note that in step 1, all variables in
formulas in P or G are initially different.

In step 2, we run a theorem proving mecha-
nism that uses graph terminal vertices as anchors
to unify variables between formulas inP and those
in G. The premise meat(x2) in P matches the
predicate meat of the sub-goal meat(x4) in G
and the variable unification x4 := x2 is applied
(and similarly for the sub-goal cut(y2) in G with
the variable unification y2 := y1).

In step 3, we use the previous variable unifica-
tion on y1, the subj edge in P and G and the ax-
iom ∀x.lady(x) → woman(x) from external knowl-
edge to infer that x3 := x1.

4 Phrase Abduction

There is one critical reason that the word-to-
word axiom injection described in Section 3.2
fails to detect phrase-to-phrase correspondences.
That is, the natural deduction mechanism decom-
poses the goal G into atomic sub-goals that are
then proved one-by-one (word-by-word), indepen-
dently of each other except for the variable unifi-
cation effect. This mechanism is particularly prob-
lematic when we attempt to prove phrases that
resist decomposition, two-place predicates (e.g.,
into(x, y)), or failures in variable unification (e.g.,
due to inaccurate semantics). Thus, we propose a
method to detect phrase-to-phrase correspondence
through natural deduction proofs.

2As given in a linguistic ontology or database such as
WordNet or VerbOcean.

4.1 Phrase pair detection

We detect phrase-to-phrase entailing relations be-
tween T ′ and H ′ by finding alignments between
the subgraphs of their meaning representations
when T ′ ⇒ H ′ or T ′ ⇒ ¬H ′ hold. Find-
ing subgraph alignments is a generalization of
the subgraph isomorphism problem, which is NP-
complete3. In this paper, we approximate a solu-
tion to this problem by using a combination of a
backtracking variable unification and a determin-
istic graph search on the neighborhood of non-
unified variables.

Using our running example in Figure 2, step 4
displays our proposed subgraph alignment. The
variable x5 in the graph of G cannot be unified
with any variable in the graph of P . This is a
very common case in natural language inferences,
as there might be concepts in H that are not di-
rectly supported by concepts in T . In this research,
we propose spanning a subgraph starting at non-
unified variables (e.g., x5 in G) whose boundaries
are semantic roles (e.g., subj, obj). Its candidate
semantics from P are then the attributes of its cor-
responding unified variables from G (e.g. cut up
precisely→ cut into pieces).

4.2 Graph alignments

To formalize this solution we introduce some
graph notation. Let V = Vu ∪ V ū ∪ L be the
set of vertices, where Vu is the set of unified vari-
ables (e.g. x1, x2, y1), V ū is the set of non-unified
variables (e.g. x5), and L is a set of predicates
(e.g., lady, woman). Let E be the set of labeled,
directed edges 〈v, l, v′〉 where v, v′ ∈ V and l are
labels that may represent a functional relation isa,
a preposition or a semantic role. We denote a set
of two-place predicates for prepositions as PREP
and a set of functional terms for semantic roles as
ARGS; e.g., ARGS = {subj,obj}. A graph that
represents P is then a tuple GP = 〈VP , EP〉, and
similarly, for G, GG = 〈VG , EG〉.

We can now define a function to span a
subgraph in the neighborhood of non-unified
variables v ∈ V ūG in the graph of G. We call
a connected set of edges in which no semantic
roles appear, i.e., {〈v, l, v′〉 | l 6∈ ARGS}, a
phrase set. Let E(x) be the phrase set in E
such that each vertex is connected to x with
an incoming or outgoing edge, that is, E(x) =
{(vi, l, vk) ∈ E | (x = vi ∨ x = vk) ∧ l 6∈ ARGS} .

3Emmert-Streib et al. (2016) gives a good overview.

759



y1

cut
up

precisely

x1 x2lady meat

subj obj

y2

cut

x3 x4

x5

woman meat

piece

subj obj

into

T : A lady is cutting up some meat precisely H: Some meat is being cut into pieces by a woman
T ′ : ∃x1∃x2∃y1(lady(x1) ∧ meat(x2) ∧ cut(y1) ∧

up(y1)∧precisely(y1)∧subj(y1, x1)∧obj(y1, x2))
H ′ : ∃x3∃x4∃x5∃y2(meat(x4) ∧ woman(x3) ∧ cut(y2) ∧
piece(x5) ∧ into(y2, x5) ∧ subj(y2, x3) ∧ obj(y2, x4))

Step 1:
Make graphs

from formulas.

y1

cut
up

precisely

x1 x2lady meat

subj obj

y1

cut

x3 x2

x5

woman meat

piece

subj obj

into

Step 2:
Anchor terminal

vertices and unify
variables x4 := x2

and y2 := y1.

y1

cut
up

precisely

x1 x2lady meat

subj obj

y1

cut

x1 x2

x5

woman meat

piece

subj obj

into

Step 3:
Use graph constraints

and knowledge
(lady is a woman)
to unify x3 := x1.

y1

cut
up

precisely

x1 x2lady meat

subj obj

y1

cut

x1 x2

x5

woman meat

piece

subj obj

into

Step 4:
Induce subgraph

alignment with non-
unified variable x5.

Figure 2: A graph representation of a theorem proving routine on basic formulas and variable unification.
Dotted circles represent non-unified variables at each step, whereas edges without labels are attributes.
The graph of the left side is the set of premises P and the graph of the right side is the set of sub-goals
G. Colored subgraphs represent a word or a phrase to which our axiom injection mechanism applies.

Note that E(x) induces a subgraph in a given
graph G and the condition l /∈ ARGS sets the
boundaries of the subgraph by excluding the
semantic roles of verb phrases. Given two phrase
sets E and E′, we say E′ is reachable from E,
written E ∼ E′, if E and E′ share at least one
variable vertex. Let ∼∗ be the transitive closure of
∼. Given a set of edges EG and a variable v, we
define the extended phrase set, written Reach(v),
as follows:

Reach(v) = {e ∈ E | EG(v) ∼∗ E}
that is, the set of edges e that can be reached from
v without crossing an edge with a semantic role

label. This function defines a partition or equiva-
lence class for non-unified variables v ∈ V ūG , and
each of these partitions induce a (possibly discon-
tinuous) phrase in G that remains unproved.

The corresponding subgraph in P to each of
these partitions is given by the vertices and edges
connected with a path of length one to the unified
variables that appear in Reach(v). That is,

Corr(v) = {e ∈ EP(v′), v′ ∈ V [v]G ∩ VP}

where V [v]G denotes the vertices in the subgraph of
G induced by the partition Reach(v).

760



A subgraph alignment betweenP and G is given
by the pair of 〈Corr(v),Reach(v)〉 for all v ∈ V ūG ,
where the phrases can be read from the predicates
in the vertices and edges labeled with prepositions.

We define a mapping (·)• from a labeled edge
〈v, l, v′〉 to an atomic formula as follows.

〈v, l, v′〉• =





v′(v) if l is isa
l(v, v′) if l ∈ PREP
l(v) = v′ if l ∈ ARGS

Let E be a set of labeled edges, and let E• be{
〈v, l, v′〉• | 〈v, l, v′〉 ∈ E

}
. The phrase axiom

generated for each non-unified variable v ∈ V ūG
is defined as
∀θC.(

∧
Corr(v)• → ∃θR. (

∧
Reach(v)•)),

where θC is a set of free variables appearing in
Corr(v)• (which includes v) and θR is a set of
free variables appearing in Reach(v)• but not in
Corr(v)•.

In Figure 2, the only non-unified variable in the
sub-goal in step 4 is x5, that is, V ūG = {x5}. Then,
starting from the variable x5, Reach(x5) is

{〈y1, into, x5〉 , 〈x5, isa,piece〉} .

Now V [x5]G = {y1, x5}, and thus Corr(x5) is
{〈y1, isa, cut〉 , 〈y1, isa,up〉 , 〈y1, isa,precisely〉} .

Finally, the following is the axiom generated from
〈Corr(x5),Reach(x5)〉4.

∀y1(cut(y1) ∧ up(y1) ∧ precisely(y1) →
∃x5(into(y1, x5) ∧ piece(x5))).

4.3 Non-basic formulas
If formulas P and G are not basic formulas (i.e.,
they contain logical operators other than ∧ and
∃), they are decomposed according to inference
rules of natural deduction. There are two types
of inference rules: introduction rules decompose
a goal formula into smaller sub-goals, and elimi-
nation rules decompose a formula in the pool of
premises into smaller ones. Figure 3 shows intro-
duction rules and elimination rules for decompos-
ing non-basic formulas including negation, dis-
junction, implication, and a universal quantifier.
By applying inference rules, a proof of non-basic
formulas appearing in sub-goals can be decom-
posed to a set of subproofs that only have basic
formulas in sub-goals. If a universal quantifier ap-
pears in premises, it is treated in the same way as
other premises.

4Note that this axiom is logically equivalent to
∀y1(cut(y1) ∧ up(y1) ∧ precisely(y1) →
∃x5(cut(y1) ∧ into(y1, x5) ∧ piece(x5)))

indicated in the colored subgraphs in step 4 of Figure 2.

P :

G : A ∨ B

P :

G : A

∨-I

P :

G : A ∨ B

P :

G : B

∨-I

P : A ∨ B
G : C

P : A
G : C

P : B
G : C

∨-E

P :

G : A → B

P : A
G : B

→-I

P : A → B
G : B

P :

G : A

→-E

P :

G : ¬A

P : A
G : False

¬-I

P : ¬A
G : False

P :

G : A

¬-E

P :

G : ∀xA(x)

P :

G : A(x)

∀-I

P : ∀xA(x)
G :

P : A(t)
G :

∀-E

Figure 3: Inference rules used for decomposing
non-basic formulas. P is a premise andG is a sub-
goal. The initial formulas are at the top, with the
formulas obtained by applying the inference rules
shown below.

P : ¬∃y1∃x1(man(x1) ∧ cut(y1) ∧ potato(x2)
∧ (subj(y1) = x1) ∧ (obj(y1) = x2)

G : ¬∃y1∃x1∃x2∃x3(man(x1) ∧ slice(y1) ∧ potato(x2)
∧ into(y1, x3)∧piece(x3)∧(subj(y1)=x1)∧ (obj(y1)=x2)

P : ¬∃y1∃x1(man(x1) ∧ cut(y1) ∧ potato(x2)
∧ (subj(y1) = x1) ∧ (obj(y1) = x2)

P0 : ∃y1∃x1∃x2∃x3(man(x1) ∧ slice(y1) ∧ potato(x2)
∧ into(y1, x3)∧piece(x3)∧(subj(y1)=x1)∧ (obj(y1)=x2)

G0 : False

P0 : ∃y1∃x1∃x2∃x3(man(x1) ∧ slice(y1) ∧ potato(x2)
∧ into(y1, x3)∧piece(x3)∧(subj(y1)=x1)∧ (obj(y1)=x2)

G1 : ∃y1∃x1(man(x1) ∧ cut(y1) ∧ potato(x2)
∧ (subj(y1) = x1) ∧ (obj(y1) = x2)

¬-I (G)

¬-E (P )

Figure 4: Proof process for the contradiction.

For example, consider the following sentence
pair with the gold label “no” (contradiction):
T : A man is not cutting a potato
H: A man is slicing a potato into pieces

Figure 4 shows the proof process of T ′ ⇒ ¬H ′.
To prove the contradiction, the formulas T ′ and
¬H ′ are set to P and G, respectively. Then, the
negation in G is removed by applying the intro-
duction rule (¬-I) toG. Here, False is the propo-
sitional constant denoting the contradiction. In
the second stage of the proof, the goal is to prove
False in G0 from the two premises P and P0. By
applying (¬-E) to P , we can eliminate the nega-
tion from P , resulting in the new goal G1.

As both the premise P0 and the sub-goal G1 are

761



basic formulas, the procedure described in the pre-
vious sections applies to the pair (P0, G1); these
basic formulas are decomposed into atomic ones,
and then the word-to-word abduction generates the
desired axiom ∀y1(cut(y1)→slice(y1)). Finally,
the graph alignment applies in the same way as
described in Figure 2, which generates the phrase
axiom:

∀y1(cut(y1) → ∃x5(into(y1, x5) ∧ piece(x5)))

Using this axiom, one can complete the proof of
the contradiction between T ′ and H ′.

5 Experiments

5.1 Dataset selection

We use the SemEval-2014 version of the SICK
dataset (Marelli et al., 2014) for evaluation. The
SICK dataset is a dataset for semantic textual sim-
ilarity (STS) as well as for RTE. It was origi-
nally designed for evaluating compositional distri-
butional semantics, so it contains logically chal-
lenging problems involving quantifiers, negation,
conjunction, and disjunction, as well as inferences
with lexical and phrasal knowledge.

The SNLI dataset (Bowman et al., 2015) con-
tains inference problems requiring phrasal knowl-
edge. However, it is not concerned with logi-
cally challenging expressions; the semantic rela-
tionships between a premise and a hypothesis are
often limited to synonym/hyponym lexical sub-
stitution, replacements of short phrases, or exact
word matching. This is because hypotheses are of-
ten parallel to the premise in structures and vocab-
ularies. The FraCaS dataset (Cooper et al., 1994)
also contains logically complex problems. How-
ever, it is confined to purely logical inferences
and thus does not contain problems requiring in-
ferences with lexical and phrasal knowledge. For
these reasons, we choose the SICK dataset to eval-
uate our method of using logical inference to ex-
tract phrasal knowledge.

The SICK dataset contains 9927 sentence pairs
with a 5000/4927 training/test split. These sen-
tence pairs are manually annotated with three
types of labels yes (entailment), no (contradic-
tion), or unknown (neutral) (see Table 1 for exam-
ples). In RTE tasks, we need to consider a direc-
tional relation between words such as hypernym
and hyponym to prove entailment and contradic-
tion. Hence, to extract phrasal knowledge for RTE
tasks, we use the training data whose gold label is

entailment or contradiction, excluding those with
the neutral label.

5.2 Experimental setup

For the natural deduction proofs, we used
ccg2lambda (Martı́nez-Gómez et al., 2016)5, a
higher-order automatic inference system, which
converts CCG derivation trees into semantic rep-
resentations and conducts natural deduction proofs
automatically. We parsed the tokenized sentences
of the premises and hypotheses using three wide-
coverage CCG parsers: C&C (Clark and Curran,
2007), EasyCCG (Lewis and Steedman, 2014),
and depccg (Yoshikawa et al., 2017). CCG deriva-
tion trees (parses) were converted into logical se-
mantic representations based on Neo-Davidsonian
event semantics (Section 3.1). The validation of
semantic templates used for semantic representa-
tions was conducted exclusively on the trial split
of the SICK dataset. We used Coq (Bertot and
Castran, 2010), an interactive natural deduction
theorem prover that we run fully automatically
with a number of built-in theorem-proving rou-
tines called tactics, which include first-order logic.

We compare phrase abduction with different ex-
perimental conditions. No axioms is our sys-
tem without axiom injection. W2W is the previ-
ous strategy of word abduction (Martı́nez-Gómez
et al., 2017). P2P is our strategy of phrase ab-
duction; W2W+P2P combines phrase abduction
with word abduction. In addition, we compare
our system with three purely logic-based (unsuper-
vised) approaches: The Meaning Factory (Bjerva
et al., 2014), LangPro (Abzianidze, 2015), and
UTexas (Beltagy et al., 2014). We also com-
pare our system with machine learning-based ap-
proaches: the current state-of-the-art deep learn-
ing model GRU (Yin and Schütze, 2017), a log-
linear regression model SemEval-2014 best (Lai
and Hockenmaier, 2014), and a hybrid approach
combining a logistic regression model and proba-
bilistic logic PL+eclassif (Beltagy et al., 2016).

5.3 Extracted paraphrases

We extracted 9445 axioms from the SICK train-
ing dataset. The proving time average to extract
phrasal axioms was only 3.0 seconds for a one-
sentence pair6. Table 2 shows some examples of

5Available at https://github.com/mynlp/ccg2lambda.
6Ours is a polynomial-time instance of the graph match-

ing problem, where the vertex cover set (maximum number
of variables in a phrase) is bounded to a small constant.

762



ID Text Hypothesis Entailment
3941 A boy is looking at a calendar There is nobody checking a calendar No
5938 Vegetables are being put into a pot by a man Someone is pouring ingredients into a pot Yes
5930 The man is not doing exercises Two men are fighting Unknown

Table 1: Examples in the SICK dataset with different entailment labels and similarity scores.

Kind Text Hypothesis

noun phrase
A blond woman is sitting on the roof of A woman with blond hair is sitting on the roof of
a yellow vehicle, and two people are inside a yellow vehicle, and two people are inside

verb phrase The person is setting fire to the cameras Some cameras are being burned by a personwith a blow torch

verb phrase
A man and a woman are walking together A man and a woman are hiking
through the woods through a wooded area

prepositional phrase
A child, who is small, is outdoors climbing A small child is outdoors climbing steps
steps outdoors in an area full of grass in a grassy area

antonym A woman is putting make-up on The woman is removing make-up

Table 2: Examples of phrase alignments constructed by phrasal axiom injection.

Prec. Rec. Acc.
GRU − − 87.1
PL+eclassif − − 85.1
SemEval2014 Best Score 81.6 81.9 84.6
The Meaning Factory 93.6 60.6 81.6
LangPro 98.0 58.1 81.4
UTexas − − 80.4
W2W+P2P 84.2 77.3 84.3
W2W 97.1 63.6 83.1
P2P 85.6 72.1 83.0
No axioms 98.9 46.5 76.7
Table 3: RTE results on the SICK dataset.

paraphrases we extracted from the natural deduc-
tion proof in the training set. In particular, the
examples of verb phrases show our method has
the potential to capture long paraphrases. Each
paraphrase in Table 2 is not contained in Word-
Net and PPDB. There are many instances of non-
contiguous phrases in the SICK dataset, in par-
ticular, verb-particle phrases. Shown in Table 2,
our semantic alignment can detect non-contiguous
phrases through the variable unification process,
which is one of the main advantages over other
shallow/syntactic methods. In addition, Table 2
shows our method is not limited to hypernym or
hyponym relations, but it is also capable for de-
tecting antonym phrases.

5.4 RTE evaluation results

Table 3 shows the experimental results. The re-
sults show that the combination of word abduc-
tion and phrase abduction improved the accuracy.
When the W2W+P2P result is substituted for the
W2W result, there is a 1.1% increase in accuracy

(from 83.1% to 84.3%). The accuracy of P2P
is almost equal to that of W2W. This is because
the recall improves from 63.6% to 72.1% while
the precision decreases from 97.1% to 85.6%.
The increase in false positive cases caused this
result; some details of false positive cases are
described in the next subsection. W2W+P2P
outperformed other purely logic-based systems.
The machine learning-based approaches outper-
form W2W+P2P, but unlike these approaches, pa-
rameter estimation is not used in our method. This
suggests that our method has the potential to in-
crease the accuracy by using a classifier.

5.5 Positive examples and error analysis

Table 4 shows some positive and negative exam-
ples on RTE with the SICK dataset. For ID 9491,
the sentence pair requires the paraphrase from a
field of brown grass to a grassy area, not included
in previous lexical knowledges. Our phrasal ax-
iom injection can correctly generate this para-
phrase from a natural deduction proof, and the sys-
tem proves the entailment relation.

ID 2367 is also a positive example of phrasal ax-
iom injection. The phrasal axiom between set fire
to cameras and burn cameras with a blow torch
was generated. This example shows that our se-
mantic alignment succeeds in acquiring a general
paraphrase by separating logical expressions such
as some from content words and also by account-
ing for syntactic structures such as the passive-
active alternation.

For ID 3628, the axiom shown in the table was
extracted from the following sentence pair with

763



ID Sentence Pair Gold Pred Axiom

9491 A group of four brown dogs are playing in a field of brown grass Yes Yes ∀x1(field(x1) ∧ brown(x1) ∧ grass(x1)Four dogs are playing in a grassy area → grassy(x1) ∧ area(x1))
2367 A person is burning some cameras with a blow torch Yes Yes ∀x1∀y1(burn(y1) ∧ with(y1, x1) ∧ blow torch(x1) ∧ camera(obj(y1))The person is setting fire to the cameras → set(y1) ∧ fire(obj(y1)) ∧ to(y1,obj(y1)) ∧ camera(obj(y1)))
3628 A pan is being dropped over the meat Unk Yes ∀y1(pan(obj(y1)) → into(y1,obj(y1)))The meat is being dropped into a pan

96 A man is jumping into an empty poolThere is no biker jumping in the air Unk No
∀y1(jump(y1) → ∃x1(in(y1, x1) ∧ air(x1)))
∀y1(man(y1) → biker(y1))

408 A group of explorers is walking through the grass Yes UnkSome people are walking

Table 4: Positive and negative examples on RTE from the SICK dataset.

their entailment label:
T1: A woman is putting meat in a pan
H1: Someone is dropping the meat into a pan
But the phrase drop over does not entail the phrase
drop into, and a proof for the inference is over-
generated in ID 3628. We extracted all possible
phrasal axioms from the training dataset, so noisy
axioms can be extracted as a consequence of mul-
tiple factors such as parsing errors or potential dis-
ambiguation in the training dataset. One possible
solution for decreasing such noisy axioms would
be to use additive composition models (Tian et al.,
2016) and asymmetric learnable scoring functions
to calculate the confidence on these asymmetric
entailing relations between phrases.

ID 96 is also an example of over-generation
of axioms. The first axiom, ∀y1(jump(y1) →
∃x1(in(y1, x1) ∧ air(x1))) was extracted from the
proof of T1 ⇒ H1:
T1: A child in a red outfit is jumping on a trampoline
H1: A little boy in red clothes is jumping in the air
The second axiom ∀y1(man(y1) → biker(y1)) was
extracted from the proof of T2 ⇒ H2:
T2: A man on a yellow sport bike is doing a wheelie and a
friend on a black bike is catching up

H2: A biker on a yellow sport bike is doing a wheelie and a
friend on a black bike is catching up

Although these axioms play a role in the proofs
of T1 ⇒ H1 and T2 ⇒ H2, the wrong ax-
iom ∀y1(man(y1) → biker(y1)) causes the over-
generation of a proof for the inference in ID 96.
The correct one would rather be ∀x1∀y1(man(y1) ∧
on(y1, x1)∧bike(x1) → biker(y1)). In this case, it is
necessary to bundle predicates in a noun-phrase by
specifying the types of a variable (entity or event)
when making phrase alignments.

For ID 408, the word explorer is not con-
tained in the training entailment dataset and
hence the relevant axiom ∀x1(explorer(x1) →
people(x1)) was not generated. While our logic-
based method enables detecting semantic phrase
correspondences in a sentence pair in an unsuper-

vised way, our next step is to predict unseen para-
phrases of this type.

6 Conclusion

In this paper, we proposed a method of detect-
ing phrase correspondences through natural de-
duction proofs of semantic relations between sen-
tence pairs. The key idea is to attempt a proof with
automatic phrasal axiom injection by the careful
management of variable sharing during the proof
construction process. Our method identifies se-
mantic phrase alignments by monitoring the proof
of a theorem and detecting unproved sub-goals
and logical premises. The method of detecting se-
mantic phrase alignments would be applicable to
other semantic parsing formalisms and meaning
representation languages such as abstract meaning
representations (AMR) (Banarescu et al., 2013).
Experiment results showed that our method de-
tected various phrase alignments including non-
contiguous phrases and antonym phrases. This re-
sult may contribute to previous phrase alignment
approaches. The extracted phrasal axioms im-
proved the accuracy of RTE tasks.

In future work, we shall enhance this method-
ology of phrasal axiom injection to predict unseen
paraphrases. The pairs of premises and sub-goals
that can be detected through the proof process con-
duct semantic alignments in a sentence pair. With
the use of an additive composition model of dis-
tributional vectors, we can evaluate the validity of
such semantic alignments. A combination of our
phrasal axiom injection and additive composition
model of distributional vectors has the potential to
detect unseen paraphrases in a sentence pair.

Acknowledgments

We thank the three anonymous reviewers for their
detailed comments. This work was supported by
JST CREST Grant Number JPMJCR1301 and AIP
Challenge Program, Japan.

764



References
Lasha Abzianidze. 2015. A tableau prover for natural

logic and language. In Proceedings of the 2015 Con-
ference on Empirical Methods in Natural Language
Processing. Association for Computational Linguis-
tics, Lisbon, Portugal, pages 2492–2502.

Lasha Abzianidze. 2016. Natural solution to FraCaS
entailment problems. In Proceedings of the 5th
Joint Conference on Lexical and Computational Se-
mantics. Association for Computational Linguistics,
Berlin, Germany, pages 64–74.

Yuki Arase and Jun’ichi Tsujii. 2017. Monolingual
phrase alignment on parse forests. In Proceedings of
the 2017 Conference on Empirical Methods in Nat-
ural Language Processing. Association for Compu-
tational Linguistics, Copenhagen, Denmark, pages
1–11.

Laura Banarescu, Claire Bonial, Shu Cai, Madalina
Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider. 2013. Abstract meaning representation
for sembanking. In Proceedings of the 7th Linguis-
tic Annotation Workshop and Interoperability with
Discourse. Association for Computational Linguis-
tics, Sofia, Bulgaria, pages 178–186.

Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Pro-
ceedings of the 43rd Annual Meeting on Associa-
tion for Computational Linguistics. Association for
Computational Linguistics, Stroudsburg, PA, USA,
pages 597–604.

Islam Beltagy, Cuong Chau, Gemma Boleda, Dan
Garrette, Katrin Erk, and Raymond Mooney. 2013.
Montague meets Markov: Deep semantics with
probabilistic logical form. In Proceedings of the
Second Joint Conference on Lexical and Computa-
tional Semantics (*Sem-2013). Atlanta, GA, pages
11–21.

Islam Beltagy, Stephen Roller, Gemma Boleda, Ka-
trin Erk, and Raymond J. Mooney. 2014. UTexas:
Natural language semantics using distributional se-
mantics and probabilistic logic. In Proceedings
of the 8th International Workshop on Semantic
Evaluation (SemEval-2014). Association for Com-
putational Linguistics and Dublin City University,
Dublin, Ireland, pages 796–801.

Islam Beltagy, Stephen Roller, Pengxiang Cheng, Ka-
trin Erk, and Raymond J. Mooney. 2016. Repre-
senting meaning with a combination of logical and
distributional models. Computational Linguistics
42(4):763–808.

Yves Bertot and Pierre Castran. 2010. Interac-
tive Theorem Proving and Program Development:
Coq’Art The Calculus of Inductive Constructions.
Springer Publishing Company, Incorporated, New
York, USA.

Johannes Bjerva, Johan Bos, Rob van der Goot, and
Malvina Nissim. 2014. The Meaning Factory: For-
mal semantics for recognizing textual entailment
and determining semantic similarity. In Proceed-
ings of the 8th International Workshop on Semantic
Evaluation (SemEval-2014). Association for Com-
putational Linguistics and Dublin City University,
Dublin, Ireland, pages 642–646.

Samuel R. Bowman, Gabor Angeli, Christopher Potts,
and Christopher D. Manning. 2015. A large anno-
tated corpus for learning natural language inference.
In Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing. Associa-
tion for Computational Linguistics, Lisbon, Portu-
gal, pages 632–642.

Timothy Chklovski and Patrick Pantel. 2004. Verbo-
cean: Mining the web for fine-grained semantic verb
relations. In Proceedings of the 2004 Conference
on Empirical Methods in Natural Language Pro-
cessing. Association for Computational Linguistics,
Barcelona, Spain, pages 33–40.

Stephen Clark and James R. Curran. 2007. Wide-
coverage efficient statistical parsing with CCG
and log-linear models. Computational Linguistics
33(4):493–552.

Robin Cooper, Richard Crouch, Jan van Eijck, Chris
Fox, Josef van Genabith, Jan Jaspers, Hans Kamp,
Manfred Pinkal, Massimo Poesio, Stephen Pulman,
et al. 1994. FraCaS–a framework for computational
semantics. Deliverable D6.

Ido Dagan, Dan Roth, Mark Sammons, and Fabio Mas-
simo Zanzotto. 2013. Recognizing Textual Entail-
ment: Models and Applications. Synthesis Lectures
on Human Language Technologies. Morgan & Clay-
pool Publishers.

Frank Emmert-Streib, Matthias Dehmer, and Yongtang
Shi. 2016. Fifty years of graph matching, network
alignment and network comparison. Information
Sciences 346-347(Supplement C):180 – 197.

Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2013. PPDB: The paraphrase
database. In Proceedings of the 2013 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologie. Association for Computational Linguistics,
Atlanta, Georgia, pages 758–764.

Bevan Keeley Jones. 2016. Learning words and syn-
tactic cues in highly ambiguous contexts. Ph.D. the-
sis, The University of Edinburgh.

Alice Lai and Julia Hockenmaier. 2014. Illinois-lh: A
denotational and distributional approach to seman-
tics. In Proceedings of the 8th International Work-
shop on Semantic Evaluation (SemEval 2014). As-
sociation for Computational Linguistics and Dublin
City University, Dublin, Ireland, pages 329–334.

765



Mike Lewis and Mark Steedman. 2014. A* CCG pars-
ing with a supertag-factored model. In Proceed-
ings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing. Association
for Computational Linguistics, Doha, Qatar, pages
990–1000.

Fei Liu, Jeffrey Flanigan, Sam Thomson, Norman M.
Sadeh, and Noah A. Smith. 2015. Toward abstrac-
tive summarization using semantic representations.
In Proceedings of the 2015 Conference of the North
American Chapter of the Association for Compu-
tational Linguistics: Human Language Technolo-
gies. The Association for Computational Linguis-
tics, pages 1077–1086.

Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Roberto Zam-
parelli. 2014. A SICK cure for the evaluation of
compositional distributional semantic models. In
Proceedings of the 9th International Conference
on Language Resources and Evaluation. European
Language Resources Association, Reykjavik, Ice-
land, pages 216–223.

Pascual Martı́nez-Gómez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2016. ccg2lambda: A
compositional semantics system. In Proceedings
of the 2016 System Demonstrations of the Associa-
tion for Computational Linguistics. Association for
Computational Linguistics, Berlin, Germany, pages
85–90.

Pascual Martı́nez-Gómez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2017. On-demand injec-
tion of lexical knowledge for recognising textual en-
tailment. In Proceedings of the 15th Conference of
the European Chapter of the Association for Compu-
tational Linguistics. Association for Computational
Linguistics, Valencia, Spain, pages 710–720.

George A. Miller. 1995. WordNet: A lexical
database for English. Communications of the ACM
38(11):39–41.

Koji Mineshima, Pascual Martı́nez-Gómez, Yusuke
Miyao, and Daisuke Bekki. 2015. Higher-order
logical inference with compositional semantics. In
Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing. Associ-
ation for Computational Linguistics, Lisbon, Portu-
gal, pages 2055–2061.

Koji Mineshima, Ribeka Tanaka, Pascual Martı́nez-
Gómez, Yusuke Miyao, and Daisuke Bekki. 2016.
Building compositional semantics and higher-order
inference system for a wide-coverage japanese CCG
parser. In Proceedings of the 2016 Conference
on Empirical Methods in Natural Language Pro-
cessing. Association for Computational Linguistics,
Austin, Texas, pages 2236–2242.

Terence Parsons. 1990. Events in The Semantics of En-
glish: a Study in Subatomic Semantics. MIT Press,
Cambridge, USA.

Dag Prawitz. 1965. Natural Deduction – A Proof-
Theoretical Study. Almqvist & Wiksell, Stockholm,
Sweden.

Siva Reddy, Mirella Lapata, and Mark Steedman. 2014.
Large-scale semantic parsing without question-
answer pairs. Transactions of the Association for
Computational Linguistics 2:377–392.

Siva Reddy, Oscar Täckström, Michael Collins, Tom
Kwiatkowski, Dipanjan Das, Mark Steedman, and
Mirella Lapata. 2016. Transforming Dependency
Structures to Logical Forms for Semantic Parsing.
Transactions of the Association for Computational
Linguistics 4:127–140.

Ran Tian, Naoaki Okazaki, and Kentaro Inui. 2016.
Learning semantically and additively compositional
distributional representations. In Proceedings of the
54th Annual Meeting of the Association for Compu-
tational Linguistics. Association for Computational
Linguistics, Berlin, Germany, pages 1277–1287.

Anne Troelstra and Helmut Schwichtenberg. 2000. Ba-
sic Proof Theory. Cambridge University Press.

Hitomi Yanaka, Koji Mineshima, Pascual Martı́nez-
Gómez, and Daisuke Bekki. 2017. Determining
semantic textual similarity using natural deduction
proofs. In Proceedings of the 2017 Conference
on Empirical Methods in Natural Language Pro-
cessing. Association for Computational Linguistics,
Copenhagen, Denmark, pages 692–702.

Wenpeng Yin and Hinrich Schütze. 2017. Task-
specific attentive pooling of phrase alignments con-
tributes to sentence matching. In Proceedings of
the 15th Conference of the European Chapter of the
Association for Computational Linguistics: Volume
1, Long Papers. Association for Computational Lin-
guistics, Valencia, Spain, pages 699–709.

Masashi Yoshikawa, Hiroshi Noji, and Yuji Mat-
sumoto. 2017. A* CCG parsing with a supertag and
dependency factored model. In Proceedings of the
55nd Annual Meeting of the Association for Compu-
tational Linguistics. Association for Computational
Linguistics, Vancouver, Canada, pages 277–287.

Shiqi Zhao, Cheng Niu, Ming Zhou, Ting Liu, and
Sheng Li. 2008. Combining multiple resources to
improve SMT-based paraphrasing model. In Pro-
ceedings of the 46rd Annual Meeting on Associa-
tion for Computational Linguistics. Association for
Computational Linguistics, Columbus, Ohio, pages
1021–1029.

766


