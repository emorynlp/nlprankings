



















































A Tag-based English Math Word Problem Solver with Understanding, Reasoning and Explanation


Proceedings of NAACL-HLT 2016 (Demonstrations), pages 67â€“71,
San Diego, California, June 12-17, 2016. cÂ©2016 Association for Computational Linguistics

 
 
 
 

A Tag-based English Math Word Problem Solver
 with Understanding, Reasoning and Explanation 

 
 

Chao-Chun Liang, Kuang-Yi Hsu, Chien-Tsung Huang,  
Chung-Min Li, Shen-Yu Miao, Keh-Yih Su 

Institute of Information Science, Academia Sinica, Taiwan 
{ccliang, ianhsu, joecth, cmli, jackymiu, kysu}@iis.sinica.edu.tw 

 
 
 
 
 

Abstract 

This paper presents a tag-based statistical 
math word problem solver with understand-
ing, reasoning, and explanation. It analyzes 
the text and transforms both body and ques-
tion parts into their tag-based logic forms, and 
then performs inference on them. The pro-
posed tag-based approach provides the flexi-
bility for annotating an extracted math quanti-
ty with its associated syntactic and semantic 
information, which can be used to identify the 
desired operand and filter out irrelevant quan-
tities. The proposed approach is thus less sen-
sitive to the irrelevant information and could 
provide the answer more precisely. Also, it 
can handle much more problem types other 
than addition and subtraction. 

1 Introduction 

The math word problem (MWP) (Mukherjee and 
Garain, 2008) is frequently chosen to study natural 
language understanding due to the following rea-
sons: (1) Since the answer for the MWP cannot be 
extracted by simply performing keyword/pattern 
matching, MWP can clearly show the merits of 
understanding and inference. (2) As MWP usually 
possesses less complicated syntax and requires less 
amount of domain knowledge, it can let the re-
searcher focus on the task of understanding and 
reasoning. (3) The body part of MWP (which men-
tions the given information for solving the problem) 
consists of only a few sentences. The understand-

ing and reasoning procedure could be checked 
more efficiently. (4) The MWP solver has its own 
standalone applications such as Computer Math 
Tutor and Helper for Math in Daily Life. 

Previous English MWP solvers can be classified 
into three categories: (1) Rule-based approaches 
with logic inference (Bobrow, 1964; Slagle, 1965), 
which apply rules to get the answer (via identifying 
entities, quantities, operations, etc.) with a logic in-
ference engine. (2) Rule-based approaches without 
logic inference (Charniak, 1968 and 1969; Gelb, 
1971; Ballard, 1979; Biermann and Ballard, 1980; 
Biermann et al., 1982;  Fletcher, 1985; Dellarosa, 
1986; Bakman, 2007; Liguda and Pfeiffer, 2012; 
Hosseini et al., 2014), which apply rules (usually 
defined as schemata) to get the answer without a 
logic inference engine. (3) Purely statistic-based 
approaches (Kushman et al., 2014; Roy et al., 
2015), which use statistical models to identify enti-
ties, quantities, operations, and get the answer 
without conducting language analysis or inference.  

The main problem of the rule-based approaches 
mentioned above is that the coverage rate problem 
is serious, as rules with wide coverage are difficult 
and expensive to construct. Also, it is awkward in 
resolving ambiguity problems. Besides, most of 
them only handle addition and subtraction these 
two math operations. On the other hand, the main 
problem of those approaches without adopting log-
ic inference is that they cannot share the common 
reasoning part among various problem types. In 
contrast, the main problems of those purely statis-
tical approaches are that they are sensitive to irrel-

67



 
 
 
 

evant information and that the performance deteri-
orates significantly when they encounter compli-
cated problems (Hosseini et al., 2014), because the 
problem is solved without first understanding the 
text. Besides, they only handle algebra problems. 

A tag-based statistical English MWP solver is 
thus proposed to perform understanding and rea-
soning, and avoid the problems mentioned above. 
The text of the MWP is first analyzed into its cor-
responding syntactic tree and then annotated with 
resolved co-reference chains. Afterwards, it is 
converted into the logic form via a few mapping 
rules.  The obtained logic form is further mapped 
into the corresponding domain dependent generic 
concepts (also expressed in logic form). Finally, 
the logic inference is performed on those logic 
statements to get the answer. Various statistical 
classifiers are applied when there are choices. 

Since different questions could be asked for the 
same given body text, we keep all syntactic rela-
tions in the logic form, which are regarded as vari-
ous tags for selecting the appropriate operands re-
lated to the specified question. For example, â€œFred 
picked 36 limesâ€ will be converted into â€œquan(q1, 
#, lime)&verb(q1, pick)&nsubj(q1, Fred) = 36â€ 
(where tags are connected with logic â€œ&â€), in 
which the quantity â€œ36â€ is identified with a label 
â€œq1â€ and attached with its associated tags. The 
proposed tag provides the flexibility for annotating 
a given math quantity with associated syntactic and 
semantic information, which can be used to identi-
fy the desired operand and filter out irrelevant 
quantities. It thus makes our MWP solver less sen-
sitive to the irrelevant information and could pro-
vide the answer more precisely.   

2 System Framework  

The block diagram of proposed math word prob-
lem solver is shown in Figure 1. First, each sen-
tence in an MWP is analyzed by the Language An-
alyzer (LA) module. The associated linguistic in-
formation is then sent to the Solution Type Classi-
fier (STC) to find out the corresponding math op-
eration. Afterwards, they are converted into the 
logic form by the Logic Form Converter (LFC). 
The Inference Engine (IE) then obtains the answer 
from those obtained logic expressions. Finally, the 
Explanation Generator (EG) module will explain 
how the answer is obtained according to the given  

reasoning chain (Russel and Norvig, 2009).  
 Among those modules, the STC is responsible 

for suggesting a way (i.e., a solution type such as 
addition, subtraction, multiplication, division, etc.) 
to solve the problem for each question of the MWP. 
The LFC extracts the related facts from the given 
linguistic information and then represents those 
facts as the first-order logic (FOL) predi-
cates/functions (Russel and Norvig, 2009). It also 
transforms each question into a FOL-like utility 
function according to the suggested solution type. 
The IE then derives new facts according to infer-
ence rules and old facts provided by the LFC. It is 
also responsible for providing utilities to perform 
math operations on related facts to get the answer. 
Detailed description of each module is given below. 

2.1 Language Analysis 
The Stanford CoreNLP suite (Manning et al., 2014) 
is adopted as our LA, which enables a list of anno-
tators to generate the necessary linguistic infor-
mation. The list includes: tokenization, sentence 
splitting, POS tagging, lemmatization, named enti-
ty recognition, parsing and co-reference resolution. 
The generated linguistic representation mainly de-
picts the syntactic relations between its words. To 
solve MWPs, it is crucial to know the relations be-
tween various entities. Dependency relation and 
co-reference resolution will provide such infor-
mation.  

2.2 Solution Type Identification 
The STC will select a math operation (that LFC 
should adopt to solve the problem) based on the 
global information across various input sentences. 
Table 1 shows 12 different solution types currently 
provided. A SVM classifier with linear kernel 
functions (Chang and Lin, 2011) is used, and it 

 
Figure 1: The block diagram of the proposed MWP solver  

68



 
 
 
 

adopted various feature-sets: (1) verb category re-
lated features, (2) various keyword indicators, and 
(3) different pattern-matching indicators for vari-
ous specified aggregative patterns. 

2.3 Logic Form Transformation 
A two-stage approach is adopted to transform the 
linguistic representation of a sentence into its cor-
responding logic forms. In the first stage, the FOL 
predicates are generated (via a few deterministic 
mapping rules) by traversing the input linguistic 
representation. For example, the sentence â€œFred 
picks 36 limesâ€ will be transformed into the fol-
lowing FOL predicates separated by the logic 
AND operator â€œ&â€: 

verb(v1,pick)&nsubj(v1, Fred)&  
dobj(v1,n1)&head(n1, lime)&nummod(n1, 36) 

All the first arguments of the above FOL predi-
cates (i.e., v1 and n1) are identifies, and the predi-
cate-names are the domain-independent syntactic 
dependency relation of the constituents in the de-
pendency structure. 

The domain-dependent logic forms are non-
deterministically generated in the second stage, 
which are derived from crucial math facts associ-
ated with quantities and relations between quanti-
ties. The following FOL function is used to de-
scribe the facts about quantities:  
 ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘(ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘–ğ‘–ğ‘–ğ‘– ,ğ‘ğ‘ğ‘ğ‘ğ‘¢ğ‘¢ğ‘¡ğ‘¡ğ‘–ğ‘–ğ‘–ğ‘–, ğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œğ‘œğ‘¡ğ‘¡ğ‘–ğ‘–ğ‘–ğ‘–) = ğ‘ğ‘ğ‘ğ‘ğ‘›ğ‘›ğ‘œğ‘œğ‘œğ‘œğ‘›ğ‘›  (1) 

For example, â€œquan(q1, #, lime)=36â€ means â€œ36 
limesâ€ (the second argument is the unit adopted, 
and ignored here). Besides domain-dependent facts, 
some auxiliary domain-independent facts associat-
ed with the math fact are also created in this stage 
to help the IE to find the solutions. For example, 
â€œverb(q1, pick)&nsubj(q1, Fred)â€ is the associated 
auxiliary facts of â€œquan(q1, #, lime)=36â€. Those 
auxiliary facts are our proposed tags to make the 
system less sensitive to the irrelevant information. 
They also provide the flexibility of handling vari-
ous kinds of possible questions.   

The questions in the MWP will be transformed 
into FOL-like utility functions provided by the IE 
according to the suggested solution type. Take the 
question â€œHow many limes were picked in total?â€ 
as an example. The STC will assign the â€œSumâ€ op-
eration type to it. Based on that, the LFC will gen-
erate the FOL function â€œSum(quan(?q, #, limes), 
verb(?q, pick)â€ to search all quantities that are as-
sociated with object â€œlimeâ€ and also attached with 
the verb tag â€œpickâ€. 

2.4 Logic Inference 
The IE is used to find the solution of an MWP. It is 
responsible for providing utilities to select desired 
facts and then obtain the answer by taking math 
operations on those selected facts. In addition, it is 
also responsible for using inference rules to derive 
new facts from those facts which are directly de-
rived from the description of the MWP. Consider 
the example shown in Figure 2, the IE will first se-
lect all qualified quantities which match â€œquan(?q, 
#, lime)â€ and with a â€œpickâ€ verb tag, and then per-
form a â€œSumâ€ operation on them. The irrelevant 
quantity â€œquan(q4, #, pear)â€ in that example is 
thus pruned out as its verb tag is â€œdropâ€, not â€œpickâ€. 
The answer is then obtained by summing those 
quantities q1, q2 and q3. 

2.5 Explanation Generation 
Based on the reasoning chain generated from the 
IE (an example is shown in Figure 3), a math oper-
ation oriented approach is adopted to explain how 
the answer is obtained (Huang et al., 2015). A spe-
cific template is used to generate the explanation 
text for each kind of operation. Consider the ex-

Addition Multiplication Surplus 

Subtraction Common-Division Comparison 

 Sum Floor-Division Algebra 
Difference  Ceil-Division Time Variant 

 

Table 1:  Various solution types for solving the MWP  

 
Figure 2: Logic form and logic inference of a Sum operation  

69



 
 
 
 

ample given in Figure 2, the template for â€œSumâ€ 
operation would be â€œTotally verb Child_1 + 
Child_2 + Child_3 + ...+ Child_n = Parent.â€. Ac-
cording to that template and the reasoning chain 
shown in Figure 3, The EG will generate the ex-
planation text â€œTotally pick 36 limes + 32 limes + 
35 limes = 103 limesâ€, which explains that the ob-
tained answer is a summation of â€œ36 limesâ€, â€œ32  
limesâ€ and â€œ35 limesâ€. 

3 Demonstration Outline 

The MWP solver comprises a web user interface 
and a processing server. The web interface is used 
to input the problem and display the processing 
outputs (from each module) of the submitted MWP. 
The server is responsible to process the submitted 
problem to get the answer. 

The user can use the web interface (Figure 4) to 
submit various MWPs. After an MWP is submitted, 
various processing modules will be invoked in a 
pipelined manner (shown in Figure 1) to solve the 
given problem. Once the process is finished, the 
user can browse the outputs generated from each 
module: (1) Parse Trees, Dependency and Co-
Reference chains, which are from the language an-
alyzer. (2) Corresponding linguistic representations, 
which are converted from the above language 
analysis result. (3) Suggested solution type, which 
identifies the desired math operation that the LFC 
should adopt. (4) Obtained logical forms, which 

are transformed from the linguistic representation. 
(5) Generated reasoning chains and explanation 
text, which explains how the problem is solved.  

An online demo can be found at:   
http://nlul.iis.sinica.edu.tw/Engl
ishMathSolver/mathDemo.py.  

4 Experiments 

The experiments are performed on the datasets 
MA1, MA2 and IXL provided by Hosseini et al. 
(2014), which are the first publically available da-
tasets that can be used to compare various systems. 
The datasets include 395 problems and 1,483 sen-
tences in total. MA1 covers simple MWPs on ad-
dition and subtraction for third, fourth, and fifth 
graders. Problems in MA2 includes more irrele-
vant information compared to the other two da-
tasets, and IXL includes more information gaps 
(Hosseini et al., 2014). The performance of our 
system is compared with ARIS (Hosseini et al., 
2014) which is a rule-based system that changes 
the entity attribute according to the schema. The 
result is also compared with KAZB (Kushman et 
al., 2014), which is a purely statistical approach 
that aligns the text with various pre-extracted 
equation templates. We follow the same evaluation 
setting. Table 2 shows that our system significant-
ly outperforms them in overall performance. 

5 Conclusion 

A tag-based statistical framework is proposed to 
perform understanding and reasoning for solving 
MWPs. The adopted tag can help identify desired 
operands and filter out irrelevant quantities. Many 
rule-based approaches only handle addition and 
subtraction math operations, but we can solve 
much more problems types, such as Multiplication, 
Division, Comparison, Algebra, etc. 

 
Figure 3: The reasoning Chain from the Inference Engine  

 
Figure 4: A web interface of the  MWP solver  

 MA1 IXL MA2 Total 
3-fold Cross validation 

Our System 94.8 71.9 88.4 84.8 
ARIS 83.6 75.0 74.4 77.7 
KAZB 89.6 51.1 51.2 64.0 

Gold Solution Type 
Our System 99.3 97.8 95.0 97.5 

 

Table 2:  Performance Comparison  

70



 
 
 
 

References 
A. Mukherjee, U. Garain. 2008. A review of methods 

for automatic understanding of natural language 
mathematical problems, Artif Intell Rev.  

D.G. Bobrow. 1964. Natural language input for a com-
puter problem solving system, Ph.D. Dissertation, 
Massachusetts Institute of Technology. 

J.R. Slagle. 1965. Experiments with a deductive ques-
tion-answering program, J-CACM 8:792-798. 

E. Charniak, CARPS. 1968. A program which solves 
calculus word problems, Report MAC-TR-51, Project 
MAC, MIT. 

E. Charniak. 1969. Computer solution of calculus word 
problems, In Proc. of International Joint Conference 
on Artificial Intelligence. 

D. Dellarosa. 1986. A computer simulation of children's 
arithmetic word-problem solving, Behavior Research 
Methods, Instraments, & Computers, 18 147-154. 

Y. Bakman. 2007. Robust Understanding of Word Prob-
lems With Extraneous Information. 

J.P. Gelb. 1971. Experiments with a natural language 
problem solving system, In Pros. of IJCAI-71. 

B. Ballard. A. Biermann. 1979. PROGRAMMING IN 
NATURAL LANGUAGE : "NLC" AS A PROTO-
TYPE, ACM-Webinar. 

A.W. Biermann, B.W. Ballard 1980. Toward Natural 
Language Computation American Journal of Compu-
tational Linguistic, 6. 

A. Biermann, R. Rodman, B. Ballard, T. Betancourt, G. 
Bilbro, H. Deas, L. Fineman, P. Fink, K. Gilbert, D. 
Gregory, F. Heidlage. 1982. INTERACTIVE NAT-
URAL LANGUAGE PROBLEM SOLVING:A 
PRAGMATIC APPROACH In Pros. of the first con-
ference on applied natural language processing. 

C.R. Fletcher. 1985. COMPUTER SIMULATION -- 
Understanding and solving arithmetic word prob-
lems: A computer simulation, Behavior Research 
Methods, Instruments, & Computers, 17 565-571. 

M.J. Hosseini, H. Hajishirzi, O. Etzioni, N. Kushman. 
2014. Learning to Solve Arithmetic Word Problems 
with Verb Categorization, EMNLP. 

N. Kushman, Y. Artzi, L. Zettlemoyer, R. Barzilay, 
2014. Learning to Automatically Solve Algebra Word 
Problems, ACL. 

C. Liguda, T. Pfeiffer, 2012, Modeling Math Word Prob-
lems with Augmented Semantic Networks, NLDB. 

S.I. Roy, T.J.H. Vieira, D.I. Roth. 2015. Reasoning 
about Quantities in Natural Language, TACL, 3 1-13. 

S. J. Russell and P. Norvig, 2009. Artificial Intelligence: 
A Modern Approach (3rd Edition), Prentice Hall. 

C.D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. J. 
Bethard, and D. McClosky. 2014. The Stanford 
CoreNLP Natural Language Processing Toolkit In 
Proceedings of the 52nd Annual Meeting of the As-

sociation for Computational Linguistics: System 
Demonstrations, pp. 55-60. 

C.-C. Chang, C.-J. Lin. 2011. LIBSVM: A library for 
support vector machines. ACM Transactions on Intel-
ligent Systems and Technology. 

Y.-C. Lin, C.-C. Liang, K.-Y. Hsu, C.-T. Huang, S.-Y. 
Miao, W.-Y. Ma, L.-W. Ku, C.-J. Liau, K.-Y. Su. 
2015. Designing a Tag-Based Statistical Math Word 
Problem Solver with Reasoning and Explanation, In-
ternational Journal of Computational Linguistics and 
Chinese Language Processing, 20(2), 1-26. 

C.-T. Huang, Y.-C. Lin, K.-Y. Su. 2015. Explanation 
Generation for a Math Word Problem Solver, Interna-
tional Journal of Computational Linguistics and Chi-
nese Language Processing, 20(2), 27-44. 

 

71


