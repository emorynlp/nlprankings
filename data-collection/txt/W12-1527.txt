










































Content Selection From Semantic Web Data


INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 146–149,
Utica, May 2012. c©2012 Association for Computational Linguistics

Content Selection From Semantic Web Data

Nadjet Bouayad-Agha1
Gerard Casamayor1

Leo Wanner1,2
1DTIC, University Pompeu Fabra

2Institució Catalana de Recerca i Estudis Avançats
Barcelona, Spain

firstname.lastname@upf.edu

Chris Mellish
Computing Science

University of Aberdeen
Aberdeen AB24 3UE, UK

c.mellish@abdn.ac.uk

Abstract

So far, there has been little success in Natural
Language Generation in coming up with gen-
eral models of the content selection process.
Nonetheless, there has been some work on
content selection that employ Machine learn-
ing or heuristic search. On the other side, there
is a clear tendency in NLG towards the use of
resources encoded in standard Semantic Web
representation formats. For these reasons, we
believe that time has come to propose an initial
challenge on content selection from Semantic
Web data. In this paper, we briefly outline the
idea and plan for the execution of this task.

1 Motivation

So far, there has been little success in Natural Lan-
guage Generation in coming up with general mod-
els of the content selection process. Most of the
researchers in the field agree that this lack of suc-
cess is because the knowledge and context (commu-
nicative goals, user profile, discourse history, query,
etc) needed for this task depend on the application
domain. This often led in the past to template-
or graph-based combined content selection and dis-
course structuring approaches operating on idiosyn-
cratically encoded small sets of input data. Fur-
thermore, in many NLG-applications, target texts
and sometimes even empirical data are not avail-
able, which makes it difficult to employ empirical
approaches to knowledge elicitation. Nonetheless,
during the last decade, there has been a steady flow
of new work on content selection that employed Ma-
chine learning (Barzilay and Lapata, 2005; Duboue
and McKeown, 2003; Jordan and Walker, 2005;

Kelly et al., 2009), heuristic search (O’Donnell et
al., 2001; Demir et al., 2010; Mellish and Pan,
2008), or a combination thereof (Bouayad-Agha et
al., 2011). All of these strategies can deal with large
volumes of data.

On the other side, there is a clear tendency in NLG
towards the use of resources encoded in terms of
standard Semantic Web representation formats such
as OWL and RDF, e.g., (Wilcock and Jokinen, 2003;
Bontcheva and Wilks, 2004; Mellish and Pan, 2008;
Power and Third, 2010; Bouayad-Agha et al., 2011;
Dannells et al., 2012), to name but a few. However,
although most of these works make a good attempt
at realisation, the problem of content determination
from Semantic Web data is relatively untouched.

For these reasons, we believe that the time has
come to bring together researchers working on (or
interested in working on) content selection to par-
ticipate in a challenge for this task using standard
freely available web data as input. The availability
of open modular multi-domain multi-billion triple
data and of open ontological resources (Bizer et al.,
2009) presented in a standard knowledge represen-
tation formalism make semantic web data a natural
choice for such a challenge.

As will be presented below, this initial challenge
presents a relatively simple content selection task
with no user model and a straightforward commu-
nicative goal so that people are encouraged to take
part and motivated to stay on for later challenges, in
which the task will be successively enhanced from
gained experience.

A content determination challenge would be a
chance to (i) directly compare the performance of

146



different types of content selection strategies; (ii)
contribute towards developing a standard “off-the-
shelf” content selection module; and (iii) contribute
towards a standard interface between text planning
and linguistic generation.

To get the widest reception possible, the challenge
will be open to any approach, be it template-, rule-
or heuristic-based, or empirical. Furthermore, it will
be advertised in the Semantic Web Community to
get contributors from other horizons, see, e.g., (Dai
et al., 2010).

In what follows, we briefly outline the idea and
plan for the execution of the challenge. In Section 2,
we outline a description of the task. In Section 3,
the data and domain that will be used are presented.
Section 4 describes how this data is to be prepared
for the task, and Section 5 how it will be released to
the participants. In Section 6, we sketch the eval-
uation including the preparation of the evaluation
dataset. Section 7 gives a proposed schedule for
each of the tasks involved in organizing the chal-
lenge. Finally, in Section 8, we provide short bi-
ographies of the members of the organization team,
focusing on their experience in the proposed task.

2 Task Description

The core of the task to be addressed can be formu-
lated as follows:

Build a system which, given a set of RDF
triples containing facts about a celebrity
and a target text (for instance, a wikipedia-
style article about that person), selects
those triples that are reflected in the target
text.

The participants are also free to consider the se-
mantics defined by the data sources in their ap-
proach, rely on additional resources like ontologies
from other sources, or disregard the semantics com-
pletely.

The implemented system should output its results
in a predefined standard format that can be used for
automatic evaluation.

It could be that the RDF data does not contain ev-
erything that would ideally be included in such an
article, but that is ignored here. The task consists in
selecting content that is communicated in the target
text.

3 The data

The domain will be constituted by short biographies
of famous people. This is an interesting domain for
the challenge because Semantic Web data and corre-
sponding texts for this domain are available in large
quantities (e.g., DBPedia or Freebase for the data
and many other sources for biography texts, among
them Wikipedia).

The data will consist, for each famous person, of
a pair of RDF-triple set and associated text(s). For
each pair, the RDF data will include both informa-
tion communicated and excluded from the text. The
text may convey information not present in the RDF-
triples, but this will be kept to a minimum, always
subject to using naturally-occurring texts. All pairs
should contain enough RDF-triples and text to make
the pair interesting for the content selection task.

When choosing data for the challenge, we will
prefer semantic contents classified under consistent
ontologies over plain Linked Data with no explicit
semantics. The semantics of the RDF data (vocab-
ularies, ontologies) will be provided, preferably en-
coded in Semantic Web standards (e.g., in RDFS or
OWL).

4 Data Preparation

The task of data preparation consists in 1) data gath-
ering and preparation, which is to be carried out by
the organizers, and 2) working dataset selection and
annotation, which is to be carried out by both the
organizers and participants.

4.1 Data gathering and preparation

This preparatory stage consists in choosing the
repository sources, downloading the relevant on-
tologies (to the extent those will be provided), and
downloading and pairing the data and associated
texts (= the paired corpus).

4.2 Working Dataset selection and annotation

The participants will be asked to participate in a pre-
liminary task consisting in marking which triples are
included in the text given a subset of the paired cor-
pus (the size of the subset still has to be decided).
This task could be supported by some automatic
anchoring techniques such as used in (Duboue and
McKeown, 2003; Barzilay and Lapata, 2005). The

147



objectives of the task are threefold: (1) to provide all
participants with a common set of “correct answers”
to be exploited in their approach, (2) to familiarize
the participants with the nature of the contents, their
semantics and the texts, and (3) to provide the task
with a ceiling for the evaluation, i.e. inter-annotator
agreement.

Annotation guidelines will be needed to ensure
that all participants follow the same procedure when
annotating texts. For this purpose, an early docu-
ment will be produced detailing the procedure to-
gether with examples and descriptions of relevant
problems such as ambiguities in the annotation. The
guidelines will be improved in multiple stages of an-
notation and revision with the goal of maximizing
inter-annotator agreement.

5 Data release

The participants in the challenge will be given ac-
cess to the set of all correct answers and a large
portion of the non-marked paired corpus, as well as
their semantics (i.e., ontologies and the like). The
remaining unseen, non-marked set will be kept for
evaluation.

6 Evaluation

The evaluation consists of 1) a preparatory stage for
selecting and annotating the evaluation dataset, and
2) an evaluation stage.

6.1 Evaluation dataset selection and annotation

Once all participants have submitted their exe-
cutable to solve the task, the evaluation set will be
processed. If timing is tight, however, this could be
done whilst the participants are still working on the
task or extra effort (for instance, from the organiz-
ers) could be brought in. A subset of the data is
randomly selected and annotated with the selected
triples by the participants. This two-stage approach
to triple selection annotation is proposed in order to
avoid any bias on the evaluation data.

6.2 Evaluation

Each executable is run against the test corpus and the
selected triples evaluated against the gold triple se-
lection set. Since this is formally a relatively simple
task of selecting a subset of a given set, we will use

for evaluation standard precision, recall and F mea-
sures. In addition, other appropriate metrics will be
explored—for instance, certain metrics for extrac-
tive summarisation (which is to some extent a simi-
lar task).

The organizers will explore whether it will be fea-
sible to select and annotate some test examples from
a different corpus and have the systems evaluated on
these as a separate task.

7 Schedule

Table 1 presents the different tasks, protagonists and
the schedule involved in the organization of the chal-
lenge. The challenge proper will take place between
November 2012 and May/June 2013.

8 Organizers

Nadjet Bouayad-Agha has been a lecturer and re-
searcher at DTIC, UPF, since 2002. She obtained
her PhD on Text Planning in 2001 from the Univer-
sity of Brighton and has been working ever since her
postgraduate studies at the University of Paris VII in
NLG, more specifically on Text Planning. In recent
years her focus has been on how to exploit semantic
web representations and technologies for Text Plan-
ning in general and content selection in particular.

Gerard Casamayor is a PhD student at DTIC,
UPF, working on text planning from general-
purpose semantic data. His main interests are ma-
chine learning and interactive, collaborative text
planning. As part of his thesis, he is developing a
text planning approach that can be trained directly
by domain experts, minimizing the need of encoding
or annotating prior knowledge about how to solve
the task.

Chris Mellish has been a professor at the Univer-
sity of Aberdeen since 2003, when he moved from a
similar position at the University of Edinburgh. He
has been doing research in NLG since 1984 and or-
ganised the second European NLG workshop. His
work on content selection includes the opportunis-
tic planning approach used by the ILEX system and
a rule-based approach to content selection from se-
mantic web data presented in ENLG 2011.

Leo Wanner has been ICREA Research Profes-
sor at DTIC, UPF, since 2005. Before, he was

148



What? Who? When?
Data gathering and preparation Organizers Summer 2012
Working dataset selection and annotation Organizers and Participants Sept/Oct 2012
Data Release Organizers November 2012
Evaluation dataset selection and annotation Organizers and Participants May 2013
Evaluation Organizers June 2013
Publication@INLG Organizers August 2013

Table 1: Content Selection Challenge Organization Schedule

affiliated as Assistant Professor with the Univer-
sity of Stuttgart. Wanner is involved in research
on multilingual text generation since the late 80ies.
Among his research foci are user-oriented con-
tent selection and the interface between language-
independent ontology-based and linguistic represen-
tations in text generation.

References

Regina Barzilay and Mirella Lapata. 2005. Collec-
tive Content Selection for Concept-to-Text Genera-
tion. Proceedings of the Joint Human Language Tech-
nology and Empirical Methods in Natural Language
Processing Conferences (HLT/EMNLP-2005) Van-
couver, Canada.

Christian Bizer, Tom Heath and Tim Berners-Lee 2009.
Linked Data - The Story So Far. International Journal
on Semantic Web and Information Systems 5(3) 1–22

Kalina Bontcheva and Yorick Wilks 2004. Automatic
Report Generation from Ontologies: the MIAKT ap-
proach Nineth International Conference on Appli-
cations of Natural Language to Information Systems
(NLDB’2004) 324–335.

Nadjet Bouayad-Agha, Gerard Casamayor and Leo Wan-
ner. 2011. Content selection from an ontology-based
knowledge base for the generation of football sum-
maries Proceedings of the 13th European Workshop
on Natural Language Generation (ENLG’2011) 72–
81 Nancy, France.

Yintang Dai, Shiyong Zhang, Jidong Chen, Tianyuan
Chen and Wei Zhang. 2010 Semantic Network Lan-
guage Generation based on a Semantic Networks Seri-
alization Grammar World Wide Web 13:307341

Dana Dannélls, Mariana Damova, Ramona Enache and
Milen Chechev. 2012 Multilingual Online Genera-
tion from Semantic Web Ontologies Proceedings of
the 21st International Conference on World Wide Web
(WWW’12) 239–242

Seniz Demir, Sandra Carberry and Kathleen F. McCoy.
2010. A Discourse-Aware Graph-Based Content-

Selection Framework. Proceedings of the Interna-
tional Language Generation Conference. Sweden.

Pablo A. Duboue and Kathleen R. McKeown. 2003. Sta-
tistical Acquisition of Content Selection Rules for Nat-
ural Language Generation. Proceedings of the 2003
conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP). Sapporo, Japan.

Dimitrios Galanis and Ion Androutsopoulos. 2007. Gen-
erating Multilingual Personalized Descriptions from
OWL Ontologies on the Semantic Web: the Natu-
ralOWL System. Proceedings of the Eleventh Eu-
ropean Workshop on Natural Language Generation
(ENLG07)

Pamela W. Jordan and Marilyn A. Walker 2005 Learning
content selection rules for generating object descrip-
tions in dialogue Journal of Artificial Intelligence Re-
search 24, 157–194.

Colin Kelly, Ann Copestake, and Nikiforos Karamanis.
2009 Investigating content selection for language gen-
eration using machine learning. Proceedings of the
12th European Workshop on Natural Language Gen-
eration.. 130–137.

Chris Mellish and Jeff Z. Pan. 2008 Language Di-
rected Inference from Ontologies. Artificial Intelli-
gence. 172(10):1285-1315.

Mick ODonnell, Chris Mellish, Jon Oberlander, and Alis-
tair Knott. 2001. ILEX: an architecture for a dynamic
hypertext generation system. Natural Language Engi-
neering. 7(3):225–250.

Richard Power and Allan Third 2010 Expressing OWL
axioms by English sentences: dubious in theory, fea-
sible in practice Proceedings of the 23rd Interna-
tional Conference on Computational Linguistics (CI-
CLING’01). 1006–1013.

Graham Wilcok and Kristiina Jokinen 2003 Generat-
ing Responses and Explanations from RDF/XML and
DAML+OIL. IJCAI03 Workshop on Knowledge and
Reasoning in Practical Dialogue Systems. 58–63.

149


