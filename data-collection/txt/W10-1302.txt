










































Automatic generation of conversational utterances and narrative for Augmentative and Alternative Communication: a prototype system


Proceedings of the NAACL HLT 2010 Workshop on Speech and Language Processing for Assistive Technologies, pages 10–18,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

Automatic generation of conversational utterances and narrative for 

Augmentative and Alternative Communication: a prototype system 

Martin Dempster & Norman Alm Ehud Reiter 
School of Computing Computer Science Department 
University of Dundee University of Aberdeen 

Dundee, Scotland, DD1 4HN, UK Aberdeen, Scotland, AB24 3UE, UK 
m.k.dempster@dundee.ac.uk 

nalm@computing.dundee.ac.uk 

e.reiter@abdn.ac.uk 

 

 

 

Abstract 

We detail the design, development and evalua-

tion of Augmentative and Alternative Com-

munication (AAC) software which encourages 

rapid conversational interaction. The system 

uses Natural Language Generation (NLG) 

technology to automatically generate conver-

sational utterances from a domain knowledge 

base modelled from content suggested by a 

small AAC user group. Findings from this 

work are presented along with a discussion 

about how NLG might be successfully applied 

to conversational AAC systems in the future. 

1 Introduction 

Augmentative and Alternative Communication 

(AAC) systems assist non-speaking people communi-

cate. Reasons for lack of speech are varied and can be 

complex, but they are typically related to some pro-

found cognitive and/or motor impairment.  

Most AAC systems are computer based, utilize syn-

thesized speech output and employ a phrase-

construction approach to input. This approach requires 

the user to construct the majority of their utterances live 

during conversation. Undoubtedly this facilitated com-

munication is hugely important to those without natural 

speech. However, this process is often unacceptably 

slow and can lead to problematic and stilted interac-

tions, mostly due to the rapid nature of unimpeded face-

to-face communication. 

Previous work has shown that it is possible to hold 

mutually rewarding conversations using wholly pre-

stored material, known as the phrase-storage approach.  

Utterances are authored ahead of time and can be se-

lected and output immediately leading to quicker com-

munication rates. However, this approach suffers from 

several drawbacks which may have affected its more 

general adoption. 

Furthermore, Natural Language Processing (NLP) 

technology has proven to be a fruitful line of inquiry 

within the field. It has offered a powerful means to im-

prove system productivity and usability. We are current-

ly investigating how Natural Language Generation 

(NLG) might be applied in a useful way within an AAC 

device geared towards fast-paced and rewarding social 

interactions. It is hoped that the linguistic control and 

automaticity offered by NLG may go some way towards 

addressing the previous criticisms of pre-stored material 

regarding its inflexibility and cost in effort. 

2 Background 

2.1 Limitations of current AAC 

 High-tech AAC systems typically augment commu-

nication for non-speaking people by allowing live mes-

sage construction through some orthographic means. 

Completed messages are generally sent to a speech syn-

thesis engine for output during communication with 

others. Many people who require AAC have associated 

physical disabilities which reduce the speed achievable 

using input methods such as keyboards, pointing devic-

es or touch-screens. The rate achievable using most 

commercial AAC systems is highly dependent on the 

nature of the user‟s disabilities but a generally accepted 

figure is in the region of 2-15 words per minute (Hig-

ginbotham, Shane et al. 2007), at least an order of mag-

nitude slower than most natural speakers. 

This relatively slow rate of input is a crucial factor in 

some of the issues that arise in AAC-facilitated commu-

nication. Because of the effort and time required to 

create utterances, the user may not be able to construct 

messages quickly enough to take active roles in fast 

10



paced conversations. As a result users may become pas-

sive while also typically using a smaller communicative 

repertoire than natural speakers (Light 1988).  

Narrative, an important type of interpersonal com-

munication, is not well handled in most communication 

aids (Waller 1992). Delayed response and slow rate of 

aided-communication are correlated with higher inci-

dence of breakdown in communication and lesser per-

ceptions of the AAC user (Todman and Rzepecka 2003; 

McCarthy and Light 2005). This is primarily due to 

conflict between the relatively long time necessary to 

formulate an utterance and the fast paced nature of con-

versation.  

These problems are particularly critical in social con-

texts. AAC users typically have small social circles and 

are dependent on contact with families and carers. They 

often lack self-esteem and have negative self-image.  As 

a result, developing new relationships and experiencing 

new things can be difficult, despite being a major priori-

ty in their lives (Datillo, Estrella et al. 2007). 

Some work has suggested that the use of pre-stored 

conversational material based on conversation models 

could help increase communication rate and conversa-

tion quality. Alm (1988) showed that it is possible to 

successfully model short „chat‟ conversations involving 

greetings, personal enquiries and small-talk.  Further-

more, the TALK system allowed a user to pre-store a 

large volume of material on specific topics so that 

whole utterances could be selected and output. The sys-

tem also made heavy use of quick-fire phrases, classes 

of regularly used utterance which could be accessed 

quickly, and showed that communication using solely 

pre-stored material was viable (Todman and Alm 2003). 

Despite encouraging results and the development of a 

commercial product, the phrase-storage approach to 

social communication has not gained wide popularity. 

The reasons for this are complex, but include: the rela-

tive inflexibility of pre-stored material; the costs asso-

ciated with authoring the material and keeping the 

material up-to-date; and the vastly different nature of 

the approach and different training requirements neces-

sary to achieve success. 

2.2 The role of NLP in AAC 

NLP technology has provided many benefits to AAC 

system designers. Possibly the first technology to be 

included in many commercial systems to date was word 

prediction and completion. There have also been many 

research prototypes exploring the applicability of more 

emerging technologies such as named entity recognition 

from synthesized speech (Wisenburn and Higginbotham 

2008), the generation of well-formed utterances from 

telegraphic input (McCoy, Pennington et al. 1998) and 

the automatic identification of contextual vocabulary 

from the web (Higginbotham, Bisantz et al. 2008). 

Netzer and Elhadad (2006) used NLG to allow the se-

mantic authoring of utterances. 

However, NLG, in the sense of data-to-text (Reiter 

and Dale 2000), has had limited application within AAC 

thus far, although Reiter et al. (2009) showed it is possi-

ble to generate stories from sensor data which allow a 

child using AAC to tell others about their day at school. 

2.3 System Rationale 

This project is exploring the use of NLG to produce 

conversational utterances in AAC systems designed for 

social interaction.  At the outset it was hoped that using 

NLG might address some of the difficulties observed in 

pre-storage systems. For instance, the generation com-

ponent could theoretically produce a range of utterances 

and speech act types automatically from the same un-

derlying data and adapt these somewhat to the interac-

tional context.  Using NLG would also have the benefit 

of offering control over the well-formedness of the out-

put, an important consideration given the difficulty 

some AAC users have in achieving literacy (Sandberg 

and Hjelmquist 1997). The fact that the system has an 

inherent awareness of the semantic content of the lin-

guistic output, rather than simply being stored as canned 

text, is also a potential benefit. In other words, NLG 

might offer a level of automaticity and flexibility that 

traditional pre-storage systems cannot offer, as well as 

potentially reducing the level of pre-authoring required 

from the user.  

3 System Development 

3.1 User-centered methodology 

To try to assess how useful NLG could be in this 

context we adopted a user-centered approach to the de-

sign of the system. A group of 3 AAC users has been 

recruited, all of whom currently use some form of high-

tech AAC. Literacy amongst the group is varied. Two of 

the individuals use the alphabetic keyboard-based 

Lightwriter communication device currently, and have 

normal cognitive and visual-perceptive skills.  All of the 

users have cerebral palsy and dysarthria, and have been 

involved in previous software evaluations.  

Weekly or twice weekly sessions were held with 

each user for several months while the software was 

being produced. Sessions consisted of various activities: 

11



discussion about the user‟s ideas for the software and 

technology; the identification of topics and collation of 

input data to the system; demonstrations of the new fea-

tures or changes since the last session; system training; 

and dry-run test conversations between the investigators 

and the users. 

3.2 System Architecture 

A growing line of inquiry in the NLG community is 

the generation of language from ontologies (Mellish and 

Sun 2005).  An ontology is a logical and hierarchical 

model of the different concepts and the nature of rela-

tionships between concepts in a particular domain. 

These concepts and relationships can be mapped onto 

linguistic constructs to allow for the production of natu-

ral language descriptions (Karakatsiotis, Galanis et al. 

2008) of parts of the ontology. 

In the case of our system, we are trying to model 

conversational topics that would be of interest in social 

conversation between users of the system and their co-

conversationalists. The current categories of topic we 

are experimenting with include travelling, listening to 

music, watching films and attending concerts.  Many 

categories are based on a simple event model which 

defines the basic characteristics common to all events, 

such as a time of occurrence (see Fig.1). We have also 

included concepts such as Person and Place which are 

associated with events to form a logical model of a par-

ticular event type.  

A separate file is created unique to each user which is 

linked to the original model. This is filled with individ-

uals consisting of data from the user. In other words, 

rather than defining the concept of an event as we did 

with the original ontology, here we are creating a de-

scription of an actual event and any other details, such 

as people or places, associated with it. We have defined 

our ontology in OWL, a standard language for the defi-

nition of ontologies, and each piece of knowledge is 

effectively stored as a RDF Triple consisting of a sub-

ject, predicate and object.   

 

 

 

 

 

 

 

 

 

 

Figure 1: The abstract event model 

The user‟s knowledge base is turned into useful con-

versational utterances through a template-driven utter-

ance generation system (e.g. Van Deemter, Krahmer et 

al. 2005).  A large set of templates has been authored, 

using the SimpleNLG programming interface, which 

turn data from the onotlogy into natural language utter-

ances. The templates are created as concrete syntax 

trees containing unspecified „slots‟ and parameters (See 

Fig.2).  These syntax trees map out the syntactic struc-

ture of the template), and are linked to a particular class 

in the ontology so that only appropriate templates are 

applied to each individual.   Slots are used to add con-

textually relevant clauses to our utterances. For exam-

ple, a template might contain a ‘time’  slot, the contents 

of which are derived from the time of the event in ques-

tion.  For instance, the slot might be filled with “next 

Tuesday evening”, “a month ago” or “this morning” 

depending on the context. Example parameters include 

the tense with which the utterance should be generated, 

and whether a pronoun or full noun phrase should be 

used to refer to the subject of the utterance. 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Figure 2: An example syntax tree with empty slots 

In addition to the language produced from the model 

and knowledge base we have included the ability to add 

canned text phrases to each individual.  

This is necessary because there may be things that 

you wish to be able say about a topic which it is not 

feasible to model.  Because we have a fairly diverse set 

of topics it is simply not possible to model all aspects of 

these topics in a reasonable time.  There is effectively a 

trade-off between complexity of the model and how 

maintainable and representative it is. A more complex 

model will lead to more expressive generated language, 

but will cost a great deal more to design and maintain. 

In the case of our system, a „lowest common denomina-

tor‟ domain model combined with additional canned 

text has proven to be a relatively straightforward and 

inexpensive design. 

12



The system has also been designed to learn over time 

the sequences of utterances a user selects and suggest 

next moves based on past behavior.  The system does 

this by maintaining a directional weighted graph which 

records sequences of utterances as they are used.  The 

graph works by recording each individual utterance as a 

node in the graph and creating relationships between 

these nodes as they occur. The more often two utter-

ances appear in sequence the higher the value given to 

the edge between the two corresponding nodes. 

3.3 Conversation model and interface issues 

Perhaps the most challenging aspect of taking the 

system from initial concept to working prototype has 

been finding the most effective way of interfacing the 

technology. We have found that due to the complexity 

of the underlying technology, reaching the stage where 

generated utterances are both useful and accessible to 

the user during conversation has required careful con-

sideration and the trialing of several approaches with the 

user group. 

It was envisaged that the generative power of NLG 

would be its most powerful benefit. The system could 

realize the same piece of data as numerous speech act 

types and, within a speech type, in several different 

phrasings. This offered the ability to counteract the in-

flexibility and uniformity of pre-stored utterances 

somewhat.  However, we have had mixed success in 

achieving this goal as it has proven difficult to find an 

effective way to interface this enhanced choice and va-

riety to the user.  If there is a large volume of generated 

utterances available to choose from we must provide an 

efficient means by which the material is presented or 

organized so that the desired utterance can be located 

quickly. If a large choice results in a delayed selection 

and thus conversational turn, we may then lose any rate 

and speed of response benefits which would negate the 

need to use pre-stored and generated material at all. 

To address this problem, we attempted to design a 

conversational model which controlled the generation of 

utterances so that only the utterances deemed most like-

ly were presented to the user, thus reducing the cogni-

tive load required to search through a large set. This was 

done using a basic system where the templates were 

tagged according to where it might be most likely to be 

used in a conversation on a topic. For instance, a tem-

plate might produce a pre-sequence, an introduction, 

elaboration or concluding remark, or it may produce a 

interrogative. With the addition of historical sequential 

moves from our directional graph we could begin to 

present subsets of utterances to the user according to 

where they were in topic development. 

Another approach trialed was inspired by the Gricean 

maxim of quantity. Each template contains meta-data 

about the information it expresses. For each generated 

utterance selected, we can „rule out‟ further generation 

of the same information. This is based on the assump-

tion that speakers will generally avoid repetition. We 

have found that this technique provides a useful way of 

supporting discourse coherence within conversations. 

Finally, using the logical model of topics we have 

created, it is possible to support and model stepwise 

topic progression. We can suggest, based on the model 

and the user knowledge base, other topics linked to the 

one currently selected. For example, if we were talking 

about an upcoming holiday to London with a friend 

called Bob we may want to the change topical perspec-

tive to related aspects of the trip. We might want to talk 

about London as a place, Bob as a friend, and other trips 

we have taken with Bob or to London. Because these 

concepts are all distinct within the model, they each 

have their own set of associated templates and result in 

sets of candidate utterances with differing perspectives. 

Navigating to related topics in this manner should be 

quicker since related topics do not have to be located 

manually. Although the users are still being trained in 

this approach to topic change, early evaluations are 

promising. It enables a „one-click‟ transition to related 

topics, allowing the user to elaborate on certain aspects 

of a previous topic and respond quickly to questions 

from their conversational partners. 

Building on the last two mechanisms, we can also 

generate bridging phrases which allow for more cohe-

sive changes in topic. This allows for a more eloquent 

transition to a new topic and also aids the discourse co-

herence.  

All of these approaches in fact belie, to some degree, 

the complexity of conversation. By its very nature, con-

versation is unpredictable, and the purpose and meaning 

of sequential moves are highly dependent on their con-

text (Clark 1996). However, any form of context identi-

fication, such as speech recognition (Wisenburn and 

Higginbotham 2008), is likely to present a major tech-

nical challenge in any production AAC system at the 

current time. The above are simply at attempt to model, 

using the NLP/AI techniques available, aspects of 

communication process, to show the potential benefits 

when using NLG-produced utterances rather than sim-

ple canned text utterances. 

Application of some of the above techniques resulted 

in a highly fluid interface in which the utterances dis-

played changed rapidly according to the conversation 

model. This presented a major challenge to users learn-

ing the system, with all displaying a strong preference 

for a static interface where the same utterances could be 

found in the same location each time they were desired.  

13



Table 1: An example conversation produced 

using the system. Speaker A is the user and speaker 

B is an unaided speaker. The right-hand column 

shows the interface selections necessary prior to 

selecting the utterance from a set of possibilities. 

The marker G represents a generated utterance, C 

represents canned text. The remainder are quick-

fire utterances. 

We believe this does not suggest that use of such 

conversational models and semantic processing is not 

feasible, but simply that in the scope of the current 

work it has not been possible to fully evaluate their 

potential. Thus we have chosen to generate candidate 

phrases in a static manner without the predictive as-

pects described above. These changes have allowed for 

quicker achievement of proficiency and have lowered 

the cognitive effort required to navigate the interface.    

In the latest version of the software, we have de-

fined a set of templates for each topic which when 

realized in series produce a coherent narrative. They 

can still be selected individually by the user for output, 

so they retain ultimate control of what is said, but the 

utterances are presented in a natural order. This means 

that the user can easily make use of the utterances as a 

narrative or can choose according to the particular sit-

uation and context.  Any interrogative templates are 

displayed in a different part of the interface. We have 

set up a two column display so that interrogatives and 

other statements are clearly delineated.  

This approach has had very promising results as we 

have found that users no longer have to search through 

a list of suggestions which changes after each conver-

sational turn. They can also use the structured nature 

of the generated utterances to confidently introduce the 

different topics in conversation.  We are finding some 

evidence of increased self-selection at the end of their 

current turn as the user is easily able to continue their 

narrative automatically without having to worry about 

the location of their next turn in the interface. There is 

some other evidence of this structured application of 

NLG to narrative as being a promising area (Reiter, 

Turner et al. 2009). 

We also believe that the passivity and lack of initia-

tion observed in AAC users could be positively ad-

dressed if AAC systems can better support a more 

varied communicative repertoire and suitable training 

is administered to show users how to confidently use 

these different constructs (e.g. Todman 2000). Early 

training sessions with our user group have again 

proved positive with increased use of the trained fea-

tures and interaction styles.  

 UTTERANCE USER 

SELECTION 

A: Hi Robert [GREET] 

B:      Oh, Hi. Nice to see you.  

A: And you. [GREET] 

A: How’s it going? [INTRO] 

B: Fine. And you?  

A: Not too bad. [INTRO] 

B: So you been keeping busy?  

A: Yeah [YES] 

A: I certainly have! [YES] 

 

A: 

 

I was out at a concert on Thursday 

night. (G) 

[GIGS] 

[Select ‘Mar-

tin Taylor’] 

B: Great. Who did you go to see?  

 

A: 

 

Have you heard of Martin Taylor? 

(G) 

[ARTIST] 

[Select ‘Mar-

tin Taylor’] 

B: No.....I don‟t think so.  

A: He is a Jazz guitarist. (G) [Select ‘Mar-

tin Taylor’] 

B: Oh, great. I like jazz music.  

A: Me too. [AGREE] 

B: So how was the concert?  

 

A: 

 

It was really good. (G) 

[GIGS] 

[Select ‘Mar-

tin Taylor’] 

A: John and David came with me. (G)  

A: We all enjoyed it. (C)  

A: We had a bit of an interesting jour-

ney home because it was snowing 

heavily, but we made it back safe. 

(C) 

 

B:     Well that‟s good news. Where was 

the concert? 

 

 

A: 

 

 

It was at the Tron Theatre in Glas-

gow. (G) 

I’ve been to Glasgow a few times 

lately. [G] 

[GIGS] 

[Select ‘Mar-

tin Taylor’] 

[Select ‘Glas-

gow’] 

A: Anyway, I best be getting on. [WRAP UP] 

A: It was great talking to you. [WRAP UP] 

B:      Yes, likewise.  

B: See you soon.  

A: OK. Cheerio. [FINISH] 

B: Bye  

14



 

 

 

 

 

 

 

 

 

 

 

 

3.4 Authoring user content 

Currently we have not managed to produce a tool that 

the user can use to update their knowledge base them-

selves. The ontology editing tool used in the program, 

Protégé, is a free academic software package designed 

for knowledge engineers and thus has a high degree of 

internal complexity and takes time to learn. It is also not 

a particularly accessible piece of software. 

We have worked with the users to build up their 

knowledge bases over a series of meetings by allowing 

them to suggest individuals to add while entering the 

details for them into the system. The process of defining 

new individual is very quick, usually requiring the input 

of just a few words and selection of the associated indi-

viduals. However, one of the main criticisms on the part 

of the users is that for the system to be useful in the long 

term, it must be kept up to date, as old material will 

quickly become less relevant and useful in less frequent 

situations.  For this reason it is critical to the success of 

any NLG-driven communication system that the data 

input is as simple and seamless as possible. 

We have shown in our system that it is possible to get 

some limited data automatically from online sources, 

rather than having to input it manually. Many web ser-

vices are being made available which enable program-

mers to access data from online services in their 

applications. For instance, both Amazon and YouTube 

have their own APIs which allow 3
rd

 party applications 

to request content information from these services.  

The notion of the semantic web is also related to this. 

There is a large effort underway to define how we might 

structure and link information on the web in such a way 

that more of it can be processed automatically by com-

puters and made available in interchangeable formats. 

Shared data and semantic web technologies such as 

these operate on the same premise as our proposed 

communication system in that they map out the basic 

vocabulary required to describe a domain, and allow 

people describe aspects of the domain in these terms.  

We have used an API provided by social music web-

site Last.fm to show that it is possible to create relevant 

conversational utterances without any authoring re-

quirement whatsoever. By supplying the users Last.fm 

username, we can use a web service supplied by the site 

to query the user‟s recent activity, for instance the songs 

they have listened to, songs rated highly or events which 

they have signed up to attend. Because the output from 

these services comes as structured XML document we 

can simply map it‟s schema onto our own vocabulary 

and feed the appropriate data to our templates to pro-

duce utterances. 

If web services are to be used we must have an 

equivalent local vocabulary to which we can map the 

data returned from any queries we send the service. 

However, in the case of semantic web sources, for ex-

ample the FOAF (friend-of-a-friend) vocabulary (Brick-

ley) describing online social networks, the process is 

simpler as we can simply use the pre-existing vocabu-

lary standard ourselves rather than having to develop 

our own. Despite the semantic web being in its infancy, 

the notion of shared data is growing in popularity and 

many popular websites and organizations are providing 

access to their information in a structured way. 

One problem with using these types of data acquisi-

tion methods for our purposes is that the data is largely 

generic and any personal opinion or evaluative informa-

tion personal to the user is limited. In some cases we 

may be able to query the data source for a rating 

awarded to a particular piece of content, for instance the 

star rating system on YouTube, but it is not clear how 

expressive the produced language will be since the 

process is likely to be a simple mapping from the rating 

to a suitable adjective. As in our system, the potential 

usefulness of the generated language is likely to be in-

creased if it is possible for the user to annotate the top-

ics with their own canned text expressions and 

evaluations. This will enable the system to express more 

of the individual‟s personality and opinions. 

We believe this is an area of great interest for AAC. 

There is growing evidence of the importance of the in-

ternet in the lives of disabled people, particularly its role 

as a communication medium for people with communi-

cation impairments (Cohen 1999). By harnessing the 

large volumes of data created when using modern hard-

ware and software systems and transforming it into use-

ful utterances, we can begin to address one of the main 

criticisms of whole utterance approaches to AAC since 

there would be no authoring requirement on the part of 

the users.   This is certainly by no means a simple 

process and this approach will require further investiga-

tion, but as semantic web technologies reach maturity 

Figure 3 - System interface 

15



and gain wider adoption it should be clearer what the 

potential of the technology is. 

4 Formal Evaluation Methodology 

In our evaluations so far, we have concentrated on 

training the users in its operation, updating conversa-

tional material and implementing changes based on the 

user feedback. We have recently begun testing the sys-

tem in real conversational encounters and the results 

have been promising. We have found it is possible to 

hold pleasing conversations lasting up to 20 minutes 

with unfamiliar partners, with the aided communicator 

achieving a rate of upwards of 40 wpm. 

There also seems to be higher incidences of initia-

tions on the part of the user, with them making good use 

of both the scripted NLG material, the quick fire phrases 

and their own pre-stored material. The topic progression 

feature is currently being underused but subjects are 

responding well to training sessions on how to incorpo-

rate this to reduce their response time and expand on 

topics to extend the amount they are able to say. 

Formal evaluations are now being undertaken. An 

AB multiple-baseline study design is being conducted in 

which each aided communicator has a series of conver-

sations with 12 unknown and unaided conversation 

partners.  In the A condition, the aided participants use 

their existing AAC system, while in the B condition 

they use our prototype system. Each conversation will 

be limited to approximately 10 minutes, and the ses-

sions will be split across a three non-consecutive days to 

avoid user fatigue.  

There will be at least 3 conversations in both the A 

and B conditions, and the intervention point will be ran-

domized across the remaining 6 conversations to allow 

for valid inferences to be made despite the small n value 

(Todman and Dugard 2001). This also reduces the bias 

introduced by any training effects and avoids the need 

to use a response-guided intervention after baseline per-

formance has been established. The difficulty and ex-

pense of recruiting large numbers of subjects in AAC 

studies is a known problem (Higginbotham 1995) and 

therefore any findings from quantitative analysis per-

formed cannot be generalized across the AAC popula-

tion. However, we expect to be able to achieve a p value 

using the randomization design of <0.05 so the results 

should at least be internally robust and give a good indi-

cation of whether further investigation is warranted.   

The conversations will be audio-recorded and ana-

lyzed for a number of metrics. Primarily we are interest-

ed in measuring the rate at which people are able to 

communicate using the new system as this seems to be 

one of the clearest indicators of success when evaluating 

a new AAC intervention. We expect to the effect size 

observed across the conditions to be large.  

We are also particularly interested whether it is poss-

ible to use automatically generated material while main-

taining or enhancing the enjoyment and quality of the 

encounter for all participants.  It is still unclear how 

acceptable generated material will be to the user so we 

will measure the relative frequency of generated and 

canned-text utterances.  

In previous studies it has also been shown that the 

use of a whole-utterance approach can change the dy-

namics of communication, such as relative speech act 

distribution and number and type of initiation, so we are 

interested to see how the availability generated material 

might impact this and what role it might play. A coding 

schema based on Wang (2007) will be used to categor-

ize the utterances used. 

We are also asking the aided and unaided conversa-

tion partners to complete questionnaires regarding vari-

ous subjective ratings of the interactions and, in the case 

of the unaided speakers, impressions of the aided com-

municator. The questions will be based on a re-

evaluation of those suggested by Todman (2000) and 

answers will be requested on a 7-point rating scale. Pre-

vious work has shown that quicker, flowing interactions 

with less breakdowns or delays can lead to more re-

warding interactions for both participants. We expect to 

observe these effects in our system but it‟s as yet un-

clear what impact the automatically generated phrases 

will have, if any, on perceptions of the user.  

Although the relatively small number of participants 

means it is unlikely that we will be able to make robust 

inferences from this data, we hope that results will be 

indicative of the naturalness and acceptability of auto-

matically generated utterances. 

5 Discussion & Future Plans 

One of the primary reasons that AAC systems featur-

ing NLP technology prove useful is that they go some 

way to leveling the playing field for many users. They 

have the potential to support the user in ways which 

reduce the effort required to communicate yet may im-

prove the quality of the communication. There are many 

NLP technologies, such as NLG, that deserve further 

attention within the field of AAC to determine what 

they can offer.  

Although our system has shown some encouraging 

preliminary results there are still many unanswered 

questions with regards to the role NLG can play.  For 

example, it is not clear how appealing NLG utterances 

16



are to use. Given that the user has not authored the form 

of the utterances themselves there is an argument that 

using them may feel unnatural. After the formal evalua-

tions we should be able provide analysis indicating 

whether NLG phrases are being used and in which sit-

uations they are proving most useful.  

One of the most challenging aspects of designing the 

system was the HCI challenge of incorporating some of 

these technologies. While it is obvious to the user that 

phrases are being generated automatically, and that 

these phrases are generated when a topic is selected, it is 

still important to note that the technologies have been 

intentionally kept largely transparent to the user. When 

using a communication system, the most important 

thing is the ability to say what you want to say, but is 

not yet clear whether the technical nature of the soft-

ware  may be an alienating factor since the user current-

ly has no access to the template construction or domain 

modeling aspects of the system. 

At the current time, the domain modeling and tem-

plate construction processes are quite complex and ex-

pensive. Tools are becoming available, from the NLG 

community, which go some way to addressing the diffi-

culty of interfacing these types of technology to non-

experts (Bilidas, Theologou et al. 2007; Power, Stevens 

et al. 2009) but these are largely unsolved problems. 

Domain modeling itself is problematic in that one 

persons notion of what defines a particular concept is 

often different to someone else‟s. For instance, one per-

son‟s idea of sport might encompass the sporting activi-

ties they take part in, while another person‟s idea of 

sport is that which they follow or watch on the televi-

sion. This has clear implications for the general usabili-

ty of the system.  Using semantic web vocabularies may 

address this somewhat since they are likely to be more 

specific to a particular purpose and be more mature and 

interoperable than the ‘home-brew’ domain models we 

have used for the prototype. 

Using whole-utterance approaches to communication 

clearly requires the adoption of a different mindset. Ra-

ther than being able to construct a novel message the 

user has to „make do’ with whatever is available in the 

system. Despite the advantages observed while using 

such systems, they have still not become generally pop-

ular. It is likely that any NLG whole utterance system 

would similarly not gain immediate acceptance because 

it is vastly different to other systems and approaches to 

communication available. To some degree we are ask-

ing the user of our NLG system to think in an object 

orientated manner since they must understand the un-

derlying model and the way the concepts are structured 

to make the most of the system. Again it is not yet clear 

how natural this process is and how much training is 

required to become an expert user of such a system. 

However perhaps the major strength of these types of 

system is the way in which they help scaffold interac-

tion so the AAC user can be much more active in con-

versation and use an increased repertoire. The design of 

the software is such that it encourages the use of types 

of phrases often underused by AAC users, for example, 

initiations, elaborating moves, questions and the differ-

ent classes of quick-fire remarks. One interesting ques-

tion is whether the use of NLG might make it easier to 

encourage the user to use new types of conversational 

move. Since no full text-authoring is required the user 

does not even have feel confident authoring the utter-

ance, it is simply provided and can be used or experi-

mented with.  Scaffolding interactions in this way may 

be one of the most interesting avenues for NLP and AI 

technologies with AAC in the future. 

 The architecture of the prototype, although effective, 

lacks efficiency and may be difficult to reuse. A great 

deal of work is being done by NLG researchers investi-

gating how NLG architectures might be made more 

modular and reusable. This is an ongoing problem but it 

seems sensible to consider how a pipeline architecture 

(Reiter and Dale 2000) might work in practice for this 

type of system. 

At the moment, the system requires a reasonable lev-

el of literacy because the interface is mainly text based. 

However, semiotic systems are preferred because of the 

literacy problems observed in many AAC users. It is not 

clear how NLG may impact on semiotic message con-

struction but systems such as Compansion (McCoy, 

Pennington et al. 1998) show there may useful applica-

tions in this area too. 

6 Conclusion 

Despite having only been able to perform informal 

evaluations so far, we believe we have seen some en-

couraging signals that NLG may have potential as an 

augmentative communication technology to assist in 

generating conversational utterances.  We believe that 

the rapid access to well-formed, contextually generated 

material offered in our system could lead to significant 

benefits for the AAC user and their interlocutors. 

There are further exciting possibilities with regards to 

the technology, particularly the ability to harvest per-

sonal data from the internet and other computer usage 

so that it can be transformed into useful phrases for in-

clusion in communication aids. We hope to have a rich-

er set of data and results in the coming months after the 

system training and formal evaluations have been com-

pleted.  

17



7 References 

Alm, N. A. (1988). Towards a Conversation Aid for 

Severely Phisically Disabled Non-Speaking People. 

Applied Computing Department. Dundee, University 

Of Dundee. Doctor Philosophy: 197. 

Bilidas, D., M. Theologou, et al. (2007). Enriching 

OWL Ontologies with Linguistic and User-related 

Annotations: the ELEON system. 19th IEEE Interna-

tional Conference on Tools with Artificial Intelli-

gence, IEEE. 

Brickley, D. (25.2.10). "FOAF Vocabulary Specifica-

tion ", from http://xmlns.com/foaf/0.1/  

Clark, H. H. (1996). Using Language, Cambridge Uni-

versity Press. 

Cohen, K. J. (1999). Using the Internet to Empower 

Augmented Communicators. CSUN'99. 

Datillo, J., G. Estrella, et al. (2007). ""I have chosen to 

live life abundantly": Perceptions of leisure by adults 

who use Augmentative and Alternative Communica-

tion." Augmentative & Alternative Communication 

24(1): 16-28. 

Higginbotham, D. J. (1995). "Use of nondisabled sub-

jects in AAC Research : Confessions of a research in-

fidel." Augmentative and Alternative Communication 

11(1): 2-5. 

Higginbotham, D. J., A. M. Bisantz, et al. (2008). "The 

Effect of Context Priming and Task Type on Augmen-

tative Communication Performance." Augmentative & 

Alternative Communication. 

Higginbotham, D. J., H. Shane, et al. (2007). "Access to 

AAC: Present, past, and future." Augmentative & Al-

ternative Communication 23(3): 243-257. 

Karakatsiotis, G., D. Galanis, et al. (2008). Natura-

lOWL: Generating Texts from OWL Ontologies in 

Protege and in Second Life. 18th European Confe-

rence on Artificial Intelligence. 

Light, J. (1988). "Interaction Involving Individuals us-

ing Augmentative and Alternative Communication 

Systems: State of the Art and Future Directions." 

Augmentative and Alternative Communication 4(2): 

66-82. 

McCarthy, J. and J. Light (2005). "Attitudes towards 

individuals who use Augmentative and Alternative 

Communication: Research Review." Augmentative 

and Alternative Communication 21(1): 41-55. 

McCoy, K. F., C. A. Pennington, et al. (1998). "Com-

pansion: From research prototype to practical integra-

tion." Natural Language Engineering 4(1): 73-95. 

Mellish, C. and X. Sun (2005). The Semantic Web as a 

Linguistic Resource: Opportunities for Natural Lan-

guage Generation. International Conference on theory, 

practical and application of Artificial Intelligence. M. 

Bramer, F. Coenen and T. Allen. Cambridge, UK, 

Springer: 77. 

Netzer, Y. and M. Elhadad (2006). Using Semantic Au-

thoring for Blissymbols Communication Boards. 

HLT-2006. 

Power, R., R. Stevens, et al. (2009). Editing OWL 

through generated CNL. Workshop on Controlled 

Natural Language (CNL'09). Marettimo Island, Italy. 

Reiter, E. and R. Dale (2000). Building Natural Lan-

guage Generation Systems. Cambridge Cambridge 

University Press. 

Reiter, E., R. Turner, et al. (2009). Using NLG to help 

language-impaired users tell stories and participate in 

social dialogues. Proceedings of the 12th European 

Workshop on Natural Language Generation. Athens, 

Greece, ACL. 

Sandberg, A. D. and E. Hjelmquist (1997). " Language 

and literacy in nonvocal children with cerebral palsy." 

Reading and Writing 9(2): 107-133. 

Todman, J. (2000). "Rate and quality of conversations 

using a text-storage AAC system: Single-case training 

study." Augmentative and Alternative Communication 

16: 164-179. 

Todman, J. and N. A. Alm (2003). "Modelling conver-

sational pragmatics in communication aids." Journal 

of Pragmatics(35): 523-538. 

Todman, J. and P. Dugard (2001). Single-case and 

small-n experimental designs: A practical guide to 

randomisation tests. Mahwah, NJ, Lawrence Erlbaum 

Associates. 

Todman, J. and H. Rzepecka (2003). "Effect of pre-

utterance pause length on perceptions of communica-

tive competence in AAC-aided social conversations." 

Augmentative and Alternative Communication 19(4): 

222-234. 

Van Deemter, K., E. Krahmer, et al. (2005). "Plan-based 

vs. Template-based NLG: A false opposition?" Com-

putational Linguistics 31(1). 

Waller, A. (1992). Providing Narratives in an Augmen-

tative Communication System. Applied Computing. 

Dundee, University Of Dundee. Doctor of Philoso-

phy: 163. 

Wang, Y. (2007). A model of conversational structure 

for augmentative and alternative communication 

(AAC) systems. University of Dundee, Unpublished 

PhD Thesis. PhD. 

Wisenburn, B. and D. J. Higginbotham (2008). "An 

AAC Application Using Speaking Partner Speech 

Recognition to Automatically Produce Contextually 

Relevant Utterances: Objective Results." Augmenta-

tive and Alternative Communication 24(2): 100-109. 

 

 

 

18


