



















































Incremental Query Generation


Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 183–191,
Gothenburg, Sweden, April 26-30 2014. c©2014 Association for Computational Linguistics

Incremental Query Generation

Laura Perez-Beltrachini
Faculty of Computer Science

Free University of Bozen-Bolzano
Bozen-Bolzano, Italy
laura.perez@loria.fr

Claire Gardent
CNRS/LORIA
Nancy, France

claire.gardent@loria.fr

Enrico Franconi
Faculty of Computer Science

Free University of Bozen-Bolzano
Bozen-Bolzano, Italy

franconi@inf.unibz.it

Abstract

We present a natural language genera-
tion system which supports the incremen-
tal specification of ontology-based queries
in natural language. Our contribution is
two fold. First, we introduce a chart
based surface realisation algorithm which
supports the kind of incremental process-
ing required by ontology-based querying.
Crucially, this algorithm avoids confusing
the end user by preserving a consistent
ordering of the query elements through-
out the incremental query formulation pro-
cess. Second, we show that grammar
based surface realisation better supports
the generation of fluent, natural sounding
queries than previous template-based ap-
proaches.

1 Introduction

Previous research has shown that formal ontolo-
gies could be used as a means not only to provide
a uniform and flexible approach to integrating and
describing heterogeneous data sources, but also to
support the final user in querying them, thus im-
proving the usability of the integrated system. To
support the wide access to these data sources, it is
crucial to develop efficient and user-friendly ways
to query them (Wache et al., 2001).

In this paper, we present a Natural Language
(NL) interface of an ontology-based query tool,
called Quelo1, which allows the end user to for-
mulate a query without any knowledge either of
the formal languages used to specify ontologies, or
of the content of the ontology being used. Follow-
ing the conceptual authoring approach described
in (Tennant et al., 1983; Hallett et al., 2007), this
interface masks the composition of a formal query

1krdbapp.inf.unibz.it:8080/quelo

as the composition of an English text describ-
ing the equivalent information needs using natu-
ral language generation techniques. The natural
language generation system that we propose for
Quelo’s NL interface departs from similar work
(Hallett et al., 2007; Franconi et al., 2010a; Fran-
coni et al., 2011b; Franconi et al., 2010b; Franconi
et al., 2011a) in that it makes use of standard gram-
mar based surface realisation techniques. Our con-
tribution is two fold. First, we introduce a chart
based surface realisation algorithm which supports
the kind of incremental processing required by on-
tology driven query formulation. Crucially, this
algorithm avoids confusing the end user by pre-
serving a consistent ordering of the query ele-
ments throughout the incremental query formu-
lation process. Second, we show that grammar
based surface realisation better supports the gener-
ation of fluent, natural sounding queries than pre-
vious template-based approaches.

The paper is structured as follows. Section 2
discusses related work and situates our approach.
Section 3 describes the task being addressed
namely, ontology driven query formulation. It in-
troduces the input being handled, the constraints
under which generation operates and the opera-
tions the user may perform to build her query.
In Section 4, we present the generation algo-
rithm used to support the verbalisation of possi-
ble queries. Section 5 reports on an evaluation of
the system with respect to fluency, clarity, cover-
age and incrementality. Section 6 concludes with
pointers for further research.

2 Related Work

Our approach is related to two main strands of
work: incremental generation and conceptual au-
thoring.

Incremental Generation (Oh and Rudnicky,
2000) used an n-gram language model to stochas-

183



tically generate system turns. The language model
is trained on a dialog corpus manually annotated
with word and utterance classes. The generation
engine uses the appropriate language model for
the utterance class and generates word sequences
randomly according to the language model distri-
bution. The generated word sequences are then
ranked using a scoring mechanism and only the
best-scored utterance is kept. The system is incre-
mental is that each word class to be verbalised can
yield a new set of utterance candidates. However
it supports only addition not revisions. Moreover
it requires domain specific training data and man-
ual annotation while the approach we propose is
unsupervised and generic to any ontology.

(Dethlefs et al., 2013) use Conditional Random
Fields to find the best surface realisation from a
semantic tree. They show that the resulting sys-
tem is able to modify generation results on the fly
when new or updated input is provided by the dia-
log manager. While their approach is fast to ex-
ecute, it is limited to a restricted set of domain
specific attributes; requires a training corpus of
example sentences to define the space of possi-
ble surface realisations; and is based on a large
set (800 rules) of domain specific rules extracted
semi-automatically from the training corpus. In
contrast, we use a general, small size grammar
(around 50 rules) and a lexicon which is automat-
ically derived from the input ontologies. The re-
sulting system requires no training and thus can
be applied to any ontology with any given signa-
ture of concepts and relations. Another difference
between the two approaches concerns revisions:
while our approach supports revisions anywhere
in the input, the CRF approach proposed by (Deth-
lefs et al., 2013) only supports revisions occurring
at the end of the generated string.

There is also much work (Schlangen and
Skantze, 2009; Schlangen et al., 2009) in the do-
main of spoken dialog systems geared at mod-
elling the incremental nature of dialog and in par-
ticular, at developing dialog systems where pro-
cessing starts before the input is complete. In these
approaches, the focus is on developing efficient ar-
chitectures which support the timely interleaving
of parsing and generation. Instead, our aim is to
develop a principled approach to the incremental
generation of a user query which supports revision
and additions at arbitrary points of the query being
built; generates natural sounding text; and maxi-

mally preserves the linear order of the query.

Conceptual authoring Our proposal is closely
related to the conceptual authoring approach de-
scribed in (Hallett et al., 2007). In this approach,
a text generated from a knowledge base, describes
in natural language the knowledge encoded so far,
and the options for extending it. Starting with an
initial very general query (e.g., all things), the user
can formulate a query by choosing between these
options. Similarly, (Franconi et al., 2010a; Fran-
coni et al., 2011b; Franconi et al., 2010b; Fran-
coni et al., 2011a) describes a conceptual author-
ing approach to querying semantic data where in
addition , logical inference is used to semantically
constrain the possible completions/revisions dis-
played to the user.

Our approach departs from this work in that it
makes use of standard grammars and algorithms.
While previous work was based on procedures and
templates, we rely on a Feature-Based Tree Ad-
joining Grammar to capture the link between text
and semantics required by conceptual authoring;
and we adapt a chart based algorithm to support
the addition, the revision and the substitution of
input material. To avoid confusing the user, we
additionally introduce a scoring function which
helps preserve the linear order of the NL query.
The generation system we present is in fact inte-
grated in the Quelo interface developed by (Fran-
coni et al., 2011a) and compared with their previ-
ous template-based approach.

3 Incremental Generation of Candidate
Query Extensions

The generation task we address is the following.
Given a knowledge base K , some initial formal
query q and a focus point p in that query, the rea-
soning services supported by Quelo’s query logic
framework (see (Guagliardo, 2009)) will compute
a set of new queries rev(q) formed by adding,
deleting and revising the current query q at point
p. The task of the generator is then to produce
a natural language sentence for each new formal
query q′ ∈ rev(q) which results from this revision
process. In other words, each time the user refines
a query q to produce a new query q′, the system
computes all revisions rev(q) of q′ that are com-
patible with the underlying knowledge base using
a reasoner. Each of these possible revisions is then
input to the generator and the resulting revised NL
queries are displayed to the user. In what follows,

184



we assume that formal queries are represented us-
ing Description Logics (Baader, 2003).

The following examples show a possible se-
quence of NL queries, their corresponding DL rep-
resentation and the operations provided by Quelo
that can be performed on a query (bold face is used
to indicate the point in the query at which the next
revision takes place). For instance, the query in
(1c) results from adding the concept Y oung to the
query underlying (1b) at the point highlighted by
man.

(1) a. I am looking for something (initial query)
⊤

b. I am looking for a man (substitute con-
cept)
Man

c. I am looking for a young man (add com-
patible concept)
Man ⊓ Y oung

d. I am looking for a young man who is
married to a person (add relation)
Man⊓Y oung⊓∃isMarried.(Person)

e. I am looking for a young married man
(substitute selection)
MarriedMan ⊓ Y oung

f. I am looking for a married man (delete
concept)
MarriedMan

4 Generating Queries

Generation of KB queries differs from standard
natural language generation algorithms in two
main ways. First it should support the revi-
sions, deletions and additions required by incre-
mental processing. Second, to avoid confusing
the user, the revisions (modifications, extensions,
deletions) performed by the user should have a
minimal effect on the linear order of the NL query.
That is the generator is not free to produce any NL
variant verbalising the query but should produce
a verbalisation that is linearly as close as possi-
ble, modulo the revision applied by the user, to the
query before revisions. Thus for instance, given
the DL query (2) and assuming a linearisation of
that formula that matches the linear order it is pre-
sented in (see Section 4.2.1 below for a definition
of the linearisation of DL formulae), sentence (2b)
will be preferred over (2c).

(2) a. Car ⊓ ∃runOn.(Diesel) ⊓
∃equippedWith.(AirCond)

b. A car which runs on Diesel and is
equipped with air conditioning

c. A car which is equipped with air condi-
tioning and runs on Diesel

In what follows, we describe the generation al-
gorithm used to verbalise possible extensions of
user queries as proposed by the Quelo tool. We
start by introducing and motivating the underlying
formal language supported by Quelo and the input
to the generator. We then describe the overall ar-
chitecture of our generator. Finally, we present the
incremental surface realisation algorithm support-
ing the verbalisation of the possible query exten-
sions.

4.1 The Input Language

Following (Franconi et al., 2010a; Franconi et al.,
2011b; Franconi et al., 2010b; Franconi et al.,
2011a) we assume a formal language for queries
that targets the querying of various knowledge and
data bases independent of their specification lan-
guage. To this end, it uses a minimal query lan-
guage L that is shared by most knowledge repre-
sentation languages and is supported by Descrip-
tion Logic (DL) reasoners namely, the language of
tree shaped conjunctive DL queries. Let R be a
set of relations and C be a set of concepts, then the
language of tree-shaped conjunctive DL queries is
defined as follows: S ::= C | ∃R.(S) | S ⊓ S
where R ∈ R, C ∈ C, ⊓ denotes conjunction and
∃ is the existential quantifier.

A tree shaped conjunctive DL query can be rep-
resented as a tree where nodes are associated with
a set of concept names (node labels) and edges are
labelled with a relation name (edge labels). Figure
1 shows some example query trees.

4.2 NLG architecture

Our generator takes as input two L formula: the
formula representing the current query q and the
formula representing a possible revision r (addi-
tion/deletion/modification) of q. Given this in-
put, the system architecture follows a traditional
pipeline sequencing a document planner which (i)
linearises the input query and (ii) partition the in-
put into sentence size chunks; a surface realiser
mapping each sentence size L formula into a sen-
tence; and a referring expression generator verbal-
ising NPs.

4.2.1 Document Planning

The document planning module linearises the in-
put query and segments the resulting linearised

185



x {Man}

(a)

x

w

{Man}

{House}

livesIn

(b)

x

w

z

{Man}

{House}

livesIn

{RichPerson}

ownedBy

(c)

x

w

z

{Man}

{House,
Beautiful}

livesIn

{RichPerson}

ownedBy

(d)

✬

✫

✩

✪

x

y w

z

{Man}

{Person}

{House,
Beautiful}

{RichPerson}

marriedTo livesIn

ownedBy

(e)

Figure 1: Example of query tree and incremental query construction.

query into sentence size chunks.

Query Linearisation Among the different
strategies investigated in (Dongilli, 2008) to
find a good order for the content contained in a
query tree the depth-first planning, i.e. depth-first
traversal of the query tree, was found to be the
most appropriate one. Partly because it is obtained
straightforward from the query tree but mostly
due to the fact that it minimizes the changes in the
text plan that are required by incremental query
modifications. Thus, (Franconi et al., 2010a)
defines a query linearisation as a strict total order2

on the query tree that satisfies the following
conditions:

• all labels associated with the edge’s leaving
node precede the edge label

• the edge label is followed by at least one label
associated with the edge’s arriving node

• between any two labels of a node there can
only be (distinct) labels of the same node

The specific linearisation adopted in Quelo is
defined by the depth-first traversal strategy of the
query tree and a total order on the children which
is based on the query operations. That is, the la-
bels of a node are ordered according to the se-
quence applications of the add compatible
concept operation. The children of a node are
inversely ordered according to the sequence of ap-
plications of the add relation operation.

According to this linearisation definition, for
the query tree (e) in Figure 1 the following linear
order is produced:

(3) a. Man marriedTo Person livesIn House
Beautiful ownedBy RichPeron

2A strict total order can be obtained by fixing an order in
the children nodes and traversing the tree according to some
tree traversal strategy.

Query Segmentation Given a linearised query
q, the document planner uses some heuristics
based on the number and the types of rela-
tions/concepts present in q to output a sequence
of sub-formulae each of which will be verbalised
as a sentence.

4.2.2 Incremental Surface Realisation and
Linearisation Constraints

We now describe the main module of the generator
namely the surface realiser which supports both
the incremental refinement of a query and a min-
imal modification of the linear order between in-
crements. This surface realiser is caracterised by
the following three main features.

Grammar-Based We use a symbolic, grammar-
based approach rather than a statistical one for two
reasons. First, there is no training corpus available
that would consist of knowledge base queries and
their increments. Second, the approach must be
portable and should apply to any knowledge base
independent of the domain it covers and indepen-
dent of the presence of a training corpus. By com-
bining a lexicon automatically extracted from the
ontology with a small grammar tailored to produce
natural sounding queries, we provide a generator
which can effectively apply to any ontology with-
out requiring the construction of a training corpus.

Chart-Based A chart-based architecture en-
hances efficiency by avoiding the recomputation
of intermediate structures while allowing for a
natural implementation of the revisions (addition,
deletion, substitution) operations required by the
incremental formulation of user queries. We show
how the chart can be used to implement these op-
erations.

Beam search. As already mentioned, for er-
gonomic reasons, the linear order of the gener-
ated NL query should be minimally disturbed dur-
ing query formulation. The generation system

186



should also be sufficiently fast to support a timely
Man/Machine interaction. We use beam search
and a customised scoring function both to preserve
linear order and to support efficiency.

We now introduce each of these components in
more details.

Feature-Based Tree Adjoining Grammar
A tree adjoining grammar (TAG) is a tuple
〈Σ, N, I,A, S〉 with Σ a set of terminals, N a set
of non-terminals, I a finite set of initial trees, A a
finite set of auxiliary trees, and S a distinguished
non-terminal (S ∈ N ). Initial trees are trees
whose leaves are labeled with substitution nodes
(marked with a down-arrow) or with terminal
categories3 . Auxiliary trees are distinguished by
a foot node (marked with a star) whose category
must be the same as that of the root node.

Two tree-composition operations are used to
combine trees: substitution and adjunction. Sub-
stitution inserts a tree onto a substitution node of
some other tree while adjunction inserts an aux-
iliary tree into a tree. In a Feature-Based Lexi-
calised TAG (FB-LTAG), tree nodes are further-
more decorated with two feature structures which
are unified during derivation; and each tree is an-
chored with a lexical item. Figure 2 shows an ex-
ample toy FB-LTAG with unification semantics.
The dotted arrows indicate possible tree combina-
tions (substitution for John, adjunction for often).
As the trees are combined, the semantics is the
union of their semantics modulo unification. Thus
given the grammar and the derivation shown, the
semantics of John often runs is as shown namely,
named(j john), run(a,j), often(a).

NPj

John

l1:john(j)

Sb

NP↓c VPba
Va

runs

lv:run(a,j)

VPx

often VP*x
lo:often(x)

l1:named(j john), lv:run(a,j), lv:often(a)

Figure 2: Derivation and Semantics for “John often runs”

Chart-Based Surface Realisation Given an
FB-LTAG G of the type described above, sen-
tences can be generated from semantic formulae
by (i) selecting all trees in G whose semantics sub-
sumes part of the input formula and (ii) combining

3For a more detailed introduction to TAG and FB-LTAG,
see (Vijay-Shanker and Joshi, 1988).

these trees using the FB-LTAG combining opera-
tions namely substitution and adjunction. Thus for
instance, in Figure 2, given the semantics l1:named(j
john), lv:run(a,j), lv:often(a), the three trees shown are
selected. When combined they produce a com-
plete phrase structure tree whose yield (John runs
often) is the generated sentence.

Following (Gardent and Perez-Beltrachini,
2011), we implement an Earley style generation
algorithm for FB-LTAG which makes use of the
fact that the derivation trees of an FB-LTAG are
context free and that an FB-LTAG can be con-
verted to a a Feature-Based Regular Tree Gram-
mar (FB-RTG) describing the derivation trees of
this FB-LTAG4.

On the one hand, this Earley algorithm en-
hances efficiency in that (i) it avoids recomput-
ing intermediate structures by storing them and
(ii) it packs locally equivalent structures into a
single representative (the most general one). Lo-
cally equivalent structures are taken to be partial
derivation trees with identical semantic coverage
and similar combinatorics (same number and type
of substitution and adjunction requirements).

On the other hand, it naturally supports the
range of revisions required for the incremental for-
mulation of ontology-based queries. Let C be the
current chart i.e., the chart built when generating a
NL query from the formal query. Then additions,
revisions and deletion can be handled as follows.

• Add concept or property X: the grammar
units selected by X are added to the agenda5

and tried for combinations with the elements
of C .

• Substitute selection X with Y : all chart items
derived from a grammar unit selected by an
element of X are removed from the chart.
Conversely, all chart items derived from a
grammar unit selected by an element of Y are
added to the agenda. All items in the agenda
are then processed until generation halts.

• Delete selection X: all chart items derived
from a grammar unit selected by an element
of X are removed from the chart. Intermedi-
ate structures that had previously used X are
moved to the agenda and the agenda is pro-
cessed until generation halts.

4For more details on this algorithm, we refer the reader to
(Gardent and Perez-Beltrachini, 2010).

5The agenda is a book keeping device which stores all
items that needs to be processed i.e., which need to be tried
for combination with elements in the chart.

187



Beam Search To enhance efficiency and favor
those structures which best preserve the word or-
der while covering maximal input, we base our
beam search on a scoring function combining lin-
ear order and semantic coverage information. This
works as follows. First, we associate each literal
in the input query with its positional information
e.g.,
(4) a. man(x)[0] marriedTo(x y)[1]

person(y)[2] livesIn(x w)[3]

house(w)[4]

This positional information is copied over to
each FB-LTAG tree selected by a given literal and
is then used to compute a word order cost (Cwo)
for each derived tree as follows:

Cwo(ti+j) = Cwo(ti) + Cwo(tj) + Cwo(ti + tj)

That is the cost of a tree ti+j obtained by com-
bining ti and tj is the sum of the cost of each
of these trees plus the cost incurred by combin-
ing these two trees. We define this latter cost to
be proportional to the distance separating the ac-
tual position (api) of the tree (ti) being substi-
tuted/adjoined in from its required position (rpi).
If ti is substituted/adjoined at position n to the
right (left) of the anchor of a tree tj with posi-
tion pj , then the actual position of ti is pj + n
(pj − n) and the cost of combining ti with tj is
| pj + n − rpi | /α (| pj − n − rpi | /α) where
we empirically determined α to be 1006.

Finally, the total score of a tree reflects the rela-
tion between the cost of the built tree, i.e. its word
order cost, and its semantic coverage, i.e. nb. of
literals from the input semantics:

S(ti) =

{
−(|literals| − 1) Cwo(ti) = 0
Cwo(ti)/(|literals| − 1) otherwise

The total score is defined by cases. Those trees
with Cwo = 0 get a negative value according to
their input coverage (i.e. those that cover a larger
subset of the input semantics are favored as the
trees in the agenda are ordered by increasing total
score). Conversely, those trees with Cwo > 0 get
a score that is the word order cost proportional to
the covered input.

In effect, this scoring mechanism favors trees
with low word order cost and large semantic cov-
erage. The beam search will select those trees with
lowest score.

6In the current implementation we assume that n = 1.
Furthermore, as ti might be a derived tree we also add to
Cwo(ti + tj) the cost computed on each tree tk used in the
derivation of ti with respect to tj .

4.2.3 Referring Expression Generation

The referring expression (RE) module takes as
input the sequence of phrase structure trees out-
put by the surface realiser and uses heuristics to
decide for each NP whether it should be ver-
balised as a pronoun, a definite or an indefinite
NP. These heuristics are based on the linear order
and morpho-syntactic information contained in the
phrase structure trees of the generated sentences.

5 Experiments and evaluation

We conducted evaluation experiments designed to
address the following questions:

• Does the scoring mechanism appropriately
capture the ordering constraints on the gen-
erated queries ? That is, does it ensure that
the generated queries respect the strict total
order of the query tree linearisation ?

• Does our grammar based approach produce
more fluent and less ambiguous NL query
than the initial template based approach cur-
rently used by Quelo ?

• Does the automatic extraction of lexicons
from ontology support generic coverage of
arbitrary ontologies ?

We start by describing the grammar used. We
then report on the results obtained for each of these
evaluation points.

5.1 Grammar and Lexicon

We specify an FB-LTAG with unification seman-
tics which covers a set of basic constructions used
to formulate queries namely, active and passive
transitive verbs, adjectives, prepositional phrases,
relative and elliptical clauses, gerund and partici-
ple modifiers. The resulting grammar consists of
53 FB-LTAG pairs of syntactic trees and semantic
schema.

To ensure the appropriate syntax/semantic in-
terface, we make explicit the arguments of a
relation using the variables associated with the
nodes of the query tree. Thus for instance,
given the rightmost query tree shown in Figure
1, the flat semantics input to surface realisation is
{Man(x), Person(y), House(w), Beautiful(w), RichPerson(z),
marriedTo(x,y), livesIn(x,w), ownedBy(w,z)}.

For each ontology, a lexicon mapping con-
cepts and relations to FB-LTAG trees is automat-
ically derived from the ontology using (Trevisan,
2010)’s approach. We specify for each experiment
below, the size of the extracted lexicon.

188



5.2 Linearisation

In this first experiment, we manually examined
whether the incremental algorithm we propose
supports the generation of NL queries whose word
order matches the linearisation of the input query
tree.

We created four series of queries such that each
serie is a sequence q1 . . . qn where qi+1 is an in-
crement of qi. That is, qi+1 is derived from qi
by adding, removing or substituting to qi a con-
cept or a relation. The series were devised so as to
encompass the whole range of possible operations
at different points of the preceding query (e.g., at
the last node/edge or on some node/edge occur-
ring further to the left of the previous query); and
include 14 revisions on 4 initial queries.

For all queries, the word order of the best NL
query produced by the generator was found to
match the linearisation of the DL query.

5.3 Fluency and Clarity

Following the so-called consensus model (Power
and Third, 2010), the current, template based ver-
sion of Quelo generates one clause per relation7.
Thus for instance, template-based Quelo will gen-
erate (5a) while our grammar based approach sup-
ports the generation of arguably more fluent sen-
tences such as (5b).

(5) a. I am looking for a car. Its make should
be a Land Rover. The body style of the
car should be an off-road car. The exterior
color of the car should be beige.

b. I am looking for car whose make is a Land
Rover, whose body style is an off-road car
and whose exterior color is beige.

We ran two experiments designed to assess how
fluency impacts users. The first experiment aims
to assess how Quelo template based queries are
perceived by the users in terms of clarity and flu-
ency, the second aims to compare these template
based queries with the queries produced by our
grammar-based approach.

Assessing Quelo template-based queries Us-
ing the Quelo interface, we generated a set of
41 queries chosen to capture different combina-
tions of concepts and relations. Eight persons
(four native speakers of English, four with C2

7This is modulo aggregation of relations. Thus two sub-
ject sharing relations may be realised in the same clause.

level of competence for foreign learners of En-
glish) were then asked to classify (a binary choice)
each query in terms of clarity and fluency. Fol-
lowing (Kow and Belz, 2012), we take Fluency
to be a single quality criterion intended to cap-
ture language quality as distinct from its meaning,
i.e. how well a piece of text reads. In contrast,
Clarity/ambiguity refers to ease of understanding
(Is the sentence easy to understand?). Taking the
average of the majority vote, we found that the
judges evaluated the queries as non fluent in 50%
of the cases and as unclear in 10% of the cases.
In other words, template based queries were found
to be disfluent about half of the time and unclear
to a lesser extent. The major observation made by
most of the participants was that the generated text
is too repetitive and lacks aggregation.

Figure 3: Online Evaluation.

Comparing template- and grammar-based
queries In this second experiment, we asked 10
persons (all proficient in the English language) to
compare pairs of NL queries where one query is
produced using templates and the other using our
grammar-based generation algorithm. The evalu-
ation was done online using the LG-Eval toolkit
(Kow and Belz, 2012) and geared to collect rel-
ative quality judgements using visual analogue
scales. After logging in, judges were given a de-
scription of the task. The sentence pairs were dis-
played as shown in Figure 3 with one sentence to
the left and the other to the right. The judges were
instructed to move the slider to the left to favor
the sentence shown on the left side of the screen;
and to the right to favor the sentence appearing to
the right. Not moving the slider means that both
sentences rank equally. To avoid creating a bias,

189



the sentences from both systems were equally dis-
tributed to both sides of the screen.

For this experiment, we used 14 queries built
from two ontologies, an ontology on cars and the
other on universities. The extracted lexicons for
each of these ontology contained 465 and 297 en-
tries respectively.

The results indicate that the queries generated
by the grammar based approach are perceived as
more fluent than those produced by the template
based approach (19.76 points in average for the
grammar based approach against 7.20 for the tem-
plate based approach). Furthermore, although the
template based queries are perceived as clearer
(8.57 for Quelo, 6.87 for our approach), the dif-
ference is not statistically significant (p < 0.5).
Overall thus, the grammar based approach appears
to produce verbalisations that are better accepted
by the users. Concerning clarity, we observed that
longer sentences let through by document plan-
ning were often deemed unclear. In future work,
we plan to improve clarity by better integrating
document planning and sentence realisation.

5.4 Coverage

One motivation for the symbolic based approach
was the lack of training corpus and the need for
portability: the query interface should be usable
independently of the underlying ontology and of
the existence of a training corpus. To support
coverage, we combined the grammar based ap-
proach with a lexicon which is automatically ex-
tracted from the ontology using the methodology
described in (Trevisan, 2010). When tested on
a corpus of 200 ontologies, this approach was
shown to be able to provide appropriate verbalisa-
tion templates for about 85% of the relation iden-
tifiers present in these ontologies. 12 000 relation
identifiers were extracted from the 200 ontologies
and 13 syntactic templates were found to be suf-
ficient to verbalise these relation identifiers (see
(Trevisan, 2010) for more details on this evalua-
tion).

That is, in general, the extracted lexicons permit
covering about 85% of the ontological data. In ad-
dition, we evaluated the coverage of our approach
by running the generator on 40 queries generated
from five distinct ontologies. The domains ob-
served are cinema, wines, human abilities, dis-
abilities, and assistive devices, e-commerce on the
Web, and a fishery database for observations about

an aquatic resource. The extracted lexicons con-
tained in average 453 lexical entries and the cov-
erage (proportion of DL queries for which the gen-
erator produced a NL query) was 87%.

Fuller coverage could be obtained by manually
adding lexical entries, or by developing new ways
of inducing lexical entries from ontologies (c.f.
e.g. (Walter et al., 2013)).

6 Conclusion

Conceptual authoring (CA) allows the user to
query a knowledge base without having any
knowledge either of the formal representation lan-
guage used to specify that knowledge base or of
the content of the knowledge base. Although this
approach builds on a tight integration between
syntax and semantics and requires an efficient pro-
cessing of revisions, existing CA tools predomi-
nantly make use of ad hoc generation algorithms
and restricted computational grammars (e.g., Def-
inite Clause Grammars or templates). In this pa-
per, we have shown that FB-LTAG and chart based
surface realisation provide a natural framework in
which to implement conceptual authoring. In par-
ticular, we show that the chart based approach nat-
urally supports the definition of an incremental al-
gorithm for query verbalisation; and that the added
fluency provided by the grammar based approach
potentially provides for query interfaces that are
better accepted by the human evaluators.

In the future, we would like to investigate the
interaction between context, document structuring
and surface realisation. In our experiments we
found out that this interaction strongly impacts flu-
ency whereby for instance, a complex sentence
might be perceived as more fluent than several
clauses but a too long sentence will be perceived
as difficult to read (non fluent). Using data that
can now be collected using our grammar based
approach to query verbalisation and generalising
over FB-LTAG tree names rather than lemmas or
POS tags, we plan to explore how e.g., Conditional
Random Fields can be used to model these inter-
actions.

Acknowledgments

We would like to thank Marco Trevisan, Paolo
Guagliardo and Alexandre Denis for facilitating
the access to the libraries they developed and to
Natalia Korchagina and the judges who partici-
pated in the evaluation experiments.

190



References

Franz Baader. 2003. The description logic handbook:
theory, implementation, and applications. Cam-
bridge university press.

Nina Dethlefs, Helen Hastie, Heriberto Cuayáhuitl, and
Oliver Lemon. 2013. Conditional Random Fields
for Responsive Surface Realisation using Global
Features. Proceedings of ACL, Sofia, Bulgaria.

Paolo Dongilli. 2008. Natural language rendering of a
conjunctive query. KRDB Research Centre Techni-
cal Report No. KRDB08-3). Bozen, IT: Free Univer-
sity of Bozen-Bolzano, 2:5.

E. Franconi, P. Guagliardo, and M. Trevisan. 2010a.
An intelligent query interface based on ontology
navigation. In Workshop on Visual Interfaces to the
Social and Semantic Web, VISSW, volume 10. Cite-
seer.

E. Franconi, P. Guagliardo, and M. Trevisan. 2010b.
Quelo: a NL-based intelligent query interface. In
Pre-Proceedings of the Second Workshop on Con-
trolled Natural Languages, volume 622.

E. Franconi, P. Guagliardo, S. Tessaris, and M. Tre-
visan. 2011a. A natural language ontology-driven
query interface. In 9th International Conference on
Terminology and Artificial Intelligence, page 43.

E. Franconi, P. Guagliardo, M. Trevisan, and S. Tes-
saris. 2011b. Quelo: an Ontology-Driven Query
Interface. In Description Logics.

C. Gardent and L. Perez-Beltrachini. 2010. RTG based
Surface Realisation for TAG. In COLING’10, Bei-
jing, China.

B. Gottesman Gardent, C. and L. Perez-Beltrachini.
2011. Using regular tree grammar to enhance sur-
face realisation. Natural Language Engineering,
17:185–201. Special Issue on Finite State Methods
and Models in Natural Language Processing.

Paolo Guagliardo. 2009. Theoretical foundations of
an ontology-based visual tool for query formulation
support. Technical report, KRDB Research Centre,
Free University of Bozen-Bolzano, October.

C. Hallett, D. Scott, and R. Power. 2007. Composing
questions through conceptual authoring. Computa-
tional Linguistics, 33(1):105–133.

Eric Kow and Anja Belz. 2012. LG-Eval: A Toolkit
for Creating Online Language Evaluation Experi-
ments. In LREC, pages 4033–4037.

Alice H Oh and Alexander I Rudnicky. 2000. Stochas-
tic language generation for spoken dialogue sys-
tems. In Proceedings of the 2000 ANLP/NAACL
Workshop on Conversational systems-Volume 3,
pages 27–32. Association for Computational Lin-
guistics.

R. Power and A. Third. 2010. Expressing owl ax-
ioms by english sentences: dubious in theory, fea-
sible in practice. In Proceedings of the 23rd Inter-
national Conference on Computational Linguistics:
Posters, pages 1006–1013. Association for Compu-
tational Linguistics.

David Schlangen and Gabriel Skantze. 2009. A gen-
eral, abstract model of incremental dialogue pro-
cessing. In Proceedings of the 12th Conference of
the European Chapter of the Association for Com-
putational Linguistics, pages 710–718. Association
for Computational Linguistics.

David Schlangen, Timo Baumann, and Michaela At-
terer. 2009. Incremental reference resolution: The
task, metrics for evaluation, and a bayesian filtering
model that is sensitive to disfluencies. In Proceed-
ings of the SIGDIAL 2009 Conference: The 10th An-
nual Meeting of the Special Interest Group on Dis-
course and Dialogue, pages 30–37. Association for
Computational Linguistics.

H. R Tennant, K. M Ross, R. M Saenz, C. W Thomp-
son, and J. R Miller. 1983. Menu-based natural lan-
guage understanding. In Proceedings of the 21st an-
nual meeting on Association for Computational Lin-
guistics, pages 151–158. Association for Computa-
tional Linguistics.

Marco Trevisan. 2010. A Portable Menuguided Nat-
ural Language Interface to Knowledge Bases for
Querytool. Ph.D. thesis, Masters thesis, Free Uni-
versity of Bozen-Bolzano (Italy) and University of
Groningen (Netherlands).

K. Vijay-Shanker and A. Joshi. 1988. Feature based
tags. In Proceedings of the 12th International Con-
ference of the Association for Computational Lin-
guistics, pages 573–577, Budapest.

Holger Wache, Thomas Voegele, Ubbo Visser, Heiner
Stuckenschmidt, Gerhard Schuster, Holger Neu-
mann, and Sebastian Hübner. 2001. Ontology-
based integration of information-a survey of existing
approaches. In IJCAI-01 workshop: ontologies and
information sharing, volume 2001, pages 108–117.
Citeseer.

Sebastian Walter, Christina Unger, and Philipp Cimi-
ano. 2013. A corpus-based approach for the induc-
tion of ontology lexica. In Natural Language Pro-
cessing and Information Systems, pages 102–113.
Springer.

191


