










































The UWB Summariser at Multiling-2013


Proceedings of the MultiLing 2013 Workshop on Multilingual Multi-document Summarization, pages 50–54,
Sofia, Bulgaria, August 9 2013. c©2013 Association for Computational Linguistics

The UWB Summariser at Multiling-2013

Josef Steinberger
University of West Bohemia
Faculty of Applied Sciences

Department of Computer Science and Engineering, NTIS Centre
Univerzitni 8, 30614 Plzeň, Czech Republic

jstein@kiv.zcu.cz

Abstract

The paper describes our participation in
the Multi-document summarization task of
Multiling-2013. The community initiative
was born as a pilot task for the Text Analy-
sis Conference in 2011. This year the cor-
pus was extended by new three languages
and another five topics, covering in total
15 topics in 10 languages. Our summariser
is based on latent semantic analysis and it
is in principle language independent. Its
results on the Multiling-2011 corpus were
promising. The generated summaries were
ranked first in several languages based on
various metrics. The summariser with mi-
nor changes was run on the updated 2013
corpus. Although we do not have the man-
ual evaluation results yet the ROUGE-2
score indicates good results again. The
summariser produced best summaries in 6
from 10 considered languages according
to the ROUGE-2 metric.

1 Introduction

Multi-document summarization has received in-
creasing attention during the last decade. This
was mainly due to the requirement of news mon-
itoring to reduce the big bulk of highly redun-
dant news data. More and more interest arises
for approaches that will be able to be applied on
a variety of languages. The summariser should
be of high quality. However, when applied in
a highly multilingual environment, it has to be
enough language-independent to guarantee simi-
lar performance across languages.

Given the lack of multilingual summarisation
evaluation resources, the summarisation commu-
nity started to discuss the topic at Text Analy-
sis Conference (TAC1) 2010. It resulted in the

1http://www.nist.gov/tac/

first multilingual shared task organised as part of
TAC 2011 – Multiling-2011 (Giannakopoulos et
al., 2012). Each group took an active role in the
creation of their language subcorpus. Because no
freely available parallel corpus suitable for multi-
document summarisation was found, news clus-
ters from WikiNews (in English) needed to be first
translated to six other languages. Three model
summaries for each cluster were then written and
both model and peer summaries were manually
evaluated. For Multiling-2013, three new lan-
guages were added (Chinese, Romanian and Span-
ish) and 5 new topics (news clusters) were added
to the corpus.

This article contains the description of our
system based on latent semantic analysis (LSA)
which participated in Multiling-2013. We first
briefly discuss the multi-document task in sec-
tion 2. Then we show our summarisation ap-
proach based on LSA (Section 3). The next sec-
tion (4) compares the participating systems based
on the ROUGE-2 score. Manually assigned scores
were not available at the time of creation of this
report. We conclude by a discussion of possi-
ble improvements of the method which require
language-specific resources.

2 Multi-document summarisation task at
Multiling’13

MultiLing-2013 is a community effort, a set of re-
search tasks and a corresponding workshop which
covers three summarisation tasks, focused on the
multilingual aspect. It aims to evaluate the appli-
cation of (partially or fully) language-independent
summarization algorithms on a variety of lan-
guages.

The annotation part consisted of four phases.
The first phase was to select English WikiNews ar-
ticles about the same event and to create the topics.
The articles were then manually translated to the
other languages. Model summaries were created

50



separately for each language by native speakers.
In a certain time frame, participating groups ran
their summarisers and the automatic summaries
were then evaluated, both manually (on a 5-to-1
scale) and automatically by ROUGE (Lin, 2004)
and the AutoSummENG metric (Giannakopoulos
and Karkaletsis, 2010).

We participated with our summariser in the
main multi-document task, which requires to gen-
erate a single, fluent, representative summary from
a set of 10 documents describing an event se-
quence. The language of the document set (topic)
was within a given range of 10 languages (Arabic,
Chinese, Czech, English, French, Greek, Hebrew,
Hindi, Romanian and Spanish) and all documents
in a set share the same language. The output sum-
mary should be of the same language as its source
documents. The output summary should be 250
words at most. The corpus was extended to 15 top-
ics (Chinese, French and Hindi subcorpora con-
tained only 10 topics).

3 LSA-based summarisation approach

Originally proposed by Gong and Liu (2002) and
later improved by Steinberger and Jez̆ek (2004),
this approach first builds a term-by-sentence ma-
trix from the source, then applies Singular Value
Decomposition (SVD) and finally uses the result-
ing matrices to identify and extract the most salient
sentences. SVD finds the latent (orthogonal) di-
mensions, which in simple terms correspond to the
different topics discussed in the source.

More formally, we first build matrix A where
each column represents the weighted term-
frequency vector of a sentence in a given set of
documents. The weighting scheme we found to
work best is using a binary local weight and an
entropy-based global weight (for details see Stein-
berger and Jez̆ek (2009)).

After that step Singular Value Decomposition
(SVD) is applied to the above matrix as A =
USVT , and subsequently matrix F = S · VT re-
duced to r dimensions2 is derived.

Sentence selection starts with measuring the
length of sentence vectors in matrix F computed as
the Euclidean norm. The length of the vector (the
sentence score) can be viewed as a measure for

2The degree of importance of each ‘latent’ topic is given
by the singular values and the optimal number of latent topics
(i.e., dimensions) r can be fine-tuned on training data. Our
previous experiments led us to set r to 8% from the number
of sentences for 250-word summaries.

importance of that sentence within the top cluster
topics.

The sentence with the largest score is selected as
the first to go to the summary (its corresponding
vector in F is denoted as fbest). After placing it
in the summary, the topic/sentence distribution in
matrix F is changed by subtracting the information
contained in that sentence:

F(it+1) = F(it) − fbest · f
T
best

|fbest|2
· F(it). (1)

The vector lengths of similar sentences are de-
creased, thus preventing within summary redun-
dancy. After the subtraction of information in
the selected sentence, the process continues with
the sentence which has the largest score computed
on the updated matrix F. The process is itera-
tively repeated until the required summary length
is reached.

4 Experiments and results

Although the approach works only with term co-
occurrence, and thus it is completely language-
independent, pre-processing plays an important
role and greatly affects the performance. When
generating the summaries for Multiling-2013 each
article was split into sentences. We used the
old DUC sentence splitter3, although a different
sentence-splitting character was used for Chinese.
It was a simplification because the sentence split-
ter should be adapted for each language (e.g. a
different list of abbreviations should be used or
language specific features should be added). If
LSA is applied on a large matrix stopwords can be
found in the first linear combination which could
be then filtered out. However, in our case we apply
it on rather small matrices and stopwords could
affect negatively the topic distribution. Thus the
safer option is to filter them out. This brings a
dependency on a language but, on the other hand,
acquiring lists of stop-words for various languages
is not difficult. Filtering these insignificant terms
does not also slow down the system. The stop-
words were filtered out for all the languages of
Multiling. The approach discussed in section 3
was then used to select sentences until the re-
quired summary length (250 words) has not been
reached. Sentence order is important for event-
based stories. In the case of the Multiling corpus,

3http://duc.nist.gov/duc2004/software/duc2003.breakSent.tar.gz

51



Language Topics Avg. Model ID1 ID11 ID2 ID21 ID3 ID4 (rank/total) ID5 ID51 Baseline
Arabic 15 .137 .132 .132 .118 .105 .052 .167 (1/9) .105 .088 .086
Chinese 10 .462 .430 .457 .212 .354 .354 (5/6) .867
Czech 15 .195 .155 .166 .123 .151 .179 (1/6) .085
English 15 .185 .161 .161 .147 .142 .083 .171 (1/9) .117 .101 .118
French 10 .198 .201 .201 .166 .177 .214 (1/6) .130
Greek 15 .111 .120 .124 .100 .112 .110 (4/6) .088
Hebrew 15 .076 .088 .100 .076 .084 .092 (2/8) .087 .084 .072
Hindi 10 .342 .125 .132 .123 .123 .129 (2/6) .114
Romanian 15 .543 .147 .139 .120 .138 .166 (1/6) .098
Spanish 15 .239 .198 .218 .180 .175 .228 (1/6) .164
Avg. rank 2.7 1.9 5.0 4.3 9 1.9 5.7 7.0 5.9

Table 1: ROUGE-2 scores of the average model and paricipating systems. Our LSA-based system is ID4
and we report its rank from the total number of systems which submitted summaries for the particular
language. We included the baseline (the start of a centroid article) and excluded the topline which uses
model sentences.

much attention has to be given to sentence order-
ing because some topics contained articles spread
over a long period, even 5 years. We did not
perform any temporal analysis at sentence level.
The sentences in the summary were ordered based
on the date of the article they came from. Sen-
tences from the same article followed their order
in the full text. Even if they were sometimes out
of context, when extracted, the adjacent sentences
at least dealt with the same (or temporary close)
event.

We analysed ROUGE scores which we received
from the organisers. We discuss here ROUGE-2
(bigram) score, a traditionally used metric in sum-
marisation evaluation (Table 1). ROUGE-2 ranked
our summariser on the top of the list for 6 from 10
languages (Arabic, Czech, English, French, Ro-
manian, Spanish). System ID11 performed better
twice (Hebrew and Hindi), there were three bet-
ter systems in Greek and the baseline won in Chi-
nese. In the following, we will discuss the results
for each language separately.

For Arabic, our system received the best
ROUGE-2 score. It was significantly better (at
confidence 95%) then 5 other systems, including
baseline. It performed on the same level as mod-
els.

It was our first attempt to run the summariser
on Chinese. We did not use any specific word-
splitting tool and we considered each character to
be a context feature for LSA. The ROUGE results
say that the summariser was not that successful
compared to the others. It was significantly bet-
ter than one system and worse than two and the

baseline which received suspiciously high score.
We annotated the Czech part of the corpus, and

therefore the result of our system can be consid-
ered only as another baseline for this language.
It received the largest ROUGE-2 score, however,
there was no significant difference among the top
four systems.

For English, our system together with the fol-
lowing systems ID1 and ID11 were significantly
better than the rest. A similar conclusion can be
driven by observing the French results. In the case
of Greek only baseline performed poorly. Our
approach was ranked fourth although there were
marginal differences between the systems. For
Hebrew and Hindi system ID11 performed the
best, followed by our system. For Romanian, a
newly introduced language this year, our system
received a high score, however, a larger confidence
interval did not show much significance. For an-
other newly-introduced language, Spanish, only
system ID11 was not significantly worse than our
system.

As a try to compare the systems across lan-
guages, an average rank was computed. (Comput-
ing an average of absolute ROUGE-2 scores did
not seem to have sense.) Our system and system
ID11 received the best average rank: 1.9.

For several languages (Arabic, French, He-
brew), our summaries were better (not signif-
icantly) then the average model according to
ROUGE-2.

The AutoSummENG method (Giannakopoulos
and Karkaletsis, 2010) gave results similar to
those of ROUGE. The only difference was in Chi-

52



nese: ROUGE-2 ranked our system 5th, Auto-
SummENG 1st.

One question remains: are the ROUGE scores
correlated with human grades? Unfortunately, the
human grades were not available at the time of the
system reports submission. However, because we
were managing annotation of the Czech subcorpus
we had access to human grades for that language.
The system ranking provided by ROUGE mostly
agree with the human grades, reaching Pearson
correlation of .97 for the systems-only scenario.
The human grades ranked our system as signifi-
cantly better than any other submission in the case
of Czech.

5 Conclusion

The evaluation indicates good results of our sum-
mariser, mainly for European Latin-script lan-
guages (Czech, English, French, Romanian and
Spanish). It could be connected to good-enough
pre-processing (sentence and word splitting). The
last two languages were added this year and the
good results show that the LSA-based summariser
can produce good summaries when run on an ‘un-
seen’ language.

We experiment with several improvements of
the method which require language-specific re-
sources. Entity detection can improve the LSA
model by adding entity features as new rows in
the SVD input matrix (Steinberger et al., 2007).
From the Multiling-2013 languages we have de-
veloped the NER tool only for 6 languages (Ara-
bic, Czech, English, French, Romanian and Span-
ish) so far (Pouliquen and Steinberger, 2009). A
coreference- (anaphora-) resolution can help in
checking and rewriting the entity references in a
summary (Steinberger et al., 2007) although there
is usually a high dependency on the language (e.g.
in the case of pronouns).

Event extraction can detect important aspects
related to the category of the topic (e.g. detect-
ing victims in a topic about an accident) (Stein-
berger et al., 2011). The aspect information can
be used in the model weighting or during sen-
tence selection. We have developed the tool for
5 languages considered in Multiling-2013 (Ara-
bic, Czech, English, French and Spanish). Tem-
poral analysis could improve sentence ordering if
a correct temporal mark, which contains informa-
tion about time of a discussed event, is attached to
each summary sentence (Steinberger et al., 2012).

So far, we experimented with English, French and
Spanish from the list of the Multiling languages.
By compressing and/or rephrasing the saved space
in the summary could be filled in by the next most
salient sentences, and thus the summary can cover
more content from the source texts. We have
already tried to investigate language-independent
possibilities in that direction (Turchi et al., 2010).

Acknowledgments

This work was supported by project “NTIS - New
Technologies for Information Society”, European
Center of Excellence, CZ.1.05/1.1.00/02.0090.

References
G. Giannakopoulos and V. Karkaletsis. 2010. Sum-

marization system evaluation variations based on n-
gram graphs. In Proceedings of the Text Analysis
Conference (TAC).

G. Giannakopoulos, M. El-Haj, B. Favre, M. Litvak,
J. Steinberger, and V. Varma. 2012. Tac 2011 multi-
ling pilot overview. In Proceedings of the Text Anal-
ysis Conference (TAC). NIST.

Y. Gong and X. Liu. 2002. Generic text summarization
using relevance measure and latent semantic analy-
sis. In Proceedings of ACM SIGIR, New Orleans,
US.

C.-Y. Lin. 2004. ROUGE: a package for auto-
matic evaluation of summaries. In Proceedings of
the Workshop on Text Summarization Branches Out,
Barcelona, Spain.

B. Pouliquen and R. Steinberger. 2009. Auto-
matic construction of multilingual name dictionar-
ies. In Cyril Goutte, Nicola Cancedda, Marc Dymet-
man, and George Foster, editors, Learning Machine
Translation. MIT Press, NIPS series.

J. Steinberger and K. Jez̆ek. 2004. Text summarization
and singular value decomposition. In Proceedings
of the 3rd ADVIS conference, Izmir, Turkey.

J. Steinberger and K. Jez̆ek. 2009. Update summa-
rization based on novel topic distribution. In Pro-
ceedings of the 9th ACM Symposium on Document
Engineering, Munich, Germany.

J. Steinberger, M. Poesio, M. Kabadjov, and K. Jez̆ek.
2007. Two uses of anaphora resolution in summa-
rization. Information Processing and Management,
43(6):1663–1680. Special Issue on Text Summari-
sation (Donna Harman, ed.).

J. Steinberger, H. Tanev, M. Kabadjov, and R. Stein-
berger. 2011. Aspect-driven news summarization.
International Journal of Computational Linguistics
and Applications, 2(1-2).

53



J. Steinberger, M. Kabadjov, R. Steinberger, H. Tanev,
M. Turchi, and V. Zavarella. 2012. Towards
language-independent news summarization. In Pro-
ceedings of the Text Analysis Conference (TAC).
NIST.

M. Turchi, J. Steinberger, M. Kabadjov, R. Steinberger,
and N. Cristianini. 2010. Wrapping up a summary:
from representation to generation. In Proceedings
of CLEF.

54


