










































An Embodied Dialogue System with Personality and Emotions


Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 31–36,
Uppsala, Sweden, 15 July 2010. c©2010 Association for Computational Linguistics

An Embodied Dialogue System with Personality and Emotions

Stasinos Konstantopoulos

NCSR ‘Demokritos’, Athens, Greece
konstant@iit.demokritos.gr

Abstract
An enduring challenge in human-
computer interaction (HCI) research is the
creation of natural and intuitive interfaces.
Besides the obvious requirement that such
interfaces communicate over modalities
such as natural language (especially spo-
ken) and gesturing that are more natural
for humans, exhibiting affect and adaptiv-
ity have also been identified as important
factors to the interface’s acceptance by the
user. In the work presented here, we pro-
pose a novel architecture for affective and
multimodal dialogue systems that allows
explicit control over the personality traits
that we want the system to exhibit. More
specifically, we approach personality as
a means of synthesising different, and
possibly conflicting, adaptivity models
into an overall model to be used to drive
the interaction components of the system.
Furthermore, this synthesis is performed
in the presence of domain knowledge,
so that domain structure and relations
influence the results of the calculation.

1 Introduction

An enduring challenge in human-computer inter-
action (HCI) research is the creation of natural
and intuitive interfaces. Besides the obvious re-
quirement that such interfaces communicate over
modalities such as natural language (especially
spoken) and gesturing that are more natural for
humans, exhibiting affect and adaptivity have also
been identified as important factors to the inter-
face’s acceptance by the user.

We perceive HCI systems as ensembles of inter-
action modules, each controlling a different inter-
action modality, and able to modulate their opera-
tion depending on external (to the modules them-
selves) parameters. A central cognitive module

deliberates about dialogue acts and orchestrates
the interaction modules in order to ensure that
such dialogue acts are carried out in a coherent
way, keeping uttered content and affect consistent
within and across interaction modules.

In this paper we describe work towards this end,
carried out in the context of the INDIGO project,
and implemented in the form of a personality mod-
ule that complements INDIGO’s dialogue man-
ager by calculating parameters related to adap-
tivity and emotion to be used by the interaction
modules in the process of concretely realizing the
abstract dialogue-action directives issued by the
dialogue manager. This calculation involves the
planned act, the user adaptivity model, the sys-
tem’s own goals, but also a machine representa-
tion of the personality that we want the system to
exhibit, so that systems with different personality
will react differently even when in the same dia-
logue state and with the same user or user type.

This is motivated by the fact that, although
personality is a characteristically human quality,
it has been demonstrated that human users at-
tribute a personality to the computer interfaces
they use, regardless of whether one has been ex-
plicitly encoded in the system’s design (Nass et al.,
1995). Furthermore, personality complementarity
and similarity are important factors for the accep-
tance of an interface by a user (Moon and Nass,
1996; Nass and Lee, 2000), so that there is no ‘op-
timal’ or ‘perfect’ system personality, but rather
the need to tune system personality to best fit its
users.

In the rest of this paper, we will briefly discuss
literature on both adaptivity and personality mod-
elling (Section 2), proceed to present the interac-
tion between multimodal dialogue strategies and
our personality model (Section 3), and finally con-
clude (Section 4).

31



2 Background

INDIGO in general and our work in particular
is, to a large extend, based on work on adaptive
natural-language interfaces to databases. The do-
mains of application of these systems have var-
ied from generating personalized encyclopedia en-
tries and museum exhibit descriptions, to support-
ing the authoring of technical manuals and on-line
store catalogues.

2.1 Adaptive HCI

The ILEX system was a major milestone in adap-
tive natural language generation (NLG), empha-
sising the separation between domain and linguis-
tic resources permitting the portability of linguis-
tic resources between domains. ILEX also intro-
duced the notion of a system agenda that rep-
resents the system’s own communicative goals,
a significant step in the direction of represent-
ing system personality. These system preferences
were combined with user preferences and a dy-
namic assimilation score (calculated from interac-
tion history) to estimate a single preference factor
for the various facts in the database for the pur-
poses of selecting the content that is to be included
in the description of each object (Ó Donnell et al.,
2001).

ILEX, however, offered no theory about where
interest and importance come from or how to com-
bine them; arbitrary values had to be provided
for all objects in the database and the combined
preference was derived by multiplying the three
factors (importance, interest, and assimilation) re-
gardless of how each object is related to other in-
teresting or important objects in the collection or
what other relevant and semantically similar ob-
jects have been assimilated.

Building upon ILEX, the M-PIRO system ex-
tended user model preferences to influence surface
realization besides content selection, so that dif-
ferent surface forms would be generated to realize
the same abstract piece of information for differ-
ent users (Isard et al., 2003). This was achieved
by explicitly representing the grammar fragments
that could be used to realize different types of facts
(properties of the object being described) and then
extending the user interests mechanism to also se-
lect which grammar fragment is more ‘interesting’
(or, rather, appropriate) to realize a particular piece
of information for a particular user model.

By comparison to ILEX, M-PIRO offered greater

flexibility and linguistic variation, as well as lan-
guage portability by allowing the combination of
different grammars with the same domain or user
models. On the other hand, the, even rudimen-
tary, ability to combine user and system prefer-
ences was dropped and user model authoring be-
came practically unmanageable due the size and
complexity of user models.

With the emergence of the Semantic Web, it
became obvious that representation technologies
such as RDF and OWL offered an opportunity
to reduce the authoring effort by operating upon
pre-existing OWL ontologies. This motivated the
development of the NATURALOWL/ELEON sys-
tem. NATURALOWL is a template-based NLG
engine, explicitly designed for generating natu-
ral language descriptions of ontological entities,
based on such entities’ abstract properties (Gala-
nis and Androutsopoulos, 2007). The ELEON au-
thoring tool (Konstantopoulos et al., 2009) can be
used to annotate OWL ontologies with linguistic
and content-selection resources and inter-operates
with NATURALOWL which can use such anno-
tations to generate descriptions of ontological ob-
jects.

2.2 Emotions and personality

Another relevant line of research is centred around
affective interaction and intelligent virtual agents.
The main focus here is the modelling and mim-
icking of the various affective markers that people
use when they communicate, aiming at more nat-
ural and seamless human-computer interaction.

Such affective systems are modulated by per-
sonality representations varying from fully-blown
cognitive architectures (Vankov et al., 2008) to rel-
atively simpler personality models. The OCEAN
or Big Five model, in particular, a standard frame-
work in psychology (Norman, 1963; Costa and
McCrae, 1992), is used to represent personality in
a variety of virtual agents and avatars capable for
multi-modal communication acts such as speech
and facial expressions (Strauss and Kipp, 2008;
Kasap et al., 2009). Such systems are typically
rich in visual expression, but lack sophistication
in natural language generation, knowledge repre-
sentation and dialogue structure.

The PERSONAGE and INDIGO systems, on the
other hand, move in the area between these sys-
tems and the database-access systems discussed
above: PERSONAGE develops a comprehensive

32



!"#$%&'()*+$&#*,)%*+$(-.$($.'*/,**'0-$(-.$(-()1*'*$(&#$2&#*#-%#.$'-$.#%(')$'-$3#/%'0-$4$05$%"'*$.#)'6#&(7)#8$

!"# $%&'(%)'*+,)-'%&.,/')0,123,45-.*++5&

9-$3#2%#:7#& $;4%"$ ;<<=+$>?@$*%(55 $ A:,*#,:$#.,/(%0&*+ $-0%$ '-60)6#.$'- $BCDBE9F$%#*%#.$ %"#$5,))$

'-%#G&(%#. $*1*%#:$A>'G,&# $HF8 $!"'* $I(* $ %"#$ 5'&*% $ %':# $ %"(% $()) $ BCDBE9$5,-/%'0-()'%1+ $ '-/),.'-G $ %"#$

(-':(%&0-'/$"#(.+$I(*$02#&(%'0-()$0-$%"#$&070%'/$2)(%50&:$(-.$'-%#&(/%'-G$I'%"$2#02)#$0%"#&$%"(-$%"#$

BCDBE9$.#6#)02:#-%$%#(:8$!"#$2,&20*#$05$%"#*#$%&'()*$I(*$%I050).J$%0$%#*%$%"#$'-%#&(/%'0-$7#%I##-$%"#$

BCDBE9$/0:20-#-%*$(-.$%"#$06#&()) $7#"(6'0,&$(-.$&#*20-*'6#-#**$*1*%#:+$(-.$()*0$%0$G'6#$>?@$

2#&*0--#)$#K2#&'#-/#$I'%"$%"#$&070%$*0$%"(%$%"#1$/(-$7#%%#&$/0-.,/%$%"#$5'-()$#6(),(%'0-8$@'%"$&#*2#/%$%0$

%"#$5'&*%$20'-%+$%"#$%&'()*$I#&#$*,//#**5,)$'-$%"(%$%"#$*1*%#:$2&06#.$%0$7#$*%(7)#$(-.$&#*20-*'6#+$#6#-$

I"#-$&,--'-G$())$%"#$BCDBE9$*05%I(&#$0-$%"#$%I0$&070%$/0:2,%#&*$L$#K/#2%$%"#$6'*'0-$*1*%#:$I"'/"+$

.,#$%0$'%*$/0:2,%(%'0-()$&#M,'&#:#-%*+$I(*$'-*%())#.$0-$($*#2(&(%#$)(2%02$/0:2,%#&$I"'/"$I(*$()*0$

:0,-%#.$0-L70(&.$%"#$&070%8

@'%"$&#*2#/%$%0$%"#$*#/0-.$20'-%+$'%$*"0,).$7#$-0%#.$%"(%$%"#$3,::#&$N(:2$%&'()*$I#&#$/0-.,/%#.$71$

-0-LBCDBE9$>?@$2#&*0--#)+$7,%$%#/"-'/()$2#&*0--#)$5&0:$CN3O$(-.$PQRS$I(*$2&#*#-%$50&$%"#$$

8

!"#$%&'()'*+,"-+."/0'.%"+,1'+.'!234'.5&'16%&&0'"0'.5&'7+68#%/$0-'15/91'

.5&':"%.$+,'&;5"7".<

.,&(%'0-$05$%"#$%&'()*$%0$2&06'.#$G,'.(-/#$(-.$(**'*%(-/#8$B-$%"#$3#2%#:7#&$%&'()*$%#/"-'/()$2#&*0--#)$

%&'#.$%0$:'-':'T#$'%*$'-60)6#:#-%$%0$)#%$>?@$:,*#,:$#.,/(%0&*+$I"0$(&#$-0-L%#/"-'/()$2#.(G0G1$(-.$

:,*#,: $ */'#-/# $ #K2#&%*+ $ G('- $ /0-5'.#-/# $ %"(% $ %"#1 $ /(- $ 02#&(%# $ %"# $ &070% $ %"&0,G" $ *,//#**'6#$

'-%#&(/%'0-*$I'%"0,%$%#/"-'/()$(**'*%(-/#8$P)%"0,G"$%"'*$G0()$I(*$()*0$2(&%'())1$5,)5'))#.+$'%$'*$#6'.#-%$

%"(%$:0&#$%&('-'-G$%&'()*$I'))$7#$-##.#.$7#50&#$%"#$5'-()$#6(),(%'0-$2"(*#

!"6 785-8'5/

!"# $ *#/0-. $/1/)# $ %&'()* $I#&# $6#&1 $ *,//#**5,)+ $ .#:0-*%&(%'-G $( $ /)#(& $ (.6(-/#:#-% $I'%" $ &#*2#/% $ %0$

/0:2)#%'-G$%"#$5,-/%'0-()'%1$05$%"#$BCDBE9$2&0%0%12#$(-.$':2&06'-G$%"#$5,-/%'0-()'%1$%"(%$I(*$()&#(.1$

'-%#G&(%#.$.,&'-G$%"#$5'&*%$/1/)#$%&'()*8

U;

Figure 1: An INDIGO robot interacting with Hel-
lenic Cosmos personnel during preliminary trials,
September 2009.

theory of using OCEAN parameters to control
natural language interaction from lexical choice
to syntax, pragmatics, and planning, but is re-
stricted to text generation and no other com-
munication modalities are covered (Mairesse and
Walker, 2007). The INDIGO dialogue system em-
phasises multi-modality as it is embodied in a
robot capable of multi-modal interaction. INDIGO
uses OCEAN to combine a separate user model
and system profile into a single parameter set used
to parametrize a number of interaction compo-
nents, such as a virtual avatar capable of display-
ing emotions, the NLG engine, the text-to-speech
engine, the dialogue manager, etc.

3 A dialogue system with personality

The INDIGO system has been fielded at the Hel-
lenic Cosmos cultural centre,1 where it provides
personalized tours with historical, architectural,
and cultural information about the buildings of the
Ancient Agora of Athens (Figure 1).

The dialogue manager (DM, Matheson et al.,
2009), implemented using TrindiKit,2 assumes the
information-state and update approach to dialogue
management (Traum and Larsson, 2003). The
information state stores information such as dia-
logue history and current robot position. Input
from the sensors (ASR, vision, laser tracker, and
touchscreen) is processed by update rules which
heuristically fuse multimodal (and possibly con-
tradicting) sensory input and implement generic
(i.e., domain and personality-independent) dia-
logue strategies. These strategies deliberate about
the next action that the robot will take, such as

1See also http://www.hellenic-cosmos.gr
2See http://sourceforge.net/projects/

trindikit/

moving to a different section of the exhibition, of-
fering a menu of choices, or describing an item.

One notable strategy implemented in the DM is
the Move On Related strategy (Bohus and Rud-
nicky, 2008), the system’s fallback when user in-
put cannot be confidently recognized even after
fusing all input modalities. In such situations, DM
uses the combined preference factors to choose the
most preferred exhibit within the ontological class
that is the current focus of the discourse. If there
is an instance in this class with a clear preference,
DM assumes this as the user response; if, on the
other hand, there is no instance with significantly
higher preference than the rest, DM prompts the
user to repeat their answer or use the touchscreen.

The other notable, and widely used, strategy is
the one that drives the two loops shown in Fig-
ure 2, in response to a user request for content:
one pertaining to dynamically realizing a person-
alized description of an object of the domain on-
tology and one pertaining to updating the system’s
emotion and mood.

3.1 Content selection and realization loop

Once the DM has resolved that the next robot ac-
tion will be the description of a domain ontology
object, the personality-driven preferences are used
to select which properties of this object will be in-
cluded in the description. These preferences are
calculated taking into account a combined user-
system preference (Konstantopoulos et al., 2008)
as well as a dynamic assimilation score, calcu-
lated from interaction history, which balances be-
tween the gratuitous and tiring repetition of high-
preference material and simply rotating through
the list of properties of an object.

The chosen content is then used by the NAT-
URALOWL NLG engine (Galanis and Androut-
sopoulos, 2007) to plan and realize a personalized
textual description of the object. Besides selecting
what to include in a description, preference is used
by NATURALOWL to annotate the generated text
with directives, such as emphasis, for the text-to-
speech effector that drives the robot’s speakers.

The combined user-system preference stems
from associating domain objects with content-
selection parameters, using an representation de-
veloped for NATURALOWL and extended in IN-
DIGO to provide for representing not only user
models but also system profiles that establish the
system’s own goals and preferences (Konstan-

33



Appraisal

Module

Effectors

Navigation

Text−to−Speech

Display

Robot head

NLG

Ontology

Domain

Model

UserRobot

Model

Personality

Module

Dialogue

Manager

Emotion
Engine

Mood

ASR

Vision

Touchscreen

Laser Tracker

Sensors

U
se

r 
fa

ci
al

 g
es

tu
re

U
se

r 
in

p
u
t

ContentAppraisal Content

C
h
o
se

n
 i

te
m

Realized

Description

Figure 2: Overall architecture of the dialogue system.

topoulos et al., 2009).
Emotional and, in general, behavioural varia-

tion among different instantiations of the system is
achieved through synthetic personality models that
assert different points of balance between the (po-
tentially) conflicting user and system preferences.
What is of particular importance is that the the
combined user-system preference is not estimated
in isolation for each and every ontological object
as was the case in ILEX, but by axiomatizing how
preference is ‘transferred’ between domain objects
based on their semantic relations. This is achieved
by defining personality in terms of logic clauses
that link the preferences of an object not only to
its user and system preferences, but also to those
of objects it semantically relates with.

3.2 Emotional appraisal and update loop
The system emotionally appraises user actions as
well as its own actions. With respect to its own
actions, the preference factors for the properties
selected to describe an object reflect the robot’s
being excited or bored to discuss the current sub-
ject.

Appraisal of user actions stems from vision and
speech analysis to reflect the impact of the manner
of what the user said. More specifically, facial ges-
ture recognition is used to detect emotional signs
(such as smiling) besides detecting affirmative and

negative nods and similar signs that are fused with
the results of speech recognition.

As user utterances are mostly short and incom-
plete answers to questions such as ‘Would you like
to hear more about this monument?’ or ‘Which
monument would you like me to talk about?’ we
cannot detect emotion based on linguistic mean-
ing or syntactic structure, but rather concentrate on
extracting useful prosodic and linguistic features
such the length of the last syllable in an utterance
or whether the first word of the utterance is an wh-
word.3 Although these features are not by them-
selves indicative of emotion, they are indicative
of prosody and their combination with segmental
features (referring to the acoustic form) extracted
directly from the speech signal was shown to im-
prove emotion estimation.

Emotional appraisal is used by an emotion sim-
ulator (Kasap et al., 2009) that uses the system’s
personality traits (OCEAN vector) to model how
dialogue acts affect the system’s emotional state.
This emotion simulator updates the system’s in-
ternal short-term emotional state and long-term
mood by applying an update function on the cur-
rent state and the emotional appraisal of each dia-
logue act. The OCEAN parameters act as param-
eters of the update function, so that, for example,

3Where, what, who, etc.

34



neuroticism (i.e., ‘tendency to distress’) makes the
update function tend towards negative emotions,
whereas agreeableness (i.e., ‘sympathetic’) makes
it more directly reflect the user’s emotions.

The speech synthesiser and the robot’s anima-
tronic head reflect emotional state as voice mod-
ulations and facial expressions, whereas mood is
taken into account by the DM when deliberating
about the robot’s next dialogue action.

4 Conclusions

In this paper we have approached personality as a
means of synthesising different, and possibly con-
flicting, adaptivity models into an overall model to
be used to drive the interaction components of the
system. Furthermore, this synthesis is performed
in the presence of domain knowledge, so that do-
main structure and relations influence the results
of the calculation.

We thusly explore the self vs. other aspect of
personality modelling, theoretically interesting but
also practically important as we cleanly separate
adaptivity and profiling data that refers the system
from that which refers to the user. This follows up
on the tradition of the line of systems stemming
from ILEX, where increasingly separable models
(domain vs. NLG resources, the latter later broken
down between linguistic and adaptivity resources)
have allowed for such hard-to-create resources to
be re-used.

Acknowledgements

The work described in this paper was funded by
the FP6-IST project INDIGO, that developed and
advanced human-robot interaction technology, en-
abling robots to perceive natural human behaviour
and act in ways that are more familiar to humans.
To achieve its goals, INDIGO advanced various
technologies, which it integrated in a robotic plat-
form.

More details are availble from the project web-
site, http://www.ics.forth.gr/indigo

References

Dan Bohus and Alex Rudnicky. 2008. Sorry, I
didn’t catch that. In Laila Dybkjær and Wolf-
gang Minker, editors, Recent Trends in Dis-
course and Dialogue, volume 39 of Text, Speech
and Language Technology, chapter 6, pages
123–154. Springer Netherlands.

P. T. Costa and R. R. McCrae. 1992. Normal
personality assessment in clinical practice: The
NEO personality inventory. Psychological As-
sessment, 4(5–13).

Dimitris Galanis and Ion Androutsopoulos. 2007.
Generating multilingual descriptions from lin-
guistically annotated OWL ontologies: the Nat-
uralOWL system. In Proceedings of the 11th
European Workshop on Natural Language Gen-
eration (ENLG 2007), Schloss Dagstuhl, Ger-
many, pages 143–146.

Amy Isard, Jon Oberlander, Ion Androutsopoulos,
and Colin Matheson. 2003. Speaking the users’
languages. IEEE Intelligent Systems, 18(1):40–
45.

Zerrin Kasap, Maher Ben Moussa, Parag Chaud-
huri, and Nadia Magnenat-Thalmann. 2009.
Making them remember: Emotional virtual
characters with memory. In Tiffany Barnes,
L. Miguel Encarnção, and Chris Shaw, editors,
Serious Games, Special Issue of IEEE Com-
puter Graphics and Applications. IEEE.

Stasinos Konstantopoulos, Vangelis Karkaletsis,
and Dimitris Bilidas. 2009. An intelligent au-
thoring environment for abstract semantic rep-
resentations of cultural object descriptions. In
Lars Borin and Piroska Lendvai, editors, Pro-
ceedings of EACL-09 Workshop on Language
Technology and Resources for Cultural Her-
itage, Social Sciences, Humanities, and Edu-
cation (LaTeCH-SHELT&R 2009), Athens, 30
Mar 2009, pages 10–17.

Stasinos Konstantopoulos, Vangelis Karkaletsis,
and Colin Matheson. 2008. Robot personal-
ity: Representation and externalization. In Pro-
ceedings of ECAI-08 Workshop on Computa-
tional Aspects of Affective and Emotional In-
teraction (CAFFEi 2008), Patras, Greece, July
21st, 2008, pages 5–13.

François Mairesse and Marilyn Walker. 2007.
PERSONAGE: Personality generation for dia-
logue. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Lin-
guistics (ACL). Prague.

Colin Matheson, Amy Isard, Jon Oberlan-
der, Stasinos Konstantopoulos, and Vangelis
Karkaletsis. 2009. Multimodal human-robot di-
alogue management. INDIGO Deliverable 4.1
(public).

35



Youngme Moon and Clifford Nass. 1996. Adap-
tive agents and personality change: comple-
mentarity versus similarity as forms of adap-
tation. In Proceedings SIGCHI Conference on
Human Factors in Computing Systems, Vancou-
ver, BC, Canada, 1996. SIG on Computer-
Human Interaction, ACM, New York, U.S.A.

Clifford Nass and Kwan Min Lee. 2000. Does
computer-generated speech manifest person-
ality? an experimental test of similarity-
attraction. In Proceedings SIGCHI Conference
on Human factors in Computing Systems, The
Hague, 2000. SIG on Computer-Human Inter-
action, ACM, New York, U.S.A.

Clifford Nass, Youngme Moon, B. Fogg, and
B. Reeves. 1995. Can computer personalities
be human personalities? International Journal
of Human-Computer Studies, 43:223–239.

W. T. Norman. 1963. Toward an adequate taxon-
omy of personality attributes: Replicated fac-
tor structure in peer nomination personality rat-
ing. Journal of Abnormal and Social Psychol-
ogy, 66:574–583.

Michael Ó Donnell, Chris Mellish, Jon Oberlan-
der, and A. Knott. 2001. ILEX: an architec-
ture for a dynamic hypertext generation system.
Natural Language Engineering, 7(3):225–250.

Martin Strauss and Michael Kipp. 2008. ERIC:
a generic rule-based framework for an affective
embodied commentary agent. In Proceedings
of the 7th international joint conference on Au-
tonomous agents and multiagent systems (AA-
MAS 08), Estoril, Portugal, 2008, pages 97–
104.

David Traum and Steffan Larsson. 2003. The in-
formation state approach to dialogue manage-
ment. In Jan van Kuppevelt and Ronnie Smith,
editors, Current and New Directions in Dis-
course and Dialogue. Kluwer Academic Pub-
lishers, Dordrecht, the Netherlands.

Ivan Vankov, Kiril Kiryazov, and Maurice Grin-
berg. 2008. Introducing emotions in an analogy-
making model. In Proceedings of 30th An-
nual Meeting of the Cognitive Science Society
(CogSci 2008), Washington D.C.

36


