






















































Instructions for ACL-2013 Proceedings


Proceedings of the 27th International Conference on Computational Linguistics, pages 2562–2569
Santa Fe, New Mexico, USA, August 20-26, 2018.

2562

Urdu Word Segmentation using Conditional Random Fields (CRFs) 

Haris Bin Zia 

ITU, Pakistan 
haris.zia@itu.edu.pk 

Agha Ali Raza 

ITU, Pakistan 
agha.ali.raza@itu.edu.pk 

Awais Athar 

EMBL-EBI, UK 
awais@ebi.ac.uk 

 

Abstract 

State-of-the-art Natural Language Processing algorithms rely heavily on efficient word segmen-

tation. Urdu is amongst languages for which word segmentation is a complex task as it exhibits 

space omission as well as space insertion issues. This is partly due to the Arabic script which 

although cursive in nature, consists of characters that have inherent joining and non-joining 

attributes regardless of word boundary. This paper presents a word segmentation system for 

Urdu which uses a Conditional Random Field sequence modeler with orthographic, linguistic 

and morphological features. Our proposed model automatically learns to predict white space as 

word boundary as well as Zero Width Non-Joiner (ZWNJ) as sub-word boundary. Using a man-

ually annotated corpus, our model achieves F1 score of 0.97 for word boundary identification 

and 0.85 for sub-word boundary identification tasks. We have made our code and corpus pub-

licly available to make our results reproducible. 

Title and Abstract in Urdu 

ں اظ اردو می  ی ع االلف 
 
ت
 
ق
لڈز ت  ن 

 
ڈم ف ن  ل ری 

ن 
 
ش ڈی  کن  ذرت عہ   ب 

امل  ں ش  وں می 
 
ان ں۔ اردو ان زب  ی  ے ہ 

 
کرت حصار 

 
ہت ای شی م  ت ر ب 

 
ق
ت 
ں  اظ می  کی الف  چرت ر 

 
ھم  رواں ی

 
گ کے الگورت ج ت راسی شن 

 
گوی

ن  رل لت  چ  ی 
ری ن ی 

 
د ت دب  ے ہ  ج 

 
ت ق ودکار طر

 
ں خ ن می  ی ع ے ج 

 
ت
 
ق
سے  ی ہ  ت 

روری طور ت ر دا
 
رض ث 

 
کی ھی غ ے اور  ی ہ 

 
ات کر دی ج  ر جذف 

گہ اکث  الی ج 
ان ج  اظ کے درمن 

ت الف 
 
ے وف کھت 

کہ   اردو ل وب  کی  ے  دہ عمل ہ  ن  چ  ی  ک ی  اظ اب 
 االلف 

زوی ج  لہ ج  ے۔ ی ہ مشن  ی ہ 
 
ات کر دی ج  ھی 

ل ت 

ر، جروف
 
ظ
 
طع ت

 
اظ سےق ں جدوِد الف  س می  ے ج  ہ سے ہ  کی وج  عمال 

ط کے   اسی 
 
ی رسم الح ی ہ    طور ت ر عرت 

 
ات ی ج 

 
ات کال ب  وں اش 

 
صلہ، دون ر می  ث 

 
صلہ اور غ م اردو کے کی می 

ں ہ  الہ می  ں ۔ اس مف  ی 

ی اور معی وی اوصاف
 
ی، لسات

 
ام امالت ظ 

 
ے۔  ی ہ ت ا ہ  کر شکن  ی ع 

 
ت
 
ق
ی ت 
 
اآشات کی ب  چرت ر 

 
ھی اردو ی کسی ت  و  ں خ  ی  ے ہ  کر رہ  ی ش  ام پ 

ظ 
 
کار ت ود 

 
ے اب ک خ ل ک  لت 

ن 
 
ش ڈی  کن  ک  ے والے اب 

 
کرت عمال 

ا اسی 

لڈ ماڈل ت ر م  ن 
 
ڈم ف ن  ھ ری 

 
ے اور اس کے شات ا ہ  کھن  ا سن  کرب  ی 

 
گوت ی س  ی جد کے طور ت ر پ 

 
ظ
کی لف  گہ  الی ج 

ے سے ج 
 
ت ق کار طر ود 

 
وزہ ماڈل خ مارا مج  ے۔ ہ  ی ہ 

 
ن انز ت  ھ ب 

 
ر ت رو وڈت

 
ت
َ
ا کی ذب لی   (ZWNJ)ج 

ی جد  
 
ظ
کو لف  مارے ماڈل  ے، ہ 

 
وت ے ہ 

 
کرت عمال 

کا اسی  کاری س  دہ  ان ش  س 
 
ی ی
 
ک دسن ے۔ اب  ا ہ  کرب  ی 

 
گوت ن 

 
ی ش ھی پ  کی جد کے طور ت ر ت  ظ 

ےکلف  لت  ت کے 
 
اخ ن 

 
کی  0.97ی س ظ 

کا اور ذب لی لف 

ے لت  ت کے 
 
اخ ن 

 
کی س ے۔  1F کا 0.85 جد  ا ہ  کر دب  اب  ن 

 
کو عمومی طور ت ر دست کاری س  کوڈ اور  ے 

ت  ی  ے ا
 
م ت ے ہ  لت  ےکے 

 
ات ن  کرار ی 

ل ب  اب  کو ق  ج 
 
ی ا ن 

 
ے ی
ت  ی  ے۔ ا ا ہ  وب   شکور جاصل ہ 

1 Introduction 

Word segmentation is an essential step for most Natural Language Processing (NLP) tasks. Most of the 

state-of-the-art NLP applications such as Machine Translation, Parts-of-Speech (POS) tagging etc. op-

erate at word level. English and other languages that use Latin script usually rely on white spaces to 

mark word boundaries, with some exceptions like compound words, and exhibit less segmentation issues 

than Asian languages like Mandarin, Lao, and Urdu etc. that do not have consistent word boundary 

markings. In the absence of word boundary markers, tokenization of text for further processing is a non-

trivial and challenging task. 

Urdu, the official language of Pakistan, is an Indo-Aryan language with over 163 million speakers1 

worldwide. It uses Arabic script with segmental writing system. More specifically it uses an abjad sys-

tem where consonants and (most) long vowels are necessarily written while short vowels (diacritics) are 

                                                      
1 https://www.ethnologue.com/language/urd 
 

This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://creativecom-

mons.org/licenses/by/4.0/ 

 



2563

optional. Urdu is bidirectional and characters are written from right-to-left while numerals are written 

from left-to-right. A sentence written in Urdu along with its English translation is given below: 

ومی 
 
کی ق ان  اکشن  ے۔ زب اناردو ب  ہ   

Urdu is the national language of Pakistan. 

 

When Urdu script is written in digital form, white space is not used for word boundary alone but also 

serves as a sub-word boundary marker as discussed in subsequent sections. Due to this absence of a 

clear word boundary marker, Urdu exhibits complex segmentation issues for natural language pro-

cessing as well as information retrieval. In this paper, we present a system to solve this problem of word 

tokenization. The major novel contributions of this paper are:  

1. A publicly available annotated corpus for Urdu word segmentation. 
2. A Conditional Random Field (CRF) word segmentation utility for Urdu based on linguistic and 

orthographic features.  

The remainder of this paper is structured as follows: Section 2 reviews segmentation techniques. We 

then present Urdu orthography and writing system in Section 3. Section 4 briefly discusses challenges 

in Urdu word segmentation. We present our corpus and model in section 5 and conclude in section 6. 

2 Literature Review 

Several techniques have been applied to solve segmentation issues for different world languages. Wong 

and Chan (1996) proposed a rule-based maximum-matching (max-match) dictionary look-up for Chi-

nese word segmentation. This technique does not take into account the context of words and also never 

generates short valid words. Another rule-based variant of max-match exists that first generates all pos-

sible segmentations of character sequences and then selects the best one based on heuristics like mini-

mum length words etc. (Sornlertlamvanich, 1993; Ping and Yu-Hang, 1994; Nie et al., 1994).  

Statistical methods like n-grams have also been extensively used to segment character sequences into 

words and have proven very effective (Kawtrakul, 1997; Aroonmanakun, 2002). However, performance 

of statistical word segmentation methods relies heavily on the quality of training corpora and computa-

tionally expensive higher order n-grams to capture long distance dependencies. Charoenpornsawat et al. 

(1998) use context-based features like Winnow (Blum, 1997) for Thai word boundary identification. 

Huihsin et al. (2005) proposed a conditional random field (CRF) sequence modeler for Chinese word 

segmentation. Their feature set consisted of simple n-gram features e.g. unigram and bigram features. 

Monroe et al. (2014) used the same CRF sequence modeler but with extended linguistic features for 

Arabic word boundary identification. They have reported F1 score of 0.92 on Egyptian Arabic Treebank2 

and 0.98 on Arabic Treebank3. Our proposed model is similar to that of Monroe et al. (2014) but based 

on a different feature set.  

More recently Cai and Zhao (2016) and Cai et al. (2017) investigated the use of neural language 

models with word and character-based embedding for efficient Chinese word segmentation and achieved 

better results than traditional segmentation algorithms. As with all deep-learning architectures, their 

model is data hungry and needs much training data, which is a barrier for low-resource languages.  

There has been some research for Urdu word segmentation (Durrani and Hussain, 2010) using hybrid 

techniques such as rule-based methods relying on max-match, statistical methods such as n-grams to-

gether with the POS tags of words. Their best technique have achieved error detection rate of 85.8% for 

space insertion and space omission errors. 

To our knowledge, there is no existing CRF based model for Urdu word segmentation along with a 

publicly available corpus and gold standard that can act as a reproducible reference for this task.  

3 Urdu Writing System 

Urdu is written using Arabic script in a cursive format (Nastaliq style) from right to left using an ex-

tended Arabic character set. The character set includes 37 basic and 4 secondary letters, seven diacritics, 

punctuation marks and special symbols (Hussain & Afzal, 2001; Afzal & Hussain, 2001; Hussain, 2004). 

                                                      
2 LDC2012E{93,98,89,99,107,125}, LDC2013E{12,21} 
3 LDC2010T13, LDC2011T09, LDC2010T08 



2564

When characters in Urdu character-set join to form words, they can acquire different shapes. Based 

on context, a character may have up to four shape variants: 1) word initial 2) word medial 3) word final, 

and 4) isolated. Characters that can acquire all of the four shapes are known as joiners while one that 

only have two forms i.e. final and isolated are termed as non-joiners. Urdu joiners and non-joiners are 

shown in Table 1. 

 

Joiners ی  ہ  ن  م  ل  گ   ک   ق  ف  غ  ع  ظ  ط  ض  ص  ش  س  خ  ح  چ  ج  ث  ٹ  ت پ   ب  

Non-joiners ے  ء  و  ژ  ز  ڑ  ر  ذ  ڈ  د  ا  

 
Table 1: Urdu joiners and non-joiners. 

 

Inherently, Urdu does not have the concept of white space as a word boundary marker. During digital 

transcriptions, native Urdu typists use space to get accurate shape of characters instead of using it to 

mark word boundaries. For example, Urdu writers may insert a space within a word د·دولت من   (rich) to 

make it visually correct, where the character · represents the ASCII space character. Omitting the space 

would lead to an incorrect visual form, د من 
 for the same word. On the other hand, writers may omit a ,دولی 

space between two separate words like اعر  Urdu poet) because the shape of characters with or without) اردوش 

space remains identical. Due to ambiguous use of white-space in Urdu, it cannot be used as a reliable 

word boundary marker for NLP applications.  

4 Challenges of Urdu Word Segmentation 

Urdu word segmentation exhibits space omission as well as space insertion challenges. These challenges 

are discussed in detail by Durrani and Hussain (2010) and are summarized below: 

4.1 Space Omission 

Urdu words ending with non-joiner characters exhibit correct shape even without space and thus the 

writer may omit a space between words ending with non-joiner characters. Omission of space does not 

affect readability of words but raises a computation issue. An example is illustrated in Table 2.  

 

a لے·اشد
 
ق ا ا۔·ت ر·طور·کے·صدر·کے·ق  گن   

b ا۔ لےکےصدرکےطورت رگن 
 
ق ا  اشدق 

c Asad went as the leader of caravan. 

 

Table 2: Urdu sentence with all words ending in non-joiner characters (a) with space (shown by a ·) 

after each word (b) with no space after any word (c) English translation. Computationally, this sen-

tence, which has eight tokens originally (with spaces), reduced to one token (without spaces).   

4.2 Space Insertion 

Another challenge of word segmentation in Urdu arises when two (or more) morphemes join to form a 

single word. If the first morpheme ends in a joiner character, writers may insert white space to prevent 

it joining with the next morpheme so that the word retains a valid visual form. If the first morpheme 

ends in a non-joiner, writers may (correctly) omit the space, as the shape of the word remains the same 

regardless. The error in this case can be avoided by using the Zero Width Non-Joiner (ZWNJ)4 Unicode 

character but Urdu users are generally not aware of its existence and most Urdu keyboards also do not 

                                                      
4 The standard ISO symbol for ZWNJ is  which has been approximated by T   in this paper to avoid formatting issues  



2565

have a direct key mapping for this character. Thus an extra space within a word creates two (or more) 

separate tokens for a single word and creates a computational problem. The space insertion problem 

exists in the following cases: 

 Affixation: to keep affixes separate from stem. 

 Compounding: to keep words compounded together from visually merging. 

 Reduplication: to keep reduplicated words from combining. 

 Foreign word: to enhance readability of transliterated words. 

 Abbreviation: to keep letters separate when foreign abbreviations are transliterated. 

 

Case a b c Translation 

Affixation وش
 
صی ب·خ

 
ت صی ب 

ی  وس 
 
و  خ

 
صی ب Tشخ

 
 Lucky ت

Compounding م
 
ظ
 
ی ط·و·ت

 
ض ی ط 

 
موض

 
ظ
 
ت
  

 
ظ
 
ی ط Tو Tمت

 
 Discipline ض

Reduplication دھام·دھوم  Pomp & Show دھام Tمدھو  دھومدھام 

Foreign word ٹ
 
ب ال·ف ن ال 

 
ت
 
  ف

 
 Football ب ال Tٹف

Abbreviation ی چ·ت 
 
ڈی·ای ڈی  چ  ای  ن    Tیت   ی 

 
 .Ph.D ڈی Tچای

 

Table 3: Example of space insertion (a) incorrect multiple tokens with space (·), correct shape (b) sin-

gle token, incorrect shape (c) single token with ZWNJ (T  ) as sub-word boundary, correct shape. 

5 Urdu Word Segmentation Model 

In order to accurately and efficiently solve space omission and insertion issues, we propose a Conditional 

Random Field (CRF) sequence model that uses linguistic and orthographic features to predict white 

space as word boundary and ZWNJ as sub-word boundary markers. Our model takes as input a concat-

enated sequence of characters and outputs sequence of words with space as word boundary and ZWNJ 

as sub-word boundary markers as shown in Figure 1. A description of our data annotation, experiments, 

and results is as follows. 

5.1 Data Annotation 

Unlike resource-rich languages such as English and Arabic that have abundant publicly accessible lin-

guistic resources, Urdu is relatively under-resourced and does not have any segmentation benchmark 

corpus. To overcome this shortcoming, we manually annotated a corpus of approximately 111,000 to-

kens by using the Urdu-Nepali-English parallel corpus5 as a starting point. This corpus is a parallel 

corpus to the common English source from PENN Treebank corpus where the source English sentences 

were news stories from Wall Street Journal (WSJ). We then used the CLE Urdu corpus cleaning appli-

cation6 to mark white space as word boundary and ZWNJ as sub-word boundary markers as per the rules 

proposed by Rehman et al. (2011). A summary of these rules is being reproduced here for the conven-

ience of the reader: 

 White space after each word ending. 

                                                      
5 http://www.cle.org.pk/software/ling_resources/UrduNepaliEnglishParallelCorpus.htm 
6 http://www.cle.org.pk/software/langproc/corpuscleaningH.htm 



2566

 ZWNJ between two roots or stems of X-Y compounding e.g. ہللا Tاء س 
 
 ای

 ZWNJ between two roots or stems of X-e-Y compounding e.g. م
 
Tاعظ ت روز   

 ZWNJ before and after و in X-o-Y compounding e.g. ی ط
 
مTوTض

 
ظ
 
ت
 

 ZWNJ between reduplicated words e.g. ی
 
یTووت

 
 روت

 ZWNJ between prefix and root in case of prefixation e.g. الق
وشTاج 

 
 خ

 ZWNJ between root and suffix in case of suffixation e.g. دہ Tش  اد  یش   

 ZWNJ between multiple morphemes of a single transliterated word e.g. ب الTٹ
 
 ف

 ZWNJ between multiple morphemes of a transliterated abbreviation e.g. ڈیTچ
 
یTای  ت 

 

The complete corpus was annotated by the first author. To calculate the inter-annotator agreement, 

100 sentences (21,781 characters) were annotated by one of the co-authors and the inter-annotator agree-

ment was found to be 0.98 as measured using Cohen’s Kappa. Both annotators are native Urdu speakers 

with a background of computer science and NLP, and use Urdu scripts in both printed and digital form 

on a regular day-to-day basis.  

Next, we applied Unicode text normalization to convert multiple equivalent representations of char-

acters to their consistent underlying normal forms and removed all diacritics and multiple spaces from 

the text. Some of these characters, such as diacritics, are good indicators of word boundaries; however, 

it is a common practice of first language writers of Urdu to exclude diacritics in all informal and most 

formal forms of writing. The reader simply uses contextual information to interpret the correct word. 

Therefore, to model the real-life situation more closely we decided to omit all diacritics from our corpus. 

Omission of diacritics makes the segmentation task harder (as their removal loses a major word disam-

biguation and hence possibly word segmentation cue) but makes it unbiased at the same time. For the 

sake of comparison, we report results with diacritics present as well as removed in later sections. 

The corpus consists of 4,325 sentences which cover most Urdu morphological and graphical con-

structs such as affixes, compounds, reduplicates, foreign words (transliterated from Latin to Arabic 

script) as well as abbreviations (transliterated from Latin to Arabic script) and words ending in both 

joiner and non-joiner characters. We have made this corpus publicly available on GitHub7 along with 

our pipeline. For evaluation purposes, we have split the data in terms of sentences: 3,500 for training 

(90K tokens) and 825 for testing (21K tokens). The test set contains 20,264 word boundary spaces and 

1,200 ZWNJ sub-word boundary markers.  

5.2 Model 

A CRF model, proposed by Lafferty et al. (2001), is defined as P(Y|X;w) where X = {x1,…,xn} is a 

sequence of input and Y = {y1,…,yn} is a predicted sequence of labels. We use a linear-chain model 

(Green and DeNero, 2012) with X as concatenated sequence of characters and Ŷ is chosen as per the 

following decision rule.  

Ŷ = argmax ∑ wT ϕ(X, yi); i = 1,…,n   
 

Where ϕ is a feature map defined in section 5.3. Our model classifies each yi as one of the following: 

 I: continuation of a word or sub-word. 

 BW: beginning of a word. 

 BS: beginning of a sub-word. 

                                                      
7 https://github.com/harisbinzia/Urdu-Word-Segmentation 



2567

 

Figure 1: Urdu word segmentation pipeline. The input is a concatenated sequence of characters and the 

output is a sequence of words with white space (·) as word boundary marker and ZWNJ (T) as sub-

word boundary marker. In this example  تراس Tت راہ (live) is a compound word that consists of two mor-

phemes ت راہ and راست so our model predicted ZWNJ between them. Similarly, کاریTسرمای ہ (investment) is an 
example of affixation with ZWNJ between root سرمای ہ and suffix کاری. 

 

5.3 Feature Engineering 

We experimented with different orthographic and linguistic features such as character windows of var-

ying lengths, joining/ non-joining behavior etc. and selected the best ones for our model. Table 4 sum-

marizes the effect of each feature on the performance of the model. Our final CRF model employs the 

following features: 

 N-grams consisting of the current character and up to three preceding and three succeeding 
characters e.g. for each ith character xi, the character sequence {xi-3,…,xi,…,xi+3} is considered. 

 Whether the current character is a digit. 

 Whether the current character is a joiner. 

 Unicode class of current character. 

 Direction of current character. Urdu is bidirectional where basic/secondary characters and dia-
critics are written from right-to-left while numeric characters from left-to-right. 

5.4 Results 

We have used precision, recall, and F1 measure as our evaluation metrics as they provides a more in-

formative assessment of the performance than the word level and character level error rates. On an 

unseen undiacritized test set of 825 sentences (21K tokens) our model achieved F1 score of 0.97 for 

word boundary and 0.85 for sub-word boundary identification. The detailed results are shown in Table 

5 and 6. 

Not surprisingly, the F1 score for sub-word boundary identification is slightly higher for diacritized 

text as some diacritics are very indicative features of sub-word boundary e.g.   ِ  in compounding. Dia-
critized text also has high precision over undiacritized text for word boundary prediction as the diacritic 

  ِ  is a clear indication of word boundary.  
We also report the macro and micro F1-measures. However the results do not show much improve-

ment between diacritized and non diacritized corpora. One possible explanation is that the corpus is very 

sparsely diacritized with only 5,237 diacritics in 111K tokens. Solution to this problem via automatic 

diacritization is beyond the scope of the current paper. 

  



2568

 F1 

Features 
Word Boundary 

(Space) 

Sub-word Boundary 

(ZWNJ) 

Current character 0.59 0 

+1 character window 0.77 0.07 

+2 character window 0.85 0.46 

+3 character window 0.92 0.72 

+isDigit 0.95 0.79 

+isJoiner 0.96 0.84 

+Unicode class 0.97 0.85 

+Direction 0.97 0.85 

 

Table 4: Results with different feature set. 

 

 Predicted 

I BW BS 

 

G
o

ld
 I 59,149 474 42 

BW 574 19,637 53 

BS 119 116 965 
  

 Predicted 

I BW BS 

 

G
o

ld
 I 60,254 405 44 

BW 560 19,660 44 

BS 115 88 997 

a) Undiacritized test set b) Diacritized test set 

 

Table 5: Confusion matrices for word and sub-word boundary identification. 

 

 Boundary Precision Recall F1  

Without 

Diacritics 

Word 0.97 0.97 0.97 macro-F1= 0.91 

micro-F1= 0.96 Sub-word 0.91 0.80 0.85 

With  

Diacritics 

Word 0.98 0.97 0.97 macro-F1= 0.92 
micro-F1= 0.96 Sub-word 0.92 0.83 0.87 

 

Table 6: Test set results with and without diacritics. 

6 Conclusion & Future work 

We present a CRF sequence modeler for word and sub-word boundary identification in Urdu text using 

orthographic and linguistic features. Our best model achieves F1 score of 0.97 and 0.85 for word and 

sub-word prediction tasks respectively. We also present handcrafted training and testing data that we 

have made publicly available to allow for reproducible research. 

The presented system is trained using a manually crafted corpus of 4,325 sentences (111K tokens) 

which is relatively small compared to segmentation benchmark corpora of Arabic and Chinese. As a 

future direction we will extend our work to tag a much bigger corpus with space as word boundary 

markers and ZWNJ as sub-word boundary markers. We will explore more linguistic features for the 

CRF model to increase performance of sub-word boundary identification task. We also plan to explore 

neural models such as RNN and Bidirectional RNN for Urdu word and sub-word boundary prediction. 

References 

Afzal, M., & Hussain, S. (2001). Urdu computing standards: development of Urdu Zabta Takhti (UZT) 1.01. 

In Multi Topic Conference, 2001. IEEE INMIC 2001. Technology for the 21st Century. Proceedings. IEEE 

International (pp. 216-222). IEEE. 

Aroonmanakun, W. (2002). Collocation and Thai word segmentation. In Proceedings of the 5th SNLP & 5th Ori-

ental COCOSDA Workshop (pp. 68-75). 

Blum, A. (1995). Empirical support for winnow and weighted-majority based algorithms: results on a calendar 

scheduling domain. In Machine Learning Proceedings 1995 (pp. 64-72). 



2569

Cai, D., & Zhao, H. (2016). Neural word segmentation learning for Chinese. arXiv preprint arXiv:1606.04300. 

Cai, D., Zhao, H., Zhang, Z., Xin, Y., Wu, Y., & Huang, F. (2017). Fast and accurate neural word segmentation for 

chinese. arXiv preprint arXiv:1704.07047. 

Charoenpornsawat, P., Kijsirikul, B., & Meknavin, S. (1998, November). Feature-based Thai unknown word 

boundary identification using winnow. In Circuits and Systems, 1998. IEEE APCCAS 1998. The 1998 IEEE 

Asia-Pacific Conference on (pp. 547-550). IEEE. 

Durrani, N., & Hussain, S. (2010, June). Urdu word segmentation. In Human Language Technologies: The 2010 

Annual Conference of the North American Chapter of the Association for Computational Linguistics (pp. 528-

536). Association for Computational Linguistics. 

Green, S., & DeNero, J. (2012, July). A class-based agreement model for generating accurately inflected transla-

tions. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Pa-

pers-Volume 1 (pp. 146-155). Association for Computational Linguistics. 

Huihsin, T., Chang, P., Andrew, G., Jurafsky, D., & Manning, C. (2005). A conditional random field word seg-

menter. In Fourth SIGHAN Workshop. 

Hussain, S., & Afzal, M. (2001). Urdu computing standards: Urdu zabta takhti (uzt) 1.01. In Multi Topic Confer-

ence, 2001. IEEE INMIC 2001. Technology for the 21st Century. Proceedings. IEEE International (pp. 223-

228). IEEE. 

Hussain, S. (2004, August). Letter-to-sound conversion for Urdu text-to-speech system. In Proceedings of the 

workshop on computational approaches to Arabic script-based languages (pp. 74-79). Association for Compu-

tational Linguistics. 

Kawtrakul, A. (1997). Automatic Thai unknown word recognition. In Proc. 4th Natural Language Processing Pa-

cific Rim Symposium (NLPRS-97), Phuket, Thailand, Oct. (pp. 341-346). 

Lafferty, J., McCallum, A., & Pereira, F. C. (2001). Conditional random fields: Probabilistic models for segmenting 

and labeling sequence data. 

Monroe, W., Green, S., & Manning, C. D. (2014). Word segmentation of informal Arabic with domain adaptation. 

In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short 

Papers) (Vol. 2, pp. 206-211). 

Nie, J. Y., Jin, W., & Hannan, M. L. (1994, June). A hybrid approach to unknown word detection and segmentation 

of Chinese. In Proceedings of International Conference on Chinese Computing (pp. 326-335). 

Ping, G., & Yu-Hang, M. (1994). The adjacent matching algorithm of Chinese automatic word segmentation and 

its implementation in the QHFY Chinese-English system. In Proceedings of the 1994 International Conference 

on Chinese Computing, Singapore (Vol. 301, p. 94). 

Rehman, Z., Anwar, W., & Bajwa, U. I. (2011). Challenges in Urdu text tokenization and sentence boundary dis-

ambiguation. In Proceedings of the 2nd Workshop on South Southeast Asian Natural Language Processing 

(WSSANLP) (pp. 40-45). 

Sornlertlamvanich, V. (1993). Word segmentation for Thai in machine translation system. Machine Translation, 

NECTEC, 556-561. 

Wong, P. K., & Chan, C. (1996, August). Chinese word segmentation based on maximum matching and word 

binding force. In Proceedings of the 16th conference on Computational linguistics-Volume 1 (pp. 200-203). 

Association for Computational Linguistics. 


