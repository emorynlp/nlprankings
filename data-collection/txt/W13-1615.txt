










































Sentence-Level Subjectivity Detection Using Neuro-Fuzzy Models


Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 108–114,
Atlanta, Georgia, 14 June 2013. c©2013 Association for Computational Linguistics

Sentence-Level Subjectivity Detection Using Neuro-Fuzzy Models 

 

Samir Rustamov Mark A. Clements 
Georgia Institute of Technology Georgia Institute of Technology 

225 North Avenue NW 225 North Avenue NW 
Atlanta, GA 30332, USA Atlanta, GA 30332, USA 

samir.rustamov@gmail.com clements@ece.gatech.edu 

 
 

Abstract 

In this work, we attempt to detect sentence-

level subjectivity by means of two supervised 

machine learning approaches: a Fuzzy Control 

System and Adaptive Neuro-Fuzzy Inference 

System. Even though these methods are popu-

lar in pattern recognition, they have not been 

thoroughly investigated for subjectivity analy-

sis. We present a novel “Pruned ICF 

Weighting Coefficient,” which improves the 

accuracy for subjectivity detection. Our fea-

ture extraction algorithm calculates a feature 

vector based on the statistical occurrences of 

words in a corpus without any lexical 

knowledge. For this reason, these machine 

learning models can be applied to any lan-

guage; i.e., there is no lexical, grammatical, 

syntactical analysis used in the classification 

process. 

1 Introduction 

There has been a growing interest, in recent years, 

in identifying and extracting subjective infor-

mation from Web documents that contain opinions. 

Opinions are usually subjective expressions that 

describe people's sentiments, appraisals, or feel-

ings. Subjectivity detection seeks to identify 

whether the given text expresses opinions (subjec-

tive) or reports facts (objective) (Lin et al., 2011). 

Automatic subjectivity analysis methods have been 

used in a wide variety of text processing and natu-

ral language  applications. In many natural lan-

guage processing tasks, subjectivity detection has 

been used as a first phase of filtering to generate 

more informative data.  

The goal of our research is to develop learning 

methods to create classifiers that can distinguish 

subjective from objective sentences. In this paper, 

we achieve sentence-level subjectivity classifica-

tion using language independent feature weighting. 

As a test problem, we employed a subjectivity da-

tabase from the "Rotten Tomatoes" movie reviews 

(see http://www.cs.cornell.edu/people/pabo/movie-

review-data). 

We present two supervised machine learning 

approaches in our development of sentence-level 

subjectivity detection: Fuzzy Control System 

(FCS), and Adaptive Neuro-Fuzzy Inference Sys-

tem (ANFIS). Even though these methods are pop-

ular in pattern recognition, they have not been 

thoroughly investigated for subjectivity analysis. 

We present a novel “Pruned ICF Weighting Coef-

ficient,” which improves the accuracy for subjec-

tivity detection. Our feature extraction algorithm 

calculates a feature vector based on statistical oc-

currences of words in the corpus without any lexi-

cal knowledge. For this reason, the machine 

learning models can be applied to any language; 

i.e., there is no lexical, grammatical, syntactical 

analysis used in the classification process.  

2 Related work 

In recent years, several different supervised and 

unsupervised learning algorithms were investigated 

for defining subjective information in text or 

speech.  

Riloff and Wiebe (2003) presented a bootstrap-

ping method to learn subjectivity classifiers from a 

collection of non-annotated texts.  Wiebe and 

Riloff (2005) used a similar method, but they also 

learned objective expressions apart from subjective 

expressions.  

Pang and Lee (2004) proposed a MinCut based 

algorithm to classify each sentence as being sub-

jective or objective. The goal of this research was 

to remove objective sentences from each review to 

improve document-level sentiment classification 

(82.8% improved to 86.4%).   

108



Grefenstette et al. (2004) presented a Web min-

ing method for identifying subjective adjectives.  

Wilson et al. (2004) and Kim et al. (2005) pre-

sented methods of classifying the strength of opin-

ion being expressed in individual clauses (or 

sentences). 

Riloff et al. (2006) defined subsumption rela-

tionships among unigrams, n -grams, and lexico-

syntactic patterns. They found that if a feature is 

subsumed by another, the subsumed feature is not 

needed.  The subsumption hierarchy reduces a fea-

ture set and reduced feature sets can improve clas-

sification performance. 

Raaijmakers et al (2008) investigated the use of 

prosodic features, word n -grams, character n -

grams, and phoneme n -grams for subjectivity 

recognition and polarity classification of dialog 

acts in multiparty conversation. They found that 

for subjectivity recognition, a combination of pro-

sodic, word-level, character-level, and phoneme-

level information yields the best performance and 

for polarity classification, the best performance is 

achieved with a combination of words, characters 

and phonemes.   

Murray and Carenini (2009) proposed to learn 

subjective patterns from both labeled and unla-

beled data using n -gram word sequences with 

varying level of lexical instantiation. They showed 

that learning subjective trigrams with varying in-

stantiation levels from both annotated and raw data 

can improve subjectivity detection and polarity 

labeling for meeting speech and email threads. 

Martineau and Finin (2009) presented Delta 

TFIDF, an intuitive general purpose technique, to 

efficiently weight word scores before 

classification. They compared SVM Difference of 

TFIDFs and SVM Term Count Baseline results for 

subjectivity classification. As a result, they showed 

that SVM based on Delta TFIDF gives high 

accuracy and low variance.  

Barbosa and Feng (2010) classified the subjec-

tivity of tweets (postings on Twitter) based on two 

kind of features: meta-information about the words 

on tweets and characteristics of how tweets are 

written.  

Yulan He (2010) proposed subjLDA for sen-

tence-level subjectivity detection by modifying the 

latent Dirichlet allocation (LDA) model through 

adding an additional layer to model sentence-level 

subjectivity labels. 

Benamara et al. (2011) proposed subjectivity 

classification at the segment level for discourse-

based sentiment analysis. They classified each 

segment into four classes, S, OO, O and SN, where 

S segments are segments that contain explicitly 

lexicalized subjective and evaluative expressions, 

OO segments are positive or negative opinion im-

plied in an objective segment, O segments contain 

neither a lexicalized subjective term nor an implied 

opinion, SN segments are subjective, though non-

evaluative, segments that are used to introduce 

opinions.  

Remus (2011) showed that by using readability 

formulae and their combinations as features in 

addition to already well-known subjectivity clues 

leads to significant accuracy improvements in 

sentence-level subjectivity classification. 

Lin et al, (2011) presented a hierarchical Bayes-

ian model based on latent Dirichlet allocation, 

called subjLDA, for sentence-level subjectivity 

detection, which automatically identifies whether a 

given sentence expresses opinion or states facts. 

All the aforementioned work focused on English 

data and most of them used an English subjectivity 

dictionary. Recently, there has been some work on 

subjectivity classification of sentences in Japanese 

(Kanayama et al., 2006), Chinese (Zagibalov et al., 

2008; Zhang et al., 2009), Romanian (Banea et al., 

2008; Mihalcea et al., 2007), Urdu (Mukund and 

Srihari, 2010), Arabic (Abdul-Mageed et al., 2011) 

and others based on different machine learning 

algorithms using general and language specific 

features.  

Mihalcea et al., (2007) and Banea et al., (2008) 

investigated methods to automatically generate 

resources for subjectivity analysis for a new target 

language by leveraging the resources and tools 

available for English. Another approach (Banea et 

al., 2010) used a multilingual space with meta clas-

sifiers to build high precision classifiers for subjec-

tivity classification. 

Recently, there has been some work focused on 

finding features that can be applied to any lan-

guage. For example, Mogadala and Varma (2012) 

presented sentence-level subjectivity classification 

using language independent feature weighting and 

performed experiments on 5 different languages 

including English and a South Asian language 

(Hindi).  

109



Rustamov et. al., (2013) applied hybrid Neuro-

Fuzzy and HMMs to document level sentiment 

analysis of movie reviews.  

In the current work, our main goal is to apply 

supervised methods based on language independ-

ent features for classification of subjective and ob-

jective sentences.  

3 Feature Extraction 

Most language independent feature extraction al-

gorithms are based on the presence or occurrence 

statistics within the corpus. We describe such an 

algorithm which is intuitive, computationally effi-

cient, and does not require either additional human 

annotation or lexical knowledge.  

We use a subjectivity dataset 1v.0: 5000 subjec-

tive and 5000 objective processed sentences in 

movie reviews [Pang/Lee ACL 2004].  

As our target does not use lexical knowledge, 

we consider every word as one code word. In our 

algorithm we do not combine verbs in different 

tenses, such as present and past  ("decide" vs "de-

cided") nor nouns as singular or plural ("fact" vs 

"facts"). Instead, we consider them as the different 

code words. 
Below, we describe some of the parameters: 

 N  is the number of classes ( in our problem 
N=2: i.e. subjective and objective classes); 

 M is the number of different words (terms) 
in the corpus; 

 R is the number of observed sequences in 
the training process; 

  r
T

rrr

r
oooO ,...,,

21
   are the sentences in the 

training dataset, where 
r

T  is the length of r-

th sentence, Rr ,...,2,1 ; 

 
ji ,

  describes the association between i-th 

term (word) and the j-th class 

 NjMi ,...,2,1;,...,1  ;  
 

ji
c

,
 is the number of times i-th term oc-

curred in the j-th class; 

 
j

jii
ct

,
 denotes the occurrence times of 

the i-th term in the corpus; 

 frequency of the i -th term in the j -th class 

i

ji

ji
t

c
c

,

,  ; 

We present a new weighting coefficient, which 

affects the accuracy of the system, so that instead 

of the number of documents we take the number of 

classes in the well-known IDF (Inverse-Document 

Frequency) formula. Similar to IDF, we call it 

Pruned ICF (Inverse-Class Frequency) 














i

i
dN

N
ICF

2
log , 

where i  is a term, idN  is the number of classes 

containing the term i , which qc ji , , where  

N
q





1
. 

The value of    is found empirically with 

4.1  being best for the corpus investigated.  

The membership degree of the terms ( ji, ) for 

appropriate classes can be estimated by experts or 

can be calculated by analytical formulas. Since a 

main goal is to avoid using human annotation or 

lexical knowledge, we calculated the membership 

degree of each term by an analytical formula as 

follows  NjMi ,...,2,1;,...,1  : 

TF:   





N

v

vi

ji

ji

c

c

1

,

,

,
 ;   (1) 

ICFTF  :   









N

v

vvi

jji

ji

ICFc

ICFc

1

,

,

, ;  (2) 

4 Subjectivity detection using Fuzzy Con-
trol System  

We use a statistical approach for estimation of the 

membership function, instead of expert knowledge, 

at the first stage. Then we apply fuzzy operations 

and modify parameters by the back-propagation 

algorithm.  

We now introduce our algorithm ( Rr ,...,2,1 ).  

1. The membership degree of terms ( r
ji ,

 ) of the 

r -th sentence are calculated from formulas (1)-(2).  
2. Maximum membership degree is found with 

respect to the  classes for every term of the r-th 

sentence  

 

.,...,1

,maxarg

,

,
1

,,

Mi

j r
vi

N

r

ji

r

ji













   (3) 

3. Means of maxima are calculated for all clas-

ses: 

110



  
.,...,1

,max:

,

,
1

,

,

Nj

iZ

T

r

vi
N

r

ji

r

j

r

Zk

r

jk

r

j

r
j




















     (4) 

We use the Center of Gravity Defuzzification 

(CoGD) method for the defuzzification operation.  

Objective and subjective sentences selected ac-

cording to classes are trained by a fuzzy control 

model. The objective function is defined as follows 

(Aida-zade et. al, 2012): 

 
NRy

R

r

rN

j

r

j

N

j

j

r

j

d

y

yE
































 min
2

1

1

2

1

1





,    (5) 

 Nyyyy ,...,, 21 ,  Ndr ,...,2,1 desired output. 
The partial derivatives of this function are 

calculated in following form:   

 


































 R

r

rN

j

r

j

N

j

j

r

j

N

j

r

j

r

t

t

d

y

y

yE

1

1

1

1








, N1,2,...,t  . 

Function (5) is minimized by the conjugate 

gradient method with the defined optimal values of 
*y .  

Rounding of y  shows the index of the classes 

obtained in the result: 










N

j

j

N

j

jj y

y

1

1

*





.        (6) 

Acceptance strategy (s): 

 



 


otherwisereject

iiyifIi
s

sss

,

,, 11
, 

where si  is the index of the appropriate class, 

 NI ,...,2,1 . Here  5.0;01  is the main quan-
tity, which influences the reliability of the system. 

It is straightforward to check which feature vec-

tor gives the best results for FCS. Table 1. shows 

average accuracy over 10 fold cross validation of 

FCS based on (1)-(2) features in the  non-restricted 

case. Note that these results depend on the classifi-

cation method these results might be different for 

different classifiers. 

 

Features Accuracy (%) 

 TF 89.87 

ICFTF   91.3 

Table 1. Results of  FCS based on TF and 
ICFTF  features. 

 

We also checked FCS based on Delta TFIDF 

features (Martineau and Finin, 2009). As DeltaIDF 

weighting coefficients of both classes are the same, 

application of DeltaIDF weighting does not change 

the accuracy of the FCS. As we see from Table 1., 

the accuracy of the method increases after applica-

tion of Pruned ICF weighting.  

We show results of subjectivity detection by 

FCS with different values of 1  based on ICFTF   

in Table 2. It can be seen that the rejection per-

centage is 0.01 for 5.0
1
 . In the testing process 

0.01% of the sentences have such words, which 

after pruned ICF weighting, becomes 0 and the 

system rejects such sentences. 
 

 Correct 

(%) 

Rejection 

(%) 

Error 

(%) 
3.0

1
  76.41 20.86 2.73 

4.0
1
  85.11 10.14 4.75 

5.0
1
  91.3 0.01 8.69 

 

Table 2. Average results of 10 folds cross vali-

dation accuracy of FCS based on ICFTF  feature 

with different value of 
1

 . 

5 Subjectivity detection using Adaptive 
Neuro Fuzzy Inference System  

Fig. 1 illustrates the general structure of Adap-

tive Neuro Fuzzy Inference System. In response to 

linguistic statements, the fuzzy interface block 

provides an input vector to a Multilayer Artificial 

Neural Network (MANN) (Fuller, 1995).  

We used statistical estimation of membership 

degree of terms by (2) instead of linguistic state-

ments at the first stage. Then we applied fuzzy op-

erations (3) and (4).  
 

111



 

Fig. 1. The structure of ANFIS. 

MANN was applied to the output of the fuzzyfi-

cation operation. The input vector of neural net-

work is taken from the output vector of the 

fuzzyfication operation (fig. 2). Outputs of MANN 

are taken as indexes of classes appropriate to the 

sentences. MANN is trained by the back-

propagation algorithm. 

 

 

 
Fig. 2. The structure of MANN in ANFIS. 

 

We set two boundary conditions for the  ac-

ceptance decision: 

1) 2ky , 

2) 3
~  pk yy , 

where y  is the output vector of MANN,  ky and 

py
~  are two successive maximum elements of the 

vector y , i.e. 

i
Ni

k yy



1
max , i

Ni
yk




1
maxarg , 

i
Nikki

p yy



1;11

max~ . 

There is shown results of subjectivity detection 

in  movie reviews by ANFIS with different values 

of 2  and 3 in Table 3. 

 

 Correct 

(%) 

Rejection 

(%) 

Error 

(%) 
5.0;8.0

32
  78.66 18.84 2.5 

5.0;5.0
32
  85.77 8.62 5.61 

No restriction 91.66 0.01 8.33 

Table 3. Average results of 10 folds cross valida-

tion accuracy ANFIS based on ICFTF   for sub-

jectivity detection in movie reviews. 

 

The accuracy of the ANFIS (91.66%) is higher 

than that of FCS (91.3%) at the cost of additional 

variables being required in the middle layer of the 

neural network.  
 

6 Conclusion  

We have described two different classification sys-

tem structures, FCS, ANFIS, and applied them to 

sentence-level subjectivity detection in a movie 

review data base. We have specifically shown how 

to train and test these methods  for classification of 

sentences as being either objective or subjective. A 

goal of the research was to formulate methods that 

did not depend on linguistic knowledge and there-

fore would be applicable to any language. An im-

portant component of these  methods is the feature 

extraction process. We focused on analysis of  in-

formative features that improve the accuracy of the 

systems with no language-specific constraints. As 

a result,  a novel  "Pruned ICF Weighting Func-

tion" was devised with a parameter specifically 

estimated for the subjectivity data set. 

When comparing the current system with others, 

it is necessary to emphasize that the use of linguis-

tic knowledge does improve accuracy. Since we do 

not use such  knowledge, our results should only 

be compared with other methods having similar 

constraints, such as those which use features based 

on bags of words that are tested on the same data 

set. Examples include studies by  Pang and Lee 

(2004) and Martineau and Finin (2009). Pang and 

Lee report 92% accuracy on sentence-level subjec-

tivity classification using Naıve Bayes classifiers 

and 90% accuracy using SVMs on the same data 

set. Martineau and Finin (2009) reported 91.26% 

accuracy using SVM Difference of TFIDFs. The 

currently reported results: FCS (91.3%), ANFIS 

(91.7%) are similar. However, our presented meth-

ods have some advantages. Because the function 

(5) is minimized only with respect to 

 
N

yyyy ,...,,
21

  (in the defined problem N=2), 

FCS is the fastest algorithm among supervised ma-

chine learning methods. At the cost of additional 

variables added within the middle layer of the neu-

ral network, ANFIS is able to improve accuracy a 

112



small amount. It is anticipated that when IF-THEN 

rules and expert knowledge are inserted into 

ANFIS and FCS, accuracy will improve to a level 

commensurate with human judgment.  

References  

Aditya Mogadala. Vasudeva Varma. 2012. Lan-

guage Independent Sentence-Level Subjectivity 

Analysis with Feature Selection. Proceedings of 

the 26th Pacific Asia Conference on Lan-

guage,Information and Computation, pages 

171–180. 

Alina Andreevskaia and Sabine Bergler. 2006. 

Mining wordnet for fuzzy sentiment: Sentiment 

tag extraction from WordNet glosses. In Pro-

ceedings of EACL 2006. 

Bing Liu. Sentiment Analysis and Opinion Mining. 

2012. Synthesis Lectures on Human Language 

Technologies. 

Bo Pang and Lillian Lee. 2004. A sentimental edu-

cation: Sentiment analysis using subjectivity 

summarization based on minimum cuts. In Pro-

ceedings of the 42nd Annual Meeting on Associ-

ation for Computational Linguistics (ACL), pp. 

271-278.  

Bo Pang and Lillian Lee. 2008. Opinion Mining 

and Sentiment Analysis. Now Publishers Inc. 

Carmen Banea, Rada Mihalcea, and Janyce Wiebe. 

2010. Multilingual subjectivity: are more lan-

guages better. Proceedings of the 23rd Interna-

tional Conference on Computational Linguistics 

(Coling 2010), pp. 28–36. 

Carmen Banea, Rada Mihalcea, Janyce Wiebe and 

Samer Hassan. 2008. Multilingual subjectivity 

analysis using machine translation. Proceedings 

of the Conference on Empirical Methods in Nat-

ural Language Processing, pp. 127–135.  

Chenghua Lin, Yulan He and Richard Everson. 

2011. Sentence Subjectivity Detection with 

Weakly-Supervised Learning. Proceedings of 

the 5th International Joint Conference on Natu-

ral Language Processing, pp. 1153–1161. 

Ellen Riloff and Janyce Wiebe. 2003. Learning 

Extraction Patterns for Subjective Expressions. 

In: Proceedings of the Conference on Empirical 

Methods in Natural Language Processing, pp. 

105–112.  

Ellen Riloff, Siddharth Patwardhan, and Janyce 

Wiebe. Feature subsumption for opinion analy-

sis. 2006. In Proceedings of the Conference on 

Empirical Methods in Natural Language Pro-

cessing (EMNLP-2006). 

Farah Benamara, Baptiste Chardon, Yannick 

Mathieu, and Vladimir Popescu. 2011. Towards 

Context-Based Subjectivity Analysis. In Pro-

ceedings of the 5th International Joint Confer-

ence on Natural Language Processing (IJCNLP-

2011). 

 Gabriel Murray and Giuseppe Carenini. 2009. 

Predicting subjectivity in multimodal conversa-

tions. In Proceedings of the Conference on Em-

pirical Methods in Natural Language 

Processing (EMNLP), pages 1348–1357. 

Gregory Grefenstette, Yan Qu, David A. Evans,  

and James G. Shanahan. 2006. Validating the 

Coverage of Lexical Resources for Affect Anal-

ysis and Automatically Classifying New Words 

along Semantic Axes. In: Proceedings of AAAI 

Spring Symposium on Exploring Attitude and 

Affect in Text: Theories and Applications, pp. 

93–107. 

Hiroshi Kanayama and Tetsuya Nasukawa. 2006. 

Fully automatic lexicon expansion for domain-

oriented sentiment analysis. Proceedings of the 

2006 Conference on Empirical Methods in Nat-

ural Language Processing, pages 355–363. 

Janyce Wiebe and Ellen Riloff. 2005. Creating 

subjective and objective sentence classifiers 

from unannotated texts. Computational Linguis-

tics and Intelligent Text Processing, Springer, 

pp. 486–497.  

Justin Martineau, and Tim Finin. 2009. Delta 

TFIDF: An Improved Feature Space for 

Sentiment Analysis. In Proceedings of the 3rd 

AAAI International Conference on Weblogs and 

Social Media. 
Kamil Aida-zade, Samir Rustamov, Elshan Mustafayev, 

and Nigar Aliyeva, 2012. Human-Computer Dia-

logue Understanding Hybrid System. IEEE  Xplore, 

International Symposium on Innovations in Intelli-

gent Systems and Applications. Trabzon, Turkey, pp. 

1-5. 

Luciano Barbosa and Junlan Feng. 2010. Robust 

sentiment detection on twitter from biased and 

noisy data. In Proceedings of the International 

Conference on Computational Linguistics (CO 

LING-2010). 

Muhammad Abdul-Mageed, Mona T. Diab, and 

Mohammed Korayem. 2011. Subjectivity and 

sentiment analysis of modern standard Arabic, 

In Proceedings of the 49th Annual Meeting of 

113



the Association for Computational Linguistics: 

short papers, pages 587–591. 

Rada Mihalcea, Carmen Banea and Janyce Wiebe. 

2007. Learning multilingual subjective language 

via cross-lingual projections. Proceedings of the 

45th Annual Meeting of the Association of Com-

putational Linguistics, pages 976–983. 

Robert Fuller. Neural Fuzzy Systems, 1995. 

Robert Remus. 2011. Improving Sentence-level 

Subjectivity Classification through Readability 

Measurement. NODALIDA-2011 Conference 

Proceedings, pp. 168–174. 

Samir Rustamov, Elshan Mustafayev, Mark 

Clements. 2013. Sentiment Analysis using 

Neuro-Fuzzy and Hidden Markov Models of 

Text. IEEE Southeastcon 2013, Jacksonvilla, 

Florida,USA. 

Smruthi Mukund and Rohini K. Srihari. 2010. A 

vector space model for subjectivity classifica-

tion in Urdu aided by co-training. In Proceed-

ings of Coling 2010: Poster Volume, pages 860–

868. 

Soo-Min Kim and Eduard Hovy. 2005. Automatic 

Detection of Opinion Bearing Words and Sen-

tences. In: Companion Volume to the Proceed-

ings of the International Joint Conference on 

Natural Language Processing, pp. 61–66. 

Stephan Raaijmakers, Khiet Truong, and Theresa 

Wilson. 2008. Multimodal subjectivity analysis 

of multiparty conversation. In Proceedings of 

the Conference on Empirical Methods in Natu-

ral Language Processing (EMNLP), pages 466–

474. 

Taras Zagibalov and John Carroll. 2008. Unsuper-

vised classification of sentiment and objectivity 

in Chinese text. In Proceedings of International 

Joint Conference on Natural Language Pro-

cessing (IJCNLP-2008), pp. 304–311. 

Theresa Wilson, Janyce Wiebe, Rebecca Hwa. 

2004. Just How Mad Are You? Finding Strong 

and Weak Opinion Clauses. In: Proceedings of 

the National Conference on Artificial Intelli-

gence, pp. 761–769. 

Yulan He. 2010. Bayesian Models for Sentence-

Level Subjectivity Detection. Technical Report 

KMI-10-02,  June 2010. 
Ziqiong Zhang, Qiang Ye, Rob Law, and Yijun Li. 

2009. Automatic Detection of Subjective Sentences 

Based on Chinese Subjective Patterns. Proceedings  

of 20th International Conference, MCDM-2009, 

pp. 29-36.  

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

114


