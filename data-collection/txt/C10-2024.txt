206

Coling 2010: Poster Volume, pages 206–213,

Beijing, August 2010

Comparing Sanskrit Texts for Critical Editions ∗

Marc Csernel

Projet AXIS: Inria-Rocquencourt

& Universite Paris-Dauphine
Marc.Csernel@inria.fr

Tristan Cazenave

LAMSADE

Universite Paris-Dauphine,

cazenave@lamsade.dauphine.fr

Abstract

Traditionally Sanskrit is written without
blank, sentences can make thousands of
characters without any separation. A crit-
ical edition takes into account all the dif-
ferent known versions of the same text in
order to show the differences between any
two distinct versions, in term of words
missing, changed or omitted. This pa-
per describes the Sanskrit characteristics
that make text comparisons different from
other languages, and will present different
methods of comparison of Sanskrit texts
which can be used for the elaboration of
computer assisted critical edition of San-
skrit texts. It describes two sets of meth-
ods used to obtain the alignments needed.
The ﬁrst set is using the L.C.S., the sec-
ond one the global alignment algorithm.
One of the methods of the second set uses
a classical technique in the ﬁeld of artiﬁ-
cial intelligence, the A* algorithm to ob-
tain the suitable alignment. We conclude
by comparing our different results in term
of adequacy as well as complexity.

Introduction

1
A critical edition is an edition that takes into
account all the different known versions of the
same text.
If the text is mainly known through
a great number of manuscripts that include non
trivial differences, the critical edition often looks
rather daunting for readers unfamiliar with the
subject:
the edition is then formed mainly by

∗ This work is supported by the EEC FP7 project IDEAS

footnotes that enlighten the differences between
manuscripts, while the main text (that of the edi-
tion) is rather short, sometimes a few lines on a
page. The differences between the texts are usu-
ally described in term of words (sometime sen-
tences) missing, added or changed in a speciﬁc
manuscript. This reminds us the edit distance but
in term of words instead of characters. The text
of the edition is established by the editor accord-
ing to his own knowledge of the text. It can be
a particular manuscript or a ”mean” text built ac-
cording to some speciﬁc criteria. Building a crit-
ical edition by comparing texts two by two, espe-
cially manuscript ones, is a task which is certainly
long and, sometimes, tedious. This is why, for
a long time, computer programs have been help-
ing philologists in their work (see O’Hara (1993)
or Monroy (2002) for example), but most of them
are dedicated to texts written in Latin (sometimes
Greek) scripts.

In this paper we will focus on the problems in-
volved by a critical edition of manuscripts writ-
ten in Sanskrit. Our approach will be illustrated
by texts that are extracted from manuscripts of the
“Banaras gloss”, k¯a´sik¯avr. tti.

The Banaras gloss was written around the 7th
century A.D., and is one of the most famous com-
mentary on the P¯an. ini’s grammar, which is known
as the ﬁrst generative grammar ever written, and
was written around the ﬁfth century B.C. as a
set of rules. These rules cannot be understood
without the explanation provided by a commen-
tary such as the k¯a´sik¯avr. tti. This collection was
chosen, because it is one of the largest collection
of Sanskrit manuscripts (about hundred different
ones) of the same text actually known.

207

In what follows we will ﬁrst describe the char-
acteristics of Sanskrit that matter for text compar-
ison algorithms, we will then show that such a
comparison requires the use of a lemmatized text
as the main text. The use of a lemmatized text in-
duces the need of a lexical preprocessing. Once
the lexical preprocessing is achieved, we can pro-
ceed to the comparison, where we develop two
kinds of approach, one based on the LCS, which
was used to solved this problem, the other one re-
lated to sequence alignment. In both cases the re-
sults are compared in terms of adequacy as well
as complexity. We then conclude and examine the
perspective of further work.

2 How to compare Sanskrit manuscripts
One of the main characteristics of Sanskrit is that
it is not linked to a speciﬁc script. But here
we will provide all our examples using the De-
van¯agar¯ı script, which is nowadays the most used.
The script has a 48 letters alphabet. Due to the
long English presence in India, a tradition of writ-
ing Sanskrit with the Latin alphabet (a translitera-
tion) has been established for a long time. These
transliteration schemes were originally carried out
to be used with traditional printing. It was adapted
for computers by Frans Velthuis (Velthuis, 1991),
more speciﬁcally to be used with TEX. According
to the Velthuis transliteration scheme, each San-
skrit letter is written using one, two or three Latin
characters; notice that according to most translit-
eration schemes, upper case and lower case Ro-
man characters have a very different meaning.

In ancient manuscripts, Sanskrit is written with-
out spaces, and this is an important graphical
speciﬁcity, because it increases greatly the com-
plexity of text comparison algorithms. On the
other hand, each critical edition deals with the no-
tion of word. Since electronic Sanskrit lexicons
such as the one built by Huet (2006; 2004) do not
cope with grammatical texts, we must ﬁnd a way
to identify each Sanskrit word within a character
string, without the help of either a lexicon or of
spaces to separate the words.

The reader interested in a deeper approach of
the Sanskrit characteristics which matters for a
computer comparison can look in Csernel and
Patte (2009).

The solution comes from the lemmatization of
one of the two texts of the comparison: the text
of the edition. The lemmatized text is prepared
by hand by the editor. We call it a padap¯at.ha,
according to a mode of recitation where sylla-
bles are separated. From this lemmatized text, we
will build the text of the edition, that we call a
sam. hitap¯at.ha, according to a mode of recitation
where the text is said continuously. The trans-
formation of the padap¯at.ha into the sam. hitap¯at.ha
is not straightforward because of the existence of
sandhi rules.

What is called sandhi — from the Sanskrit: li-
aison — is a set of phonetic rules which apply to
the morpheme junctions inside a word or to the
junction of words in a sentence. These rules are
perfectly codiﬁed in P¯an. ini’s grammar. Roughly
speaking the Sanskrit reﬂects (via the sandhi) in
the writing the liaison(s) which are made by a
human speaker. A text with separators (such as
spaces) between words, can look rather different
(the letter string can change greatly) from a text
where no separator is found (see the example of
padap¯at.ha on next page).

The processing is done in three steps, but only

two of them will be considered in this paper:

• First step: The padap¯at.ha is transformed
into a virtual sam. hitap¯at.ha in order to make
feasible a comparison with a manuscript.
The transformation consists in removing all
the separations between words and then
in applying the sandhi.
This virtual
sam. hitap¯at.ha which will form the text of the
edition, is compared with each manuscript.
As a sub product of this lexical treatment, the
places where the separation between words
occur will be kept into a table which will be
used in further treatments.
• Second step: An alignment of a manuscript
and the virtual sam. hitap¯at.ha. We describe
three different methods to obtain these align-
ments. The aim is to identify, as precisely as
possible, the words in the manuscript, using
the padap¯at.ha as a pattern. Once the words
of the manuscript have been determined, we
can see through the alignment those which
have been added, modiﬁed or suppressed.

208

• Third step:: Display the results in a compre-
hensive way for the editor.

The comparison is done paragraph by para-
graph, according to the paragraphs made in the
padap¯at.ha during its elaboration by the editor.
Each of the obtained alignments, together with
the lemmatized text (i.e. padap¯at.ha), suggests an
identiﬁcation of the words of the manuscript.

3 The lexical preprocessing
The goal of this step is to transform both the
padap¯at.ha and the manuscript in order to make
them comparable. This treatment will mainly
consist
in transforming the padap¯at.ha into a
sam. hitap¯at.ha by applying the sandhi.

At the end of the lexical treatment the texts are
transmitted to the comparison module in an inter-
nal encoding.

This allows us to ensure the comparison what-

ever the text encoding.
An example of padap¯at.ha:

viˆudˆpanna ruupa siddhis+v.rttis+iya.m

kaa"sikaa naama
We can see that words are separated by three dif-
ferent lemmatization signs: +,
, ˆ which indicate
respectively the presence of an inﬂected item, the
component of a compound word, the presence of
a preﬁx.

The previous padap¯at.ha becomes the following

sam. hitap¯at.ha:
vyutpannaruupasiddhirv.rttiriya.mkaa"si

kaanaama
after the transformation induced by the lexical
pre-processing, the bold letters represent the let-
ters (and the lemmatization signs) which have
been transformed.

Notice that we were induced (for homogene-
ity reasons) to remove all the spaces from the
manuscript before the comparison process. Thus
no word of the manuscript can appear separately
during that process.

The sandhi are perfectly determined by
the Sanskrit grammar
(see for example Re-
nou (1996)). They induce a special kind of dif-
ﬁculties due to the fact that their construction can
be, in certain cases, a two-step process. During
the ﬁrst step, a sandhi induces the introduction of

1d0
< tasmai
4c3,5
< gurave
---
> gane
> "
> saaya

Word 1 ’tasmai’ is :
- Missing
Word 2 ’"srii’ is :
- Followed by
Added word(s)
’ga.ne"saaya’
Word 3 ’gurave’ is :
- Missing

Ediff with spaces L.C.S. based results without space

Table 1: different comparisons

a new letter (or a letter sequence). This new letter
can induce, in the second step, the construction of
another sandhi.

4 The ﬁrst trials

The very ﬁrst trials on Sanskrit critical edition
were conducted by Csernel and Patte (2009).
Their ﬁrst idea was to use diff (Myers (1986)) in
order to obtain the differences between two San-
skrit sequences.

But they ﬁnd the result quite disappointing. The
classical diff command line provided no useful
information at all.

They obtained a slightly better result with
Emacs ediff, as shown in Table 1, left col-
umn: we can see which words are different. But
as soon as they wanted to compare the same se-
quences without blank, they could not get a better
result using ediff than using diff. This is why
they started to implement an L.C.S. (Hirschberg,
1975) based algorithm. Its results appear in the
right column of Table 1.

4.1 The L.C.S based algorithm
The L.C.S matrix associated with the previous re-
sult can be seen on ﬁgure 1 on next page.

On this ﬁgure the vertical text represents the
sam. hitap¯at.ha,
the horizontal text is associated
with a manuscript. The horizontal bold dark lines
have been provided by the padap¯at.ha, before it
has been transformed into the sam. hitap¯at.ha.

The rectangles indicate how the correspon-
dences have been done between the sam. hitap¯at.ha
and the manuscript. One corresponds to a word
missing (tasmai),
two correspond to a word
present in both strings:
the words s"rii and
nama.h, the last one corresponds to a word with
a more ambiguous status, we can say either that

209

by moving in the same word the letters apart from
the gaps.

In the following we consider that the distance
matrix has been built from the top left to the bot-
tom right, and that the alignment is built by keep-
ing a path from the bottom right till the top left of
the matrix.

In such case, if some words are missing in the
manuscript, some letters can be misaligned (not
with the proper word), but this misalignment can
be easily corrected by shifting the orphan letters
till the correct matching word.

5.1 Shifting the orphan letters
We will call an orphan letter a letter belonging to
an incomplete word of the manuscript (generally)
and being isolated. To obtain a proper alignment
these letters must ﬁt with the words to which they
belong.

The sequence Seq 1 below gives a good ex-
ample. The upper line of the table represents
the padap¯at.ha, the second one the manuscript.
In this table, the words pratyaahaaraa and
rtha.h are missing in the manuscript. Conse-
quently the letters a.h are misplaced, with the
word rtha.h. The goal is to shift them to the
right place with the word upade"sa.h. The
result after shifting the letters appears in the se-
quence Seq 2 .

u p a d e "s a .h p r a t y aa h aa r aa r th a .h
u p a d e "s - -
- - a .h

- - - - - - - - - -

Seq 1

u p a d e "s a .h p r a t y aa h aa r aa r th a .h
u p a d e "s a .h - - - - - - - - - -
- - - -

Seq 2

On the second example (Seq 3 & 4) we see on the
left side of the table that the letter a must just be
shifted from the beginning of asiddhy to the
end of saavarny giving Seq 4.

s aa v a r .n y a p r a s y d dh y
s aa v a r .n y - - - a s y d dh y
Seq 3: the orphan letter

s aa v a r .n y a p r a s y d dh y
s aa v a r .n y a - - - s y d dh y

Seq 4: once shifted

Figure 1: The L.C.S. Matrix

the word has been replaced or that one word is
missing and another word has been added. We can
see below the result in term of alignment where
the double ”|” represents a separation between
two words.

t a s m ai "s r ii g u r a v e - - - - n a m a .h
- - - - - "s r ii g - - a .n e "s aa y a n a m a .h

the corresponding alignment

If the result appears quite obvious within this
example, it is not always so easy, particularly
when different paths within the matrix can lead
to different alignments providing different results.
This induced them to put a lot of post treat-
ments to improve their results, and, at the end, the
method looked rather complicated. This is why
we were induced to produce an aligment method
based on the edit distance.

5 Alignment based on edit distance

We used two different methods to get the align-
ments formed by the matrix: the ﬁrst one, based
on the common sense, is the subject of this sec-
tion. The second one, based on the IDA* algo-
rithm is the subject of the next one.

The idea is to get anyone of the alignments be-
tween the sam. hitap¯at.ha and the manuscript, from
the distance matrix, and then apply some simple
transformations to get the right one.

The ﬁrst goal is to minimize the number of in-
complete words which appear in the alignment
(mostly in the manuscript). The second goal is to
improve the compactness of each letter sequence

210

But another kind of possible shift is the one
linked to the presence of supplementary letters
within the manuscript such as in Seq 5. The
letters a and nam of the padap¯at.ha are shifted to
the right end of the sequence prayoj such as
shown in Seq 6.

Moving to the position at the upper left means
aligning two characters in the sequences. Mov-
ing up means aligning a gap in the horizontal se-
quence with a letter in the vertical sequence. Mov-
ing to the left means aligning a gap in the vertical
sequence with a letter in the horizontal sequence.

p r a y o j - - - - - a - - -
- n a m
p r a y o j a n a m s a .m j "n aa n a m

Seq 5: before shifting

p r a y o j a n a m - - - - -
- - - -
p r a y o j a n a m s a .m j "n aa n a m

Seq 6: once shifted

5.2 The results
The results of the program are ﬁrst displayed as a
text ﬁle. They do not come directly from the align-
ment but from a further treatment, which elimi-
nates some of the useless differences discovered,
and transform the other ones into something more
convenient for a human reader.
Paragraph 3 is Missing in File Asb2

Word 11 ’saara’ is:
- Substituted with ’saadhu’ in Man. aa
Word 17 ’viv.rta’ is:
- Followed by Added word(s) ’grantha"saa’

in Manuscript A3

Word 21 ’viudpanna’ is:
- Substituted with ’vyutpannaa’ in Man. A3

(P3) Word 32 ’k.rtyam’ is:

- Substituted with ’karyam’ in

Manuscript A3

- Substituted with ’kaaryam’ in

Manuscripts aa, am4, ba2
Such a result, if not fully perfect, has been vali-
dated as a correct base for further ameliorations.

6 Using A* for critical edition
In this section we explain the application of A*
(Hart et al., 1968; Ikeda and Imai, 1994) to critical
edition. We start deﬁning a position for the prob-
lem, then we explain the cost function we have
used and the admissible heuristic. We end with
the search algorithm.

6.1 Positions
A position is a couple of indexes (x,y) that repre-
sents a position in the dynamic programming ma-
trix. The starting position is at the bottom right of
the matrix. The goal position is at the upper left of
the matrix (0,0). There are at most three succes-
sors of a position:
the upper position (x,y-1),
the position on the left (x-1,y) and the position
at the upper left (x-1,y-1).

6.2 A cost function for the critical edition
It appeared at the end of the ﬁrst trials of Csernel
and Patte (2009) that we can consider the most
important criteria concerning the text alignment
to be an alignment concerning as few words as
possible, and as a secondary criteria the highest
possible compactness.

It can be formalized by a cost function which

will contain

• the edit distance between the two strings.
• the number of sequences of gaps.
• the number of words in the manuscript con-

taining at least a gap.

6.3 The admissible heuristic
We can observe that the edit distance contained
in the dynamic programming matrix is always
smaller than the score function we want to min-
imize since the score function is the edit distance
increased by the number of gap sequences and the
number of words containing gaps.

At any node in the tree, the minimum cost path
that goes through that node will be greater than the
cost of the path to the node (the g value) increased
by the edit distance.

The edit distance contained in the dynamic pro-
gramming matrix is an admissible heuristic for
our problem.

6.4 The search algorithm
The search algorithm is the adaptation of IDA*
(Korf, 1985) to the critical edition problem.
It
takes 7 parameters: g the cost of the path to the
node, y and x the coordinates of the current po-
sition in the matrix, and four booleans that tell if
a gap has already been seen in the same word of
the padap¯at.ha, if a gap has already been seen in
the same word of the manuscript, if the previous
move is a gap in the manuscript or a move in the
padap¯at.ha.

211

The search is successful if it has reached the up-
per left of the matrix (x = 0 and y = 0, lines
3 and 4 of the pseudo code), and it fails if the
minimal cost of the path going through the current
node is greater than the threshold (lines 5-6). The
search is also stopped if the position has already
been searched during the same iteration, with the
same threshold and a less or equal g (lines 7-8).

In other cases recursive calls are performed

(lines 15, 22, 36 and 43).

The ﬁrst case deals with the insertion of a gap
in the padap¯at.ha (possible if x is strictly positive,
lines 11-16).
If this is the ﬁrst gap in the word
we do not add anything to the cost, since we don’t
care about the number of words containing gaps in
the padap¯at.ha, if the previous move is not a gap
in the padap¯at.ha then we add one to the cost (line
14) and the recursive call is made with a cost of
g + deltag + 1 since inserting a gap also costs
one.

The second case deals with alignment of the
same letters (lines 17-23).
In that case the re-
cursive call is performed with the same g since
it costs zero to align the same letters and that no
gap is inserted.

The third case deals with the insertion of a gap
in the manuscript (possible if y is strictly positive,
lines 24-37). Then the cost is increased by one for
the ﬁrst gap in the word (line 28), by one for the
ﬁrst gap of a sequence of gaps (line 32), and by
one since a gap is inserted.

The fourth case deals with the alignment of two
different letters and increases the cost by one since
aligning two different letters costs one and no gap
is inserted (lines 38-45).

The pseudo code for the search algorithm is:
bool search (g, y, x, gapAlreadySeen,

gapInMat,
previousIsGapInMat,
previousIsGapInPad)

if y=0 and x=0

return true

if g + h(y,x) > threshold

return false

if position already searched with smaller g

return false

newSeen = gapAlreadySeen
newSeenMat = gapInMat

if x > 0

deltag = 0
if not previousIsGapInPad

// cost of a sequence of gaps

1

2

3
4

5
6

7
8

9
10

11
12
13

// in the Padapatha
deltag = deltag + 1

if search (g+deltag+1, y, x-1,

true, gapInMat, false, true)

return true

if y > 0 and x > 0

if alignment of the same letters

if new word in the Padapatha

newSeen = false
newSeenMat = false

if search (g, y-1 , x-1, newSeen,
newSeenMat, false, false)

return true

if y > 0

deltag = 0;
if not gapInMat

// cost of each word containing
// gaps in the Matrikapatha
deltag = 1
newSeenMat = true

if not previousIsGapInMat

// cost of a sequence of gaps in
// the Matrikapatha
deltag = deltag + 1

if new word in the Padapatha

newSeen = false;
newSeenMat = false;

if search (g+deltag+1, y-1, x,

newSeen, newSeenMat, true, false)
return true;

if y>0 and x>0

if alignment of different letters

if new word in the Padapatha

newSeen = false
newSeenMat = false

if search (g+1, y-1 , x-1, newSeen,
newSeenMat, false, false)

return true

return false

14
15

16

17
18
19
20
21
22

23

24
25
26
27

28
29
30
31

32
33
34
35
36

37

38
39
40
41
42
43

44

45

The search function is bounded by a threshold
on the cost of the path. In order to ﬁnd the shortest
path, an iterative loop progressively increasing the
cost is used.

7 Experiments and Conclusions
We have tested on our Sanskrit texts three differ-
ent methods to align them: one based upon the
L.C.S., the two other ones based on the edit dis-
tance. We have tested them on a set of 43 different
manuscripts of a short text, the introduction of the
k¯a´sik¯avr. tti: the praty¯ah¯aras¯utrah. . A critical edi-
tion of this text exists (Bhate et al., 2009), and we
have not seen obvious differences with our results.
The size of the padap¯at.ha related to this text is
approximately 9500 characters. The time needed
for the treatment is approximately 29 seconds for
the L.C.S based one, 22 for the second method
(with the shifts) and 185 seconds for the third one
based on the IDA*algorithm (all mesured on a
Pentium 4 (3.2mgz)).

The comparison between the ﬁrst method and

212

the two others cannot be absolute, because the
ﬁrst one displays its results under a more syn-
thetic form, and cannot display only the align-
ments. This form takes a little more time to be
proceeded but less time to be written.
Comparing the different methods:

• The ﬁrst trial (L.C.S.) was a very useful
one, because it allows displaying signiﬁcant
results to Sanskrit philologists, and opens
the possibility of further research. But it
is too complicated compared with other ap-
proaches, and the different steps needed,
though useful, do not provide the opportunity
to make easily further improvements.

• The second approach gives the best results in
term of time. It is conceptually quite simple,
and not too difﬁcult to implement in term of
programming. And it gives place, because
it has been simple to implement, for further
improvements.

• What can we say then about

the IDA*
method, which is by far the longest to make
the computation? That it is unmistakably not
the best choice as a production method when
computation time is a preoccupation (but the
time overhead has nothing deﬁnitive), but it
is for sure, for the person ”who knows” the
most ﬂexible, and the easiest way to imple-
ment alignment methods, and to check an
hypothesis. Using A* would probabbly be
faster as the branching factor is small.

The use of edit distance based methods has
been, by the simpliﬁcations and the ameliorations
it provide for the comparison of the Sanskrit text
a great improvement. Both methods will allow
us to consider different coefﬁcients for replacing
the letters in the edit distance matrix and leads to
further simpliﬁcation of the pre-processing. The
IDA* (or other A*) method, opens wide the doors
for further experiments. Among these experi-
ments one of the most interesting will consist in
the modelling of an interaction between the infor-
mation provided by the annotations contained in
each manuscript (especially the presence of miss-
ing parts of the text) and the alignment.

It is difﬁcult to provide a numerical evaluation
of the different results, ﬁrst because they are not
provided under the same form, the ﬁrst method
is provided as a human readable text and the two
other ones as sequence alignments, secondly be-
cause it is difﬁcult (and we did not ﬁnd it) to
provide a criterion which differs from the func-
tion we optimize in the A* algorithm. Otherwise
even if the differences between the two methods
are rather tiny, the A* algorithm which optimizes
by construction the criterion will be considered al-
ways as slightly better.

Another possible improvement is related to the
fact that in Sanskrit, the order of the words is not
necessary meaningful. Two sentences with the
words appearing in two different orders can have
the same meaning.

But there is a problem that none of these meth-
ods can solve, the problem induced by the absence
of a word which has been used to build a sandhi.
Once it disappeared the sandhi disappeared too,
and a new sandhi can appear, then it looks like
a real change of the text, but these modiﬁcations
are perfectly justiﬁed in term of Sanskrit grammar
and should not be notiﬁed in the critical edition.
For example if we look at the following sequence:

"s aa s t r a
p r a v .r t t y a r th a .h
"s aa s t r aa - - - - - - - - - r th a .h

• the word "saastra has been changed in

"saastraa (with a long a at the end).

• the word prav.rtty has disappeared.
• the word artha.h has been changed to

rtha.h

is valid.

In fact only the second point
If
we put the words "saastra and artha.h
one after another in a Sanskrit
text we get
"saastraartha.h. The two short a at the
junction of the two words become a long aa (in
bold) because of a sandhi rule. We have (until
now) no precise idea on the way to solve this kind
of problem, but we have the deep feeling that the
answer will not be straightforward.

On the other hand we believe that the problems
induced by the comparison of Sanskrit texts for

213

Renou, Louis.
phon´etique,
le verbe,
(r´eimpression).

1996.

composition, d´erivation,

Grammaire sanskrite:
le nom,
Maisonneuve, Paris.

la phrase.

Velthuis, F., 1991.

sion 1.2, User Manual.
archive/language/devanagari/velthuis/.

Devan¯agar¯ı

for TEX, Ver-
http://www.ctan.org/tex-

the construction of a critical edition, is an inter-
esting family of problems. We hope that the so-
lutions of these problems can be applied to other
languages, and perhaps that it will also beneﬁt to
some other problems.

References
Bhate, Saroja, Pascale Haag, and Vincenzo Ver-
giani. 2009. The critical edition.
In Haag, Pas-
cale and Vincenzo Vergiani, editors, Studies in the
k¯a´sik¯avr. tti The section on Praty¯ah¯aras. Societa Ed-
itrice Fiorentina.

Csernel, Marc and Franc¸ois Patte. 2009. Critical edi-
tion of sanskrit texts.
In Sanskrit Computational
Linguistics, volume 5402 of Lecture Notes in Com-
puter Science, pages 358–379.

Hart, P., N. Nilsson, and B. Raphael. 1968. A for-
mal basis for the heuristic determination of mini-
mum cost paths. IEEE Trans. Syst. Sci. Cybernet.,
4(2):100–107.

Hirschberg, D.S.

1975. A linear space algorithm
for computing maximal common subsequences.
CACM, 18(6):341–343.

Huet, Gerard. 2004. Design of a lexical database for
sanskrit. In COLING Workshop on Electronic Dic-
tionaries, pages 8–14, Geneva.

Huet, Gerard. 2006. H´eritage du sanskrit: Diction-

naire franc¸ais-sanskrit.
http://sanskrit.inria.fr/Dico.pd.

Ikeda, T. and T. Imai. 1994. Fast A* algorithms for
multiple sequence alignment. In Genome Informat-
ics Workshop 94, pages 90–99.

Korf, R. E. 1985. Depth-ﬁrst iterative-deepening:
an optimal admissible tree search. Artiﬁcial Intel-
ligence, 27(1):97–109.

Monroy, C. et al. 2002. Visualization of variants in
textual collations to analyse the evolution of literary
works in the cervantes project.
In Proceedings of
the 6th European Conference, ECDL 2002, pages
638–53, Rome, Italy.

Myers, E.W. 1986. An O(ND) difference algorithm

and its variations. Algorithmica, 1(2):251–266.

O’Hara, R.J. Robinson, P.M.W. 1993. Computer-
assisted methods of stemmatic analysis. In Blake,
Norman and Peter Robinson, editors, Occasional
Papers of the Canterbury Tales Project, volume 1,
pages 53–74. Ofﬁce for Humanities Communica-
tion, Oxford University.

