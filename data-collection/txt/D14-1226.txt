



















































Summarizing Online Forum Discussions -- Can Dialog Acts of Individual Messages Help?


Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2127–2131,
October 25-29, 2014, Doha, Qatar. c©2014 Association for Computational Linguistics

Summarizing Online Forum Discussions – Can Dialog Acts of Individual
Messages Help?

Sumit Bhatia1, Prakhar Biyani2 and Prasenjit Mitra2
1IBM Almaden Research Centre, 650 Harry Road, San Jose, CA 95123, USA

2Information Science and Technology, Pennsylvania State University, University Park, PA 16802
sumit.bhatia@us.ibm.com, {pxb5080, pmitra}@ist.psu.edu

Abstract

A typical discussion thread in an online fo-
rum spans multiple pages involving par-
ticipation from multiple users and thus,
may contain multiple view-points and so-
lutions. A user interested in the topic of
discussion or having a problem similar to
being discussed in the thread may not want
to read all the previous posts but only a few
selected posts that provide her a concise
summary of the ongoing discussion. This
paper describes an extractive summariza-
tion technique that uses textual features
and dialog act information of individual
messages to select a subset of posts. Pro-
posed approach is evaluated using two real
life forum datasets.

1 Introduction

In recent times, online discussion boards (or fo-
rums) have become quite popular as they provide
an easily accessible platform to users in different
parts of the world to come together, share informa-
tion and discuss issues of common interest. The
archives of web forums contain millions of discus-
sion threads and act as a valuable repository of hu-
man generated information that can be utilized for
various applications. Oftentimes, the discussions
in a thread span multiple pages involving partici-
pation from multiple users and thus, may contain
multiple view-points and solutions. In such a case,
the end-user may prefer a concise summary of the
ongoing discussion to save time. Further, such a
summary helps the user to understand the back-
ground of the whole discussion as well as provides
an overview of different view-points in a time ef-
ficient manner. In addition to generic forums on
the web, automatic forum summarization methods
can prove to be useful for various domain specific
applications, such as helping students and support-

ing tutors in virtual learning environments (Car-
bonaro, 2010).

A typical discussion thread in a web forum con-
sists of a number of individual posts or messages
posted by different participating users. Often, the
thread initiator posts a question to which other
users reply, leading to an active discussion. As
an example, consider the discussion thread shown
in Figure 1 where the thread starter describes his
problem about the missing headphone switch in
his Linux installation. In the third post in the
thread, some other user asks about some clarifying
details and in the next post the topic starter pro-
vides the requested details that makes the problem
clearer. On receiving additional details about the
problem, some other user provides a possible so-
lution to the problem (fifth post). The topic starter
tries the suggested solution and reports his experi-
ence in the next post (sixth post). Thus, we see that
each individual post in a discussion thread serves
a different purpose in the discussion and we posit
that identifying the purpose of each such post is
essential for creating effective summaries of the
discussions. Intuitively, the most important mes-
sages in a discussion are the ones that describe the
problem being discussed and the solutions being
proposed to solve the problem.

The role of an individual message in a discus-
sion is typically specified in terms of dialog acts.
There have been efforts to automatically assign
dialog acts to messages in online forum discus-
sions (Jeong et al., 2009; Joty et al., 2011; Bhatia
et al., 2012) and also using dialog acts for linguis-
tic analysis of forum data, such as in subjectiv-
ity analysis of forum threads (Biyani et al., 2012;
Biyani et al., 2014). In this paper, we describe our
initial efforts towards addressing the problem of
automatically creating summaries of such online
discussion threads. We frame forum summariza-
tion as a classification problem and identify mes-
sages that should be included in a summary of the

2127



discussion. In addition to textual features, we em-
ploy dialog act labels of individual messages for
summarization and show that incorporating dialog
acts leads to substantial improvements in summa-
rization performance.

Figure 1: An example thread illustrating different
role played by each post in the discussion. Differ-
ent users are indicated by different colors.

2 Definition of Dialog Acts Used

We use the same set of dialog acts as defined by
Bhatia et al. (2012). Note that based on the appli-
cation context and requirements new dialog acts
can be defined and added.
1. Question: The poster asks a question which
initiates discussion in the thread. This is usually
the first post in the thread but not always. Often,
the topic initiator or some other user may ask other
related questions in the thread.
2. Repeat Question: Some user repeats a previ-
ously asked question (e.g. Me too having the same
problem.).
3. Clarification: The poster asks clarifying ques-
tions in order to gather more details about the
problem or question being asked. For example,
Could you provide more details about the issue
you are facing.

4. Further Details: The poster provides more de-
tails about the problem as asked by other fellow
posters.
5. Solution: The poster suggests a solution to the
problem being discussed in the thread.
6. Positive Feedback: Somebody tries the sug-
gested solution and provides a positive feedback if
the solution worked.
7. Negative Feedback: Somebody tries the sug-
gested solution and provides a negative feedback
if the solution did not work.
8. Junk: There is no useful information in the
post. For example, someone justs posts a smiley
or some comments that is not useful to topic being
discussed. For example, “bump”, “sigh”, etc., or
messages posted by forum moderators such as this
thread is being closed for discussion.

3 Proposed Approach for Thread
Summarization

In general, text summarization techniques can
be classified into two categories, namely extrac-
tive Summarization, and Abstractive Summariza-
tion (Hahn and Mani, 2000). Extractive summa-
rization involves extracting salient units of text
(e.g., sentences) from the document and then con-
catenating them to form a shorter version of the
document. Abstractive summarization, on the
other hand, involves generating new sentences by
utilizing the information extracted from the doc-
ument corpus (Carenini and Cheung, 2008), and
often involves advanced natural language process-
ing tools such as parsers, lexicons and grammars,
and domain-specific knowledge bases (Hahn and
Mani, 2000). Owing to their simplicity and good
performance, extractive summarization techniques
are often the preferred tools of choice for various
summarization tasks (Liu and Liu, 2009) and we
also adopt an extractive approach for discussion
summarization in this work.

3.1 Summarization Unit – Individual
Sentence vs Individual Message

Before we can perform extractive summarization
on discussion threads, we need to define an ap-
propriate text unit that will be used to construct
the desired summaries. For typical summariza-
tion tasks, a sentence is usually treated as a unit of
text and summaries are constructed by extracting
most relevant sentences from a document. How-
ever, a typical discussion thread is different from

2128



a generic document in that the text of a discus-
sion thread is created by multiple authors (users
participating in the thread). Further, the text of
a discussion can be divided into individual user
messages, each message serving a specific role
in the whole discussion. In that sense, summa-
rizing a discussion thread is similar to the task
of multi-document summarization where content
of multiple documents that are topically related is
summarized simultaneously to construct an inclu-
sive, coherent summary. However, we also note
that an individual user message in a discussion is
much smaller than a stand-alone document (com-
pare 3 ∼ 4 sentences in a message to a few dozen
sentences in a document). Thus, the sentences in a
message are much more coherent and contextually
related to each other than in a stand-alone docu-
ment. Hence, selecting just a few sentences from a
message may lead to loss of context and make the
resulting summaries hard to comprehend. There-
fore, in this work, we choose each individual mes-
sage as a text unit and thus, the thread summaries
are created by extracting most relevant posts from
a discussion.

3.2 Framing Thread Summarization as Post
Classification

We consider the problem of extracting relevant
posts from a discussion thread as a binary classifi-
cation problem where the task is to classify a given
post as either belonging to the summary or not.
We perform classification in a supervised fashion
by employing following features.
1. Similarity with Title (TitleSim): This feature
is computed as the cosine similarity score between
the post and the title of the thread.
2. Length of Post (Length): The number of
unique words in the post.
3. Post Position (Position): The normalized po-
sition of the post in the discussion thread. It is
defined as follows:

Position of the post in the thread
Total # of posts in the thread

(1)

4. Centroid Similarity (Centroid): This fea-
ture is obtained by computing the cosine similarity
score between the post document vector and the
vector obtained as the centroid of all the post vec-
tors of the thread. Similarity with centroid mea-
sures the relatedness of each post with the under-
lying discussion topic. A post with a higher sim-
ilarity score with the thread centroid vector indi-

cates that the post better represents the basic ideas
of the thread.
5. Inter Post Similarity: This feature is com-
puted by taking the mean of the post’s cosine sim-
ilarity scores with all the other posts in the thread.
6. Dialog Act Label (Class): This is a set of bi-
nary features indicating the dialog act class label
of the post. We have one binary feature corre-
sponding to each dialog act.

4 Experimental Evaluation

4.1 Data Description

We used the dataset used by Bhatia et al. (2012)
that consists of randomly sampled 100 threads
from two different online discussion forums
– ubuntuforums.org and tripadvisor.
com. There are a total of 556 posts in the 100
threads from Ubuntu dataset and 916 posts in 100
threads from NYC dataset. The associated dialog
act labels of individual messages in each of the
threads are also available.

Next, for creating data for the summarization
task, two independent human evaluators (H1 and
H2) were recruited to create summaries of the
discussion threads in the two datasets. For each
thread, the evaluators were asked to read the whole
discussion and write a summary of the discussion
in their own words. The annotators were requested
to keep the length of summaries roughly between
10% and 25% of the original text length. Thus for
each thread, we obtain two human written sum-
maries.

These hand-written summaries were then used
to identify most relevant posts in a discussion
thread in a manner similar to one used by Ram-
bow et al. (2004). We compute cosine similarity
scores for each post in the thread with the corre-
sponding thread summary and the top k ranked
posts are then selected to be part of the sum-
mary of the thread. The number k is deter-
mined by the compression factor used for creat-
ing summaries. We choose a compression fac-
tor of 20%. The top k ranked posts, thus consti-
tute the gold summary of each thread. Note that
we obtain two gold summaries for each thread –
one corresponding to each evaluator. This sum-
marization data can be downloaded for research
purposes from http://sumitbhatia.net/
source/datasets.html.

2129



Evaluator Method Ubuntu NYCPrecision F-1 Precision F-1

Baseline 0.39 0.53 0.32 0.46

H1

Without Dialog Acts 0.578 0.536 0.739 0.607
With Dialog Acts 0.620 0.608 0.760 0.655

Gain +7.27% +13.43% +2.84% +7.91%

Baseline 0.38 0.52 0.31 0.45

H2

Without Dialog Acts 0.739 0.607 0.588 0.561
With Dialog Acts 0.760 0.655 0.652 0.588

Gain +14.94% +20.53% +10.88% +4.81%

Table 1: Results of post classification for summarization task. H1 and H2 correspond to the two hu-
man evaluators. Percentage improvements obtained by addition of post class label information is also
reported.

4.2 Baseline

As a baseline method, we use a rule based clas-
sifier that classifies all the Question and Solution
posts in a thread as belonging to the summary and
discards the remaining posts.

4.3 Results and Discussions

We used Naive Bayes classifier as implemented
in the Weka machine learning toolkit (Hall et al.,
2009) for classification experiments. We trained
the classifier on 75% of the data and used the re-
maining 25% for testing. Table 1 reports the clas-
sification results using (i) the baseline method,(ii)
features 1–5 only, and (iii) using all the features
(dialog act labels, in addition to the five features).
For both the datasets, we observe that incorpo-
rating dialog act information along with textual
features results in performance gain across all re-
ported metrics. The strong performance improve-
ments achieved for the two datasets corroborate
the proposed hypothesis that knowing the role
of each individual message in an online discus-
sion can help create better summaries of discus-
sion threads. Further, we observe that the preci-
sion values are very low for the baseline algorithm
(from 0.31 to 0.39) with moderate F-1 values (0.45
to 0.53), indicating a higher recall. This means
that even though many of the posts in the gold
summaries belong to question and solution cate-
gories, not all the posts belonging to these two cat-
egories are useful for summarization. Using tex-
tual features and dialog act labels in a supervised
machine learning framework captures the distin-
guishing characteristics of in-summary and out of
summary posts and thus, yields a much better clas-
sification performance.

5 Related Work

Among various applications of text summariza-
tion, work on E-Mail thread summarization (Ram-
bow et al., 2004; Cohen et al., 2004) can be con-
sidered as closely related to the problem discussed
in this paper. An E-Mail thread is similar to a fo-
rum discussion thread in that it involves back and
forth communication with the participants, how-
ever, the problem of discussion thread summariza-
tion is very different (and difficult) due to a rela-
tively larger number of participants, highly infor-
mal and noisy language, and frequent topic drifts
in discussions. Zhou and Hovy (2005) identify
clusters in internet relay chats (irc) and then em-
ploy lexical and structural features to summarize
each cluster. Ren et al. (2011) have proposed a fo-
rum summarization algorithm that models the re-
ply structures in a discussion thread.

6 Conclusions and Future Work

We proposed that dialog act labels of individual
messages in an online forums can be helpful in
summarizing discussion threads. We framed dis-
cussion thread summarization as a binary clas-
sification problem and tested our hypothesis on
two different datasets. We found that for both
the datasets, incorporating dialog act information
as features improves classification performance as
measured in terms of precision and F-1 measure.
As future work, we plan to explore various other
forum specific features such as user reputation and
quality of content to improve summarization per-
formance.

2130



References
Sumit Bhatia, Prakhar Biyani, and Prasenjit Mitra.

2012. Classifying user messages for managing web
forum data. In Proceedings of the 15th International
Workshop on the Web and Databases 2012, WebDB
2012, Scottsdale, AZ, USA, May 20, 2012, pages 13–
18.

Prakhar Biyani, Sumit Bhatia, Cornelia Caragea, and
Prasenjit Mitra. 2012. Thread specific features are
helpful for identifying subjectivity orientation of on-
line forum threads. In COLING 2012, 24th Inter-
national Conference on Computational Linguistics,
Proceedings of the Conference: Technical Papers, 8-
15 December 2012, Mumbai, India, pages 295–310.

Prakhar Biyani, Sumit Bhatia, Cornelia Caragea,
and Prasenjit Mitra. 2014. Using non-
lexical features for identifying factual and
opinionative threads in online forums.
Knowledge-Based Systems, In Press, doi =
http://dx.doi.org/10.1016/j.knosys.2014.04.048.

Antonella Carbonaro. 2010. Towards an automatic
forum summarization to support tutoring. In Mil-
tiadisD. Lytras, Patricia Ordonez De Pablos, David
Avison, Janice Sipior, Qun Jin, Walter Leal, Lorna
Uden, Michael Thomas, Sara Cervai, and David
Horner, editors, Technology Enhanced Learning.
Quality of Teaching and Educational Reform, vol-
ume 73 of Communications in Computer and In-
formation Science, pages 141–147. Springer Berlin
Heidelberg.

Giuseppe Carenini and Jackie Chi Kit Cheung. 2008.
Extractive vs. nlg-based abstractive summarization
of evaluative text: The effect of corpus controver-
siality. In Proceedings of the Fifth International
Natural Language Generation Conference, pages
33–41. Association for Computational Linguistics.

William W. Cohen, Vitor R. Carvalho, and Tom M.
Mitchell. 2004. Learning to Classify Email into
“Speech Acts”. In EMNLP, pages 309–316. ACL.

Udo Hahn and Inderjeet Mani. 2000. The challenges
of automatic summarization. Computer, 33(11):29–
36.

Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA Data Mining Software: An Up-
date. SIGKDD Explorations, 11(1).

Minwoo Jeong, Chin-Yew Lin, and Gary Geunbae Lee.
2009. Semi-supervised speech act recognition in
emails and forums. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing: Volume 3 - Volume 3, EMNLP
’09, pages 1250–1259.

Shafiq R. Joty, Giuseppe Carenini, and Chin-Yew Lin.
2011. Unsupervised modeling of dialog acts in
asynchronous conversations. In IJCAI, pages 1807–
1813. IJCAI/AAAI.

Fei Liu and Yang Liu. 2009. From extractive to ab-
stractive meeting summaries: can it be done by sen-
tence compression? In Proceedings of the ACL-
IJCNLP 2009 Conference Short Papers, pages 261–
264. Association for Computational Linguistics.

O. Rambow, L. Shrestha, J. Chen, and C. Laurdisen.
2004. Summarizing email threads. Proceedings of
HLT-NAACL 2004: Short Papers.

Zhaochun Ren, Jun Ma, Shuaiqiang Wang, and Yang
Liu. 2011. Summarizing web forum threads based
on a latent topic propagation process. In Proceed-
ings of the 20th ACM International Conference on
Information and Knowledge Management, CIKM
’11, pages 879–884, New York, NY, USA. ACM.

Liang Zhou and Eduard Hovy. 2005. Digesting vir-
tual ”geek” culture: The summarization of technical
internet relay chats. In Proceedings of the 43rd An-
nual Meeting on Association for Computational Lin-
guistics, ACL ’05, pages 298–305, Stroudsburg, PA,
USA. Association for Computational Linguistics.

2131


