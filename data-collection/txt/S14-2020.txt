



















































Blinov: Distributed Representations of Words for Aspect-Based Sentiment Analysis at SemEval 2014


Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 140–144,
Dublin, Ireland, August 23-24, 2014.

Blinov: Distributed Representations of Words for  

Aspect-Based Sentiment Analysis at SemEval 2014 

 

 

Pavel Blinov, Eugeny Kotelnikov 

Vyatka State Humanities University 

{blinoff.pavel, kotelnikov.ev}@gmail.com 

 

  

 

Abstract 

The article describes our system 

submitted to the SemEval-2014 task 

on Aspect-Based Sentiment Analy-

sis. The methods based on distribut-

ed representations of words for the 

aspect term extraction and aspect 

term polarity detection tasks are pre-

sented. The methods for the aspect 

category detection and category po-

larity detection tasks are presented 

as well. Well-known skip-gram 

model for constructing the distribut-

ed representations is briefly de-

scribed. The results of our methods 

are shown in comparison with the 

baseline and the best result. 

1 Introduction 

The sentiment analysis became an important 

Natural Language Processing (NLP) task in the 

recent few years. As many NLP tasks it’s a chal-

lenging one. The sentiment analysis can be very 

helpful for some practical applications. For ex-

ample, it allows to study the users’ opinions 

about a product automatically. 

Many research has been devoted to the general 

sentiment analysis (Pang et al., 2002), 

(Amine et al., 2013), (Blinov et al., 2013) or 

analysis of individual sentences (Yu and Hatzi-

vassiloglou, 2003), (Kim and Hovy, 2004), 

(Wiebe and Riloff, 2005). Soon it became clear 

that the sentiment analysis on the level of a 

whole text or even sentences is too coarse. Gen-

eral sentiment analysis by its design is not capa-

ble to perform the detailed analysis of an ex-

pressed opinion. For example, it cannot correctly 

detect the opinion in the sentence “Great food 

but the service was dreadful!”. The sentence car-

ries opposite opinions on two facets of a restau-

rant. Therefore the more detailed version of the 

sentiment analysis is needed. Such a version is 

called the aspect-based sentiment analysis and it 

works on the level of the significant aspects of 

the target entity (Liu, 2012). 

The aspect-based sentiment analysis includes 

two main subtasks: the aspect term extraction 

and its polarity detection (Liu, 2012). In this arti-

cle we describe the methods which address both 

subtasks. The methods are based on the distribut-

ed representations of words. Such word represen-

tations (or word embeddings) are useful in many 

NLP task, e.g. (Turian et al., 2009), (Al-

Rfou’ et al., 2013), (Turney, 2013). 

The remainder of the article is as follows: sec-

tion two gives the overview of the data; the third 

section shortly describes the distributed represen-

tations of words. The methods of the aspect term 

extraction and polarity detection are presented in 

the fourth and the fifth sections respectively. The 

conclusions are given in the sixth section. 

2 The Data 

The organisers provided the train data for restau-

rant and laptop domains. But as it will be clear 

further our methods are heavily dependent on 

unlabelled text data. So we additionally collected 

the user reviews about restaurants from tripad-

viser.com and about laptops from amazon.com. 

General statistics of the data are shown in Ta-

ble 1. 

 

 

 

 

This work is licensed under a Creative Commons At-

tribution 4.0 International Licence. Page numbers and pro-

ceedings footer are added by the organisers. Licence details: 

http://creativecommons.org/licenses/by/4.0/ 

140



Table 1: The amount of reviews. 

Domain The amount of reviews 

Restaurants 652 055 

Laptops 109 550 

 

For all the data we performed tokenization, 

stemming and morphological analysis using the 

FreeLing library (Padró and Stanilovsky, 2012). 

3 Distributed Representations of Words 

In this section we’ll try to give the high level 

idea of the distributed representations of words. 

The more technical details can be found in 

(Mikolov et al., 2013). 

It is closely related with a new promising di-

rection in machine learning called the deep learn-

ing. The core idea of the unsupervised deep 

learning algorithms is to find automatically the 

“good” set of features to represent the target ob-

ject (text, image, audio signal, etc.). The object 

represented by the vector of real numbers is 

called the distributed representation (Ru-

melhart et al., 1986). We used the skip-gram 

model (Mikolov et al., 2013) implemented in 

Gensim toolkit (Řehůřek and Sojka, 2010). 

In general the learning procedure is as follows. 

All the texts of the corpus are stuck together in a 

single sequence of sentences. On the basis of the 

corpus the lexicon is constructed. Next, the di-

mensionality of the vectors is chosen (we used 

300 in our experiments). The greater number of 

dimensions allows to capture more language reg-

ularities but leads to more computational com-

plexity of the learning. Each word from the lexi-

con is associated with the real numbers vector of 

the selected dimensionality. Originally all the 

vectors are randomly initialized. During the 

learning procedure the algorithm “slides” with 

the fixed size window (it’s algorithm parameter 

that was retained by default – 5 words) along the 

words of the sequence and calculates the proba-

bility (1) of context words appearance within the 

window based on its central word under review 

(or more precisely, its vector representation) 

(Mikolov et al., 2013). 

  




W

w w

T

w

w

T

w

IO
vv

vv
wwp IO

1
)exp(

)exp(
)|(

, 
(1) 

where 
w

v  and 
w

v  are the input and output vector 

representations of w; 
I

w  and 
O

w  are the current 

and predicted words, W  – the number of words 

in vocabulary. 

The ultimate goal of the described process is 

to get such “good” vectors for each word, which 

allow to predict its probable context. All such 

vectors together form the vector space where 

semantically similar words are grouped. 

4 Aspect Term Extraction Method 

We apply the same method for the aspect term 

extraction task (Pontiki et al., 2014) for both do-

mains. The method consists of two steps: the 

candidate selection and the term extraction. 

4.1 Candidate Selection 

First of all we collect some statistics about the 

terms in the train collection. We analysed two 

facets of the aspect terms: the number of words 

and their morphological structure. The infor-

mation about the number of words in a term is 

shown in Table 2. 

 

Table 2: The statistics for the number of words 

in a term. 

Aspect term 

Domain 

Restaurant, % Laptop, % 

One-word 72.13 55.66 

Two-word 19.05 32.87 

Greater 8.82 11.47 

 

On the basis of that we’ve decided to process 

only single and two-word aspect terms. From the 

single terms we treat only singular (NN, e.g. 

staff, rice, texture, processor, ram, insult) and 

plural nouns (NNS, e.g. perks, bagels, times, 

dvds, buttons, pictures) as possible candidates, 

because they largely predominate among the 

one-word terms. All conjunctions of the form 

NN_NN (e.g. sea_bass, lotus_leaf, chicken_dish, 

battery_life, virus_protection, custom-

er_disservice) and NN_NNS (e.g. sushi_places, 

menu_choices, seafood_lovers, usb_devices, re-

covery_discs, software_works) were candidates 

for the two-word terms also because they are 

most common in two-word aspect terms. 

4.2 Term Extraction 

The second step for the aspect term identification 

is the term extraction. As has already been told 

the space (see Section 3) specifies the word 

groups. Therefore the measure of similarity be-

tween the words (vectors) can be defined. For 

NLP tasks it is often the cosine similarity meas-

ure. The similarity between two vectors 

),...,(
1 n

aaa 


 and ),...,( 1 nbbb 


 is given by 

(Manning et al., 2008): 

141














n

i i

n

i i

n

i ii

ba

ba

1

2

1

2

1)cos( , (2) 

where   – the angle between the vectors, n – the 
dimensionality of the space. 

In case of the restaurant domain the category 

and aspect terms are specified. For each category 

the seed of the aspect terms can be automatically 

selected: if only one category is assigned for a 

train sentence then all its terms belong to it. 

Within each set the average similarity between 

the terms (the threshold category) can be found. 

For the new candidate the average similarities 

with the category’s seeds are calculated. If it is 

greater than the threshold of any category than 

the candidate is marked as an aspect term. 

Also we’ve additionally applied some rules: 

 Join consecutive terms in a single term. 

 Join neutral adjective ahead the term (see 
Section 5.2 for clarification about the neu-

tral adjective). 

 Join fragments matching the pattern: <an 
aspect term> of <an aspect term>. 

In case of the laptop domain there are no spec-

ified categories so we treated all terms as the 

terms belonging to one general category. And the 

same procedure with candidates was performed. 

4.3 Category Detection 

For the restaurant domain there was also the as-

pect category detection task (Ponti-

ki et al., 2014). 

Since each word is represented by a vector, 

each sentence can be cast to a single point as the 

average of its vectors. Further average point for 

each category can be found by means of the sen-

tence points. Then for an unseen sentence the 

average point of its word vectors is calculated. 

The category is selected by calculating the dis-

tances between all category points and a new 

point and by choosing the minimum distance. 

4.4 Results 

The aspect term extraction and the aspect catego-

ry detection tasks were evaluated with Precision, 

Recall and F-measure (Pontiki et al., 2014). The 

F-measure was a primary metric for these tasks 

so we present only it. 

The result of our method ranked 19 out of 28 

submissions (constrained and unconstrained) for 

the aspect term extraction task for the laptop do-

main and 17 out of 29 for the restaurant domain. 

For the category detection task (restaurant do-

main) the method ranked 9 out of 21. 

Table 3 shows the results of our method 

(Bold) for aspect term extraction task in compar-

ison with the baseline (Pontiki et al., 2014) and 

the best result. Analogically the results for the 

aspect category detection task are presented in 

Table 4. 

 

Table 3: Aspect term extraction results  

(F-measure). 

 Laptop Restaurant 

Best 0.7455 0.8401 

Blinov 0.5207 0.7121 

Baseline 0.3564 0.4715 

 

Table 4: Aspect category detection results 

(F-measure). 

 Restaurant 

Best 0.8858 

Blinov 0.7527 

Baseline 0.6389 

5 Polarity Detection Method 

Our polarity detection method also exploits the 

vector space (from Section 3) because the emo-

tional similarity between words can be traced in 

it. As with the aspect term extraction method we 

follow two-stage approach: the candidate selec-

tion and the polarity detection. 

5.1 Candidate Selection 

All adjectives and verbs are considered as the 

polarity term candidates. The amplifiers and the 

negations have an important role in the process 

of result polarity forming. In our method we took 

into account only negations because it strongly 

affects the word polarity. We’ve joined into one 

unit all text fragments that match the following 

pattern: not + <JJ | VB>. 

5.2 Term Polarity Detection 

At first we manually collected the small etalon 

sets of positive and negative words for each do-

main. Every set contained 15 words that clearly 

identify the sentiment. For example, for the posi-

tive polarity there were words such as: great, 

fast, attentive, yummy, etc. and for the negative 

polarity there were words like: terrible, ugly, 

not_work, offensive, etc. 

By measuring the average similarity for a can-

didate to the positive and the negative seed 

words we decided whether it is positive (+1) or 

negative (–1). Also we set up a neutral threshold 

and a candidate’s polarity was treated as neutral 

(0) if it didn’t exceed the threshold. 

142



For each term (within the window of 6 words) 

we were looking for its closest polarity term can-

didate and sum up their polarities. For the final 

decision about the term’s polarity there were 

some conditions: 

 If sum > 0 then positive. 

 If sum < 0 then negative. 

 If sum == 0 and all polarity terms are neu-
tral then neutral else conflict. 

5.3 Category Polarity Detection 

By analogy with the category detection method, 

using the train collection, we calculate the aver-

age polarity points for each category, i.e. there 

were 5×4 such points (5 categories and 4 values 

of polarity). Then a sentence was cast to a point 

as the average of all its word-vectors. And clos-

est polarity points for the specified categories 

defined the polarity. 

5.4 Results 

The results of our method (Bold) for the polarity 

detection tasks are around the baseline results for 

the Accuracy measure (Tables 5, 6). 

 

Table 5: Aspect term polarity detection results 

(Accuracy). 

 Laptop Restaurant 

Best 0.7049 0.8095 

Blinov 0.5229 0.6358 

Baseline 0.5107 0.6428 

 

Table 6: Category polarity detection results 

(Accuracy). 

 Restaurant 

Best 0.8293 

Blinov 0.6566 

Baseline 0.6566 

 

However the test data is skewed to the positive 

class and for that case the Accuracy is a poor 

indicator. Because of that we also show macro F-

measure results for our and baseline methods 

(Tables 7, 8). 

 

Table 7: Aspect term polarity detection results 

(F-measure). 

 Laptop Restaurant 

Blinov 0.3738 0.4334 

Baseline 0.2567 0.2989 

 

 

 

 

Table 8: Category polarity detection results 

(F-measure). 

 Restaurant 

Blinov 0.5051 

Baseline 0.3597 

 

From that we can conclude that our method of 

the polarity detection more delicately deals with 

the minor represented classes than the baseline 

method. 

6 Conclusion 

In the article we presented the methods for two 

main subtasks for aspect-based sentiment analy-

sis: the aspect term extraction and the polarity 

detection. The methods are based on the distrib-

uted representation of words and the notion of 

similarities between the words. 

For the aspect term extraction and category 

detection tasks we get satisfied results which are 

consistent with our cross-validation metrics. Un-

fortunately for the polarity detection tasks the 

result of our method by official metrics are low. 

But we showed that the proposed method is not 

so bad and is capable to deal with the skewed 

data better than the baseline method. 

Acknowledgments 

We would like to thank the organizers and the 

reviewers for their efforts. 

Reference 

Abdelmalek Amine, Reda Mohamed Hamou and 

Michel Simonet. 2013. Detecting Opinions in 

Tweets. International Journal of Data Mining and 

Emerging Technologies, 3(1):23–32. 

Christopher Manning, Prabhakar Raghavan and Hin-

rich Schütze. 2008. Introduction to Information Re-

trieval. Cambridge University Press, New York, 

NY, USA. 

Bo Pang, Lillian Lee and Shivakumar Vaithyanathan. 

2002. Thumbs up?: sentiment classification using 

machine learning techniques. In Proceedings of the 

Conference on Empirical Methods in Natural Lan-

guage Processing, pages 79–86. 

Bing Liu. 2012. Sentiment Analysis and Opinion 

Mining. Synthesis Lectures on Human Language 

Technologies. 

Pavel Blinov, Maria Klekovkina, Eugeny Kotelnikov 

and Oleg Pestov. 2013. Research of lexical ap-

proach and machine learning methods for senti-

ment analysis. Computational Linguistics and In-

tellectual Technologies, 2(12):48–58. 

143



Janyce Wiebe and Ellen Riloff. 2005. Creating sub-

jective and objective sentence classifiers from un-

annotated texts. In Proceedings of the 6th Interna-

tional Conference on Computational Linguistics 

and Intelligent Text Processing, pages 486–497. 

Joseph Turian, Lev Ratinov, Yoshua Bengio and Dan 

Roth. 2009. A preliminary evaluation of word rep-

resentations for named-entity recognition. In Pro-

ceedings of NIPS Workshop on Grammar Induc-

tion, Representation of Language and Language 

Learning. 

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-

rado and Jeffrey Dean. 2013. Distributed Represen-

tations of Words and Phrases and their Composi-

tionality. In Proceedings of NIPS, pages 3111–

3119. 

Lluís Padró and Evgeny Stanilovsky. 2012. FreeLing 

3.0: Towards Wider Multilinguality. In Proceed-

ings of the Language Resources and Evaluation 

Conference, LREC 2012, pages 2473–2479. 

Soo-Min Kim and Eduard Hovy. 2004. Determining 

the sentiment of opinions. In Proceedings of the 

20th International Conference on Computational 

Linguistics, COLING-2004. 

Maria Pontiki, Dimitrios Galanis, John Pavlopoulos, 

Harris Papageorgiou, Ion Androutsopoulos and 

Suresh Manandhar. 2014. SemEval-2014 Task 4: 

Aspect Based Sentiment Analysis. In Proceedings 

of the 8th International Workshop on Semantic 

Evaluation, SemEval 2014, Dublin, Ireland. 

Peter Turney. 2013. Distributional semantics beyond 

words: Supervised learning of analogy and para-

phrase. Transactions of the Association for Compu-

tational Linguistics, 1:353-366. 

Radim Řehůřek and Petr Sojka. 2010. Software 

Framework for Topic Modelling with Large Cor-

pora. In Proceedings of the LREC 2010 Workshop 

on New Challenges for NLP Frameworks, pages 

46–50. 

Rami Al-Rfou’, Bryan Perozzi, Steven Skiena. 2013. 

Polyglot: Distributed Word Representations for 

Multilingual NLP. In Proceedings of Conference 

on Computational Natural Language Learning, 

CoNLL’2013. 

David Rumelhart, Geoffrey Hintont, Ronald Wil-

liams. 1986. Learning representations by back-

propagating errors. Nature. 

Hong Yu and Vasileios Hatzivassiloglou. 2003. To-

wards answering opinion questions: Separating 

facts from opinions and identifying the polarity of 

opinion sentences. In Proceedings of the 2003 

Conference on Empirical Methods in Natural Lan-

guage Processing, pages 129–136. 

144


