










































Toward Plot Units: Automatic Affect State Analysis


Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 17–25,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

Toward Plot Units: Automatic Affect State Analysis

Amit Goyal and Ellen Riloff and Hal Daume III and Nathan Gilbert

School of Computing

University of Utah

Salt Lake City, UT 84112

{amitg,riloff,hal,ngilbert}@cs.utah.edu

Abstract

We present a system called AESOP that au-

tomatically produces affect states associated

with characters in a story. This research repre-

sents a first step toward the automatic genera-

tion of plot unit structures from text. AESOP

incorporates several existing sentiment analy-

sis tools and lexicons to evaluate the effective-

ness of current sentiment technology on this

task. AESOP also includes two novel compo-

nents: a method for acquiring patient polar-

ity verbs, which impart negative affect on their

patients, and affect projection rules to propa-

gate affect tags from surrounding words onto

the characters in the story. We evaluate AE-

SOP on a small collection of fables.

1 Introduction

In the 1980s, plot units (Lehnert, 1981) were pro-

posed as a knowledge structure for representing nar-

rative stories and generating summaries. Plot units

are fundamentally different from the story represen-

tations that preceded them because they focus on the

emotional states and tensions between characters as

the driving force behind interesting plots and cohe-

sive stories. Plot units were used in narrative sum-

marization studies, both in computer science and

psychology (Lehnert et al., 1981), but the compu-

tational models of plot units relied on tremendous

amounts of manual knowledge engineering.

Given the recent swell of activity in automated

methods for sentiment analysis, we embarked on a

project to see whether current techniques could auto-

matically detect the affect states needed for plot unit

analysis. Plot units are complex structures that in-

clude affect states, causal links, and cross-character

links, and generating complete plot unit structures is

beyond the scope of this work. As an initial step to-

ward the long-term goal of automatically generating

plot units, we began by creating a system to automat-

ically identify the affect states associated with char-

acters. An affect state represents the emotional state

of a character, based on their perspective of events

in the story. Plots units include three types of af-

fect states: positive (+) states, negative (-) states, and

mental (M) states that have neutral emotion (these

are often associated with plans and goals).

Our system, called AESOP, pulls together a va-

riety of existing technologies in sentiment analy-

sis to automatically identify words and phrases that

have positive/negative polarity or that correspond

to speech acts (for mental states). However, we

needed to develop a method to automatically map

these affect tags onto characters in the story.1 To

address this issue, we created affect projection rules

that propagate affect tags from words and phrases to

characters in the story via syntactic relations.

During the course of our research, we came to ap-

preciate that affect states, of the type required for

plot units, can represent much more than just di-

rect expressions of emotion. A common phenom-

ena are affect states that result from a character be-

ing acted upon in a positive or negative way. For

example, “the cat ate the mouse” produces a pos-

itive affect state for the cat and a negative affect

1This is somewhat analogous to, but not exactly the same as,

associating opinion words with their targets or topics (Kim and

Hovy, 2006; Stoyanov and Cardie, 2008).

17



The Father and His Sons

(s1) A father had a family of sons who were perpetually

quarreling among themselves. (s2) When he failed to

heal their disputes by his exhortations, he determined to

give them a practical illustration of the evils of disunion;

and for this purpose he one day told them to bring him a

bundle of sticks. (s3) When they had done so, he placed

the faggot into the hands of each of them in succession,

and ordered them to break it in pieces. (s4) They tried

with all their strength, and were not able to do it. (s5) He

next opened the faggot, took the sticks separately, one by

one, and again put them into his sons’ hands, upon which

they broke them easily. (s6) He then addressed them in

these words: “My sons, if you are of one mind, and unite

to assist each other, you will be as this faggot, uninjured

by all the attempts of your enemies; but if you are divided

among yourselves, you will be broken as easily as these

sticks.”

(a) “Father and Sons” Fable

Father Sons
(quarreling)a1

(stop quarreling)a3

(annoyed)a2

(exhortations)a4

(exhortations fail)a5

m

m

a

(teach lesson)a6
m

(get sticks & break)a7
m

(get sticks & break)a8

(cannot break sticks)a9
a

(cannot break sticks)a10

a

(bundle & break)a11
(bundle & break)a12

(break sticks)a13
a

(break sticks)a14

a

m

a

shared

request

request

shared

shared

s2

s2

s2

s2

s2

s2

s4

s5

s5

s1

s2

s4

s5

s5

(lesson succeeds)a15s5
(b) Plot Unit Analysis for “Father and Sons” Fable

state for the mouse because obtaining food is good

but being eaten is bad. This type of world knowl-

edge is difficult to obtain, yet essential for plot unit

analysis. In AESOP, we use corpus statistics to au-

tomatically learn a set of negative patient polarity

verbs which impart a negative polarity on their pa-

tient (e.g., eaten, killed, injured, fired). To acquire

these verbs, we queried a large corpus with patterns

to identify verbs that frequently occur with agents

who stereotypically have evil intent.

We evaulate our complete system on a set of AE-

SOP’s fables. In this paper, we also explain and cat-

egorize different types of situations that can produce

affect states, several of which cannot be automati-

cally recognized by existing sentiment analysis tech-

nology. We hope that one contribution of our work

will be to create a better awareness of, and apprecia-

tion for, the different types of language understand-

ing mechanisms that will ultimately be necessary for

comprehensive affect state analysis.

2 Overview of Plot Units

Narratives can often be understood in terms of the

emotional reactions and affect states of the char-

acters therein. The plot unit formalism (Lehnert,

1981) provides a representational mechanism for af-

fect states and the relationships between them. Plot

unit structures can be used for tasks such as narrative

summarization and question answering.

Plot unit structures consist of affect states for each

character in a narrative, and links explaining the re-

lationships between these affect states. The affect

states themselves each have a type: (+) for positive

states, (-) for negative states, and (M) for mental

states (with neutral affect). Although affect states

are not events per se, events often trigger affect

states. If an event affects multiple characters, it can

trigger multiple affect states, one for each character.

Affect states are further connected by causal links,

which explain how the narrative hangs together.

These include motivations (m), actualizations (a),

terminations (t) and equivalences (e). Causal links

exist between affect states for the same character.

Cross-character links explain how single events af-

fect two characters. For instance, if one character

requests something of the other, this is an M-to-M

link, since it spans a shared mental affect for both

characters. Other speech acts can be represented as

M to + (promise) or M to - (threat).

To get a better feeling of the plot unit represen-

tation, a short fable, “The Father and His Sons,” is

shown in Figure 1(a) and our annotation of its plot

unit structure is shown in Figure 1(b). In this fa-

ble, there are two characters (the “Father” and the

“Sons”) who go through a series of affect states, de-

picted chronologically in the two columns.

In this example, the first affect state is a negative

state for the sons, who are quarreling (a1). This state

is shared by the father (via a cross-character link)

who has a negative annoyance state (a2). The fa-

ther then decides that he wants to stop the sons from

quarreling, which is a mental event (a3). The causal

link from a2 to a3 with an m label indicates a “mo-

tivation.” His first attempt is by exhortations (a4).

18



This produces an M (a3) linked to an M (a4) with

a m (motivation) link, which represents subgoaling.

The father’s overall goal is to stop the quarreling

(a3) and in order to do so, he creates a subgoal of

exhorting the sons to stop (a4). The exhortations

fail, which produces a negative state (a5) for the fa-

ther. The a causal link indicates an “actualization”,

representing the failure of the plan (a4).

The failure of the father’s exhortations leads to a

new subgoal: to teach the sons a lesson (a6). The m

link from a5 to a6 is an example of “enablement.”

At a high level, this subgoal has two parts, indicated

by the two gray regions (a7 − a10 and a11 − a14).
The first gray region begins with a cross-character

link (M to M), which indicates a request (in this case,

to break a bundle of sticks). The sons fail at this,

which upsets them (a9) but pleases the father (a10).

The second gray region depicts the second part of

the father’s subgoal; he makes a second request (a11

to a12) to separate the bundle and break the sticks,

which the sons successfully do, making them happy

(a13) and the father happy (a14). This latter struc-

ture (the second gray region) is an HONORED RE-

QUEST plot unit. At the end, the father’s plan suc-

ceeds (a15) which is an actualization (a link) of his

goal to teach the sons a lesson (a6).

In this example, as well as the others that we an-

notated in our gold standard, (see Section 5.1), we

annotated conservatively. In particular, in reading

the story, we may assume that the father’s origi-

nal plan of stopping the son’s quarrelling also suc-

ceeded. However, this is not mentioned in the story

and therefore we chose not to represent it. It is also

important to note that plot unit representations can

have t (termination) and e (equivalence) links that

point backwards in time, but they do not occur in

the Father and Sons fable.

3 Where Do Affect States Come From?

We began this research with the hope that recent re-

search in sentiment analysis would supply us with

effective tools to recognize affect states. However,

we soon realized that affect states, as required for

plot unit analysis, go well beyond the notions of pos-

itive/negative polarity and private states that have

been studied in recent sentiment analysis work. In

this section, we explain the wide variety of situa-

tions that can produce an affect state, based on our

observations in working with fables. Most likely, an

even wider variety of situations could produce affect

states in other text genres.

3.1 Direct Expressions of Emotion

Plot units can include affect states that correspond to

explicit expressions of positive/negative emotional

states, as has been studied in the realm of sentiment

analysis. For example, “Max was disappointed”

produces a negative affect state for Max, and “Max

was pleased” produces a positive affect state for

Max. However, the affect must relate to an event that

occurs in the story’s plot. For example, a hypotheti-

cal expression of emotion would not yield an affect

state (e.g., “if the rain stops, she will be pleased”).

3.2 Situational Affect States

Positive and negative affect states also frequently

represent good and bad situational states that char-

acters find themselves in. These states do not rep-

resent emotion, but indicate whether a situation is

good or bad for a character based on world knowl-

edge. For example, “Wolf, who had a bone stuck

in his throat, ...” produces a negative affect state

for the wolf. Similarly, “The Old Woman recovered

her sight...” produces a positive affect state. Senti-

ment analysis is not sufficient to generate these af-

fect states. Sometimes, however, a direct expression

of emotion will also be present (e.g., “Wolf was un-

happy because he had a bone stuck...”), providing

redundancy and multiple opportunities to recognize

the correct affect state for a character.

Situational affect states are common and often

motivate plans and goals that are central to the plot.

3.3 Plans and Goals

Plans and goals are another common reason for

affect states. The existence of a plan or goal is

usually represented as a mental state (M). Plans and

goals can be difficult to detect automatically. A

story may reveal that a character has a plan or goal

in a variety of ways, such as:

Direct expressions of plans/goals: a plan or goal

may be explicitly stated (e.g., “the lion wanted to

find food”). In this case, a mental state (M) should

19



be generated.

Speech acts: a plan or goal may be revealed

through a speech act between characters. For

example, “the wolf asked an eagle to extract the

bone” is a directive speech act that indicates the

wolf’s plan to resolve its negative state (having a

bone stuck). This example illustrates how a negative

state (bone stuck) can motivate a mental state (plan).

When a speech act involves multiple characters, it

produces multiple mental states. For example, a

mental state should also be produced for the eagle,

because it now has a plan to help the wolf (by virtue

of being asked).

Inferred plans/goals: plans and goals sometimes

must be inferred from actions. For example, “the

lion hunted deer” reveals the lion’s plan to obtain

food. Similarly, the serpent spat poison into the

man’s water” implies that the serpent had a plan to

kill the man.

Plans and goals also produce positive/negative af-

fect states when they succeed/fail. For example, if

the eagle successfully extracts the bone from the

wolf’s throat, then both the wolf and the eagle will

have positive affect states, because both were suc-

cessful in their respective goals. A directive speech

act between two characters coupled with positive af-

fect states for both characters is a common plot unit

structure called an HONORED REQUEST, depicted

by the second gray block shown in Fig.1(b).

The affect state for a character is always with

respect to its view of the situation. For example,

consider: “The owl besought a grasshopper to

stop chirping. The grasshopper refused to desist,

and chirped louder and louder.” Both the owl and

the grasshopper have M affect states representing

the request from the owl to the grasshopper (i.e.,

the owl’s plan to stop the chirping is to ask the

grasshopper to knock it off). The grasshopper

refuses the request, so a negative affect state is

produced for the owl, indicating that its plan failed.

However, a positive affect state is produced for

the grasshopper, because its goal was to continue

chirping which was accomplished by refusing the

request. This scenario is also a common plot unit

structure called a DENIED REQUEST.

3.4 Patient Role Affect States

Many affect states come directly from events. In

particular, when a character is acted upon (the theme

or patient of an event), a positive or negative affect

state often results for the character. These affect

states reflect world knowledge about what situations

are good and bad. For example:

Negative patient roles: killed X, ate X, chased X,

captured X, fired X, tortured X

Positive patient roles: rescued X, fed X, adopted X,

housed X, protected X, rewarded X

For example, “a man captured a bear” indicates a

negative state for the bear. Overall, this sentence

would generate a SUCCESS plot unit consisting of

an M state and a + state for the man (with an actual-

ization a causal link between them representing the

plan’s success) and a - state for the bear (as a cross-

character link indicating that what was good for the

man was bad for the bear). A tremendous amount of

world knowledge is needed to generate these states

from such a seemingly simple sentence. Similarly,

if a character is rescued, fed, or adopted, then a + af-

fect state should be produced for the character based

on knowledge that these events are desirable. We

are not aware of existing resources that can automat-

ically identify affect polarity with respect to event

roles. In Section 4.1.2, we explain how we automat-

ically acquire Patient Polarity Verbs from a corpus

to identify some of these affect states.

4 AESOP: Automatic Affect State Analysis

We created a system, called AESOP, to try to auto-

matically identify the types of affect states that are

required for plot unit analysis. AESOP incorporates

existing resources for sentiment analysis and speech

act recognition, and includes two novel components:

patient polarity verbs, which we automatically gen-

erate using corpus statistics, and affect projection

rules, which automatically project and infer affect

labels via syntactic relations.

AESOP produces affect states in a 3-step process.

First, AESOP labels individual words and phrases

with an M, +, or - affect tag. Second, it identi-

fies all references to the two main characters of the

20



story. Third, AESOP applies affect projection rules

to propagate affect states onto the characters, and in

some cases, to infer new affect states.

4.1 Step 1: Assigning Affect Tags to Words

4.1.1 Sentiment Analysis Resources

AESOP incorporates several existing sentiment

analysis resources to recognize affect states associ-

ated with emotions and speech acts.

• OpinionFinder2 (Wilson et al., 2005) (Version
1.4) is used to identify all three types of states. We

use the +/- labels assigned by its contextual polar-

ity classifier (Wilson, 2005) to create +/- affect tags.

The MPQASD tags produced by its Direct Subjective

and Speech Event Identifier (Choi et al., 2006) are

used as M affect tags.

• Subjectivity Lexicon3 (Wilson, 2005): The pos-
itive/negative words in this list are assigned +/- af-

fect tags, when they occur with the designated part-

of-speech (POS).

• Semantic Orientation Lexicon4 (Takamura et
al., 2005): The positive/negative words in this list

are assigned +/- affect tags, when they occur with

the designated part-of-speech.

• A list of 228 speech act verbs compiled from
(Wierzbicka, 1987)5, which are used for M states.

4.1.2 Patient Polarity Verbs

As we discussed in Section 3.4, existing resources

are not sufficient to identify affect states that arise

from a character being acted upon. Sentiment lexi-

cons, for example, assign polarity to verbs irrespec-

tive of their agents or patients. To fill this gap,

we tried to automatically acquire verbs that have a

strong patient polarity (i.e., the patient will be in a

good or bad state by virtue of being acted upon).

We used corpus statistics to identify verbs that

frequently occur with agents who typically have

evil (negative) or charitable (positive) intent. First,

we identified 40 words that are stereotypically evil

agents, such as monster, villain, terrorist, and mur-

derer, and 40 words that are stereotypically charita-

ble agents, such as hero, angel, benefactor, and res-

cuer. Next, we searched the google Web 1T 5-gram

2http://www.cs.pitt.edu/mpqa/opinionfinderrelease/
3http://www.cs.pitt.edu/mpqa/lexiconrelease/collectinfo1.html
4http://www.lr.pi.titech.ac.jp/∼takamura/pndic en.html
5http://openlibrary.org/b/OL2413134M/English speech act verbs

corpus6 using patterns designed to identify verbs

that co-occur with these words as agents. For each

agent term, we applied the pattern “*ed by [a,an,the]

AGENT” and extracted the list of matching verbs.7

Next, we rank the extracted verbs by computing

the ratio between the frequency of the verb with a

negative agent versus a positive agent. If this ratio

is > 1, then we save the verb as a negative patient

polarity verb (i.e., it imparts negative polarity to its

patient). This process produced 408 negative patient

polarity verbs, most of which seemed clearly neg-

ative for the patient. Table 1 shows the top 20 ex-

tracted verbs. We also tried to identify positive pa-

tient polarity verbs using a positive-to-negative ra-

tio, but the extracted verbs were often neutral for the

patient, so we did not use them.

scammed damaged disrupted ripped

raided corrupted hindered crippled

slammed chased undermined possesed

dogged tainted grounded levied

patched victimized posessed bothered

Table 1: Top 20 negative patient polarity verbs

4.2 Step 2: Identifying the Characters

The problem of coreference resolution in fables

is somewhat different than for other genres, pri-

marily because characters are often animals (e.g.,

“he”=“owl”). So we hand-crafted a simple rule-

based coreference system. For the sake of this task,

we made two assumptions: (1) There are only two

characters per fable, and (2) Both characters are

mentioned in the fable’s title.

We then apply heuristics to determine number and

gender for the characters based on word lists, Word-

Net (Miller, 1990) and POS tags. If no determina-

tion of a character’s gender or number can be made

from these resources, a process of elimination is em-

ployed. Given the two character assumption, if one

character is known to be male, but there are female

pronouns in the fable, then the other character is as-

sumed to be female. The same is done for number

agreement. Finally, if there is only one character be-

tween a pronoun and the beginning of a document,

6http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2006T13
7The corpus is not POS tagged so there is no guarantee these

will be verbs, but they usually are in this construction.

21



the pronoun is assumed to corefer with that char-

acter. The character then assumes the gender and

number of that pronoun. Lastly, WordNet is used

to obtain a small set of non-pronominal, non-string-

match resolutions by exploiting hypernym relations,

for instance, linking Peasant with the man.

4.3 Step 3: Affect Projection

Our goal is to produce affect states for each char-

acter in the story. Therefore every affect tag needs

to be attributed to a character, or discarded. Since

plots typically revolve around actions, we used the

verbs as the basis for projecting affect tags onto the

characters. In some cases, we also spawn new affect

tags associated with mental states to indicate that an

action is likely the manifestation of a plan.

We developed 6 types of affect projection rules

that orchestrate how affect tags are assigned to the

characters based on verb argument structure. We

use the Sundance shallow parsing toolkit (Riloff and

Phillips, 2004) to generate a syntactic analysis of

each sentence, including syntactic chunking, clause

segmentation, and active/passive voice recognition.

We normalize the verb phrases (VPs) with respect to

voice (i.e., we transform the passive voice construc-

tions into an active voice equivalent) to simplify our

rules. We then make the assumption that the Subject

of the VP is its AGENT and the Direct Object of the

VP is its PATIENT.8 The affect projection rules only

project affect states onto AGENTS and PATIENTS

that correspond to a character in the story. The five

types of rules are described below.

1. AGENT VP : This case applies when the VP

has no PATIENT, or a PATIENT that is not a char-

acter in the story, or the PATIENT corefers with

the AGENT. All affect tags associated with the VP

are projected onto the AGENT. For example, “Mary

laughed (+)” projects a positive affect state onto

Mary.

2. VP PATIENT9: All affect tags associated with

the VP are projected onto the PATIENT, unless both

M and +/- tags exist, in which case only the +/- tags

are projected. For example, “loved (+) the cat”,

projects a positive affect state onto the cat.

8We are not actually doing thematic role recognition, so this

will not always be correct, but it is a reasonable approximation.
9Agent is missing or not a character.

3. AGENT VP PATIENT: This case applies when

the AGENT and PATIENT refer to different char-

acters. All affect tags associated with the VP are

projected onto the PATIENT, unless both M and +/-

tags exist, in which case only the +/- tags are pro-

jected (as in Rule #2). If the VP has an M tag, then

we also project an M tag onto the AGENT (repre-

senting a shared, cross-character mental state). If

the VP has a +/- tag, then we project a + tag onto

the agent (as an inference that the AGENT accom-

plished some action).

4. AGENT VERB1 to VERB2 PATIENT. We di-

vide this into two cases: (a) If the agent and patient

refer to the same character, then Rule #1 is applied

(e.g., “Bo decided to teach himself...”). (b) If the

agent and patient are different, we apply Rule #1 to

VERB1 to agent and Rule #2 to VERB2. If no af-

fect tags are assigned to either verb, then we create

an M affect state for the agent (assuming that the VP

represents some sort of plan).

5. If a noun phrase refers to a character and in-

cludes a modifying adjective with an affect tag, then

the affect is mapped onto the character. For exam-

ple, “the happy (+) fox”.

Finally, if an adverb or adjectival phrase (e.g.,

predicate adjective) has an affect tag, then that affect

tag is mapped onto the preceding VP and the projec-

tion rules above are applied. For all of the rules, if

a clause contains a negation word, then we flip the

polarity of all words in that clause. Our negation list

contains: no, not, never, fail, failed, fails, don’t, and

didn’t.

5 Evaluation

5.1 Data Set

Plot unit analysis of ordinary text is enormously

complex – even the idea of manually creating gold

standard annotations seemed like a monumental

task. So we began our exploration with simpler and

more constrained texts that seemed particularly ap-

propriate for plot unit analysis: fables. Fables have

two desirable attributes: (1) they have a small cast

of characters, and (2) they typically revolve around

a moral, which is exemplified by a short and concise

plot. Even so, fables are challenging for NLP due to

anthropomorphic characters, flowery language, and

sometimes archaic vocabulary.

22



State M (66) + (52) - (39) All (157)

System R P F R P F R P F R P F

Bsent baseline .65 .10 .17 .52 .08 .14 .74 .06 .11 .63 .08 .14

Bclause baseline .48 .28 .35 .44 .22 .29 .69 .17 .27 .52 .22 .31

All 4 resources (w/proj. rules) .48 .43 .45 .23 .39 .29 .23 .41 .29 .34 .41 .37

OpinionFinder .36 .42 .39 .00 .00 .00 .00 .00 .00 .15 .35 .21

Subjectivity Lexicon .45 .43 .44 .23 .35 .28 .21 .44 .28 .32 .41 .36

Semantic Dictionary .42 .45 .43 .00 .00 .00 .00 .00 .00 .18 .45 .26

Semantic Orientation Lexicon .41 .43 .42 .17 .53 .26 .08 .43 .13 .25 .45 .32

PPV Lexicon .41 .42 .41 .02 .17 .04 .21 .73 .33 .23 .44 .30

AESOP (All 4 + PPV) .48 .40 .44 .25 .36 .30 .33 .46 .38 .37 .40 .38

Table 2: Evaluation results for 2 baselines, 4 sentiment analysis resources with projection rules, and our PPV lexicon

with projection rules. (The # in parentheses is the number of occurrences of that state in the gold standard).

We collected 34 fables from an Aesop’s Fables

web site10, choosing fables that have a true plot

(some only contain quotes) and exactly two charac-

ters. We divided them into a development set of 11

stories, a tuning set of 8 stories, and a test set of 15

stories. The Father and Sons story from Figure 1(a)

is an example from our set.

Creating a gold standard was itself a substantial

undertaking. Plot units are complex structures, and

training non-experts to produce them did not seem

feasible in the short term. So three of the authors

discussed and iteratively refined manual annotations

for the development and tuning set stories until we

became comfortable that we had a common under-

standing for the annotation task. Then to create our

gold standard test set, two authors independently

created annotations for the test set, and a third au-

thor adjudicated the differences. The gold standard

contains complete plot unit annotations, including

affect states, causal links, and cross-character links.

For the experiments in this paper, however, only the

affect state annotations were used.

5.2 Baselines

We created two baselines to measure what would

happen if we use all 4 sentiment analysis resources

without any projection rules. The first one (Bsent)

operates at the sentence level. It naively projects ev-

ery affect tag that occurs in a sentence onto every

character in the same sentence. The second base-

line (Bclause) operates identically, but at the clause

level.

10http://www.pacificnet.net/∼johnr/aesop/

5.3 Evaluation

As our evaluation metrics we used recall (R), preci-

sion (P), and F-measure (F). We evaluate each sys-

tem on individual affect states (+, - and M) as well

as across all affect states. The evaluation is done at

the sentence level. Meaning, if a system produces

the same affect state as present in the gold standard

for a sentence, we count it as a correct affect state.

Our main evaluation also requires each affect state

to be associated with the correct character.

Table 2 shows the coverage of our two baseline

systems as well as the four Sentiment Analysis

Resources used with our projection rules. We can

make several observations:

• As expected, the baselines achieve relatively high
recall, but low precision.

• Each of the sentiment analysis resources alone
is useful, and using them with the projection rules

leads to improved performance over the baselines

(10 points in F score for M and 6 points overall).

This shows that the projection rules are helpful

in identifying the characters associated with each

affect state.

• The PPV Lexicon, alone, is quite good at cap-
turing negative affect states. Together with the

projection rules, this leads to good performance on

identifying mental states as well.

To better assess our projection rules, we evaluated

the systems both with respect to characters and with-

out respect to characters. In this evaluation, system-

produced states are correct even if they are assigned

to the wrong character. Table 3 reveals several re-

sults: (1) For the baseline: there is a large drop when

23



State M (66) + (52) - (39) All (157)

System R P F R P F R P F R P F

Bclause w/o char .65 .37 .47 .50 .25 .33 .77 .19 .30 .63 .26 .37

AESOP w/o char .55 .44 .49 .33 .47 .39 .36 .50 .42 .43 .46 .44

Bclause w/ char .48 .28 .35 .44 .22 .29 .69 .17 .27 .52 .22 .31

AESOP w/ char .48 .40 .44 .25 .36 .30 .33 .46 .38 .37 .40 .38

Table 3: Evaluating affect states with and without respect to character.

State M (66) + (52) - (39) All (157)

System R P F R P F R P F R P F

Bclause PCoref .48 .28 .35 .44 .22 .29 .69 .17 .27 .52 .22 .31

AESOP PCoref .48 .40 .44 .25 .36 .30 .33 .46 .38 .37 .40 .38

Bclause ACoref .42 .45 .43 .25 .34 .29 .54 .24 .33 .39 .33 .36

AESOP ACoref .41 .54 .47 .12 .40 .18 .26 .45 .33 .27 .49 .35

Table 4: Final results of Bclause and AESOP systems with perfect and automated coreference

evaluated with respect to the correct character. (2)

For AESOP: there is a smaller drop in both preci-

sion and recall for M and -, suggesting that our pro-

jection rules are doing well for these affect states.

(3) For AESOP: there is a large drop in both preci-

sion and recall for +, suggesting that there is room

for improvement of our projection rules for positive

affect.

Finally, we wish to understand the role that coref-

erence plays. Table 4 summarizes the results with

perfect coreference and with automated coreference.

AESOP is better than both baselines when we use

perfect coreference (PCoref), which indicates that

the affect projection rules are useful. However,

when we use automated coreference (ACoref), re-

call goes down and precision goes up. Recall goes

down because our automated coreference system is

precision oriented: it only says “coreferent” if it is

sure.

The increase in precision when moving to auto-

mated coreference is bizarre. We suspect it is pri-

marily due to the handling of quotations. Our perfect

coreference system resolves first and second person

pronouns in quotations, but the automated system

does not. Thus, with automated coreference, we al-

most never produce affect states from quotations.

This is a double-edged sword: sometimes quotes

contain important affect states, sometimes they do

not. For example, from the Father and Sons fable,

“if you are divided among yourselves, you will be

broken as easily as these sticks.” Automated coref-

erence does not produce any character resolutions

and therefore AESOP produces no affect states. In

this case this is the right thing to do. However, in

another well-known fable, a tortoise says to a hare:

“although you be as swift as the wind, I have beaten

you in the race.” Here, perfect coreference produces

multiple affect states, which are related to the plot:

the hare recieves a negative affect state for having

been beaten in the race.

6 Conclusions

AESOP demonstrates that sentiment analysis tools

can successfully recognize many affect states when

coupled with syntax-based projection rules to map

the affect states onto characters. We also showed

that negative patient polarity verbs can be harvested

from a corpus to identify characters that are in a neg-

ative state due to an action. However, performance is

still modest, revealing that much work remains to be

done. In future work, new methods will be needed

to represent affect states associated with plans/goals,

events, and inferences.

7 Acknowledgments

The authors thank the anonymous reviewers for
many helpful comments. This work was sup-
ported in part by the Department of Homeland Se-
curity Grant N0014-07-1-0152, the DARPA Ma-
chine Reading program under contract FA8750-09-
C-0172, and the NSF grant IIS-0712764.

24



References

Yejin Choi, Eric Breck, and Claire Cardie. 2006. Joint

extraction of entities and relations for opinion recogni-

tion. In EMNLP ’06: Proceedings of the 2006 Confer-

ence on Empirical Methods in Natural Language Pro-

cessing, pages 431–439, Morristown, NJ, USA. Asso-

ciation for Computational Linguistics.

S. Kim and E. Hovy. 2006. Extracting Opinions, Opin-

ion Holders, and Topics Expressed in Online News

Media Text. In Proceedings of ACL/COLING Work-

shop on Sentiment and Subjectivity in Text.

W. Lehnert, J. Black, and B. Reiser. 1981. Summariz-

ing Narratives. In Proceedings of the Seventh Interna-

tional Joint Conference on Artificial Intelligence.

W. G. Lehnert. 1981. Plot Units and Narrative Summa-

rization. Cognitive Science, 5(4):293–331.

G. Miller. 1990. Wordnet: An On-line Lexical Database.

International Journal of Lexicography, 3(4).

E. Riloff and W. Phillips. 2004. An Introduction to the

Sundance and AutoSlog Systems. Technical Report

UUCS-04-015, School of Computing, University of

Utah.

V. Stoyanov and C. Cardie. 2008. Topic Identification

for Fine-Grained Opinion Analysis. In Conference on

Computational Linguistics (COLING 2008).

Hiroya Takamura, Takashi Inui, and Manabu Okumura.

2005. Extracting semantic orientations of words using

spin model. In ACL ’05: Proceedings of the 43rd An-

nual Meeting on Association for Computational Lin-

guistics.

A. Wierzbicka. 1987. English speech act verbs: a se-

mantic dictionary. Academic Press, Sydney, Orlando.

T. Wilson, P. Hoffmann, S. Somasundaran, J. Kessler,

J. Wiebe, Y. Choi, C. Cardie, E. Riloff, and S. Pat-

wardhan. 2005. OpinionFinder: A system for subjec-

tivity analysis. In Proceedings of HLT/EMNLP 2005

Interactive Demonstrations.

Theresa Wilson. 2005. Recognizing contextual polarity

in phrase-level sentiment analysis. In In Proceedings

of HLT-EMNLP.

25


