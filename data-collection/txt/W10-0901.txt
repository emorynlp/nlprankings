










































Machine Reading as a Process of Partial Question-Answering


Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 1–9,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

Machine Reading as a Process of Partial Question-Answering 

Peter Clark and Phil Harrison
Boeing Research & Technology 

The Boeing Company, PO Box 3707, Seattle, WA 98124, USA 
{peter.e.clark,philip.harrison}@boeing.com

Abstract

This paper explores the close relationship be-

tween question answering and machine read-

ing, and how the active use of reasoning to 

answer (and in the process, disambiguate) 

questions can also be applied to reading de-

clarative texts, where a substantial proportion 

of the text’s contents is already known to (rep-

resented in) the system. In question answer-

ing, a question may be ambiguous, and it may 

only be in the process of trying to answer it 

that the "right" way to disambiguate it be-

comes apparent. Similarly in machine reading, 

a text may be ambiguous, and may require 

some process to relate it to what is already 

known. Our conjecture in this paper is that 

these two processes are similar, and that we 

can modify a question answering tool to help 

"read" new text that augments existing system 

knowledge. Specifically, interpreting a new 

text T can be recast as trying to answer, or 

partially answer, the question "Is it true that 

T?", resulting in both appropriate disambigua-

tion and connection of T to existing knowl-

edge. Some preliminary investigation suggests 

this might be useful for proposing knowledge 

base extensions, extracted from text, to a 

knowledge engineer. 

1 Introduction 

Machine reading is not just a task of language 

processing, but an active interplay between knowl-

edge and language; Prior knowledge should guide 

interpretation of new text, and new interpretations 

should augment that prior knowledge. Such inter-

action is essential if ambiguities in language are to 

be resolved "correctly" (with respect to what is 

known), and if the resulting interpretations are to 

be integrated with existing knowledge. The main 

insight of this paper is that this interaction is simi-

lar to that required for knowledge-based question 

answering, which also requires searching a knowl-

edge base (KB) for a valid interpretation of the 

question. In our earlier work on question answer-

ing (Clark and Harrison, 2010), we found that 

some disambiguation decisions for question inter-

pretation could be deferred, to be resolved during 

question answering, guided by what was found in 

the KB. In this paper, we show how a similar ap-

proach can be applied to interpreting declarative 

text, so that a similar interplay between language 

and knowledge is achieved. 

"Machine reading" itself is a loosely-defined no-

tion, ranging from extracting selective facts to con-

structing complex, inference-supporting 

representations of text. One approach for selective 

extraction is the use of semantic templates 

("scripts", "frames") to provide a set of roles (slots) 

and constraints on objects playing those roles (fill-

ers) to be expected in text, and might be filled by 

methods ranging from simply skimming text, e.g., 

FRUMP (DeJong, 1979), to full language process-

ing, e.g., (Dahlgren et al., 1991). Other work has 

looked at techniques for learning phrasal patterns 

likely to contain slot fillers (Riloff, 1996; Sekine, 

2006) or contain information semantically similar 

to a set of seed examples (Carlson et al, 2009). 

At the other end of the spectrum, some systems 

attempt a full understanding of text, i.e., have the 

ambitious goal of building a complete representa-

tion of the text's contents (e.g., Zadrozny 1991, 

Hobbs et al, 1993). A common thread of these ap-

proaches is to search a space of alternative disam-

biguations and elaborations and select the most 

1



"coherent", based on criteria such as maximizing 

coreference, minimizing redundancy, and avoiding 

contradictions. For example, Mulkar et al (2007) 

search for a set of abductive inferences on the 

(logical form of the) text that minimizes cost 

(maximizes coherence) of the result, where an ab-

ductive inference might be a word sense or 

coreference decision with an associated cost. Simi-

larly, Zadrozny and Jensen (1991) search a space 

of disambiguations when interpreting paragraphs 

by elaborating each alternative (using dictionary 

definitions) and selecting the most coherent based 

on similar criteria. Work on model building is in-

spiring but also challenging due to the lack of con-

straint on the final models (even with substantial 

domain knowledge) and the difficulty of quantify-

ing "coherence".

Our work falls somewhere between these two. We 

do not use templates for new knowledge, but rather 

use inference at run-time to identify what is known 

and thus what to expect that the text might be say-

ing. However, unlike full model building ap-

proaches, we assume that the majority of what is 

being read is already known (represented) in the 

KB, and thus the reading task is primarily one of 

recognizing that knowledge in the text, and extend-

ing it with any new facts that are encountered. We 

might term this a "model extension" approach; it 

corresponds to Feigenbaum's (2003) challenge of, 

given the representation of a book, have a machine 

read a second book (about the same topic) and in-

tegrate the new knowledge contained in that text. 

2 The Problem 

Our work is in the context of cell biology, where 

we have a moderately sized1, hand-built knowl-

edge base available containing formal representa-

tions of biological structures and processes 

expressed in first-order logic. Our goal is to take 

paragraphs of text about a topic partially covered 

by the KB, and identify facts which are already 

known, facts which are new,  and  the  connections  
                                                          
1 Specifically, it has detailed representations of entities and 

processes related to cell division, DNA replication, and pro-

tein synthesis, containing approximately 250 domain-specific 

concepts (built on top of a pre-existing library of approxi-

mately 500 domain-general concepts), 120 relations (binary 

predicates), and approximately 2000 axioms, built as part of  

Project Halo (Gunning et al., 2010). 

Topic: prophase 

Input Paragraph:

In the cytoplasm, the mitotic spindle, consisting of 

microtubules and other proteins, forms between the 

two pairs of centrioles as they migrate to opposite 

poles of the cell. 

Output Axioms: (expressed in English)

In all prophase events: 

a. The mitotic spindle has parts the microtubule 

and the protein. 

b. The mitotic spindle is created between the 

centrioles in the cytoplasm.

c. The centrioles move to the poles.

Figure 1: The system’s behavior, showing known 

(normal font) and new (bold) facts identified 

from the text. Note that the output is not just a 

simple recitation of the input, but a mixture of 

known and new axioms for the KB. 

between the two. An example of the system’s out-

put is shown in Figure 1. In the Output Axioms in 

that Figure, the normal font shows facts that the 

system has recognized as already known in the 

KB, while bold font shows new knowledge. It is 

important to note that the output facts are not just a 

simple  recitation of the input, but have been inter-

preted in the context of the KB. For example in the 

input paragraph:  

"the mitotic spindle, consisting of microtubules" 

has not been interpreted as describing some “con-

sisting” event, but recognized (via use of para-

phrases, described later) as referring to the has-

part(mitotic-spindle01,microtubules01) element in 

the representation of prophase in the KB, i.e., de-

noting a "has part" relationship ((a) in Figure 1). 

Similarly,  

   "the spindle forms"

has not been interpreted as an organizing event 

(“form a team”) nor as the spindle doing the form-

ing (“the spindle forms something”), but instead 

been recognized as the result(create01,mitotic-

spindle01) element in the representation of pro-

phase in the KB, i.e., "forms" has been interpreted 

as this particular creation event in the representa-

tion of prophase (b in Figure 1). Doing this re-

quires not just careful language processing; it 

requires querying the knowledge base to see/infer 

2



what is already known, and using this to guide the 

interpretation.

This process is similar to that needed for question-

answering. Consider giving a question form of 

(part of) the earlier paragraph to a question-

answering system: 

(1) Is it true that the mitotic spindle consists of 

microtubules?

Again, the phrase "consists of" is ambiguous, and 

may mean different things in different contexts. 

However, in the context of question-answering, 

there is a natural approach to disambiguating this: 

as the user is asking about what is in the KB, then 

a natural approach is to query the KB for relation-

ships that hold between the mitotic spindle and 

microtubules, and see if any are a plausible inter-

pretation of "consists of". If there is one, then it is 

likely to be the interpretation that the user intended 

(assuming the user is not being deliberately ob-

scure; we call this a "benevolent user" assump-

tion). If this happens, then the question-answering 

system can answer "yes"; but more importantly 

from a machine reading point of view, the system 

has also correctly disambiguated the original ques-

tion and located the facts it mentions in the knowl-

edge base as side-effects. It is this process that we 

want to apply to interpreting declarative texts, with 

the change that unproven parts should be treated as 

new assertions, rather than failed queries. 

3 Approach

Based on these observations, our approach is to 

interpret a new text T by treating it as a question to 

the KB asking whether the facts in T are already 

known. By attempting to answer this question, the 

system resolves ambiguity for the known facts 

(namely, the resolution that leads to them being 

recognized is preferred). For new facts, the system 

falls back on more traditional NLP modules, fil-

tered by coarser-grained type constraints. In addi-

tion, the identification of known facts in the KB 

and the connection between the old facts and the 

new facts provides anchor points for the new facts 

to be connected to. 

To implement this approach, we have used three 

important features of our question-answering sys-

tem, here reapplied to the task of text interpreta-

tion:

a. The use of a large database of paraphrases to 

explore alternative phrasings (hence alternative 

interpretations) of text; 

b. Deferring word sense and semantic role com-

mitment during initial language processing, to 

be resolved later based on what is found in the 

KB;

c. The use of standard disambiguation techniques 

to process new facts not located in the KB. 

We now summarize these three features, then pre-

sent the complete algorithm. 

3.1 Paraphrases

A relatively recent advance in NLP has been the 

automatic construction of paraphrase databases 

(containing phrasal patterns with approximately 

equivalent meaning), built by finding phrases that 

occur in distributionally similar contexts (e.g., 

Dras et al, 2005). To date, paraphrase databases 

have primarily been exploited for recognizing tex-

tual entailment (e.g., Bentivogli et al., 2009). In 

our work, we take them in a new direction and ex-

ploit them for language interpretation. 

We use the DIRT paraphrase database (Lin and 

Pantel, 2001a,b), containing approximately 12 mil-

lion automatically learned rules of the form: 

IF X relation Y THEN X relation' Y

where relation is a path in the dependency tree be-

tween constitutents X and Y, or equivalently (as 

we use later) a chain of clauses:

{p0(x0,x1), w1(x1), …pn-1(x n-1,xn)}

where pi is the syntactic relation between (non-

prepositional) constituents xi and xi+1, and wi is the 

word used for xi. An example from DIRT is: 

IF X is found in Y THEN X is inside Y 

The condition “X is found in Y” can be expressed 

as the clause chain: 

{ object-of(x,f), "find"(f), "in"(f,y) } 

We use DIRT to explore alternative interpretations 

of the text, singling out those that help identify the 

facts in the text that are already known in the KB. 

3.2 Deferred Sense Commitment

Two common challenges for NLP are word sense 

disambiguation (WSD) and semantic role labeling 

3



(SRL). While there are a number of existing tools 

for performing these tasks based on the linguistic 

context (e.g., Toutanova et al., 2008, Erk and Pado, 

2006), their performance is only moderate (e.g., 

Agirre et al, 2007). The problem is accentuated 

when trying to disambiguate in a way consistent 

with a particular KB, because there is often a de-

gree of subjectivity in how the knowledge engineer 

chose to represent the world in that KB (e.g., 

whether some object is the "agent" or "instrument" 

or "site" of an activity is to a degree a matter of 

viewpoint). Trying to create a WSD or SRL mod-

ule that reliably mimics the knowledge engineer’s 

decision procedure is difficult. 

To address this, we defer WSD and SRL commit-

ment during the initial text processing. Instead, 

these ambiguities are resolved during the subse-

quent stage of querying the KB to see if (some in-

terpretion of) the text is already known. One can 

view this as a trivial form of preserving under-

specification (eg. Pinkal, 1999) in the initial lan-

guage processing, where the words themselves 

denote their possible meanings. 

3.3 Interpretation of New Knowledge 

Given some text, our system attempts to disam-

biguate it by searching for (some interpretation of) 

its statements in the KB. However, this will only 

disambiguate statements of facts that are already 

known. For new facts, we fall back on traditional 

disambiguation methods, using a set of approxi-

mately 100 hand-built rules for semantic role label-

ling, and word sense disambiguation preferences 

taken from WordNet sense frequency statistics and 

from the KB. In addition, we use a simple filter to 

discard apparently irrelevant/nonsensical assertions 

by discarding those that use concepts unrelated to 

the domain. These are defined as those with words 

whose preferred WordNet sense falls under one of 

a small number of hand-selected "non-biological" 

synsets (namely human_activity#n#1, mental_ob-

ject#n#1, artifact#n#1, instrumentation#n#1, psy-

chological_feature#n#1, device#n#1). One might 

also be able to use a KB-guided approach to dis-

ambiguation similar to that described for known 

facts, by (for example) looking for generalizations 

of (interpretations of) new facts in the knowledge 

base. This is a direction for future exploration. 

4 Algorithm and Implementation 

4.1 Topics and Participants 

For now, we assume that all knowledge in the KB 

can be represented by “forall…exists…” state-

ments, i.e., statements of the form: 

 x isa(x,C) !y1..yn p1(v1,v2), …, pq(vr,vs) [1] 

(We will later discuss how this assumption can be 

relaxed). pi are predicates in the KB’s ontology and 

each vi is either a variable v"{x,y1,…,yn} or a 

symbol in the KB’s ontology. We say clauses 

pi(vj,vk) are about concept C, and that C is the topic

of the clauses. We also say that any instance yi that 

is in some (possibly indirect) relationship to x is a 

participant in the representation of instance x of C. 

Thus all the yi in [1] are participants, plus there 

may be additional participants implied by other 

axioms. For some given instance X0 of C, we can 

identify all the participants in the representation of 

X0 by forward chaining from isa(X0,C) and col-

lecting all the instances connected via some chain 

of predicates to X0. We encode this using a par-

ticipant(x,yi) relation
2. As this computation is po-

tentially unbounded, we use a depth bound to 

heuristically limit this computation. 

4.2 Initial Language Processing 

Assume the system has a paragraph of text about a 

topic, and that it has identified what that topic is3.

For example, consider that the topic is prophase (a 

step in cell division), and the paragraph is the sin-

gle sentence: 

T: The mitotic spindle consists of hollow micro-

tubules.

Text is parsed using a broad coverage, phrase 

structure parser (Harrison and Maxwell, 1986), 

followed by coreference resolution, producing a 

"syntactic" logical form, here: 

LF: "mitotic-spindle"(s), "consist"(c), "hollow"(h), 

"microtubule"(m), subject(c,s), "of"(c,m), 

modifier(m,h). 

                                                          
2 We can formalize this by adding participant(x,yi) to the con-

clusion in [1] for all yi, plus an axiom that participant is transi-

tive. 
3 E.g., via some topic classification algorithm. For our experi-

ments here, we manually declare the topic. 

4



4.3 Semantic Interpretation 

To interpret T the system then tries to answer, or 

partially answer, the corresponding question: 

T: Is it true that the mitotic spindle consists of hol-

low microtubules? 

Note that this question is in the context of the topic 

(prophase), and thus the mentioned objects are im-

plicitly participants in prophase. To do this, the 

system proceeds as follows, using a deductive rea-

soning engine operating over the KB: 

(a) setup: create an instance X0 of the topic, i.e., 

assert isa(X0,topic) in the KB, then find its 

participants { y | participant(X0,y) }. Next, 

bind one of the variables in the LF to a partici-

pant that the variable's word might denote. 

(b) query: for each clause in the LF with at least 

one bound variable, iteratively query the KB to 

see if some interpretation of those clauses are 

provable i.e., already known. 

In this example, for setup (a) the system first cre-

ates an instance X0 of prophase, i.e., asserts 

isa(X0,Prophase) in the KB, then finds its partici-

pants Y0,...,Yn by querying for participant(X0,y). 

The participants Y0,Y1,… will be instances of ob-

jects and events known (in the KB) to be present in 

prophase, e.g., instances of Move, Centrosome, 

Elongate, Mitotic-Spindle, etc. The system then 

instantiates a variable in the LF, e.g., s in "mitotic-

spindle"(s) with a participant that "mitotic spindle"  

might refer to, e.g., Y4, if Y4 is an instance of Mi-

totic-Spindle. The resulting LF looks: 

LF:"mitotic-spindle"(Y4),"consist"(c),"hollow"(h), 

"microtubule"(m), subject(c,Y4), "of"(c,m), 

modifier(m,h). 

For querying (b), the system uses the algorithm as 

follows (on the next page): 

Y4:Mitotic-Spindle
X0:Prophase

Y0:Move Y1:Centrosome

Y7:Microtubule

Y3:Elongate Y5:Pole

subevent 

has-part has-region 
object

object

Y8:Hollow
shape 

isa(Y4,Mitotic-Spindle), isa(Y8,Hollow), isa(Y7,Microtubule), has-part(Y4,Y7), shape(Y7,Y8).

"mitotic-spindle"(s), "consist"(c), "hollow"(h), "microtubule"(m), subject(c,s), "of"(c,m), modifier(m,h). 

isa(Y4,Mitotic-Spindle), "consist"(c), "hollow"(h), "microtubule"(m), subject(c,Y4), "of"(c,m), modifier(m,h) 

isa(Y4,Mitotic-Spindle), "hollow"(h), isa(Y7,Microtubule), has-part(Y4,Y7), modifier(Y7,h). 

isa(Y4,Mitotic-Spindle), “part"(p), "hollow"(h), "microtubule"(m), subject(p,Y4), "of"(p,m), modifier(m,h). 

(a)

(b)

(c)

(d)

(Graphical depiction of) (part of) the representation of Prophase:

LF interpretation: New Knowledge 

has-part 
Y6:Create

…

Recognized Old Knowledge 

Figure 2: The path found through the search space for an interpretation of the example sentence. (a) setup 

(b) paraphrase substitution (c) interpretation of {subject-of(Y4,p),“part”(p),“of”(p,m)} as has-part(Y4,m), 

preferred as it is provable from the KB, resulting in m=Y7 (d) interpretation of new knowledge (standard 

WSD and SRL tools). 

destination 

Y2:Eukaryotic-Cell 

…

5



repeat

select a clause chain Cu of “syntactic” clauses 

                 in the LF with at least 1 bound variable 

Cu = {p(x,y)} or {w(x)} or 

                                {p1(x,z), w(z), p2(z,y)}

select some interpretation C of Cu where: 

          C is a possible interpretation of Cu
          or C'u is a possible paraphrase for Cu and 

                  C is a possible interpretation of C'u
try prove C[bindings]   new-bindings 

   If success: 

replace Cu with C 

add new-bindings to bindings 

until

    as many clauses proved as possible 

where:

# A syntactic clause is a clause whose predicate 

is a word or syntactic role (subject, object, 

modifier, etc.) All clauses in the initial LF are 

syntactic clauses. 

# A clause chain is a set of "syntactic" clauses in 

the LF of the form {p(x,y)} or {w(x)} or 

{p1(x,z), w(z), p2(z,y)}, where pi, w are words 

or syntactic roles (subject, modifier, etc). 

# A possible paraphrase is a possible substitu-

tion of one syntactic clause chain with another, 

listed in the DIRT paraphrase database. 

# A possible interpretation of the singleton syn-

tactic clause chain {w(x)} is isa(x,class), 

where class is a possible sense of word w. 

# A possible interpretation of a syntactic clause 

chain {p(x,y)} or {p1(x,z),w(z),p2(z,y)} is 

r(x,y), where r is a semantic relation corre-

sponding to syntactic relation p (e.g., "in"(x,y) 

  is-inside(x,y)) or word w (e.g., {subject-

of(e,h), "have"(h), "of"(h,n)}   has-part(e,n)). 

Possible word-to-class and word-to-predicate map-

pings are specified in the KB.

As there are several points of non-determinism in 

the algorithm, including the setup (e.g., which 

clauses to select, which interpretation to explore), 

it is a search process. Our current implementation 

uses most-instantiated-first query ordering plus 

breadth-first search, although other implementa-

tions could traverse the space in other ways. 

Figure 2 illustrates this procedure for the example 

sentence. The procedure iteratively replaces syn-

tactic clauses with semantic clauses that corre-

spond to an interpretation that is provable from the 

KB. If all the clauses are proved, then the original 

text T is redundant; there exists an interpretation 

under which it can be proved from the KB, and we 

assume under the benevolent user assumption that 

this is the interpretation that the user intended.  

If some syntactic clauses remain unproved, then 

they correspond to new knowledge, and a standard 

NLP pipeline is then used to interpret them. In this 

example (Figure 2), the "hollow" modifier to the 

microtubule Y7 was unproved, and was subse-

quently interpreted by the NLP pipeline as the 

shape of the microtubule. This new clause is con-

verted into a (potential) addition to the KB by 

identifying an axiom that concluded one of  the 

known  connected facts (here, has-part(Y4,Y7)), 

and then proposing the new clause as an additional 

conclusion of that axiom. If there are no connected 

clauses, it is instead proposed as a new axiom 

about prophase. The user can verify/reject that 

proposal as he/she desires. 

5 Illustration 

An illustration of the system’s typical processing 

of a paragraph is shown in Figure 3. As in Figure 

1, normal font shows facts recognized as already 

known, and bold shows new knowledge. Again 

note that the output facts are not a simple recitation 

of the input, but have been interpreted with respect 

to the KB. For example, in (e), Create is the pre-

ferred interpretation of "form", and in (d), has-part 

is the preferred interpretation of "consisting of", as 

these result in the interpretation being provable 

from the KB. Also note that new knowledge is an-

chored to old, e.g., in (d), proteins are posited as an 

additional part of the mitotic spindle participant of 

prophase.

There are several errors and meaningless state-

ments in the output also. For example, "something 

signals" is not particularly helpful, and "the chro-

mosome moves" is, although biologically correct, a 

misinterpretation of the original English "the 

chromosome is seen as...", with Move being a pos-

sible interpretation of "see" (as in "I'll see you to 

the door"). In addition some sentences were mis-

parsed or unparsed, and some interpretations were 

discarded as they involved non-biological con-

cepts. Many representational issues have been 

skirted also, discussed shortly. 

6



Topic: prophase

Input Paragraph:
4

During prophase, chromosomes become visible, 

the nucleolus disappears, the mitotic spindle forms, 

and the nuclear envelope disappears. Chromo-

somes become more coiled and can be viewed un-

der a light microscope. Each duplicated 

chromosome is seen as a pair of sister chromatids 

joined by the duplicated but unseparated centro-

mere. The nucleolus disappears during prophase. 

In the cytoplasm, the mitotic spindle, consisting of 

microtubules and other proteins, forms between the 

two pairs of centrioles as they migrate to opposite 

poles of the cell. The nuclear envelope disappears 

at the end of prophase. This signals the beginning 

of the substage called prometaphase. 

Output Axioms: (expressed in English) 

In all prophase events: 

d. The chromosome moves.

e. The chromatids are attached by the centro-

mere. 

f. The nucleolus disappears during the pro-

phase.

g. The mitotic spindle has parts the microtubule 

and the protein. 

h. The mitotic spindle is created between the 

centrioles in the cytoplasm.

i. The centrioles move to the poles.

j. The nuclear envelope disappears at the end. 

k. Something signals. 

Figure 3: Illustration of the System’s Behavior 

6 Preliminary Evaluation 

To make a preliminary assessment of how much 

useful information the system is producing, we 

conducted a small study. 10 paragraphs about pro-

phase (from different Web sources) were run 

through the system (110 sentences in total). The 

system extracted 114 statements of which 23 

(20%) were interpreted as fully known (i.e., al-

ready in the KB), 27 (24%) as partially new 

knowledge, and 64 (56%) as completely new 

knowledge. The extracted statements were then 

scored by a biologist as one of:  

c = correct; useful knowledge that should be in 

the KB 

                                                          
4 From http://www.phschool.com/science/biology_place/ bio-

coach/mitosisisg/prophase.html 

q = questionable; not useful knowledge (mean-

ingless, overly general, vague) 

i  =  incorrect 

The results are shown in Table 1. 

Statements that are: 

Fully 

known

Mixture of 

known & new

Fully 

new

Correct 22 19 25

Questionable 1 8 38

Incorrect 0 0 1

Table 1: Correctness of axioms proposed by the 

system. 

For the statements that mix old and new knowl-

edge, 70% were judged correct, and for completely 

new statements, 39% were judged correct.5 This 

suggests the system is at least producing some use-

ful suggestions, and for the statements that mix old 

and new knowledge, has identified the connection 

points in the KB for the new facts. Although this 

level of accuracy is too low for automation, it sug-

gests the system might be a useful tool for helping 

a knowledge engineer check that he/she has fully 

encoded the contents of a passage when building 

the KB, and performing those approved additions 

automatically. 

7 Discussion and Conclusion 

We have described a method for reading "at the 

fringe" of what is known, leveraging existing 

knowledge to help in the reading process by treat-

ing text interpretation as partial question answer-

ing. This approach is appropriate for situations in 

which a reasonable proportion of the text's content 

is already known to (represented in) the KB. Our 

evaluation suggests that the approach has merit, at 

least as an interactive knowledge acquisition tool. 

As we have suggested, existing knowledge can 

help guide and anchor interpretation, but to what 

extent might it stifle the system from learning 

genuinely new knowledge? At present, our system 

is unable to extend its own ontology (it can only 

learns axioms expressed using its existing ontol-

ogy), and thus will skim over unrecognized words 

                                                          
5 For the 1 statement already fully known but judged as ques-

tionable, the score appears to be due to poor rendering in Eng-

lish, the axiom being rendered as "The membrane break 

down." rather than "The membrane breaks down.". 

7



even if those words reflect something new (with 

respect to the KB) and important about the domain. 

The system is thus biased towards texts about con-

cepts that it has at least heard of before (even if it 

knows little about them), expecting small, incre-

mental additions of knowledge, rather than work-

ing hard to untangle information about completely 

novel topics. It can learn about concepts it has al-

ready heard of, but not, at present, learn new con-

cepts. While it would be simple to modify the 

system to treat any new word as a new concept, 

this may potentially overwhelm the system, and so 

such extensions would need to be made carefully. 

This is an area for future work. 

How large must the starting KB be? Although it 

can be missing (possibly many) axioms, we implic-

itly assume that at least the basic ontology and the 

mapping from words to concepts is reasonably 

complete (for the types of texts being considered), 

i.e., there is a good "skeleton" KB to add axioms 

to. Thus, methodologically, a first step for using 

our system would be to create the initial ontology 

and lexical mappings, e.g., via corpus analysis or 

using an ontology learning tool  (Gomez-Perez and 

Manzano-Macho, 2003). Beyond that, the more 

axioms the starting KB has the better, as each 

axiom can potentially guide the interpretation of a 

new sentence. In the limiting case, where there are 

no axioms (only the ontology and lexical map-

pings), our system's behavior reverts to that of a 

normal, pipelined NLP interpreter (with the normal 

associated problems). 

This work is still preliminary, and there are nu-

merous other issues and limitations that need to be 

addressed also. Three notable issues are as follows: 

# Syntactic ambiguity: While we defer WSD 

and SRL commitment, our system is eagerly 

committing to a single parse during initial lan-

guage processing, and that parse may be 

wrong. An obvious extension is to similarly 

defer some syntactic commitments until se-

mantic interpretation, for example using an 

underspecified or packed logical form (e.g., 

Bobrow et al, 2005) or exploring alternative 

parses.

# Interpretation of new knowledge: While our 

approach leverages the KB to interpret state-

ments about known facts, and thus help find 

the anchor points for new facts, those state-

ments of new facts are still interpreted using a 

traditional pipelined approach, with all its as-

sociated brittlenesses (as evidenced in the last 

column in Table 1). Creative ways for using 

the KB to similarly help guide new fact inter-

pretation are needed, for example searching the 

KB for generalizations or variants of those 

facts, and then preferring the interpretations 

they suggest. 

# Representational adequacy: Our work so far 

has assumed a simple, deductive representa-

tional framework of individual objects and 

events, and correspondingly assumes the same 

individuality in language. However the world, 

and language used to describe it, often goes 

beyond this to include a miriad of representa-

tionally difficult phenomena (sets, pairs, ag-

gregates, conditionality, plausibility, 

constraints, etc.). Our system largely skips 

over such aspects, as it is unable to represent 

them. 

Despite these limitations, the picture of text inter-

pretation as partial question-answering appears to 

be a useful one, as it suggests a means by which 

language and knowledge can be connected. We are 

optimistic that it can be further developed and im-

proved for better machine reading in the future. 

Acknowledgements 

We are grateful to Vulcan Inc. who partially sup-

ported this work through Project Halo.  

References

Agirre, E., Marquez, L., Wicentowski, R., Eds., 2007. 

Proceedings of the 4th International Workshop on 

Semantic Evaluations (SemEval), ACL, Prague, 
Czech Republic. 

Bentivogli, L., Dagan, I., Dang, Hoa, Giampiccolo, D., 

Magnini, B. 2009. The Fifth PASCAL Recognizing 

Textual Entailment Challenge. In Proc Text Analysis 
Conference (TAC’09).

Bobrow, D. G., Condoravdi, Crouch, R. Kaplan, R. 

Karttunen, L., King, L.T.H., de Paiva, V., Zaenen, A. 

2005. A Basic Logic for Textual Inference. In Pro-
ceedings of the AAAI Workshop on Inference for Tex-

tual Question Answering, Pittsburgh, PA. 

Carlson, A., Betteridge, J., Hruschka, E., Mitchell, T. 

2009. Coupling Semi-Supervised Learning of Cate-

8



gories and Relations. Proceedings of the NAACL 
HLT 2009 Workshop on Semi-supervised Learning 

for Natural Language Processing.

Clark, P., Harrison, P. 2010. Exploiting Paraphraes and 

Deferred Sense Commitment to Interpret Questions 

more Reliably. (Submitted). 

Dahlgren, K., Lord, C., Wada, H., McDowell, J., Sabler, 

E. 1991. ITP: Description of the interpretext system 

as used for MUC-3. In Proc 3rd Message Under-
standing Conference (MUC-3), pp163-170. 

DeJong, G. 1979. Prediction and Substantiation: Two 

processes that comprise understanding. IJCAI’79,

pp217-222. 

Dras, M., Yamamoto, K. (Eds). 2005. Proc 3rd Interna-

tionl Workshop of Paraphrasing. South Korea. 

Erk, K., Pado, S. 2006. Shalmaneser – a flexible toolbox 

for semantic role assignment. Proc LREC 2006,
Genoa, Italy. 

Feigenbaum, E. 2003. Some Challenges and Grand 

Challenges for Computational Intelligence. Journal 

of ACM, 50 (1), pp 32-40. 

Gomez-Perez, A., Manzano-Macho, D. 2003. "A Survey 

of Ontology Learning Methods and Techniques", 

Technical Report, Univ Politecnica de Madrid (On-

toWeb Deliverable 1.5, http://www.sti-innsbruck.at/ 

fileadmin/documents/deliverables/Ontoweb/D1.5.pdf 

)

Gunning, D., Greaves, M., Chaudhri, V. et al. 2010. 

Project Halo Update – Progress Towards Digital Ar-
istotle (Submitted). 

Harrison, P., Maxwell, M. 1986. A New Implementa-

tion of GPSG. In Proc. 6th Canadian Conf on AI. 

Hobb, J., Stickel, M., Appelt, D., Martin, P. 1993. Inter-

pretation as Abudction. In Artificial Intelligence 63 

(1-2), pp 69-142. 

Lin, D. and Pantel, P. 2001a. Discovery of Inference 

Rules for Question Answering. Natural Language 
Engineering 7 (4) pp 343-360.  

Lin, D. and Pantel, P. 2001b. Discovery of Inference 

Rules in Text. Proc ACM SIGKDD Conf on Know-

eldge Discovery and Data Mining.

Mulkar, R., Hobbs, J. Hovy, E. 2007. Learning to Read 

Syntactically Complex Biology Texts. In Proc 8th 
International Symposium on Logical Formalizations 

of Commonsense Reasoning (AAAI Spring Sympo-
sium). 

Pinkal, M. 1999. On Semantic Underspecification. In 

Bunt, H./Muskens, R. (Eds.). Proceedings of the 2nd 

International Workshop on Compuational Linguistics 
(IWCS 2).

Riloff, E. 1996. Automatically Generating Extraction 

Patterns from Untagged Text. Proc AAAI’96.

Sekine, S. 2006. On-Demand Information Extraction. 

Proc. COLING-ACL.

Toutanova, K., Haghighi, A., Manning, C. 2008. A 

Global Joint Model for Semantic Role Labeling. 

Computational Linguistics, 34 (2). 

Zadrozny, W., Jensen, K. 1991. Semantics of Para-

graphs. in Computational Linguistics 17 (2) pp171-
209. 

9


