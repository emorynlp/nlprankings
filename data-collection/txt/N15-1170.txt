



















































Cross-lingual Text Classification Using Topic-Dependent Word Probabilities


Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1466–1471,
Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics

Cross-lingual Text Classification Using Topic-Dependent Word Probabilities

Daniel Andrade Akihiro Tamura Masaaki Tsuchida Kunihiko Sadamasa
Knowledge Discovery Research Laboratories, NEC Corporation, Japan

{s-andrade@cj, a-tamura@ah,
m-tsuchida@cq, k-sadamasa@az}.jp.nec.com

Abstract

Cross-lingual text classification is a major
challenge in natural language processing,
since often training data is available in only
one language (target language), but not avail-
able for the language of the document we want
to classify (source language). Here, we pro-
pose a method that only requires a bilingual
dictionary to bridge the language gap. Our
proposed probabilistic model allows us to es-
timate translation probabilities that are condi-
tioned on the whole source document. The
assumption of our probabilistic model is that
each document can be characterized by a dis-
tribution over topics that help to solve the
translation ambiguity of single words. Us-
ing the derived translation probabilities, we
then calculate the expected word frequency of
each word type in the target language. Fi-
nally, these expected word frequencies can be
used to classify the source text with any classi-
fier that was trained using only target language
documents. Our experiments confirm the use-
fulness of our proposed method.

1 Introduction

Text classification is ubiquitous in natural language
processing. It’s applications range from simple topic
detection, like articles about sport vs articles about
computers, to sentimental analysis, and subtle dis-
crimination of Tweets that report the abuse of drugs
or the metaphoric use of drugs (“love is like a drug”).
Text classification hugely relies on manually anno-
tated training data in one language.

However, creating training data for each language
is expensive, and therefore, we are interested in us-
ing training data given in only one language (e.g.

English, denoted as target language) to classify text
written in a different language (e.g. Chinese, or
Japanese, denoted as source language).

Our approach addresses this issue by using a sim-
ple bilingual dictionary. Bilingual dictionaries have
the great advantage that they are available often for
free1, and have good coverage for major languages,
like Chinese and Japanese. With the help of the dic-
tionary, we calculate the expected frequency of each
word in the target language. Finally, we create a fea-
ture vector in the target language that is used as input
for the text classifier.

However, due to the translation ambiguity of a
word in the source language, it is important to care-
fully choose the translation probability for calculat-
ing the expected frequencies of the target words. For
example, consider a Japanese news article that con-
tains the word 拘束 (restrict, restrain, in custody),
and we want to find out whether the article is about
“foreign policy” or not. The most simple method
is to use all its English translations, and assume
a uniform distribution over them, i.e. {0.33, 0.33
and 0.33}. However, depending on the topic of the
news article, the translation “in custody” is more ap-
propriate. For example, if the article reports about
a crime/crime suspect, the translation “in custody”
is more likely than “restrict” and “restrain”. Con-
versely, if the article is about “military”, the trans-
lation “in custody” is less likely. Moreover, an arti-
cle that is about the topic “military” is more likely
to belong to the class “foreign policy”. This exam-
ple demonstrates the importance of estimating good
translation probabilities in order to improve the clas-

1For example from Wikitionay.org under Creative Com-
mons Licence.

1466



sification of the source text.
Therefore, we propose a probabilistic model that

uses latent document topics to help improve the
translation probabilities for a source document. Our
experiments, on three different pairs of corpora, con-
firm that our probabilistic model for estimating word
translation probabilities is helpful for cross-lingual
text classification.

2 Related Work

The work in (Wu et al., 2008) and (Shi et al.,
2010) uses a bilingual dictionary for cross-lingual
text classification. The method described in (Wu et
al., 2008) is motivated by transfer learning to adjust
the class probability p(c) to account for the differ-
ences in distributions between source and target lan-
guage. Similar to our work, in the first step, they
generate a probabilistic bilingual lexicon that con-
tain word translation probabilities p(e|f). However,
one main difference to our work is that they translate
each source word f in source text F independently,
without considering any topic or context information
of F .

Instead of translating the source text into the tar-
get language, the method in (Shi et al., 2010) sug-
gests to translate the target classification model into
the source language. They directly estimate the
translation probabilities p(f |e, c) using the source
and target language data. One limitation of their
method is that it assumes that the class of the docu-
ment, that we want to translate, is given.

Our idea of learning word translation probabili-
ties in context is related to the work in (Koehn and
Knight, 2000). They describe an efficient method for
learning word translation probabilities p(f |e) using
a bilingual dictionary and a pair of comparable cor-
pora2. Like our approach, their method has the ad-
vantage that no parallel corpora are needed for trans-
lation. However, to solve the ambiguity of word-
translation they considered only (local) bi-gram con-
text. Moreover, their method assumes that the word
order in the languages are the same. This is obvi-
ously not the case for language pairs like English
and Japanese.

We note that the bilingual paired topic model,
2Two corpora written in different languages which do not

need to be translations of each other

suggested in (Jagarlamudi and Gao, 2013), can also
be used to disambiguate and select the appropriate
word translations by using the topic associated with
the given document. However, their model does not
consider the use of a document class, and uses fixed
word translation probabilities. In Section 3.2, we
show that our model can also be used to learn the
translation probabilities.

Alternatively, the multi-lingual topic model de-
scribed in (Ni et al., 2011), and the use of a common
low-dimensional projection described in (Platt et al.,
2010) have also been applied to the cross-lingual
text classification problem. However, both models
require for training that cross-lingually aligned doc-
uments are available.

3 Proposed Method

Our proposed method does not use one translation
of F , but implicitly generates all translations and
weights them by the probability of each translation.
More formally, let E be one translation of source
text F . Moreover, let countE(e) denote the fre-
quency of word e in E. Instead of using countE(e),
we use the expected number of word occurrences de-
noted by E[countE(e)|F ] as features. When we use
a simple uni-gram language model in the source lan-
guage we get:

E[countE(e)|F ] =
k∑

j=1

p(ej = e|fj) (1)

where we might write F as (f1, f2, f3, ...fk), where
fj is the j-th word in F , and k is the number of words
in source text F .3 The random variable ej denotes
the translation of the j-th word in F . However, such
a simple model translates each source word indepen-
dently and ignores the context of the word.

In the following, we describe a probabilistic
model that allows us to consider the whole document
context F into account for translating one word fj .
The generative story is as follows:

1. For each document, we generate a class label c
with probability υc. Here we consider only the
binary classification task with class label “pos-
itive”, or “negative”.

3Here “word” refers to a word occurrence (and not unique
word). Therefore, k is the length of the source text F .

1467



2. For each document, we generate a topic z with
probability πz|c.

3. Given topic z, we generate each word e in the
target language document independently from
a categorical distribution with probability ϑe|z .

4. For each word e in the target language, we gen-
erate a word f in the source language inde-
pendently from a categorical distribution with
probability θf |e.4

Under this model, for one target docu-
ment (e1, ..., ek) and its corresponding source
document (f1, ..., fk), the joint probability
p(z, c, e1, ..., ek, f1, ..., fk) is

υcπz|c
k∏

j=1

ϑej |z · θfj |ej .

The parameter vector ϑz specifies the target word
probabilities ϑe|z that can be learned from the target
language training data as described in Section 3.1.
The parameter vector θe specifies the word transla-
tion probability θf |e for a target word e into a source
language word f . These word translation probabil-
ities are determined with the help of the bilingual
dictionary as described in Section 3.2.

Our goal is to estimate the translation probability
p(e|fj , F ), since this allows us to calculate

E[countE(e)|F ] =
k∑

j=1

p(ej = e|fj , F ) . (2)

Note, that under our proposed probabilistic model, it
holds that

p(ej |fj , F ) =
∑

z

p(ej |fj , z) · p(z|F ) .

This can be interpreted as follows. First, the model
determines a probability distribution over the latent
topics, conditioned on the given input source docu-
ment, i.e. p(z|F ). And then, second, the model uses
the conditional probability p(z|F ) to determine the

4It might seem that we need cross-lingually aligned docu-
ments, or documents of same length in both languages. How-
ever, both is not the case, since in our experiments the trans-
lations will always be unobserved, and therefore sum over all
possible translations.

translation probability for each word in the source
document, i.e. p(ej |fj , z).

The actual calculation of p(ej = e|fj , F ) can be
derived as follows.5

p(ej |fj , F ) = p(ej |f1, ..., fk)
∝ p(ej , f1, ..., fk)
=

∑
c

∑
z

p(ej , f1, ..., fk|z)p(z|c)p(c) ,

where the probability p(ej , f1, ..., fk|z) can be effi-
ciently calculated using∑

el1∈V
...

∑
elk−1∈V

p(e1, . . . , ek, f1, . . . , fk|z)

=
∑

el1∈V
...

∑
elk−1∈V

k∏
j′=1

θfj′ |ej′ · ϑej′ |z

= θfj |ej · ϑej |z
∏

j′∈{l1...lk−1}

∑
ej′∈V

θfj′ |ej′ · ϑej′ |z ,

where the indexes l1 . . . lk−1 correspond to
1, . . . , j − 1, j + 1, . . . k.

3.1 Learning υc, πz|c, and ϑe|z
Note that under our model, class c and topic z are in-
dependent from f1, ..., fk given document e1, ..., ek
in the target language. Therefore, the parameters
υc, πz|c, and ϑe|z can be learned solely using the
training documents in the target language. Given a
collection of training documents with known classes
D = {(E1, c1)..., (En, cn)}, we can estimate the pa-
rameters as follows.

Parameter υc is estimated using the maximum-
likelihood (ML), which is

υ∗c =
∑n

i=1 1c(ci)
n

, (3)

where 1x(y) is the indicator function which is 1, if
x = y, otherwise 0.

The optimal ML-estimate of ϑe|z and πz|c can
be found by maximizing log p(D|ϑ, π), for which,
however, an analytic solution cannot be derived.
Therefore, instead, we use the EM-algorithm

5When it is clear from the context, we write p(ej) instead of
p(ej = e).

1468



(Dempster et al., 1977), deriving for the E-step: set-
ting the probability distribution q to

p(zi|D, ϑ, π) ∝ πzi|ci
ki∏

j=1

∑
ej

ϑej |zi , (4)

and in the M-step:

ϑ∗e|z =
∑n

i=1

∑ki
j=1 1e(ej) · q(zi = z)∑n

i=1

∑ki
j=1 q(zi = z)

(5)

and

π∗z|c =
∑n

i=1 1c(ci) · q(zi = z)∑n
i=1 q(zi = z)

. (6)

3.2 Learning θf |e
Here we propose to chose the translation probabili-
ties θf |e with highest probability, under our current
model, and such that the probability of observing
the source documents (without labels) is maximized.
Formally, given a collection of source documents
D′ := F1, ..., Fm, the optimal translation probabil-
ity θ∗f |e is

argmax
θf|e

p(D′|θf |e, υ∗c , π∗z|c, ϑ∗e|z) ,

where υ∗c , π∗z|c, ϑ
∗
e|z are the parameters learned in the

previous section. Unfortunately, the exact optimiza-
tion is intractable, and therefore, we resort again to
an EM-approximation, analogously to before.

The E-step corresponds to setting for each source
document i, the probability q(ei,1, ..., ei,ki) to

p(ei,1, ..., ei,ki |fi,1, . . . fi,k, θf |e)

∝
∑
ci

∑
zi

p(ci)p(zi|ci)
k∏

j=1

p(ei,j |zi)θfi,j |ei,j .

In the M-step, we update θf |e to

θ∗f |e =
∑m

i=1

∑ki
j=1 1f (fj,i) · q(ei,j = e)∑m

i=1

∑ki
j=1 q(ei,j = e)

.

4 Experiments

For our experiments we use three pair of corpora
denoted by NEWS, WEB, and TWEETS. The cor-
pora NEWS contains news articles in English and

Method NEWS WEB TWEETS
Co 0.687 (0.68) 0.842 (0.84) 0.430 (0.18)
Co (freq) 0.668 (0.68) 0.849 (0.83) 0.424 (0.20)
Co (uni) 0.666 (0.68) 0.842 (0.83) 0.426 (0.22)
Wu et al. 0.632 (0.56) 0.849 (0.74) 0.391 (0.13)
Freq 0.635 (0.58) 0.842 (0.76) 0.376 (0.13)
Uniform 0.628 (0.53) 0.856 (0.76) 0.407 (0.13)
CN/JA only 0.816 (0.81) 0.893 (0.90) 0.894 (0.89)
EN only 0.718 (0.67) 0.967 (0.97) 0.682 (0.67)

Table 1: Shows the break-even point (f1-score) of the pro-
posed method Co and three baselines for each pair of cor-
pora. Co (freq) and Co (uni) denote the proposed method
without estimation of dictionary probabilities, but instead
using word frequency and uniform distribution, respec-
tively.

Japanese crawled from Internet news sites during
2012-2013, and were annotated as being related to
“foreign policy” or not related. The corpora WEB
contains web pages in English and Chinese that are
categorized either as “sport” or “computer” in the
Open Directory Project (ODP)6 crawled in 2013.
TWEETS contains tweets in English and Chinese
gathered during 2013, classified as related to “vio-
lence”, or not related.7

We tokenize and stem the words in the English
corpora using Senna (Collobert et al., 2011). For
Chinese and Japanese we use the morphological an-
alyzers described in (Qiu et al., 2013), and an in-
house analyzer, respectively. The Chinese to English
dictionary, and the Japanese to English dictionary
contains translations for 94351 and 1483440 words,
respectively.

For the classification we use LIBSVM (Chang
and Lin, 2011) with linear kernel, and the feature
representation as suggested in (Rennie et al., 2003).

For the parameter estimation of our proposed
model we use EM, as described in Section 3.1 and
3.2.8 The number of topics was determined by opti-
mizing the f1-measure using only the English train-
ing data when applying the probabilistic model to
monolingual text classification. In order to prevent
non-zero probabilities, we use a symmetric Dirichlet

6www.dmoz.com
7The number of documents in the corpora pairs for

source/target language are 2472/2289, 1302/6294, and
2005/1499 for NEWS, WEB and TWEETS, respectively.

8We observed convergence for less than 50 iterations.

1469



prior.
We compare our proposed method “Co” to four

different baselines that also use solely a bilingual
dictionary. For all methods (baselines and pro-
posed), we use Equation (2) to estimate the expected
word frequencies. The baseline “Wu et al.” refers
to the method proposed in (Wu et al., 2008). The
baseline “Freq” sets the probability p(e|f) to be pro-
portional to the word frequency in the training data.
Analogously, the baseline “Uniform” assumes a uni-
form probability over all translations of f .

For measuring the performance of each text clas-
sifier we use precision and recall. The break-even
point9 and the f1-measure of our proposed method
and all baselines are shown in Table 1. As can be
seen, our method performs favorable for the NEWS
and TWEETS corpora. For the WEB corpora pair
and our proposed method is at par with the base-
line “Wu et al.”, and looses slightly to the “Uni-
form” baseline. For reference, we also show the up-
per bounds “CN/JA only” and “EN only” that train
and test in the same source and target language, re-
spectively.10

We also analyzed the contribution of using the
word translation probabilities learned in Section 3.2.
The method “Co (freq)” is the same as our pro-
posed method, except that the translation proba-
bilities p(f |e) are not estimated using the method
described in Section 3.2, but instead simply uses
the word-frequency distribution. Analogously, the
method “Co (uni)” is the same as our proposed
method, except that p(f |e) is set to the uniform
probability for all translations of e. Limiting the dis-
cussion to break-even points, we see, in Table 1, an
improvement of around 2 percent points for NEWS,
but only minor changes in performance for the other
two corpora (WEB and TWEETS).

Finally, we give an example which shows the
translation probabilities for the word 拘束 (restrict,
restrain, custody) for two different source docu-
ments in NEWS. The first source document F1 re-
ports a military action, and is labeled as “foreign
policy”. The second document F2 is a news article
about terror, and is labeled as “not foreign policy”.
The results shown in Table 2, confirm our intuition,

9That is the point where precision and recall are equal.
10These results were acquired using cross-validation.

that the translation “custody” is more likely in doc-
uments related to crime.

e = restrict e = restrain e = custody
p(e|f, F1) 0.33 0.10 0.57
p(e|f, F2) 0.02 0.00 0.98

Table 2: Shows the translation probabilities for the source
word f = 拘束, within document F1 (military related,
class is “foreign policy”) and document F2 (terror related,
class is not “foreign policy”).

5 Conclusions

In contrast, to most previous work, we focused
on the word translation problem, rather than the
domain-adaptation problem for cross-lingual text
classification. We have proposed a probabilistic
model that allows us to estimate word-translation
probabilities that are conditioned on the whole
source document. Our experiments on three differ-
ent pairs of corpora, show that our estimated transla-
tion probabilities can improve text classification ac-
curacy, and that our estimated word translation prob-
abilities are able to reflect the topic of a text.

References
Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM:

A library for support vector machines. ACM Transac-
tions on Intelligent Systems and Technology, 2:27:1–
27:27. Software available at http://www.csie.
ntu.edu.tw/∼cjlin/libsvm.

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011.
Natural language processing (almost) from scratch.
The Journal of Machine Learning Research, 12:2493–
2537.

Arthur P Dempster, Nan M Laird, Donald B Rubin, et al.
1977. Maximum likelihood from incomplete data via
the em algorithm. Journal of the Royal statistical So-
ciety, 39(1):1–38.

Jagadeesh Jagarlamudi and Jianfeng Gao. 2013. Mod-
eling click-through based word-pairs for web search.
In Proceedings of the ACM SIGIR Conference, pages
483–492. ACM.

P. Koehn and K. Knight. 2000. Estimating word trans-
lation probabilities from unrelated monolingual cor-
pora using the em algorithm. In Proceedings of the
National Conference on Artificial Intelligence, pages
711–715. Association for the Advancement of Artifi-
cial Intelligence.

1470



Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.
2011. Cross lingual text classification by mining mul-
tilingual topics from wikipedia. In Proceedings of
the ACM International Conference on Web Search and
Data Mining, pages 375–384. ACM.

John C Platt, Kristina Toutanova, and Wen-tau Yih. 2010.
Translingual document representations from discrimi-
native projections. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing, pages 251–261. Association for Computational
Linguistics.

Xipeng Qiu, Qi Zhang, and Xuanjing Huang. 2013. Fu-
dannlp: A toolkit for chinese natural language process-
ing. In Proceedings of Annual Meeting of the Associ-
ation for Computational Linguistics.

Jason D Rennie, Lawrence Shih, Jaime Teevan, and
David R Karger. 2003. Tackling the poor assump-
tions of naive bayes text classifiers. In Proceedings
of the International Conference on Machine Learning,
volume 3, pages 616–623.

Lei Shi, Rada Mihalcea, and Mingjun Tian. 2010. Cross
language text classification by model translation and
semi-supervised learning. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, pages 1057–1067. Association for Com-
putational Linguistics.

Ke Wu, Xiaolin Wang, and Bao-Liang Lu. 2008. Cross
language text categorization using a bilingual lexicon.
In Proceedings of the International Joint Conference
on Natural Language Processing, pages 165–172.

1471


