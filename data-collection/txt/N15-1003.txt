



















































Improving unsupervised vector-space thematic fit evaluation via role-filler prototype clustering


Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 21–31,
Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics

Improving unsupervised vector-space thematic fit evaluation
via role-filler prototype clustering

Clayton Greenberg, Asad Sayeed and Vera Demberg
Computational Linguistics and Phonetics / M2CI Cluster of Excellence

Saarland University
66123 Saarbrücken, Germany

{claytong,asayeed,vera}@coli.uni-saarland.de

Abstract

Most recent unsupervised methods in vector
space semantics for assessing thematic fit (e.g.
Erk, 2007; Baroni and Lenci, 2010; Sayeed
and Demberg, 2014) create prototypical role-
fillers without performing word sense disam-
biguation. This leads to a kind of sparsity
problem: candidate role-fillers for different
senses of the verb end up being measured by
the same “yardstick”, the single prototypical
role-filler.

In this work, we use three different feature
spaces to construct robust unsupervised mod-
els of distributional semantics. We show that
correlation with human judgements on the-
matic fit estimates can be improved consis-
tently by clustering typical role-fillers and
then calculating similarities of candidate role-
fillers with these cluster centroids. The sug-
gested methods can be used in any vector
space model that constructs a prototype vec-
tor from a non-trivial set of typical vectors.

1 Introduction

Thematic fit estimations can be quite useful for
many NLP applications and also for cognitive mod-
els of human language processing difficulty, since
human processing difficulty is highly sensitive to
semantic plausibilities (Ehrlich and Rayner, 1981).
For example, we expect that after the word mash,
banana would be easier to process because it fits
well as the patient, or direct object, of mash, but
milk would be harder to process because it does not
fit well.

A common method for estimating the thematic fit
between a verb and a proposed role filler involves
computing a centroid, or vector average, over the
most typical role fillers for that verb, and then cal-
culating the cosine similarity between this centroid
and the proposed role filler (Baroni and Lenci, 2010;
Blacoe and Lapata, 2012; Erk, 2012). For instance,
we use the cosine of the angle between the banana
vector and a vector average of the 20 nouns that,
according to training data, are most likely to be
mashed as a score for how well banana fits as the
patient of mash. Hopefully, the banana vector will
be closer to the centroid than milk, so banana will
have a higher cosine similarity to the centroid, and
thus a higher thematic fit score, than milk.

This conceptualization assumes that the most typ-
ical fillers for a verb-role will all be variants of a
single prototype, i.e. distributionally similar to each
other. However, such an assumption may not be
true for ambiguous verbs. A verb with many dif-
ferent senses may have typical fillers for each sense,
which fit relatively equally well, but are distribution-
ally very different from one another. This means that
the calculated prototypical filler will be a mixture
of the arguments that are typical role fillers for the
main senses of the verb. For example, consider the
verb serve, for which the 24 most typical preposi-
tional arguments related via the preposition with fall
into three different senses, as illustrated in Figure 1.

Supposing that the centroid occupies a part of the
vector space between two typical role fillers, but is
relatively far from any one of the typical role fillers
from which it was composed, as in Figure 1, none of
the original typical role fillers will achieve high the-

21



overall	  	  
centroid	  

regiment	  

Verb	  serve,	  “with”-­‐preposi9onal	  object	  

ba;alion	  
squadron	  

army	  
no
9c
e	  

or
de
r	  

sauce	  
salad	  

meal	  

wine	   cluster	  3	  
centroid	  

cluster	  2	  
centroid	  

cluster	  1	  
centroid	  

Figure 1: Illustration of TypeDM centroid for with-PP
arguments of the verb serve.

matic fit scores. Also, verbs will be “penalized” for
having many senses in that it will seem as though no
role filler fits as well as they do with unambiguous
verbs. This may produce inconsistent judgements
when comparing one verb that is highly polysemous
with a second, more restrictive verb whose mean-
ing overlaps with the most dominant meanings of
the first verb. For example, cut can be used in the
sense of “cutting costs,” which carries with it re-
strictions on instruments, locations, and so on that
somewhat overlap with eliminate as in “eliminating
costs.” Things that are plausible to be eliminated
are also plausible to be cut. But cut is also used in
the sense of “cutting a cake” or “cutting (editing) a
film.” Without taking word sense into account, costs
would be judged by the model as being less appro-
priate as a patient of cut than it should, and also its
score for filling the patient role of eliminate would
be infelicitously higher than its score for filling the
patient role of cut.

One possible solution to this problem would be
to do full word sense disambiguation on the re-
sources from which these vector spaces are con-
structed. Then, there would be separate entries in
the space for each meaning. This would however
increase the overall size of the vector space by a sig-
nificant factor and also cause an additional burden
on corpus construction and annotation, even if auto-
matic.

In this paper, we will approach the verb-role sense
problem by clustering the most typical role-filler
vectors and calculating the maximal cosine similar-
ity for a candidate role filler with respect to each

cluster prototype vector. So, to estimate the the-
matic fit of salad as an item with which something
is served, in the vector space represented by Fig-
ure 1, we would use the cosine similarity with the
nearest cluster centroid, the cluster 1 centroid. For
a thematic fit task, the correlation between calcu-
lated estimates and human judgements can be ex-
pected to improve. In particular, good role fillers
that are very different from one another and belong
to different senses of a verb can all be assigned the-
matic fit scores as high as those of good role fillers
of monosemous verbs.

We will evaluate our system using three distribu-
tional spaces: TypeDM (Baroni and Lenci, 2010),
which is based on a syntactic dependency parser,
SDDM (Sayeed and Demberg, 2014), which uses
features obtained from the semantic role labeller
SENNA (Collobert et al., 2011), and SDDMX , a
novel extension of SDDM . This way, we can draw
conclusions about feature space-specific and feature
space-general trends.

The effects of clustering and choice of distri-
butional space will be evaluated against the Padó
(2007) and McRae et al. (1998) datasets of hu-
man judgements on thematic fit of agent and patient
roles, and the Ferretti et al. (2001) datasets of human
judgements on thematic fit of instrument and loca-
tion roles. These different roles are conceptually in-
teresting to compare, as instruments tend to be more
strongly constrained by verbs than locations.

2 Background and related work

2.1 Thematic fit

The fit of a filler of a thematic role can be character-
ized as a semantic constraint on what can fill poten-
tially available syntactic slots for a given predicate.
For example, not every noun can satisfy the agent
or patient roles of the typically transitive verb eat.
There must be a valid “eater” for the agent and a
valid “eatee” for the patient. Some nouns are simply
more plausible than others in these positions: lunch
is eaten, but rarely ever eats. But there can also be
optional role assignments: there are certain utensils
with which one is more or less likely to eat (i.e.,
appropriate instrument role-fillers) and even places
where one is more or less likely to eat (i.e., location
roles).

22



Verb Noun Semantic role Score
advise doctor agent 6.8
advise doctor patient 4.0
confuse baby agent 3.7
confuse baby patient 6.0
eat lunch agent 1.1
eat lunch patient 6.9
kill lion agent 2.7
kill lion patient 4.9
kill man agent 3.4
kill man patient 5.4

Table 1: Sample of judgements from Padó (2007).

In order to model thematic roles, we use the in-
sight that thematic fit correlates with human plau-
sibility judgements (Padó et al., 2009; Vandekerck-
hove et al., 2009). Therefore, we can use datasets
of human plausibility judgements to evaluate com-
putational thematic fit estimates. One such dataset
by Padó (2007) includes 18 verbs with up to 12 can-
didate nominal arguments and totals 414 verb-noun-
role triples. The words were chosen based on their
frequencies in the Penn Treebank and FrameNet.
Human participants were asked to rate the appropri-
ateness of given nouns as agents and as patients for
given verbs on a scale from 1 to 7. The judgements
were then averaged. We provide a small sample of
these judgements in Table 1.

We use three other datasets as well. Ferretti et al.
(2001) provide two datasets, one with 248 verb-
instrument pairs and one with 274 verb-location
pairs. Additionally, McRae et al. (1998) give a
dataset of 1444 more agent/patient judgements. We
write agent/patient as such because like Padó (2007),
the agent plausibility and patient plausibility are
given in the same dataset, albeit separately. Once
again, human participants were asked to rate the ap-
propriateness of given nouns as locations, instru-
ments, and agents/patients, respectively, of the verbs
in each dataset on a scale from 1 to 7. We will make
use of these in our evaluation in order to see how
well the models and algorithms we propose apply to
various thematic roles, not just the most commonly
tested and to-date most accurately estimated roles of
agent and patient.

2.2 Distributional Semantics
2.2.1 Distributional Memory

Our semantic modeling technique comes from
Baroni and Lenci (2010), who developed an explic-
itly multifunctional, i.e. not tightly bound to a par-
ticular task, framework for recording distributional
information about linguistic co-occurrence. Distri-
butional Memory (DM) records frequency informa-
tion about links between words in a sentence as a
third order tensor, in which words or lemmata are
represented as two of the tensor axes and the syntac-
tic or semantic link between them is the third axis.

The following corpora were used to construct the
Baroni and Lenci (2010) version of DM:

• ukWaC, a corpus of about two billion words
collected by crawling the .uk web domain
(Ferraresi et al., 2008).

• WackyPedia, a snapshot selection of Wikipedia
articles.

• The British National Corpus (BNC), a 100-
million word corpus including documents such
as books and periodicals.

The sentences from these sources were first run
through MaltParser (Nivre et al., 2007). The
dependency links (e.g. SBJ, NMOD) were run
through a set of hand-crafted patterns to identify
higher-level lexicalized links (e.g. as-long-as,
in-a-kind-of). They then counted link type fre-
quencies, so that links that involve the same lexi-
cal item (e.g. long, kind, as in the lexicalized
links just mentioned) were collapsed into a single
link, and the number of surface form realizations
was used as the frequency count. All words were
lemmatized and stored with basic part of speech in-
formation.

All these counts were then adjusted by Local Mu-
tual Information (Baroni and Lenci, 2010), which is
given by

LMI(i, j, k) = Oijk log
Oijk
Eijk

(1)

where i, j are words, k is the link between them,
O is the observed frequency, and E is the expected
frequency under independence. Tuples with nonpos-
itive LMI values were removed. They called this
tensor TypeDM .

23



2.2.2 DM Based on Semantic Role Labels
In order to create a competitor to the much

less manually pruned cousin of TypeDM named
DepDM, Sayeed and Demberg (2014) based SDDM
(short for SENNA-DepDM) on similar corpora but
used alternative features. Namely, this tensor was
built from ukWaC and BNC, but the features came
from a semantic role labelling (SRL) system called
SENNA (Collobert and Weston, 2007; Collobert
et al., 2011). SENNA uses a multi-layer neural net-
work architecture that learns in a sliding window
over token sequences working on raw text instead of
syntactic parses, as other semantic role labellers do
(Bohnet, 2010). SENNA extracts word features re-
lated to identity, capitalization, and suffix/tense (ap-
proximated by the last two characters of the word).
From these features, in a process similar to decod-
ing a conditional random field, the network derives
features related to verb position, part of speech, and
chunk membership.

SENNA was trained on PropBank and large
amounts of unlabelled data. It achieves a role la-
belling F-score of 75.49% (in this case, tested on
CoNNL 2005 data), which is slightly lower than
state of the art SRL systems which use parse trees
as input.

SDDM was built by running the sentences from
the input corpora through SENNA and using the role
labels as links between predicates and role-fillers.
Unlike TypeDM , SDDM required almost no fur-
ther processing; the raw frequency counts of triples
were used in the LMI calculation.

In this paper, we present SDDMX , an extended
version of the SDDM model1. SDDMX contains
the same links as SDDM and also contains links be-
tween nouns that belong to the same predicate in-
stance, using the predicate as a link label. For exam-
ple, supposing that during training the system en-
countered the man eats a donut with a role link be-
tween man and eat and another role link between
donut and eat, then in SDDMX , a link was cre-
ated between man and donut. This link was labelled
with the verb lemma for the 400 most frequent verbs
(eat in our example), and vb otherwise.

Sayeed and Demberg (2014) found that although

1We provide SDDM and SDDMX at
http://rollen.mmci.uni-saarland.de/.

the donut was eaten by Bob

NMOD

SBJ

VC

LGS

PMOD

the donut was eaten by Bob

ARG1 V ARG0

Figure 2: The same sentence with MaltParser (above)
and SENNA (below) labels. Sayeed and Demberg (2014)
used a simplified approach similar to the head percola-
tion table of Magerman (1994) to find head nouns from
SENNA annotation.

SDDM is an arguably simpler DM model than
TypeDM , it performs nearly as well as TypeDM on
a thematic fit estimation task using the Padó (2007)
and McRae et al. (1998) agent/patient datasets. They
also found that averaging the thematic fit scores
of SDDM with those of TypeDM outperforms
TypeDM alone and nearly reaches the performance
of a supervised model (Herdağdelen and Baroni,
2009). This suggests that TypeDM and SDDM
cover different aspects of the corpora on which
they were trained. Links generated by SENNA
may directly access semantic role features that
the MaltParser-based TypeDM must infer through
hand-crafted rules, such as tagging the subject as a
patient instead of an agent in passive-voice contexts.
Figure 2 illustrates the differences between the la-
belling approaches.

We make use of the SDDM , SDDMX , and
TypeDM tensors in our experiments to demonstrate
how our techniques improve performance in the-
matic fit modelling across different feature spaces.

2.2.3 Centroid-based thematic fit calculation in
DM

Investigating alternative ways to calculate the-
matic fit over the DM framework is a major goal of
this work, so we now describe the baseline process.

Baroni and Lenci (2010) used the following ap-
proach to estimate thematic fit on the Padó (2007)
agent/patient dataset: To assess the fit of a noun w1
in a role r for a verb w2, they construct a centroid
from the 20 highest-ranked fillers for r with w2 se-
lected by LMI, using the relevant syntactic depen-
dency links, such as subject and object, instead of

24



thematic roles. To illustrate, in order to determine
how well workshop fits as a location for eat, they
would construct a centroid of other locations for eat
that appear in the DM, e.g. kitchen, restaurant, cafe-
teria up to 20.

Each of these top 20 represent a “slice” of the ten-
sor along one of the word axes. One such slice, cor-
responding to w1, is a matrix of links and words to
whichw1 is connected. This tensor slice is collapsed
into a vector whose components are word-link pairs.
This is the vector of w1.

All 20 such vectors are added up and the sum is
the centroid that represents, e.g., the typical loca-
tions of eat. Then a vector is constructed from the
slice of the tensor corresponding to workshop. The
thematic fit score is the cosine of the location cen-
troid of eat and the vector of workshop.

Accessing thematic roles in SDDM and
SDDMX is straightforward, as the links in these
models are PropBank roles. Agent is ARG0, patient
is ARG1, location is ARGM-LOC, and we use a
combination of ARGM-MNR, ARG2, and ARG3 to
represent instruments, based on a translation of
the roles used by Ferretti et al. (2001). The role
mapping for TypeDM involves a combination of
sbj tr and subj intr (transitive and intran-
sitive subjects) for agents, obj for patients, the
prepositional links in, at, and on for locations,
and with for instruments.

2.3 Word Sense Disambiguation in
Distributional Models

While distributional models carry important infor-
mation about the relative frequencies of word us-
ages, and perhaps even phrase usages, they often
must collapse such usages into one representation.
For example, suppose within the domain of cooking
recipes, serve occurs in its food sense (see cluster
1 in Figure 1) 97% of the time. The other senses
will have negligible effect on the representation of
serve because their frequencies are so much lower.
But in a web crawl, the distribution is quite likely to
be more uniform, which means the senses will “split
the difference” in the representation and end up not
being that similar to any instance of serve.

Many systems work to alleviate this problem by
performing manipulations on words as they occur in
training corpora (e.g., Thater et al., 2011). Namely,

the base vector for the potentially ambiguous word
is contextualized, as in scaled element-wise, by the
vectors of the neighboring words for that instance.
This is quite intuitive because if serve and cake oc-
cur next to each other, the chance that a non-food
sense of the word serve was intended would be ex-
tremely small, in fact much smaller than a corpus-
wide distribution would predict. These systems have
been effective at improving correlation with human
judgements for a verb-object composition model,
i.e. approximating a vector for serve cake given
a vector for serve and a vector for cake (Kartsak-
lis et al., 2014), and also reducing noise in simi-
larity scores for a nearest neighbor-based preposi-
tional phrase attachment disambiguator (Greenberg,
2014).

It remains a choice of the system whether to store
explicit senses separately, and relatedly, whether to
consult a knowledge base for the number of senses
for each word, or even for meaning representations
of those senses. Using a task-general knowledge
base, in addition to the inherent cost of building
one, is not particularly suited for our task because
the items to be disambiguated are verb-role pairs, as
opposed to just verbs, and usually such knowledge
bases do not handle individual thematic roles sepa-
rately. For instance, it may be optimal to analyze
serve as having three senses with respect to instru-
ments, two senses with respect to patients, and one
sense with respect to agents.

Assigning semantic categories to the slots of a
verb subcategorization frame harks back to work by
Resnik (1996) and Rooth et al. (1999). Resnik’s
work presupposes predefined noun classes obtained
from WordNet. Rooth et al. induced latent role-filler
classes via expectation maximization. Erk et al.
(2010) found that neither are good models of the-
matic fit. Padó et al. (2009) provided thematic fit
scores that take into account verb class using a su-
pervised model. In the vector space context, in-
ducing different vectors for multiple verb senses has
been investigated recently by Reisinger and Mooney
(2010), Huang et al. (2012), and Neelakantan et al.
(2014), although these were not focused on role-
fillers for verbs. Our contribution is to make use of a
large-scale, unsupervised vector space model to pro-
vide thematic fit scores after inducing implicit verb
sense classes relative to thematic role.

25



3 Methods

We begin our discussion of sense disambiguation for
thematic fit with the following insight: the baseline
(Centroid ) method takes as input a set of typical
role-fillers, the highest-ranked ones according to the
DM, and returns a single prototype vector. How-
ever, if we allow the system to return a set of proto-
type vectors, then the framework gains the capacity
to handle multiple senses of the verb-role pair.

The first choice is how to handle the output. Now
instead of one cosine similarity, we would have a set
of cosines corresponding to the similarities between
the test role-filler and each prototype vector in the
set. But if we make the theoretical assumption that
each prototype corresponds to a sense, then roughly
only one should apply at a time. So, we choose to
use the one that is most relevant, i.e. similar, to the
test role-filler. Therefore, we use the maximum of
the cosine similarities as the thematic fit score.

3.1 One best or nearest

In the extreme case, we can just use the unaltered set
of highly-ranked role-fillers as our set of prototypes.
For example, if we query TypeDM for the top four
instrument-fillers of eat, we would retrieve spoon,
hand, bread, and sauce. Then, to assign a thematic
fit score for fork as an instrument-filler, we compute
the cosine similarities of (fork, spoon), (fork, hand),
(fork, bread), and (fork, sauce). The cosine simi-
larity of (fork, spoon) is the highest, so this cosine
determines the score. We refer to this method as
OneBest . Note that OneBest requires the calcu-
lation of a large number of cosines, which is a rel-
atively expensive operation given the sparse repre-
sentations of words in DM spaces.

The number of retrieved top role-fillers (n) ap-
pears to be the only parameter for OneBest . Yet,
this method poses a few theoretical questions. First,
there most likely should be an upper bound on the
number of role-fillers that the system can retrieve at
once. Mathematically, allowing the system to re-
trieve the entire relevant cross-section of the ten-
sor would be equivalent to reducing the thematic fit
evaluation task to a binary decision, i.e. whether the
verb-role has occurred with the test role-filler in the
training data. So, we would not be able to model any
graded effect on the fit of two seen role-fillers, even

if one of them fits with the verb-role better than the
other. Also, psycholinguistically, it seems implausi-
ble that one must remember all of the times that one
has encountered a word in order to use it. Therefore,
we impose 50 as an arbitrary upper bound on n. We
also set a lower bound of 10 on n because values
smaller than this generated quite erratic sets of top
role-fillers.

Second, OneBest might return a cosine of 1.0 if
the DM retrieves the test role-filler itself as one of
the top role-fillers. This could unfairly help the cor-
relation between the cosines returned by the system
and human judgements because the good role-fillers
would all have the same cosine value, thus reducing
the effect of the cosine ratings produced for the more
distant (interesting) role-fillers. Therefore, we pro-
hibit our system from returning any cosines of 1.0.
The test role-filler thus achieves a high score by hav-
ing a closely related role-filler in the prototype set,
not by being present itself.

3.2 Clustering

In order to reduce noise from OneBest , we cluster
similar top role-fillers together, calculate centroids
for each cluster, and use these cluster centroids as
the prototype set. This way, the presence of an
anomalous vector in the centroid set has less effect.
We use the group average agglomerative clustering
package within NLTK (Bird et al., 2009). This algo-
rithm works by initializing each top role-filler in its
own cluster and iteratively combining the two most
similar clusters.

For the stopping criterion, which determines the
final number of clusters for the verb-role, we use the
Variance Ratio Criterion (V RC) method (Caliński
and Harabasz, 1974). Let c be the baseline centroid
of all top role-fillers retrieved, f be a top role-filler,
and cf be the cluster centroid of the cluster to which
f is assigned. Then, this method works by (a) calcu-
lating the V RC metric for each number of clusters
(k), given by

V RC(k) =
SSB
k − 1/

SSW
n− k (2)

where we define

SSB =
∑

f
(1− cos2(cf , c)) (3)

26



and

SSW =
∑

f
(1− cos2(f, cf )) (4)

and then (2) choosing the final number of clusters
such that

ωk = (V RCk+1 − V RCk)− (V RCk − V RCk−1)
(5)

is minimized. Intuitively, this procedure is meant
to find the number of clusters for which adding
another cluster does not explain significantly more
variance in the data. Also, note that the V RC metric
is equivalent to the F-score in a one way ANOVA.

The main drawback of the V RC method is that it
cannot evaluate fewer than three clusters, due to hav-
ing both a V RCk+1 and a V RCk−1 term in Equa-
tion (5). However, as long as enough top role-fillers
are retrieved, it should not hurt the system. Equiva-
lently, we set V RC0 and V RC1 equal to V RC2. To
examine the effect of this choice, we evaluate two
clustering methods: 2Clusters , which chooses two
clusters for every verb-role, and kClusters , which
dynamically chooses a number of clusters between
3 and 10 based on the above criterion.

Once again, the system is prohibited from return-
ing a cosine of 1.0. This means that if the DM re-
trieves the test role-filler itself as one of the top role-
fillers, the system would skip comparing the test
role-filler against itself if it were in a singleton clus-
ter, but would not skip it if it were a member of a
cluster of size two or greater. The alternative to this
would have been removing the test role-filler before
clustering, but we saw these role-filler-specific par-
titions as a form of supervision.

3.3 Evaluation procedure
The Centroid , OneBest , 2Clusters , and kClusters
methods each determine their own prototype vector
set for a verb-role, and then return the maximum co-
sine similarity value for each test role-filler. Proto-
type sets are stored in a dictionary so they can be
reused. It is necessary to expand the sparse data
structure of each vector in order to efficiently com-
pute all of the necessary cosine similarities. Finally,
we calculate Spearman’s ρ values to measure the
correlations between these sets of thematic fit scores
and the four datasets of human judgements.

Dataset SDDM (X ) TypeDM
Padó (2007) 98.6 100.0

McRae et al. (1998) 96.0 95.2
Ferretti et al. (2001) inst. 94.0 93.1
Ferretti et al. (2001) loc. 99.6 98.9

Table 2: Coverage (%) by dataset for each DM model.

10 20 30 40 50

0.
20

0.
30

0.
40

Role−fillers retrieved (n)
S

pe
ar

m
an

's
 r

ho

SDDMX Centroid
SDDMX OneBest
SDDMX kClusters
TypeDM Centroid
TypeDM OneBest
TypeDM kClusters

Figure 3: Spearman’s ρ values for Ferretti et al. (2001)
instruments vs. the number of vectors retrieved.

For our main experiment, we always retrieve the
top 20 highest-ranked role-fillers for the verb-role
pair to compute the prototype set. This allows our
work to be more directly comparable with other im-
plementations. Also, choosing a value of n that
maximizes ρ would make this unsupervised system
more supervised. However, it is useful to know
how the number of top role-fillers retrieved affects
the correlation with human judgements, so as a
follow-up experiment, we evaluate versions of the
Centroid , OneBest , and kClusters methods, with
the SDDMX and TypeDM models, retrieving from
10 to 50 top role-fillers, against the Ferretti et al.
(2001) instruments dataset.

4 Results

In Table 2, we report the coverage percentages for
the DM models on each of the thematic fit datasets.
Note that since SDDM and SDDMX differ only in
the additional links added between existing pairs of
words, their coverages are the same.

Figure 3 shows the relationship between the num-
ber of vectors retrieved from the DM model and the
correlation of the system with human judgements.

27



Padó (2007) agents McRae et al. (1998) agents Ferretti et al. (2001) instruments
SDDM SDDMX TypeDM SDDM SDDMX TypeDM SDDM SDDMX TypeDM

Centroid 0.515 0.528 0.535 0.371 0.394 0.359 0.193 0.274 0.357
OneBest 0.321 0.324 0.464 0.375 0.376 0.431 0.274 0.336 0.394
2Clusters 0.489 0.412 0.522 0.367 0.373 0.370 0.252 0.331 0.388
kClusters 0.281 0.322 0.460 0.396 0.394 0.416 0.335 0.344 0.422

Padó (2007) patients McRae et al. (1998) patients Ferretti et al. (2001) locations
SDDM SDDMX TypeDM SDDM SDDMX TypeDM SDDM SDDMX TypeDM

Centroid 0.511 0.505 0.525 0.133 0.131 0.343 0.187 0.248 0.230
OneBest 0.447 0.467 0.509 0.214 0.233 0.307 0.234 0.276 0.244
2Clusters 0.526 0.498 0.551 0.175 0.166 0.353 0.294 0.249 0.235
kClusters 0.401 0.428 0.555 0.212 0.227 0.350 0.293 0.326 0.289

All from Padó (2007) All from McRae et al. (1998) All datasets
SDDM SDDMX TypeDM SDDM SDDMX TypeDM SDDM SDDMX TypeDM

Centroid 0.512 0.521 0.530 0.237 0.251 0.325 0.258 0.296 0.354
OneBest 0.385 0.395 0.482 0.273 0.287 0.345 0.275 0.304 0.359
2Clusters 0.508 0.458 0.532 0.252 0.256 0.336 0.287 0.289 0.366
kClusters 0.343 0.375 0.503 0.287 0.294 0.359 0.294 0.317 0.385

Table 3: Spearman’s ρ for each method on each dataset and on all datasets together, using the 20 highest ranked words
per verb-role.

The first six sections of Table 3 give the Spear-
man’s ρ values for our four centroid set construction
methods evaluated against the four datasets of hu-
man judgements, organized by thematic role, all us-
ing the 20 highest-ranked words per verb-role. We
note that the ρ value for the Padó (2007) dataset us-
ing TypeDM and the Centroid method is slightly
higher than the value reported in Baroni and Lenci
(2010) due to correcting some transpositions in the
original file. Finally, the last three sections of Table
3 give the performance of each method on the two
whole agent/patient datasets (for comparison with
previous work), as well as on all datasets merged
together.

5 Discussion

While SDDM and SDDMX have marginally bet-
ter coverage than TypeDM , we do not expect that
this had an effect on our results. Figure 3 shows
that for the various numbers of vectors retrieved
from the DM models, kClusters consistently out-
performs OneBest , which consistently outperforms
Centroid on the Ferretti et al. (2001) instruments
dataset. So, using just a single centroid that is a mix-
ture of all possible good role-fillers for a verb leads
to problems due to conflating different word mean-

ings. But at the other extreme, we see how the ρ
values for the OneBest method peak (at n = 13 for
SDDMX and n = 34 for TypeDM ) and then de-
crease instead of increasing monotonically. This is
because we disallowed cosines of 1.0 and because
as we increase the number of vectors retrieved, the
easier it becomes to be close to one of the prototype
vectors, regardless of thematic fit distinctions within
the prototype set.

For the model comparison, we see that while
TypeDM generally performs better than SDDMX
on instruments, clustering reduces the gap consider-
ably. Also SDDMX outperforms TypeDM for all
methods on locations as shown in Table 3. This dif-
ference suggests that locations appear in sufficiently
diverse syntactic configurations such that the hand-
crafted rules from TypeDM do not work well.

From the All datasets section of Table 3, we see
that both OneBest and kClusters improve the ρ val-
ues over the Centroid baseline for all three DM
models. This holds, too, for the individual instru-
ments and locations datasets. Also, the two cluster-
ing methods perform better than Centroid on Padó
(2007) patients with all DM models and on McRae
et al. (1998) patients with TypeDM . The fact that
Centroid performs best on Padó (2007) agents con-

28



firms previous analyses that have shown that the dis-
tribution of objects is more sensitive to verb sense
than subjects. kClusters outperforming OneBest
in a majority of cases suggests that clustering has
successfully smoothed the top role-fillers, thus cap-
turing sense-like patterns in the verb-roles.

As an example of the effect of the kClusters
method, we obtained the following top 20
instrument-fillers for the verb “eat” in 4 clusters us-
ing TypeDM :

• gusto, relish
• family, friend
• chopstick, finger, fork, hand, knife, spoon
• appetite, bread, butter, cheese, food, meal,

meat, mouth, rice, sauce

The V RC method selected 7 to 9 clusters a little
more often than 3 to 6, which is perhaps more clus-
ters than the number of senses we could expect from
a task general knowledge base. We can see from this
example that the four clusters do not all correspond
to separate senses, but instead, they rather nicely
separate out noise from true instruments. Note that
since these role-fillers came from TypeDM , they ap-
peared as the object of “with,” as a proxy for finding
instruments. The true instruments ended up all in the
third cluster, which created a cluster centroid that is
less affected by noise and errors from the syntactic
or semantic parse. So, the higher number of senses
seems appropriate for this task and data.

We attribute the differences in results between
the Padó (2007) and McRae et al. (1998) datasets
to the differences in how these datasets were con-
structed. First, the Padó (2007) dataset contains only
frequent verbs and most, but not all, of the verb-
role pairs contain well-fitting and poorly-fitting role-
fillers. The latter point is especially important be-
cause if the range of human judgements is small
for a certain verb, then it is much more difficult to
achieve a large ρ value regardless of the general per-
formance level of the system. McRae et al. (1998),
however, selected role-fillers much more automat-
ically for their psycholinguistic study, so the data
points do not necessarily reflect a typical sample of
thematic role fitness decisions that occur in natu-
ralistic language samples. So, it makes sense that

the McRae et al. (1998) ρ values are systematically
lower than those of Padó (2007). In fact, the Padó
(2007) ρ values approach the ceiling of 0.6 as ap-
proximated by the supervised system.

Lastly, the effect of clustering was larger on in-
struments and locations than on agents and patients.
A possible explanation is that instruments and lo-
cations are less-precisely defined thematic roles and
better explained by several subclasses, i.e. clusters.
In addition it could be that clustering helps to com-
bat SRL inconsistencies.

6 Conclusions and future work

We show that clustering verb-roles into “senses”
within a vector space framework achieves a higher
correlation with human judgements on thematic fit
over pure Centroid and OneBest methods. While
we demonstrated this using the Distributional Mem-
ory technique by Baroni and Lenci (2010), the
method will also be applicable to other vector space
models.

This task has also been useful for comparing
among DM models and the different thematic fit
datasets. In particular, we can qualitatively eval-
uate how reliable syntax can be for determining
the semantic notion of thematic fit, and the rela-
tive strength of human intuitions on verb-imposed
restrictions on the various roles (agent, patient, in-
strument, and location).

In future work, we can investigate more sophisti-
cated methods of vector clustering (such as expec-
tation maximization and non-negative matrix factor-
ization), interactions with verb and noun frequency,
and interactions with number of word senses from
a task-general knowledge-base such as WordNet. It
would be especially useful to evaluate this system
of a dataset of human judgements with verbs that
systematically vary in polysemy, as this would more
clearly expose the general trends we wish to model
computationally.

Acknowledgments

This research was funded by the German Research
Foundation (DFG) as part of SFB 1102: “Informa-
tion Density and Linguistic Encoding.” Also, the au-
thors wish to thank the three anonymous reviewers
whose valuable ideas contributed to this paper.

29



References

Baroni, M. and Lenci, A. (2010). Distribu-
tional memory: A general framework for corpus-
based semantics. Computational Linguistics,
36(4):673–721.

Bird, S., Klein, E., and Loper, E. (2009). Natural
Language Processing with Python. O’Reilly Me-
dia.

Blacoe, W. and Lapata, M. (2012). A comparison of
vector-based representations for semantic compo-
sition. In Proceedings of the 2012 Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, pages 546–556, Jeju Island, Korea. As-
sociation for Computational Linguistics.

Bohnet, B. (2010). Very high accuracy and fast de-
pendency parsing is not a contradiction. In Pro-
ceedings of the 23rd International Conference on
Computational Linguistics, COLING ’10, pages
89–97, Stroudsburg, PA, USA. Association for
Computational Linguistics.

Caliński, T. and Harabasz, J. (1974). A dendrite
method for cluster analysis. Communications
in Statistics-Simulation and Computation, 3(1):1–
27.

Collobert, R. and Weston, J. (2007). Fast semantic
extraction using a novel neural network architec-
ture. In Proceedings of the 45th Annual Meeting
of the Association of Computational Linguistics,
pages 560–567, Prague, Czech Republic. Associ-
ation for Computational Linguistics.

Collobert, R., Weston, J., Bottou, L., Karlen, M.,
Kavukcuoglu, K., and Kuksa, P. (2011). Natural
language processing (almost) from scratch. The
Journal of Machine Learning Research, 12:2493–
2537.

Ehrlich, S. F. and Rayner, K. (1981). Contextual ef-
fects on word perception and eye movements dur-
ing reading. Journal of verbal learning and verbal
behavior, 20(6):641–655.

Erk, K. (2007). A simple, similarity-based model
for selectional preferences. In Proceedings of the
45th Annual Meeting of the Association of Com-
putational Linguistics, pages 216–223, Prague,

Czech Republic. Association for Computational
Linguistics.

Erk, K. (2012). Vector space models of word mean-
ing and phrase meaning: A survey. Language and
Linguistics Compass, 6(10):635–653.

Erk, K., Padó, S., and Padó, U. (2010). A flexi-
ble, corpus-driven model of regular and inverse
selectional preferences. Computational Linguis-
tics, 36(4):723–763.

Ferraresi, A., Zanchetta, E., Baroni, M., and Bernar-
dini, S. (2008). Introducing and evaluating
ukwac, a very large web-derived corpus of en-
glish. Proceedings of the 4th Web as Corpus
Workshop (WAC-4) Can we beat Google, pages
47–54.

Ferretti, T. R., McRae, K., and Hatherell, A. (2001).
Integrating verbs, situation schemas, and thematic
role concepts. Journal of Memory and Language,
44(4):516–547.

Greenberg, C. (2014). Disambiguating prepositional
phrase attachment sites with sense information
captured in contextualized distributional data. In
Proceedings of the ACL 2014 Student Research
Workshop, pages 71–77, Baltimore, Maryland,
USA. Association for Computational Linguistics.

Herdağdelen, A. and Baroni, M. (2009). BagPack:
A general framework to represent semantic rela-
tions. In Proceedings of the Workshop on Ge-
ometrical Models of Natural Language Seman-
tics, pages 33–40, Athens, Greece. Association
for Computational Linguistics.

Huang, E. H., Socher, R., Manning, C. D., and Ng,
A. Y. (2012). Improving word representations via
global context and multiple word prototypes. In
Proceedings of the 50th Annual Meeting of the
Association for Computational Linguistics: Long
Papers - Volume 1, ACL ’12, pages 873–882,
Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.

Kartsaklis, D., Kalchbrenner, N., and Sadrzadeh, M.
(2014). Resolving lexical ambiguity in tensor re-
gression models of meaning. In Proceedings of
the 52nd Annual Meeting of the Association for
Computational Linguistics (Vol. 2: Short Papers),
pages 212–217, Baltimore, USA. Association for
Computational Linguistics.

30



Magerman, D. M. (1994). Natural Lagnuage Pars-
ing as Statistical Pattern Recognition. PhD thesis,
Stanford University.

McRae, K., Spivey-Knowlton, M. J., and Tanen-
haus, M. K. (1998). Modeling the influence of
thematic fit (and other constraints) in on-line sen-
tence comprehension. Journal of Memory and
Language, 38(3):283–312.

Neelakantan, A., Shankar, J., Passos, A., and Mc-
Callum, A. (2014). Efficient non-parametric esti-
mation of multiple embeddings per word in vector
space. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Process-
ing (EMNLP), pages 1059–1069. Association for
Computational Linguistics.

Nivre, J., Hall, J., Nilsson, J., Chanev, A., Eryigit,
G., Kübler, S., Marinov, S., and Marsi, E. (2007).
Maltparser: A language-independent system for
data-driven dependency parsing. Natural Lan-
guage Engineering, 13(2):95–135.

Padó, U. (2007). The integration of syntax and se-
mantic plausibility in a wide-coverage model of
human sentence processing. PhD thesis, Saarland
University.

Padó, U., Crocker, M. W., and Keller, F. (2009).
A probabilistic model of semantic plausibil-
ity in sentence processing. Cognitive Science,
33(5):794–838.

Reisinger, J. and Mooney, R. J. (2010). Multi-
prototype vector-space models of word meaning.
In Human Language Technologies: The 2010 An-
nual Conference of the North American Chapter
of the Association for Computational Linguistics,
HLT ’10, pages 109–117, Stroudsburg, PA, USA.
Association for Computational Linguistics.

Resnik, P. (1996). Selectional constraints: An
information-theoretic model and its computa-
tional realization. Cognition, 61(1):127–159.

Rooth, M., Riezler, S., Prescher, D., Carroll, G., and
Beil, F. (1999). Inducing a semantically anno-
tated lexicon via em-based clustering. In Pro-
ceedings of the 37th Annual Meeting of the As-
sociation for Computational Linguistics on Com-
putational Linguistics, ACL ’99, pages 104–111,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.

Sayeed, A. and Demberg, V. (2014). Combining
unsupervised syntactic and semantic models of
thematic fit. In Proceedings of the first Italian
Conference on Computational Linguistics (CLiC-
it 2014).

Thater, S., Fürstenau, H., and Pinkal, M. (2011).
Word meaning in context: A simple and effec-
tive vector model. In Proceedings of 5th Inter-
national Joint Conference on Natural Language
Processing, pages 1134–1143, Chiang Mai, Thai-
land. Asian Federation of Natural Language Pro-
cessing.

Vandekerckhove, B., Sandra, D., and Daelemans, W.
(2009). A robust and extensible exemplar-based
model of thematic fit. In EACL 2009, 12th Con-
ference of the European Chapter of the Associa-
tion for Computational Linguistics, Proceedings
of the Conference, Athens, Greece, March 30 -
April 3, 2009, pages 826–834.

31


