Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1290–1298,

Beijing, August 2010

1290

Entity Linking Leveraging

Automatically Generated Annotation 

Wei Zhang†    Jian Su‡ Chew Lim Tan†   Wen Ting Wang‡

National University of Singapore 

†School of Computing 
{z-wei, tancl} 
@comp.nus.edu.sg

Abstract

is 

linking 

for  entity 

Entity linking refers entity mentions in a 
document  to  their  representations  in  a 
knowledge base (KB). In this paper, we 
propose  to  use  additional  information 
sources  from  Wikipedia  to  find  more 
name variations for entity linking task. In 
addition, as manually creating a training 
corpus 
labor-
intensive and costly, we present a novel 
method to automatically generate a large 
scale  corpus  annotation  for  ambiguous 
mentions  leveraging  on  their  unambi-
guous synonyms in the document collec-
tion.  Then,  a  binary  classifier  is  trained 
to filter out KB entities that are not simi-
lar  to  current  mentions.  This  classifier 
not  only  can  effectively  reduce  the  am-
biguities  to  the  existing  entities  in  KB, 
but  also  be  very  useful  to  highlight  the 
new entities to KB for the further popu-
lation. Furthermore, we also leverage on 
the Wikipedia documents to provide ad-
ditional information which is not availa-
ble  in  our  generated  corpus  through  a 
domain  adaption  approach  which  pro-
vides 
improve-
ments.  The experiment results show that 
our  proposed  method  outperforms  the 
state-of-the-art approaches. 

further  performance 

Introduction 

1
The  named  entity  (NE)  ambiguation  has  raised 
serious  problems  in  many  areas,  including  web 

‡ Institute for Infocomm Research 

{sujian, wwang}

@i2r.a-star.edu.sg

people  search,  knowledge  base  population 
(KBP),  and  information  extraction,  because  an 
entity (such as Abbott Laboratories, a diversified 
pharmaceuticals  health  care  company)  can  be 
referred to by multiple mentions (e.g. “ABT” and 
“Abbott”), and a mention (e.g. “Abbott”) can be 
shared by different entities (e.g. Abbott Texas: a 
city in United States; Bud Abbott, an American 
actor;  and  Abbott  Laboratories,  a  diversified 
pharmaceutical health care company).  

Both Web People Search (WePS) task (Artiles 
et al. 2007) and Global Entity Detection & Rec-
ognition task (GEDR) in Automatic Content Ex-
traction 2008 (ACE08) disambiguate entity men-
tions  by  clustering  documents  with  these  men-
tions. Each cluster then represents a unique enti-
ty. Recently entity linking has been proposed in 
this field. However, it is quite different from the 
previous tasks.

Given  a  knowledge  base,  a  document  collec-
tion,  entity  linking  task  as  defined  by  KBP-091
(McNamee and Dang, 2009) is to determine for 
each  name  string  and  the  document  it  appears, 
which knowledge base entity is being referred to, 
or  if  the  entity  is  a  new  entity  which  is  not 
present in the reference KB.  

Compared with GEDR and WePS, entity link-
ing has a given entity list (i.e. the reference KB) 
to  which  we  disambiguate  the  entity  mentions. 
Moreover, in document collection, there are new 
entities which are not present in KB and can be 
used for further population. In fact, new entities 
with  or  without  the  names  in  KB  cover  more 
than half of testing instances. 

1 http://apl.jhu.edu/~paulmac/kbp.html 

1291

Entity linking has been explored by several re-
searchers.  Without  any  training  data  available, 
most  of  the  previous  work  ranks  the  similarity 
between ambiguous mention and candidate enti-
ties through Vector Space Model (VSM). Since 
they  always  choose  the  entity  with  the  highest 
rank as the answer, the ranking approaches hard-
ly  detect  a  situation  where  there  may be  a  new 
entity that is not present in KB. It is also difficult 
to combine bag of words (BOW) with other fea-
tures.  For  example,  to  capture  the  “category” 
information, the method of Cucerzan (2007) in-
volves a complicated optimization issue and the 
approach has to be simplified for feasible com-
putation, which compromises the accuracy.  Be-
sides  unsupervised  methods,  some  supervised 
approaches (Agirre et al. 2009, Li et al. 2009 and 
McNamee et al. 2009) also have been proposed 
recently  for entity  linking.  However,  the  super-
vised  approaches  for  this  problem  require  large 
amount  of  training  instances.  But  manually 
creating a corpus is labor-intensive and costly.  
In this paper, we explore how to solve the enti-
ty linking problem. We present a novel method 
that  can  automatically  generate  a  large  scale 
corpus  for  ambiguous  mentions  leveraging  on 
their  unambiguous  synonyms  in  the  document 
collection.  A binary classifier based on Support 
Vector  Machine  (SVM)  is  trained  to  filter  out 
some  candidate  entities  that  are  not  similar  to 
ambiguous  mentions.  This  classifier  can  effec-
tively reduce the ambiguities to the existing enti-
ties in KB, and it is very useful to highlight the 
new  entities  to  KB  for  the  further  population. 
We also leverage on the Wikipedia documents to 
provide  additional  information  which  is  not 
available in our generated corpus through a do-
main  adaption  approach  which  provides  further 
performance  improvements.  Besides,  more  in-
formation  sources  for  finding  more  variations 
also  contribute  to  the  overall  22.9%  accuracy 
improvements on KBP-09 test data over baseline. 
The remainder of the paper is organized as fol-
lows.  Section  2  reviews  related  work  for  entity 
linking. In Section 3 we detail our algorithm in-
cluding  name  variation  and  entity  disambigua-
tion. Section 4 describes the experimental setup 
and results. Finally, Section 5 concludes the pa-
per.

2 Related Work 

The crucial component of entity linking is the 
disambiguation  process.  Raphael  et  al.  (2007) 
report a disambiguation algorithm for geography. 
The algorithm ranks the candidates based on the 
manually assigned popularity scores in KB. The 
class  with  higher  popularity  will  be  assigned 
higher  score.  It  causes  that  the  rank  of  entities 
would never change, such as Lancaster (Califor-
nia) would always have a higher rank than Lan-
caster  (UK)  for  any  mentions.  However,  as  the 
popularity  scores  for  the  classes  change  over 
time, it is difficult to accurately assign dynamic 
popularity  scores.  Cucerzan  (2007)  proposes  a 
disambiguation approach based on vector space 
model for linking ambiguous mention in a doc-
ument  with  one  entity  in  Wikipedia.  The  ap-
proach ranks the candidates and chooses the ent-
ity  with  maximum  agreement  between  the  con-
textual  information  extracted  from  Wikipedia 
and  the  context  of  a  document,  as  well  as  the 
agreement  among  the  category  tags  associated 
with  the  candidate  entities.  Nguyen  and  Cao 
(2008) refer the mentions in a document to KIM 
(Popov  et  al. 2004)  KB.  KIM  KB  is  populated 
with over 40,000 named entities. They represent 
a mention and candidates as vectors of their con-
textual  noun  phrase  and  co-occurring  NEs,  and 
then the similarity is determined by the common 
terms of the vectors and their associated weights. 
For linking mentions in news articles with a Wi-
kipedia-derived KB (KBP-09 data set), Varma et 
al.  (2009)  rank  the  entity  candidates  using  a 
search  engine.  Han  and  Zhao  (2009)  rank  the 
candidates  based  on  BOW  and  Wikipedia  se-
mantic knowledge similarity. 

All the related work above rank the candidates 
based on the similarity between ambiguous men-
tion and candidate entities. However, the ranking 
approach hardly detects the new entity which is 
not present in KB. 

Some  supervised  approaches  also  have  been 
proposed.  Li  et  al.  (2009)  and  McNamee  et  al. 
(2009)  train  their  models  on  a  small  manually 
created data set containing only 1,615 examples. 
But  entity  linking  requires  large  training  data. 
Agirre  et  al.  (2009)  use  Wikipedia  to  construct 
their  training  data  by  utilizing  Inter-Wikipedia 
links and the surrounding snippets of text. How-
ever,  their  training  data  is  created  from  a         

1292

different  domain  which  does  not  work  well  in 
the targeted news article domain.  
3 Approach
In  this  section  we  describe  our  two-stage  ap-
proach  for  entity  linking:  name  variation  and 
entity disambiguation. The first stage finds vari-
ations for every entity in the KB and  generates 
an  entity  candidate  set  for  a  given  query.  The 
second  stage  is  entity  disambiguation,  which 
links an entity mention with the real world entity 
it refers to. 
3.1 Name Variation 
The  aim  for  Name  Variation  is  to  build  a 
Knowledge  Repository  of  entities  that  contains 
vast amount of world knowledge of entities like 
name  variations,  acronyms,  confusable  names, 
spelling  variations,  nick  names  etc.  We  use 
Wikipedia  to  build  our  knowledge  repository 
since  Wikipedia  is  the  largest  encyclopedia  in 
the  world  and  surpasses  other  knowledge  bases 
in  its  coverage  of  concepts  and  up-to-date 
content.  We  obtain  useful  information  from 
Wikipedia  by  the  tool  named  Java  Wikipedia 
Library 2 (Zesch  et  al.  2008),  which  allows  to 
access all information contained in Wikipedia. 

Cucerzan  (2007)  extracts  the  name  variations 
of  an  entity  by  leveraging  four  knowledge 
sources  in  Wikipedia:  “entity  pages”,  “disam-
biguation  pages”    “redirect  pages”  and  “anchor 
text”.

Entity page in Wikipedia is uniquely identified 
by its title – a sequence of words, with the first 
word always capitalized. The title of Entity Page 
represents  an  unambiguous  name  variation  for 
the entity. A redirect page in Wikipedia is an aid 
to navigation. When a page in Wikipedia is redi-
rected, it means that those set of pages are refer-
ring to the same entity. They often indicate syn-
onym terms, but also can be abbreviations, more 
scientific  or  more  common  terms,  frequent 
misspellings or alternative spellings etc. Disam-
biguation pages are created only for ambiguous 
mentions  which  denote  two  or  more  entities  in 
Wikipedia, typically followed by the word “dis-
ambiguation” and containing a list of references 
to  pages  for  entities  that  share  the  same  name. 
This  is  more  useful  in  extracting  the  abbrevia-

2 http://www.ukp.tu-darmstadt.de/software/JWPL 

tions of entities, other possible names for an ent-
ity etc. Besides, both outlinks and inlinks in Wi-
kipedia  are  associated  with  anchor  texts  that 
represent name variations for the entities.

Using  these  four  sources  above,  we  extracted 
name variations for every entity in KB to form 
the Knowledge Repository as Cucerzan’s (2007) 
method. For example, the variation set for entity 
E0272065  in  KB  is  {Abbott  Laboratories,  Ab-
bott Nutrition, Abbott …}. Finally, we can gen-
erate  the  entity  candidate  set  for  a  given  query 
using  the  Knowledge  Repository.  For  example, 
for  the  query  containing  “Abbott”,  the  entity 
candidate set retrieved is {E0272065, E0064214 
…}.

From our observation, for some queries the re-
trieved  candidate  set  is  empty.  If  the  entity  for 
the  query  is  a  new  entity,  not  present  in  KB, 
empty  candidate  set  is  correct.  Otherwise,  we 
fail to identify the mention in the query as a var-
iation, commonly because the mention is a miss-
pelling  or  infrequently  used  name.  So  we  pro-
pose to use two more sources “Did You Mean” 
and “Wikipedia Search Engine” when Cucerzan 
(2007)  algorithm  returns  empty  candidate  set. 
Our experiment results show that both proposed 
knowledge sources are effective for entity link-
ing. This contributes to a performance improve-
ment on the final entity linking accuracy. 

Did  You  Mean:  The “did you mean” feature 
of  Wikipedia  can  provide  one  suggestion  for 
misspellings of entities. This feature can help to 
correct  the  misspellings.  For  example,  “Abbot 
Nutrition”  can  be  corrected  to  “Abbott  Nutri-
tion”.

Wikipedia  Search  Engine:  This  key  word 
based search engine can return a list of relevant 
entity pages of Wikipedia. This feature is more 
useful in extracting infrequently used name. 

Algorithm  1  below  presents  the  approach  to 
generate the entity candidate set over the created 
Knowledge Repository. RefE(s) is the entity set 
indexed by mention s retrieved from Knowledge 
Repository.  In Step 8, we use the longest com-
mon subsequence algorithm to measure the simi-
larity between strings s and the title of the entity 
page with highest rank. More details about long-
est  common  subsequence  algorithm  can  be 
found in Cormen et al. (2001). 

1293

 

Algorithm 1 Candidate Set Generation 
Input: mention s;      
1: if RefE(s) is empty
2:        s’(cid:197)Wikipedia“did you 
           mean”Suggestion 
3:        If s’ is not NULL  
4:             s (cid:197) s’
5:        else
6:            EntityPageList (cid:197) WikipediaSear
               chEngine(s) 
7:            EntityPage(cid:197)FirstPage of EntityPageL 
               ist 
8:            Sim=Similarity(s,EntityPage.title)
9:            if Sim > Threshold 
10: 
11:          end if 
12:
13: end if 
Output: RefE(s);

 s(cid:197) EntityPage.title

end if 

 

Entity Disambiguation 

3.2
The  disambiguation  component  is  to  link  the 
mention  in  query  with  the  entity  it  refers  to  in 
candidate set. If the entity to which the mention 
refers is a new entity which is not present in KB, 
nil will be returned. In this Section, we will de-
scribe  the  method  for  automatic  data  creation, 
domain adaptation from Wikipedia data, and our 
supervised learning approach as well. 
3.2.1 Automatic Data Creation  
The basic idea is to take a document with an un-
ambiguous reference to an entity E1 and replac-
ing it with a phrase which may refer to E1, E2 or 
others.

Observation: Some full names for the entities 
in the world are unambiguous. This phenomenon 
also appears in the given document collection of 
entity  linking.  The  mention  “Abbott  Laborato-
ries” appearing at multiple locations in the doc-
ument  collection  refers  to  the  same  entity  “a
pharmaceuticals health care company” in KB.

From this observation, our method takes into 
account the mentions in the Knowledge Reposi-
tory associated with only one entity and we treat 
these  mentions  as  unambiguous  name.  Let  us 
take Abbott  Laboratories-{E0272065}  in  the 
Knowledge Repository as an example. We first 

use  an  index  and  search  tool  to  find  the  docu-
ments with unambiguous mentions. Such as, the 
mention “Abbott Laboratories” occurs in docu-
ment LDC2009T13  and  LDC2007T07  in  the 
document  collection.  The  chosen  text  indexing 
and  searching  tool  is  the  well-known  Apache 
Lucene  information  retrieval  open-source  li-
brary3.

Next,  to  validate  the  consistency  of  NE  type 
between  entities  in  KB  and  in  document,      we 
run  the  retrieved  documents  through  a  Named 
Entity  Recognizer,  to  tag  the  named  entities  in 
the  documents.  Then  we  link  the  document  to 
the  entity in  KB  if  the  document  contains  a 
named entity whose name exactly matches with 
the unambiguous mention and type (i.e. Person, 
Organization  and  Geo-Political  Entity)  exactly 
matches  with  the  type  of  entity  in  KB.  In  this 
example, after Named Entity Recognition, “Ab-
bott Laboratories” in document LDC2009T13 is
tagged  as  an  Organization  which  is  consistent 
with the entity type of E0272065 in KB. We link 
the
in 
LDC2009T13 with entity E0272065.  

“Abbott  Laboratories”  occurring 

where 

Finally, we replace the mention in the selected 
documents  with  the  ambiguous  synonyms.  For 
example,  we  replace  the  mention  “Abbott  La-
boratories” in document  LDC2009T13  with
“Abbott” 
Abbott-{E0064214, 
E0272065…} is an entry in Knowledge Reposi-
tory. “Abbott” is ambiguous, because it is refer-
ring not only to E0272065, but also to E0064214 
in Knowledge Repository. Then, we can get two 
instances  for  the  created  data  set  as  Figure  1, 
where one is positive and the other is negative.  

(Abbott, LDC2009T13)  E0272065    +

(Abbott, LDC2009T13)  E0064214    -

          … 

                         +   refer to  -  not refer to

Figure 1: An instance of the data set 

However,  from  our  studies,  we  realize  some 
limitations on our training data. For example, as 
shown  in  Figure  1,  the  negative  instance  for 
E0272065  and 
for 

the  positive 

instance 

3 http://lucene.apache.org 

1294

E0064214  are  not  in  our  created  data  set. 
However,  those  instances  exist  in  the  current 
document  collection.  We  do  not  retrieve  them 
since  there  is  no  unambiguous  mention  for 
E0064214 in the document collection.   

To reduce the effect of this problem, we pro-
pose  to  use  the  Wikipedia  data  as  well,  since 
Wikipedia data has training examples for all the 
entities in KB. Articles in Wikipedia often con-
tain mentions of entities that already have a cor-
responding  article,  and  at  least  the  first  occur-
rence of the mentions of an entity in a Wikipedia 
article must be linked to its corresponding Wiki-
pedia article, if such an article exists. Therefore, 
if  the  mention  is  ambiguous,  the  hyperlink  is 
disambiguating it. Next, we will describe how to 
incorporate Wikipedia data. 

Incorporating  Wikipedia  Data.  The  docu-
ment  collection  for  entity  linking  is  commonly 
from other domains, but not Wikipedia. To ben-
efit from Wikipedia data, we introduce a domain 
adaption  approach  (Daumé  III,  2007)  which  is 
suitable  for  this  work  since  we  have  enough 
“target”  domain  data.  The  approach  is  to  aug-
ment the feature vectors of the instances. Denote 
by X the input space, and by Y the output space, 
in  this  case,  X  is  the  space  of  the  real  vectors 
(cid:2030)(cid:4666)(cid:154)(cid:4667) for the instances in data set and Y= {+1,-1} 
is the label. Ds is the Wikipedia domain dataset 
and Dt
is  our  automatically  created  data  set. 
Suppose for simplicity that X=RF for some F > 0 
(RF is the space  of  F-dimensions).  The  aug-
mented  input  space  will  be  defined  by (cid:1850)(cid:3544) =R3F.
Then, define mappings (cid:2030)s, (cid:2030)t : X (cid:198) (cid:1850)(cid:3544) for map-
ping the Wikipedia and our created data set re-
spectively.  These are defined as follows:

(cid:2030)(cid:2929)(cid:4666)(cid:154)(cid:4667) (cid:3404)(cid:3407) (cid:2030)(cid:4666)(cid:154)(cid:4667)(cid:481) (cid:2030)(cid:4666)(cid:154)(cid:4667)(cid:481) (cid:882) (cid:3408)(cid:3)

(cid:2030)(cid:2930)(cid:4666)(cid:154)(cid:4667) (cid:3404)(cid:3407) (cid:2030)(cid:4666)(cid:154)(cid:4667)(cid:481)(cid:882)(cid:481) (cid:2030)(cid:4666)(cid:154)(cid:4667) (cid:3408)

Where 0=<0,0,…,0> (cid:143)RF is the zero vector. We 
use the simple linear kernel in our experiments. 
However,  the  following  kernelized  version  can 
help us to gain some insight into the method. K
denotes 
two  vectors. 
K(x,x’)=<(cid:3)(cid:2030) (x), (cid:2030) (x’)>.  When  the  domain  is 
the  same,  we  get: (cid:1837)(cid:3569)(cid:4666)(cid:1876)(cid:481) (cid:1876)(cid:4593)(cid:4667) (cid:3404)(cid:3407) (cid:3)(cid:2030)(cid:3)(cid:4666)(cid:1876)(cid:4667)(cid:481) (cid:2030)(cid:3)(cid:4666)(cid:1876)(cid:495)(cid:4667) (cid:3408)
(cid:3397)(cid:3407) (cid:3)(cid:2030)(cid:3)(cid:4666)(cid:1876)(cid:4667)(cid:481) (cid:2030)(cid:3)(cid:4666)(cid:1876)(cid:495)(cid:4667) (cid:3404) (cid:884)(cid:1837)(cid:4666)(cid:1876)(cid:481) (cid:1876)(cid:4593)(cid:4667).  When  they  are 
from  different  domains,  we  get: (cid:1837)(cid:3569)(cid:4666)(cid:1876)(cid:481) (cid:1876)(cid:4593)(cid:4667) (cid:3404)(cid:3407)

the  dot  product  of 

(cid:3)(cid:2030)(cid:3)(cid:4666)(cid:1876)(cid:4667)(cid:481) (cid:2030)(cid:3)(cid:4666)(cid:1876)(cid:495)(cid:4667) (cid:3408)(cid:3404) (cid:1837)(cid:4666)(cid:1876)(cid:481) (cid:1876)(cid:4593)(cid:4667).  Putting  this  togeth-
er, we have: 

(cid:1837)(cid:3569) (cid:3404) (cid:3420)

(cid:3)(cid:884)(cid:1837)(cid:4666)(cid:1876)(cid:481) (cid:1876)(cid:4593)(cid:4667)(cid:3)(cid:3)(cid:149)(cid:131)(cid:143)(cid:135)(cid:3)(cid:134)(cid:145)(cid:143)(cid:131)(cid:139)(cid:144)
(cid:3)(cid:3)(cid:3)(cid:1837)(cid:4666)(cid:1876)(cid:481) (cid:1876)(cid:4593)(cid:4667)(cid:3)(cid:134)(cid:139)(cid:136)(cid:136)(cid:484) (cid:134)(cid:145)(cid:143)(cid:131)(cid:139)(cid:144)(cid:3)

This is an intuitively pleasing result. Loosely 
speaking,  this  means  that  data  points  from  our 
created data set have twice as much influence as 
Wikipedia  points  when  making  predictions 
about test data from document collection. 
3.2.2 The Disambiguation Framework 
To disambiguate a mention in document collec-
tion, the ranking method is to rank the entities in 
candidate  set  based  on  the  similarity  score.  In 
our work, we transform the ranking problem into 
a  classification  problem:  deciding  whether  a 
mention refers to an entity on an SVM classifier.
If  there  are  2  or  more  than  2  candidate  entities 
that  are  assigned  positive  label  by  the  binary 
classifier,  we  will  use  the  baseline  system  (ex-
plained  in  Section  4.2)  to  rank  the  candidates 
and the entity with the highest rank will be cho-
sen.

In the learning framework, the training or test-
ing  instance  is  formed  by  (query, entity) pair.
For Wikipedia data, (query, entity) is positive if 
there  is  a  hyperlink  from  the  article  containing 
the  mention  in  query to  the  entity,  otherwise 
(query, entity) is negative.  Our  automatically 
created data has been assigned labels in Section 
3.2.1.  Based on the training instances, a binary 
classifier is generated by using particular learn-
ing  algorithm.    During  disambiguation,  (query,
entity)  is  presented  to  the  classifier  which  then 
returns a class label.  

Each (query, entity) pair is represented by the 
feature vector using different features and simi-
larity  metrics.  We  chose  the  following  three 
classes of features as they represent a wide range 
of information - lexical features, word-category 
pair, NE type - that have been proved to be ef-
fective  in  previous  works  and  tasks.  We  now 
discuss  the  three  categories  of  features  used  in 
our framework in details. 

Lexical features. For Bag of Words feature in 
Web  People  Search, Artiles  et  al.  (2009)  illu-
strated that noun phrase and n-grams longer than 
2  were  not  effective  in  comparison  with  token-
based features and using bi-grams gives the best 

1295

results  only  reaching  recall  0.7.  Thus,  we  use 
token-based  features.  The  similarity  metric  we 
choose  is  cosine  (using  standard  tf.idf  weight-
ing). Furthermore, we also take into account the 
co-occurring NEs and represent it in the form of 
token-based  features.  Then,  the  single  cosine 
similarity feature is based on Co-occurring NEs 
and Bag of Words. 

Word  Category  Pair.  Bunescu (2007) dem-
onstrated  that  word-category  pairs  extracted 
from  the  document  and  Wikipedia  article  are  a 
good  signal  for  disambiguation.  Thus  we  also 
consider word-category pairs as a feature  class, 
i.e.,  all  (w,c) where w  is  a  word  from  Bag  of 
Words of document and c is a category to which 
candidate entity belongs.  

Experimental Setup 

NE Type. This feature is a single binary fea-
ture to guarantee that the type of entity in docu-
ment  (i.e.  Person,  Geo-Political  Entity  and  Or-
ganization)  is  consistent  with  the  type  of  entity 
in KB. 
4 Experiments and Discussions 
4.1
    In our study, we use KBP-09 knowledge base 
and document collection for entity linking. In the 
current setting of KBP-09 Data, the KB has been 
generated  automatically  from  Wikipedia.  The 
KB contains 818,741 different entities. The doc-
ument  collection  is  mainly  composed  of  news-
wire text from different press agencies. The col-
lection contains 1.3 million documents that span 
from 1994 to the end of 2008. The test data has 
3904  queries  across  three  named  entity  types: 
Person,  Geo-Political  Entity  and  Organization. 
Each query contains a document with an ambi-
guous mention.    

Wikipedia  data  can  be  obtained  easily  from 
the website4 for free research use. It is available 
in the form of database dumps that are released 
periodically.  In  order  to  leverage  various  infor-
mation mentioned in Section 3.1 to derive name 
variations, make use of the links in Wikipedia to 
generate our training corpus and get word cate-
gory information for the disambiguation, we fur-
ther get Wikipedia data directly from the website. 
The version we used in our experiments was re-
leased  on  Sep.  02,  2009.  The  automatically 

4 http://download.wikipedia.org   

created  corpus  (around  10K)  was  used  as  the 
training  data,  and  30K  training  instances  asso-
ciated with the entities in our corpus was derived 
from Wikipedia. 

For  pre-processing,  we  perform  sentence 
boundary  detection  and  Chunking derived  from 
Stanford  parser (Klein  and  Manning,  2003), 
Named  Entity  Recognition  using  a  SVM  based 
system  trained  and  tested  on  ACE  2005  with 
92.5(P) 84.3(R) 88.2(F), and coreference resolu-
tion  using  a  SVM  based  coreference  resolver 
trained and tested on ACE 2005 with 79.5%(P), 
66.7%(R) and 72.5%(F).  

We  select  SVM  as  the  classifier  used  in  this 
paper  since  SVM  can  represent  the  stat-of-the-
art  machine  learning  algorithm.  In  our  imple-
mentation,  we  use  the  binary  SVMLight  devel-
oped  by  Joachims  (1999).  The  classifier  is 
trained with default learning parameters. 

We adopt the measure used in KBP-09 to eva-
luate  the  performance  of  entity  linking.  This 
measure is micro-averaged accuracy: the number 
of  correct  link  divided  by  the  total  number  of 
queries.
4.2

Baseline Systems 

We  build  the  baseline  using  the  ranking  ap-
proach which ranks the candidates based on si-
milarity between mention and candidate entities. 
The entity with the highest rank is chosen. Bag 
of  words  and  co-occurring  NEs  are  represented 
in the form of token-based feature vectors. Then 
tf.idf is employed to calculate similarity between 
feature vectors.  

To  make  the  baseline  system  with  token-
based features state-of-the-art, we conduct a se-
ries  of  experiments.    Table  1  lists  the  perfor-
mances  of  our  token-based  ranking  systems.  In 
our  experiment,  local  tokens  are  text  segments 
generated  by  a  text  window  centered  on  the 
mention. We set the window size to 55, which is 
the  value  that  was  observed  to  give  optimum 
performance  for  the  disambiguation  problem 
(Gooi and Allan, 2004). Full tokens and NE are 
all the tokens and named entities co-occurring in 
the  text  respectively.  We  notice  that  tokens  of 
the  full  text  as  well  as  the  co-occurring  named 
entity  produce  the  best  baseline  performance, 
which we use for the further experiment. 

1296

 

local tokens 

local tokens + NE 
full tokens + NE 

Micro-averaged 

Accuracy 

60.0 
60.6 
61.9 

Table 1: Results of the ranking methods 

Experiment and Result 

4.3
As  discussed  in  Section  3.1,  we  exploit  two 
more knowledge sources in Wikipedia: “did you 
mean”  (DYM)  and  “Wikipedia  search  engine” 
(SE) for name variation step. We conduct some 
experiments to compare our name variation me-
thod using  Algorithm  1  in  Section  3.1 with  the 
name variation method of Cucerzan (2007). Ta-
ble  2  shows  the  comparison  results  of  different 
name  variation  methods  for  entity  linking.  The 
experiments  results  show  that,  in  entity  linking 
task, our name variation method outperforms the 
method  of  Cucerzan  (2007)  for  both  entity  dis-
ambiguation methods. 

Name Variation 

Approaches 
Cucerzan
(2007) 

+DYM+SE 

Ranking
Method 

60.9 

61.9 

Our Disambig-
uation Method 

82.2 

83.8 

Table 2: Entity Linking Result for two name 
variation approaches. Column 1 used the base-
line method for entity disambiguation step. Col-
umn 2 used our proposed entity disambiguation 
method.

Table  3  compares  the  performance  of  different 
methods  for  entity  linking  on  the  KBP-09  test 
data.  Row  1  is  the  result  for  baseline  system. 
Row 2 and  Row 3 show the results training on 
Wikipedia  data  and  our  automatically  data  re-
spectively. Row 4 is the result training on both 
Wikipedia and our created data using the domain 
adaptation method mentioned in Section 3.2.1. It 
shows that our method trained on the automati-
cally  generated  data  alone  significantly  outper-
forms  baseline.  Compared  Row  3  with  Row  2, 
our created data set serves better at training the 
classifier than Wikipedia data. This is due to the 
reason that Wikipedia is a different domain from 
newswire  domain.  By  comparing  Row  4  with 

Row 3, we find that by using the domain adapta-
tion  method  in  Section  3.2.1,  our  method  for 
entity linking can be further improved by 1.5%. 
Likely,  this  is  because  of  the  limitation  of  the 
auto-generated  corpus  as  discussed  in  Section 
3.2.1.  In  another  hand,  Wikipedia  can  comple-
ment  the  missing  information  with  the  auto-
generated corpus. So combining Wikipedia data 
with our generated data can achieve better result. 
Compared with baseline system using Cucerzan 
(2007) name variation method in Table 2, in to-
tal  our  proposed  method  achieves  a  significant 
22.9% improvement.  

 

Baseline 

Wiki 

Created Data 

Wiki (cid:198) Created Data 

Micro-averaged Accu-

racy
61.9 
79.9 
82.3 
83.8 

Table 3: Micro-averaged Accuracy for Entity 

Linking   

     To  test  the  effectiveness  of  our  method  to 
deal with new entities not present in KB and ex-
isting  entities  in  KB  respectively,  we  conduct 
some  experiments  to  compare  with  Baseline.  
Table 4 shows the performances of entity linking 
systems  for  existing  entities  (non-NIL)  in  KB 
and new entity (NIL) which is not present in KB. 
We  can  see  that  the  binary  classifier  not  only 
effectively reduces the ambiguities to the exist-
ing  entities  in  KB,  but  also  is  very  useful  to 
highlight the new entities to KB for the further 
population. Note that, in baseline system, all the 
new  entities  are  found  by  the  empty  candidate 
set of name variation process, while the disam-
biguation component has no contribution.  How-
ever, our approach finds the new entities not on-
ly by the empty candidate set, but also leverag-
ing  on  disambiguation  component  which  also 
contributes to the performance improvement.  

 

Baseline 

Wiki (cid:198) Created 

Data 

non-NIL 
72.6  
79.2 

NIL 
52.4  
87.8  

Table 4: Entity Linking on Existing and New 

Entities

1297

in  KBP-09.  Among 

Finally, we also compare our method with the 
top  5  systems 
them, 
Siel_093  (Varma  et  al.  2009)  and  NLPR_KBP1
(Han and Zhao 2009) use similarity ranking ap-
proach; Stanford_UBC2  (Agirre  et  al.  2009),
QUANTA1 (Li et al. 2009) and hltcoe1 (McNa-
mee et al. 2009) use supervised approach. From 
the  results  shown  in  Figure  2,  we  observe  that 
our  method  outperforms  all  the  top  5  systems 
and the baseline system of KBP-09. Specifically, 
our method achieves better result than both simi-
larity ranking approaches. This is due to the li-
mitations  of  the  ranking  approach  which  have 
been  discussed  in  Section  2.  We  also  observe 
that  our  method  gets  a  5%  improvement  over 
Stanford_UBC2.  This  is  because  they  collect 
their  training  data  from  Wikipedia  which  is  a 
different  domain  from  document  collection  of 
entity  linking,  news  articles  in  this  case;  while 
our automatic data generation method can create 
a  data  set  from  the  same  domain  as  the  docu-
ment  collection.  Our  system  also  outperforms 
QUANTA1  and  hltcoe1  because  they  train  their 
model  on  a  small  manually  created  data  set 
(1,615  examples),  while  our  method  can  auto-
matically generate a much larger data set. 

0.838

0.8217

0.8033 0.7984 0.7884

0.7672

0.571

0.9
0.85
0.8
0.75
0.7
0.65
0.6
0.55
0.5

Figure 2: A comparison with KBP09 systems 

5 Conclusion

 The purpose of this paper is to explore how 
to  leverage  the  automatically  generated  large 
scale annotation for entity linking. Traditionally, 
without any training data available, the solution 
is  to  rank  the  candidates  based  on  similarity. 
However, it is difficult for the ranking approach 

to detect a new entity that is not present in KB, 
and it is also difficult to combine different fea-
tures. In this paper, we create a large corpus for 
entity linking by an automatic method. A binary 
classifier is then trained to filter out KB entities 
that are not similar to current mentions. We fur-
ther  leverage  on  the  Wikipedia  documents  to 
provide other information which is not available 
in our generated corpus through a domain adap-
tion  approach.  Furthermore,  new  information 
sources  for  finding  more  variations  also  contri-
bute  to  the  overall  22.9%  accuracy  improve-
ments on KBP-09 test data over baseline. 

References  
E. Agirre et al. Stanford-UBC at TAC-KBP. In Pro-
ceedings  of  Test  Analysis  Conference  2009  (TAC 
09).

J.  Artiles,  J.  Gonzalo,  and  S.  Sekine.  2007.  The  se-
meval-2007  web  evaluation:  Establishing  a 
benchmark for the web people search task. In Pro-
ceeding of the Fourth International Work-shop on 
Semantic Evaluations (SemEval-2007).

J. Artiles, E. Amigo and J. Gonzalo. 2009. The role 
of  named  entities  in  Web  People  Search.  In  pro-
ceeding of the 47th Annual Meeting of the Associa-
tion for Computational Linguistics. 

R.  Bunescu.  2007.  Learning  for  information  extrac-
tion from named entity recognition and disambig-
uation to relation extraction. Ph.D thesis, Universi-
ty of Texas at Austin, 2007. 

T.  H.  Cormen,  et  al.  2001.  Introduction  To  Algo-
rithms  (Second  Edition).  The  MIT  Press,  Page 
350-355. 

S.  Cucerzan.  2007.  Large-Scale  Named  Entity  Dis-
ambiguation Based on Wikipedia Data. Empirical 
Methods  in  Natural  Language  Processing,  June 
28-30, 2007. 

H. Daumé III. 2007. Frustratingly easy domain adap-
tation. In Proceedings of the 45th Annual Meeting 
of the Association of Computational Linguistics . 

C. H. Gooi and J. Allan. 2004. Cross-document core-
ference on a large scale corpus. In proceedings of 
Human  Language  Technology  Conference  North 
American Association for Computational Linguis-
tics Annual Meeting, Boston, MA. 

X. Han and J. Zhao. NLPR_KBP in TAC 2009 KBP 
Track: A Two-Stage Method to Entity Linking. In 
Proceedings  of  Test  Analysis  Conference  2009 
(TAC 09).

1298

T. Joachims. 1999. Making large-scale SVM learning 
practical.  In  Advances  in  Kernel  Methods  -  Sup-
port Vector Learning. MIT Press. 

D. Klein and C. D. Manning. 2003. Fast Exact Infe-
rence with a Factored Model for Natural Language 
Parsing.  In  Advances 
in  Neural  Information 
Processing  Systems  15  (NIPS  2002),  Cambridge, 
MA: MIT Press, pp. 3-10. 

F. LI  et  al.  THU  QUANTA  at  TAC  2009  KBP  and 
RTE Track. In Proceedings of Test Analysis Con-
ference 2009 (TAC 09).  

P. McNamee and H. T. Dang. 2009. Overview of the 
TAC 2009 Knowledge Base Population Track. In 
Proceedings  of  Test  Analysis  Conference  2009 
(TAC 09).  

P. McNamee  et  al.  HLTCOE  Approaches  to  Know-
ledge Base Population at TAC 2009.  In Proceed-
ings of Test Analysis Conference 2009 (TAC 09).  
H.  T.  Nguyen  and  T.  H.  Cao.  2008.  Named  Entity 
Disambiguation on an Ontology Enriched by Wi-
kipedia.  2008  IEEE  International  Conference  on 
Research, Innovation and Vision for the Future in 
Computing & Communication Technologies. 

B. Popov et al. 2004. KIM - a Semantic Platform for 
Information  Extraction  and  Retrieval.  In  Journal 
of  Natural  Language  Engineering,  Vol.  10,  Issue 
3-4, Sep 2004, pp. 375-392, Cambridge University 
Press.

V.  Raphael,  K.  Joachim  and  M.  Wolfgang,  2007. 
Towards  ontology-based  disambiguation  of  geo-
the  16th
graphical  identifiers.  In  Proceeding  of
WWW workshop on I3: Identity, Identifiers, Identi-
fications, 2007.  

V. Varma et al. 2009. IIIT Hyderabad at TAC 2009. 
In Proceedings of Test Analysis Conference 2009 
(TAC 09).  

T.  Zesch,  C.  Muller  and  I.  Gurevych.  2008.  Extrac-
tiong  Lexical Semantic  Knowledge from  Wikipe-
dia and Wiktionary. In Proceedings of the Confe-
rence  on  Language  Resources  and  Evaluation 
(LREC), 2008.  

