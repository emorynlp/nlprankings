



















































ISTI@SemEval-2 Task 8: Boosting-Based Multiway Relation Classification


Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 218–221,
Uppsala, Sweden, 15-16 July 2010. c©2010 Association for Computational Linguistics

ISTI@SemEval-2 Task #8:
Boosting-Based Multiway Relation Classification

Andrea Esuli, Diego Marcheggiani, Fabrizio Sebastiani
Istituto di Scienza e Tecnologie dell’Informazione

Consiglio Nazionale delle Ricerche
56124 Pisa, Italy

firstname.lastname@isti.cnr.it

Abstract

We describe a boosting-based supervised
learning approach to the “Multi-Way Clas-
sification of Semantic Relations between
Pairs of Nominals” task #8 of SemEval-
2. Participants were asked to determine
which relation, from a set of nine relations
plus “Other”, exists between two nomi-
nals, and also to determine the roles of the
two nominals in the relation.

Our participation has focused, rather than
on the choice of a rich set of features,
on the classification model adopted to de-
termine the correct assignment of relation
and roles.

1 Introduction

The “Multi-Way Classification of Semantic Rela-
tions between Pairs of Nominals” (Hendrickx et
al., 2010) we faced can be seen as the composition
of two sub-tasks:

1. Determining which relation r, from a set of
relations R (see Table 1), exists between two
entities e1 and e2.

2. Determining the direction of the relation, i.e.,
determining which of r(e1, e2) or r(e2, e1)
holds.

The set R is composed by nine “semantically
determined” relations, plus a special Other rela-
tion which includes all the pairs which do not be-
long to any of the nine previously mentioned rela-
tions.
The two novel aspects of this task with respect to
the similar task # 4 of SemEval-2007 (Girju et al.,
2007) (“Classification of Semantic Relations be-
tween Nominals”) are (i) the definition of the task
as a “single-label” classification task and (ii) the

1 Cause-Effect
2 Instrument-Agency
3 Product-Producer
4 Content-Container
5 Entity-Origin
6 Entity-Destination
7 Component-Whole
8 Member-Collection
9 Message-Topic

Table 1: The nine relations defined for the task.

need of determining the direction of the relation
(i.e., Item 2 above).

The classification task described can be formal-
ized as a single-label (aka “multiclass”) text clas-
sification (SLTC) task, i.e., as one in which exactly
one class must be picked for a given object out of
a set of m available classes.

Given a set of objects D (ordered pairs of nom-
inals, in our case) and a predefined set of classes
(aka labels, or categories) C = {c1, . . . , cm},
SLTC can be defined as the task of estimating
an unknown target function Φ : D → C, that
describes how objects ought to be classified, by
means of a function Φ̂ : D → C called the classi-
fier1.

In the relation classification task which is the
object of this evaluation, the set C of classes is
composed of 19 elements, i.e., the nine relations
of Table 1, each one considered twice because it
may take two possible directions, plus Other.

2 The learner

As the learner for our experiments we have used a
boosting-based learner called MP-BOOST (Esuli
et al., 2006). Boosting is among the classes of su-
pervised learning devices that have obtained the
best performance in several learning tasks and,
at the same time, have strong justifications from
computational learning theory. MP-BOOST is a

1Consistently with most mathematical literature we use
the caret symbol (ˆ) to indicate estimation.

218



variant of ADABOOST.MH (Schapire and Singer,
2000), which has been shown in (Esuli et al.,
2006) to obtain considerable effectiveness im-
provements with respect to ADABOOST.MH.

MP-BOOST works by iteratively generating, for
each class cj , a sequence Φ̂

j
1, . . . , Φ̂

j
S of classifiers

(called weak hypotheses). A weak hypothesis is a
function Φ̂js : D → R, where D is the set of doc-
uments and R is the set of real numbers. The sign
of Φ̂js(di) (denoted by sgn(Φ̂

j
s(di))) represents the

binary decision of Φ̂js on whether di belongs to cj ,
i.e. sgn(Φ̂js(di)) = +1 (resp.,−1) means that di is
believed to belong (resp., not to belong) to cj . The
absolute value of Φ̂js(di) (denoted by |Φ̂js(di)|)
represents instead the confidence that Φ̂js has in
this decision, with higher values indicating higher
confidence.

At each iteration s MP-BOOST tests the effec-
tiveness of the most recently generated weak hy-
pothesis Φ̂js on the training set, and uses the results
to update a distributionDjs of weights on the train-
ing examples. The initial distribution Dj1 is uni-
form by default. At each iteration s all the weights
Djs(di) are updated, yieldingD

j
s+1(di), so that the

weight assigned to an example correctly (resp., in-
correctly) classified by Φ̂js is decreased (resp., in-
creased). The weight Djs+1(di) is thus meant to
capture how ineffective Φ̂j1, . . . , Φ̂

j
s have been in

guessing the correct cj-assignment of di (denoted
by Φj(di)), i.e., in guessing whether training doc-
ument di belongs to class cj or not. By using this
distribution, MP-BOOST generates a new weak
hypothesis Φ̂js+1 that concentrates on the exam-
ples with the highest weights, i.e. those that had
proven harder to classify for the previous weak hy-
potheses.

The overall prediction on whether di belongs to
cj is obtained as a sum Φ̂j(di) =

∑S
s=1 Φ̂

j
s(di) of

the predictions made by the weak hypotheses. The
final classifier Φ̂j is thus a committee of S clas-
sifiers, a committee whose S members each cast
a weighted vote (the vote being the binary deci-
sion sgn(Φ̂js(di)), the weight being the confidence
|Φ̂js(di)|) on whether di belongs to cj . For the final
classifier Φ̂j too, sgn(Φ̂j(di)) represents the bi-
nary decision as to whether di belongs to cj , while
|Φ̂j(di)| represents the confidence in this decision.

MP-BOOST produces a multi-label classifier,
i.e., a classifier which independently classifies a
document against each class, possibly assigning
a document to multiple classes or no class at

”<e1>People</e1> have been moving back into
<e2>downtown</e2>.”

Entity-Destination(e1,e2)
F People FS Peopl FH group FP NNP
FS1 have FS1S have FS1H have FS1P VBP
FS2 been FS2S been FS2H be FS2P VBN
FP3 moving FP3S move FP3H travel FP3P VBG
SP3 moving SP3S move SP3H travel SP3P VBG
SP2 back SP2S back SP2H O SP2P RB
SP1 into SP1S into SP1H O SP1P IN
S downtown SS downtown SH city district SP NN
SS1 . SS1S . SS1H O SS1P .

Table 2: A training sentence and the features ex-
tracted from it.

all. In order to obtain a single-label classifier,
we compare the outcome of the |C| binary clas-
sifiers, and the class which has obtained the high-
est Φ̂j(di) value is assigned to di, i.e., Φ̂(di) =
arg maxj Φ̂j(di).

3 Vectorial representation

We have generated the vectorial representations of
the training and test objects by extracting a number
of contextual features from the text surrounding
the two nominals whose relation is to be identified.

An important choice we have made is to “nor-
malize” the representation of the two nominals
with respect to the order in which they appear in
the relation, and not in the sentence. Thus, if e2
appears in a relation r(e2, e1), then e2 is consid-
ered to be the first (F) entity in the feature genera-
tion process and e1 is the second (S) entity.

We have generated a number of features for
each term denoting an entity and also for the three
terms preceding each nominal (P1, P2, P3) and for
the three terms following it (S1, S2, S3):

T : the term itself;

S : the stemmed version of the term, obtained
using a Porter stemmer;

P : the POS of the term, obtained using the Brill
Tagger;

H : the hypernym of the term, taken from Word-
Net (“O” if not available).

Features are prefixed with a proper composition
of the above labels in order to identify their role
in the sentence. Table 2 illustrates a sentence from
the training set and its extracted features.

219



If an entity is composed by k > 1 terms, entity-
specific features are generated for all the term n-
grams contained in the entity, for all n ∈ [1, ..., k].
E.g., for “phone call” features are generated for
the n-grams: “phone”, “call”, “phone call”.

In all the experiments described in this paper,
MP-BOOST has been run for S = 1000 iterations.
No feature weighting has been performed, since
MP-BOOST requires binary input only.

4 Classification model

The classification model we adopted in our exper-
iments splits the two tasks of recognizing the rela-
tion type and the one of determining the direction
of the relation in two well distinct phases.

4.1 Relation type determination
Given the training set Tr of all the sentences for
which the classifier outcome is known, vectorial
representations (see Section 3) are built in a way
that “normalizes” the direction of the relation, i.e.:

• if the training object belongs to one of the
nine relevant relations, the features extracted
from the documents are given proper identi-
fiers in order to mark their role in the relation,
not the order of appearance in the sentence;

• if the training object belongs to Other the
two distinct vectorial representations are gen-
erated, one for relation Other(e1, e2) and one
for Other(e2, e1).

The produced training set has thus a larger num-
ber of examples than the one actually provided.
The training set provided for the task yielded 9410
training examples from the original 8000 sen-
tences. A 10-way classifier is then trained on the
vectorial representation.

4.2 Relation direction determination
The 10-way classifier is thus able to assign a rela-
tion, or the Other relation, to a sentence, but not to
return the direction of the relation. The direction
of the relation is determined at test time, by classi-
fying two instances of each test sentence, and then
combining the outcome of the two classifications
in order to produce the final classification result.

More formally, given a test sentence d belong-
ing to an unknown relation r, two vectorial repre-
sentations are built: one, d1,2, under the hypoth-
esis that r(e1, e2) holds, and one, d2,1, under the
hypothesis that r(e2, e1) holds.

Both d1,2 and d2,1 are classified by Φ̂:

• if both classifications return Other, then d is
assigned to Other;

• if one classification returns Other and the
other returns a relation r, then r, with the
proper direction determined by which vec-
torial representation determined the assign-
ment, is assigned to d;

• if the two classifications return two relations
r1,2 and r2,1 different from Other (of the
same or of different relation type), then the
one that obtains the highest Φ̂ value deter-
mines the relation and the direction to be as-
signed to d.

5 Experiments

We have produced two official runs.
The ISTI-2 run uses the learner, vectorial rep-

resentation, and classification model described in
the previous sections.

The ISTI-1 run uses the same configuration of
ISTI-2, with the only difference being how the
initial distribution Dj1 of the boosting method is
defined. Concerning this, we followed the ob-
servations of (Schapire et al., 1998, Section 3.2)
on boosting with general utility functions; the ini-
tial distribution in the ISTI-1 run is thus set to be
equidistributed between the portion Tr+j of pos-
itive examples of the training set and the portion
Tr−j of negative examples, for each class j, i.e.,

Dj1(di) =
1

2|Tr+j |
iff di ∈ Tr+j (1)

Dj1(di) =
1

2|Tr−j |
iff di ∈ Tr−j (2)

This choice of initial distribution, which gives
more relevance to the less frequent type of ele-
ments of the training set (namely, the positive ex-
amples), is meant to improve the performance on
highly imbalanced classes, thus improving effec-
tiveness at the the macro-averaged level.

We have also defined a third method for an addi-
tional run, ISTI-3; unfortunately we were not able
to produce it in time, and there is thus no offi-
cial evaluation for this run on the test data. The
method upon which the ISTI-3 run is based re-
lies on a more “traditional” approach to the clas-
sification task, i.e., a single-label classifier trained

220



Run πµ ρµ Fµ1 π
M ρM FM1

Official results
ISTI-1 72.01% 67.08% 69.46% 71.12% 66.24% 68.42%
ISTI-2 73.55% 63.54% 68.18% 72.38% 62.34% 66.65%

10-fold cross-validation
ISTI-1 73.60% 69.34% 71.41% 72.44% 68.17% 69.95%
ISTI-2 75.34% 65.92% 70.32% 73.96% 64.65% 68.52%
ISTI-3 68.52% 61.58% 64.86% 66.19% 59.75% 62.31%

Table 3: Official results (upper part), and results of the three relation classification methods when used in
a 10-fold cross-validation experiment on training data (lower part). Precision, recall, and F1 are reported
as percentages for more convenience.

on the nine relations plus Other, not considering
the direction, coupled with nine binary classifiers
trained to determined the direction of each rela-
tion. We consider this configuration as a reason-
able baseline to evaluate the impact of the original
classification model adopted in the other two runs.

Table 3 summarizes the experimental results.
The upper part of the table reports the official re-
sults for the two official runs. The lower part
reports the results obtained by the three rela-
tion classification methods when used in a 10-
fold cross-validation experiment on the training
data. The evaluation measures are precison (π),
recall (ρ), and the F1 score, computed both in
a microaveraged (∗µ) and a macroaveraged
(∗M ) way (Yang, 1999).

The results for ISTI-1 and ISTI-2 in the 10-fold
validation experiment are similar both in trend and
in absolute value to the official results, allowing
us to consider the ISTI-3 results in the 10-fold
validation experiment as a good prediction of the
efficacy of the ISTI-3 method on the test data.
The classification model of ISTI-2, which uses
an initial uniform distribution for the MP-BOOST
learner as ISTI-3, improves FM1 over ISTI-3 by
9.97%, and Fµ1 by 8.42%.

The use of aF1-customized distribution in ISTI-
1 results in a F1 improvement with respect to
ISTI-2 (FM1 improves by 2.66% in official re-
sults, 2.09% in 10-fold validation results), which
is mainly due to a relevant improvement in recall.

Comparing ISTI-1 with ISTI-3 the total im-
provement is 12.26% for FM1 and 10.10% for F

µ
1 .

6 Conclusion and future work

The original relation classification model we have
adopted has produced a relevant improvement in
efficacy with respect to a “traditional” approach.

We have not focused on the development of a
rich set of features. In the future we would like to

apply our classification model to the vectorial rep-
resentations generated by the other participants, in
order to evaluate the distinct contributions of the
feature set and the classification model.

The use of a F1-customized initial distribution
for the MP-BOOST learner has also produced a
relevant improvement, and it will be further inves-
tigated on more traditional text classification tasks.

References
Andrea Esuli, Tiziano Fagni, and Fabrizio Sebastiani.

2006. MP-Boost: A multiple-pivot boosting al-
gorithm and its application to text categorization.
In Proceedings of the 13th International Sympo-
sium on String Processing and Information Retrieval
(SPIRE’06), pages 1–12, Glasgow, UK.

Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Sz-
pakowicz, Peter Turney, and Deniz Yuret. 2007.
Semeval-2007 task 04: Classification of semantic
relations between nominals. In Proceedings of the
Fourth International Workshop on Semantic Evalu-
ations (SemEval-2007), pages 13–18, Prague, CZ.
Association for Computational Linguistics.

Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,
Preslav Nakov, Diarmuid Ó Séaghdha, Sebastian
Padó, Marco Pennacchiotti, Lorenza Romano, and
Stan Szpakowicz. 2010. Semeval-2010 task 8:
Multi-way classification of semantic relations be-
tween pairs of nominals. In Proceedings of the 5th
SIGLEX Workshop on Semantic Evaluation, Upp-
sala, Sweden.

Robert E. Schapire and Yoram Singer. 2000. Boostex-
ter: A boosting-based system for text categorization.
Machine Learning, 39(2/3):135–168.

Robert E. Schapire, Yoram Singer, and Amit Singhal.
1998. Boosting and rocchio applied to text filtering.
In SIGIR ’98: Proceedings of the 21st annual inter-
national ACM SIGIR conference on Research and
development in information retrieval, pages 215–
223, New York, NY, USA. ACM.

Yiming Yang. 1999. An evaluation of statistical ap-
proaches to text categorization. Information Re-
trieval, 1(1/2):69–90.

221


