



















































Bilingual Structured Language Models for Statistical Machine Translation


Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2398–2408,
Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.

Bilingual Structured Language Models for Statistical Machine Translation

Ekaterina Garmash and Christof Monz
Informatics Institute, University of Amsterdam

Science Park 904, 1098 XH Amsterdam, The Netherlands
{e.garmash,c.monz}@uva.nl

Abstract

This paper describes a novel target-side
syntactic language model for phrase-based
statistical machine translation, bilingual
structured language model. Our approach
represents a new way to adapt structured
language models (Chelba and Jelinek,
2000) to statistical machine translation,
and a first attempt to adapt them to phrase-
based statistical machine translation. We
propose a number of variations of the
bilingual structured language model and
evaluate them in a series of rescoring ex-
periments. Rescoring of 1000-best transla-
tion lists produces statistically significant
improvements of up to 0.7 BLEU over a
strong baseline for Chinese-English, but
does not yield improvements for Arabic-
English.

1 Introduction

Many model components of competitive statisti-
cal machine translation (SMT) systems are based
on rather simplistic definitions with little linguis-
tic grounding, which includes the definitions of
phrase pairs, lexicalized reordering, and n-gram
language models. However, earlier work has also
shown that statistical MT can benefit from ad-
ditional linguistically motivated models. Most
prominent among the linguistically motivated ap-
proaches are syntax-based MT systems which
take into account the syntactic structure of sen-
tences through CKY decoding and categorial la-
bels (Zollmann and Venugopal, 2006; Shen et al.,
2008). On the other hand, the commonly used
phrase-based SMT approaches can also reap some
of the benefits of using syntactic information by

integrating linguistic components addressing spe-
cific phenomena, such as Cherry (2008), Carpuat
et al. (2010), Crego and Yvon (2010), Ge (2010),
Xiang et al. (2011), Lerner and Petrov (2013),
Garmash and Monz (2014).

This paper is a contribution to the existing body
of work on how syntactically motivated models
help translation performance. We work with the
phrase-based SMT (PBSMT) (Koehn et al., 2003)
framework as the baseline system. Our choice is
motivated by the fact that PBSMT is a conceptu-
ally simple and therefore flexible framework. It is
typically quite straightforward to integrate an ad-
ditional model into the system. Also, PBSMT is
the most widely used framework in the SMT re-
search community, which ensures comparability
of our results to other people’s work on the topic.

There is a variety of ways syntax can be used in
a PBSMT model. Typically a syntactic represen-
tation of a source sentence is used to define con-
straints on the order in which the decoder trans-
lates it. For example, Cherry (2008) defines soft
constraints based on the notion of syntactic cohe-
sion (Section 2). Ge (2010) captures reordering
patterns by defining soft constraints based on the
currently translated word’s POS tag and the words
structurally related to it. On the other hand, tar-
get syntax is more challenging to use in PBSMT,
since a target-side syntactic model does not have
access to the whole target sentence at decoding.
Post and Gildea (2008) is one of the few target-
side syntactic approaches applicable to PBSMT,
but it has been shown not to improve translation.
Their approach uses a target side parser as a lan-
guage model: one of the reasons why it fails is
that a parser assumes its input to be grammatical
and chooses the most likely parse for it. What we
are interested in during translation is how gram-

2398



matical the target sentence actually is.
In addition to reordering constraints, source

syntax can be used for target-side language mod-
eling. A target side string can be encoded with
source-syntactic building blocks and then scored
as to how well-formed it is. Crego and Yvon
(2010), Niehues et al. (2011), Garmash and Monz
(2014) model target sequences as strings of tokens
built from the target POS tag and the POS tags of
the source words related to it through alignment
and the source parse. In this paper, we define
a target-side syntactic language model that takes
structural constraints from the source sentence, but
uses the words from the target side (as ‘building
blocks’). We do it by adapting an existing mono-
lingual model of Chelba and Jelinek (2000), struc-
tured language models, to the bilingual setting.
Our contributions can be summarized as follows:

• we propose a novel method to adapt monolin-
gual structured language models (Chelba and
Jelinek, 2000) (Section 3) to a PBSMT sys-
tem (Section 4), which does not require an
external on-the-fly parser, but only uses the
given source-side syntactic analysis to infer
structural relations between target words;

• building on the existing literature, we pro-
pose a set of deterministic rules that incre-
mentally build up a parse of a target trans-
lation hypothesis based on the source parse
(Section 4);

• we evaluate our models in a series of rescor-
ing experiments and achieve statistically sig-
nificant improvements of up to 0.7 BLEU for
Chinese-English (Section 5).

Before describing the models, we motivate our
method with a common assumption about cross-
lingual correspondence (Section 2).

2 Direct correspondence assumption and
syntactic cohesion in SMT

Before we apply the syntactic model introduced in
Section 3 to the bilingual setting (Section 4), we
first explain two widely used assumptions about
syntactic correspondence across languages.

We take a dependency tree to be a syntactic rep-
resentation of a sentence and reason about other
syntactic assumptions and models in its terms.
In this work, we choose a dependency structure
over a constituency structure because the former

0 1 2

(a)

0 1 2

(b)

0 1 2 3

(c)

0 1 2 3

(d)

Figure 1: Examples of projective and non-
projective parses. (a-b): projective (a) and non-
projective (b) parses of the same dependency tree.
(b) is non-projective because node 1 is not a de-
scendant of either 0 or 2 (it is the parent of 2). (c-
d): projective (c) and non-projective (d) parses of
the same dependency tree. Node 2 in (d) is placed
between its sibling (node 1) and the child of its
sibling (node 3), neither of which is its ancestor.

is more primitive.1 A dependency parse D is a
dependency tree analysis of a sentence W , and
we will think of it as a relation between words
of W , such that D(w, v) if w is a parent (head)
of v (v being a child/modifier). D can be gener-
alized to D∗ which is an relation between words
that are connected by a continuous path in a de-
pendency tree (i.e. D∗(w, v) if D(w, v) or if ∃u
s.t. D(w, u) ∧ D∗(u, v)). We assume unlabeled
dependency trees. Finally, we make a projectivity
assumption, which is supported by empirical data
in many languages (Kuhlmann and Nivre, 2006;
Havelka, 2007), and makes a model computation-
ally less expensive. A dependency parse D of a
sentence W = w1, . . . , wn is projective, if for ev-
ery word pair wi, wj ∈ W s.t. D(wi, wj) it holds
that every wk ∈ W s.t. i < k < j or j < k < i is
a descendant of wi, i.e., D∗(wi, wk); see Figure 1.

Most NLP models that address the interaction
of two or more languages are based (explicitly or
implicitly) on the direct correspondence assump-
tion (DCA) (Hwa et al., 2002). It states that close
translation equivalents in different languages have
the same dependency structure. This is grounded
linguistically, as translation equivalence implies
semantic equivalence and therefore thematic rela-
tions are preserved (Hwa et al., 2002). Thus de-
pendency relations are preserved, as they are de-
fined based on thematic relations between words.
On the other hand, there is plenty empirical evi-
dence supporting the violation of DCA under cer-
tain conditions (Hwa et al., 2002). For instance,
even semantically very close sentences in differ-
ent languages may have a different number of

1A dependency parse (a dependency tree analysis of a sen-
tence) is more primitive because every constituency parse can
be formalized as a projective dependency parse with labeled
relations, but not vice versa (Osborne, 2008).

2399



0 1 2

a b c

(a)

0 1 2

a b c

(b)

0 1 2 3

a b c d

(c)

0 1 2 3

a b c d

(d)

Figure 2: Examples of cohesive and uncohesive
translations. (a-b): cohesive (a) and uncohesive
(b) translations of the same dependency parse. (b)
is uncohesive because words a and c translate the
source subtree {(1, 2)}, but the target word b does
not translate this subtree. (c-d): cohesive (c) and
uncohesive (d) translations. (d) is uncohesive be-
cause a and c translate the source subtree {(0, 1)},
but b does not translate it.

words. Syntactic divergence increases if the two
languages are typologically different.

Even though DCA only holds up to a certain
level of precision, it is widely used in NLP. There
are models of cross-lingual transfer that define
syntactic structure of one language by condition-
ing it on the structure of semantically equiva-
lent sentences in another language (Naseem et al.,
2012). DCA has also been used in SMT. In partic-
ular, syntax-based SMT is built implicitly around
this assumption (Wu, 1997; Yamada and Knight,
2001). In Quirk and Menezes (2006) DCA is
explicitly implemented by defining a translation
model in terms of treelet pairs where target-side
treelets are produced by projecting source depen-
dencies via word alignments.

Closely related to DCA is the notion of syn-
tactic cohesion of translation (Fox, 2002; Cherry,
2008). This is a constraint that does not allow for
non-projective reordering: Given a source parse
DS , a translation W is cohesive if all translated
target words wi, wj do not have any word wk be-
tween them such that there is a source subtree sub
in DS such that some parts of it are translated by
wi andwj but not bywk (Figure 2). Cherry (2008)
and Bach et al. (2009) define a set of soft con-
straints based on the syntactic cohesion assump-
tion which are applicable to PBSMT decoding.
They only require phrase applications, and not
necessarily individual target words, to conform to
the cohesion principle. For example, if we imag-
ine a situation where a subtree as in Figure 2(b)
is translated as a whole with one phrase applica-
tion (and not word by word), then it does not vio-
late the cohesion principle, although it is internally

uncohesive. Both our approach and Cherry (2008)
implement the idea of conforming the target trans-
lation to the source syntactic structure, but in dif-
ferent ways. Approaches like Cherry (2008) de-
fine principles that constrain the decoder in order
to produce better translations. Our goal is to have
a model that allows for a more direct way of evalu-
ation of how well-formed the target translation is.
In Section 5 we compare translation performance
of the two approaches.

3 Structured language models

As discussed in Sections 1 and 2, we would like to
test how much a PBSMT can benefit from an ad-
ditional syntax-based LM. In this section, we de-
scribe a syntactic language model, structured LM
(SLM) (Chelba and Jelinek, 2000), that we extend
to a bilingual setting and apply to SMT in Sec-
tion 4. SLMs have been applied in SMT before
(Yamada and Knight, 2001; Yu et al., 2014), but
as we show in Section 4, we provide a much sim-
pler method to integrate it into the system. While
a SLM is not the only syntactically defined LM,
it is one of the few that models sentence genera-
tion sequentially. And due to the way the decoding
procedure of PBSMT is defined, it is natural and
straightforward to use models whose score can be
computed sequentially. Other syntactic language
models define sentence generation hierarchically
(Shen et al., 2008; Sennrich, 2015), which com-
plicates their integration into a PBSMT system.

The linguistic intuition behind SLMs is that the
structural children of a word do not essentially
change its distributional properties but just provide
additional specification. In Figure 3(a) the word
president has two modifiers: the and former and
it follows yesterday (an adjunct) and precedes met
(a predicate). This ordering is correct in English.
If instead its modifier was a or an entire relative
clause, it would not make it incorrect.

To capture this observation, (Chelba and Je-
linek, 2000) propose a language model where each
word wi of a sentence W is predicted by an or-
dered subset of the words preceding wi. This con-
ditioning subset is selected based on the syntactic
properties of the preceding sequence Wi−1: the
strong predictors are kept and the weak ones are
left out. The strong predictors are the set of ex-
posed heads. Given a subsequence Wi−1 and its
associated parseDi−1, exposed heads are the roots
of all the disconnected subtrees inDi−1. Note that

2400



the former

president

the

pressyesterday

met

(a)

the former

president metyesterday

(b)

the
arrived

president metyesterday

who … in London two days before

(c)

Figure 3: A fully parsed sentence (a) and its partial
parse (b) during sequential generation. The par-
tial parse in (b) has two disconnected subtrees with
roots yesterday and president. These roots are the
exposed heads for met. (c) is an alternative sen-
tence with a similar structure: president is still a
root of a subtree, and thus and an exposed head.

a parseDi−1 is not necessarily fully connected and
thus a word can have multiple conditioning words.

For an example, consider again Figure 3(a). In
a left-to-right scenario, when met is generated, a
regular n-gram LM conditions it on yesterday the
former president, while a SLM conditions it on
yesterday president, since these two words are the
exposed heads with respect to met (Figure 3(b)).
The words the and former are modifiers of pres-
ident and they get filtered out. Thus we obtain a
less specific conditioning history, which may lead
to the resulting model being less sparse. Another
potential benefit is that SLMs can capture long-
distance reordering: If president had as its mod-
ifier a relative clause (Figure 3(c)) then a simple
n-gram LM would be conditioned on days before
(assuming n = 3), while an SLM would condition
met on yesterday president.

Summarizing the ideas of words being con-
ditioned on a structurally defined subset of the
preceding sentence, Chelba and Jelinek (2000)
formalize the generation process of W as fol-
lows:2 Each new word wi is conditioned on a

2The original model by (Chelba and Jelinek, 2000) is de-
fined in terms of a lexicalized constituency grammar, but as

sequence of exposed heads Expos(W,D). Then a
tag ti is predicted, and the parse Di−i of Wi−1
is extended to Di incorporating wi and ti (where
Wi−1 is the prefix of W preceding wi):

p(W,D) =
|W |∏
i=1

p(wi|Expos(Wi−1, Di−1))

· p(ti|wi, Expos(Wi−1, Di−1))
· p(Di|wi, ti, Expos(Wi−1, Di−1)).

(1)

They use a shift-reduce parser with reduce-left,
reduce-right, and shift operations.

4 Bilingual structured language models

In this section, we combine the direct correspon-
dence assumption (Section 2) and SLMs (Sec-
tion 3), and define bilingual structured language
models (BiSLMs) for PBSMT. Structured LMs
have been successfully applied in SMT before.
Yamada and Knight (2001) use SLMs in a string-
to-tree SMT system where a derivation of a target-
side parse tree is part of the decoding algorithm,
and target syntactic representations are obtained
‘for free’. Yu et al. (2014) use an on-the-fly shift-
reduce parser to build an incremental target parse.

The approaches sketched above rely on re-
sources that a standard PBSMT system does not
have access to by default. Phrase-based decoders
do not provide us with a parse of the target
sentence, and inferring the parse of a target string
with an external parser is computationally expen-
sive and potentially unreliable (see Section 1).
Our main insight is that in a bilingual setting one
does not need an additional probabilistic target
parsing model. We assume that the source parse is
given (precomputed) and that the DCA (Section 2)
holds, and project the parse deterministically onto
the target side via word alignments3. We obtain
the following equation:

p(T |S,DS) =
|T |∏
i=1

p(ti| Expos(Ti−1,

ProjP(DS , S, Ti−1))),

(2)

where T is a target sentence, Ti−1 is the sequence
in T preceding the i-th target word ti, S is a

we discussed in Section 2, constituency parses can be trans-
formed into dependency parses.

3Phrase-internal word alignments are stored in the phrase
table and are available at decoding time, see Section 4.4.

2401



pujing shuo ta xihuan suoyou de eluosi funv

putin said he likes all russian women

(a)

pujing shuo ta xihuan

putin said he likes

(b)

pujing shuo ta xihuan suoyou de eluosi funv

putin said he likes all russian women

(c)

Figure 4: Chinese-English sentence pair (a) and
sets of exposed heads (underlined) at different
generation (b and c) steps of a bilingual SLM.

source sentence,DS is a source dependency parse,
and ProjP is a function that returns a partial tar-
get parse DT i−1 by projecting DS onto Ti−1. In
words, at each time step iwe predict the next word
ti conditioned on the exposed heads of the partial
parse of Ti−1 projected from the source side. We
limit Expos to returning the four preceding exposed
heads.4 Because the function ProjP is determinis-
tic and because we do not have to predict tags for
words, Equation 2 is simpler than Equation 1.

We first illustrate Equation 2 with an example
in Figure 4. Since word alignment is monotonic
in Figure 4(a), it is straightforward to project the
source dependencies onto the target side. We aim
to imitate a monolingual parser in the way we
build up our projected parse: Reduce operations
should be invoked whenever both of the subtrees
involved in the operation are complete, i.e., are
not expected to have any more modifiers (Sec-
tion 4.2). For example, when the target word likes
is produced its exposed heads are said and he (Fig-
ure 4(b)), since Putin is a modifier of said. Like-
wise, the exposed heads for women are said likes
all Russian (Figure 4(c)).

In what follows we discuss how to define ProjP.
Compared to projection approaches like (Quirk

4As written above, we choose the dependency structures
over the lexicalized constituency ones because the latter can
be mapped to the former. It is thus more likely that a pro-
jected dependency tree is still be a well-formed parse, than a
projected constituency tree. We decided to work with struc-
tural models that are more flexible, but one may also define
BiSLM in terms of the more constraining constituency trees
and see if the such model has better generalization power.

and Menezes, 2006), we would like our model
to project a source parse incrementally, allowing
it to be used in a PBSMT decoder. We think of
ProjP as a function that computes the output in
two stages: first, it infers from the source parse the
dependency relations between target words (Sec-
tion 4.1), second, it decides how to parse the tar-
get sequence, i.e. in which order to assign these
dependencies (Section 4.2). Additionally, in Sec-
tion 4.3 we propose to use additional labelings of
target words, and in Section 4.4 we describe some
important implementation details.

4.1 Dependency graph projection

Adoption of DCA (Section 2) allows to build up a
target dependency tree from a source tree by pro-
jecting the latter through word alignments. The
definition of DCA can be rephrased as requiring
a one-to-one correspondence map between words
of a sentence pair, allowing one to unambigu-
ously map dependencies: Given a source parse,
if t1 is the head of t2, then map(t1) is the head
of map(t2). The correspondence relation that
we have in PBSMT is the word alignment align:
in the most general case, it is a many-to-many
correspondence, and the straightforward projec-
tion described above can lead to incorrect depen-
dency structures. To overcome these problems,
we describe a simple ordered set of projection
rules, based on the ones specified by (Quirk and
Menezes, 2006) (and we point out if otherwise).

The general idea behind this set of rules is to ex-
tract a one-to-one function align1−1 from source
words to target words from align and use it to
project source dependencies as described in the
paragraph above (R1 below). We then use addi-
tional rules (R2-R4 below) for the target words
that are not in align1−1. Given a source sen-
tence S with a parse DS , a target sentence T and
word alignment align, align1−1 is extracted as fol-
lows: For all ti ∈ T with multiple aligned source
words {si1 , si2 , ...} only align1−1(si1) = ti (only
leftmost source word is kept, the links from the
rest of the source words are removed5). For all
si ∈ S with aligned target words {ti1 , ti2 , ...} keep
the link only for the leftmost aligned target word:
align1−1(si) = ti1 . For example, in Figure 5(b)
the link between f0 and e1 is not in align1−1, and
in Figure 5(c) the link between f1 and e0 is re-
moved (and the arc from f2 to f1 is not projected).

5This is an ad-hoc solution, other heuristics could be used.

2402



f0 f1 f2

e0 e1 e2

(a)

f0 f1

e0 e1 e3

(b)

f0 f1 f2

e0 e1

(c)

f0 f1

e0 e1 e2 e3

(d)

f0

e0

f1 f2

e1

(e)

f0 f1 f2

e0 e1

(f)

f0 f1

e0 e1e1

(g)

Figure 5: Examples for dependency projection
rules. (a): no alignment links get removed (R1).
(b): f0 − e1 link is removed from align1−1 (R1).
(c): f1 − e0 link gets removed (R1). (d): e1 and
e2 get adjoined to e0 (R2). (e): R3a. (f): R3b.
(g) demonstrates two versions of R4: the dashed
arrow gets ‘realized’ only if we adjoin unaligned
words to the preceding head.

The following rules should be applied in order
(as else-if conditions). Given a source sentence
S with a parse DS , a target sentence T and word
alignment align between them, ti ∈ T is a head of
tj ∈ T (i.e. DT (ti, tj)):
(R1) if there are sk, sl ∈ S s.t. DS(sk, sl) and
align1−1(sk) = ti and align1−1(sl) = tj ; see Fig-
ures 5(a)-5(c);
(R2) if ∃s ∈ S s.t. align1−1(s) = ti and (s, tj) ∈
align. This rule deals with one-to-many align-
ments; see Figure 5(d);
(R3a) if ∃sk s.t. align1−1(sk) = ti and ∃sl s.t.
(sl, tj) ∈ align and and DS(sl, sk), and ti linearly
precedes tj . In words: if two target words are in
align1−1 but do not get connected via R1, find a
source word aligned to the second target word that
may get them connected; see Figure 5(e);
(R3b) same as R3a, but in case tj precedes ti (i.e.,
find an additional source word aligned to the first
target word; see Figure 5(f)).6

(R4) In case ¬∃s (s, tj) ∈ align (tj is unaligned),
we consider two strategies: We simplify the rule of
Quirk and Menezes (2006) (dealing with the same
situation) by adjoining it to the immediately pre-
ceding head. We also consider a strategy whereby
the word remains unconnected to any word in the
sentence; see Figure 5(g).

6R3a and R3b differ from the rules proposed in Quirk and
Menezes (2006) dealing with the same situation, since we had
to adapt it to the left-to-right parsing scenario.

f0 f1 f2

e0 e1 e2

(a)

f0 f1 f2

e0 e2e1

f2

e3

(b)

Figure 6: (a): The dashed lines are the dependency
arcs that would project through word alignment,
resulting in a non-projective projective (impossi-
ble under strong source-completeness). (b): The
dashed lines are the parse produced under weak
source-completeness. Under strong completeness
none of the words will get connected.

4.2 BiSLM parsing procedure

Given an inference procedure for dependency re-
lations between target words (Section 4.1), one
can specify in which order the corresponding de-
pendency arcs are assigned to the target sentence.
We define an incremental parsing procedure in
terms of three operations: shift, left-reduce, and
right-reduce. The operations are applied as soon
as the sufficient conditions hold: We specify the
conditions using the following structural proper-
ties. A target subtree is source-complete if all the
descendants of align−11−1(root(sub)) (source corre-
spondent of the root of the current subtree) (Sec-
tion 4.1) have been translated and reduced. A tar-
get subtree is complete if it is source-complete and
all the target words that are its children through
non-projected arcs (through R2 or R4 in Sec-
tion 4.1) have been translated and reduced. The
bilingual parsing operations and the sufficient con-
ditions for them are defined as follows:
Shift: after the word is produced it is shifted onto
the stack as an elementary subtree.
Left-reduce: if a disconnected subtree subi
and a disconnected subtree subi−1 imme-
diately preceding it are both complete and
DT (root(subi), root(subi−1)), adjoin subi−1
to subi so that root(subi−1) is a modifier of
root(subi).
Right-reduce: analogous to left-reduce, but
DT (root(subi−1), root(subi)).

In the case of non-cohesive translation the re-
sulting target dependencies are non-projective.
Our definition of left- and right-reduce only pro-
duces projective parses. For a non-cohesive
translation, certain subtrees will never be source-
complete and will never be reduced; see Fig-
ure 6(a). Note that this is not a disadvantage

2403



of our model. Cherry (2008) simply assumes
that non-cohesive reordering should be penalized,
and our model is able to learn this pattern. We
also consider an alternative to incorporating non-
cohesive alignments by relaxing the definition of
completeness for subtrees: A projected subtree
sub is weakly source-complete if all descendants
of all source word(s) which are aligned to the root
of sub have been translated and, only if the defini-
tion of reduce applies, reduced; see Figure 6(b).

4.3 Syntactic labeling of tokens

One of the problems with SLMs in general is that
at time steps i and j the sets of exposed heads for
ti and tj can differ in size, which may imply dif-
ferent predictive power. To this end, we add an ad-
ditional detail to our model: Each time a reduction
occurs, we label the root of the subtree to which
another subtree has been adjoined, thus making
the conditioning history more specific. We use the
following labelings:
Reduction labeling: if a subtree is adjoint to sub
from the left, then label root(sub) with LR. If it is
adjoint from the right, then label it with RR.
Reduction POS-labeling: same as in simple re-
duction labeling, but add the POS tag of the root
of the reduced subtree to the label.

4.4 Implementation and training

To use BiSLM during decoding, one needs access
to phrase-internal alignments and target POS tags.
We store phrase-internal alignments and target-
side POS annotations of each phrase in the phrase
table, based on the most frequent internal align-
ment during training and the most likely target-
side POS labeling t̂ given the phrase pair: t̂ =
arg maxt̄ p(t̄|ē, f̄). We train BiSLMs on the par-
allel training data (Section 5.1) and use the Stan-
ford dependency parser (Chang et al., 2009) for
Chinese and and the Stanford constituency parser
(Green and Manning, 2010) for Arabic7. POS-
tagging of the training data is produced with the
Stanford POS-tagger (Toutanova et al., 2003). We
learn a 5-gram model using SRILM (Stolcke et al.,
2011) with modified Kneser-Ney smoothing.

5 Experiments

To evaluate the effectiveness of BiSLMs for PB-
SMT, we performed rescoring experiments for

7We extract dependency parses from its output based on
Collins (1999)

Arabic-English and Chinese-English. We com-
pare the resulting 1-best translation lists with an
output of the baseline system and the baseline aug-
mented with soft cohesion constraints from Bach
et al. (2009).

System MT06 MT08 MT06+MT08
baseline 32.60 25.94 29.56
cohesion 32.52 25.98 29.54

Table 1: Chinese-English baseline and compari-
son model (Cherry, 2008; Bach et al., 2009) re-
sults.

System MT08 MT09 MT08+MT09
baseline 45.84 48.61 47.18

cohesion constr. 45.61 48.49 47.02

Table 2: Arabic-English baseline and comparison
model (Cherry, 2008; Bach et al., 2009) results.

5.1 Experimental setup

This section provides information about our base-
line system. Word-alignment is produced with
GIZA++ (Och and Ney, 2003). We use an in-
house implementation of a PBSMT system similar
to Moses (Koehn et al., 2007). Our baseline has
all standard PBSMT features including language
model, lexical weighting, and lexicalized reorder-
ing. The distortion limit is set to 5. A 5-gram LM
is trained on the English Gigaword corpus (1.6B
tokens) using SRILM with modified Kneser-Ney
smoothing and linear interpolation. Information
about the training data for the Arabic-English and
Chinese-English systems is in Table 3.8 Feature
weights are tuned using pairwise ranking opti-
mization (Hopkins and May, 2011) on the MT04
benchmark (for both language pairs). For testing,
we use MT08 and MT09 for Arabic, and MT06
and MT08 for Chinese. We use case-insensitive
BLEU (Papineni et al., 2002) as evaluation met-
ric. Approximate randomization (Noreen, 1989;
Riezler and Maxwell, 2005) is used to detect sta-
tistically significant differences.

5.2 Baseline and comparison systems

As a comparison model, we implemented six fea-
tures from Cherry (2008) and Bach et al. (2009)9

and added them to the log-linear interpolation used
8The standard LDC corpora were used for training.
9Exhaustive and non-exhaustive interruption check, ex-

haustive and non-exhaustive interruption count, verb- and
noun-dominated subtree interruption count.

2404



Training set N. of lines N. of tokens
Source side of Ar-En set 4,376,320 148M
Target side of Ar-En set 4,376,320 146M
Source side of Ch-En set 2,104,652 20M
Target side of Ch-En set 2,104,652 28M

Table 3: Training data for Arabic-English and
Chinese-English experiments.

by the baseline system. Since these features are bi-
nary or count-based, we cannot use them directly
in rescoring. For that reason we integrated the fea-
tures into the decoder and tuned the correspond-
ing weights. The results for Chinese-English and
Arabic-English translation experiments are pre-
sented in Table 1 and 2, respectively. We see that
adding the cohesion constraints does not improve
performance. This finding is different from, for
example, Feng et al. (2010), where they get im-
provement for Chinese-English: however, we note
that their training set is smaller than ours, and their
baseline is weaker as it does not contain lexical-
ized distortion models.

5.3 Rescoring experiments
Rescoring with BiSLMs is performed as follows:
For the test runs of the baseline system we com-
pute the n = 1000 best translation hypotheses
for each source sentence and extract their deriva-
tions (sequence of phrase pair applications). Each
phrase pair in our implementation is associated
with a unique phrase-internal alignment and tar-
get POS-sequence. We fully reconstruct word-
alignment for each pair of a source sentence and
its translation hypothesis. We project a precom-
puted source parse onto the target side and com-
pute representations of the target sentence to be
computed by a BiSLM. For each hypothesis, we
take its BiSLM score and its score assigned by
the baseline system and compute the final score
as a weighted sum of the original baseline score
and a length-normalized BiSLM score10, where
the weight λ is empirically set to 0.3:

λ · scoreBiSLM
lengthHypothesis

+ (1− λ) · scoreBaseline (3)

5.3.1 Chinese-English
Our main focus here is Chinese-English, since it
has more instances of longer-distance reordering,
at which syntax-based models are typically good.

10Normalization is needed to ensure comparability of
scores for translation hypotheses of different lengths, since
longer translation hypotheses will have lower scores.

labeling complete unalign BLEU diff.
-adjoin

plain strong + 30.09N +0.53
- 30.20N +0.64

weak + 30.11N +0.55
- 30.22N +0.66

reduce strong + 29.94M +0.40
- 30.19N +0.63

weak + 30.09N +0.53
- 30.24N +0.68

reduce-POS strong + 30.09N +0.53
- 30.25N +0.69

weak + 30.05N +0.49
- 30.25N +0.69

Table 4: Rescoring experiments for Chinese
MT06+08 1000-best translation sets. Unrescored
BLEU is 29.56. The column labeling contains in-
formation about the kind of labeling used on the
target side of a BiSLM: just target words, target
words with a reduction label, or target words with
a reduction label and a POS of the root of the re-
duced subtree (Section 4.3). The column com-
plete indicates whether we use a strong or weak
definition of a complete subtree (Section 4.2). The
column unalign-adjoin indicates whether we ad-
join an unaligned target word to the preceding
subtree (Section 4.1). Statistically significant im-
provements over the baseline are marked N at the
p < .01 level and M at the p < .05 level. H marks
significant decrease at the p < .01 level.

SLMs by design are good at capturing longer-
distance dependencies. We try out several varia-
tions of BiSLM. First, we test whether to use a
strong or weak definition of a complete subtree
(Section 4.2). Second, we investigate whether to
adjoin unaligned target words to a preceding head
(Section 4.1; unalign-adjoin+/-). Third, we com-
pare several target-side labeling methods (Sec-
tion 4.3): plain (just target words), reduce (LR or
RR) or reduce-POS (LR POS or RR POS, where
POS is the tag of the root of the reduced subtree).
The rescoring results are presented in Table 4.

The results show statistically significant im-
provement over the baseline of up to 0.7 BLEU
(for all of the employed BiSLM variants except
one). The rescoring experiments also demonstrate
the tendency of the unalign-adjoin- feature value
to produce higher scores than unalign-adjoin+.
But the other two distinguishing features do not
have an effect on BLEU scores. As future work,
we are interested in examining if these features
produce the same distribution of scores when a
BiSLM is fully integrated into the decoder.

2405



labeling complete unalign BLEU diff.
-adjoin

plain strong + 47.20 -0.02
- 47.00H -0.18

weak + 47.22 +0.04
- 46.98H -0.20

reduce strong + 47.15 -0.03
- 46.99H -0.19

weak + 47.09 -0.09
- 46.98H -0.20

reduce-POS strong + 47.15 -0.03
- 46.98H -0.20

weak + 47.17 +0.01
- 47.00H -0.18

Table 5: Rescoring experiments for Arabic
MT08+09 n-best translation sets. Unrescored
BLEU for is 47.18. For notation see Table 4.

5.3.2 Arabic-English

We also rescore the n-best lists for the output of
the Arabic-English baseline system and results are
shown in Table 5. Arabic and English are typolog-
ically very different, but the range of reordering is
much smaller than for Chinese-English. We ex-
pect reordering-related models to have lesser ef-
fect on Arabic as compared to Chinese (Carpuat
et al., 2010). Experimental results on Arabic-
English could indicate what kind of translation
aspect benefits from BiSLMs. We see that for
Arabic-English, just as for the cohesion constraint,
BiSLM have little effect on BLEU scores, or
even decrease them. This is a weak indication
that BiSLMs are better at capturing reordering as-
pects. As for the varying features defining dif-
ferent BiSLM versions, we again see little effect
of the labeling type or subtree completeness def-
inition. On the other hand, we see the oppo-
site pattern for the unalign-adjoin feature, where
unalign-adjoin+ is preferred.

To gain further insight into the different effect
of BiSLM on the two language pairs, we evalu-
ated our experimental output against a reordering-
sensitive metric LRscore (Birch et al., 2010). We
use the version of LRscore which is an average of
the inverse Kendall’s Tau distance and the Ham-
ming distance. In order to compute alignments for
test sets which are needed to compute the score we
concatenated the parallel text with an additional
250K lines of parallel text from the training data to
ensure better generalization of the alignment algo-
rithm (GIZA++). The LRscores of the baseline are
compared to the best performing BiSLM system
with respect to BLEU, for each of the language
pair. The results are provided in Tables 6 and 7.

system LRscore MT06+08
baseline 0.4736
BiSLM 0.4907

Table 6: LRscores (average inverse Kendall’s
Tau distance and Hamming distance) for Chinese-
English baseline and BiSLM with reduce-labeling,
weak completeness, unalign-adjoin-.

system LRscore MT08+09
baseline 0.6671
BiSLM 0.6719

Table 7: LRscores for Arabic-English baseline and
BiSLM with plain-labeling, weak completeness,
unalign-adjoin+.

As expected, the scores for Chinese-English are
much lower than for Arabic-English, which is con-
sistent with the observation reordering is more dif-
ficult for Chinese-English. BiSLM yields larger
improvements for Chinese-English suggesting that
the proposed model helps addressing difficult re-
ordering problems. While there are also small im-
provements for Arabic-English the they may be
too small to be detectable by BLEU.

6 Conclusions

In this paper we proposed a novel way to adapt
structured language models to phrase-based SMT.
Our method requires minimal changes to the PB-
SMT pipeline. We tried a number of variations
of our model and evaluated them in rescoring ex-
periments, resulting in statistically significant im-
provement for Chinese-English. The model is
based on the idea of syntactic transfer (DCA; Sec-
tion 2) and the positive result indicates its ability
to capture syntactic patterns across languages. For
Arabic-English, we did not observe any improve-
ments, suggesting that our models indeed mainly
improve reordering aspects. Improvements in
rescoring are a positive indication that our model
may be a strong feature during decoding. As fu-
ture work, we will fully integrate our model into a
PBSMT decoder and evaluate it on other language
pairs with different reordering distributions.

Acknowledgments

We thank the reviewers for their useful com-
ments. This research was funded in part by the
Netherlands Organization for Scientific Research
(NWO) under project numbers 639.022.213 and
612.001.218.

2406



References
Nguyen Bach, Stephan Vogel, and Colin Cherry. 2009.

Cohesive constraints in a beam search phrase-based
decoder. In Proceedings of the 2009 Annual Con-
ference of the North American Chapter of the As-
sociation for Computational Linguistics, pages 1–4.
Association for Computational Linguistics.

Alexandra Birch, Miles Osborne, and Phil Blunsom.
2010. Metrics for mt evaluation: evaluating reorder-
ing. Machine Translation, 24(1):15–26.

Marine Carpuat, Yuval Marton, and Nizar Habash.
2010. Improving Arabic-to-English statistical ma-
chine translation by reordering post-verbal subjects
for alignment. In Proceedings of the ACL 2010 Con-
ference Short Papers, pages 178–183. Association
for Computational Linguistics.

Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and
Christopher D. Manning. 2009. Discriminative
reordering with chinese grammatical relations fea-
tures. In Proceedings of the Third Workshop on Syn-
tax and Structure in Statistical Translation, pages
51–59. Association for Computational Linguistics.

Ciprian Chelba and Frederick Jelinek. 2000. Struc-
tured language modeling. Computer Speech and
Language, 14(4):283–332.

Colin Cherry. 2008. Cohesive phrase-based decoding
for statistical machine translation. In Proceedings
of Association for Computational Linguistics, pages
72–80.

Michael Collins. 1999. Head-Driven Statistical Mod-
els for Natural Language Parsing. Ph.D. thesis,
University of Pennsylvania.

Josep M. Crego and François Yvon. 2010. Improv-
ing reordering with linguistically informed bilin-
gual n-grams. In Proceedings of the 23rd Inter-
national Conference on Computational Linguistics,
pages 197–205. Association for Computational Lin-
guistics.

Minwei Feng, Arne Mauser, and Hermann Ney. 2010.
A source-side decoding sequence model for statis-
tical machine translation. In Conference of the As-
sociation for Machine Translation in the Americas,
Denver, Colorado, USA.

Heidi J. Fox. 2002. Phrasal cohesion and statisti-
cal machine translation. In Proceedings the Con-
ference on Empirical Methods in Natural Language
Processing, pages 304–311. Association for Com-
putational Linguistics.

Ekaterina Garmash and Christof Monz. 2014.
Dependency-based bilingual language models for
reordering in statistical machine translation. In Pro-
ceedings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP),
pages 1689–1700, Doha, Qatar, October. Associa-
tion for Computational Linguistics.

Niyu Ge. 2010. A direct syntax-driven reordering
model for phrase-based machine translation. In
Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the
Association for Computational Linguistics, pages
849–857. Association for Computational Linguis-
tics.

Spence Green and Christopher D. Manning. 2010.
Better arabic parsing: Baselines, evaluations, and
analysis. In Proceedings of the 23rd International
Conference on Computational Linguistics, pages
394–402. Association for Computational Linguis-
tics.

Jiri Havelka. 2007. Beyond projectivity: Multilin-
gual evaluation of constraints and measures on non-
projective structures. In Proceedings of the 45th An-
nual Meeting of the Association of Computational
Linguistics, pages 608–615. Association for Com-
putational Linguistics.

Mark Hopkins and Jonathan May. 2011. Tuning as
ranking. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
pages 1352–1362. Association for Computational
Linguistics.

Rebecca Hwa, Philip Resnik, Amy Weinberg, and
Okan Kolak. 2002. Evaluating translational corre-
spondence using annotation projection. In Proceed-
ings of the 40th Annual Meeting on Association for
Computational Linguistics, pages 392–399. Associ-
ation for Computational Linguistics.

Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of the 2003 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics on Human Language Technology, pages
48–54. Association for Computational Linguistics.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, et al. 2007. Moses: Open source
toolkit for statistical machine translation. In Pro-
ceedings of the 45th Annual Meeting of the Associ-
ation for Computational Linguistics on Interactive
Poster and Demonstration Sessions, pages 177–180.
Association for Computational Linguistics.

Marco Kuhlmann and Joakim Nivre. 2006. Mildly
non-projective dependency structures. In Proceed-
ings of the COLING/ACL 2006 Main Conference
Poster Sessions, pages 507–514, Sydney, Australia,
July. Association for Computational Linguistics.

Uri Lerner and Slav Petrov. 2013. Source-side classi-
fier preordering for machine translation. In Proceed-
ings of the Empirical Methods in Natural Language
Processing.

Tahira Naseem, Regina Barzilay, and Amir Globerson.
2012. Selective sharing for multilingual dependency

2407



parsing. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics: Long Papers-Volume 1, pages 629–637. Asso-
ciation for Computational Linguistics.

Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider context by using bilin-
gual language models in machine translation. In
Proceedings of the Sixth Workshop on Statistical
Machine Translation, pages 198–206. Association
for Computational Linguistics.

Eric W. Noreen. 1989. Computer Intensive Meth-
ods for Testing Hypotheses. An Introduction. Wiley-
Interscience.

Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.

Timothy Osborne. 2008. Major constituents and two
dependency grammar constraints on sharing in coor-
dination. Linguistics, 46(6):1109–1165.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of the
40th annual meeting of the Association for Compu-
tational Linguistics, pages 311–318. Association for
Computational Linguistics.

Matt Post and Daniel Gildea. 2008. Parsers as lan-
guage models for statistical machine translation. In
Proceedings of the Eighth Conference of the Asso-
ciation for Machine Translation in the Americas,
pages 172–181. Citeseer.

Chris Quirk and Arul Menezes. 2006. Dependency
treelet translation: The convergence of statistical
and example-based machine translation? Machine
Translation, 20:43–65, March.

Stefan Riezler and John T. Maxwell. 2005. On some
pitfalls in automatic evaluation and significance test-
ing for MT. In Proceedings of the ACL Workshop on
Intrinsic and Extrinsic Evaluation Measures for Ma-
chine Translation and/or Summarization.

Rico Sennrich. 2015. Modelling and optimizing on
syntactic n-grams for statistical machine translation.
Transactions of the Association for Computational
Linguistics, 3:169–182.

Libin Shen, Jinxi Xu, and Ralph M. Weischedel. 2008.
A new string-to-dependency machine translation al-
gorithm with a target dependency language model.
In Proceedings of the Association for Computational
Linguistics, pages 577–585.

Andreas Stolcke, Jing Zheng, Wen Wang, and Victor
Abrash. 2011. Srilm at sixteen: Update and out-
look. In Proceedings of IEEE Automatic Speech
Recognition and Understanding Workshop, page 5.

Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology,
pages 173–180. Association for Computational Lin-
guistics.

Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational linguistics, 23(3):377–403.

Bing Xiang, Niyu Ge, and Abraham Ittycheriah. 2011.
Improving reordering for statistical machine trans-
lation with smoothed priors and syntactic features.
In Proceedings of the Fifth Workshop on Syntax,
Semantics and Structure in Statistical Translation,
pages 61–69. Association for Computational Lin-
guistics.

Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proceedings
of the 39th Annual Meeting on Association for Com-
putational Linguistics, pages 523–530. Association
for Computational Linguistics.

Heng Yu, Haitao Mi, Liang Huang, and Qun Liu. 2014.
A structured language model for incremental tree-
to-string translation. Proceedings of COLING 2014,
the 25th International Conference on Computational
Linguistics, pages 1133–1143.

Andreas Zollmann and Ashish Venugopal. 2006. Syn-
tax augmented machine translation via chart parsing.
In Proceedings of the Workshop on Statistical Ma-
chine Translation, pages 138–141. Association for
Computational Linguistics.

2408


