










































UMCCDLSI: Reinforcing a Ranking Algorithm with Sense Frequencies and Multidimensional Semantic Resources to solve Multilingual Word Sense Disambiguation


Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 241‚Äì249, Atlanta, Georgia, June 14-15, 2013. c¬©2013 Association for Computational Linguistics

UMCC_DLSI: Reinforcing a Ranking Algorithm with Sense 

Frequencies and Multidimensional Semantic Resources to solve 

Multilingual Word Sense Disambiguation 

 

Yoan Guti√©rrez, Yenier 

Casta√±eda, Andy Gonz√°lez, 

Rainel Estrada, Dennys D. Piug, 

Jose I. Abreu, Roger P√©rez 

Antonio Fern√°ndez Orqu√≠n, 

Andr√©s Montoyo, Rafael Mu√±oz 

Franc Camara 

DI, University of Matanzas DLSI, University of Alicante Independent Consultant 

Matanzas, Cuba Alicante, Spain USA 

{yoan.gutierrez, 

yenier.castaneda, 

rainel.estrada, 

dennys.puig, jose.abreu, 

roger.perez}@umcc.cu, 

andy.gonzalez@infonet.umcc

.cu 

antonybr@yahoo.com, 

{montoyo,rafael}@dlsi.ua.

es 

info@franccamara.c

om 

 

Abstract 

This work introduces a new unsupervised 

approach to multilingual word sense 

disambiguation. Its main purpose is to 

automatically choose the intended sense 

(meaning) of a word in a particular context for 

different languages. It does so by selecting the 

correct Babel synset for the word and the 

various Wiki Page titles that mention the 

word. BabelNet contains all the output 

information that our system needs, in its Babel 

synset. Through Babel synset, we find all the 

possible Synsets for the word in WordNet. 

Using these Synsets, we apply the 

disambiguation method Ppr+Freq to find what 

we need. To facilitate the work with WordNet, 

we use the ISR-WN which offers the 

integration of different resources to WordNet. 

Our system, recognized as the best in the 

competition, obtains results around 69% of 

Recall. 

1 Introduction 

Word Sense Disambiguation (WSD) focuses on 

resolving the semantic ambiguity of a given word.  

This is an important task in Natural Language 

Processing (NLP) because in many applications, 

such as Automatic Translation, it is essential to 

know the exact meaning of a word in a given 

context. In order to solve semantic ambiguity, 

different systems have been developed. However, 

we can categorize them in two main groups: 

supervised and unsupervised systems. The 

supervised ones need large quantity of hand-tagged 

data in order to gather enough information to build 

rules, train systems, and so on. Unsupervised 

systems, on the other hand, do not need such a 

large amount of hand-tagged datasets. This means 

that, when there aren‚Äôt enough corpora to train the 

systems, an unsupervised system is a good option. 

A sub-task of WSD is Multilingual Word Sense 

Disambiguation (MWSD) (Navigli et al., 2013) 

that aims at resolving ambiguities in different 

languages. 

In a language, there are words that have only one 

sense (or meaning), but in other languages, the 

same words can have different senses. For 

example, ‚Äúpatient‚Äù is a word that in English can be 

either a noun or an adjective, but in German, it 

only has one sense - ‚Äúviz‚Äù (a person that needs 

treatment). This shows that the information 

obtained by combining two languages can be more 

useful for WSD because the word senses in each 

language can complement each other. For it to be 

useful, MWSD needs a multilingual resource that 

contains different languages, such as BabelNet 

(Navigli and Ponzetto, 2010; 2012) and 

EuroWordNet (Vossen, 1998). 

241



As the preferred disambiguation method, we 

decided to use the Ppr+Freq (Personalized Page 

Rank combined with Frequencies of senses)  

(Guti√©rrez, 2012) method because, among 

unsupervised systems, graph-based methods have 

obtained more promising results.  

It is worth mentioning the relevant approaches 

used by the scientific community to achieve 

promising results. One approach used is structural 

interconnections, such as Structural Semantic 

Interconnections (SSI), which create structural 

specifications of the possible senses for each word 

in a context (Navigli and Velardi, 2005). The other 

approaches used are ‚ÄúExploring the integration of 

WordNet‚Äù (Miller et al., 1990), FrameNet (Laparra 

et al., 2010) and those using Page-Rank such as 

(Sinha and Mihalcea, 2007) and (Agirre and Soroa, 

2009). 

The aforementioned types of graph based 

approaches have achieved relevant results in both 

the SensEval-2 and SensEval-3 competitions (see 

Table 1). 

Algorithm Recall 

TexRank (Mihalcea, 2005)  54.2% 

(Sinha and Mihalcea, 2007) 56.4% 

(Tsatsaronis et al., 2007) 49.2% 

Ppr (Agirre and Soroa, 2009) 58.6% 

Table 1. Relevant WSD approaches. Recall measure is 

calculated recalls using SensEval-2 (English All Word 

task) guidelines over. 

Experiments using SensEval-2 and SensEval-3 

corpora suggest that Ppr+Freq (Guti√©rrez, 2012) 

can lead to better results by obtaining over 64% of 

Recall. Therefore we selected Ppr+Freq as the 

WSD method for our system. 

The key proposal for this work is an 

unsupervised algorithm for MWSD, which uses an 

unsupervised method, Ppr+Freq, for semantic 

disambiguation with resources like BabelNet (as 

sense inventory only) (Navigli and Ponzetto, 2010) 

and ISR-WN (as knowledge base) (Guti√©rrez et al., 

2011a; 2010a). 

ISR-WN was selected as the default knowledge 

base because of previous NLP research, which 

included: (Fern√°ndez et al., 2012; Guti√©rrez et al., 

2010b; Guti√©rrez et al., 2012; 2011b; 2011c; 

2011d), which achieved relevant results using ISR-

WN as their knowledge base. 

2 System architecture  

By using one of BabelNet (BN) features, our 

technique begins by looking for all the Babel 

synsets (Bs) linked to the lemma of each word in 

the sentence that we need to disambiguate.  

Through the Bs offsets, we can get its 

corresponding WordNet Synset (WNS), which 

would be retrieved from WordNet (WN) using the 

ISR-WN resource. As a result, for each lemma, we 

have a WordNet Synset List (WNSL) from which 

our Word Sense Disambiguation method obtains 

one WNS as the correct meaning. 

Our WSD method consists of applying a 

modification of the Personalizing PageRank (Ppr) 

algorithm (Agirre and Soroa, 2009), which 

involves the senses frequency. More specifically, 

the key proposal is known as Ppr+Freq (see 

Section 2.3).  

Given a set of WNSLs of WNSL, as words 

window, we applied the Synsets ranking method, 

Ppr+Freq, which ranks in a descending order, the 

Synsets of each lemma according to a calculated 

factor of relevance. The first Synset (WNS) of 

each WNSL (the most relevant) is established as 

the correct one and its associated Babel synset (Bs) 

is also tagged as correct. To determine the Wiki 

Page Titles (WK), we examine the WIKI 

(Wikipedia pages) and WIKIRED (Wikipedia 

pages redirections) in the correct Babel synset 

obtained. 

Figure 1 shows a general description of our 

system that is made up of the following steps: 

I. Obtaining lemmas  
II. Obtaing WN Synset of selected lemmas  

III. Applying Ppr+Freq method  
IV. Assigning Synset, Babel synset and Wiki 

page title 

Note that ISR-WN contains WN as its nucleus. 

This allows linking both resources, BabelNet and 

ISR-WN.

242



 
Figure 1. General process description taking as instance a sentence provided by the trial dataset. 

 

2.1 Obtaining lemmas  

For each input sentence, we extract the labeled 

lemmas. As an example, for the sentence, ‚ÄúThe 

struggle against the drug lords in Colombia will be 

a near thing,‚Äù the selected lemmas are: ‚Äústruggle,‚Äù 
‚Äúdrug_lord,‚Äù ‚ÄúColombia‚Äù, and ‚Äúnear_thing.‚Äù 

 
Figure 2. Obtaining synset of lemmas. 

 

2.2 Obtaing WN Synset of selected lemmas  

For each lemma obtained in the previous section, 

we look through BabelNet to recover the Bs that 

contains the lemma among its labels. When BSs 

are mapped to WN, we use the ISR-WN resource 

to find the corresponding Synset. Since a lemma 

can appear in a different Bs, it can be mapped with 

several WNS. Thus, we get a Synset list for each 

lemma in the sentence. In case the lemma does not 

have an associated Bs, its list would be empty. An 

example of this step is shown on Figure 2. 

2.3 Applying Ppr+Freq method 

In the above case, Ppr+Freq modifies the ‚Äúclassic‚Äù 

Page Rank approach instead of assigning the same 

weight for each sense of WN in the disambiguation 

graph (ùê∫ùê∑). 

The PageRank (Brin and Page, 1998) 

adaptation, Ppr , which was popularized by (Agirre 

IV . Assigning Synset, Babel Synset and Wiki page title

‚Äú The struggle against the drug lords in Colombia will be a near thing .‚Äù

struggle drug_lord Colombia near_thing

Wikipedia WordNet BabelNet ISR-WN

WordNet
(WN)

SUMO

WN-Domain WN-Affect

SemanticClass eXtended WN3.0

eXtended WN1.7

struggle%1:04:01:: drug_lord%1:18:00:: colombia%1:15:00:: near_thing%1:04:00::

bn:00009079n bn:00028876n bn:00020697n bn:00057109n

-- Drug_Lord Colombia --

I. Obtaing lemmas

II. Obtaining Synset of selected lemmas

III. Applying Ppr+Freq method

WN key

BS

WK

struggle drug_lord Colombia near_thing

struggle

bn:00074762n wn:00587514n

bn:00009079n wn:00739796n

bn:00009080n wn:00901980n

drug_lord bn:00028876n wn:09394468n

colombia

bn:00020697n wn:08196765n

bn:02051949n

bn:02530766n

near_thing bn:00057109n wn:00193543n

Sentence lemmas 

Babel synset 

WordNet synset 

243



and Soroa, 2009) in Word Sense Disambiguation 

thematic, and which has obtained relevant results, 

was an inspiration to us in our work. The main idea 

behind this algorithm is that, for each edge 

between ùë£i and ùë£j in graph ùê∫, a vote is made from 
ùë£i to ùë£j. As a result, the relevance of ùë£j is 
increased. 

On top of that, the vote strength from ùëñ to ùëó 
depends on ùë£ùëñ‚Ä≤ùë† relevance. The philosophy behind 
it is that, the more important the vertex is, the more 

strength the voter would have. Thus, PageRank is 

generated by applying a random walkthrough from 

the internal interconnection of ùê∫, where the final 
relevance of ùë£ùëñ  represents the random walkthrough 
probability over ùê∫, and ending on ùë£ùëñ. 

Ppr+Freq includes the existent semantic and 

frequency patterns of each sense of the word to 

disambiguate while finding a way to connect each 

one of these words in a knowledge base. 

The new graph-based approach of WSD 

generates a graph of disambiguated words for each 

input sentence. For that reason, it is necessary to 

classify the word senses according to the other 

words that compose the context. The general 

method is shown in Figure 3. This method is 

divided into three steps: 

I. Creation of a disambiguation graph 
II. Application of Ppr+Freq in the generated 

graph 

III. Selection of the correct answer 

Creation of a disambiguation graph: In the first 

step, a disambiguation graph is built by means of a 

Breath First Search (BFS) over the ‚Äúsuper‚Äù graph 

composed by all the resources integrated into ISR-

WN. The components involved in this process are: 

WordNet, SUMO (Zouaq et al., 2009) WordNet 

Domains (Magnini and Cavaglia, 2000) WordNet 

Affects (Strapparava and Valitutti, 2004) Semantic 

Classes (Izquierdo et al., 2007) and eXtended 

WordNet (XWN) relations (Moldovan and Rus, 

2001). This search aims to recover all senses 

(nodes), domain labels (from WordNet Domain 

and WordNet Affects), SUMO categories, and 

Semantic Classes labels through the shortest path 

between every pair of senses in the WNSL set 

associated with the input sentence. Using ISR-WN 

as the KB, through experimentation, we obtained 

the shortest paths with a length of five edges. For a 

better understanding of this process, see (Guti√©rrez, 

2012). 

Application of Ppr+Freq in the generated 

graph: In the second step, we use the weighted 

Personalized PageRank. Here, all the vertices from 

vector ùë£ in ùê∫ùê∑ are initialized with the value  
1

ùëÅ
 ; 

where ùëÅ is the number of nodes in ùê∫ùê∑. On the 
other hand, the vertices that represent word senses 

in the analyzed sentence are not initialized with 

this value. Instead, they are initialized with values 

in the range [0‚Ä¶1], which are associated to their 

occurrence frequency in SemCor1 (Corpus and 

sense frequencies knowledge). In the last step, 

after applying the Ppr+Freq algorithm over ùê∫ùê∑, we 
get a representative vector which contains ISR-WN 

nodes in ùê∫ùê∑ sorted in a descending order by a 
ranking score computed by this algorithm. For a 

better description, see (Guti√©rrez, 2012). 

Selection of the correct answer: As the correct 

sense, we take the highest ranked sense of each 

target word involved in this vector. Note that 

domain labels, SUMO categories, semantic class 

labels, and affect labels are ranked too. They could 

be used in the future to determine relevant 

conceptualizations that would be useful for text 

classification and more. 

In our system, we assume the following 

configuration: dumping factor ùëê = 0.85 and like in 
(Agirre and Soroa, 2009) we used 30 iterations. A 

detailed explanation about PageRank algorithm 

can be found in (Agirre and Soroa, 2009). 

Table 2 shows an example that analyzes the 

Synset for each word in the sentence and also 

shows how the higher ranked Synsets of the target 

words are selected as the correct ones. For a 

detailed explanation of Ppr+Freq, see (Guti√©rrez, 

2012). 

2.4 Assigning Synset, Babel synset and Wiki 
Pages 

In this step, English is handled differently from 

other languages because WordNet Synsets are 

available only for English. The following sections 

explain how we proceed in each case. Once the 

Synsets list is obtained for each lemma in section 

2.3, selecting the correct answer for the lemma is 

all that‚Äôs left to do. 

                                                      
1 http://www.cse.unt.edu/~rada/downloads.html 

244



 
Figure 3. General process of WSD with Ppr+Freq. 

2.4.1 English 

Given a lemma, we go through its Synset list from 

beginning to end looking for the first Synset that 

contains a key2 for the lemma. If such Synset 

exists, it is designated as the Synset for the lemma. 

Otherwise, no Synset is assigned. 

As already explained, each Synset in the list is 

connected to a Bs. Therefore, the lemma linked 

with the correct WNS selected in the previous step, 

is chosen as the correct lemma. In case no Synsets 

were designated as the correct ones, we take the 

first Bs in BN, which contains the lemma among 

its labels.  

To determine the Wiki pages titles (WK) we 

examine the WIKIRED and WIKI labels in the 

correct Bs selected in the preceding step. This 

search is restricted only to labels corresponding to 

the analyzed language and discriminating upper 

and lower case letters. Table 2 shows some sample 

results of the WSD process. 

Lemma struggle drug_lord 

WNS 00739796n 09394468n 

WN key struggle%1:04:01:: drug_lord%1:18:00:: 

Bs bn:00009079n bn:00028876n 

WK - Drug_Lord 

Lemma colombia near_thing 

WNS 08196765n 00193543n 

WN key colombia%1:15:00:: near_thing%1:04:00:: 
Bs bn:00020697n bn:00057109n 

WK Colombia - 

Table 2 : Example of English Language. 

                                                      
2A sense_key is the best way to represent a sense in 

semantic tagging or other systems that refer to WordNet 

senses. sense_key‚Äôs are independent of WordNet sense 

numbers and synset_offset‚Äôs, which vary between versions of 

the database. 

2.4.2 Other languages  

For this scenario, we introduce a change in the first 

step discussed in the previous section. The reason 

is that the Synsets do not contain any keys in any 

other language than English. Thus, the correct 

Synset for the lemma is the first in the Synset list 

for the lemma obtained, as described, in section 

2.3. 

3 Results 

We tested three versions (runs) of the proposed 

approach and evaluated them through a trial 

dataset provided by Task123 of Semeval-2013 

using babelnet-1.0.1. Table 3 shows the result for 

each run. Note that the table results were 

calculated with the traditional WSD recall 

measure, being this measure which has ranked 

WSD systems on mostly Semeval competitions. 

On the other hand, note that our precision and 

recall results are different because the coverage is 

not 100%. See Table 5. 

 English French 

Runs WNS Bs WK Bs WK 

Run1 0.70 0.71 0.77 0.59 0.85 

Run2 0.70 0.71 0.78 0.60 0.85 

Run3 0.69 0.70 0.77 - - 

Table 3 : Results of runs with trial recall values. 

As can be noticed on Table 3, results of different 

versions do not have big differences, but in 

general, Run2 achieves the best results; it‚Äôs better 

                                                      
3 http://www.cs.york.ac.uk/semeval-2013/task12 

ISR-WN footballer#1 | cried#9 | winning#3

footballer | cry | winning

Lemmas

‚ÄúThe footballer cried when winning‚Äù

Disambiguation

Graph

(0,9)

Footballer#1

(0,3)

cry#7

(0,4)

cry#9

(0,2)

cry#10

(0,2)

cry#11

(0,2)

cry#12

(0,2)

winning#1

(0,3)

winning#3

Creating GD

Ppr+Freq

Selecting senses

245



than Run1 in the WK with a 78% in English and 

Bs with 60% in French. The best results are in the 

WK in French with a value of 85%. 

Since we can choose to include different 

resources into ISR-WN, it is important to analyze 

how doing so would affect the results. Table 4 

shows comparative results for Run 2 of a trial 

dataset with BabelNet version 1.1.1. 

As can be observed in Table 4, the result does not 

have a significant change even though we used the 

ISR-WN with all resources.  

A better analysis of Ppr+Freq in, as it relates to 

the influence of each resource involved in ISR-WN 

(similar to Table 4 description) assessing 

SensEval-2 and SensEval-3 dataset, is shown in 

(Guti√©rrez, 2012). There are different resource 

combinations showing that only XWN1.7 and all 

ISR-WN resources obtain the highest performance. 

Other analysis found in (Guti√©rrez, 2012) evaluates 

the influence of adding the sense frequency for 

Ppr+Freq.  

By excluding the Factotum Domain, we obtain 

the best result in Bs 54% for French (only 1% 

more than the version used in the competition). 

The other results are equal, with a 69% in WNS, 

66% in Bs, 64% in WK for English, and 69% in 

WK for French. 

        English French 

WN Domains Sumo Affect Factotum 

Domain 

SemanticClass XWN3.0 XWN1.7 WNS Bs WK Bs WK 

X X X X X X X X 0.69 0.66 0.64 0.53 0.69 

X X  X X X X X 0.69 0.66 0.64 0.53 0.69 

X    X X X X 0.68 0.65 0.64 0.52 0.69 

X X X X  X X X 0.69 0.66 0.64 0.54 0.69 

X X X X  X  X 0.68 0.65 0.65 0.53 0.69 

Table 4. Influence of different resources that integrate ISR-WN in our technique. 

    Wikipedia BabelNet WordNet 

System Language Precision Recall F-score Precision Recall F-score Precision Recall F-score 

MFS DE 0.836 0.827 0.831 0.676 0.673 0.686 - - - 

  EN 0.86 0.753 0.803 0.665 0.665 0.656 0.63 0.63 0.63 

  ES 0.83 0.819 0.824 0.645 0.645 0.644 - - - 

  FR 0.698 0.691 0.694 0.455 0.452 0.501 - - - 

  IT 0.833 0.813 0.823 0.576 0.574 0.572 - - - 

Run1 DE 0.758 0.46 0.572 0.619 0.617 0.618 - - - 

  EN 0.619 0.484 0.543 0.677 0.677 0.677 0.639 0.635 0.637 

  ES 0.773 0.493 0.602 0.708 0.703 0.705 - - - 

  FR 0.817 0.48 0.605 0.608 0.603 0.605 - - - 

  IT 0.785 0.458 0.578 0.659 0.656 0.657 - - - 

Run2 DE 0.769 0.467 0.581 0.622 0.62 0.621 - - - 

  EN 0.62 0.487 0.546 0.685 0.685 0.685 0.649 0.645 0.647 

  ES 0.778 0.502 0.61 0.713 0.708 0.71 - - - 

  FR 0.815 0.478 0.603 0.608 0.603 0.605 - - - 

  IT 0.787 0.463 0.583 0.659 0.657 0.658 - - - 

Run3 EN 0.622 0.489 0.548 0.68 0.68 0.68 0.642 0.639 0.64 

Table 5. Results of Runs for Task12 of semeval-2013 using the test dataset. 

 

246



3.1 Run1 

In this Run, WNSLs consist of all the target words 

involved in each sentence. This run is applied at 

the sentence level. The results for the competition 

are shown in Table 5. For this Run, the best result 

was obtained for Spanish with a 70.3% in Bs and 

49.3% in WK of Recall. As we can see, for Run1 
the precision is high for Wikipedia disambiguation, 

obtaining for French the best result of the ranking. The 

low Recall in Wikipedia is due to the exact mismatching 

of labels between our system output and the gold 

standard. This fact, affects the rest of our runs. 

3.2 Run2 

In this Run, WNSLs consist of all the target words 

involved in each domain. We can obtain the target 

words because the training and test dataset contain 

the sentences grouped by topics.  For instance, for 

English, 13 WNSLs are established. This Run is 

applied at the corpora level. The results for the 

competition are shown in Table 5. It is important to 

emphasize that our best results ranked our 

algorithm as first place among all proposed 

approaches for the MWSD task. 

For this run, the best Recall was obtained for 

Spanish with a 70.8% in Bs and 50.2% in WK. 

This Run also has the best result of the three runs. 

For the English competition, it ended up with a 

64.5% in WNS, 68.5% in Bs, and 48.7% in WK. 

This Run obtained promising results, which took 

first place in the competition. It also had better 

results than that of the First Sense (Most Frequent 

Sense) baseline in Bs results for all languages, 

except for German. In Bs, it only obtained lower 

results in German with a 62% of Recall for our 

system and 67.3% for the First Sense baseline. 

3.3 Run3 

In this run, WNSLs consist of all the words 

included in each sentence. This run uses target 

words and non-target words of each sentence, as 

they are applied to the sentence level. The results 

for the competition are shown in Table 5.  

As we can see, the behavior of this run is similar 

to the previous runs. 

4 Conclusions and Future work  

The above results suggest that our proposal is a 

promising approach. It is also important to notice 

that a richer knowledgebase can be built by 

combining different resources such as BabelNet 

and ISR-WN, which can lead to an improvement 

of the results. Notwithstanding, our system has 

been recognized as the best in the competition, 

obtaining results around 70% of Recall. 

According to the Task12 results4, only the 

baseline Most Frequent Sense (MFS) could 

improve our scores in order to achieve better WK 

and German (DE) disambiguation. Therefore, we 

plan to review this point to figure out why we 

obtained better results in other categories, but not 

for this one. At the same time, further work will 

use the internal Babel network to run the Ppr+Freq 

method in an attempt to find a way to enrich the 

semantic network obtained for each target sentence 

to disambiguate. On top of that, we plan to 

compare Ppr (Agirre and Soroa, 2009) with 

Ppr+Freq using the Task12 dataset. 

Availability of our Resource 

In case researchers would like to use our resource, 

it is available at the GPLSI5 home page or by 

contacting us via email. 

Acknowledgments 

This research work has been partially funded by 

the Spanish Government through the project 

TEXT-MESS 2.0 (TIN2009-13391-C04), "An√°lisis 

de Tendencias Mediante T√©cnicas de Opini√≥n 

Sem√°ntica" (TIN2012-38536-C03-03) and 

‚ÄúT√©cnicas de Deconstrucci√≥n en la Tecnolog√≠as del 

Lenguaje Humano‚Äù (TIN2012-31224); and by the 

Valencian Government through the project 

PROMETEO (PROMETEO/2009/199). 

References 

Agirre, E. and A. Soroa. Personalizing PageRank for 

Word Sense Disambiguation. Proceedings of the 12th 

conference of the European chapter of the 

Association for Computational Linguistics (EACL-

2009), Athens, Greece, 2009. 

                                                      
4 http://www.cs.york.ac.uk/semeval-

2013/task12/index.php?id=results 

5 http://gplsi.dlsi.ua.es/ 

247



Fern√°ndez, A.; Y. Guti√©rrez; H. D√°vila; A. Ch√°vez; A. 

Gonz√°lez; R. Estrada; Y. Casta√±eda; S. V√°zquez; A. 

Montoyo and R. Mu√±oz. UMCC_DLSI: 

Multidimensional Lexical-Semantic Textual 

Similarity. {*SEM 2012}: The First Joint Conference 

on Lexical and Computational Semantics -- Volume 

1: Proceedings of the main conference and the shared 

task, and Volume 2: Proceedings of the Sixth 

International Workshop on Semantic Evaluation 

{(SemEval 2012)}, Montreal, Canada, Association 

for Computational Linguistics, 2012. 608--616 p.  

Guti√©rrez, Y. An√°lisis Sem√°ntico Multidimensional 

aplicado a la Desambiguaci√≥n del Lenguaje Natural. 

Departamento de Lenguajes y Sistemas Inform√°ticos. 

Alicante, Alicante, 2012. 189. p. 

Guti√©rrez, Y.; A. Fern√°ndez; A. Montoyo and S. 

V√°zquez. Integration of semantic resources based on 

WordNet. XXVI Congreso de la Sociedad Espa√±ola 

para el Procesamiento del Lenguaje Natural, 

Universidad Polit√©cnica de Valencia, Valencia, 

SEPLN 2010, 2010a. 161-168 p. 1135-5948. 

Guti√©rrez, Y.; A. Fern√°ndez; A. Montoyo and S. 

V√°zquez. UMCC-DLSI: Integrative resource for 

disambiguation task. Proceedings of the 5th 

International Workshop on Semantic Evaluation, 

Uppsala, Sweden, Association for Computational 

Linguistics, 2010b. 427-432 p.  

Guti√©rrez, Y.; A. Fern√°ndez; A. Montoyo and S. 

V√°zquez Enriching the Integration of Semantic 

Resources based on WordNet Procesamiento del 

Lenguaje Natural, 2011a, 47: 249-257. 

Guti√©rrez, Y.; S. V√°zquez and A. Montoyo. Improving 

WSD using ISR-WN with Relevant Semantic Trees 

and SemCor Senses Frequency. Proceedings of the 

International Conference Recent Advances in Natural 

Language Processing 2011, Hissar, Bulgaria, RANLP 

2011 Organising Committee, 2011b. 233--239 p.  

Guti√©rrez, Y.; S. V√°zquez and A. Montoyo. Sentiment 

Classification Using Semantic Features Extracted 

from WordNet-based Resources. Proceedings of the 

2nd Workshop on Computational Approaches to 

Subjectivity and Sentiment Analysis (WASSA 

2.011), Portland, Oregon., Association for 

Computational Linguistics, 2011c. 139--145 p.  

Guti√©rrez, Y.; S. V√°zquez and A. Montoyo. Word Sense 

Disambiguation: A Graph-Based Approach Using N-

Cliques Partitioning Technique. en:  Natural 

Language Processing and Information Systems. 

MU√ëOZ, R.;MONTOYO, A.et al, Springer Berlin / 

Heidelberg, 2011d. 6716: 112-124.p.  

Guti√©rrez, Y.; S. V√°zquez and A. Montoyo. A graph-

Based Approach to WSD Using Relevant Semantic 

Trees and N-Cliques Model. CICLing 2012, New 

Delhi, India, 2012. 225-237 p.  

Izquierdo, R.; A. Su√°rez and G. Rigau A Proposal of 

Automatic Selection of Coarse-grained Semantic 

Classes for WSD Procesamiento del Lenguaje 

Natural, 2007, 39: 189-196. 

Laparra, E.; G. Rigau and M. Cuadros. Exploring the 

integration of WordNet and FrameNet. Proceedings 

of the 5th Global WordNet Conference (GWC'10), 

Mumbai, India, 2010.  

Magnini, B. and G. Cavaglia. Integrating Subject Field 

Codes into WordNet. Proceedings of Third 

International Conference on Language Resources and 

Evaluation (LREC-2000), 2000. 1413--1418 p.  

Mihalcea, R. Unsupervised large-vocabulary word sense 

disambiguation with graph-based algorithms for 

sequence data labeling. Proceedings of HLT05, 

Morristown, NJ, USA., 2005.  

Miller, G. A.; R. Beckwith; C. Fellbaum; D. Gross and 

K. Miller. Five papers on WordNet. Princenton 

University, Cognositive Science Laboratory, 1990. 

Moldovan, D. I. and V. Rus Explaining Answers with 

Extended WordNet ACL, 2001. 

Navigli, R.; D. Jurgens and D. Vannella. SemEval-2013 

Task 12: Multilingual Word Sense Disambiguation. . 

Proceedings of the 7th International Workshop on 

Semantic Evaluation (SemEval 2013), in conjunction 

with the Second Joint Conference on Lexical and 

Computational Semantics (*SEM 2013), Atlanta, 

Georgia, 2013.  

Navigli, R. and S. P. Ponzetto. BabelNet: Building a 

Very Large Multilingual Semantic Network. 

Proceedings of the 48th Annual Meeting of the 

Association for Computational Linguistics, Uppsala, 

Sweden, Association for Computational Linguistics, 

2010. 216--225 p.  

Navigli, R. and S. P. Ponzetto BabelNet: The automatic 

construction, evaluation and application of a wide-

coverage multilingual semantic network Artif. Intell., 

2012, 193: 217-250. 

Navigli, R. and P. Velardi Structural Semantic 

Interconnections: A Knowledge-Based Approach to 

Word Sense Disambiguation IEEE Transactions on 

Pattern Analysis and Machine Intelligence, 2005, 

27(7): 1075-1086. 

Sinha, R. and R. Mihalcea. Unsupervised Graph-based 

Word Sense Disambiguation Using Measures of 

Word Semantic Similarity. Proceedings of the IEEE 

International Conference on Semantic Computing 

(ICSC 2007), Irvine, CA, 2007. 

248



Strapparava, C. and A. Valitutti. WordNet-Affect: an 

affective extension of WordNet. Proceedings of the 

4th International Conference on Language Resources 

and Evaluation (LREC 2004), Lisbon, 2004. 1083-

1086 p.  

Tsatsaronis, G.; M. Vazirgiannis and I. 

Androutsopoulos. Word sense disambiguation with 

spreading activation networks generated from 

thesauri. IJCAI, 2007.  

Vossen, P. EuroWordNet: A Multilingual Database with 

Lexical Semantic Networks.  Dordrecht, Kluwer 

Academic Publishers, 1998.  

Zouaq, A.; M. Gagnon and B. Ozell. A SUMO-based 

Semantic Analysis for Knowledge Extraction. 

Proceedings of the 4th Language & Technology 

Conference, Pozna≈Ñ, Poland, 2009.  

 

 

249


