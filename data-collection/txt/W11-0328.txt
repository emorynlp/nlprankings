










































Learning with Lookahead: Can History-Based Models Rival Globally Optimized Models?


Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pages 238–246,
Portland, Oregon, USA, 23–24 June 2011. c©2011 Association for Computational Linguistics

Learning with Lookahead:
Can History-Based Models Rival Globally Optimized Models?

Yoshimasa Tsuruoka†∗ Yusuke Miyao‡∗ Jun’ichi Kazama∗
† Japan Advanced Institute of Science and Technology (JAIST), Japan

‡ National Institute of Informatics (NII), Japan
∗ National Institute of Information and Communications Technology (NICT), Japan
tsuruoka@jaist.ac.jp yusuke@nii.ac.jp kazama@nict.go.jp

Abstract

This paper shows that the performance of
history-based models can be significantly im-
proved by performing lookahead in the state
space when making each classification deci-
sion. Instead of simply using the best ac-
tion output by the classifier, we determine
the best action by looking into possible se-
quences of future actions and evaluating the
final states realized by those action sequences.
We present a perceptron-based parameter op-
timization method for this learning frame-
work and show its convergence properties.
The proposed framework is evaluated on part-
of-speech tagging, chunking, named entity
recognition and dependency parsing, using
standard data sets and features. Experimental
results demonstrate that history-based models
with lookahead are as competitive as globally
optimized models including conditional ran-
dom fields (CRFs) and structured perceptrons.

1 Introduction

History-based models have been a popular ap-
proach in a variety of natural language process-
ing (NLP) tasks including part-of-speech (POS) tag-
ging, named entity recognition, and syntactic pars-
ing (Ratnaparkhi, 1996; McCallum et al., 2000; Ya-
mada and Matsumoto, 2003; Nivre et al., 2004).
The idea is to decompose the complex structured
prediction problem into a series of simple classifi-
cation problems and use a machine learning-based
classifier to make each decision using the informa-
tion about the past decisions and partially completed
structures as features.

Although history-based models have many prac-
tical merits, their accuracy is often surpassed by
globally optimized models such as CRFs (Lafferty
et al., 2001) and structured perceptrons (Collins,
2002), mainly due to the label bias problem. To-
day, vanilla history-based models such as maximum
entropy Markov models (MEMMs) are probably not
the first choice for those who are looking for a ma-
chine learning model that can deliver the state-of-
the-art accuracy for their NLP task. Globally opti-
mized models, by contrast, are gaining popularity in
the community despite their relatively high compu-
tational cost.

In this paper, we argue that history-based mod-
els are not something that should be left behind
in research history, by demonstrating that their ac-
curacy can be significantly improved by incorpo-
rating a lookahead mechanism into their decision-
making process. It should be emphasized that we
use the word “lookahead” differently from some lit-
erature on syntactic parsing in which lookahead sim-
ply means looking at the succeeding words to choose
the right parsing actions. In this paper, we use the
word to refer to the process of choosing the best ac-
tion by considering different sequences of future ac-
tions and evaluating the structures realized by those
sequences. In other words, we introduce a looka-
head mechanism that performs a search in the space
of future actions.

We present a perceptron-based training algorithm
that can work with the lookahead process, together
with a proof of convergence. The algorithm enables
us to tune the weight of the perceptron in such a way
that we can correctly choose the right action for the

238



State Operation Stack Queue
0 I saw a dog with eyebrows
1 shift I saw a dog with eyebrows
2 shift I saw a dog with eyebrows
3 reduceL saw(I) a dog with eyebrows

. . .
4 saw(I) dog(a) with eyebrows
5 shift saw(I) dog(a) with eyebrows
6 shift saw(I) dog(a) with eyebrows
7 reduceR saw(I) dog(a) with(eyebrows)
8 reduceR saw(I) dog(a, with(eyebrows))
5’ reduceR saw(I, dog(a)) with eyebrows
6’ shift saw(I, dog(a)) with eyebrows
7’ shift saw(I, dog(a)) with eyebrows
8’ reduce R saw(I, dog(a)) with(eyebrows)
9’ reduce R saw(I, dog(a), with(eyebrows))

Figure 1: Shift-reduce dependency parsing

current state at each decision point, given the infor-
mation obtained from a search.

To answer the question of whether the history-
based models enhanced with lookahead can actually
compete with globally optimized models, we eval-
uate the proposed framework with a range of stan-
dard NLP tasks, namely, POS tagging, text chunking
(a.k.a. shallow parsing), named entity recognition,
and dependency parsing.

This paper is organized as follows. Section 2
presents the idea of lookahead with a motivating
example from dependency parsing. Section 3 de-
scribes our search algorithm for lookahead and a
perceptron-based training algorithm. Experimen-
tal results on POS tagging, chunking, named entity
recognition, and dependency parsing are presented
in Section 4. We discuss relationships between our
approach and some related work in Section 5. Sec-
tion 6 offers concluding remarks with some potential
research directions.

2 Motivation

This section describes an example of dependency
parsing that motivates the introduction of lookahead
in history-based models.

A well-known history-based approach to depen-
dency parsing is shift-reduce parsing. This al-
gorithm maintains two data structures, stack and

queue: A stack stores intermediate parsing results,
and a queue stores words to read. Two operations
(actions), shift and reduce, on these data structures
construct dependency relations one by one.

For example, assume that we are given the follow-
ing sentence.

I saw a dog with eyebrows.

In the beginning, we have an empty stack, and a
queue filled with a list of input words (State 0 in Fig-
ure 1). The shift operation moves the left-most ele-
ment of the queue to the stack. In this example, State
1 is obtained by applying shift to State 0. After the
two shift operations, we reach State 2, in which the
stack has two elements. When we have two or more
elements in the stack, we can apply the other opera-
tion, reduce, which merges the two stack elements
by creating a dependency relation between them.
When we apply reduceL, which means to have the
left element as a dependent of the right element, we
reach State 3: The word “I” has disappeared from
the stack and instead it is attached to its head word
“saw”.1 In this way, the shift-reduce parsing con-
structs a dependency tree by reading words from the
queue and constructing dependency relations on the
stack.

1In Figure 1, H(D1, D2, . . .) indicates that D1, D2, . . . are
the dependents of the head H .

239



Let’s say we have now arrived at State 4 after sev-
eral operations. At this state, we cannot simply de-
termine whether we should shift or reduce. In such
cases, conventional methods rely on a multi-class
classifier to determine the next operation. That is,
a classifier is used to select the most plausible oper-
ation, by referring to the features about the current
state, such as surface forms and POSs of words in
the stack and the queue.

In the lookahead strategy, we make this decision
by referring to future states. For example, if we ap-
ply shift to State 4, we will reach State 8 in the end,
which indicates that “with” attaches to “dog”. The
other way, i.e., applying reduceR to State 4, eventu-
ally arrives at State 9’, indicating “with” attaches to
“saw”. These future states indicate that we were im-
plicitly resolving PP-attachment ambiguity at State
4. While conventional methods attempt to resolve
such ambiguity using surrounding features at State
4, the lookahead approach resolves the same ambi-
guity by referring to the future states, for example,
State 8 and 9’. Because future states can provide ad-
ditional and valuable information for ambiguity res-
olution, improved accuracy is expected.

It should be noted that Figure 1 only shows one
sequence of operations for each choice of operation
at State 4. In general, however, the number of poten-
tial sequences grows exponentially with the looka-
head depth, so the lookahead approach requires us to
pay the price as the increase of computational cost.
The primary goal of this paper is to demonstrate that
the cost is actually worth it.

3 Learning with Lookahead

This section presents our framework for incorporat-
ing lookahead in history-based models. In this pa-
per, we focus on deterministic history-based models
although our method could be generalized to non-
deterministic cases.

We use the word “state” to refer to a partially
completed analysis as well as the collection of his-
torical information available at each decision point
in deterministic history-based analysis. State transi-
tions are made by “actions” that are defined at each
state. In the example of dependency parsing pre-
sented in Section 2, a state contains all the infor-
mation about past operations, stacks, and queues as

1: Input
2: d: remaining depth of search
3: S0: current state
4: Output
5: S: state of highest score
6: v: highest score
7:
8: function SEARCH(d, S0)
9: if d = 0 then

10: return (S0, w · φ(S0))
11: (S, v)← (null,−∞)
12: for each a ∈ POSSIBLEACTIONS(S0)
13: S1 ← UPDATESTATE(S0, a)
14: (S′, v′)← SEARCH(d− 1, S1)
15: if v′ > v then
16: (S, v)← (S′, v′)
17: return (S, v)

Figure 2: Search algorithm.

well as the observation (i.e. the words in the sen-
tence). The possible actions are shift, reduceR, and
reduceL. In the case of POS tagging, for example, a
state is the words and the POS tags assigned to the
words on the left side of the current target word (if
the tagging is conducted in the left-to-right manner),
and the possible actions are simply defined by the
POS tags in the annotation tag set.

3.1 Search

With lookahead, we choose the best action at each
decision point by considering possible sequences of
future actions and the states realized by those se-
quences. In other words, we need to perform a
search for each possible action.

Figure 2 describes our search algorithm in pseudo
code. The algorithm performs a depth-first search to
find the state of the highest score among the states in
its search space, which is determined by the search
depth d. This search process is implemented with
a recursive function, which receives the remaining
search depth and the current state as its input and
returns the state of the highest score together with
its score.

We assume a linear scoring model, i.e., the score
of each state S can be computed by taking the dot
product of the current weight vector w and φ(S),
the feature vector representation of the state. The

240



1: Input
2: C: perceptron margin
3: D: depth of lookahead search
4: S0: current state
5: ac: correct action
6:
7: procedure UPDATEWEIGHT(C, D, S0, ac)
8: (a∗, S∗, v)← (null, null,−∞)
9: for each a ∈ POSSIBLEACTIONS(S0)

10: S1 ← UPDATESTATE(S0, a)
11: (S′, v′)←SEARCH(D,S1)
12: if a = ac then
13: v′ ← v′ − C
14: S∗c ← S′
15: if v′ > v then
16: (a∗, S∗, v)← (a, S′, v′)
17: if a∗ 6= ac then
18: w ← w + φ(S∗c )− φ(S∗)

Figure 3: Perceptron weight update

scores are computed at each leaf node of the search
tree and backed up to the root.2

Clearly, the time complexity of determinis-
tic tagging/parsing with this search algorithm is
O(nmD+1), where n is the number of actions
needed to process the sentence, m is the (average)
number of possible actions at each state, and D is
the search depth. It should be noted that the time
complexity of k-th order CRFs is O(nmk+1), so
a history-based model with k-depth lookahead is
comparable to k-th order CRFs in terms of train-
ing/testing time.

Unlike CRFs, our framework does not require the
locality of features since it is history-based, i.e., the
decisions can be conditioned on arbitrary features.
One interpretation of our learning framework is that
it trades off the global optimality of the learned pa-
rameters against the flexibility of features.

3.2 Training a margin perceptron

We adapt a learning algorithm for margin percep-
trons (Krauth and Mezard, 1987) to our purpose of

2In actual implementation, it is not efficient to compute the
score of a state from scratch at each leaf node. For most of
the standard features used in tagging and parsing, it is usually
straight-forward to compute the scores incrementally every time
the state is updated with an action.

optimizing the weight parameters for the lookahead
search. Like other large margin approaches such
as support vector machines, margin perceptrons are
known to produce accurate models compared to per-
ceptrons without a margin (Li et al., 2002).

Figure 3 shows our learning algorithm in pseudo
code. The algorithm is very similar to the standard
training algorithm for margin perceptrons, i.e., we
update the weight parameters with the difference of
two feature vectors (one corresponding to the cor-
rect action, and the other the action of the highest
score) when the perceptron makes a mistake. The
feature vector for the second best action is also used
when the margin is not large enough. Notice that the
feature vector for the second best action is automat-
ically selected by using a simple trick of subtracting
the margin parameter from the score for the correct
action (Line 13 in Figure 3).

The only difference between our algorithm and
the standard algorithm for margin perceptrons is that
we use the states and their scores obtained from
lookahead searches (Line 11 in Figure 3), which are
backed up from the leaves of the search trees. In Ap-
pendix A, we provide a proof of the convergence of
our training algorithm and show that the margin will
approach at least half the true margin (assuming that
the training data are linearly separable).

As in many studies using perceptrons, we average
the weight vector over the whole training iterations
at the end of the training (Collins, 2002).

4 Experiments

This section presents four sets of experimental re-
sults to show how the lookahead process improves
the accuracy of history-based models in common
NLP tasks.

4.1 Sequence prediction tasks

First, we evaluate our framework with three se-
quence prediction tasks: POS tagging, chunking,
and named entity recognition. We compare our
method with the CRF model, which is one of the de
facto standard machine learning models for such se-
quence prediction tasks. We trained L1-regularized
first-order CRF models using the efficient stochastic
gradient descent (SGD)-based training method pre-
sented in Tsuruoka et al. (2009). Since our main in-

241



terest is not in achieving the state-of-the-art results
for those tasks, we did not conduct feature engineer-
ing to come up with elaborate features—we sim-
ply adopted the feature sets described in their paper
(with an exception being tag trigram features tested
in the POS tagging experiments). The experiments
for these sequence prediction tasks were carried out
using one core of a 3.33GHz Intel Xeon W5590 pro-
cessor.

The first set of experiments is about POS tagging.
The training and test data were created from the Wall
Street Journal corpus of the Penn Treebank (Marcus
et al., 1994). Sections 0-18 were used as the training
data. Sections 19-21 were used for tuning the meta
parameters for learning (the number of iterations and
the margin C). Sections 22-24 were used for the
final accuracy reports.

The experimental results are shown in Table 1.
Note that the models in the top four rows use exactly
the same feature set. It is clearly seen that the looka-
head improves tagging accuracy, and our history-
based models with lookahead is as accurate as the
CRF model. We also created another set of models
by simply adding tag trigram features, which can-
not be employed by first-order CRF models. These
features have slightly improved the tagging accu-
racy, and the final accuracy achieved by a search
depth of 3 was comparable to some of the best re-
sults achieved by pure supervised learning in this
task (Shen et al., 2007; Lavergne et al., 2010).

The second set of experiments is about chunking.
We used the data set for the CoNLL 2000 shared
task, which contains 8,936 sentences where each to-
ken is annotated with the “IOB” tags representing
text chunks. The experimental results are shown
in Table 2. Again, our history-based models with
lookahead were slightly more accurate than the CRF
model using exactly the same set of features. The
accuracy achieved by the lookahead model with a
search depth of 2 was comparable to the accuracy
achieved by a computationally heavy combination
of max-margin classifiers (Kudo and Matsumoto,
2001). We also tested the effectiveness of additional
features of tag trigrams using the development data,
but there was no improvement in the accuracy.

The third set of experiments is about named en-
tity recognition. We used the data provided for
the BioNLP/NLPBA 2004 shared task (Kim et al.,

2004), which contains 18,546 sentences where each
token is annotated with the “IOB” tags representing
biomedical named entities. We performed the tag-
ging in the right-to-left fashion because it is known
that backward tagging is more accurate than forward
tagging on this data set (Yoshida and Tsujii, 2007).

Table 3 shows the experimental results, together
with some previous performance reports achieved
by pure machine leaning methods (i.e. without rule-
based post processing or external resources such as
gazetteers). Our history-based model with no looka-
head was considerably worse than the CRF model
using the same set of features, but it was signifi-
cantly improved by the introduction of lookahead
and resulted in accuracy figures better than that of
the CRF model.

4.2 Dependency parsing

We also evaluate our method in dependency parsing.
We follow the most standard experimental setting
for English dependency parsing: The Wall Street
Journal portion of Penn Treebank is converted to de-
pendency trees by using the head rules of Yamada
and Matsumoto (2003).3 The data is split into train-
ing (section 02-21), development (section 22), and
test (section 23) sets. The parsing accuracy was eval-
uated with auto-POS data, i.e., we used our looka-
head POS tagger (depth = 2) presented in the previ-
ous subsection to assign the POS tags for the devel-
opment and test data. Unlabeled attachment scores
for all words excluding punctuations are reported.
The development set is used for tuning the meta pa-
rameters, while the test set is used for evaluating the
final accuracy.

The parsing algorithm is the “arc-standard”
method (Nivre, 2004), which is briefly described in
Section 2. With this algorithm, state S corresponds
to a parser configuration, i.e., the stack and the
queue, and action a corresponds to shift, reduceL,
and reduceR. In this experiment, we use the same
set of feature templates as Huang and Sagae (2010).

Table 4 shows training time, test time, and parsing
accuracy. In this table, “No lookahead (depth = 0)”
corresponds to a conventional shift-reduce parsing
method without any lookahead search. The results

3Penn2Malt is applied for this conversion, while depen-
dency labels are removed.

242



Training Time (sec) Test Time (sec) Accuracy
CRF (L1 regularization & SGD training) 847 3 97.11 %
No lookahead (depth = 0) 85 5 97.00 %
Lookahead (depth = 1) 294 9 97.19 %
Lookahead (depth = 2) 8,688 173 97.19 %
No lookahead (depth = 0) + tag trigram features 88 5 97.11 %
Lookahead (depth = 1) + tag trigram features 313 10 97.22 %
Lookahead (depth = 2) + tag trigram features 10,034 209 97.28 %
Structured perceptron (Collins, 2002) n/a n/a 97.11 %
Guided learning (Shen et al., 2007) n/a n/a 97.33 %
CRF with 4 billion features (Lavergne et al., 2010) n/a n/a 97.22 %

Table 1: Performance of English POS tagging (training times and accuracy scores on test data)

Training time (sec) Test time (sec) F-measure
CRF (L1 regularization & SGD training) 74 1 93.66
No lookahead (depth = 0) 22 1 93.53
Lookahead (depth = 1) 73 1 93.77
Lookahead (depth = 2) 1,113 9 93.81
Voting of 8 SVMs (Kudo and Matsumoto, 2001) n/a n/a 93.91

Table 2: Performance of text chunking (training times and accuracy scores on test data).

clearly demonstrate that the lookahead search boosts
parsing accuracy. As expected, training and test
speed decreases, almost by a factor of three, which
is the branching factor of the dependency parser.

The table also lists accuracy figures reported in
the literature on shift-reduce dependency parsing.
Most of the latest studies on shift-reduce depen-
dency parsing employ dynamic programing or beam
search, which implies that deterministic methods
were not as competitive as those methods. It should
also be noted that all of the listed studies learn struc-
tured perceptrons (Collins and Roark, 2004), while
our parser learns locally optimized perceptrons. In
this table, our parser without lookahead search (i.e.
depth = 0) resulted in significantly lower accuracy
than the previous studies. In fact, it is worse than the
deterministic parser of Huang et al. (2009), which
uses (almost) the same set of features. This is pre-
sumably due to the difference between locally opti-
mized perceptrons and globally optimized structured
perceptrons. However, our parser with lookahead
search is significantly better than their determinis-
tic parser, and its accuracy is close to the levels of
the parsers with beam search.

5 Discussion

The reason why we introduced a lookahead mech-
anism into history-based models is that we wanted
the model to be able to avoid making such mistakes
that can be detected only in later stages. Probabilis-
tic history-based models such as MEMMs should be
able to avoid (at least some of) such mistakes by per-
forming a Viterbi search to find the highest proba-
bility path of the actions. However, as pointed out
by Lafferty et al. (2001), the per-state normaliza-
tion of probabilities makes it difficult to give enough
penalty to such incorrect sequences of actions, and
that is primarily why MEMMs are outperformed by
CRFs.

Perhaps the most relevant to our work in terms
of learning is the general framework for search and
learning problems in history-based models proposed
by Daumé III and Marcu (2005). This framework,
called LaSO (Learning as Search Optimization), can
include many variations of search strategies such as
beam search and A* search as a special case. In-
deed, our lookahead framework could be regarded
as a special case in which each search node con-

243



Training time (sec) Test time (sec) F-measure
CRF (L1 regularization & SGD training) 235 4 71.63
No lookahead (depth = 0) 66 4 70.17
Lookahead (depth = 1) 91 4 72.28
Lookahead (depth = 2) 302 7 72.00
Lookahead (depth = 3) 2,419 33 72.21
Semi-Markov CRF (Okanohara et al., 2006) n/a n/a 71.48
Reranking (Yoshida and Tsujii, 2007) n/a n/a 72.65

Table 3: Performance of biomedical named entity recognition (training times and accuracy scores on test data).

Training time (sec) Test time (sec) Accuracy
No lookahead (depth = 0) 1,937 4 89.73
Lookahead (depth = 1) 4,907 13 91.00
Lookahead (depth = 2) 12,800 31 91.10
Lookahead (depth = 3) 31,684 79 91.24
Beam search (k = 64) (Zhang and Clark, 2008) n/a n/a 91.4
Deterministic (Huang et al., 2009) n/a n/a 90.2
Beam search (k = 16) (Huang et al., 2009) n/a n/a 91.3
Dynamic programming (Huang and Sagae, 2010) n/a n/a 92.1

Table 4: Performance of English dependency parsing (training times and accuracy scores on test data).

sists of the next and lookahead actions4, although
the weight updating procedure differs in several mi-
nor points. Daumé III and Marcu (2005) did not try
a lookahead search strategy, and to the best of our
knowledge, this paper is the first that demonstrates
that lookahead actually works well for various NLP
tasks.

Performing lookahead is a very common tech-
nique for a variety of decision-making problems
in the field of artificial intelligence. In computer
chess, for example, programs usually need to per-
form a very deep search in the game tree to find a
good move. Our decision-making problem is sim-
ilar to that of computer Chess in many ways, al-
though chess programs perform min-max searches
rather than the “max” searches performed in our al-
gorithm. Automatic learning of evaluation functions
for chess programs can be seen as the training of
a machine learning model. In particular, our learn-
ing algorithm is similar to the supervised approach

4In addition, the size of the search queue is always truncated
to one for the deterministic decisions presented in this paper.
Note, however, that our lookahead framework can also be com-
bined with other search strategies such as beam search. In that
case, the search queue is not necessarily truncated.

(Tesauro, 2001; Hoki, 2006) in that the parameters
are optimized based on the differences of the feature
vectors realized by the correct and incorrect actions.

In history-based models, the order of actions is of-
ten very important. For example, backward tagging
is considerably more accurate than forward tagging
in biomedical named entity recognition. Our looka-
head method is orthogonal to more elaborate tech-
niques for determining the order of actions such as
easy-first tagging/parsing strategies (Tsuruoka and
Tsujii, 2005; Elhadad, 2010). We expect that incor-
porating such elaborate techniques in our framework
will lead to improved accuracy, but we leave it for
future work.

6 Conclusion

We have presented a simple and general framework
for incorporating a lookahead process in history-
based models and a perceptron-based training algo-
rithm for the framework. We have conducted ex-
periments using standard data sets for POS tagging,
chunking, named entity recognition and dependency
parsing, and obtained very promising results—the
accuracy achieved by the history-based models en-

244



hanced with lookahead was as competitive as glob-
ally optimized models including CRFs.

In most of the experimental results, steady im-
provement in accuracy has been observed as the
depth of the search is increased. Although it is
not very practical to perform deeper searches with
our current implementation—we naively explored
all possible sequences of actions, future work should
encompass extending the depths of search space
by introducing elaborate pruning/search extension
techniques.

In this work, we did not conduct extensive feature
engineering for improving the accuracy of individ-
ual tasks because our primary goal with this paper is
to present the learning framework itself. However,
one of the major merits of using history-based mod-
els is that we are allowed to define arbitrary features
on the partially completed structure. Another inter-
esting direction of future work is to see how much
we could improve the accuracy by performing ex-
tensive feature engineering in this particular learning
framework.

Appendix A: Convergence of the Learning
Procedure

Let {xi, aic}Ki=1 be the training examples where aic
is the correct first action for decision point xi, and
let Si be the set of all the states at the leaves of
the search trees for xi generated by the lookahead
searches and Sic be the set of all the states at the
leaves of the search tree for the correct action aic.
We also define Si = Si \ Sic. We write the weight
vector before the k-th update as wk. We define
S∗c = argmax

S∈Sic
w·φ(S) and S∗ = argmax

S∈Si
w·φ(S)5.

Then the update rule can be interpreted as wk+1 =
wk +(φ(S∗c )−φ(S∗)). Note that this update is per-
formed only when φ(Sc) ·wk−C < φ(S∗) ·wk for
all Sc ∈ Sc since otherwise S∗ in the learning algo-
rithm cannot be a state with an incorrect first action.
In other words, φ(Sc) ·w − φ(S∗) ·w ≥ C for all
Sc ∈ Sc after convergence.

Given these definitions, we prove the convergence
for the separable case. That is, we assume the exis-
tence of a weight vector u (with ||u|| = 1), δ (> 0),

5S∗c and S∗ depend on the weight vector at each point, but
we omit it from the notation for brevity.

and R (> 0) that satisfy:

∀i,∀Sc ∈ Sic,∀S ∈ Si φ(Sc) · u− φ(S) · u ≥ δ,
∀i,∀Sc ∈ Sic,∀S ∈ Si ||φ(Sc)− φ(S)|| ≤ R.

The proof is basically an adaptation of the proofs
in Collins (2002) and Li et al. (2002). First, we ob-
tain the following relation:

wk+1 · u = wk · u + (φ(S∗c ) · u− φ(S∗) · u)
= wk · u + δ ≥ w1 · u + kδ = kδ.

Therefore, ||wk+1 · u||2 = ||wk+1||2 ≤ (kδ)2 —
(1). We assumed w1 = 0 but this is not an essential
assumption.

Next, we also obtain:

||wk+1||2 ≤ ||wk||2 + 2(φ(S∗c )− φ(S∗)) ·wk

+||φ(S∗c )− φ(S∗)||2

≤ ||wk||2 + 2C + R2

≤ ||w1||2 + k(R2 + 2C) = k(R2 + 2C)— (2)

Combining (1) and (2), we obtain k ≤ (R2 +
2C)/δ2. That is, the number of updates is bounded
from above, meaning that the learning procedure
converges after a finite number of updates. Substi-
tuting this into (2) gives ||wk+1|| ≤ (R2 + 2C)/δ
— (3).

Finally, we analyze the margin achieved by the
learning procedure after convergence. The margin,
γ(w), is defined as follows in this case.

γ(w) = min
xi

min
Sc∈Sic,S∈Si

φ(Sc) ·w − φ(S) ·w
||w||

= min
xi

min
Sc∈Sic

φ(Sc) ·w − φ(S∗) ·w
||w||

After convergence (i.e., w = wk+1), φ(Sc) · w −
φ(S∗)·w ≥ C for all Sc ∈ Sc as we noted. Together
with (3), we obtain the following bound:

γ(w) ≥ min
xi

δC

2C + R2

=
δC

2C + R2
=

(
δ

2

)(
1− R

2

2C + R2

)
As can be seen, the margin approaches at least half
the true margin, δ/2 as C → ∞ (at the cost of infi-
nite number of updates).

245



References

Michael Collins and Brian Roark. 2004. Incremental
parsing with the perceptron algorithm. In Proceedings
of ACL, pages 111–118.

Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings of
EMNLP, pages 1–8.

Hal Daumé III and Daniel Marcu. 2005. Learning as
search optimization: Approximate large margin meth-
ods for structured prediction. In Proceedings of ICML,
pages 169–176.

Yoav Goldbergand Michael Elhadad. 2010. An effi-
cient algorithm for easy-first non-directional depen-
dency parsing. In Proceedings of NAACL-HLT, pages
742–750.

Kunihito Hoki. 2006. Optimal control of minimax
search results to learn positional evaluation. In Pro-
ceedings of the 11th Game Programming Workshop
(GPW), pages 78–83 (in Japanese).

Liang Huang and Kenji Sagae. 2010. Dynamic program-
ming for linear-time incremental parsing. In Proceed-
ings of ACL, pages 1077–1086.

Liang Huang, Wenbin Jiang, and Qun Liu. 2009.
Bilingually-constrained (monolingual) shift-reduce
parsing. In Proceedings of EMNLP, pages 1222–1231.

J.-D. Kim, T. Ohta, Y. Tsuruoka, Y. Tateisi, and N. Col-
lier. 2004. Introduction to the bio-entity recogni-
tion task at JNLPBA. In Proceedings of the Interna-
tional Joint Workshop on Natural Language Process-
ing in Biomedicine and its Applications (JNLPBA),
pages 70–75.

W Krauth and M Mezard. 1987. Learning algorithms
with optimal stability in neural networks. Journal of
Phisics A, 20(11):L745–L752.

Taku Kudo and Yuji Matsumoto. 2001. Chunking with
support vector machines. In Proceedings of NAACL.

John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. In Pro-
ceedings of ICML, pages 282–289.

Thomas Lavergne, Olivier Cappé, and François Yvon.
2010. Practical very large scale CRFs. In Proceed-
ings of ACL, pages 504–513.

Yaoyong Li, Hugo Zaragoza, Ralf Herbrich, John Shawe-
Taylor, and Jaz S. Kandola. 2002. The perceptron
algorithm with uneven margins. In Proceedings of
ICML, pages 379–386.

Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1994. Building a large annotated cor-
pus of English: The Penn Treebank. Computational
Linguistics, 19(2):313–330.

Andrew McCallum, Dayne Freitag, and Fernando
Pereira. 2000. Maximum entropy markov models for
information extraction and segmentation. In Proceed-
ings of ICML, pages 591–598.

Joakim Nivre, Johan Hall, and Jens Nilsson. 2004.
Memory-based dependency parsing. In Proceedings
of CoNLL, pages 49–56.

Joakim Nivre. 2004. Incrementality in deterministic de-
pendency parsing. In ACL 2004 Workshop on Incre-
mental Parsing: Bringing Engineering and Cognition
Together, pages 50–57.

Daisuke Okanohara, Yusuke Miyao, Yoshimasa Tsu-
ruoka, and Jun’ichi Tsujii. 2006. Improving the scal-
ability of semi-markov conditional random fields for
named entity recognition. In Proceedings of COL-
ING/ACL, pages 465–472.

Adwait Ratnaparkhi. 1996. A maximum entropy model
for part-of-speech tagging. In Proceedings of EMNLP
1996, pages 133–142.

Libin Shen, Giorgio Satta, and Aravind Joshi. 2007.
Guided learning for bidirectional sequence classifica-
tion. In Proceedings of ACL, pages 760–767.

Gerald Tesauro, 2001. Comparison training of chess
evaluation functions, pages 117–130. Nova Science
Publishers, Inc.

Yoshimasa Tsuruoka and Jun’ichi Tsujii. 2005. Bidirec-
tional inference with the easiest-first strategy for tag-
ging sequence data. In Proceedings of HLT/EMNLP
2005, pages 467–474.

Yoshimasa Tsuruoka, Jun’ichi Tsujii, and Sophia Ana-
niadou. 2009. Stochastic gradient descent training
for l1-regularized log-linear models with cumulative
penalty. In Proceedings of ACL-IJCNLP, pages 477–
485.

Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical
dependency analysis with support vector machines. In
Proceedings of IWPT, pages 195–206.

Kazuhiro Yoshida and Jun’ichi Tsujii. 2007. Reranking
for biomedical named-entity recognition. In Proceed-
ings of ACL Workshop on BioNLP, pages 209–216.

Yue Zhang and Stephen Clark. 2008. A tale of
two parsers: investigating and combining graphbased
and transition-based dependency parsing using beam-
search. In Proceedings of EMNLP, pages 562–571.

246


