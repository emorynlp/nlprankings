















































Instructions for ACL-2013 Proceedings


Bilingual Sentence Alignment of a Parallel Corpus by Using English as 

a Pivot Language 

 
Josafá de Jesus Aguiar Pontes 

National Polytechnic School of Ecuador, Quito, Ecuador 
Ladrón de Guevara E11-253, Quito 170517 

josafa@furui.cs.titech.ac.jp 

 

  

Abstract 

Statistically training a machine translation 

model requires a parallel corpus contain-

ing a huge amount of aligned sentence 

pairs in both languages. However, it is not 

easy to obtain such a corpus when English 

is not the source or the target language. 

The European Parliament parallel corpus 

contains only English sentence alignments 

with 20 European languages, missing 

alignments for other 190 language pairs. A 

previous method using sentence length in-

formation is not enough reliable to pro-

duce alignments for training statistical 

machine translation models. Hybrid meth-

ods combining sentence length and bilin-

gual dictionary information may produce 

better results, but dictionaries may not be 

affordable. Thus, we introduce a tech-

nique which aligns non-English corpora 

from the European Parliament by using 

English as a pivot language without a bi-

lingual dictionary. Our technique has been 

illustrated with French and Spanish, re-

sulting on an equivalent performance with 

the existing one in the original English-

French and English-Spanish corpora. 

1 Introduction 

Obtaining a parallel corpus of aligned sentence 

pairs is an important task to further work for hu-

man translators and several natural language pro-

cessing applications such as statistical machine 

translation (Brown et al, 1990; Melamed, 1998), 

                                                 
1 Europarl, 2005. www.statmt.org/europarl/ 

cross-lingual information retrieval (Davis and 

Dunning, 2995; Landauer and Littman, 1990; 

Oard, 1997) and lexical acquisition (Gale and 

Church, 1991; Melamed, 1997), to mention some. 

Bilingual corpora are useful for human translators 

to search for a chunk of text in a source language 

and to find its corresponding translation into a tar-

get language. From the machine's standpoint, one 

of the most common applications is on training 

statistical models for machine translation. In the 

translation domain, no matter human or machine, 

they both need a very huge amount of aligned sen-

tence pairs in order to find appropriate word com-

bination that enable them to produce good trans-

lations.  

Each language is a world of symbols made of 

its own set of words and their possible combina-

tions that lead to a meaning from the native speak-

ers' point of view. A parallel corpus comes as a 

map in between two languages, indicating which 

set of word combinations in a source language 

produces another set of words in a target language. 

Being so, we assume that the more sentence pairs 

there are in a corpus, the better is the mapping be-

tween the two languages and consequently, the 

better are the derived translations from it. There-

fore, a huge amount of translated sentence pairs is 

essential. 

Due to this growing demand, a number of par-

allel corpora have become available within the 

last decade, for instance the Europarl corpus 

(Koehn, 20051), the News from OPUS2, the JRC-

2 Tiedemann, 2009 http://opus.lingfil.uu.se/ECB.php 



Acquis corpus3, the MultiUN corpus4 and the EU 

Official Journal EU Official Journal Multilingual 

Legal Text in 22 European Languages (Gale and 

Church, 1993), which are freely downloadable for 

research purposes. The Europarl corpus in partic-

ular is a parallel corpus extracted from the pro-

ceedings of the European Parliament. It consists 

of texts in 21 European languages, where English 

is the only language with which the other lan-

guages are aligned. Some of the remaining re-

sources above mentioned do contain alignments 

between all combinations of language pairs; how-

ever, the quality of these alignments is questiona-

ble given that the alignment method utilized for 

most of them is solely based on sentence length 

information (Varga et al., 2005). Our experiments 

show that such alignments may present around 

90% of precision. Obviously, the performance de-

pends on the internal arrangement of the sentences 

being provided as input. Although the information 

of a good bilingual dictionary may be used to en-

hance the performance of an aligner (Schmid, 

19945), it is not normally available for free, even 

less when none of the two languages involved is 

English. In other words, most of the freely availa-

ble non-English parallel corpora have not been 

aligned with the use of the respective bilingual 

dictionaries and therefore the quality relies basi-

cally on sentence length information. 

Although the Europarl corpus has also been 

aligned with sentence length feature, there are un-

derlying alignment information and noise removal 

which make the final quality to be very high. First, 

its alignment is simplified by the fact that the texts 

are originally available in a paragraph aligned for-

mat. Second, each paragraph is typically small, 

containing from 2 to 5 sentences only. Third, 

much noise is removed by discarding an utterance 

of a speaker when the number of paragraphs in it 

differs in the two languages being aligned. The 

prior data preparation done by the underlying par-

agraph information combined with the noise re-

                                                 
3 Ralf et al., 2006. http://ipsc.jrc.ec.europa.eu/in-
dex.php?id=198 
4 Eisele and Chen, 2010 www.dfki.de/lt/publica-
tion_show.php?id=4790 

 

moval technique leads to an alignment of excel-

lent quality. According to our experiments its pre-

cision reaches more than 99%. 

Each corpus contains approximately 2 million 

English sentences and it is pairwise aligned with 

20 other European languages. Since each parallel 

corpus is independently aligned, the number of 

sentences in each bitext is not the same across the 

language pairs. Most of the difference is due to the 

utterance removal process described above which 

occurred prior to the alignment. Consequently, not 

all the English sentences of a corpus (e.g. the Eng-

lish part from the English-French bitext) are pre-

sent in the other corpus (e.g. the English part from 

the English-Spanish bitext). In other words, con-

sidering the English-French and the English-

Spanish corpora for example, not all of the Eng-

lish sentences from the former can be found in the 

latter and viceversa. It means there are sentence 

insertions, deletions and substitutions when we 

consider two English corpora coming from 

diferent aligned language pairs of the same Euro-

parl corpus. 

It is unreasonable to expect the same alignment 

precision of two non-English texts from the Euro-

parl corpus just by using the sentence length in-

formation. The prior sentence insertions, deletions 

and substitutions introduce an observable noise 

when comparing a pair of non-English texts, mak-

ing harder the work of the aligner. In fact, our ex-

periments point out to a precision of only 90% 

given an amount of such a data. As previously 

stated, a bilingual dictionary may be helpful to im-

prove this figure, but unfortunately, good ones are 

very expensive6  to be affordable by developing 

countries for research purposes. 

Taking these constraints into consideration, we 

have developed a sentence alignment method 

which exempts the use a bilingual dictionary 

when a multilingual corpus has previously and ef-

ficiently been aligned with English. This is the 

case of the Europarl corpus which contains only 

English sentence alignments with other lan-

guages. This paper is organized in the following 

5 www.cis.unimuenchen.de/~schmid/tools/TreeTagger/ 
6 ELRA: SCI-FRES-EURADIC http://catalog.elra.info/pro-
duct_info.php?cPath=42_45&products_id=668 

 



way: In the Section 2 we describe our method. 

Section 3 contains the experiments for validating 

the method. Section 4 brings the results and the 

related discussions. In Section 5 we point out to 

conclusions and future work. 

Bilingual Sentence Alignment Algorithm 

This section is divided into two parts. First, we de-

fine the core algorithm and explain which type of 

corpus is needed in order to utilize the method. 

Then we provide additional details of the algo-

rithm for implementation. 

Assumptions and the Core of the Algorithm 

We assume that we use a multilingual corpus 

which has previously been aligned with at least 

one language. Let's say that English is the pivot 

language. We want to obtain sentence alignments 

between any two foreign (non-English) languages 

of this data. Let's illustrate our method with 

French and Spanish. By assumption, there are 

available an English-French and an English-Span-

ish corpora, where each corpus is individually 

sentence aligned with English as the pivot lan-

guage. Although the majority of the English sen-

tences of both corpora are the same, not all of 

them need to be so. In other words, we allow for 

insertions, deletions and substitutions of English 

sentences on both sides and therefore the number 

of sentences in both bitexts are different. This is 

the case of the Europarl corpus. 

Our method is very simple. It basically consists 

of creating a new alignment between two English 

corpora while keeping the reference to the original 

alignment information in order to map from one 

foreign language to the other. For instance, sup-

pose that we need to obtain a French-Spanish sen-

tence alignment. Since English is the common 

language for both English-French and English-

Spanish corpora, the English texts are first aligned 

with each other. The original English-French and 

the English-Spanish alignment information is the 

basis for the new English-English sentence align-

ment to work properly. 

Four cases are possible during this alignment 

process. First, the simplest cases consist of those 

sentences which are exactly the same in both cor-

pora (one-to-one cases). Second, the first side of 

the corpus contains a short sentence which needs 

to be concatenated with one or more adjacent sen-

tences in order to produce the same sequence of 

characters as the second side (many-to-one cases). 

Third, the first side of the corpus contains a long 

sentence while the second contains a short sen-

tence which needs to be concatenated with one or 

more adjacent sentences in order to result in the 

same sequence of characters as the first side (one-

to-many cases). And finally, there are cases where 

a sentence of a side is not a substring of the sen-

tence from the other side or vice-versa and there-

fore these sentence pairs are not easily aligned 

(one-to-zero or zero-to-one cases).  

In spite of this, we still try to find an alignment 

for them, given that we allow for insertions, dele-

tions and substitutions of English sentences in the 

input data at both sides. In such a case, our algo-

rithm temporarily stores the sentence positions of 

both unaligned sentences in order to perform the 

following procedures. A pointer to the sentence of 

the first side refers to a string that is compared 

with each one of the next 500 sentences of the sec-

ond side. If found somewhere, an alignment is ob-

tained and the algorithm proceeds from the next 

sentence position on, at both sides. Otherwise, a 

pointer to the sentence of the second side is used 

for comparison with each of the next 500 sen-

tences of the first side. If found somewhere, an 

alignment is obtained and the algorithm proceeds 

from the next sentence position on, at both sides. 

However, when no alignment can be obtained af-

ter trying these thousand times, we assume there 

is no way of aligning those pointed sentences with 

any other adjacent sentence of the opposite side. 

Then it continues the execution of the aligner from 

the next sentence positions on, right after the 

pointers.  

Note that we assume the number 500 as a gen-

erous search limit between the two texts, given 

that during the preparation of the Europarl corpus, 

each paragraph typically contained only a few 

sentences and the discarded utterances occurred 

only when the number of paragraphs in them dif-

fered in the original two languages being aligned. 

During the execution of this algorithm, the his-

tory of all sentence positions having successful 

English-English alignments is stored. We call it 

ladder alignment history, making reference to the 



Hunalign tool developed by Varga et al. It con-

tains a list of pair of numbers, representing the 

sentence position of both English corpora having 

successful alignment with each other. This is the 

main information needed for aligning the pairs of 

French and Spanish sentences of our example. 

Note that the sentence positions on the left stand 

for the English corpus originally aligned with 

French, while the sentence positions on the right 

stand for the English corpus originally aligned 

with Spanish. Therefore, each pair of numbers 

represents the alignment between French and 

Spanish sentences. While the number of lines in 

the ladder alignment history represent the number 

of newly aligned sentences. 

Also note that the sentence positions of the new 

alignment are relative to the original alignments 

in the English-French and English-Spanish paral-

lel corpora. It means that the original alignment 

errors are also preserved. A new alignment error 

is produced whenever an x English sentence is 

correctly aligned with French but incorrectly 

aligned with Spanish or vice-versa. This is a one-

to-one error type, and it is due to a single bad pre-

existing alignment which is found either in the 

English-French or in the English-Spanish corpus. 

Now, let's consider the case where a y English 

sentence is originally misaligned with both 

French and Spanish at the same time. The newly 

produced alignment accounts for both as a single 

error, given that the French sentence is misaligned 

with a single Spanish sentence. This is a two-to-

one error type.  

#New alignment errors  ≤ ∑(#alignment errors of 

Pivot-Foreign1) +∑(#alignment errors of Pivot-

Foreign2) (Equation 1) 

It implies that the number of alignment errors 

produced by our algorithm is usually less than the 

sum of all misalignments for each original bitext. 

In the worst case, there is no two-to-one error 

type, i.e. the sentences of both parallel corpora do 

not contain any overlapping misalignments. In  

such a case, the number of new alignment errors 

is the sum of all misalignments present in both 

original corpora. This idea is expressed by Equa-

tion (1), where Pivot indicates the common lan-

guage of the original alignments (i.e. English), 

while Foreign1 and Foreign2 represent the pair of 

foreign languages that our algorithm aligns, being 

illustrated here by the French and Spanish lan-

guages. 

Additional Details of the Algorithm 

1. Now that we have presented the core of our 
algorithm, we introduce some further details 

which allow our algorithm to work efficiently. 

When an English-English alignment is one-to-

many or many-to-one, a special symbol is added 

in between two adjacent sentences. The amount of 

special symbols indicates how many short adja-

cent sentences are concatenated together in order 

to correspond to the same string of characters as 

the long sentence. We also store the information 

whether the concatenated short sentences are on 

the left (English-French corpus) or on the right 

(English-Spanish corpus), so that our algorithm 

can later reproduce the same number of sentence 

concatenations to the adjacent sentences of a cor-

pus. This information is stored in the ladder align-

ment history as a pair of numbers, where the first 

one stands for the number of concatenated English 

sentences originating from the English-French 

corpus while the second is the number of concat-

enated English sentences originating from the 

English-Spanish corpus. 

However, the ladder alignment history at this 

point is not yet ready. Some wrong alignment 

might have been introduced during the English-

English sentence alignment process, which is nor-

mal for any aligner. We do here a post-processing 

which confirms whether every pair of aligned 

English sentences contains exactly the same string 

of characters. The wrongly aligned sentences are 

removed. This is the way we use for automatically 

validating the produced alignments. We do so by 

fetching the respective pair of English sentences 

whose indexes are present in the ladder alignment 

history. They are extracted from both English 

texts, respectively from the English-French and 

the English-Spanish corpora. Then, we remove 

the special symbols used for sentence concatena-

tion of one-to-many or many-to-one cases in order 

to perform the string comparisons. Finally, we 

preserve only those lines containing exactly the 

same English sentences, and consequently pro-

ducing a clean ladder alignment history. 



We use the sentence alignment information pre-

sent in it to obtain the aligned foreign sentence 

pairs. It tells the sentence index of the first foreign 

language which matches with the sentence index 

of the second one. It also tells on a sentence basis 

how many adjacent sentences of a corpus need to 

be concatenated in order to fully correspond to its 

translation. The work of the algorithm from this 

point on is basically to read the pieces of data from 

the following three files: ladder alignment history, 

first and second foreign language corpora. It com-

bines the sentences together in order to produce 

the aligned parallel corpus. It finalizes the process 

by removing null sentence pairs and those having 

null translations. 

Experiments 

2. We want to quantify the efficiency of our al-
gorithm to produce an aligned parallel corpus of 

non-English language pairs given that the sen-

tences in both languages have been previously 

aligned with English. We illustrate the perfor-

mance of our method by using the French and the 

Spanish texts from the Europarl corpus, which had 

been previously aligned with English on an indi-

vidual basis. The English-French and the English-

Spanish parallel corpora are freely available for 

download. 

We have created a reference French-Spanish 

parallel corpus from the Europarl data. We ex-

tracted the first 14,941 sentences from the French 

corpus and the first 14,356 sentences from the 

Spanish corpus, totalizing 29,297 monolingual 

sentences. This alignment has been done in three 

steps. First, each corpus has been individually 

lemmatized by using the TreeTagger software. 

Second, we utilized a sentence aligner software 

called Hunalign to produce the sentence align-

ments, providing both lemmatized corpora as in-

put and a French-Spanish bilingual dictionary of 

69,231 entries. Finally, we manually revised all 

the automatically produced alignments by the 

tool. Although a considerable part of the align-

ments were correct, we still had to apply manual 

corrections on about 2,000 alignments. As result, 

we obtained 13,847 pairs of correctly aligned 

French-Spanish sentences. This is the gold data 

for the evaluation. 

Once we have the reference alignments ready, 

we align the sentences based on two previous 

methods. For that, we utilize the Hunalign soft-

ware. This tool can perform the work based only 

on sentence length information (6). In this case, 

the input data is the pair of texts to be aligned. 

This first method produces our baseline align-

ments. In addition, the software can also align sen-

tences based on the combination of sentence 

length and bilingual dictionary information. In 

this case, the input data is the same pair of texts 

and a good bilingual dictionary. This second 

method is supposed to produce better results than 

the baseline. 

Finally, we are ready to evaluate our algorithm. 

It receives as input the 14,941 non-lemmatized 

English sentences coming from the English-

French corpus and the 14,356 non-lemmatized 

English sentences coming from the English-Span-

ish corpus. Initially, it produces 14,855 non-vali-

dated English-English sentence alignments. We 

call it non-validated because at this point our al-

gorithm still needs to confirm whether every pair 

of aligned English sentences matches exactly the 

same string of characters for both corpora. After 

the validation process has taken place, it produces 

a total amount of 13,711 English-English sentence 

alignments in the clean ladder alignment history. 

 

4 Results and Discussions 

 

First, we want to check the performance of the 

alignment based only on sentence length infor-

mation, which is our baseline. For this, we provide 

the Hunalign tool with 14,941 lemmatized sen-

tences from the French corpus and the 14,356 

lemmatized sentences from the Spanish corpus. 

Consequently, it produces 13,459 true positives 

out of 13,847 and 1,354 false positives. This out-

come indicates a precision rate of 0.908. The num-

ber of false negatives is 388 (13,847-13,459), re-

sulting on a recall rate of 0.972. Table 1 shows 

these results under the column Baseline. 

Second, we want to check the performance of the 

alignment based on sentence length combined 

with bilingual dictionary information. Now, the 

tool receives as input the same lemmatized paral-



lel corpus and our French-Spanish bilingual dic-

tionary having 69,231 entries. It produces 13,704 

true positives out of 13,847, while the number of 

false positives is 1,146. As for the precision rate, 

it raises to 0.923. The number of false negatives 

decreases to 143 (13,847-13,704) cases, produc-

ing a recall rate of 0.989. The results of this ex-

periment are summarized on the SL+Dic column 

of Table 1. 

Third, after obtaining the 13,711 sentence pairs 

described in the last paragraph of Section 3, our 

algorithm removes the null sentence pairs and 

those having null translations. Finally we obtain a 

French-Spanish parallel corpus having 13,640 en-

tries. Then we compare our alignments with the 

reference. On the one hand, we obtain a result of 

13,542 correct alignments and 98 incorrect ones. 

In other words, the number of true positives is 

13,542 instances while the number of false posi-

tives is just 98 cases. This result indicates a very 

good precision rate of 0.993. On the other hand, 

the algorithm misses 305 (13,847-13,542) align-

ments that are still possible. This figure represents 

the instances of false negatives, which leads to a 

recall rate of 0.978. Table 1 contains these results 

under its last column.  

For this particular data, the misses of correct 

alignments is more than 3 times the number of 

false positives, representing a loss rate of 2.2% of 

all possible correct alignments. This implies that 

if the size of a parallel corpus for training a statis-

tical machine translator model is very large, the 

loss would be irrelevant since the amount of train-

ing data would still be very large. For such a pur-

pose and under such conditions, an excellent pre-

cision rate is much more relevant than a perfect 

recall. Note that the highest possible precision rate 

is essential because otherwise wrong sentence 

alignments necessarily produce wrong word mis-

alignments and consequently wrong translations. 

However when the number of wrong sentence 

alignments present in the parallel corpora is mini-

mal (i.e. less than 1%), lesser will be the errors 

introduced to the posterior training of word align-

ments. In fact, good translation models depend not 

only on the size of a parallel corpus, but also on 

the high quality of the sentence alignments. In Ta-

ble 1, we present the results of the evaluation by 

using three methods: 1) sentence length (SL) in-

formation (baseline), 2) sentence length + bilin-

gual dictionary (SL+Dic) information and 3) our 

method, which is based on the high quality of ex-

isting alignments with the pivot language. Note 

also that the method proposed by Gale and 

Church, 1991 is indicated as a baseline when there 

is no other source of information available than 

the sentences themselves. However, when a good 

bilingual dictionary is available, an improvement 

is observed and the precision rate rises in 15% = 

(100-(1,146*100/1,354))/100 for the tested data. 

But an even better result is obtained when a high 

quality alignment has been previously performed 

with a pivot language. The improvement we could 

observe from applying our method was 92% = 

(100-(98*100/1,354))/100 for the tested data. This 

excellent result suggests that our method is effi-

cient to transfer the original alignment infor-

mation from a pair of parallel corpora sharing a 

common language to aligning the new pair of lan-

guages in question. 

 

 

 Baseline SL+Dic Our 

method 

True posi-

tives   

13,459 13,704 13,542 

False posi-

tives 

1,354 1,146 98 

False nega-

tives 

388 143 305 

Precision 0.908 0.923 0.993 

Recall 0.972 0.989 0.978 

Table 1: French-Spanish sentence alignment 

using three methods 

Conclusions and Future Work 

3. A number of natural language processing ap-
plications heavily depend upon the availability of 

a parallel corpus. Statistical machine translation 

for instance requires a parallel corpus containing 

a huge amount of aligned sentence pairs in both 

languages. However, the lack of availability of al-

most perfectly aligned non-English parallel cor-

pus makes unfeasible the development of such ap-

plications and researches.  



Nevertheless, the relatively recent availability 

of the Europarl corpus which aligns English sen-

tences with other 20 European languages has shed 

light on the development of our new method for 

obtaining such a training data. We have intro-

duced a technique, which allows for sentence 

alignments of non-English texts based on the orig-

inal English alignments, given a multilingual par-

allel corpus such as the Europarl. 

Our method has been evaluated and tested 

against two previous methods: the first one utiliz-

ing sentence length information (baseline), while 

the second one, combining sentence length with 

bilingual dictionary information. Our method has 

proved to be much more efficient to align French 

and Spanish sentences than the other two previous 

methods. By applying our method, we could ob-

serve an error rate reduction of false positives of 

92% in comparison with the baseline. Of course, 

this is due to the good quality of the original align-

ments, which are present in the Europarl corpus. 

Unfortunately, the proposed approach of aligning 

corpora at the sentence level cannot be applied to 

all sorts of bilingual data as it needs the source and 

target already aligned with a pivot language. This 

is a limitation of course, but even more limiting is 

when there is no reliable parallel corpus available 

at all for the desired language pairs. 

Further work on this area stands for applying 

our method over all the 20 European languages of 

the Europarl texts. The use of our method will al-

low for building up to 190 new language pairs out 

of these corpora. We intend to develop mecha-

nisms to process all this data and make the non-

English parallel corpora available for future re-

search and development of natural language pro-

cessing applications. We hope this contribution 

will foster research and innovation in order to help 

on the development of machine translation sys-

tems for language pairs which data is not afforda-

ble or cannot be easily obtained. 

Acknowledgments  

This scientific work has been financed by the Pro-

meteo Project of the Secretaría de Educación Su-

perior de Ciencia, Tecnología e Innovación, 

SENESCYT of the Republic of Ecuador under the 

grant 20130943. We also would like to thank re-

searcher Philipp Koehn who contributed by 

providing valuable information for validating the 

novelty of this research. 

References 

Brown, P.F. et al.:  A Statistical Approach to Ma-
chine Translation. Computational Linguistics, 
16(2), 79-85 (1990).  

Davis, M., Dunning T.: A TREC Evaluation of 
Query Translation Methods for Multi-Lingual 
Text Retrieval. Fourth Text Retrieval Confer-
ence (TREC-4). NIST (1995).  

Eisele, A., Chen, Y.: MultiUN: A Multilingual 
Corpus from United Nation Documents. Pro-
ceedings of the Seventh conference on Interna-
tional Language Resources and Evaluation, 
Pages 2868-2872, La Valletta, Malta, European 
Language Resources Association (ELRA), 
5/2010, www.dfki.de/lt/publica-
tion_show.php?id=4790. 

ELRA: SCI-FRES-EURADIC French-Spanish 
Bilingual Dictionary. Catalog Reference : 
ELRA-M0035, http://catalog.elra.info/pro-
duct_info.php?cPath=42_45&pro-
ducts_id=668. 

EU Official Journal Multilingual Legal Text in 22 
European Languages, http://apertium.eu/data 

 

Gale, W.A., Church, K. W.: Identifying Word 
Correspondences in Parallel Texts. Fourth 
DARPA Workshop on Speech and Natural lan-
guage, Asilomar, California (1991).  

Gale, W.A., Church, K. W.: A Program for Align-
ing Sentences in Bilingual Corpora. Computa-
tional Linguistics, 19(1) (1993). 

Koehn, P.: Europarl: A Parallel Corpus for Statis-
tical Machine Translation,  MT Summit (2005), 
www.statmt.org/europarl/ 

Landauer, T.K., Littman, M. L.: Fully Automatic 
Cross-Language Document Retrieval Using 
Latent Semantic Indexing. Proceedings of the 
Sixth Annual Conference of the UW Centre for 
the New Oxford English Dictionary and Text 
Research, pp. 31-38, UW Centre for the New 
OED and Text Research, Waterloo, Ontario 
(1990) 

Melamed, I.D.: Word-to-word Models of Transla-
tion Equivalence. IRCS technical report #98-
08, University of Pennsylvania (1998) 



Melamed, I.D.: Automatic Discovery of Noncom-
positional Compounds in Parallel Data. Pro-
ceedings of the 2nd Conference on Empirical 
Methods in Natural Language Processing 
(EMNLP-97), Brown University (1997). 

Oard, D.W.: Cross-language Text Retrieval Re-
search in the USA. Third DELOS Workshop. 
European Research Consortium for Informatics 
and Mathematics (1997).  

Ralf, S. et al. : The JRC-Acquis: A Multilingual 
Aligned Parallel Corpus with 20+ Languages. 
Proceedings of the 5th International Confer-
ence on Language Resources and Evaluation 
(LREC'2006). Genoa, Italy, (2006), 
http://ipsc.jrc.ec.europa.eu/index.php?id=198. 

Schmid, H.: Probabilistic Part-of-Speech Tagging 
Using Decision Trees. Proceedings of Interna-
tional Conference on New Methods in Lan-
guage Processing, Manchester, UK, 1994. 
www.cis.unimuenchen.de/~schmid/tools/Tree-
Tagger/. 

Tiedemann, J.: News from OPUS - A Collection 
of Multilingual Parallel Corpora with Tools and 
Interfaces. Recent Advances in Natural Lan-
guage Processing (vol V), pages 237-248, John 
Benjamins, Amsterdam/Philadelphia (2009), 
http://opus.lingfil.uu.se/ECB.php 

Varga, D. et al. : Parallel Corpora for Medium 
Density Languages. In Proceedings of the 
RANLP 2005, pages 590-596 (2005) 

 


