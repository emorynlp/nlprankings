










































Hierarchical Spectral Partitioning of Bipartite Graphs to Cluster Dialects and Identify Distinguishing Features


Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 33–41,
Uppsala, Sweden, 16 July 2010. c©2010 Association for Computational Linguistics

Hierarchical spectral partitioning of bipartite graphs to cluster dialects
and identify distinguishing features

Martijn Wieling
University of Groningen

The Netherlands
m.b.wieling@rug.nl

John Nerbonne
University of Groningen

The Netherlands
j.nerbonne@rug.nl

Abstract
In this study we apply hierarchical spectral
partitioning of bipartite graphs to a Dutch
dialect dataset to cluster dialect varieties
and determine the concomitant sound cor-
respondences. An important advantage of
this clustering method over other dialec-
tometric methods is that the linguistic ba-
sis is simultaneously determined, bridging
the gap between traditional and quantita-
tive dialectology. Besides showing that
the results of the hierarchical clustering
improve over the flat spectral clustering
method used in an earlier study (Wieling
and Nerbonne, 2009), the values of the
second singular vector used to generate the
two-way clustering can be used to identify
the most important sound correspondences
for each cluster. This is an important ad-
vantage of the hierarchical method as it
obviates the need for external methods to
determine the most important sound corre-
spondences for a geographical cluster.

1 Introduction

For almost forty years quantitative methods have
been applied to the analysis of dialect variation
(Séguy, 1973; Goebl, 1982; Nerbonne et al.,
1999). Until recently, these methods focused
mostly on identifying the most important dialectal
groups using an aggregate analysis of the linguis-
tic data.

One of these quantitative methods, clustering,
has been applied frequently to dialect data, espe-
cially in an effort to compare computational anal-
yses to traditional views on dialect areas (Davis
and Houck, 1995; Clopper and Pisoni, 2004; Hee-
ringa, 2004; Moisl and Jones, 2005; Mucha and
Haimerl, 2005; Prokić and Nerbonne, 2009).

While viewing dialect differences at an ag-
gregate level certainly gives a more comprehen-

sive view than the analysis of a single subjec-
tively selected feature, the aggregate approach has
never fully convinced traditional linguists of its
use as it fails to identify the linguistic distinc-
tions among the identified groups. Recently, how-
ever, Wieling and Nerbonne (2009; 2010) an-
swered this criticism by applying a promising
graph-theoretic method, the spectral partitioning
of bipartite graphs, to cluster varieties and simulta-
neously determine the linguistic basis of the clus-
ters.

The spectral partitioning of bipartite graphs has
been a popular method for the task of co-clustering
since its introduction by Dhillon in 2001. Besides
being used in the field of information retrieval
for co-clustering words and documents (Dhillon,
2001), this method has also proven useful in the
field of bioinformatics, successfully co-clustering
genes and conditions (Kluger et al., 2003).

Wieling and Nerbonne (2009) used spectral par-
titioning of bipartite graphs to co-cluster dialect
varieties and sound correspondences with respect
to a set of reference pronunciations. They reported
a fair geographical clustering of the varieties in
addition to sensible sound correspondences. In a
follow-up study, Wieling and Nerbonne (2010) de-
veloped an external method to rank the sound cor-
respondences for each geographic cluster, which
also conformed largely to the subjectively selected
“interesting” sound correspondences in their ear-
lier study (Wieling and Nerbonne, 2009).

In all the aforementioned studies, the spectral
graph partitioning method was used to generate a
flat clustering. However, Shi and Malik (2000)
indicated that a hierarchical clustering obtained
by repeatedly grouping in two clusters should be
preferred over the flat clustering approach as ap-
proximation errors are reduced. More importantly,
genealogical relationships between languages (or
dialects) are generally expected to have a hierar-
chical structure due to the dynamics of language

33



Figure 1: Distribution of GTRP varieties including
province names

change in which early changes result in separate
varieties which then undergo subsequent changes
independently (Jeffers and Lehiste, 1979).

In this study, we will apply the hierarchical
spectral graph partitioning method to a Dutch di-
alect dataset. Besides comparing the results to
the flat clustering obtained by Wieling and Ner-
bonne (2009), we will also show that identifying
the most important sound correspondences is in-
herent to the method, alleviating the need for an
external ranking method (e.g., see Wieling and
Nerbonne, 2010).

While the current study applies the hierarchical
clustering and (novel) ranking method to pronun-
ciation data, we would also like to point out that
these methods are not restricted to this type of data
and can readily be applied to other domains such
as information retrieval and bioinformatics where
other spectral methods (e.g., principal component
analysis) have already been applied successfully
(e.g., see Furnas et al., 1988 and Jolicoeur and
Mosimann, 1960).

2 Material

In this study, we use the same dataset as dis-
cussed by Wieling and Nerbonne (2009). In short,
the Goeman-Taeldeman-Van Reenen-project data
(GTRP; Goeman and Taeldeman, 1996; Van den

Vaals

Sittard

Appelscha

Oudega

Figure 2: Example of a bipartite graph of varieties
and sound correspondences

Berg, 2003) is the most recent Dutch dialect
dataset digitally available consisting of 1876 pho-
netically transcribed items for 613 dialect varieties
in the Netherlands and Flanders. We focus on
a subset of 562 words selected by Wieling et al.
(2007) for all 424 Netherlandic varieties. We do
not include the Belgian varieties, as the transcrip-
tions did not use the same number of tokens as
used for the Netherlandic transcriptions. The geo-
graphic distribution of the GTRP varieties includ-
ing province names is shown in Figure 1.

3 Methods

The spectral graph partitioning method we apply
requires as input an undirected bipartite graph. A
bipartite graph is a graph consisting of two sets of
vertices where each edge connects a vertex from
one set to a vertex in the other set. Vertices within
a set are not connected. An example of a bipartite
graph is shown in Figure 2. The vertices on the left
side represent the varieties, while the vertices on
the right side represent the sound correspondences
(each individual sound is surrounded by a set of
square brackets). An edge between a variety and
a sound correspondence indicates that the sound
correspondence occurs in that variety with respect
to a specific reference variety.

As we are interested in clustering dialect vari-
eties and detecting their underlying linguistic ba-
sis, our bipartite graph consists of dialect varieties
and for each variety the presence of sound corre-
spondences compared to a reference variety (indi-
cated by an edge; see Figure 2). Because we do
not have pronunciations of standard (or historical)
Dutch, we use the pronunciations of the city Delft
as our reference, since they are close to standard

34



Dutch (Wieling and Nerbonne, 2009) and allow a
more straightforward interpretation of the sound
correspondences than those of other varieties.

3.1 Obtaining sound correspondences
We obtain the sound correspondences by aligning
the pronunciations of Delft against the pronuncia-
tions of all other dialect varieties using the Leven-
shtein algorithm (Levenshtein, 1965). The Leven-
shtein algorithm generates an alignment by mini-
mizing the number of edit operations (insertions,
deletions and substitutions) needed to transform
one string into the other. For example, the Lev-
enshtein distance between [bInd@n] and [bEind@],
two Dutch dialect pronunciations of the word ‘to
bind’, is 3:

bInd@n insert E 1
bEInd@n subst. i/I 1
bEind@n delete n 1
bEind@

3

The corresponding alignment is:

b I n d @ n
b E i n d @

1 1 1
When all edit operations have the same cost, it

is clear that the vowel [I] in the alignment above
can be aligned with either the vowel [E] or the
vowel [i]. To improve the initial alignments, we
use an empirically derived segment distance table
obtained by using the pointwise mutual informa-
tion (PMI) procedure as introduced by Wieling et
al. (2009).1 They showed that applying the PMI
procedure resulted in much better alignments than
using several other alignment procedures.

The initial step of the PMI procedure consists
of obtaining a starting set of alignments. In our
case we obtain these by using the Levenshtein
algorithm with a syllabicity constraint: vowels
may only align with (semi-)vowels, and conso-
nants only with consonants, except for syllabic
consonants which may also be aligned with vow-
els. Subsequently, the substitution cost of every
segment pair (a segment can also be a gap, rep-
resenting an insertion or a deletion) can be calcu-
lated according to a pointwise mutual information
procedure assessing the statistical dependence be-
tween the two segments:

1The PMI procedure is implemented in the dialectom-
etry package RUG/L04 which can be downloaded from
http://www.let.rug.nl/ kleiweg/L04.

PMI(x, y) = log2

(
p(x, y)

p(x) p(y)

)
Where:

• p(x, y) is estimated by calculating the num-
ber of times x and y occur at the same posi-
tion in two aligned strings X and Y , divided
by the total number of aligned segments (i.e.
the relative occurrence of the aligned seg-
ments x and y in the whole data set). Note
that either x or y can be a gap in the case of
insertion or deletion.

• p(x) and p(y) are estimated as the number
of times x (or y) occurs, divided by the total
number of segment occurrences (i.e. the rel-
ative occurrence of x or y in the whole data
set). Dividing by this term normalizes the co-
occurrence frequency with respect to the fre-
quency expected if x and y are statistically
independent.

In short, this procedure adapts the distance be-
tween two sound segments based on how likely it
is that they are paired in the alignments. If two
sounds are seen more (less) often together than we
would expect based on their relative frequency in
the dataset, their PMI score will be positive (neg-
ative). Higher scores indicate that segments tend
to co-occur in correspondences more often, while
lower scores indicate the opposite. New segment
distances (i.e. segment substitution costs) are ob-
tained by subtracting the PMI score from 0 and
adding the maximum PMI score (to enforce that
the minimum distance is 0). Based on the adapted
segment distances we generate new alignments
and we repeat this procedure until the alignments
remain constant.

We extract the sound correspondences from the
final alignments and represent the bipartite graph
by a matrix A having 423 rows (all varieties, ex-
cept Delft) and 957 columns (all occurring sound
correspondences). We do not include frequency
information in this matrix, but use binary values to
indicate the presence (1) or absence (0) of a sound
correspondence with respect to the reference pro-
nunciation.2 To reduce the effect of noise, we only

2We decided against using (the log) of the frequencies,
as results showed that this approach gave too much weight
to uninformative high-frequent substitutions of two identical
sounds.

35



regard a sound correspondence as present in a vari-
ety when it occurs in at least three aligned pronun-
ciations. Consequently, we reduce the number of
sound correspondences (columns of A) by more
than half to 477.

3.2 Hierarchical spectral partitioning of
bipartite graphs

Spectral graph theory is used to find the princi-
pal properties and structure of a graph from its
graph spectrum (Chung, 1997). Wieling and Ner-
bonne (2009) used spectral partitioning of bipar-
tite graphs as introduced by Dhillon (2001) to
co-cluster varieties and sound correspondences,
enabling them to obtain a geographical cluster-
ing with a simultaneously derived linguistic basis
(i.e. the clustered sound correspondences). While
Wieling and Nerbonne (2009) focused on the
flat clustering approach, we will use the hierar-
chical approach by iteratively clustering in two
groups. This approach is preferred by Shi and Ma-
lik (2000), because approximation errors are re-
duced compared to the flat clustering approach.

The hierarchical spectral partitioning algorithm,
following Dhillon (2001), proceeds as follows:

1. Given the 423 × 477 variety-by-segment-
correspondence matrix A as discussed pre-
viously, form

An = D1
−1/2AD2

−1/2

with D1 and D2 diagonal matrices such that
D1(i, i) = ΣjAij and D2(j, j) = ΣiAij

2. Calculate the singular value decomposition
(SVD) of the normalized matrix An

SVD(An) = UΛV T

and take the singular vectors u2 and v2

3. Compute z2 =
[
D1

−1/2 u2
D2

−1/2 v2

]
4. Run the k-means algorithm on z2 to obtain

the bipartitioning

5. Repeat steps 1 to 4 on both clusters separately
to create the hierarchical clustering

The following example (taken from Wieling and
Nerbonne, 2010) shows how we can co-cluster the
graph of Figure 2 in two groups. The matrix rep-
resentation of this graph is as follows:

[2]:[I] [-]:[@] [d]:[w]
Appelscha (Friesland) 1 1 0
Oudega (Friesland) 1 1 0
Vaals (Limburg) 0 1 1
Sittard (Limburg) 0 1 1

The first step is to construct matrices D1 and
D2 which contain the total number of edges from
every variety (D1) and every sound correspon-
dence (D2) on the diagonal. Both matrices are
shown below.

D1 =


2 0 0 0
0 2 0 0
0 0 2 0
0 0 0 2

 D2 =
2 0 00 4 0

0 0 2


The normalized matrix An can be calculated

using the formula displayed in step 1 of the hierar-
chical bipartitioning algorithm:

An =


.5 .35 0
.5 .35 0
0 .35 .5
0 .35 .5


Applying the singular value decomposition to An
yields:

U =


−.5 .5 .71 0
−.5 .5 −.71 0
−.5 −.5 0 −.71
−.5 −.5 0 .71



Λ =


1 0 0
0 .71 0
0 0 0
0 0 0



V T =

−.5 −.71 −.5.71 0 −.71
−.5 .71 −.5


Finally, we look at the second singular vector of

U (second column) and V T (second row; i.e. sec-
ond column of V ) and compute the 1-dimensional
vector z2:

z2 =
[
.35 .35 −.35 −.35 .5 0 −.5

]T
The first four values correspond with the places
Appelscha, Oudega, Vaals and Sittard, while the

36



last three values correspond to the segment substi-
tutions [2]:[I], [-]:[@] and [d]:[w].

After running the k-means algorithm (with ran-
dom initialization) on z2, the items are assigned to
one of two clusters as follows:[

1 1 2 2 1 1 2
]T

This clustering shows that Appelscha and
Oudega are grouped together (corresponding to
the first and second item of the vector, above) and
linked to the clustered segment substitutions of
[2]:[I] and [-]:[@] (cluster 1). Also, Vaals and Sit-
tard are clustered together and linked to the clus-
tered segment substitution [d]:[w] (cluster 2). The
segment substitution [-]:[@] (an insertion of [@]) is
actually not meaningful for the clustering of the
varieties (as can be seen in A), because the middle
value of V T corresponding to this segment substi-
tution equals 0. It could therefore just as likely be
grouped cluster 2. Nevertheless, the k-means al-
gorithm always assigns every item to one cluster.3

3.3 Determining the importance of sound
correspondences

Wieling and Nerbonne (2010) introduced a post
hoc method to rank each sound correspondence
[a]:[b] based on the representativenessR in a clus-
ter ci (i.e. the proportion of varieties v in cluster ci
containing the sound correspondence):

R(a, b, ci) =
|v in ci containing [a]:[b]|

|v in ci|

and the distinctiveness D (i.e. the number of vari-
eties v within as opposed to outside cluster ci con-
taining the sound correspondence normalized by
the relative size of the cluster):

D(a, b, ci) =
O(a, b, ci)− S(ci)

1− S(ci)

Where the relative occurrence O and the relative
size S are given by:

O(a, b, ci) =
|v in ci containing [a]:[b]|
|v containing [a]:[b]|

S(ci) =
|v in ci|
|all v’s|

3Note that we could also have decided to drop this sound
correspondence. However using our ranking approach (see
Secion 3.3) already ensures that the uninformative sound cor-
respondences are ranked very low.

The importance I is then calculated by averaging
the distinctiveness and representativeness:

I(a, b, ci) =
R(a, b, ci) +D(a, b, ci)

2

An extensive explanation of this method can be
found in Wieling and Nerbonne (2010).

As we now only use a single singular vector
to determine the partitioning (in contrast to the
study of Wieling and Nerbonne, 2010 where they
used multiple singular vectors to determine the
flat clustering), we will investigate if the values
of the singular vector v2 reveal information about
the importance (as defined above) of the individ-
ual sound correspondences. We will evaluate these
values by comparing them to the importance val-
ues on the basis of the representativeness and dis-
tinctiveness (Wieling and Nerbonne, 2010).

4 Results

In this section, we will report the results of apply-
ing the hierarchical spectral partitioning method to
our Dutch dialect dataset. In addition, we will also
compare the geographical clustering to the results
obtained by Wieling and Nerbonne (2009).

We will only focus on the four main clusters
each consisting of at least 10 varieties. While
our method is able to detect smaller clusters in
the data, we do not believe these to be sta-
ble. We confirmed this by applying three well-
known distance-based clustering algorithms (i.e.
UPGMA, WPGMA and Ward’s Method; Prokić
and Nerbonne, 2009) to our data which also only
agreed on four main clusters. In addition, Wieling
and Nerbonne (2009) reported reliable results on a
maximum of 4 clusters.

4.1 Geographical results
Figure 3 shows a dendrogram visualizing the ob-
tained hierarchy as well as a geographic visualiza-
tion of the clustering. For comparison, Figure 4
shows the visualization of four clusters based on
the flat clustering approach of Wieling and Ner-
bonne (2009).

It is clear that the geographical results of the
hierarchical approach (Figure 3) are comparable
to the results of the flat clustering approach (Fig-
ure 4) of Wieling and Nerbonne (2009).4 How-

4Note that the results of the flat clustering approach were
based on all 957 sound correspondences. No noise-reducing
frequency threshold was applied there, as this was reported to
lead to poorer results (Wieling and Nerbonne, 2009).

37



Figure 3: Geographic visualization of the clus-
tering including dendrogram. The shades of grey
in the dendrogram correspond with the map (e.g.,
the Limburg varieties can be found at the bottom-
right).

ever, despite the Frisian area (top-left) being iden-
tical, we clearly observe that both the Low Saxon
area (top-right) and the Limburg area (bottom-
right) are larger in the map based on the hierar-
chical approach. As this better reflects the tradi-
tional Dutch dialect landscape (Heeringa, 2004),
the hierarchical clustering method seems to be
an improvement over the flat clustering method.
Also the hierarchy corresponds largely with the
one found by Heeringa (2004, Chapter 9), identi-
fying Frisian, Limburg and Low Saxon as separate
groups.

4.2 Most important sound correspondences

To see whether the values of the singular vector v2
can be used as a substitute for the external ranking
method, we correlated the absolute values of the

Figure 4: Geographic visualization of the flat clus-
tering reported in Wieling and Nerbonne (2009).
The shades of grey are identical to the shades of
grey in Figure 3.

singular vector with the importance values based
on the distinctiveness and representativeness. For
the sound correspondences of the Frisian area we
obtained a high Spearman’s rank correlation co-
efficient ρ of .92 (p < .001). For the Low Saxon
area and the Limburg area we obtained similar val-
ues (ρ = .87, p < .001 and ρ = .88, p < .001,
respectively). These results clearly show that the
values of the second singular vector v2 can be
used as a good substitute for the external ranking
method.

Frisian area
The following table shows the five most important
sound correspondences for the Frisian area.

Rank 1 2 3 4 5
Reference - [x] [f] [x] [a]
Frisian [S] [j] - [z] [i]

While we have limited overlap (only [x]:[z]; oc-
curing in e.g. zeggen ‘say’ Dutch [zEx@], Frisian
[siz@]) with the sound correspondences selected
and discussed by Wieling and Nerbonne (2010)
who used the flat clustering method without a fre-
quency threshold (also causing some of the differ-
ences), we observe more overlap with the subjec-

38



tively selected sound correspondences in Wieling
and Nerbonne (2009; [x]:[j] in e.g. geld ‘money’
Dutch [xElt], Frisian [jIlt]; and [a]:[i] in e.g. kaas
‘cheese’ Dutch [kas], Frisian [tsis]). In addition,
we detected two novel sound correspondences
([f]:[-] and [-]:[S]).

We commonly find the correspondence [-]:[S]
in the infinitive form of verbs such as wachten
‘wait’ Dutch [waxt@], Frisian [waxtS@]; vechten
‘fight’ Dutch [vExt@], Frisian [vExtS@]; or spuiten
‘spray’ Dutch [spœYt@], Frisian [spoYtS@], but it
also appears e.g. in Dutch tegen ‘against’ [teix@],
Frisian [tSIn]. The [f]:[-] correspondence is found
in words like sterven ‘die’ standard Dutch [stERf@],
Frisian [stER@].

Low Saxon area

The most important sound correspondences of the
Low Saxon area are shown in the table below.

Rank 1 2 3 4 5
Reference [k] [v] [@] [f] [p]
Low Saxon [P] [b] [m] [b] [P]

These sound correspondences overlap to a large
extent with the most important sound correspon-
dences identified and discussed by Wieling and
Nerbonne (2010). The correspondence [k]:[P] can
be found in words like planken ‘boards’, Dutch
[plANk@], Low Saxon [plANPN

"
], while the corre-

spondence [v]:[b] is found in words like bleven
‘remain’ Dutch [blEv@n], Low Saxon [blibm

"
].

The final overlapping correspondence [f]:[b] can
be observed in words like proeven ‘test’ Dutch
[pruf@], Low Saxon [proybm

"
].

The sound correspondence [@]:[m] was dis-
cussed and selected by Wieling and Ner-
bonne (2009) as an interesting sound correspon-
dence, occurring in words like strepen ‘stripes’
Dutch [strep@], Low Saxon [strepm

"
].

The new correspondence [p]:[P] occurs in
words such as lampen ’lamps’ standard Dutch
[lamp@], Aduard (Low Saxon) [lamPm

"
], but also

postvocalically, as in gapen ’yawn’, standard
Dutch [xap@], Aduard (Low Saxon) [xoPm

"
]. It

is obviously related to the [k]:[P] correspondence
discussed above.

Limburg area

The most important sound correspondences for the
Limburg area are displayed in the table below.

Rank 1 2 3 4 5
Reference [r] [s] [o] [n] [r]
Limburg [x] [Z] - [x] [ö]

For this area, we observe limited overlap with
the most important sound correspondences based
on distinctiveness and representativeness (Wieling
and Nerbonne, 2010; only [n]:[x] overlaps, occur-
ing in words like kleden ‘cloths’ Dutch [kled@n],
Limburg [klEId@x]), as well as with the subjec-
tively selected interesting sound correspondences
(Wieling and Nerbonne, 2009; only [r]:[ö] over-
laps, which occurs in words like breken ‘to break’
Dutch [brek@], Limburg [böEk@]).

The sound correspondence [o]:[-] can be found
in wonen ‘living’, pronounced [woun@] in our
reference variety Delft and [wun@] in Limburg.
As the standard Dutch pronunciation is actually
[won@], this correspondence is caused by the
choice of our reference variety, which is unfortu-
nately not identical to standard Dutch.

The other two sound correspondences are more
informative. The sound correspondence [r]:[x] can
be found in words like vuur ‘fire’ Dutch [fyr],
Limburg [vy@x] and is similar to the sound cor-
respondence [r]:[ö] discussed above. The other
correspondence [s]:[Z] occurs when comparing the
standard-like Delft variety to Limburg varietes in
words such as zwijgen ’to be silent’ [sweix@], Lim-
burg [ZwiG@]; or zwemmen ’swim’ [swEm@], Lim-
burg [Zw8m@].

Hierarchical versus flat clustering
In general, then, the sound correspondences un-
covered by the hierarchical version of the spectral
clustering technique turn out to be at least as in-
teresting as those uncovered by the flat clustering,
which leads us to regard the hierarchical cluster-
ing technique as defensible in this respect. Since
dialectologists are convinced that dialect areas are
organized hierarchically, we are naturally inclined
toward hierarchical clustering techniques as well.
We note additionally that the using the values of
the second singular vector is an adequate substitu-
tion of the external ranking method based on dis-
tinctiveness and representativeness, which means
that the present paper also marks a step forward in
simplifying the methodology.

5 Discussion

In this study we showed that using hierarchi-
cal spectral partitioning of bipartite graphs results

39



in an improved geographical clustering over the
flat partitioning method and also results in sen-
sible concomitant sound correspondences. One
of the reasons for the improvement of the geo-
graphical clustering could be the approximation
errors which arise when going from the real val-
ued solution to the discrete valued solution, and
which increase with every additional singular vec-
tor used (Shi and Malik, 2000).

In addition, we showed that using the values of
the second singular vector obviates the need for
an external ranking method (e.g., see Wieling and
Nerbonne, 2010) to identify the most important
sound correspondences.

Since the spectral partitioning of bipartite
graphs appears to be identifying significant (rep-
resentative and distinctive) correspondences well
– both in the flat clustering design and in the
(present) hierarchical scheme, several further op-
portunities become worthy of exploration. First,
we might ask if we can automatically identify
a threshold of significance for such correspon-
dences, as to-date we have only sought to verify
significance, not to exclude marginally significant
elements. Second, while we have applied the tech-
nique exclusively to data for which the correspon-
dence consists of a comparison of dialect data to
(near) standard data, the analysis of historical data,
in which varieties are compared to an earlier form,
is within reach. As the first step, we should wish to
compare data to a well-established historical pre-
decessor as further steps might require genuine re-
construction, still beyond anyone’s reach (as far as
we know). Third, the technique would be more
generally applicable if it did not require agree-
ing on a standard, or pole of comparison. This
sounds difficult, but multi-alignment techniques
might bring it within reach (Prokić et al., 2009).

It is intriguing to note that Nerbonne (in press)
found only sporadic correspondences using fac-
tor analysis on data which incorporated frequency
of correspondence, and we have likewise found
frequency-weighted data less successful as a ba-
sis for spectral bipartite clustering. Shackleton
(2007), Wieling and Nerbonne (2010) and the cur-
rent paper are more successful using data which
lacks information about the frequency of occur-
rence of sounds and/or sound correspondences.
The question arises as to whether this is general
and why this is so. Is it due to the skewness of fre-
quency distributions, in which a suitable normal-

ization might be attempted? Or is it simply more
straightforward to focus on the absolute presence
or absence of a sound or sound correspondence?

While sound correspondences function well as
a linguistic basis, it might also be interesting to
investigate morphological distinctions present in
the GTRP corpus. This would enable us to com-
pare the similarity of the geographic distributions
of pronunciation variation and morphological vari-
ation.

Finally, while we only tested this method on a
single dataset, it would be interesting to see if our
results and conclusions also hold when applied to
more and different datasets. We also realize that
the evaluation in this study is rather qualitative, but
we intend to develop more quantitative evaluation
methods for future studies.

Acknowledgements

We thank Gertjan van Noord and Tim Van de
Cruys for their comments during a presentation
about the flat spectral graph partitioning method,
which instigated the search for an inherent rank-
ing method.

References
Fan Chung. 1997. Spectral graph theory. American

Mathematical Society.

Cynthia G. Clopper and David B. Pisoni. 2004. Some
acoustic cues for the perceptual categorization of
American English regional dialects. Journal of Pho-
netics, 32(1):111–140.

L.M. Davis and C.L. Houck. 1995. What Determines a
Dialect Area? Evidence from the Linguistic Atlas of
the Upper Midwest. American Speech, 70(4):371–
386.

Inderjit Dhillon. 2001. Co-clustering documents and
words using bipartite spectral graph partitioning. In
Proceedings of the seventh ACM SIGKDD interna-
tional conference on Knowledge discovery and data
mining, pages 269–274. ACM New York, NY, USA.

George Furnas, Scott Deerwester, Susan Dumais,
Thomas Landauer, Richard Harshman, Lynn
Streeter, and Karen Lochbaum. 1988. Information
retrieval using a singular value decomposition
model of latent semantic structure. In Proceedings
of the 11th annual international ACM SIGIR confer-
ence on Research and development in information
retrieval, pages 465–480. ACM.

Hans Goebl. 1982. Dialektometrie: Prinzipien
und Methoden des Einsatzes der Numerischen
Taxonomie im Bereich der Dialektgeographie.

40



Österreichische Akademie der Wissenschaften,
Wien.

Ton Goeman and Johan Taeldeman. 1996. Fonolo-
gie en morfologie van de Nederlandse dialecten.
Een nieuwe materiaalverzameling en twee nieuwe
atlasprojecten. Taal en Tongval, 48:38–59.

Wilbert Heeringa. 2004. Measuring Dialect Pronunci-
ation Differences using Levenshtein Distance. Ph.D.
thesis, Rijksuniversiteit Groningen.

Robert Jeffers and Ilse Lehiste. 1979. Principles and
methods for historical linguistics. MIT Press, Cam-
bridge.

Pierre Jolicoeur and James E. Mosimann. 1960. Size
and shape variation in the painted turtle. A principal
component analysis. Growth, 24:339–354.

Yuval Kluger, Ronen Basri, Joseph Chang, and Mark
Gerstein. 2003. Spectral biclustering of microarray
data: Coclustering genes and conditions. Genome
Research, 13(4):703–716.

Vladimir Levenshtein. 1965. Binary codes capable of
correcting deletions, insertions and reversals. Dok-
lady Akademii Nauk SSSR, 163:845–848.

Hermann Moisl and Val Jones. 2005. Cluster anal-
ysis of the newcastle electronic corpus of tyneside
english: A comparison of methods. Literary and
Linguistic Computing, 20(supp.):125–146.

Hans-Joachim Mucha and Edgard Haimerl. 2005.
Automatic validation of hierarchical cluster anal-
ysis with application in dialectometry. In Claus
Weihs and Wolgang Gaul, editors, Classification—
the Ubiquitous Challenge. Proc. of the 28th Meet-
ing of the Gesellschaft für Klassifikation, Dortmund,
March 9–11, 2004, pages 513–520, Berlin. Springer.

John Nerbonne, Wilbert Heeringa, and Peter Kleiweg.
1999. Edit distance and dialect proximity. In David
Sankoff and Joseph Kruskal, editors, Time Warps,
String Edits and Macromolecules: The Theory and
Practice of Sequence Comparison, 2nd ed., pages v–
xv. CSLI, Stanford, CA.

John Nerbonne. in press. Various Variation Aggre-
gates in the LAMSAS South. In C. Davis and M. Pi-
cone, editors, Language Variety in the South III.
University of Alabama Press, Tuscaloosa.

Jelena Prokić and John Nerbonne. 2009. Recognizing
groups among dialects. In John Nerbonne, Charlotte
Gooskens, Sebastian Kurschner, and Rene van Be-
zooijen, editors, International Journal of Humani-
ties and Arts Computing, special issue on Language
Variation.

Jelena Prokić, Martijn Wieling, and John Nerbonne.
2009. Multiple sequence alignments in linguistics.
In Lars Borin and Piroska Lendvai, editors, Lan-
guage Technology and Resources for Cultural Her-
itage, Social Sciences, Humanities, and Education,
pages 18–25.

Jean Séguy. 1973. La dialectométrie dans l’atlas lin-
guistique de gascogne. Revue de Linguistique Ro-
mane, 37(145):1–24.

Robert G. Shackleton, Jr. 2007. Phonetic variation in
the traditional english dialects. Journal of English
Linguistics, 35(1):30–102.

Jianbo Shi and Jitendra Malik. 2000. Normalized cuts
and image segmentation. IEEE Transactions on pat-
tern analysis and machine intelligence, 22(8):888–
905.

Boudewijn van den Berg. 2003. Phonology & Mor-
phology of Dutch & Frisian Dialects in 1.1 million
transcriptions. Goeman-Taeldeman-Van Reenen
project 1980-1995, Meertens Instituut Electronic
Publications in Linguistics 3. Meertens Instituut
(CD-ROM), Amsterdam.

Martijn Wieling and John Nerbonne. 2009. Bipartite
spectral graph partitioning to co-cluster varieties and
sound correspondences in dialectology. In Mono-
jit Choudhury, Samer Hassan, Animesh Mukher-
jee, and Smaranda Muresan, editors, Proc. of the
2009 Workshop on Graph-based Methods for Nat-
ural Language Processing, pages 26–34.

Martijn Wieling and John Nerbonne. 2010. Bipartite
spectral graph partitioning for clustering dialect va-
rieties and detecting their linguistic features. Com-
puter Speech and Language. Accepted to appear in
a special issue on network models of social and cog-
nitive dynamics of language.

Martijn Wieling, Wilbert Heeringa, and John Ner-
bonne. 2007. An aggregate analysis of pronuncia-
tion in the Goeman-Taeldeman-Van Reenen-Project
data. Taal en Tongval, 59:84–116.

Martijn Wieling, Jelena Prokić, and John Nerbonne.
2009. Evaluating the pairwise alignment of pronun-
ciations. In Lars Borin and Piroska Lendvai, editors,
Language Technology and Resources for Cultural
Heritage, Social Sciences, Humanities, and Educa-
tion, pages 26–34.

41


