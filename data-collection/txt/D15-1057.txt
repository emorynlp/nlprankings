



















































Extraction and generalisation of variables from scientific publications


Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 505–511,
Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.

Extraction and generalisation of variables from scientific publications

Erwin Marsi, Pinar Öztürk
Department of Computer and Information Science

Norwegian University of Science and Technology (NTNU)
{emarsi,pinar}@idi.ntnu.no

Abstract

Scientific theories and models in Earth sci-
ence typically involve changing variables
and their complex interactions, including
correlations, causal relations and chains
of positive/negative feedback loops. Vari-
ables tend to be complex rather than
atomic entities and expressed as noun
phrases containing multiple modifiers, e.g.
oxygen depletion in the upper 500 m of
the ocean or timing and magnitude of sur-
face temperature evolution in the Southern
Hemisphere in deglacial proxy records.
Text mining from Earth science literature
is therefore significantly different from
biomedical text mining and requires dif-
ferent approaches and methods. Our ap-
proach aims at automatically locating and
extracting variables and their direction of
variation: increasing, decreasing or just
changing. Variables are initially extracted
by matching tree patterns onto the syntax
trees of the source texts. Next, variables
are generalised in order to enhance their
similarity, facilitating hierarchical search
and inference. This generalisation is ac-
complished by progressive pruning of syn-
tax trees using a set of tree transformation
operations. Text mining results are pre-
sented as a browsable variable hierarchy
which allows users to inspect all mentions
of a particular variable type in the text as
well as any generalisations or specialisa-
tions. The approach is demonstrated on a
corpus of 10k abstracts of Nature publica-
tions in the field of Marine science. We
discuss experiences with this early proto-
type and outline a number of possible im-
provements and directions for future re-
search.

1 Introduction

Text mining of scientific literature originates from
efforts to cope with the ever growing flood of pub-
lications in biomedicine (Swanson, 1986; Swan-
son, 1988; Swanson and Smalheiser, 1997; Hearst,
1999; Ananiadou et al., 2006; Zweigenbaum et
al., 2007; Cohen and Hersh, 2005; Krallinger
et al., 2008; Rodriguez-Esteban, 2009; Zweigen-
baum and Demner-Fushman, 2009; Ananiadou et
al., 2010; Simpson and Demner-Fushman, 2012;
Ananiadou et al., 2014). Consequently the re-
sulting approaches, methods, tools and applica-
tions – as well as data, corpora and evaluation
tasks – are rooted in the paradigm of biomedi-
cal research and its conceptual framework. Typ-
ical source text consists of abstracts from PubMed
or full-text articles from PubMed Central. Stan-
dard tasks include recognition, normalisation and
mapping of biological entities (e.g., genes, pro-
teins, drugs, symptoms and diseases), extraction
of biological relations (e.g., protein-protein inter-
action, disease-gene associations or drug-drug in-
teraction) or bio-event extraction (e.g., regulation
or inhibition events and their participants). There
are extensive ontologies like the Gene Ontology
(Consortium, 2001), annotated corpora like the
GENIA (Kim et al., 2003) and BioInfer (Pyysalo
et al., 2007) corpora and dedicated shared tasks in-
cluding BioCreative (Hirschman et al., 2005) and
BioNLP (Pyysalo et al., 2012). In short, there is
a whole infrastructure supporting biomedical text
mining (Cohen and Hunter, 2008).

Text mining is now spreading out to other scien-
tific disciplines, notably in the humanities and so-
cial sciences (O’Connor et al., 2011), holding the
promise for knowledge discovery from large text
collections. Our own research targets text min-
ing in the field of Earth science, more specifically
in Oceanography or Marine science, with a focus
on climate change. As text mining efforts in this

505



area are extremely rare (Ekstrom and Lau, 2008;
Vossen et al., 2010; Zhang et al., 2013; Marsi et
al., 2014; Aamot, 2014), it is not surprising that a
corresponding infrastructure is mostly lacking. In
addition, however, we found that due to significant
differences between the conceptual frameworks of
biomedicine and marine science, simply “porting”
the biomedical text mining infrastructure to an-
other domain will not suffice.

One major difference is that the biomedical en-
tities of interest are relatively well defined – genes,
proteins, organisms, species, drugs, diseases, etc.
– and typically expressed as proper nouns. In con-
trast, defining the entities of interest in marine sci-
ence turns out to be much harder. Not only does it
seem to be more open-ended in nature, the entities
themselves tend to be complex and expressed as
noun phrases containing multiple modifiers, giv-
ing rise to examples like oxygen depletion in the
upper 500 m of the ocean or timing and magnitude
of surface temperature evolution in the Southern
Hemisphere in deglacial proxy records.

Given the difficulties with entities, we pro-
pose to concentrate first on text mining of events,
leaving entities underspecified for the time being.
Theories and models in marine science are char-
acterised by changing variables and their com-
plex interactions, including correlations, causal re-
lations and chains of positive/negative feedback
loops. Many marine scientists are interested in
finding evidence – or counter-evidence – in the lit-
erature for events of change and their relations.
Here we present ongoing work to automatically
locate and extract variables and their direction of
variation: increasing, decreasing or just changing.
Examples are given in Table 1.

Since many of these changing variables are long
and complex expressions, their frequency of oc-
currence tends to be low, making the discovery of
relations among different variables harder. As a
partial solution to this problem, we propose pro-
gressive pruning of syntax trees using a set of tree
transformation operations. For example, general-
ising oxygen depletion in the upper 500 m of the
ocean to oxygen depletion in the ocean and sub-
sequently to the much more frequent oxygen de-
pletion. Text mining results are then presented as
a browsable variable hierarchy which allows users
to inspect all mentions of a particular variable type
in the text as well as any generalisations or special-
isations.

2 Variable extraction

Our text material consists of 10k abstracts from
journals published by Nature Publishing Group.
Search terms obtained from domain experts were
used to query Nature’s OpenSearch API1 for pub-
lications in a limited range of relevant journals,
after 1997, retrieving records including title and
abstract. The top-10k abstracts matching most
search terms were selected for further processing
with CoreNLP (Manning et al., 2014), including
tokenisation, sentence splitting, POS tagging, lem-
matisation and parsing. Lemmatised parse trees
were obtained by substituting terminals with their
lemmas. The resulting new corpus contains 9,586
article abstracts, 59,787 sentences and approxi-
mately 4M tokens.

Methods for information extraction broadly rely
on either knowledge-based pattern matching or su-
pervised machine learning (Sarawagi, 2008). Al-
though ML approaches are currently dominant in
IE research, rule-based systems have several ad-
vantages, including: (a) the rules are interpretable
and thus suitable for rapid development and do-
main transfer; and (b) humans and machines
can contribute to the same model (Valenzuela-
Escárcega et al., 2015). In our case, patterns of-
fered more flexibility in exploring the domain,
whereas the manual annotation required for ML
demands more commitment to a precise definition
of entities, relations and events, which we found
hard to achieve at this stage. Tree pattern match-
ing is applied to lemmatised syntax trees using the
Tregex engine (Levy and Andrew, 2006), which
supports a compact language for writing regular
expressions over trees; see Table 1 for examples
of patterns and matching phrases. For instance,
the pattern for a decreasing variable is defined as
a noun phrase (NP) that is immediately dominated
(>) by a verb phrase (VP), which in turn is headed
by (<<#) the lemma reduce. Similarly, the pat-
tern for increase describes an NP dominated by
a prepositional phrase (PP) that is headed by the
preposition in or of ; in addition, this PP must be
preceded by an NP sister node ($,) headed by the
lemma increase.

Patterns were generated by instantiating a small
set of hand-written pattern templates, drawing
from manually created lists of verbs and nouns ex-

1http://www.nature.com/developers/
documentation/api-references/
opensearch-api

506



Table 1: Examples of tree patterns and matching variables

Direction: Tree pattern: Matched variable in sentence:

Change NP <- (/NN/=d1 < variability
$ /NN/) !$. PP

Thus the annual, Milankovitch and continuum temperature
variability together represent the response to deterministic inso-
lation forcing.

Increase NP > (PP <<# (in|of) $,
(NP <<# increase))

The record reveals a linear increase in annual temperature be-
tween 1958 and 2010 by 2.4 +/-1.2 degreesC . . .

Decrease NP > (VP <<# reduce ) Some researchers have observed that abundant natural gas substi-
tuting for coal could reduce carbon dioxide (CO2) emissions.

pressing change, increase or decrease. The pat-
terns cover expression as a main verb (X increases,
something increases X), attributive use of verbs
(increasing temperature, temperature is increas-
ing), head of NP (a temperature increase) or NP
with PP modifier (increase in temperature). The
total number of patterns is 320: 90 for change, 122
for increase, 108 for decrease (see supplements for
a full list). The total number of matched variables
in the corpus is 21,817: 9,352 for change, 7,400
for increase and 5,065 for decrease.

Some variables do not exactly correspond to a
node, i.e., not every variable is a valid syntac-
tic phrase. For instance, the pattern for Change
in Table 1 matches the NP the annual, Mi-
lankovitch and continuum temperature variabil-
ity, whereas the actual variable is the annual, Mi-
lankovitch and continuum temperature. This is
corrected in a post-processing step that deletes
the variability node from the extracted subtree
and substring. For this purpose, the pattern
contains an assignment of the name d1 to the
node directly dominating the lemma variability
(/NN/=d1 < variability)), allowing a cor-
responding tree operation to delete this node,
which is implemented using the Tsurgeon coun-
terpart of Tregex.

3 Variable generalisation

Since many of the extracted variables are long and
complex expressions, their frequency is low. The
most frequent variables are generic terms (climate
1207, temperature 156, global climate 73), but
over 66% is unique. This evidently impedes the
discovery of relations among variables. As a par-
tial solution to this problem, variables are gener-
alised by progressive pruning of syntax trees using
a set of tree transformation operations.

Figure 1 shows an example of generalisation
by iterative tree pruning. The first transformation
STRIP INIT DT strips the initial determiner from

the NP. Next, COORD 3.1 deletes everything but
the first conjunct from a coordinated structure of
three NPs, resulting in annual temperature , which
is finally reduced to just temperature by stripping
the premodifier (STRIP PREMOD 1 ). An anal-
ogous procedure is applied to the other two con-
juncts of the coordinated structure.

Tree transformations are implemented using
Tsurgeon (Levy and Andrew, 2006): Tregex pat-
terns match the syntactic structures of interest,
whereas an associated Tsurgeon operation deletes
selected nodes (see supplements for details). The
transformations are ordered in four groups. The
first group handles coordination of two to four
conjuncts (cf. Figure 1) – at the phrase level or the
lexical level – as well as cases of ellipsis (e.g. hail-
storm frequency and intensity into hailstorm fre-
quency and hailstorm intensity). The second group
strips bracketed material in parenthetical and list
structures. The third group deletes non-restrictive
relative clauses and other non-restrictive modi-
fiers preceded by a comma. The final group pro-
gressively strips premodifiers (mainly adjectives)
from left to right and postmodifiers (PPs, relative
clauses) from right to left . Since different trans-
formation may arrive at the same generalisation
(e.g. temperature in Figure 1), duplicates are fil-
tered out. After filtering, 150,716 variables re-
mained, which is 4.86 times the number of orig-
inally extracted variables.

As mentioned, the point of generalisation is to
find relations among variables. In Table 1, for ex-
ample, both the annual, Milankovitch and contin-
uum temperature variability and annual temper-
ature between 1958 and 2010 are generalised to
annual temperature. However, many generalised
variables are unique and thus serve no purpose in
relating variables. Retaining only original vari-
ables and generalised variables with at least two
mentions yields a total of 17,613 variable types.

507



Figure 2: Partial screenshot of user interface showing variable type hierarchy (left) and linked variable
mentions in text (right) where colour encodes change (green), increase (red) or decrease (blue)

the annual , Milankovitch and continuum temperature
STRIP INIT DT→ annual , Milankovitch and
continuum temperature

COORD 3.1→ annual temperature
STRIP PREMOD 1→ temperature

COORDI 3.2→Milankovitch temperature
STRIP PREMOD 1→ temperature

COORD 3.3→ continuum temperature
STRIP PREMOD 1→ temperature

Figure 1: Example of generalisation by iterative
tree pruning

4 User interface

The output of the text mining step can be regarded
as a directed graph where the nodes are variable
types and the edges point from a more specific
variable to a more general variable (as a result of
a particular tree transformation). Each variable
type is also linked to a set of tokens, i.e. variable
mentions in the text which are either changing, in-
creasing or decreasing. Figure 2 shows how this
information is presented to the user in a browser
(see supplements for full version). The left panel
lists the variable types, ordered from most gen-
eral to most specific and, secondary, on decreas-
ing token frequency. Links point to more spe-
cific/general variables types, as well as to chang-
ing/increasing/decreasing variable mentions in the
text. The right panel shows the source text, where
colour encodes changing (green), increasing (red)
or decreasing (blue) variable mentions, which are
linked to their most specific variable type. This
setup allows users to quickly explore variables, for
example, finding abstracts containing a variable of
interest and from there to related variables.

5 Discussion

We have argued that the paradigm established in
biomedical text mining does not transfer directly
to other scientific domains like Earth science. A
new approach was proposed for extracting vari-
ables and their direction of variation (increasing,
decreasing or just changing), focusing on events
rather than entities. A generic system based on
syntactic pattern matching and tree transforma-
tions was described for extraction and subsequent
generalisation of variable events. Text mining
results are presented in an innovative way as a
browsable hierarchy ranging from most general
to most specific variables, with links to their tex-
tual instances. In addition, a first text corpus in
marine science was produced, including automati-
cally annotated change events. Our corpus as well
as the extracted variables are publicly available2.
We think our approach to extraction is generalis-
able to other domains where the entities of inter-
est are common nouns or complex noun phrases
rather the proper nouns, e.g. in nanotechnology &
nanoscience (Kostoff et al., 2007).

To the best of our knowledge, there are currently
no other systems for text mining in Earth science
which we can compare our results with, nor are
there any benchmark data sets for our task. Most
related is (Marsi et al., 2014), but their definition
of variables is more restricted and their pilot cor-
pus is too small for evaluation purposes. Report-
ing on our ongoing work now, future work will
include an evaluation by asking domain exports to
judge the correctness of extracted variables as well

2https://dl.dropboxusercontent.com/u/
2370516/emnlp15_corpus.zip

508



as their generalisations in the given context.

Preliminary observations indicate that most
problems originate from syntactic parsing errors,
in particular well-known ambiguities in coordi-
nation and PP-attachment. As a result, patterns
may either fail to match or match unintentionally,
yielding incomplete or incoherent variables. Since
many sentences are long, complex and domain-
specific, it comes as no surprise that the parser of-
ten fails to correctly resolve well-known ambigui-
ties in coordination and PP-attachment. However,
with pattern matching on strings and/or POS tags
instead of syntax trees, determining boundaries of
variables would be problematic. False positives
also occur because of different semantics of the
same pattern, e.g. change in western Europe is
unlikely to mean literally that the European con-
tinent is changing, neither does changes in less
than a few thousand years imply that past years
are changing.

At the same time, certain false negatives are
beyond the power of pattern matching. For in-
stance, variation may be entailed rather than ex-
plicitly stated: ocean acidification entails increas-
ing acidity of ocean water and Arctic warming en-
tails increasing temperature in the Arctic region.
This is closely related to textual entailment (An-
droutsopoulos and Malakasiotis, 2010; Dagan et
al., 2006), requiring inference in combination with
domain knowledge. A related matter is nega-
tion (no increase in global temperature), which
can even be expressed in non-trivial ways (tem-
perature remained constant) (Morante and Daele-
mans, 2009). Variables were also found to be re-
cursive or embedded, expressing “a change of a
change”. For example, reduce subseasonal tem-
perature variance implies both a change in tem-
perature as well as a decrease of this temperature
change. The current visualisation falls short in
these cases, as HTML browsers cannot render a
link in a link.

Generalisation by tree pruning appears to work
quite well as long as the parse is correct. How-
ever, pruning by itself is insufficient and should
be supplemented with other methods. For in-
stance, linking named entities like species, chemi-
cals or locations to unique concepts in appropriate
ontologies/taxonomies would support generalisa-
tions such as iron is a metal or a diatom is a plank-
ton. Generalisation also bears a strong resem-
blance to other text-to-text generation tasks such

as paraphrasing (Androutsopoulos and Malakasio-
tis, 2010), sentence compression (Jing, 2000) and
sentence simplification (Shardlow, 2014). Given
suitable training data, ML approaches may there-
fore be applied, e.g. (Knight and Marcu, 2002;
Cohn and Lapata, 2009).

The most general variables are probably too
generic to be of much help to a user, e.g. con-
centration, rate, level, etc. Likewise, climate is by
far the most frequent changing variable due to the
frequently occurring collocation climate change.
In addition, variables often contain references to
previously mentioned entities – anaphoric it being
the ultimate example of this – suggesting a need
for co-reference resolution (Miwa et al., 2012).

Yet another future direction is to structurally
model variables as opposed to a possibly over-
simplified generalisation. Similar to nominal SRL,
one can define relevant arguments including fre-
quency (e.g. annual), temporal scope (between
1958 and 2010), location, etc. The most generic
variables mentioned earlier in fact provide a good
basis for such modelling.

Extraction and generalisation of variables pro-
vides a basis for building systems supporting
knowledge discovery. One approach is min-
ing associations between variables frequently co-
occurring in the same sentence or abstract (Jenssen
et al., 2001; Hashimoto et al., 2012)) More precise
results can be expected by extracting causal re-
lations between change events (Chang and Choi,
2005; Blanco et al., 2008; Raja et al., 2013).
Pairs of change events – causally or otherwise
associated – obtained from different publications
can be chained together, possibly in combina-
tion with domain knowledge, in order to gener-
ate new hypotheses, as pioneered in the work on
literature-based knowledge discovery (Swanson,
1986; Swanson, 1988; Swanson and Smalheiser,
1997). Automatic extraction and generalisation of
variables from scientific publications thus paves
the way for future research on text mining in Earth
science.

Acknowledgments

Financial aid from the European Commission
(OCEAN-CERTAIN, FP7-ENV-2013-6.1-1; no:
603773) is gratefully acknowledged. We thank
Murat Van Ardelan for sharing his knowledge of
Marine science and the anonymous reviewers for
their valuable comments.

509



References
Elias Aamot. 2014. Literature-based discovery for

oceanographic climate science. In Proceedings of
the Student Research Workshop at the 14th Confer-
ence of the European Chapter of the Association
for Computational Linguistics, pages 1–10, Gothen-
burg, Sweden, April. Association for Computational
Linguistics.

Sophia Ananiadou, Douglas B. Kell, and Jun I. Tsu-
jii. 2006. Text mining and its potential applications
in systems biology. Trends Biotechnol, 24(12):571–
579, December.

Sophia Ananiadou, Sampo Pyysalo, Jun’ichi Tsujii,
and Douglas B. Kell. 2010. Event extraction
for systems biology by text mining the literature.
Trends in biotechnology, 28(7):381–390, July.

Sophia Ananiadou, Paul Thompson, Raheel Nawaz,
John McNaught, and Douglas B Kell. 2014. Event-
based text mining for biology and functional ge-
nomics. Briefings in functional genomics, page
elu015.

Ion Androutsopoulos and Prodromos Malakasiotis.
2010. A survey of paraphrasing and textual entail-
ment methods. Journal of Artificial Intelligence Re-
search, 38:135–187, May.

Eduardo Blanco, Nuria Castell, and Dan I Moldovan.
2008. Causal relation extraction. In LREC, pages
310–313.

Du-Seong Chang and Key-Sun Choi. 2005. Causal re-
lation extraction using cue phrase and lexical pair
probabilities. In Natural Language Processing–
IJCNLP 2004, pages 61–70. Springer.

Aaron M. Cohen and William R. Hersh. 2005. A
survey of current work in biomedical text mining.
Briefings in Bioinformatics, 6(1):57–71, March.

Kevin Bretonnel Cohen and Lawrence Hunter. 2008.
Getting Started in Text Mining. PLoS Comput Biol,
4(1):e20+, January.

Trevor Cohn and Mirella Lapata. 2009. Sentence
compression as tree transduction. J. Artif. Int. Res.,
34(1):637–674.

The Gene Ontology Consortium. 2001. Creating the
gene ontology resource: Design and implementa-
tion. Genome Research, 11(8):1425–1433, August.

Ido Dagan, Oren Glickman, and Bernardo Magnini.
2006. The PASCAL Recognising Textual Entail-
ment challenge. Machine Learning Challenges,
pages 177–190.

Julia A Ekstrom and Gloria T Lau. 2008. Exploratory
text mining of ocean law to measure overlapping
agency and jurisdictional authority. In Proceedings
of the 2008 international conference on Digital gov-
ernment research, pages 53–62. Digital Government
Society of North America.

Chikara Hashimoto, Kentaro Torisawa, Stijn
De Saeger, Jong H. Oh, and Jun’ichi Kazama.
2012. Excitatory or inhibitory: A new semantic
orientation extracts contradiction and causality
from the web. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning, EMNLP-CoNLL ’12, pages
619–630, Stroudsburg, PA, USA. Association for
Computational Linguistics.

Marti A. Hearst. 1999. Untangling text data mining.
In Proceedings of the 37th Annual Meeting of the As-
sociation for Computational Linguistics on Compu-
tational Linguistics, ACL ’99, pages 3–10, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.

Lynette Hirschman, Alexander Yeh, Christian
Blaschke, and Alfonso Valencia. 2005. Overview
of BioCreAtIvE: critical assessment of informa-
tion extraction for biology. BMC Bioinformatics,
6(Suppl 1):S1+.

T. K. Jenssen, A. Laegreid, J. Komorowski, and
E. Hovig. 2001. A literature network of human
genes for high-throughput analysis of gene expres-
sion. Nat Genet, 28:21–28.

Hongyan Jing. 2000. Sentence reduction for auto-
matic text summarization. In Proceedings of the
sixth conference on Applied natural language pro-
cessing, pages 310–315. Association for Computa-
tional Linguistics.

J. D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003. GE-
NIA corpus—a semantically annotated corpus for
bio-textmining. Bioinformatics, 19(suppl 1):i180–
i182, July.

Kevin Knight and Daniel Marcu. 2002. Summariza-
tion beyond sentence extraction: A probabilistic ap-
proach to sentence compression. Artificial Intelli-
gence, 139(1):91–107.

Ronald N. Kostoff, Raymond G. Koytcheff, and Clif-
ford G.Y. Lau. 2007. Global nanotechnology re-
search literature overview. Technological Forecast-
ing and Social Change, 74(9):1733 – 1747. Three
Special Sections: Assessment of China’s and India’s
Science and Technology Literature Nanotechnology
Policy Minding the Gap: Previewing the Potential of
Breakthrough Technologies.

Martin Krallinger, Alfonso Valencia, and Lynette
Hirschman. 2008. Linking genes to literature:
text mining, information extraction, and retrieval ap-
plications for biology. Genome Biology, 9(Suppl
2):S8+, September.

Roger Levy and Galen Andrew. 2006. Tregex and
Tsurgeon: tools for querying and manipulating tree
data structures. In Proceedings of the fifth interna-
tional conference on Language Resources and Eval-
uation, pages 2231–2234.

510



Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven J. Bethard, and David Mc-
Closky. 2014. The Stanford CoreNLP natural lan-
guage processing toolkit. In Proceedings of 52nd
Annual Meeting of the Association for Computa-
tional Linguistics: System Demonstrations, pages
55–60.

Erwin Marsi, Pinar Oztürk, Elias Aamot, Gleb Sizov,
and Murat V Ardelan. 2014. Towards text mining in
climate science: Extraction of quantitative variables
and their relations. In Proceedings of the Fourth
Workshop on Building and Evaluating Resources for
Health and Biomedical Text Processing, Reykjavik,
Iceland.

Makoto Miwa, Paul Thompson, and Sophia Ana-
niadou. 2012. Boosting automatic event ex-
traction from the literature using domain adapta-
tion and coreference resolution. Bioinformatics,
28(13):1759–1765.

Roser Morante and Walter Daelemans. 2009. Learn-
ing the scope of hedge cues in biomedical texts.
In Proceedings of the Workshop on Current Trends
in Biomedical Natural Language Processing, pages
28–36. Association for Computational Linguistics.

Brendan O’Connor, David Bamman, and Noah Smith.
2011. Computational text analysis for social sci-
ence: Model assumptions and complexity. In Pro-
ceedings of the Second Workshop on Computational
Social Science and the Wisdom of the Crowds (NIPS
2011).

Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjorne, Jorma Boberg, Jouni Jarvinen, and Tapio
Salakoski. 2007. BioInfer: a corpus for information
extraction in the biomedical domain. BMC Bioin-
formatics, 8:50.

Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Jun’ichi Tsujii, and Sophia Ananiadou. 2012.
Overview of the ID, EPI and REL tasks of BioNLP
shared task 2011. BMC Bioinformatics, 13(Suppl
11):S2+, June.

Kalpana Raja, Suresh Subramani, and Jeyakumar
Natarajan. 2013. Ppinterfinder–a mining tool for
extracting causal relations on human proteins from
literature. Database (Oxford), 2013:bas052.

Raul Rodriguez-Esteban. 2009. Biomedical Text
Mining and Its Applications. PLoS Comput Biol,
5(12):e1000597+, December.

Sunita Sarawagi. 2008. Information extraction.
Found. Trends databases, 1(3):261–377, March.

Matthew Shardlow. 2014. A survey of automated text
simplification. International Journal of Advanced
Computer Science and Applications, 4(1).

Matthew S. Simpson and Dina Demner-Fushman.
2012. Biomedical Text Mining: A Survey of Re-
cent Progress. In Charu C. Aggarwal and ChengXi-
ang Zhai, editors, Mining Text Data, pages 465–517.
Springer US.

Don R. Swanson and Neil R. Smalheiser. 1997. An
interactive system for finding complementary liter-
atures: a stimulus to scientific discovery. Artificial
Intelligence, 91(2):183–203, April.

Don R. Swanson. 1986. Fish oil, raynaud’s syndrome,
and undiscovered public knowledge. Perspectives in
biology and medicine, 30(1):7–18.

Don R. Swanson. 1988. Migraine and magnesium:
eleven neglected connections. Perspectives in Biol-
ogy and Medicine, 31(4):526–557.

Marco A. Valenzuela-Escárcega, Gustave Hahn-
Powell, Thomas Hicks, and Mihai Surdeanu. 2015.
A domain-independent rule-based framework for
event extraction. In Proceedings of the 53rd Annual
Meeting of the Association for Computational Lin-
guistics and the 7th International Joint Conference
on Natural Language Processing of the Assian Fed-
eration of Natural Language Processing: Software
Demonstrations (ACL-IJCNLP).

Piek Vossen, German Rigau, Eneko Agirre, Aitor
Soroa, Monica Monachini, and Roberto Bartolini.
2010. KYOTO: an open platform for mining facts.
In Proceedings of the 6th Workshop on Ontologies
and Lexical Resources , pages 1–10, Beijing, China,
August. Coling 2010 Organizing Committee.

Ce Zhang, Vidhya Govindaraju, Jackson Borchardt,
Tim Foltz, Christopher Ré, and Shanan Peters.
2013. GeoDeepDive: Statistical inference using fa-
miliar data-processing languages. In Proceedings of
the 2013 ACM SIGMOD International Conference
on Management of Data, SIGMOD ’13, pages 993–
996, New York, NY, USA. ACM.

Pierre Zweigenbaum and Dina Demner-Fushman.
2009. Advanced Literature-Mining Tools. In David
Edwards, Jason Stajich, and David Hansen, editors,
Bioinformatics, pages 347–380. Springer New York.

Pierre Zweigenbaum, Dina Demner-Fushman, Hong
Yu, and Kevin B. Cohen. 2007. Frontiers of
biomedical text mining: current progress. Briefings
in Bioinformatics, 8(5):358–375, September.

511


