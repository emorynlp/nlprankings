



















































A Dependency-Constrained Hierarchical Model with Moses


Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 464–471,
Sofia, Bulgaria, August 8-9, 2013 c©2013 Association for Computational Linguistics

A Dependency-Constrained Hierarchical Model with Moses

Yvette Graham†‡
†Department of Computing and Information Systems, The University of Melbourne

‡Centre for Next Generation Localisation, Dublin City University
ygraham@unimelb.edu.au

Abstract

This paper presents a dependency-
constrained hierarchical machine transla-
tion model that uses Moses open-source
toolkit for rule extraction and decoding.
Experiments are carried out for the
German-English language pair in both di-
rections for projective and non-projective
dependencies. We examine effects on
SCFG size and automatic evaluation
results when constraints are applied with
respect to projective or non-projective
dependency structures and on the source
or target language side.

1 Introduction

A fundamental element of natural language syntax
is the dependency structure encoding the binary
asymmetric head-dependent relations captured in
dependency grammar theory. A main criteria for
determining the dependency structure of a given
sentence is the following: The linear position of
dependent, D, is specified with reference to its
head, H (Kübler et al., 2009). This runs in parallel
with that which hierarchical machine translation
SCFG rules encode: The linear position of a trans-
lated phrase, Xi, is specified with reference to the
lexicalised words in the rule. Figure 1 shows de-

She lives
�� ����

in
��

a white house
����

.

Ella vive
�� ����

en
��

una casa
�� ��

blanca .

Figure 1: Projective Dependency Structures

pendency structures for She lives in a white house
and its Spanish translation, with example SCFG

(1) X →< white house , casa blanca >
(2) X →< white , blanca >
(3) X →< house , casa >
(4) X →< X0 house , casa X0 >
(5) X →< white X0 , X0 blanca >

Figure 2: Initial rules (1), (2) and (3), with hierar-
chical rules (4) and (5)

rules shown in Figure 2. Given the existence of
initial rules (1), (2) and (3), hierarchical rules (4)
and (5) can be created. Rule (4) specifies the lin-
ear position of the translation of the English phrase
that precedes house with reference to lexicalised
casa.

For hierarchical machine translation models
(Chiang, 2005), there is no requirement for a syn-
tactic relationship to exist between the lexicalised
words of a rule and the words replaced by non-
terminals, the only requirement being that substi-
tuted words form an SMT phrase (Koehn et al.,
2003). The dependency structure of either the
source or target (or indeed both) can, however, be
used to constrain rule extraction as to only allow
hierarchical rules in which the linear position of
dependents are specified with reference to the po-
sition of their lexicalised heads. For example, in
the case of the hierarchical rules in Figure 2, rule
(4) satisfies such a constraint according to both the
source and target language dependency structures
(since white is the dependent of house and blanca
is the dependent of casa, and it is both white and
blanca that are replaced by non-terminals while
the heads remain lexicalised) and results in a syn-
chronous grammar rule that positions a dependent
relative to the position of its lexicalised head. Rule
(5), on the other hand, does not satisfy such a con-
straint for either language dependency structure.

In this work, we examine a dependency-
constrained model in which hierarchical rules are

464



only permitted in which lexicalised heads spec-
ify the linear position of missing dependents, and
examine the effects of applying such constraints
across a variety of settings for German to English
and English to German translation.

2 Related Work

The increased computational complexity intro-
duced by hierarchical machine translation mod-
els (Chiang, 2005), has motivated techniques of
constraining model size as well as decoder search.
Among such include the work of Zollmann et al.
(2008) and Huang and Xiang (2010), in which rule
table size is vastly reduced by means of filtering
low frequency rules, while Tomeh et al. (2009),
Johnson et al. (2007) and Yang and Zheng (2009)
take the approach of applying statistical signifi-
cance tests to rule filtering, with Lee et al. (2012)
defining filtering methods that estimate transla-
tional effectiveness of rules.

Dependency-based constraints have also been
applied in a variety of settings to combat complex-
ity challenges. Xie et al. (2011) use source side
dependency constraints for translation from Chi-
nese to English, while Shen et al. (2010) apply
target-side dependency constraints for the same
language pair and direction in addition to Ara-
bic to English, Peter et al. (2011) also apply de-
pendency constraints on the target side, but rather
soft constraints that can be relaxed in the case that
an ill-formed structure does in fact yield a bet-
ter translation. Gao et al. (2011) similarly ap-
ply soft dependency constraints but to the source
side for Chinese to English translation, and Galley
and Manning (2009) show several advantages to
using maximum spanning tree non-projective de-
pendency parsing decoding for Chinese to English
translation. Li et al. (2012), although not con-
straining with dependency structure, instead cre-
ate non-terminals with part-of-speech tag combi-
nations for Chinese words identified as heads for
translation into English.

In this paper, we apply the same dependency
constraint to SCFG rule extraction in a variety
of configurations to investigate effects of apply-
ing constraints on the source or target side, to the
language with most or least free word order, as
well as constraining with non-projective depen-
dency structures.

Non-Projective Dependencies
German 38%
English 11%

Table 1: WMT Parallel Training Data

3 Non-Projective Dependencies

A non-projectivity structure is defined as follows:
A non-projective dependency structure is a depen-
dency structure in which at least one dependency
relation exists between a head, H , and its depen-
dent, D, in which the directed path from H to
D does not include at least one word positioned
linearly in the surface form between H and D.
Figure 3 shows an example non-projective depen-
dency structure arising from English Wh-fronting.

Non-projective dependencies occur frequently

When did
�� ����

the crisis
��

begin
��

?

Figure 3: Non-projective Dependency Structure

for many languages, increasingly so for languages
with high levels of free words order. An exami-
nation of Chinese treebanks, for example, reports
that Chinese displays nine different kinds of non-
projective phenomena (Yuelong, 2012) with re-
ports of as many as one in four sentences in tree
banks having non-projective dependency struc-
tures (Nivre, 2007). Even for a language with
relatively rigid word order such as English non-
projectivity is still common, due to Wh-fronting,
topicalisation, scrambling and extraposition. Ta-
ble 1 shows the frequency of non-projective de-
pendency structures in WMT parallel data sets for
German and English when parsed with a state-of-
the-art non-projective dependency parser (Bohnet,
2010).

4 Constrained Model

We define the dependency constraint as follows: to
create a hierarchical rule by replacing a word or
phrase with a non-terminal, all the words of that
phrase must belong to a single complete depen-
dency tree and its head must remain lexicalised
in the rule. In this way, the hierarchical rules of
the SCFG position missing dependents relative to
the position of lexicalised heads. Before extract-

465



ing SCFG rules for the dependency-constrained
models, we transform non-projective structures
into projective ones, in order to allow the sub-
stitution of non-projective dependency trees by a
single non-terminal. Although the transformation
simplifies the dependency structure, it will intro-
duce some dis-fluency to the training data, and we
therefore include experiments to examine such ef-
fects.

Figure 4 shows a German-English translation
constrained by means of the German dependency
structure and Figure 5 shows the full set of
dependency-constrained hierarchical SCFG rules,
where dependents are specified with reference to
lexicalised heads.

5 Implementation with Moses

For rule extraction we use Moses (Williams and
Koehn, 2012) implementation of GHKM (Galley
et al., 2004; Galley et al., 2006), which although is
conventionally used to extract syntax-augmented
SCFGs from phrase-structure parses (Zollmann
and Venugopal, 2006), we apply the same rule ex-
traction tool to dependency parses. Rule extrac-
tion is implemented in such a way as not to be re-
stricted to any particular set of node labels. The
conventional input format is for example:

<tree label="NP">
<tree label="DET"> the </tree>
<tree label="NN"> cat </tree>

</tree>

The dependency-constrained ruleset can be ex-
tracted with this implementation by arranging de-
pendency structures into tree structures as fol-
lows:1

<tree label="X">
<tree label="X">
<tree label="X"> the </tree>
<tree label="X"> black </tree>
cat

</tree>
ate
<tree label="X">
<tree label="X"> the </tree>
rat

</tree>
</tree>

Since XML format requires nesting of substruc-
tures, only projective dependency structures can
be input to the tool in the way we use it, as non-
projectivity breaks nesting.

1Note that is is possible to replace X with dependency
labels.

6 Non-Projectivity Transform

We therefore transform non-projective depen-
dency structures into projective ones by relocat-
ing the dislocated dependent to a position closer
to its head so that it no longer violates projectivity.
We do this in such a way as not to break any of
the existing dependency relations between pairs of
words. Figure 6 shows an example non-projective
structure (a) before and (b) after the transforma-
tion, where the transformation results in the con-
stituent comprised of words when and begin form-
ing a continuous string, making possible the sub-
stitution of this constituent with a non-terminal.
The fact that one side of the training data from
which hierarchical rules are extracted, however, is
no longer guaranteed to be fluent, raises the ques-
tion as to what effect this disfluency might have
when the constraint is applied on the target side.
We therefore include in our evaluation for both
language directions (and for the case where the
constraints are applied to the source) the effects
of word reorder cause by the transformation. The

Figure 6: Non-Projectivity Transformation

algorithm for converting non-projective structures
is an inorder traversal of the dependency struc-
ture as follows, where words are indexed accord-
ing to their position in the original string prior to
the transformation:

Algorithm 6.1: DEP IN ORD(root)

for each d ∈ D and d.index < root.index
do dep in ord(d)

PRINT(root)
for each d ∈ D and d.index > root.index

do dep in ord(d)

466



Figure 4: German English translation with German dependency structure, words surrounded by a dashed
box form a complete dependency tree.

Rules spanning source words 0-6: ich möchte nur wenige anmerkungen machen .
X0 möchte nur wenige anmerkungen machen . X0 should like to make just a few comments .
ich möchte X0 . i should like to X0 .
ich möchte X0 machen . i should like to make X0 .
ich möchte X0 anmerkungen machen . i should like to make X0 comments .
ich möchte X0 wenige anmerkungen machen . i should like to make X0 a few comments .
ich möchte nur wenige anmerkungen machen X0 i should like to make just a few comments X0

non-proj X0 möchte X1 . X0 should like to X1 .
X0 möchte X1 machen . X0 should like to make X1 .
X0 möchte X1 anmerkungen machen . X0 should like to make X1 comments .
X0 möchte X1 wenige anmerkungen machen . X0 should like to make X1 a few comments .
X0 möchte nur wenige anmerkungen machen X1 X0 should like to make just a few comments X1
ich möchte X0 X1 i should like to X0 X1
ich möchte X0 machen X1 i should like to make X0 X1
ich möchte X0 anmerkungen machen X1 i should like to make X0 comments X1
ich möchte X0 wenige anmerkungen machen X1 i should like to make X0 a few comments X1

X0 möchte X1 X2 X0 should like to X1 X2
X0 möchte X1 machen X2 X0 should like to make X1 X2
X0 möchte X1 anmerkungen machen X2 X0 should like to make X1 comments X2
X0 möchte X1 wenige anmerkungen machen X2 X0 should like to make X1 a few comments X2

Rules spanning source words 2-5: nur wenige anmerkungen machen
X0 machen make X0
X0 anmerkungen machen make X0 comments
X0 wenige anmerkungen machen X0 a few comments

Rules spanning source words 2-4: nur wenige anmerkungen
X0 anmerkungen X0 comments
X0 wenige anmerkungen X0 a few comments

Rules spanning source words 2-3: nur wenige
X0 wenige X0 a few

Figure 5: Complete set of dependency-constrained hierarchical SCFG rules for Figure 4

467



7 Experiments

WMT training data sets were used for both paral-
lel (1.49 million German/English sentence pairs)
and monolingual training (11.51 million English
& 4.74 million German sentences). Mate non-
projective dependency parser (Bohnet, 2010) was
used for parsing both the German and English
parallel data with standard pre-trained models,
the same parser was used for projective parsing
with non-projectivity turned off.2 Parallel train-
ing data lines containing multiple sentences were
merged into a single pseudo-dependency structure
by adding an artificial root and head-dependent re-
lation between the head of the initial sentence and
any subsequent sentences. Non-projective depen-
dencies were converted into projective structures
using Algorithm 6.1.

Giza++ (Och et al., 1999) was employed for
automatic word alignment, and Moses GHKM
rule extraction (Williams and Koehn, 2012) was
used for hierarchical rule extraction for the
dependency-constrained models. Default settings
were used for rule extraction for all models with
the exception on non-fractional counting being
used, as well as Good-turing discounting. Both
the dependency-constrained and standard mod-
els use the same set of initial rules. For de-
coding, since only a single non-terminal, X , is
present for all models, Moses hierarchical decoder
(Koehn et al., 2007) was used with default set-
tings with the exception of rule span limit being re-
moved for all models. SRILM (Stolke, 2002) was
used for 5-gram language modeling and Kneser-
Ney smoothing (Kneser and Ney, 1995) for both
German-to-English and English-to-German trans-
lation. MERT (Och, 2003) was carried out on
WMT newstest2009 development set optimizing
for BLEU, and final results are reported for held-
out test sets, newstest2010 and newstest2011, with
BLEU (Papineni et al., 2001) and LR-score (Birch
and Osborne, 2010) for evaluation.

7.1 Results

Table 2 shows automatic evaluation results for
both the dependency-constrained and standard
hierarchical models for both language direc-
tions. Compared to the standard hierarchical
model (orig), the best performing dependency-
constrained models, sl npr (de-en) and tl npr (en-

2OpenNLP (Feinerer, 2012) sentence splitter is recom-
mended with the parser we and was used for preprocessing.

de), show significant decreases in mean BLEU
score, -0.44 for German to English and -0.13
for English to German. However, there is a
trade-off, as the dependency-constrained models
achieve vast reductions in model size, approx.
93% for German to English and 89% for English
to German in numbers of SCFG hierarchical rules.
This results in decreased decoding times, with the
best performing dependency-constrained models
achieving a decrease of 26% for German to En-
glish and 34% for English to German in mean de-
coding times.

The decrease in BLEU scores is not likely to be
attributed to less accurate long-distance reordering
for German to English translation, as the Kendall
Tau LR-scores for this language direction show an
increase over the standard hierarchical models of
+0.25 mean LR. Although this is not the case for
English to German, as mean LR scores show a
slight decrease (-0.11 LR).

The number of hierarchical rules (not including
glue rules) employed during decoding provides a
useful indication of to what degree each model ac-
tually uses hierarchical rules to construct transla-
tions, i.e. not simply concatenating phrases with
glue rules. For English to German translation,
while the number of hierarchical rules present in
the SCFG is vastly reduced, the number of hier-
archical rules used during decoding actually in-
creases, with double the number of hierarchical
rules used to translate test segments compared to
the standard hierarchical model, from an average
of only 0.58 hierarchical rules per segment for the
standard model to 1.19 per segment. This indi-
cates that the set of hierarchical rules is refined by
the dependency constraint.

When the more linguistically valid non-
projective dependency structure, as opposed to
the projective dependency structure, is used to
constrain rule extraction significant increases in
BLEU scores are achieved for all configurations.
The most significant gains in this respect occur
when constraints are applied on the source side,
+0.58 mean BLEU for German to English and
+0.50 mean BLEU for English to German.

In general, when constraints are applied to the
more free word order language, German, regard-
less of whether or not translation is into or out of
German, marginally higher BLEU scores result,
with an increase of +0.03 mean BLEU for German
to English translation and similarly an increase of

468



SCFG mean hier. mean segment
hier. rules newstest 2010 newstest 2011 mean rules decode time
(millions) BLEU LR-K BLEU LR-K BLEU decoder (seconds)

de-en

hpb

orig 35.25 22.30 71.86 20.47 70.55 21.39 2.51 6.76
tl re 34.77 22.31 71.43 20.49 70.27 21.40 2.63 6.39
tl are 34.77 22.41 71.16 20.36 69.89 21.39 2.68 6.14
sl are 33.87 22.40 70.78 20.27 69.78 21.34 2.71 6.02
sl re 33.87 22.06 71.38 20.15 70.25 21.11 2.41 6.17

dc

sl npr 2.49 21.57 71.87 20.09 71.04 20.95 1.15 4.99
tl npr 1.45 21.88 72.20 19.95 71.36 20.92 2.85 4.62
tl pr 1.12 21.43 71.82 19.75 70.90 20.59 1.40 3.62
sl pr 0.34 21.05 72.20 19.69 71.36 20.37 1.10 1.98

en-de

hpb

orig 36.30 16.14 70.24 15.05 69.91 15.60 0.58 7.25
tl re 35.20 16.13 69.81 14.94 69.45 15.54 1.03 5.16
tl are 35.20 16.15 69.06 14.57 68.66 15.36 1.89 4.82
sl are 35.68 15.72 69.25 14.44 69.06 15.08 1.88 5.23
sl re 35.68 15.72 70.21 14.38 69.84 15.05 1.16 5.16

dc

tl npr 4.00 16.03 70.12 14.91 69.81 15.47 1.19 4.79
sl npr 1.09 15.94 70.07 14.85 69.69 15.40 1.78 3.46
tl pr 0.92 15.88 70.46 14.78 69.90 15.33 1.23 4.05
sl pr 0.88 15.58 70.18 14.22 69.80 14.90 1.19 2.90

Table 2: Effects of dependency constraints and dependency-based reordering on translation quality for
German-to-English (de-en) and English to German (en-de), hpb=hierarchical phrase-based, orig=no re-
ordering, ∗re=dependency-based word reordering where only hierarchical rules are extracted from re-
ordered training data, ∗are=dependency-based word reordering where all SCFG rules extracted from re-
ordered training data, dc=dependency-constrained, ∗pr=projective parse used for dependency constraint,
∗npr=non-projective parse used for dependency constraint, sl∗=constraints or reordering for source lan-
guage, tl∗=constraints or reordering for target language, numbers of hierarchical rules reported do not
include glue rules.

+0.07 mean BLEU for English to German, with
the increase being statistically significant for Ger-
man to English for the newstest2010 test set, but
not statistically significant for newstest2011 test
set or English to German (Koehn, 2004).

Overall the best performing dependency-
constrained models are those that retain the high-
est numbers of hierarchical rules in the SCFG.
This indicates that although the dependency-
constrained models produce a refined ruleset,
they nevertheless discard some SCFG rules that
would be useful to translate the unseen test data.
One possible reason is that although the non-
projective dependency structures are significantly
better, these high-quality linguistic structures may
still not be optimal for translation. Another pos-
sibility is that a the GHKM rule extraction con-
straints combined with the dependency constraint
is causing a small set of very useful rules to be
discarded.

7.2 Dependency-based Reordering

We examine the effects of the non-projective
transformation in isolation of any dependency-
constraints by training a standard hierarchical

model on the reordered corpus with no depen-
dency constraints applied. We do this in two set-
ups. First, we extract hierarchical rules from the
reordered training corpus and initial rules from the
original unaltered corpus (∗ re in Table 2), as this
is the set-up for the dependency-constrained mod-
els. Simply for interest sake, we repeat this exper-
iment but extract all rules (hierarchical and initial
rules) from the reordered corpus (∗ are in Table 2).

Surprisingly, when non-projective reordering is
carried out on the target side no significant de-
crease in BLEU scores occurs for both language
directions. In fact, a minor increase in mean
BLEU (+0.01) is observed for German to English
translation, but this small increase is not statisti-
cally significant. For the English to German direc-
tion, a minor decrease of -0.06 mean BLEU occurs
(not statistically significant).

Similarly for German to English, when reorder-
ing is applied to the source side, only a minor
decrease (-0.05) results. Non-projective reorder-
ing causes the most significant reduction in per-
formance for English to German when the English
source is reordered, with a decrease of -0.52 mean
BLEU.

469



Conclusions

This paper examines non-projectivity and lan-
guage application for dependency-constrained
hierarchical models using Moses open-source
toolkit. Experiments show that when applied
to English to German translation, vastly reduced
model size and subsequently decreased decoding
times result with only a minor decrease in BLEU.
In addition, higher numbers of (non-glue) hierar-
chical rules are used to translate test segments. For
German to English translation, similar decreases
in model size and decoding times occur, but at the
expense of a more significant decrease in BLEU.

In general, results for the dependency-
constrained models show that applying constraints
on the source or target side does not have a major
impact on BLEU scores. Rather the use of high
quality linguistic structures is more important, as
significant improvements are made for all con-
figurations when the non-projective dependency
structure is used to constrain rule extraction.

Acknowledgments

Many thanks to the Moses developers, especially
Hieu Hoang and Alexandra Birch. Thanks also to
Tsuyoshi Okita and anonymous reviewers. This
research was supported by the Australian Re-
search Council, as well as Science Foundation Ire-
land as part of the Centre for Next Generation Lo-
calisation.

References
Alexandra Birch and Miles Osborne. 2010. Lrscore for

evaluating lexical and reordering quality in mt. In
Proceedings of the Joint Fifth Workshop on Statisti-
cal Machine Translation and MetricsMATR, pages
327–332, Uppsala, Sweden, July. Association for
Computational Linguistics.

Bernd Bohnet. 2010. Very high accuracy and fast de-
pendency parsing is not a contradiction. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics, pages 89–97. Association for
Computational Linguistics.

David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting on Association
for Computational Linguistics, pages 263–270. As-
sociation for Computational Linguistics.

Ingo Feinerer. 2012. tm: Text mining package. R
package version 0.5-7.1.

Michel Galley and Christopher D Manning. 2009.
Quadratic-time dependency parsing for machine
translation. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the
4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP: Volume 2-Volume
2, pages 773–781. Association for Computational
Linguistics.

Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What’s in a translation rule?
In HLT-NAACL, pages 273–280.

Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training
of context-rich syntactic translation models. In
Proceedings of the 21st International Conference
on Computational Linguistics and the 44th annual
meeting of the Association for Computational Lin-
guistics, pages 961–968. Association for Computa-
tional Linguistics.

Yang Gao, Philipp Koehn, and Alexandra Birch. 2011.
Soft dependency constraints for reordering in hier-
archical phrase-based translation. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, pages 857–868. Association
for Computational Linguistics.

Fei Huang and Bing Xiang. 2010. Feature-rich dis-
criminative phrase rescoring for smt. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics, pages 492–500. Association
for Computational Linguistics.

Howard Johnson, Joel Martin, George Foster, and
Roland Kuhn. 2007. Improving translation qual-
ity by discarding most of the phrasetable. In Pro-
ceedings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 967–975.

Reinhard Kneser and Hermann Ney. 1995. Improved
backing-off for m-gram language modeling. In
Proceedings of the IEEE International Conference
on Accoustics, Speech and Signal Processing, vol-
ume 1.

Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase based translation. In Pro-
ceedings of the Joint Conference on Human Lan-
guage Technologies and the Annual Meeting of the
North American Chapter of the Association of Com-
putational Linguistics (HLT-NAACL).

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Christopher J. Dyer, Ondřej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open source toolkit for statistical machine
translation. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguis-
tics Companion Volume Proceedings of the Demo

470



and Poster Sessions, pages 177–180, Prague, Czech
Republic, June. Association for Computational Lin-
guistics.

Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Dekang Lin and
Dekai Wu, editors, Proceedings of EMNLP 2004,
pages 388–395, Barcelona, Spain, July. Association
for Computational Linguistics.

Sandra Kübler, Ryna McDonald, and Joakim Nivre.
2009. Dependency Parsing. Synthesis Lectures on
Human Language Technologies. Morgan & Clay-
pool.

Seung-Wook Lee, Dongdong Zhang, Mu Li, Ming
Zhou, and Hae-Chang Rim. 2012. Translation
model size reduction for hierarchical phrase-based
statistical machine translation. In Proceedings of the
50th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 2: Short Papers), pages
291–295, Jeju Island, Korea, July. Association for
Computational Linguistics.

Junhui Li, Zhaopeng Tu, Guodong Zhou, and Josef
van Genabith. 2012. Using syntactic head infor-
mation in hierarchical phrase-based translation. In
Proceedings of the Seventh Workshop on Statisti-
cal Machine Translation, pages 232–242, Montréal,
Canada, June. Association for Computational Lin-
guistics.

Joakim Nivre. 2007. Incremental non-projective
dependency parsing. In Proceedings of Human
Language Technologies: The Annual Conference
of the North American Chapter of the Association
for Computational Linguistics (NAACL-HLT), pages
396–403, Rochester, NY.

Franz Josef Och, Christoph Tillmann, and Hermann
Ney. 1999. Improved alignment models for sta-
tistical machine translation. In Proceedings of the
Joint Conference of Empirical Methods in Natu-
ral Language Processing and Very Large Corpora
(EMNLP-VLC), pages 20–28.

Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Erhard Hinrichs
and Dan Roth, editors, Proceedings of the 41st An-
nual Meeting of the Association for Computational
Linguistics, pages 160–167.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. BLEU: a method for automatic
evaluation of machine translation. Technical Re-
port RC22176(W0109-022), IBM Research Report,
September 17.

Jan-Thorsten Peter, Matthias Huck, Hermann Ney, and
Daniel Stein. 2011. Soft string-to-dependency hi-
erarchical machine translation. In Marcello Fed-
erico, Mei-Yuh Hwang, Margit Rödder, and Sebas-
tian Stüker, editors, Proceedings of the seventh In-
ternational Workshop on Spoken Language Transla-
tion (IWSLT), pages 246–253.

Libin Shen, Jinxi Xu, and Ralph Weischedel. 2010.
String-to-dependency statistical machine transla-
tion. Computational Linguistics, 36(4):649–671.

Andreas Stolke. 2002. SRILM - an extensible lan-
guage modeling toolkit. In Proceedings of the Inter-
national Conference on Spoken Language Process-
ing, pages 577–585.

Nadi Tomeh, Nicola Cancedda, and Marc Dymetman.
2009. Complexity-based phrase-table filtering for
statistical machine translation. In Proceedings of the
Twelfth Machine Translation Summit (MT Summit
XII). International Association for Machine Trans-
lation.

Philip Williams and Philipp Koehn. 2012. GHKM
rule extraction and scope-3 parsing in moses. In
Proceedings of the Seventh Workshop on Statisti-
cal Machine Translation, pages 434–440, Montreal,
Canada, June. Association for Computational Lin-
guistics.

Jun Xie, Haitao Mi, and Qun Liu. 2011. A novel
dependency-to-string model for statistical machine
translation. In Proceedings of the 2011 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 216–226, Edinburgh, Scotland, UK.,
July. Association for Computational Linguistics.

Mei Yang and Jing Zheng. 2009. Toward smaller,
faster, and better hierarchical phrase-based smt. In
Proceedings of the ACL-IJCNLP 2009 Conference
Short Papers, pages 237–240, Suntec, Singapore,
August. Association for Computational Linguistics.

Wang Yuelong. 2012. Edge-crossing Non-projective
Phenomena in Chinese Language. Ph.D. thesis, Na-
tional University of Singapore.

Andreas Zollmann and Ashish Venugopal. 2006. Syn-
tax augmented machine translation via chart parsing.
In Proceedings on the Workshop on Statistical Ma-
chine Translation, pages 138–141, New York City,
June. Association for Computational Linguistics.

Andreas Zollmann, Ashish Venugopal, Franz Josef
Och, and Jay Ponte. 2008. A systematic comparison
of phrase-based, hierarchical and syntax-augmented
statistical MT. In Proceedings of the 22nd Inter-
national Conference on Computational Linguistics
(Coling 2008), pages 1145–1152, Manchester, UK,
August. Coling 2008 Organizing Committee.

471


