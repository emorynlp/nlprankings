










































A Toolkit to Assist L2 Learners Become Independent Writers


Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics and Writing, pages 33–41,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

 
 

A Toolkit to Assist L2 Learners Become Independent Writers  

John Milton and Vivying S. Y. Cheng 
Language Center 

HKUST, Clear Water Bay 
Hong Kong 

{lcjohn,vivying}@ust.hk 
 

 

 

 

  

Abstract 

This paper describes a resource-rich toolkit 
that assists EFL writers take a discovery-
based approach to writing accurate and fluent 
English.  The system helps learners identify 
lexico-grammatical errors by matching pat-
terns gleaned from a very large corpus of 
learners’ texts.  Users are guided to appropri-
ate language patterns as they write and revise 
through online declarative and procedural re-
sources.  Even as more robust and fully auto-
matic feedback technologies evolve, 
comprehensive resource-rich support will re-
main necessary for second-language (L2) 
writers who must develop practical life-long 
language learning strategies.  To assist lan-
guage tutors support novice L2 writers, we 
have also produced tools that help tutors rein-
force their students’ independent writing and 
proofreading strategies.  The operation and ra-
tionale of this approach have been imple-
mented and evaluated in several Hong Kong 
universities and secondary schools.  

1 Introduction 

Proofing technologies for L2 writers have been of 
interest to the NLP community since the 1970s, 
and have been subject to critical evaluation since 
the early 80s (e.g., Frase et al, 1981, Dobrin, 
1985).  In spite of continued interest in this area 
(e.g. Vernon, 2000; Foster and Vogel, 2004; Yi et 
al, 2008; Bender, 2009), computational linguists 
themselves remain disappointed with the lack of 
ongoing development of commercially available 
systems (Wampler, 2002).  A more serious prob-
lem, from the view of applied linguists, is that en-

thusiasm for the technology has often resulted in a 
purely operational approach.  The focus on algo-
rithmic solutions to the correction of ill-formed 
input has frequently overlooked the long-term 
pedagogical needs of L2 novice writers.  The pars-
ing techniques of grammar checkers may reliably 
flag a subset of L2 errors; however, there is some 
question as to whether automatically generated 
prescriptive advice, even when it is reliable, actu-
ally helps learner language evolve (Bolt, 1992; 
Chen, 1997).  While machine-generated error iden-
tification and correction may be a desirable con-
venience for casual writers, explicit correction by a 
machine, or for that matter, a human tutor, appears 
to be counterproductive in the development of an 
L2 writer’s proficiency (Truscott, 1996; Ferris and 
Hedgcock, 2005).  

The goal of the project described here is to de-
velop a suite of tools that will help novice writers 
who are learning to write in academic or profes-
sional contexts improve the accuracy and fluency 
of their texts, while also becoming more confident 
in their long-term command of English.  We have 
developed companion tools to help teachers of 
writing improve the efficiency and reliability of 
their feedback, and move L2 novice writers toward 
life-long independence.  The following section out-
lines some of the limitations of currently available 
grammar checking software in accomplishing these 
goals. 

2 Limitations of Parsing Technology 

Most grammar checking programs use some form 
of parsing to identify errors.  Typically, if a sen-
tence is ungrammatical according to a set of pars-
ing rules, the programs attempt alternate analysis.  
However, the unconstrained text of L2 learners is 

33



 
 

difficult to parse.  Even more demanding is the 
ability of software (or, very often, human tutors) to 
suggest a ‘correct’ version that reflects the writer’s 
intention.  This requires semantic disambiguation 
well beyond our current ontology or technology. 

The difficulties in parsing natural language are 
compounded in the case of interlanguage (Schnei-
der and McCoy, 1998).  Parsers generally are 
based on theoretical models of how grammatical 
sentences of the target language should be con-
structed.  This approach is especially ineffective 
for cases where the speakers’ first language is lin-
guistically remote from the target language.  For 
example, the current version of the parser-based 
grammar checker in Microsoft Word sacrifices a 
low rate of recall for a relatively high rate of preci-
sion in the analysis of Chinese speakers’ English 
texts.  That is, it displays few flagged errors com-
pared to the total number of errors actually occur-
ring in a text, a necessary trade-off resulting from 
the need to reduce distracting false positives.  This 
is understandable since the rates of recall and pre-
cision for various grammatical constituents are 
inconsistent, and the numbers of false positives are 
not easily reduced across all types of grammatical 
constructions. 

The insufficient, but nevertheless often still in-
accurate, and frequently non-existent, advice of 
these programs is easily demonstrated.  Following 
are a few common sentence-level errors produced 
by Chinese-speaking novice writers, and the com-
ments generated by the Microsoft Word grammar 
checker: 

1. It worth studying hard.  
[Advice: Fragment (consider revising)] 
2. I born in Hong Kong.  
[Advice: substitute I bore / I had born / I have 
born] 
3. There have three students there.  
[Error not flagged] 
 
These errors are typical examples of learners’ at-

tempts to map Chinese syntax on English construc-
tions (treating ‘worth’, which functions here as a 
preposition1, as a verb, forcing the passive verb 
‘born’ into an active construction, and blending the 
verbs ‘be’ and ‘have’ into one form, as their 
                                                             
1 The tendency of most dictionaries to label ‘worth’ as an ad-
jective, regardless of its function in the sentence, may com-
pound the confusion for speakers of Chinese, who often 
confuse adjective and noun forms and functions. 

equivalents are in Chinese).  The first comment is 
unhelpful; all options in the second set of sugges-
tions are, bizarrely, further from Standard English 
than the student’s original text, and the third sen-
tence passes without comment.  

In addition to its general unreliability for L2 
writers, grammar/style-checking software has been 
censured for giving overly narrow and prescriptive 
advice (Pennington, 1992), for compounding the 
already constrained nature of L2 production 
(Chapelle, 2001) and for otherwise abusing the 
tenets of good pedagogy (McGee and Ericsson, 
2002).  Even if the reliability of parsing technology 
can be significantly enhanced, much of the compo-
sition research of the last fifty years has argued 
against imposing corrections on the texts of novice 
writers.  Current theories of language pedagogy 
promote learner independence and discourage di-
rect correction by tutors.  In light of the limitations 
of writing software, reliance on a deus ex machina 
for correction is hardly a desirable alternative to 
dependence on a language tutor. 

A more principled, and ultimately more valid, 
role for language tools in supporting L2 novice 
writers is to enable them to test their evolving hy-
potheses of the L2.  This should free the human 
tutor in an academic context to act as a guide, en-
suring that these hypotheses evolve. 

3 Assisting L2 Writers become Independ-
ent 

Our objective has been to develop a program that 
avoids machine-generated prescription, while still 
helping L2 writers identify common grammatical, 
lexical and style errors.  Instead of proscribing us-
age and preempting users’ choices, we expose L2 
writers to authentic language and help them be-
come aware of the differences between their inter-
language and the particular L2 genre they are 
attempting to produce.  

Unlike typical grammar checkers, our program 
does not appropriate the embryonic text of novice 
writers.  Many of these learners will spend much of 
their professional life writing in the L2, and they 
need to develop independence.  While not explic-
itly correcting lexico-grammatical errors, we aim 
to sensitize learners to common errors, without 
relying on a generic parser. 

34



 
 

 
Figure 1: A discovery-based model of the writing proc-
ess. 

Figure 1 illustrates our model of a discovery-
based approach for L2 writers.  During the writing 
process, learners can consult resources that provide 
information on problematic L2 grammatical struc-
tures, as well as the semantic and collocational 
properties of L2 lexis.  Users are guided through a 
discovery process that helps them become respon-
sible for their own writing, thus reducing the bur-
den on both software and human tutors to identify 
and correct errors.  The role of the software, and of 
the human tutor, is to assist the writer express 
meaning in an acceptable manner, rather than ex-
plicitly to interpret the writer’s text. 

Our approach allows L2 writers to improve in 
two fundamentally different ways: through didactic 
explanations and via an inductive/procedural ap-
proach.  They can choose either method or a com-
bination, depending on the nature of the language 
problem and each user’s learning style (e.g., their 
extent of ‘field dependence’, see Witkin et al., 
1977). 

The program ‘Check My Words’ (Figure 2) 
gives L2 novice writers access to interactive ex-
planations of common structural and lexical errors 
from an Internet grammar as they write.  These 
explanations are based on an analysis of a large L2 
corpus consisting of millions of words of the writ-
ing of Chinese speakers, from which a typology of 
misused, and blatantly underused or overused lexi-
cal and structural patterns, was extracted (e.g., Mil-
ton, 2001).  Hundreds of problematic words and 
patterns in a learner’s text are explained.  This is 
the kind of didactic, deductive advice that a good 
textbook might provide, except that there are few 
textbooks targeted directly at the EFL learning dif-
ficulties of speakers of particular L1s, and this in-
ternet grammar is embellished with interactive 
multimedia: it is fun to use.  

Secondly, the program enables learners to dis-
cover how the language they are struggling to use 
is formulated in relevant, professionally written 
texts.  They have a choice of search engines that 
they can use to look up words in context.  To-
gether, these search engines address many of the 
problems learners encounter in choosing words, 
forms and constructions.  This inductive, proce-
dural access to writing models, combined with the 
feedback tutors can provide via companion tools, 
greatly increases the amount of positive and nega-
tive evidence about the L2 available to the novice 
writer—support that researchers of applied linguis-
tics believe promotes language acquisition (e.g., 
Trahey and White, 1993, Doughty and Varela, 
1998).  

In addition to helping learners become more 
confident, responsible, and independent in select-
ing language that is both accurate and appropriate 
to their purposes, this approach helps relieve lan-
guage tutors of the need to act as proofreading 
slaves.  When learners are given the tools to attend 
to form, taught how to use the tools, and held ac-
countable for their own progress, teachers can 
share more of the burden of responsibility for 
learning with their students.  This approach re-
duces the need to impose corrections, either by 
human or machine intervention.  The next section 
explains this procedure in more detail.  

4 Promoting language awareness  

‘Check My Words’ is designed to encourage learn-
ers of English become aware of the role of lexis, 
forms, and functions in the L2, and to self-correct.  
Errors in the L2 writing of Chinese speakers have 
been analyzed and compiled into an online gram-
mar guide mapped to the user’s word processor so 
that problematic words and structures can be que-
ried during the writing process to determine if they 
are misused in the writer’s document.  

An example is one of the interlanguage patterns 
we noted earlier: ‘It worth studying hard.’  In such 
cases, where the error is easily captured as a lexical 
pattern (‘worth’ occurring without the verb ‘be’), 
the program highlights the pattern, and the user 
then presses a ‘Check’ button to see possible er-
rors, with the most probable error highlighted 
(Figure 3).  The user selects a link to consult the 
English Grammar Guide (EGG). 

35



 
 

 

 
 
Figure 3: The type of prompt that appears when a 
learner ‘checks’ a highlighted expression. 
 

Explanations in the EGG are accompanied by 
examples and a mini-test.  Interesting multimedia 
resources are also used to illustrate the explanation.  
For example, in Figure 4, the use of the word 
‘worth’ is exemplified in an advertisement that 
sells its products with the rationalization that 
‘you’re worth it’.  

 
Figure 4: An explanatory fragment of the word ‘worth’ 

from the English Grammar Guide. 
 

Over 500 lexico-grammatical errors are indexed, 
based on a comprehensive analysis of a corpus of 
the learners’ texts.  Figure 5 illustrates a cartoon 
conversation addressing another common error in 
this interlanguage—the blending of the verb and 
adjective functions of ‘concern’ (e.g., ‘I concern 
about…’). 

 

Figure 5: An explanatory fragment of the word ‘con-
cern’ from the English Grammar Guide. 

In addition to an online descriptive grammar, the 
program points users to procedural/inductive re-
sources—online lookup engines—where they can 
explore the contextual properties of difficult L2 
patterns and retrieve collocates of any word or pat-
tern.  

 
 

Figure 6: The pull-down list of resources on the Check 
My Words toolbar. 
 

Users choose one of these resources from the 
Check My Words toolbar (Figure 6), and the pro-
gram generates appropriate search syntax for each 
lookup resource (a Google search of the web, news 
or scholarly articles, or via our own lookup engine, 
‘Word Neighbors’).  These resources provide 

 
Figure 2: The Check My Words toolbar for EFL learners. 

36



 
 

‘snapshots’ of the word or structure in context, 
which is especially useful for learners who have 
not read widely in the L2.  Word Neighbors dis-
plays the collocational properties of words and 
phrases in selected, professionally written texts, 
and provides learners the opportunity to explore 
the relationship between their own output and L2 
target forms.  Users are guided in looking up words 
and expressions in Word Neighbors via the dia-
logue shown in Figure 7.  

 
Figure 7: The dialogue prompt for Word Neighbors. 

The features of Word Neighbors’ can be demon-
strated by again exploring the sample error: It 
worth studying hard.  Figure 8 displays the word 
worth as the target word.  The search parameters 
are set by default to display missing words and to 
suggest alternatives for malformed words.  Word 
Neighbors also displays patterns as they occur in 
various genres.  The parameters Show X words 
before/after allow users to select the number of 
words to be shown before or after the target word.  
The Span X word(s) drop-down enables the user to 
investigate possible missing or redundant words in 
a phrase, and the Show all word forms checkbox 
enables users to display all forms of a word.  

The first screen from the Word Neighbors 
search result (Figure 8) shows all classes2 of the 
target word and, in this case, the classes that nor-
mally precede that word.  The user has empirical 
evidence that worth is usually a preposition pre-
ceded by a copula verb.  Clicking Show results 
displays specific instances of this pattern (Figure 
9).  Clicking See contexts then displays sentences 
and paragraphs containing the words (Figure 10). 

The difference between our approach to error 
correction and that of systems that rely on auto-
matic detection is well illustrated by preposition 
errors.  Chodorow et al (2007), for example, dis-
cuss a method for detecting preposition errors that 
they report achieves a precision of 0.8 and a recall 
of 0.3. 
                                                             
2 Texts are tagged with CLAWS (Garside and Smith, 1997). 

 

Figure 8: Word Neighbors displays search result of the 
word ‘worth’ in different word class patterns 

 

 
 
Figure 9: Word Neighbors displays the search result for 
the pattern VERB + PREP. 
 

 
 
Figure 10: Word Neighbors displays sentences contain-
ing the pattern ‘is worth’. 
 
 

37



 
 

While this type of ambitious scientific research 
is important and interesting, it is still of limited use 
by non-native writers.  We have not attempted to 
flag preposition errors unless they are invariable 
associated with a frequently misused lexical pat-
tern (e.g., ‘They demanded for more time.’).  In-
stead, the novice writer is encouraged to use a 
resource such as Word Neighbors to look up the 
typical patterns of prepositions.  These errors lend 
themselves well to such a pattern-matching ap-
proach.  If we take this error as an example, the 
user has only to highlight the words surrounding 
the preposition, and look up the pattern ‘demanded 
* more’.  The program ellipts the preposition and 
looks for a span of three words, resulting in the 
display in Figure 11.  

Concordance-type tools such as Word Neigh-
bors provide authentic information about the pat-
terns of language, but the L2 writer must often 
decide which context is appropriate for a particular 
case.  Dialogue boxes and tutorials give learners 
guidance with this discovery-based learning ap-
proach.  Supporting pedagogical materials that 
teachers using these tools have developed allow 
learners to practice correcting sentence level er-
rors.  The materials are aimed particularly at in-
creasing the learners’ awareness of collocational 
restrictions and at encouraging them to look up 
collocational properties.  The materials have been 
integrated into EFL courses at several Hong Kong 
universities and secondary schools. 

 
 

Figure 11: Word Neighbors displays the patterns of  
‘demanded * more’. 

We have found that in institutional contexts 
where novice writers may have learned to rely 
completely on teacher feedback for correction, 
simply putting tools in students’ hands is not 
enough.  In the next section, we describe compan-
ion tools that enable teachers to prompt their stu-
dents to notice particular errors and reformulate 
their sentences without the teacher’s explicit cor-
rection. 

5 Resource-rich Feedback 

Teachers of academic written English face enor-
mous problems when they, rather than the learners 
themselves, bear the burden for improving the ac-
curacy and fluency of their students’ texts.  Teach-
ers are typically called upon to provide individual 
support to large numbers of students who are often 
at various levels of acquisition and who have a 
wide range of motivational drives and individual 
needs.  These quantitative demands, together with 
the complexity of understanding and reformulating 
the texts of novice writers, limit the effectiveness 
of any feedback a teacher can provide.  In addition, 
teachers often find themselves repeatedly identify-
ing and correcting errors that they have pointed out 
many times before.  This is especially discouraging 
when the errors reoccur in the same student’s texts.  

This was the impetus for the design of Mark My 
Words, a companion to the students’ version, 
Check My Words.  Like Check My Words, it in-
stalls as a toolbar in Microsoft Word (Figure 12).  
Teachers can use this tool to insert ‘resource rich’ 
comments in students’ texts (e.g., Milton, 2006).  
These comments include links to the resources 
available from the students’ Check My Words 
toolbar.  Students can be held accountable for re-
formulating their own texts using the same re-
sources they themselves have available during the 
writing process.  

The following steps illustrate the process a 
teacher might use when responding to a student’s 
text.  This procedure is ideally employed after the 
student has completed at least one draft and fol-
lowed a revision process similar to that outlined in 
the previous section.  Let’s assume that a student 
has submitted a text containing the error illustrated 
previously (‘It worth studying.’).  

Teachers have a variety of options in comment-
ing on a text, depending on how explicit they want 
to be.  When the teacher wants to bring an error to 

38



 
 

the student’s attention, the teacher puts the cursor 
on the word or highlights a phrase and clicks a 
Mark button.  The program attempts to identify the 
error based on simple heuristics (e.g., identifying 
the POS and any pattern that matches a mal-rule), 
and dialogues such as the following one presented 
in figure 13 are available. 

The ‘Topic’ and ‘Hint’ text boxes contain boi-
lerplate comments that the teacher customizes as 
desired.  The teacher can accept the default sugges-
tions or select a resource or search engine and set 
parameters to display the Standard English lexical 
pattern.  The English Grammar Guide link, online 
dictionary, and Word Neighbors are selected in this 
example.  These links then appear in the student’s 
text.  These links reinforce the student’s familiarity 
with the resources, encouraging students to use the 
resources to revise their texts. 

The student has only to ‘mouse over’ the 
teacher’s initials to see each ‘resource rich’ com-
ment, and can click to open the resource.  In the 
example illustrated in Figure 14, three resources 
are available: usage explanations (the ‘Click here 
for more advice and practice’ link points to the 
relevant page of the online English Grammar 
Guide), definitions (Cambridge Dictionary), and 
collocational patterns (Word Neighbors). 

Teachers can comment on repeated errors of the 
same type by clicking a ‘Copy Comment’ button, 
although usually it is not necessary (nor advisable) 
to highlight every error.  Current feedback peda-
gogy suggests that, rather than highlighting all er-
rors, it is more effective to draw students’ attention 
to a subset of errors.  In addition to comments cov-
ering the most distracting and disruptive types of 
sentence level errors, the Mark My Words program 
lists many other comments covering formatting, 
organization, style, content, and logic.  Teachers 
can easily add more comments, and customize and 
associate these with any concept or pattern in a 
student’s text, and these in turn with any online 
resources.  By having students concentrate on 
structures and lexis that are particularly difficult 
for each individual, we can more reasonably expect 
L2 novice writers to learn to identify and revise 
these problems themselves.  

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 13: dialogue boxes that allow teachers to custom-
ize comments. 
 
 
 

 

 

 

 
 
 
 
The Mark My Words program retains a database 

of comments made on previous assignments so that 
a teacher knows whether a student has had atten-
tion drawn to particular lexical and structural prob-
lems.  At the bottom of each text, teachers can 
generate a ‘Comments Table’ that summarizes the 
comments (Figure 15).  This allows teachers to 
maintain a record of comments given to particular 
students.  These comments and error logs are per-
manently available for students and teachers to 
refer to as prompts for each subsequent draft and 
revision. 

Figure 14: a comment from Mark My Words. 

 
Figure 12: The Mark My Words toolbar for tutors of English. 

39



 
 

This procedure does not necessarily replace 
classroom instruction or individual consultation.  
However, by encouraging EFL learners to use such 
resources, and demonstrating their usefulness 
through instruction and as part of the feedback 
process, we can equip learners to proofread for 
themselves, and help them assume responsibility 
for becoming independent writers. 

 

 
Figure 15: a summary of comments from Mark My 
Words. 

6 Implementation and Assessment 

The tools and techniques described above have 
been designed with the needs of intermediate and 
advanced EFL learners in mind—especially Chi-
nese-speaking secondary and tertiary students.  
This approach meets many of the requirements laid 
out for corpus-based language learning tools (e.g., 
Ghadessy et al, 2001 and Romer, 2006).  Other 
work in this area (e.g., Gaskell and Cobb, 2004) 
has illustrated the promise that such methods have 
for enabling teachers to guide students in accessing 
and understanding the discrepancy between their 
language patterns and those of Standard English. 

The programs have been integrated into EFL 
courses at several Hong Kong universities and sec-
ondary schools and continue to undergo refine-
ments based on user feedback.  A comprehensive 
evaluation of students’ and teachers’ reactions to 
the programs emphasizes the need for training and 
pedagogical materials that support teachers and 
students: a number of genre-specific writing sylla-
buses (e.g., lab-report writing) are being built 
around the use of the programs. 

Although our main aim is not to identify all er-
rors or prescribe correction, the ability of the 
Check My Words program to identify the lexico-
grammatical errors of a specific cohort of L2 writ-
ers (Chinese speakers of English) is steadily im-

proving.  We maintain an ‘Assignment 
Management System’, through which students and 
teachers exchange electronic documents.  This sys-
tem enables us to collect user-generated knowledge 
in the form of common errors in the L2 writing of 
this cohort of users, as well as errors tagged by 
their language teachers.  Students who use the 
Check My Words program currently submit ap-
proximately 1 million words per month, and teach-
ers tag about 15,000 errors in these texts monthly, 
using the Mark My Words program.  We are able 
to mine these texts for mal-rules and for the usage 
marked by their teachers, and we can use the cor-
pus as an iterative test bed for error checking.  

A quantitative analysis of about a million words 
of the re-drafted texts of students who have used 
the program, and another million words of those 
who did not use the program during composition 
show significant improvements in accuracy and 
fluency of those who used the program.  Students 
who follow this process tend to use a wider range 
of language formulae and, as well as gaining con-
fidence in using the tools to check lexis and struc-
tures, they more successfully attempt grammatical 
structures normally avoided in the novice L2 writ-
ing of speakers of Chinese (such as modality and 
subordination).  In surveys, the L2 novice writers 
report that they find the programs ‘very useful’.  
Teachers report that students who used the pro-
gram as a proofreading aid were able to self-
correct more reliably than students who did not use 
the program.  

However, although the technical infrastructure 
of Hong Kong schools and universities can easily 
accommodate these programs (students and teach-
ers generally have access to good computer facili-
ties), the adoption of this method of feedback by 
teachers has been slow.  Examination-driven teach-
ing practices emphasize teacher-centered methods, 
and teachers have little incentive to encourage stu-
dents in independent learning and discovery-based 
writing.  Nevertheless, most teachers who try this 
method quickly become proficient and embrace it, 
recognizing that it can help transfer the burden for 
proofreading to their students.  They appreciate 
being able to customize and share comments, and 
avoid explicit correction, while still assisting stu-
dents and holding them accountable for conveying 
meaning in an acceptable manner and in their own 
words. 

40



 
 

7 Conclusion 

The programs described in this paper demonstrate 
techniques that can help L2 writers acquire accu-
racy and fluency in written English and develop 
life-long writing habits in the L2.  The approach 
takes advantage of online resources to help stu-
dents and teachers shift from a machine- or 
teacher-centered pedagogy to one that puts the L2 
writer at the center of the writing process by mak-
ing the learner accountable, and ultimately more 
confident and independent.  The Check My Words 
and Mark My Words programs described in this 
paper are available from http://mywords.ust.hk/. 

References 
E. M. Bender. 2009. Linguistically Naïve!=Language 

Independent: Why NLP Needs Linguistic Typology. 
Proceedings of the EACL 2009 Workshop on the In-
teraction between Linguistics and Computational 
Linguistics: Virtuous, Vicious or Vacuous? Athens, 
Greece, 26–32. 

P. Bolt. 1992. An evaluation of grammar-checking pro-
grams as self-help learning aids for learners of Eng-
lish as a foreign language. Computer Assisted 
Learning, 5(1–2):49–9. 

C. Chapelle. 2001. Computer Applications in Second 
Language Acquisition: Foundations for Teaching, 
Testing, and Research. Cambridge, UK: Cambridge 
University Press.   

J. F. Chen. 1997. Computer generated error feedback 
and the writing process. TESL-EJ Teaching English 
as a second Foreign Language, 2(3). 

M. Chodorow, J. Tetreault, and N.-R. Han. 2007. Detec-
tion of grammatical errors involving prepositions. 
Proceedings of the Fourth ACL-SIGSEM Workshop 
on Prepositions, Prague, Czech Republic: Associa-
tion for Computational Linguistics, 25–30. 

D. N. Dobrin. 1985. Style analyzers once more. Com-
puters and Composition, 3:22–32. 

D. Ferris. and J. S. Hedgcock. 2005. Teaching ESL 
Composition: Purpose, Process, and Practice (2nd 
ed.) Mahwah: Lawrence Erlbaum Associates. 

J. Foster. and J. Vogel. 2004. Parsing Ill-Formed Text 
Using an Error Grammar. Artificial Intelligence Re-
view, 21(3-4):269–291. 

L. T. Frase, N. H. Macdonald, P. S. Gingrich, S. A. 
Keenan and J. L. Collymore, 1981. Computer aids 
for text assessment and writing instruction, NSPI 
Journal, 21. 

D. Gaskell, and T. Cobb. 2004. Can learners use con-
cordance feedback for writing errors? System, 32(3): 
301–319. 

M. Ghadessy, A. Henry, and R. Roseberry, (eds.). 2001. 
Small Corpus Studies and ELT: Theory and Practice, 
John Benjamins. 

R. Garside, and N. Smith. 1997. A hybrid grammatical 
tagger: CLAWS4, In R. Garside, G. Leech and A. 
McEnery. (eds.) Corpus Annotation: Linguistic In-
formation from Computer Text Corpora. Longman, 
London, 102–121. 

T. McGee and P. Ericsson. 2002. The Politics of the 
Program: MS Word as the Invisible Grammarian, 
Computers and Composition, 19:453–470. 

J. Milton. 2001. Elements of a Written Interlanguage: a 
computational and corpus-based study of institu-
tional influences on the acquisition of English by 
Hong Kong Chinese students. HKUST, Hong Kong. 

J. Milton. 2006. Resource-Rich Web-Based Feedback: 
helping learners become independent writers, In Hy-
land, K. and Hyland F. (eds.) Feedback in Second 
Language Writing: Contexts and Issues, Cambridge 
University Press, 123–137. 

M. C. Pennington. 1992. Beyond off-the-shelf computer 
remedies for student writers: Alternatives to canned 
feedback. System, 20(4):423–447. 

D. Schneider. and K. F. McCoy. 1998. Recognizing 
syntactic errors in the writing of second language 
learners. Proceedings of the 36th conference on As-
sociation for Computational Linguistics volume 2. 
Montreal, Quebec, Canada. 

M. Trahey. and L. White. 1993. Positive evidence and 
preemption in the L2 classroom. Studies in Second 
Language Acquisition, 15:181–204. 

J. Truscott. 1996. The case against grammar correction 
in L2 writing classes. Language Learning, 46(2): 
327-369. 

A. Vernon. 2000. Computerized grammar checkers 
2000: capabilities, limitations, and pedagogical pos-
sibilities. Computers and Composition, 17:329–349. 

B. Wampler. 2002. A computer scientist's lament: 
grammar has lost its technological edge. The New 
York Times.  

H. A. Witkin, C. Moore, D. Goodenough, and P. Cox. 
1977. Field Dependent and Field Independent Cogni-
tive Styles and their Educational Implications, Re-
view of Educational Research, 47:1–64. 

X. Yi, J. Gao and W. B. Dolan. 2008. A Web-based 
English Proofing System for English as a Second 
Language Users Proceedings of the Third Interna-
tional Joint Conference on Natural Language Proc-
essing volume 1. 

 

41


