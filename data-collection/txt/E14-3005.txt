



















































Expanding the Range of Automatic Emotion Detection in Microblogging Text


Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 38–44,
Gothenburg, Sweden, April 26-30 2014. c©2014 Association for Computational Linguistics

Expanding the Range of Automatic Emotion Detection in 

Microblogging Text 

 

 

Jasy Liew Suet Yan 

School of Information Studies 

Syracuse University 

Syracuse, New York, USA 

jliewsue@syr.edu 

 

  

 

Abstract 

Detecting emotions on microblogging sites such as 

Twitter is a subject of interest among researchers in 

behavioral studies investigating how people react to 

different events, topics, etc., as well as among users 

hoping to forge stronger and more meaningful 

connections with their audience through social media. 

However, existing automatic emotion detectors are 

limited to recognize only the basic emotions. I argue 

that the range of emotions that can be detected in 

microblogging text is richer than the basic emotions, 

and restricting automatic emotion detectors to identify 

only a small set of emotions limits their practicality in 

real world applications. Many complex emotions are 

ignored by current automatic emotion detectors 

because they are not programmed to seek out these 

“undefined” emotions. The first part of my 

investigation focuses on discovering the range of 

emotions people express on Twitter using manual 

content analysis, and the emotional cues associated 

with each emotion. I will then use the gold standard 

data developed from the first part of my investigation 

to inform the features to be extracted from text for 

machine learning, and identify the emotions that 

machine learning models are able to reliably detect 

from the range of emotions which humans can 

reliably detect in microblogging text. 

1 Introduction 

The popularity of microblogging sites such as 

Twitter provide us with a new source of data to 

study how people interact and communicate with 

their social networks or the public. Emotion is a 

subject of interest among researchers in 

behavioral studies investigating how people react 

to different events, topics, etc., as well as among 

users hoping to forge stronger and more 

meaningful connections with their audience 

through social media. There is growing interest 

among researchers to study how emotions on 

social media affect stock market trends (Bollen, 

Mao, & Zeng, 2011), relate to fluctuations in 

social and economic indicators (Bollen, Pepe, & 

Mao, 2011), serve as a measure for the 

population’s level of happiness (Dodds & 

Danforth, 2010), and provide situational 

awareness for both the authorities and the public 

in the event of disasters (Vo & Collier, 2013).  

In order to perform large-scale analysis of 

emotion phenomena and social behaviors on 

social media, there is a need to first identify the 

emotions that are expressed in text as the 

interactions on these platforms are dominantly 

text-based. With the surging amount of 

emotional content on social media platforms, it is 

an impossible task to detect the emotions that are 

expressed in each message using manual effort. 

Automatic emotion detectors have been 

developed to deal with this challenge. However, 

existing applications still rely on simple keyword 

spotting or lexicon-based methods due to the 

absence of sufficiently large emotion corpora for 

training and testing machine learning models 

38



(Bollen, Pepe, et al., 2011; Dodds & Danforth, 

2010).  

Research in using machine learning 

techniques to process emotion-laden text is 

gaining traction among sentiment analysis 

researchers, but existing automatic emotion 

detectors are restricted to identify only a small 

set of emotions, thus limiting their practicality 

for capturing the richer range of emotions 

expressed on social media platforms. The current 

state-of-the-art of simply adopting the basic 

emotions described in the psychology literature 

as emotion categories in text, as favored by a 

majority of scholars, is too limiting. Ekman’s six 

basic emotions (happiness, sadness, fear, anger, 

disgust, and surprise) (Ekman, 1971) are 

common emotion categories imposed on both 

humans and computers tasked to detect emotions 

in text (Alm, Roth, & Sproat, 2005; Aman & 

Szpakowicz, 2007; Liu, Lieberman, & Selker, 

2003). It is important to note that most basic 

emotions such as the six from Ekman are derived 

from facial expressions that can be universally 

recognized by humans. Verbal expressions of 

emotion are different from non-verbal 

expressions of emotion. Emotions expressed in 

text are richer than the categories suggested by 

the basic emotions. Also, people from different 

cultures use various cues to express a myriad of 

emotions in text. 

By using a restricted set of emotion 

categories, many emotions not included as part 

of the basic set are ignored or worse still, force-

fitted into one of the available emotion 

categories. This introduces a greater level of 

fuzziness in the text examples associated with 

each emotion.  

Example [1]: “My prayers go to family of Amb. 

Stevens & others affected by this tragedy. We 

must not allow the enemy to take another. 

http://t.co/X8xTzeE4” 

Example [1] is an obvious case of “sympathy” 

as the writer is expressing his or her condolences 

to people affected by a tragedy. If “sympathy” is 

not in the pre-defined list of emotion categories 

that humans can choose from, human annotators 

may label this instance as “sadness”, which is not 

entirely accurate. These inaccuracies will then be 

propagated into the automatic emotion detector. 

While the basic emotions have been 

established as universal emotions (Ekman, 

1999), their usefulness in emotion detection in 

text is still unclear. How useful are the six basic 

emotions in detecting consumers’ emotional 

reactions towards a product or service from 

microblogs? What if a company wishes to detect 

disappointment? The focus on only the basic 

emotions has resulted in a dearth of effort to 

build emotion detectors that are able to recognize 

a wider range of emotions, especially the 

complex ones. Complex emotions are not merely 

combinations of the basic ones. For example, 

none of the combinations of Ekman’s six basic 

emotions seem to represent “regret” or 

“empathy”. Without human-annotated examples 

of complex emotions, automatic emotion 

detectors remain ignorant of these emotions 

simply because they are not programmed to seek 

out these “undefined” emotions.    

There is a need to create automatic emotion 

detectors that can detect a richer range of 

emotions apart from the six basic emotions 

proposed by Ekman to deal with emotional 

content from social media platforms. A broader 

range of emotions will enable automatic emotion 

detectors to capture more fine-grained emotions 

that truly reflect actual human emotional 

experience. Limited research has been done so 

far to determine the full range of emotions which 

humans can reliably detect in text, as well as 

salient cues that can be used to identify distinct 

emotions in text. A crucial step to address this 

gap is to develop a gold standard corpus 

annotated with a richer set of emotions for 

machine learning models to learn from.   

My research goal is to first discover the range 

of emotions humans can reliably detect in 

microblogging text, and investigate specific cues 

humans rely on to detect each emotion. Is there a 

universal set of cues humans rely on to detect a 

particular emotion or do these cues differ across 

39



individuals? Using grounded theory, the first part 

of my investigation focuses on discovering the 

range of emotions from tweets collected from a 

popular microblogging site, Twitter, and the 

emotional cues associated with each emotion. 

Twitter offers a wealth of publicly available 

emotional content generated by a variety of users 

on numerous topics. The inherently social nature 

of interactions on Twitter also allows me to 

investigate social emotions apart from personal 

emotions. In the second part of my investigation, 

human annotations from the first part of my 

investigation will serve as gold standard data for 

machine learning experiments used to determine 

the emotions that automatic methods can reliably 

detect from the range of emotions that humans 

can reliably identify.     

2 Background 

Early research on automatic emotion detection in 

text is linked to subjectivity analysis (Wiebe, 

Wilson, Bruce, Bell, & Martin, 2004; Wiebe, 

Wilson, & Cardie, 2005). Emotion detection in 

text is essentially a form of sentiment 

classification task based on finer-grained 

emotion categories. Automatic emotion detection 

has been applied in the domain of emails (Liu et 

al., 2003), customer reviews (Rubin, Stanton, & 

Liddy, 2004), children’s stories (Alm et al., 

2005), blog posts (Aman & Szpakowicz, 2007), 

newspaper headlines (Strapparava & Mihalcea, 

2008), suicide notes (Pestian et al., 2012), and 

chat logs (Brooks et al., 2013). Early 

development of automatic emotion detectors 

focused only on the detection of Ekman’s six 

basic emotions: happiness, surprise, sadness, fear, 

disgust, and anger (Alm et al., 2005; Aman & 

Szpakowicz, 2007; Liu et al., 2003; Strapparava 

& Mihalcea, 2008). Plutchik’s model is an 

expansion of Ekman’s basic emotions through 

the addition of trust and anticipation in his eight 

basic emotions (Plutchik, 1962), while Izard’s 

ten basic emotions also include guilt and shame 

(Izard, 1971).  

 Scholars have only recently started to expand 

the categories for automatic emotion 

classification as noted in the 14 emotions that are 

pertinent in the domain of suicide notes (Pestian 

et al., 2012), and 13 top categories that are used 

for emotion classification out of 40 emotions that 

emerged from the scientific collaboration chat 

logs (Brooks et al., 2013; Scott et al., 2012). 

However, existing gold standard corpora are 

limited by the emotion categories that are most 

often specific to a particular domain. 

Furthermore, it is difficult to pinpoint the exact 

words, symbols or phrases serving as salient 

emotion indicators because existing gold 

standard data are manually annotated at the 

sentence or message level. 

 Using Twitter, scholars have explored 

different strategies to automatically harness large 

volumes of data automatically for emotion 

classification. Pak & Paroubek (2010) applied a 

method similar to Read (2005) to extract tweets 

containing happy emoticons to represent positive 

sentiment, and sad emoticons to represent 

negative sentiment. First, this limits the emotion 

classifier to detect only happiness and sadness. 

Second, the lack of clear distinctions between the 

concepts of sentiment and emotion is 

problematic because tweeters may express a 

negative emotion towards an entity which they 

hold a positive sentiment on, and vice versa. For 

example, a tweeter expressing sympathy to 

another person who has experienced an 

unfortunate event is expressing a negative 

emotion but the tweet contains an overall 

positive sentiment. Third, such a data collection 

method assumes that the emotion expressed in 

the text is the same as the emotion the emoticon 

represents, and does not take into account of 

cases where the emotion expressed in the text 

may not be in-sync with the emotion represented 

by the emoticon (e.g., sarcastic remarks).  

 Mohammad (2012) and Wang, Chen, 

Thirunarayan, & Sheth (2012) applied a slightly 

improved method to create a large corpus of 

readily-annotated tweets for emotion 

classification. Twitter allows the use of hashtags 

(words that begin with the # sign) as topic 

indicators. These scholars experimented with 

extracting tweets that contain a predefined list of 

40



emotion words appearing in the form of hashtags. 

Mohammad (2012) only extracted tweets with 

emotion hashtags corresponding to Ekman’s six 

basic emotions (#anger, #disgust, #fear, #joy, 

#sadness, and #surprise) while Wang et al. (2012) 

expanded the predefined hashtag list to include 

emotion words associated with an emotion 

category, as well as the lexical variants of these 

emotion words. Although this method allows 

researchers to take advantage of the huge amount 

of data available on Twitter to train machine 

learning models, little is known about the 

specific emotional cues that are associated with 

these emotion categories. Also, this data 

collection method is biased towards tweeters 

who choose to express their emotions explicitly 

in tweets. 

 Kim, Bak, & Oh (2012) proposed a semi-

supervised method using unannotated data for 

emotion classification. They first applied Latent 

Dirichlet Allocation (LDA) to discover topics 

from tweets, and then determined emotions from 

the discovered topics by calculating the 

pointwise mutual information (PMI) score for 

each emotion from a list of eight emotions given 

a topic. The evaluation of this method using a 

corpus of manually annotated tweets revealed 

that this automatic emotion detector only 

managed to correctly classify 30% of tweets 

from the test dataset. The gold standard corpus 

used for evaluation was developed through 

manual annotations using Amazon Mechanical 

Turk (AMT). Only 3% of the tweets received full 

agreement among five annotators. 

3 Defining Emotions In Text 

In everyday language, people refer to emotion as 

prototypes of common emotions such as 

happiness, sadness, and anger (Fehr & Russell, 

1984). In the scientific realm, emotion is 

generally defined as “ongoing states of mind that 

are marked by mental, bodily or behavioral 

symptoms” (Parrott, 2001). Specifically, each 

emotion category (e.g., happiness, sadness, anger, 

etc.) is distinguishable by a set of mental, bodily 

or behavioral symptoms. When a person 

expresses emotion in text, these symptoms are 

encoded in written language (words, phrases and 

sentences). 

Emotion in text is conceptualized as emotion 

expressed by the writer of the text. Emotion 

expression consists of “signs that people give in 

various emotional states”, usually with the 

intention to be potentially perceived or 

understood by the others (Cowie, 2009). People 

express their emotional states through different 

non-verbal (e.g., facial expression, vocal 

intonation, and gestures) and verbal (e.g., text, 

spoken words) manifestations. Emotion 

expression in text is a writer’s descriptions of his 

or her emotional experiences or feelings. It is 

important to note that emotion expression only 

provides a window into a person’s emotional 

state depending on what he or she chooses to 

reveal to the others. It may not be depictions of a 

person’s actual emotional state, which is a 

limitation to the study of emotion in text (Calvo 

& D’Mello, 2010). 

4 Research Questions 

Detecting emotions in microblog posts poses 

new challenges to existing automatic emotion 

detectors due to reasons described below: 

 Unlike traditional texts, tweets consist of 

short texts expressed within the limit of 

140 characters, thus the language used to 

express emotions differs from longer 

texts (e.g., blogs, news, and fairy tales). 

 The language tweeters use is typically 

informal. Automatic emotion detectors 

must be able to deal with the presence of 

abbreviations, acronyms, orthographic 

elements, and misspellings. 

 Emotional cues are not limited to only 

emotion words. Twitter features such as 

#hashtags (topics), @username, retweets, 

and other user profile metadata may 

serve as emotional cues. 

Using data from Twitter, a popular 

microblogging platform, I will develop an initial 

framework to study the richness of emotions 

41



expressed for personal, as well as for social 

purposes. My research investigation is guided by 

the research questions listed below:  

 What emotions can humans reliably 

detect in microblogging text? 

 What salient cues are associated with 

each emotion? 

 How can good features for machine 

learning be identified from the salient 

cues humans associate with each emotion? 

 What emotions in microblogging text can 

be reliably detected using current 

machine learning techniques? 

5 Proposed Methodology 

My research design consists of three phases: 1) 

small-scale inductive content analysis for code 

book development, 2) large-scale deductive 

content analysis for gold standard data 

development, and 3) the design of machine 

learning experiments for automatic emotion 

detection in text. 

5.1 Data Collection 

When sampling for tweets from Twitter, I will 

utilize three sampling strategies to ensure the 

variability of emotions being studied. First, I will 

collect a random sample of publicly-available 

tweets. This sampling strategy aims to create a 

sample that is representative of the population on 

Twitter but may not produce a collection of 

tweets with sufficient emotional content. The 

second sampling strategy is based on topics or 

events. To ensure that tweets are relevant to this 

investigation, tweets will be sampled based on 

hashtags of events likely to evoke text with 

emotional content. Topics will include politics, 

sports, products/services, festive celebrations, 

and disasters.  

The third sampling strategy is based on users. 

This sampling strategy allows me to explore the 

range of emotions expressed by different 

individuals based on different stimuli, and not 

biased towards any specific events. To make the 

manual annotation feasible, I plan to first identify 

the usernames of 1) active tweeters with a large 

number of followers (e.g., tweets from 

politicians) to ensure sufficient data for analysis, 

and 2) random tweeters to represent “average” 

users of Twitter. I acknowledge that this 

sampling strategy may be limited to only certain 

groups of people, and may not be representative 

of all Twitter users but it offers a good start to 

exploring the range of emotions being expressed 

in individual streams of tweets.  

5.2 Phase 1 

To develop a coding scheme for emotion 

annotation, I will first randomly sample 1,000 

tweets each from the random, topic-based, and 

user-based datasets for open coding. I will work 

with a small group of coders to identify the 

emotion categories from a subset of the 1,000 

tweets. Coders will be given instructions to 

assign each tweet with only one emotion label 

(i.e., the best emotion tag to describe the overall 

emotion expressed by the writer in a tweet), 

highlight the specific cues associated with the 

emotion, as well as identify the valence and 

intensity of the emotion expressed in the tweet.  

To verify the grouping of the emotion tags, 

coders will be asked to perform a card sorting 

exercise to group emotion tags that are 

semantically similar in the same group. Based on 

the discovered emotion categories, nuanced 

colorations within each category may be detected 

from the valence and intensity codes.  

Coders will incrementally annotate more 

tweets (300 tweets per round) until a point of 

saturation is reached, where new emotion 

categories stop emerging from data. I will 

continuously meet with the coders to discuss 

disagreements until the expected inter-annotator 

agreement threshold for the final set of emotion 

categories is achieved.   

5.3 Phase 2 

Using the coding scheme developed from Phase 

1, I will obtain a larger set of manual annotations 

using Amazon Mechanical Turk (AMT). AMT 

allows me to collect manual annotations of 

42



emotions on a large-scale, thus enabling me to 

investigate if there are any differences as to what 

a larger crowd of people identify as emotion cues 

in tweets. Each tweet will be annotated by at 

least three coders. To ensure the quality of the 

manual annotations collected from AMT, 

workers on AMT will have to undergo a short 

training module explaining the coding scheme, 

and will have to pass a verification test before 

being presented with the actual tweets to be 

annotated. Inter-annotator agreement will be 

calculated, and the emotion categories that 

humans can reliably detect in text will be 

identified.  

5.4 Phase 3 

Detecting a single emotion label for each tweet 

can be defined as a multi-class classification 

problem. The corpus from Phase 2 will be used 

as training data, and the corpus from Phase 1 will 

be used as testing data for the machine learning 

model. An analysis of the emotional cues from 

Phase 1 and Phase 2 datasets is conducted to 

identify salient features to be used for machine 

learning. Support vector machines (SVM) have 

been shown to perform well in this problem 

space (Alm et al., 2005; Aman & Szpakowicz, 

2007; Brooks et al., 2013; Cherry, Mohammad, 

& de Bruijn, 2012) so I will run experiments 

using SVM, and compare the performance of the 

model against a baseline using simple lexical 

features (i.e., n-grams). 

6 Research Contributions 

Analyzing the emotional contents in tweets 

can expand the theoretical understanding of the 

range of emotions humans express on social 

media platforms like Twitter. From a natural 

language processing standpoint, it is also crucial 

for the community to gain clearer insights on the 

cues associated with each fine-grained emotion. 

On top of that, findings from the machine 

learning experiments will inform the community 

as to whether training the machine learning 

models based on data collected using usernames, 

instead of topic hashtags will reduce noise in the 

data, and improve the performance of automatic 

emotion detection in microblogging texts.  

The expected contributions of this research 

investigation are three-fold: 1) the construction 

of an emotion taxonomy and detailed annotation 

scheme that could provide a useful starting point 

for future research, 2) the creation of machine 

learning models that can detect a wider range of 

emotions in text in order to enable researchers to 

tap into this wealth of information provided by 

Twitter to study a greater multitude of behavioral 

and social phenomenon, and 3) findings on the 

range of emotions people express on Twitter can 

potentially help inform the design of social 

network platforms to be more emotion sensitive. 

References  

Alm, C. O., Roth, D., & Sproat, R. (2005). Emotions 

from text: Machine learning for text-based 

emotion prediction. In Proceedings of the 

Conference on Human Language Technology 

and Empirical Methods in Natural Language 

Processing (pp. 579–586). Stroudsburg, PA, 

USA. 

Aman, S., & Szpakowicz, S. (2007). Identifying 

expressions of emotion in text. In Text, 

Speech and Dialogue (pp. 196–205).  

Bollen, J., Mao, H., & Zeng, X. (2011). Twitter mood 

predicts the stock market. Journal of 

Computational Science, 2(1), 1–8.  

Bollen, J., Pepe, A., & Mao, H. (2011). Modeling 

public mood and emotion: Twitter sentiment 

and socio-economic phenomena. In 

Proceedings of the Fifth International AAAI 

Conference on Weblogs and Social Media 

(pp. 450–453).  

Brooks, M., Kuksenok, K., Torkildson, M. K., Perry, 

D., Robinson, J. J., Scott, T. J., … Aragon, 

C. R. (2013). Statistical affect detection in 

collaborative chat. Presented at the 

Conference on Computer Supported 

Cooperative Work and Social Computing, 

San Antonio, TX.  

Calvo, R. A., & D’Mello, S. (2010). Affect detection: 

An interdisciplinary review of models, 

methods, and their applications. IEEE 

Transactions on Affective Computing, 1(1), 

18–37.  

Cherry, C., Mohammad, S. M., & de Bruijn, B. 

(2012). Binary classifiers and latent sequence 

43



models for emotion detection in suicide 

notes. Biomedical Informatics Insights, 5, 

147–154.  

Cowie, R. (2009). Perceiving emotion: Towards a 

realistic understanding of the task. 

Philosophical Transactions of the Royal 

Society of London B: Biological Sciences, 

364(1535), 3515–3525.  

Dodds, P. S., & Danforth, C. M. (2010). Measuring 

the happiness of large-scale written 

expression: Songs, blogs, and Presidents. 

Journal of Happiness Studies, 11(4), 441–

456.  

Ekman, P. (1971). Universals and cultural differences 

in facial expressions of emotion. Nebraska 

Symposium on Motivation, 19, 207–283. 

Ekman, P. (1999). Basic emotions. In Handbook of 

Cognition and Emotion (pp. 45–60). John 

Wiley & Sons, Ltd.  

Fehr, B., & Russell, J. A. (1984). Concept of emotion 

viewed from a prototype perspective. 

Journal of Experimental Psychology: 

General, 113(3), 464–486.  

Izard, C. E. (1971). The face of emotion (Vol. xii). 

East Norwalk,  CT,  US: Appleton-Century-

Crofts. 

Kim, S., Bak, J., & Oh, A. H. (2012). Do you feel 

what I feel? Social aspects of emotions in 

Twitter conversations. In International AAAI 

Conference on Weblogs and Social Media 

(ICWSM).  

Liu, H., Lieberman, H., & Selker, T. (2003). A model 

of textual affect sensing using real-world 

knowledge. In Proceedings of the 8th 

International Conference on Intelligent User 

Interfaces (pp. 125–132). 

Mohammad, S. M. (2012). #Emotional tweets. In 

Proceedings of the First Joint Conference on 

Lexical and Computational Semantics. 

Montreal, QC. 

Pak, A., & Paroubek, P. (2010). Twitter as a corpus 

for sentiment analysis and opinion mining. In 

Seventh International Conference on 

Language Resources and Evaluation 

(LREC).  

Parrott, W. G. (2001). Emotions in social psychology:  

Essential readings (Vol. xiv). New York,  

NY,  US: Psychology Press. 

Pestian, J. P., Matykiewicz, P., Linn-Gust, M., South, 

B., Uzuner, O., Wiebe, J., … Brew, C. 

(2012). Sentiment analysis of suicide notes: 

A shared task. Biomedical Informatics 

Insights, 5(Suppl. 1), 3–16.  

Plutchik, R. (1962). The Emotions: Facts, theories, 

and a new model. New York: Random 

House. 

Read, J. (2005). Using emoticons to reduce 

dependency in machine learning techniques 

for sentiment classification. In Proceedings 

of the ACL Student Research Workshop (pp. 

43–48). Stroudsburg, PA, USA. 

Rubin, V. L., Stanton, J. M., & Liddy, E. D. (2004). 

Discerning emotions in texts. In The AAAI 

Symposium on Exploring Attitude and Affect 

in Text (AAAI-EAAT).  

Scott, T. J., Kuksenok, K., Perry, D., Brooks, M., 

Anicello, O., & Aragon, C. (2012). Adapting 

grounded theory to construct a taxonomy of 

affect in collaborative online chat. In 

Proceedings of the 30th ACM International 

Conference on Design of Communication 

(pp. 197–204). New York, USA. 

Strapparava, C., & Mihalcea, R. (2008). Learning to 

identify emotions in text. In Proceedings of 

the 2008 ACM Symposium on Applied 

Computing (pp. 1556–1560). New York, 

USA. 

Vo, B.-K. H., & Collier, N. (2013). Twitter emotion 

analysis in earthquake situations. 

International Journal of Computational 

Linguistics and Applications, 4(1), 159–173. 

Wang, W., Chen, L., Thirunarayan, K., & Sheth, A. P. 

(2012). Harnessing Twitter “big data” for 

automatic emotion identification. In 2012 

International Conference on Privacy, 

Security, Risk and Trust (PASSAT), and 2012 

International Conference on Social 

Computing (SocialCom) (pp. 587–592).  

Wiebe, J. M., Wilson, T., Bruce, R., Bell, M., & 

Martin, M. (2004). Learning subjective 

language. Computational Linguistics, 30(3), 

277–308.  

Wiebe, J. M., Wilson, T., & Cardie, C. (2005). 

Annotating expressions of opinions and 

emotions in language. Language Resources 

and Evaluation, 39(2-3), 165–210.  

 

44


