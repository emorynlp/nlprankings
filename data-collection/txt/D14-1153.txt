



















































Intrinsic Plagiarism Detection using N-gram Classes


Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1459‚Äì1464,
October 25-29, 2014, Doha, Qatar. c¬©2014 Association for Computational Linguistics

Intrinsic Plagiarism Detection using N-gram Classes 

 

 

Imene Bensalem 

MISC Lab  

Constantine 2 University,  

Algeria 

 

bens.imene@gmail.com 

Paolo Rosso 

NLE Lab  

PRHLT Research Center  

Universitat Polit√®cnica de 

Val√®ncia, Spain 

prosso@dsic.upv.es 

Salim Chikhi 

MISC Lab 

Constantine 2 University, 

Algeria 

 

slchikhi@yahoo.com 

 

  

 

Abstract 

When it is not possible to compare the suspi-

cious document to the source document(s) 

plagiarism has been committed from, the evi-

dence of plagiarism has to be looked for in-

trinsically in the document itself. In this pa-

per, we introduce a novel language-

independent intrinsic plagiarism detection 

method which is based on a new text repre-

sentation that we called n-gram classes. The 

proposed method was evaluated on three pub-

licly available standard corpora. The obtained 

results are comparable to the ones obtained 

by the best state-of-the-art methods. 

1 Introduction and Related Works 

Intrinsic plagiarism detection is an essential 

alternative in situations where the plagiarism 

source does not have a digital version, e.g. an old 

book, or the plagiarized text was directly written 

by another author without copying from any 

source, e.g. the case of a student who asked 

someone else to write for him parts of his essay 

or thesis. Hence, the task of detecting plagiarism 

intrinsically is to identify, in the given suspicious 

document, the fragments that are not consistent 

with the rest of the text in terms of writing style.  

The automatic analysis of the writing style is 

an important component of many NLP applica-

tions. For some of them, when analyzing the 

style, a document is considered as a whole, 

which is the case of the authorship identification 

(Stamatatos, 2009a) and the authorship verifica-

tion (Koppel and Seidman, 2013). For other ap-

plications, a document is perceived as a set of 

fragments, for each of them the writing style 

needs to be analyzed individually. Examples of 

such applications include: paragraph authorship 

clustering (Brooke and Hirst, 2012), authorial 

segmentation of multi-author documents (Akiva 

and Koppel, 2013), detection of stylistic incon-

sistencies between consecutive paragraphs 

(Graham et al., 2005) and plagiarism direction 

identification (Grozea and Popescu, 2010). 

For intrinsic plagiarism detection, it is crucial 

to analyze the writing style at fragments level. 

However, the majority of methods tend to ana-

lyze the whole document writing style as well. 

Indeed, intrinsic plagiarism detection puts to-

gether, in one research problem, many difficul-

ties that are not present, or present separately, in 

the aforementioned related problems.  Its main 

difficulties are listed below. 

In contrast to multi-author documents related 

problems, the number of authors in the suspi-

cious documents is unknown, i.e., it might be one 

author if the document is plagiarism-free or 

many unknown authors if it contains plagiarism.  

Unlike the authorship attribution and verifica-

tion, where the examined text and the potential 

author text are separate (and hence their writing 

styles could be readily characterized and com-

pared), these two parts are both merged in the 

same document with unknown boundaries. Fur-

thermore, the plagiarized fragments in a suspi-

cious document might stem from different au-

thors, which renders the computational characte-

rization of plagiarism difficult.  

As opposed to the problem of authorship clus-

tering, where the task is merely to attribute al-

ready defined fragments of a given document to 

different authors, the segmentation is a crucial 

and inevitable task in a real scenario of intrinsic 

plagiarism detection. Indeed, a granular segmen-

tation may lead to an undependable style analy-

sis, and a coarse segmentation may prevent the 

identification of the short plagiarized texts. 

Due to the aforementioned difficulties, intrin-

sic plagiarism detection is still a challenging 

1459



problem. This is evidenced by the still low per-

formance scores of the majority of methods
1
. To 

the best of our knowledge, just two methods, 

namely Stamatatos (2009b) and Oberreuter et al. 

(2011), reached an f-measure greater than 0.30 

on a standardized corpus. Other methods, for 

instance (Stein et al., 2011) and (Tschuggnall 

and Specht, 2013), obtained better performance 

scores. Nonetheless, they have been evaluated on 

only selected documents from the whole standar-

dized evaluation corpus which makes their re-

sults not comparable to the others.  

Although the writing style analysis is an old 

research area and has been applied successfully 

to solve many problems, notably authorship at-

tribution, it is obvious that its application to iden-

tify the plagiarized fragments still needs to be 

investigated further. In this paper, we address 

this research problem by proposing a novel way 

of quantifying the writing style that we called n-

gram classes. We show that our method, which is 

supervised classification-based, is able to discri-

minate between the plagiarized and the original 

text fragments with a performance comparable to 

the best state-of-the-art methods despite it uses a 

small number of features when building the clas-

sification model.  

The remainder of the paper is organized as fol-

lows. Section 2 presents our motivation. Sections 

3 and 4 present the new features and the pro-

posed method. Section 5 provides the evaluation 

results. Finally, Section 6 draws our conclusions. 

2 Motivation 

The idea of our method is inspired by the work 

of Grozea and Popescu (2010), in the context of 

plagiarism direction identification. They reported 

that the character 8-grams of a plagiarized text 

fragment are more frequent in the source docu-

ment (because the author is the same) than in the 

plagiarized document. Thus, we believe that, it is 

possible to distinguish the plagiarized fragments 

from the original ones on the basis of the fre-

quency of their character n-grams in the suspi-

cious document. That is, if many of the character 

n-grams of a fragment are infrequent in the doc-

ument, it would be probably a plagiarized frag-

ment. However, if many of them are frequent, 

then the fragment is likely to be original. 

On the other hand, according to the authorship 

attribution researches, character n-grams are a 

                                                 
1 See for instance PAN workshop (http://pan.webis.de) se-

ries, from 2007 to 2012, where several papers on intrinsic 

plagiarism detection have been published.  

powerful tool for characterizing the writing style 

(Stamatatos, 2009a). Moreover, they have been 

used in one of the best intrinsic plagiarism detec-

tion methods (Stamatatos, 2009b).  

Generally, in n-gram based methods the text is 

represented by a vector of n-grams with their 

frequencies. The shortcoming of this text repre-

sentation is the increase of its size with the in-

crease of the text or the n-gram length.  

Our method proposes a novel way of using 

character n-grams
2
 for text representation. The 

idea is to represent the fragments of the suspi-

cious document in a reduced vector where each 

feature value is the frequency of a class of n-

grams instead of a particular n-gram. Therefore, 

the dimension of any fragment vector is always 

equal to the number of classes rather than the 

number of n-grams. The class of an n-gram is 

determined according to its frequency level in 

the given document as we will show in the next 

section. 

3 N-gram  Classes 

Formally, we define an n-gram class as a 

number from 0 to m‚àí1 such that the class labeled 

0 involves the least frequent n-grams and the 

class labeled m‚àí1 contains the most frequent n-

grams in a document. If m > 2, classes between 0 

and m‚àí1 will contain n-grams with intermediate 

frequency levels.  

Concretely, to assign the n-grams of a given 

document to m classes, first, the document is 

represented by a 2 √ó l matrix (l is the total num-

ber of n-grams), where the first row contains the 

n-grams ngi (i =1..l) and the second one contains 

their number of occurrences freqi (raw frequen-

cy). 

Let max_freq denotes the maximum frequen-

cy, so:  

max_freq = argmax   freqi ;    i=1..l (1) 

 

Then, the class of a n-gram ngi is computed as 

follows:  

 Class ngi = Log base (freq i);           (2) 

Given that: 

base =   ùëöùëéùë•_ùëìùëüùëíùëû
ùëö‚àí1

   .               (3) 

 

By computing the base of the logarithm as 

shown in the equation (3), the most frequent n-

grams (i.e. the n-grams with the maximum num-

ber of occurrences) will be in the class m‚àí1, and 

                                                 
2 In the rest of the paper, when not said differently, the term 

n-gram is always used to denote character n-gram. 

1460



the least frequent n-grams (e.g. the ones that ap-

pear only once) will be in the class 0, and the n-

grams with intermediate levels of frequency will 

be in the classes between 0 and m‚àí1. Figure 1 

illustrates an example of computing the n-gram 

classes of a document. The chosen number of 

classes m in this example is 3.  

Figure 1. Steps for computing the n-gram classes 

of a document. The number of classes in this ex-

ample is 3 (class labels are from 0 to 2). 

Note that, what we explained above is solely 

how to compute the class of each n-gram of a 

document. However, our purpose is to represent 

the document fragments using these classes. To 

this end, for each fragment, first, its n-grams are 

extracted. Then, each n-gram is replaced by its 

class obtained from the document model built 

previously. Finally, the proportion of each class 

in the fragment is computed. So, the fragment  

can be represented by a vector of m values, 

where the first value is the proportion of the class 

0, the second value is the proportion of the class 

1 and so on.  Figure 2 illustrates these steps. For 

the sake of simplicity, we suppose that the frag-

ment contains only 5 n-grams. 

Figure 2. Steps for representing a document 

fragment by the proportion of 3 n-gram classes. 

4 The Proposed Method 

Once the suspicious document has been seg-

mented to fragments and these latter have been 

represented by a set of features, an important 

phase in the process of the intrinsic plagiarism 

detection is to decide whether a fragment is pla-

giarized or original. This phase  has been imple-

mented in the literature methods using different 

techniques, notably clustering (Akiva, 2011), 

supervised classification (Meyer zu Eissen et al., 

2007), distance functions with thresholds 

(Stamatatos, 2009b; Oberreuter et al., 2011) and 

density-based methods (Stein et al., 2011). 

In our supervised method, the classification 

model is trained with a small number of features 

which are the proportions of the n-gram classes 

described in the previous section.  

In detail, our method is composed of the fol-

lowing steps: 

1. Segment each document d into fragments si by 
using the sliding window technique.  Let S de-

notes the set of these fragments.  

2. Build the n-gram class document model (see 
Figure 1) without considering numerals.  We 

choose to consider the frequency of a n-gram 

ngi as the number of its occurrence in d such 

that it is counted once per fragment. Therefore, 

the minimum value that could take a frequency 

is 1 if ngi appears only in one fragment, and its 

maximum value is |S| (the number of fragments 

in d) if ngi occurs in each fragment si ‚àà S.  
3. Represent each fragment si by a vector of m 

features fj , j ‚àà {0,‚Ä¶, m‚àí1}. So that, each fj is 
the proportion of the n-grams that belong to the 

class labeled j to the total number of n-grams in si.  

4. Combine into one dataset the fragment vectors 
obtained from all the training corpus docu-

ments. Then, label each vector with its authen-

ticity state, i.e. plagiarized, if the fragment pla-

giarism percentage exceeds 50% and original 

otherwise. 

5. Build a classifier using the training set pro-
duced in the previous step. For this purpose, we 

trained and tested several classification algo-

rithms implemented on  WEKA software (Hall 

et al., 2009). The best results were obtained 

with the Na√Øve Bayes algorithm
3
. 

The aforementioned steps represent the train-

ing phase of our method, which aims to construct 

the classifier. In practice, in order to detect the 

plagiarism in a given document, this classifier is 

                                                 
3 Consult the arff file from the archive file associated to this 

paper which contains the fragments class proportion model 

and the plagiarism prediction for each fragment.  

1461



directly applied to the document fragments after 

the step 3. 

5 Evaluation 

5.1 Datasets 

We evaluated our method on 3 corpora: PAN-

PC-09
4
 and PAN-PC-11

5
 which are the corpora 

used in the international competition of plagiar-

ism detection in 2009 and 2011 respectively
6
, as 

well as InAra corpus
7
, which is a publicly availa-

ble collection of artificial suspicious documents 

in Arabic (Bensalem et al., 2013).  The three 

document collections include XML annotations 

indicating the plagiarized segments positions.   

For the evaluation on English and Spanish 

documents, the classifier has been trained on 

PAN-PC-11 test corpus and evaluated on this 

same corpus using 10-fold cross validation as 

well as PAN-PC-09 test corpus. For the evalua-

tion on Arabic documents, the classifier has been 

trained and tested on InAra corpus using 10-fold 

cross validation.  

5.2 Results  

As evaluation measures we used macro-

averaged precision, recall, f-measure, granularity 

and plagdet as they were defined in (Potthast et 

al., 2010). 

In order to choose the parameters of our me-

thod, we trained the classifier using various train-

ing sets generated by using the different combi-

nations of the n-gram length n (from 1 to 10) and 

the number of classes m (from 2 to 10). We 

adopted the parameters that yielded the higher f-

measure, namely n = 6 and m = 4. 

With regard the sliding window parameters, 

we used three different options for the window 

size, which are 100, 200 and 400 words, with a 

step equal to the quarter of the window size. On-

ly one option is applied to a given document de-

pending on its length. 

We deliberately use similar sliding window 

parameters as the method of Oberreuter et al. 

                                                 
4 http://www.uni-

weimar.de/en/media/chairs/webis/research/corpora/corpus-

pan-pc-09/ 
5 http://www.uni-

weimar.de/en/media/chairs/webis/research/corpora/corpus-

pan-pc-11/ 
6 We used only the corpora parts that are dedicated to the 

evaluation of the intrinsic approach. 
7 http://sourceforge.net/projects/inaracorpus/ 

(2011)
8
 in order to compare the two methods 

without being much affected by the segmentation 

strategy.  

Table 1 compares the results of our method to 

the one of Oberreuter et al. (2011) being the 

winner in PAN 2011 competition and considered 

one of the best intrinsic plagiarism detection me-

thods. 

 

  Our method Oberreuter et al.9  

PAN-

PC-09 

Precision 0.31 0.39 

Recall 0.49 0.31 

F-measure 0.38 0.35 

Granularity 1.21 1.00 

PAN-

PC-11 

Precision 0.22 0.34 

Recall 0.50 0.31 

F-measure 0.30 0.33 

Granularity 1.13 1.00 

InAra Precision 0.24 0.29 

Recall 0.69 0.25 

F-measure 0.35 0.27 

Granularity 1.27 1.44 

 

Table 1. Performance of the n-gram frequency 

class method on 3 corpora. 

 

From Table 1 it can be appreciated that our 

method in terms of recall noticeably 

outperforms Oberreuter et al. (2011), although 

precision and granularity still needs to be further 

improved. Nonetheless, in comparison with other 

methods such as the one of Stamatatos (2009b), 

that obtained the best results in PAN 2009 com-

petition on plagiarism detection, precision is still 

very much competitive: 0.31 vs. 0.23 (PAN-PC-

09) and 0.22 vs. 0.14 (PAN-PC-11). In terms of 

f-measure, Oberreuter et al. (2011) method is 

significantly higher than our method on PAN-

PC-11 corpus, but both methods have statistical-

ly similar results on InAra
10

.  

Considering plagdet, which is a score that 

represents the overall performance of a plagiar-

                                                 
8 Oberreuter et al. (2011) used mainly 400 words as the 

window size that may change according to the document 

length.  
9 The results of Oberreuter et al. method (2011) on PAN-

PC-09 and PAN-PC-11 are taken from his paper. However, 

we re-implemented this method in order to evaluate it on 

InAra. Note that our re-implementation maybe not perfectly 

similar to the original one since the authors did not provide 

details on the parameters tuning.   
10 The Kolomogorov Smirnov test with a significance level 

of 5% has been used to compare the two methods f-

measures on PAN-PC-11 and InAra. Unfortunately, on the 

PAN-PC-09 corpora we were unable to carry out this test 

since we do not have the results of Oberreuter et al. per each 

document.     

1462



ism detection method, our method could be 

ranked the 2
nd

, after Oberreuter et al. (2011) and 

before Stamatatos (2009b) as it is shown in Table 

2. 

Table 2. Plagdet of our method in comparison 

with the two best methods on PAN competition 

corpora. 

6 Conclusion 

In this paper we have shown that representing 

the text fragments of a given suspicious docu-

ment  by  the proportion of character n-gram 

classes (the most frequent, the least frequent and 

intermediate levels) is a promising way for de-

tecting plagiarism intrinsically.  

The experiments described in this paper were 

performed on three corpora comprising docu-

ments in English, Spanish and for the first time 

Arabic. We obtained comparable results to the 

best performing systems.  

Our method best configuration is 6 as the n-

grams length and only 4 as the number of classes 

(i.e. 4 features). As future work, it would be in-

teresting to combine the most precise classes of 

different n-gram lengths in order to improve the 

precision. It would be important as well to try 

other segmentation strategies and post-

processing techniques in order to improve the 

granularity. Another interesting experiment we 

plan to carry out in the future is to use the n-

gram classes along with the traditional stylistic 

features such as the vocabulary richness, average 

sentence length, etc.  

Acknowledgments 

The first author would like to thank Parth 

Gupta for his helpful feedback and Gabriel 

Oberreuter for providing some implementation 

details of his method.  

The work of the second author was carried out 

in the framework of DIANA APPLICATIONS- 

Finding Hidden Knowledge in Texts: 

Applications (TIN2012-38603-C02-01) and 

WIQ-EI IRSES (Grant No. 269180 within the 

EC FP 7 Marie Curie People) research projects, 

and the VLC/CAMPUS Microcluster on 

Multimodal Interaction in Intelligent Systems. 

References 

Navot Akiva. 2011. Using Clustering to Identify 

Outlier Chunks of Text - Notebook for PAN at 

CLEF 2011. In Notebook Papers of CLEF 2011 

LABs and Workshops, September 19-22, 

Amsterdam, The Netherlands, pages 5‚Äì7. 

Navot Akiva and Moshe Koppel. 2013. A Generic 

Unsupervised Method for Decomposing Multi-

Author Documents. Journal of the American 

Society for Information Science and Technology, 

64(11):2256‚Äì2264. 

Imene Bensalem, Paolo Rosso, and Salim Chikhi. 

2013. A New Corpus for the Evaluation of Arabic 

Intrinsic Plagiarism Detection. In Pamela Forner, 

Henning M√ºller, Roberto Paredes, Paolo Rosso, 

and Benno Stein, editors, CLEF 2013, LNCS, vol. 

8138, pages 53‚Äì58, Heidelberg. Springer. 

Julian Brooke and Graeme Hirst. 2012. Paragraph 

Clustering for Intrinsic Plagiarism Detection using 

a Stylistic Vector-Space Model with Extrinsic 

Features - Notebook for PAN at CLEF 2012. In 

CLEF 2012 Evaluation Labs and Workshop ‚Äì 

Working Notes Papers, 17-20 September, Rome, 

Italy. 

Neil Graham, Graeme Hirst, and Bhaskara Marthi. 

2005. Segmenting Documents by Stylistic 

Character. Natural Language Engineering, 

11(04):397‚Äì415. 

Cristian Grozea and Marius Popescu. 2010. Who ‚Äô s 

the Thief‚ÄØ? Automatic Detection of the Direction of 

Plagiarism. In CICLing 2010, Ia≈üi, Romania, 

March 21-27, LNCS, vol. 6008, pages 700‚Äì710. 

Springer. 

Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard 

Pfahringer, Peter Reutemann, and Ian H. Witten. 

2009. The WEKA Data Mining Software: An 

Update. SIGKDD Explorations, 11(1):10‚Äì18. 

Moshe Koppel and Shachar Seidman. 2013. 

Automatically Identifying Pseudepigraphic Texts. 

In EMNLP 2013, pages 1449‚Äì1454, 

Seattle,Washington, USA. Association for 

Computational Linguistics. 

Sven Meyer zu Eissen, Benno Stein, and Marion 

Kulig. 2007. Plagiarism Detection without 

Reference Collections. In Reinhold Decker and 

Hans -J. Lenz, editors, Advances in Data Analysis, 

Selected Papers from the 30th Annual Conference 

of the German Classification Society (GfKl), 

Berlin, pages 359‚Äì366, Heidelberg. Springer. 

Gabriel Oberreuter, Gaston L‚ÄôHuillier, Sebasti√°n A. 

R√≠os, and Juan D. Vel√°squez. 2011. Approaches for 

Intrinsic and External Plagiarism Detection - 

Notebook for PAN at CLEF 2011. In CLEF 2011 

Evaluation Labs and Workshop ‚Äì Working Notes 

 Oberreuter 

et al. 

Our 

method 

Stamatatos 

PAN-PC-09 0.35 0.33 0.25 

PAN-PC-11 0.33 0.28 0.19 

1463



Papers, September 19-22, Amsterdam, The 

Netherlands, pages 1‚Äì10. 

Martin Potthast, Benno Stein, Alberto Barr√≥n-

Cede√±o, and Paolo Rosso. 2010. An Evaluation 

Framework for Plagiarism Detection. In Chu-Ren 

Huang and Daniel Jurafsky, editors, Proceedings of 

the 23rd International Conference on 

Computational Linguistics (COLING 2010), pages 

997‚Äì1005, Stroudsburg, USA. Association for 

Computational Linguistics. 

Efstathios Stamatatos. 2009a. A Survey of Modern 

Authorship Attribution Methods. Journal of the 

American Society for Information Science, 

60(3):538‚Äì556. 

Efstathios Stamatatos. 2009b. Intrinsic Plagiarism 

Detection Using Character n-gram Profiles. In 

Benno Stein, Paolo Rosso, Efstathios Stamatatos, 

Moshe Koppel, and Eneko Agirre, editors, 

Proceedings of the SEPLN‚Äô09 Workshop on 

Uncovering Plagiarism, Authorship and Social 

Software Misuse (PAN 09), pages 38‚Äì46. CEUR-

WS.org. 

Benno Stein, Nedim Lipka, and Peter Prettenhofer. 

2011. Intrinsic Plagiarism Analysis. Language 

Resources and Evaluation, 45(1):63‚Äì82. 

Michael Tschuggnall and G√ºnther Specht. 2013. 

Using Grammar-Profiles to Intrinsically Expose 

Plagiarism in Text Documents. In NLDB 2013, 

LNCS, vol. 7934, pages 297‚Äì302. Springer. 

 

 

1464


