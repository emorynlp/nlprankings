Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1619‚Äì1629,

SoÔ¨Åa, Bulgaria, August 4-9 2013. c(cid:13)2013 Association for Computational Linguistics

1619

Looking for Help from Tweets during a Large Scale Disaster

Aid is Out There:

Istv¬¥an Varga‚Ä† Motoki Sano‚Ä† Kentaro Torisawa‚Ä† Chikara Hashimoto‚Ä†

Kiyonori Ohtake‚Ä† Takao Kawai¬ß Jong-Hoon Oh‚Ä† Stijn De Saeger‚Ä†

‚Ä†Information Analysis Laboratory,

National Institute of Information and Communications Technology (NICT), Japan
{istvan, msano, torisawa, ch, kiyonori.ohtake, rovellia, stijn}@nict.go.jp

¬ßKnowledge Discovery Research Laboratories, NEC Corporation, Japan

t-kawai@bx.jp.nec.com

Abstract

The 2011 Great East Japan Earthquake
caused a wide range of problems, and as
countermeasures, many aid activities were
carried out. Many of these problems and
aid activities were reported via Twitter.
However, most problem reports and corre-
sponding aid messages were not success-
fully exchanged between victims and lo-
cal governments or humanitarian organi-
zations, overwhelmed by the vast amount
of information. As a result, victims could
not receive necessary aid and humanitar-
ian organizations wasted resources on re-
dundant efforts. In this paper, we propose
a method for discovering matches between
problem reports and aid messages. Our
system contributes to problem-solving in
a large scale disaster situation by facilitat-
ing communication between victims and
humanitarian organizations.

1 Introduction
The 2011 Great East Japan Earthquake in March
11, 2011 killed 15,883 people and destroyed over
260,000 households (National Police Agency of
Japan, 2013). Accustomed way of living suddenly
became unmanageable and people found them-
selves in extreme conditions for months.

Just after the disaster, many people used Twitter
for posting problem reports and aid messages as
it functioned while most communication channels
suffered disruptions (Winn, 2011; Acar and Mu-
raki, 2011; Sano et al., 2012). Examples of such
problem reports and aid messages, translated from
Japanese tweets, are given below (P1, A1).

P1 My friend said infant formula is sold out. If
somebody knows shops in Sendai-city where
they still have it in stock, please let us know.

A1 At Jusco supermarket in Sendai, you can still

buy water and infant formula.

If A1 would have been forwarded to the sender
of P1, it could have helped since it would help
the ‚Äúfriend‚Äù to obtain infant formula. But in re-
ality, the majority of such reports/messages, es-
pecially unforeseen ones went unnoticed amongst
the mass of information (Ohtake et al., 2013). In
addition, there were cases where many humani-
tarian organizations responded to the same prob-
lems and wasted precious resources. For instance,
many volunteers responded to problems which
were heavily reported by public media, leading
to oversupply (Saijo, 2012). Such waste of re-
sources could have been avoided if the organiza-
tions would have successfully shared the aid mes-
sages for the same problems.

Such observations motivated this work. We de-
veloped methods for recognizing problem reports
and aid messages in tweets and Ô¨Ånding proper
matches between them. By browsing the discov-
ered matches, victims can be assisted to over-
come their problems, and humanitarian organiza-
tions can avoid redundant relief efforts. We deÔ¨Åne
problem reports, aid messages and their successful
matches as follows.

Problem report: A tweet that informs about the
possibility or emergence of a problem that re-
quires a treatment or countermeasure.

Aid message: A tweet that (1) informs about sit-
uations or actions that can be a remedy or so-
lution for a problem, or (2) informs that the
problem is solved or is about to be solved.

Problem-aid tweet match: A tweet pair

is a
problem-aid tweet match (1) if the aid mes-
sage informs how to overcome the problem,
(2) if the aid message informs about the set-

1620

tlement of the problem, or (3) if the aid mes-
sage provides information which contributes
to the settlement of the problem.

In this work we excluded direct requests, such as
‚ÄúSend us food!‚Äù, from problem reports. This is be-
cause it is relatively easy to recognize such direct
requests by checking mood types (i.e., imperative)
and their behavior is quite different from prob-
lem reports like ‚ÄúPeople in Sendai are starving‚Äù.
Problem reports in this work do not directly state
which actions are required, only implying the ne-
cessity of a countermeasure through claiming the
existence of problems.

An underlying assumption of our method is that
we can Ô¨Ånd a noun-predicate dependency relation
that works as an indicator of problems and aids in
problem reports and aid messages, which we refer
to as problem nucleus and aid nucleus.1 An exam-
ple of problem nucleus is ‚Äúinfant formula is sold
out‚Äù in P1, and that of aid nucleus is ‚Äú(can) buy
infant formula‚Äù in A1. Many problem-aid tweet
matches can be recognized through problem and
aid nuclei pairs.

We also assume that if the problem and aid nu-
clei match, they share the same noun. Then, the
semantics of predicates in the nuclei is the main
factor that decides whether the nuclei constitute
a match. We introduce a semantic classiÔ¨Åcation
of predicates according to the framework of ex-
citation polarities proposed in Hashimoto et al.
(2012). Our hypothesis is that excitation polarities
along with trouble expressions can characterize
problem reports, aid messages and their matches.
We developed a supervised method encoding such
information into its features.

An evident alternative to this approach is to use
sentiment analysis (Mandel et al., 2012; Tsagkali-
dou et al., 2011) assuming that problem reports
should include something ‚Äòbad‚Äô while aid mes-
sages describe something ‚Äògood‚Äô. However, we
will show that this does not work well in our exper-
iments. We think this is due to mismatch between
the concepts of problem/aid and sentiment polar-
ity. Note that previous work on ‚Äòdemand‚Äô recogni-
tion also found similar tendencies (Kanayama and
Nasukawa, 2008).

Another issue in this task is, of course, the
context surrounding problem/aid nuclei. The fol-
1We found that out of 500 random tweets only 4.5% of
problem reports and 9.1% of aid messages did not contain
any problem report/aid message nuclei.

lowing (imaginary) tweets exemplify the problems
caused by contexts.
FP1 I do not believe infant formula is sold out

in Sendai.

FA1 At Jusco supermarket in Iwaki, you can still

buy infant formula.

The problem nuclei of FP1 and P1 are the same
but FP1 is not a problem report because of the ex-
pression ‚ÄúI do not believe‚Äù. The aid nuclei of FA1
and A1 are the same but FA1 does not constitute
a proper match with P1 because FA1 and P1 re-
fer to different cities, ‚ÄúIwaki‚Äù and ‚ÄúSendai‚Äù.
In
this work, the problems concerning the modality
and other semantic modiÔ¨Åcations to problem/aid
nuclei by context are dealt with by the introduc-
tion of features representing the text surrounding
the nuclei in machine learning. As for the loca-
tion problem, we apply a location recognizer to all
tweets and restrict the matching candidates to the
tweet pairs referring to the same location.

2 Approach

Figure 1: Problem-aid matching system overview.

We developed machine learning based systems
to recognize problem reports, aid messages and
problem-aid tweet matches. Figure 1 illustrates
the whole system. First, location names in tweets
are identiÔ¨Åed by matching tweets against our loca-
tion dictionary, described in Section 3. Then, each
tweet is paired with each dependency relation in
the tweet, which is a candidate of problem/aid nu-
clei and given to the problem report and aid mes-
sage recognizers. A tweet-nucleus-candidate pair
judged as problem report is combined with another
tweet-nucleus-candidate pair recognized as an aid
message if the two nuclei share the same noun and
the tweets share the same location name, and given
to the problem-aid match recognizer.




	



	


	




	










	

		








	

	



		


	










	

	



		



1621

In the following, problem and aid nuclei are
denoted by a noun-template pair. A template is
composed of a predicate and its argument posi-
tion. For instance, ‚Äúwater supply stopped‚Äù in P2
is a problem nucleus, ‚Äúwater supply recovered‚Äù in
A2 is an aid nucleus and they are denoted by the
noun-template pairs ‚ü®water supply, X stopped‚ü© and
‚ü®water supply, X recovered‚ü©.
P2 In Sendai city, water supply stopped.

A2 In Sendai city, water supply recovered.

Roughly speaking, we regard the tasks of prob-
lem report recognition and aid message recogni-
tion as the tasks of Ô¨Ånding proper problem/aid
nuclei in tweets and our method performs these
tasks based on the semantic properties of nouns
and templates in problem/aid nucleus candidates
and their surrounding contexts.

The basic intuition behind this approach can
be explained using excitation polarity proposed in
Hashimoto et al. (2012). Excitation polarity differ-
entiates templates into ‚Äòexcitatory‚Äô or ‚Äòinhibitory‚Äô
with regard to the main function or effect of en-
tities referred to by their argument noun. While
excitatory templates (e.g., cause X, buy X, suf-
fer from X) entail that the main function or ef-
fect is activated or enhanced, inhibitory templates
(e.g., ruin X, prevent X, X runs out) entail that
the main function or effect is deactivated or sup-
pressed. The templates that do not Ô¨Åt into the
above categorization are classiÔ¨Åed as ‚Äòneutral‚Äô.

We observed that problem reports in general
included either of (A) a dependency relation be-
tween a noun referring to some trouble and an
excitatory template or (B) a dependency rela-
tion between a noun not referring to any trouble
and an inhibitory template. Examples of (A) in-
clude ‚ü®carbon monoxide poisoning, suffer from
X‚ü©, ‚ü®false rumor, spread X‚ü©. They refer to events
that activate troubles. On the other hand, (B) is
exempliÔ¨Åed by ‚ü®school, X is collapsed‚ü©, ‚ü®battery,
X runs out‚ü©, which imply that some non-trouble
objects such as resources, appliances and facilities
are dysfunctional. We assume that if we can Ô¨Ånd
such dependency relations in tweets, the tweets are
likely to be problem reports.

Contrary, a tweet is more likely to be an aid
message when it includes either (C) a dependency
relation between a noun referring to some trouble
and an inhibitory template or (D) a dependency re-
lation between a noun not referring to any trou-

excitatory
inhibitory

trouble

(A) problem nucleus

non-trouble
(D) aid nucleus

(C) aid nucleus

(B) problem nucleus

Table 1: Problem/aid-excitation matrix.

ble and an excitatory template. Examples of (C)
are ‚ü®Ô¨Çu, X was eradicated (in some shelter)‚ü© and
‚ü®debris, remove X‚ü©. They represent the dysfunc-
tion of troubles and can mean the solution or the
settlement of troubles. On the other hand, exam-
ples of (D) include ‚ü®school, X re-build‚ü© and ‚ü®baby
formula, buy X‚ü©. They entail that some resources
function properly or become available. These for-
mulations are summarized in Table 1.

As an interesting consequence of such a view
on problem/aid nucleus, we can say the following
regarding problem-aid tweet matchings: when a
problem nucleus and an aid nucleus are an ade-
quate match, the excitation polarities of their tem-
plates are opposite. Consider the following tweets.

P3 Some people were going back to Iwaki, but the
water system has not come back yet. It‚Äôs ter-
rible that bath is unusable.

A3 We open the bath for the public, located on
the 2F of Iwaki Kuhon temple. If you‚Äôre stay-
ing at a relief shelter and would like to take a
bath, you can use it.

‚ÄúBath is unusable‚Äù in P3 is a problem nucleus
while ‚Äúopen the bath‚Äù in A3 is an aid nucleus.
Since the problem reported in P3 can be solved
with A3, they are a successful match. The in-
hibitory template ‚ÄúX is unusable‚Äù indicates that
the function of ‚Äúbath‚Äù, a non-trouble expression,
is suppressed. The excitatory template ‚Äúopen X‚Äù
indicates that the function of ‚Äúbath‚Äù is activated.

The same holds when we consider the noun re-
ferring to troubles like ‚ÄúÔ¨Çu‚Äù. The polarity of the
template in a problem nucleus should be excita-
tory like ‚ÄúÔ¨Çu is raging‚Äù while that of an aid nucleus
should be inhibitory like ‚ü®Ô¨Çu, X was eradicated‚ü©.
These examples keep the constraint that the prob-
lem and aid nucleus should have opposite polari-
ties when they constitute a match.

Note that the formulations of problem report,
aid message and their matches or the excitation
matrix (Table 1) were not presented to our anno-
tators and our test/training data may contain data
that contradict with the formulations. These for-
mulations constitute the hypothesis to be validated
in this work.

1622

An important point to be stressed here is that
there are problem-aid tweet matches that do not
Ô¨Åt into our formulations. For instance, we as-
sume that the problem nucleus and aid nucleus in
a proper match share the same noun. However,
tweet pairs such as ‚ÄúThere are many injured people
in Sendai city‚Äù and ‚ÄúWe are sending ambulances
to Sendai‚Äù can constitute a proper match, but there
is no proper problem-aid nuclei pair that share the
same noun in these tweets. (We can Ô¨Ånd the de-
pendency relations sharing ‚ÄúSendai‚Äù but they do
not express anything about the contents of prob-
lem and aid.) The point is that the tweet pairs can
be judged because people know ambulances can
be a countermeasure to injured people as world
knowledge. Introducing such world knowledge is
beyond the scope of this current study.

Also, we exclude direct requests from problem
reports. As mentioned in the introduction, identi-
fying direct requests is relatively easy, hence we
excluded them from our target.

3 Problem Report and Aid Message

Recognizers

We recognize problem reports and aid messages in
given tweets using a supervised classiÔ¨Åer, SVMs
with linear kernel, which worked best in our pre-
liminary experiments. The feature set given to
the SVMs are summarized in the top part of Ta-
ble 2. Note that we used a common feature
set for both the problem report recognizer and
aid message recognizer and that it is categorized
into several types:
features concerning trouble
expressions (TR), excitation polarity (EX), their
combination (TREX1) and word sentiment polar-
ity (WSP), features expressing morphological and
syntactic structures of nuclei and their context sur-
rounding problem/aid nuclei (MSA), features con-
cerning semantic word classes (SWC) appearing
in nuclei and their context, request phrases, such
as ‚ÄúPlease help us‚Äù, appearing in tweets (REQ),
and geographical locations in tweets recognized
by our location recognizer (GL). MSA is used to
express the modality of nuclei and other contex-
tual information surrounding nuclei. REQ was in-
troduced based on our observation that if there are
some requests in tweets, problem nuclei tend to
appear as justiÔ¨Åcation for the requests.

We also attempted to represent nucleus template
IDs, noun IDs and their combinations directly in
our feature set to capture typical templates fre-

TR
EX1

Whether the nucleus noun is a trouble/non-trouble expression.
The excitation polarity and the value of the excitation score of the
nucleus template.

TREX1 All possible combinations of trouble/non-trouble of TR and exci-

tation polarities of EX1.

WSP1 Whether the nucleus noun is positive/negative/not in the Word Sen-

timent Polarity (WSP) dictionary.

WSP2 Whether the nucleus template is positive/negative/not in the WSP

WSP3 Whether the nucleus template is followed by a positive/negative

dictionary.

word within the tweet.

MSA5

MSA4

MSA2

MSA1 Morpheme n-grams, syntactic dependency n-grams in the tweet
and morpheme n-grams before and after the nucleus template.
(1 ‚â§ n ‚â§ 3)
Character n-grams of the nucleus template to capture conjugation
and modality variations. (1 ‚â§ n ‚â§ 3)
MSA3 Morpheme and part-of-speech n-grams within the bunsetsu con-
taining the nucleus template to capture conjugation and modality
variations. (1 ‚â§ n ‚â§ 3) (A bunsetsu is a syntactic constituent
composed of a content word and several function words, the small-
est unit of syntactic analysis in Japanese.)
The part-of-speech of the nucleus template‚Äôs head to capture
modality variations outside the nucleus template‚Äôs bunsetsu.
The number of bunsetsu between the nucleus noun and the nucleus
template. We found that a long distance between the noun and the
template suggests parsing errors.
Re-occurrence of the nucleus noun‚Äôs postpositional particle be-
tween the nucleus noun and the nucleus template. We found
that the re-occurrence of the same postpositional particle within
a clause suggests parsing errors.
The semantic class n-grams in the tweet.
The semantic class(es) of the nucleus noun.
Presence of a request phrase in the tweet, identiÔ¨Åed from within
426 manually collected request phrases.
Geographical locations in the tweet identiÔ¨Åed using our location
recognizer. Existence/non-existence of locations in tweets are also
encoded.
Whether the problem and aid nucleus templates have the same or
opposite excitation polarities.
Product of the values of the excitation scores for the problem and
the aid nucleus template.

SWC1
SWC2
REQ

MSA6

EX2

EX3

GL

TREX2 All possible combinations of trouble/non-trouble of TR, excitation
polarity EX1 of the problem nucleus template and excitation po-
larity EX1 of the aid nucleus template.
Common semantic word classes of the problem report and aid mes-
sage.

SIM1

SIM2 Whether there are common nouns modifying the common nucleus

noun or not in the problem report and aid message.

SIM3 Whether the words in the same word class modify the common

SIM4

CTP

SSR1

SSR2
SSR3

SSR4

nucleus noun or not in the problem report and aid message.
The semantic similarity score between the problem nucleus tem-
plate and the aid nucleus template.
Whether the problem nucleus template and the aid nucleus tem-
plate are in contradiction relation dictionary or not.
Problem report recognizer‚Äôs SVM score of problem nucleus tem-
plate.
Problem report recognizer‚Äôs SVM score of aid nucleus template.
Aid message recognizer‚Äôs SVM score of the problem nucleus tem-
plate.
Aid message recognizer‚Äôs SVM score of the aid nucleus template.

Table 2: Features used with the problem re-
port recognizer and the aid message recognizer
(above); additional features used in training the
problem-aid match recognizer (below).

quently appearing in problem and aid nuclei, but
since there was no improvement we omit them.

The other feature types need some non-trivial
dictionaries. In the following, we explain how we
created the dictionaries for each feature type along
with the motivation behind their introduction.

Trouble Expressions (TR) As mentioned previ-
ously, trouble expressions work as good evidence
for recognizing problem reports and aid messages.
The TR feature indicates whether the noun in the
problem/aid nucleus candidate is a trouble ex-

1623

pression or not. For this purpose, we created
a list of trouble expressions following the semi-
supervised procedure presented in De Saeger et al.
(2008). After manual validation of the list, we ob-
tained 20,249 expressions referring to some trou-
bles, such as ‚Äútsunami‚Äù and ‚ÄúÔ¨Çu‚Äù. The value of the
TR feature is determined by checking whether the
nucleus noun is contained in the list.

Excitation Polarities (EX) The excitation po-
larities are also important in recognizing problem
reports and aid messages as mentioned before. For
constructing the dictionary for excitation polarities
of templates, we applied the bootstrapping proce-
dure in Hashimoto et al. (2012) to 600 million Web
pages. Hashimoto‚Äôs method provides the value of
the excitation score in [‚àí1, 1] for each template
indicating the polarities and their strength. Posi-
tive value indicates excitatory, negative value in-
hibitory and small absolute value neutral. After
manual checking of the results by the majority
vote of three human annotators (other than the au-
thors), we limited the templates to the ones that
have score values consistent with the majority vote
of the annotators, obtaining a dictionary consisting
of 7,848 excitatory, 836 inhibitory and 7,230 neu-
tral templates. The Fleiss‚Äô (1971) kappa-score was
0.48 (moderate agreement). We used the excita-
tion score values as feature values. Excitation has
already been used in many works, such as causal-
ity and contradiction extraction (Hashimoto et al.,
2012) or Why-QA (Oh et al., 2013).

Word Sentiment Polarity (WSP) As we sug-
gested before, full-Ô¨Çedged sentiment analysis to
recognize the expressions, including clauses and
phrases, that refer to something good or bad was
not effective in our task. However, the sentiment
polarity, assigned to single words turned out to
be effective. To identify the sentiment polarity
of words, we employed the word sentiment polar-
ity dictionary used with a sentiment analysis tool
for Japanese, the Opinion Extraction Tool soft-
ware2, which is an implementation of Nakagawa
et al. (2010). The dictionary includes 9,030 posi-
tive and 27,951 negative words. Note that we used
the Opinion Extraction Tool in the experiments to
check the effectiveness of the full-Ô¨Çedged senti-
ment analysis in this task.

Semantic Word Class (SWC) We assume that
nouns in the same semantic class behave simi-
2Provided at the ALAGIN Forum (http://www.alagin.jp/).

larly in crisis situations. For example, if ‚Äúinfec-
tion‚Äù appears in a problem report, the tweets in-
cluding ‚Äúpulmonary embolism‚Äù are also likely to
be problem reports. Semantic word class features
are used to capture such tendencies. We applied
an EM-style word clustering algorithm in Kazama
and Torisawa (2008) to 600 million Web pages and
clustered 1 million nouns into 500 classes. This
algorithm has been used in many works, such as
relation extraction (De Saeger et al., 2011) and
Why-QA (Oh et al., 2012), and can generate vari-
ous kinds of semantically clean word classes, such
as foods, diseasenames, and naturaldisasters. We
used the word classes in tweets as features.3

Geographical Locations (GL) Our
location
loca-
recognizer matches tweets against our
tion dictionary.
Location names and their
existence/non-existence in tweets constitute evi-
dence, thus we encoded such information into our
features. The location dictionary was created from
the Japan Post code data4 and Wikipedia, contain-
ing 2.7 million location names including cities,
schools and other facilities (Kazama et al., 2013).

4 Problem-Aid Match Recognizer
After problem report and aid message recogni-
tion, the positive outputs of the respective classi-
Ô¨Åers are used as input in this step. The problem-
aid match recognizer classiÔ¨Åes an aid message-
nucleus pair together with the problem report-
nucleus pair employing SVMs with linear ker-
nel, which performed best in this task again. The
problem-aid match recognizer uses all the features
used in the problem report recognizer and the aid
message recognizer along with additional features
regarding: excitation polarity (EX) and trouble
expressions (TR), distributional similarity (SIM),
contradiction (CTP) and SVM-scores of the prob-
lem report and aid message recognizers (SSR).
Here also we attempted to capture typical or fre-
quent matches of nuclei using template and noun
IDs and their combinations, but we did not observe
any improvement so we omit them from the fea-
ture set. The bottom part of Table 2 summarizes
the additional feature set, some of which are de-
scribed below in more detail.

3There is a slight complication here. For each noun n, EM
clustering estimates a probability distribution P (n|c‚àó) for n
and semantic class c‚àó. From this distribution we obtained
discrete semantic word classes by assigning each noun n to
semantic class c = argmaxc‚àó p(c‚àó|n).

4http://www.post.japanpost.jp/zipcode/download.html

1624

As for TR and EX, our intuition is that if a prob-
lem nucleus and an aid nucleus are an adequate
match, their excitation polarities are opposite, as
described in Section 2. We encode whether the ex-
citation polarities of nuclei templates are the same
or not in our features. Also, the excitation polar-
ities of problem and aid nuclei and TR are com-
bined (TREX1, TREX2) so that the classiÔ¨Åer can
know whether the nuclei follow the constraint for
adequate matches described in Section 2.

As for SIM, if an aid message matches a prob-
lem report, besides the common nucleus noun, it is
reasonable to assume that certain contexts are se-
mantically similar. We capture this characteristic
in three ways. SIM1 looks for common semantic
word classes in the problem report and aid mes-
sage. SIM2 and SIM3 target the modiÔ¨Åers of the
common nucleus noun if they exist.

We also observed that if an aid message matches
a problem report, the problem nucleus template
and aid nucleus template are often distributionally
similar. A typical example is ‚ÄúX is sold out‚Äù and
‚Äúbuy X‚Äù. SIM4 captures this tendency. As the dis-
tributional similarity between templates, we used
a Bayesian distributional similarity measure pro-
posed by Kazama et al. (2010).5

CTP indicates whether the problem and aid nu-
clei are in contradiction relation or not. This fea-
ture was implemented based on the observation
that when problem and aid nuclei are in contradic-
tion relation, they are often proper matches (e.g.,
‚ü®blackout, ‚ÄúX starts‚Äù‚ü© and ‚ü®blackout, ‚ÄúX ends‚Äù‚ü©).
CTP indicates whether nucleus pairs are in the
one million contradiction phrase pairs6 automat-
ically obtained by applying a method proposed by
Hashimoto et al. (2012) to 600 million Web pages.

5 Experiments

We evaluated our problem report recognizer and
problem-aid match recognizer. For the sake of
space, we give only the performance Ô¨Ågures of the
aid message recognizer at the end of Section 5.1.
We collected tweets posted during and after
the 2011 Great East Japan Earthquake, between
March 10 and April 4, 2011. After applying
keyword-based Ô¨Åltering with a list of over 300

5The original similarity was deÔ¨Åned over noun pairs and it
was estimated from dependency relations. Obtaining similar-
ity between template pairs, not noun pairs, is straightforward
given the same dependency relations. We used 600 million
Web pages for this similarity estimation.

6The precision of the pairs was reported as around 70%.

disaster related keywords, we obtained 55 million
tweets. After dependency parsing7, we used them
in our evaluation.

5.1 Problem Report Recognition
Firstly, we evaluated our problem report recog-
nizer. Particularly, we assessed the effect of ex-
citation polarities and trouble expressions in two
settings. The Ô¨Årst is against a naturally distributed
gold standard data. The second targets problem
reports with problem nuclei unseen in the training
data.

In both experiments we observed that the per-
formance drops when excitation polarities and
trouble expressions are removed from the feature
set. The performance drop was larger in the sec-
ond experiment which suggests that the excitation
polarities and trouble expressions are more effec-
tive against unseen problem reports.

Training and test data for problem report recog-
nition consist of tweet-nucleus candidate pairs
randomly sampled from our 55 million tweet data.
The training data (R) and test data (T ) consist of
13,000 and 1,000 pairs, respectively, manually la-
beled by three annotators (other than the authors)
as problem or other. Final judgment was made by
majority vote. The Fleiss‚Äô kappa score for train-
ing and test data for annotation judgement is 0.74
(substantial agreement).

Our problem report recognizer and its variants
are listed in Table 3. Table 4 shows the evalua-
tion results. The proposed method achieved about
44% recall and nearly 80% precision, outperform-
ing all other systems in terms of precision, F-score
and average precision8. The improvement in pre-
cision when using TR&EX is statistically signif-
icant (p < 0.05).9 Note that F-measure dropped

PROPOSED: Our proposed method with all features used.
PROPOSED-*: The proposed method without the feature set de-
noted by ‚Äú*‚Äù. Here EX and TR denote all excitation po-
larity and trouble expression related features, respectively,
including their combinations (TREX1).

PROPOSED+OET: The proposed method incorporating the
classiÔ¨Åcation results of problem nucleus candidates by the
Opinion Extraction Tool as additional binary features.

RULE-BASED: The method that regards only nuclei satisfying

the constraint in Table 1 as problem nuclei.

Table 3: Evaluated problem report recognizers.
7http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?KNP
8We calculate average precision using the formula: aP =
, where P rec(k) is the precision at
cut-off k and rel(k) is an indicator function equaling 1 if
the item at rank k is relevant, zero otherwise.

(P rec(k)√órel(k))

‚àën

9Throughout this paper we performed two-tailed test of

k=1

n

1625

Recognition system R (%)
44.26
PROPOSED
45.08
PROPOSED-TR&EX
44.67
PROPOSED-EX
43.85
PROPOSED-TR
28.69
PROPOSED-MSA
43.42
PROPOSED-SWC
43.14
PROPOSED-WSP
PROPOSED-REQ
42.64
44.14
PROPOSED-GL
44.24
PROPOSED+OET
RULE-BASED
30.32

P (%)
79.41
74.83
74.66
74.31
70.71
75.97
77.83
76.16
78.34
79.41
67.96

F (%)
56.83
56.26
55.89
55.15
40.81
55.25
55.50
55.50
55.50
56.82
41.93

aP (%)
71.82
69.67
69.90
69.44
57.74
70.61
70.45
54.67
56.46
71.81
n/a

Table 4: Recall (R), precision (P), F-score (F) and
average precision (aP) of the problem report rec-
ognizers.

whenever each type of feature was removed, im-
plying that each type of feature is effective in this
task. Especially note the performance drop if we
remove excitation polarities (EX), trouble expres-
sion (TR) and both excitation and trouble expres-
sion features (TR&EX), conÔ¨Årming that they are
crucial in recognizing problem reports with high
accuracy. Also note that the performance of PRO-
POSED+OET was actually slightly worse than that
of the proposed method. This suggests that full-
Ô¨Çedged sentiment analysis is not effective at least
in this setting. The rule-based method achieved
relatively high precision despite of the low recall,
demonstrating the importance of problem and aid
nuclei formulations described in Section 1.

The second experiment assessed the efÔ¨Åciency
of our problem report recognizer against unseen
problem nuclei under the condition that every tem-
plate in nuclei has excitation polarity. We sampled
the training and test data so that the problem nu-
cleus nouns and templates in the training and test
data are disjoint. First we created a subset of the
test data by selecting the samples which had nu-
clei with excitation templates. We call this sub-
set T ‚Ä≤. Next, we removed samples from training
data R if either of their problem nouns or tem-
plates appeared in the nuclei of T ‚Ä≤. The result-
ing new training data (called R‚Ä≤) and test data (T ‚Ä≤)
consist of 6,484 and 407 tweet-nucleus candidate
pairs, respectively. We trained our problem report
recognizer using R‚Ä≤ and tested its performance us-
ing T ‚Ä≤. Figure 2 shows the precision-recall curves
obtained by changing the threshold on the SVM
scores. The effectiveness of excitation polarities
and trouble expressions was more evident in this
setting. The PROPOSED‚Äôs performance was ac-
tually better in this setting (almost 50% recall at

population proportion (Ott and Longnecker, 2010) using
SVM-threshold=0.

Figure 2: Precision-recall curves of problem re-
port recognizers against unseen problem nuclei.

more that 80% precision), than the previous set-
ting, showing that excitation templates and trouble
expressions are crucial in achieving high perfor-
mance especially for unseen problem nuclei. The
same was conÔ¨Årmed when we removed excitation
polarity and trouble expression related features,
with performance dropping by 7.43 points in terms
of average precision. The improvement in pre-
cision when using TR&EX is statistically signif-
icant (p < 0.01). This implies, assuming that we
have a wide-coverage dictionary of templates with
excitation polarities, that excitation polarities are
important in dealing with unexpected problems in
disaster situations.

We also evaluated the aid-message recognizer,
using tweet-nucleus pairs in R and T as train-
ing and test data and the annotation scheme was
also the same. The average Fleiss‚Äô kappa score
was 0.55 (moderate agreement). Our recognizer
achieved 53.82% recall and 65.67% precision and
showed similar tendencies with the problem report
recognizer, with the excitation polarities and trou-
ble expressions contributing to higher accuracy.

We can conclude that excitation polarities and
trouble expressions are important in identifying
problem reports and aid messages during disaster
situations.

5.2 Problem-Aid Matching
Next, we evaluated the performance of
the
problem-aid match recognizer. We applied our
problem report recognizer and aid message recog-
nizer to all 55 million tweets and combined the
tweet-nucleus pairs judged as problem reports and
aid messages, respectively, to create the training
and test data.

The training data consists of two parts (M 1 and
M 2). M 1 includes many variations of the aid
messages for each problem report, while M 2 en-

n
o
i
s
i
c
e
r
P

 1

 0.9

 0.8

 0.7

 0.6

 0.5

 0.4

 0.3

 0.2

 0

 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9

 1

Recall

PROPOSED-TR
PROPOSED-EX

PROPOSED-TR&EX
PROPOSED

1626

sures diversity in nouns and templates in problem
nuclei. For M 1, we randomly picked up problem
reports from the output of the problem report rec-
ognizer and to each we attached up to 30 randomly
picked, distinct aid messages that have the same
nucleus noun. Building M 2 follows the construc-
tion method of M 1, except that: (1) we used up
to 30 distinct problem nuclei for each noun; (2)
for each problem report we attached only one ran-
domly picked aid message.

In creating the test data T 2, we followed the
construction method used for M 2 to assess the
performance of our proposal with a large variety
of problems. M 1, M 2 and T 2 consist of 3,000,
6,000 and 1,000 samples, respectively. The an-
notation was done by majority vote of three hu-
man annotators (other than the authors), the aver-
age Fleiss‚Äô kappa-score for training and test data
was 0.63 (substantial agreement).

We trained the problem-aid match recognizers
of Table 5 with M 1 and M 2. The evaluation
results performed on T 2 are shown in Table 6.
We can observe that, among the nuclei related
features, the trouble expression (TR) and excita-
tion polarity (EX) features and their combination
(TR&EX) contribute most to the performance, al-
though the contribution of nuclei related features
is less in comparison to the problem report and aid
message recognition. The improvement in preci-
sion when using TR&EX is marginally signiÔ¨Åcant
(p = 0.056). Instead, morphological and syntactic
analysis (MSA) and semantic word class (SWC)
features greatly improved performance.

As the Ô¨Ånal experiments, we evaluated top-
ranking matches of our problem-aid match recog-
nizer, where the recognizer classiÔ¨Åed all the possi-
ble combinations of tweet-nuclei pairs taken from
55 million tweets. In addition, we assessed the ef-
fectiveness of excitation polarities and trouble ex-
pressions by comparing all positive matches pro-
duced by our full problem-aid match recognizer
(PROPOSED) and those produced by the problem-
aid match recognizer (PROPOSED-TR&EX) that

PROPOSED: Our proposed method with all features used.
PROPOSED-*: The proposed method without the feature set de-
noted by ‚Äú*‚Äù. Here also EX and TR denote all excitation
polarity and trouble expression related features, respec-
tively, including their combinations (TREX1 and TREX2).
RULE-BASED: The method that judges only problem-aid nuclei
combinations with opposite excitation polarities as proper
matches.

Table 5: Evaluated problem-aid match recogniz-
ers.

Matching system
PROPOSED
PROPOSED-TR&EX
PROPOSED-EX
PROPOSED-TR
PROPOSED-MSA
PROPOSED-SWC
PROPOSED-WSP
PROPOSED-CTP
PROPOSED-SIM
PROPOSED-REQ
PROPOSED-GL
PROPOSED-SSR
RULE-BASED

R (%)
30.67
28.83
31.29
30.56
13.50
26.99
30.61
30.06
29.95
30.58
30.61
30.67
15.33

P (%)
70.42
67.14
67.11
69.33
53.66
67.69
69.51
70.00
70.11
70.25
70.31
69.44
17.36

F (%)
42.92
40.33
42.68
42.42
21.57
38.59
42.50
42.05
41.97
42.61
42.65
42.72
16.28

aP (%)
55.16
53.99
54.19
54.85
44.52
52.23
54.81
54.94
54.98
54.67
55.02
54.91
n/a

Table 6: Recall (R), precision (P), F-score (F) and
average precision (aP) of the problem-aid match
recognizers.

did not use excitation polarities and trouble ex-
pressions in its feature set. Note that PROPOSED-
TR&EX was fed by the problem report and aid
message recognizers that didn‚Äôt use excitation po-
larities and trouble expressions. For both systems‚Äô
training data we used R for the problem report
and aid message recognizers; M 1 and M 2 for the
problem-aid matching recognizers.

PROPOSED and PROPOSED-TR&EX output 15.2
million and 13.4 million positive matches, cover-
ing 1,691 and 1,442 nucleus nouns, respectively.
Table 7 shows match samples identiÔ¨Åed with PRO-
POSED. We observed that the output of each sys-
tem was dominated by just a handful of frequent
nucleus nouns, such as ‚Äúwater‚Äù or ‚Äúgasoline‚Äù. We
preferred to assess the performance of our system
against a large variation of problem-aid nuclei,
thus we restricted the number of matches to 10
for each noun10. After this restriction the number
of matches found by PROPOSED and PROPOSED-

Figure 3: Problem-aid match recognition perfor-
mance for ‚Äòall‚Äô and ‚Äòunseen‚Äô problem reports.

10Note that this setting is a pessimistic estimation of our
system‚Äôs overall performance, since according to our obser-
vations problem reports with very frequent nucleus nouns had
proper matches with a higher accuracy than problem reports
with less frequent nucleus nouns.

n
o
i
s
i
c
e
r
P

 1

 0.8

 0.6

 0.4

 0.2

 0

 0  1000  2000  3000  4000  5000  6000  7000  8000  9000

Rank

PROPOSED (unseen)
PROPOSED-TR&EX (unseen)
PROPOSED (all)
PROPOSED-TR&EX (all)

1627

Problem report: „ÅÑ„Çè„Åç„ÅÆÂ∏∏Á£êÁóÖÈô¢„ÄÅ„ÅÑ„Çè„ÅçÊ≥åÂ∞øÂô®ÁßëÁóÖÈô¢„ÄÅ
Á´πÊûóË≤ûÂêâË®òÂøµ„ÇØ„É™„Éã„ÉÉ„ÇØ„ÄÅÊ≥â‰∏≠Â§Æ„ÇØ„É™„Éã„ÉÉ„ÇØ„ÅØ„ÄÅÔºëÔºóÊó•„Åã
„ÇâÈÄèÊûê„Çí‰∏≠Ê≠¢„Åó„Åæ„Åô„ÄÇÊÇ£ËÄÖ„ÅÆÊñπ„ÅØËá≥ÊÄ•ÈÄ£Áµ°„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
(Starting from the 17th, the Iwaki Joban Hospital, the Iwaki
Urology Clinique, the Takebayashi Sadakichi Memorial Clin-
ique and the Izumi Central Clinique have all suspended dial-
ysis sessions. Patients are advised to urgently make contact.)
Aid message: „ÅÑ„Çè„ÅçÊ≥åÂ∞øÂô®ÁßëÁóÖÈô¢„ÅßÁü≠ÊôÇÈñìÈÄèÊûê„ÅåÂèØËÉΩ„Åß
„Åô„ÄÇÂèó‰ªòÊôÇÈñì„ÅØÔºôÊôÇ„Åã„ÇâÔºëÔºñÊôÇ„Åæ„Åß„Åß„Åô„ÄÇÔºàÈÄèÊûê„ÅÆÂÜçÈñãÔºâ
short dialysis sessions are
(Restart of dialysis sessions:
available at the Iwaki Urology Clinique between 9 AM and
4 PM.)
Problem report: „Åî„ÇÅ„Çì„Å™„Åï„ÅÑÊã°Êï£„Çí„ÅäÈ°ò„ÅÑ„Åó„Å¶„ÇÇ„ÅÑ„ÅÑ„Åß
„Åô„Åã„ÄÇ‰ªôÂè∞„ÅÆÁà∂Ë¶™„ÅÆË©±„Åß„Åô„Å®Êê∫Â∏Ø„ÅÆÂÖÖÈõª„Åå„ÇÇ„ÅÜ„Å™„ÅÑ‰∫∫„Åå
Á∂öÂá∫„Åó„Å¶„ÅÑ„Çã„Åù„ÅÜ„Åß„Åô„ÄÇÊê∫Â∏ØÂÖÖÈõªÂô®„ÅÆÊîØÊè¥„ÅåÂøÖË¶Å„Åã„Å®ÊÄù
„Çè„Çå„Åæ„Åô„ÄÇ
(Please spread this message. According to my father in
Sendai, there are more and more people whose phones ran
out of battery. We need phone chargers!)
Aid message: „ÄêÊã°Êï£Â∏åÊúõ„Äë‰ªôÂè∞Ëã•ÊûóÂå∫ÂΩπÊâÄ„ÅßÊê∫Â∏ØÈõªË©±„ÅÆ
ÂÖÖÈõª„Åå„Åß„Åç„Çã„Åù„ÅÜ„Åß„Åô„ÄÇ
([Please spread] At the City Hall of Wakabayashi-ku, Sendai,
you can recharge your phone battery.)

Table 7: Examples from the output of the proposed
method in the ‚Äòall‚Äô setting. Problem report and aid
message nuclei are boldfaced in the English trans-
lations.

The

performance

TR&EX was 8,484 and 7,363, respectively.
PROPOSED
in
assessed

and
of
PROPOSED-TR&EX were
two
settings: ‚Äòall‚Äô and ‚Äòunseen‚Äô. For ‚Äòall‚Äô, we selected
400 problem-aid matches from the outputs of the
respective systems after applying the 10-match
restriction. For ‚Äòunseen‚Äô, Ô¨Årst we removed the
samples from the systems‚Äô outputs if either the
nucleus noun or template pair appear in the nuclei
of the problem-aid match recognizers‚Äô training
data. Next we applied the same sampling process
as with ‚Äòall‚Äô. Three annotators (other than the
authors) manually labeled the sample sets, Ô¨Ånal
judgment being made by majority vote. The
Fleiss‚Äô kappa score for all test data was 0.73
(substantial agreement).

Figure 3 shows the systems‚Äô precision curves,
drawn from the samples whose X-axis positions
represent the ranks according to SVM scores. In
both scenarios we can conÔ¨Årm that excitation po-
larity and trouble expression related features con-
tribute to this task.
In the ‚Äòall‚Äô setting in terms
of average precision calculated over the top 7,200
matches, PROPOSED‚Äôs 62.36% is 10.48 points
higher than that of PROPOSED-TR&EX. For un-
seen problem/aid nuclei PROPOSED method‚Äôs av-
erage precision of 58.57% calculated at the top
3,800 matches is 5.47 points higher than that of
PROPOSED-TR&EX at the same data point. The
improvement in precision when using TR&EX is

statistically signiÔ¨Åcant in both settings (p < 0.01).

6 Related Work
Twitter has been observed as a platform for situ-
ational awareness during various crisis situations
(Starbird et al., 2010; Vieweg et al., 2010), as sen-
sors for an earthquake reporting system (Sakaki et
al., 2010; Okazaki and Matsuo, 2010) or to de-
tect epidemics (Aramaki et al., 2011). Besides
Twitter, blogs or forums have also been the tar-
get of community response analysis (Qu et al.,
2009; Torrey et al., 2007). Similar to our work
are the ones of Neubig et al. (2011) and Ishino et
al. (2012), who tackle speciÔ¨Åc problems that occur
during disasters (i.e., safety information and trans-
portation information, respectively); and Munro
(2011), who extracted ‚Äúactionable messages‚Äù (re-
quests and aids, indiscriminately), matching being
performed manually. Our work differs from (Neu-
big et al., 2011) and (Ishino et al., 2012) in that we
do not restrict the range of problem reports, and as
opposed to (Munro, 2011), matching is automatic.
Systems such as that of Seki (2011)11 or Munro
(2013)12 are successful examples of crisis crowd-
sourcing, but these require extensive human inter-
vention to coordinate useful information.

Another category of related work relevant to our
task is troubleshooting. Baldwin et al. (2007) and
Raghavan et al. (2010) use discussion forums to
solve technical problems using supervised learn-
ing methods, but these approaches presume that
the solution of a speciÔ¨Åc problem is within the
same thread. In our work we do not employ struc-
tural characteristics of tweets as restrictions (e.g.,
a problem report and its aid message need to be in
the same tweet chain).

7 Conclusions
In this paper, we proposed a method to dis-
cover matches between problem reports and aid
messages from tweets in large-scale disasters.
Through a series of experiments, we demonstrated
that the performance of the problem-aid match-
ing can be improved with the usage of seman-
tic orientation of excitation polarities, proposed in
(Hashimoto et al., 2012), and trouble expressions.
We are planning to deploy our system and re-
lease model Ô¨Åles of the classiÔ¨Åers to assist relief
efforts in future crisis scenarios.

11http://www.sinsai.info/
12http://www.mission4636.org/

1628

References
Adam Acar and Yuya Muraki. 2011. Twitter for cri-
sis communication: Lessons learned from Japan‚Äôs
tsunami disaster.
International Journal of Web
Based Communities, 7(3):392‚Äì402.

Eiji Aramaki, Sachiko Maskawa, and Mizuki Morita.
2011. Twitter catches the Ô¨Çu: Detecting inÔ¨Çuenza
epidemics using Twitter. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP 2011), pages 1568‚Äì1576.

Timothy Baldwin, David Martinez, and Richard B.
Penman. 2007. Automatic thread classiÔ¨Åcation for
Linux user forum information access. In Proceed-
ings of the 12th Australasian Document Computing
Symposium (ADCS 2007), pages 72‚Äì79.

Stijn De Saeger, Kentaro Torisawa, and Jun‚Äôichi
Kazama. 2008. Looking for trouble. In Proceed-
ings of the 22nd International Conference on Com-
putational Linguistics (COLING 2008), pages 185‚Äì
192.

Stijn De Saeger, Kentaro Torisawa, Masaaki Tsuchida,
Jun‚Äôichi Kazama, Chikara Hashimoto, Ichiro Ya-
mada, Jong-Hoon Oh, Istv¬¥an Varga, and Yulan Yan.
2011. Relation acquisition using word classes and
partial patterns.
In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP 2011), pages 825‚Äì835.

Joseph L. Fleiss.

1971. Measuring nominal scale
agreement among many raters. Psychological Bul-
letin, 5:378‚Äì382.

Chikara Hashimoto, Kentaro Torisawa,

Stijn
De Saeger, Jong-Hoon Oh, and Jun‚Äôichi Kazama.
2012. Excitatory or inhibitory: A new semantic
orientation extracts contradiction and causality from
the web. In Proceedings of the 2012 Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning (EMNLP-CoNLL 2012), pages 619‚Äì630.

Aya Ishino, Shuhei Odawara, Hidetsugu Nanba, and
Toshiyuki Takezawa. 2012. Extracting transporta-
tion information and trafÔ¨Åc problems from tweets
during a disaster: Where do you evacuate to?
In
Proceedings of the Second International Conference
on Advances in Information Mining and Manage-
ment (IMMM 2012), pages 91‚Äì96.

Hiroshi Kanayama and Tetsuya Nasukawa. 2008. Tex-
tual demand analysis: Detection of users‚Äô wants and
needs from opinions. In Proceedings of the 22nd In-
ternational Conference on Computational Linguis-
tics (COLING 2008), pages 409‚Äì416.

Jun‚Äôichi Kazama and Kentaro Torisawa. 2008. Induc-
ing gazetteers for named entity recognition by large-
scale clustering of dependency relations.
In Pro-
ceedings of the 46th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies (ACL-08: HLT), pages 407‚Äì
415.

Jun‚Äôichi Kazama, Stijn De Saeger, Kow Kuroda,
Masaki Murata, and Kentaro Torisawa. 2010. A
Bayesian method for robust estimation of distribu-
tional similarities.
In Proceedings of the 48th An-
nual Meeting of the Association for Computational
Linguistics (ACL 2010), pages 247‚Äì256.

Jun‚Äôichi Kazama, Stijn De Saeger, Kentaro Torisawa,
Jun Goto, and Istv¬¥an Varga. 2013. Saigaiji jouhou
e no shitsumon outo shisutemu no tekiyou no koko-
romi. (An attempt for applying question-answering
system on disaster related information).
In Pro-
ceeding of the Nineteenth Annual Meeting of The
Association for Natural Language Processing. (in
Japanese).

Benjamin Mandel, Aron Culotta, John Boulahanis,
Danielle Stark, Bonnie Lewis, and Jeremy Rodrigue.
2012. A demographic analysis of online sentiment
during Hurricane Irene. In Proceedings of the Sec-
ond Workshop on Language Analysis in Social Me-
dia (LASM 2012), pages 27‚Äì36.

Robert Munro.

2011.

Subword and spatiotempo-
ral models for identifying actionable information in
Haitian Kreyol.
In Proceedings of the Fifteenth
Conference on Computational Natural Language
Learning (CoNLL-2011), pages 68‚Äì77.

Robert Munro.

2013.

crisis-affected community.
16(2):210‚Äì266.

Crowdsourcing and the
Information Retrieval,

Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi.
2010. Dependency tree-based sentiment classiÔ¨Åca-
tion using CRFs with hidden variables. In Human
Language Technologies: The 2010 Annual Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics (NAACL HLT
2010), pages 786‚Äì794.

National Police Agency of Japan. 2013. Damage sit-
uation and public countermeasures associated with
2011 Tohoku district ‚Äì off the PaciÔ¨Åc Ocean Earth-
quake. http://www.npa.go.jp/archive/
keibi/biki/higaijokyo_e.pdf. (accessed
on 30 April, 2013).

Graham Neubig, Yuichiroh Matsubayashi, Masato
Hagiwara, and Koji Murakami. 2011. Safety infor-
mation mining ‚Äï what can NLP do in a disaster ‚Äï.
In Proceedings of the 5th International Joint Con-
ference on Natural Language Processing (IJCNLP
2011), pages 965‚Äì973.

Jong-Hoon Oh, Kentaro Torisawa, Chikara Hashimoto,
Takuya Kawada, Stijn De Saeger, Jun‚Äôichi Kazama,
and Yiou Wang. 2012. Why question answering
using sentiment analysis and word classes. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL 2012), pages 368‚Äì378.

1629

Jong-Hoon Oh, Kentaro Torisawa, Chikara Hashimoto,
Motoki Sano, Stijn De Saeger, and Kiyonori Ohtake.
2013. Why-question answering using intra- and
inter-sentential causal relations.
In Proceedings of
the 51st Annual Meeting of the Association for Com-
putational Linguistics (ACL 2013).

Kate Starbird, Leysia Palen, Amanda L. Hughes, and
Sarah Vieweg. 2010. Chatter on the red: What
hazards threat reveals about the social life of mi-
croblogged information.
In Proceedings of The
2010 ACM Conference on Computer Supported Co-
operative Work (CSCW 2010), pages 241‚Äì250.

Cristen Torrey, Moira Burke, Matthew L. Lee,
Anind K. Dey, Susan R. Fussell, and Sara B. Kiesler.
2007. Connected giving: Ordinary people coordi-
nating disaster relief on the Internet. In Proceedings
of the 40th Annual Hawaii International Conference
on System Sciences (HICSS-40), pages 179‚Äì188.

Katerina Tsagkalidou, Vassiliki Koutsonikola, Athena
Vakali, and Konstantinos Kafetsios. 2011. Emo-
tional aware clustering on micro-blogging sources.
In Proceedings of the 4th international conference
on Affective computing and intelligent interaction
(ACII 2011), pages 387‚Äì396.

Sarah Vieweg, Amanda L. Hughes, Kate Starbird, and
Leysia Palen. 2010. Microblogging during two nat-
ural hazards events: What Twitter may contribute
to situational awareness.
In Proceedings of the
SIGCHI Conference on Human Factors in Comput-
ing Systems (CHI 2010), pages 1079‚Äì1088.

Patrick Winn. 2011. Japan tsunami disaster: As Japan

scrambles, Twitter reigns. GlobalPost, 18 March.

2013.

Kiyonori Ohtake, Kentaro Torisawa, Jun Goto, and
Stijn De Saeger.
Saigaiji ni okeru hi-
saisha to kyuuen kyuujosha kan no souhoko komyu-
nikeeshon. (Bi-directional communication between
victims and rescures during a crisis). In Proceeding
of the Nineteenth Annual Meeting of The Association
for Natural Language Processing. (in Japanese).

Makoto Okazaki and Yutaka Matsuo. 2010. Seman-
tic Twitter: Analyzing tweets for real-time event
notiÔ¨Åcation.
In Proceedings of the 2008/2009 in-
ternational conference on Social software: Re-
cent trends and developments in social software
(BlogTalk 2008), pages 63‚Äì74.

R. Lyman Ott and Michael T. Longnecker, 2010. An
Introduction to Statistical Methods and Data Analy-
sis, chapter 10.2. Brooks Cole, 6th edition.

Yan Qu, Philip Fei Wu, and Xiaoqing Wang. 2009.
Online community response to major disaster: A
study of Tianya forum in the 2008 Sichuan Earth-
quake.
In 42st Hawaii International International
Conference on Systems Science (HICSS-42), pages
1‚Äì11.

Preethi Raghavan, Rose Catherine, Shajith Ikbal,
Nanda Kambhatla, and Debapriyo Majumdar. 2010.
Extracting problem and resolution information from
online discussion forums.
In Proceedings of the
16th International Conference on Management of
Data (COMAD 2010).

Takeo Saijo. 2012. Hito-o tasukeru sungoi shikumi. (A
stunning system that saves people). Diamond Inc.
(in Japanese).

Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.
2010. Earthquake shakes Twitter users: Real-time
event detection by social sensors.
In Proceedings
of the 19th International Conference on World Wide
Web (WWW 2010), pages 851‚Äì860.

Motoki Sano, Istv¬¥an Varga, Jun‚Äôichi Kazama, and Ken-
2012. Requests in tweets dur-
taro Torisawa.
ing a crisis: A systemic functional analysis of
tweets on the Great East Japan Earthquake and
the Fukushima Daiichi nuclear disaster.
In Pa-
pers from the 39th International Systemic Func-
tional Congress (ISFC39), pages 135‚Äì140.

Haruyuki Seki. 2011. Higashi-nihon daishinsai fukkou
shien platform sinsai.info no naritachi to kongo no
kadai. (The organizational structure of sinsai.info
restoration support platform for the 2011 Great East
Japan Earthquake and future challenges). Journal of
digital practices, 2(4):237‚Äì241. (in Japanese).

