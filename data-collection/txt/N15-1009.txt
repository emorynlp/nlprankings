



















































Weakly Supervised Slot Tagging with Partially Labeled Sequences from Web Search Click Logs


Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 84–92,
Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics

Weakly Supervised Slot Tagging with Partially Labeled Sequences from Web
Search Click Logs

Young-Bum Kim† Minwoo Jeong† Karl Stratos‡ Ruhi Sarikaya†

†Microsoft Corporation, Redmond, WA
‡Columbia University, New York, NY

{ybkim, minwoo.jeong, ruhi.sarikaya}@microsoft.com
stratos@cs.columbia.edu

Abstract

In this paper, we apply a weakly-supervised
learning approach for slot tagging using con-
ditional random fields by exploiting web
search click logs. We extend the constrained
lattice training of Täckström et al. (2013) to
non-linear conditional random fields in which
latent variables mediate between observations
and labels. When combined with a novel
initialization scheme that leverages unlabeled
data, we show that our method gives signifi-
cant improvement over strong supervised and
weakly-supervised baselines.

1 Introduction

A key problem in natural language processing
(NLP) is to effectively utilize large amounts of unla-
beled and partially labeled data in situations where
little or no annotations are available for a task of
interest. Many recent work tackled this problem
mostly in the context of part-of-speech (POS) tag-
ging by transferring POS tags from a supervised lan-
guage via automatic alignment and/or constructing
tag dictionaries from the web (Das and Petrov, 2011;
Li et al., 2012; Täckström et al., 2013).

In this work, we attack this problem in the con-
text of slot tagging, where the goal is to find correct
semantic segmentation of a given query, which is an
important task for information extraction and natu-
ral language understanding. For instance, answering
the question “when is the new bill murray movie re-
lease date?” requires recognizing and labeling key
phrases: e.g., “bill murray” as actor and “movie”
as media type.

The standard approach to slot tagging involves
training a sequence model such as a conditional ran-
dom field (CRF) on manually annotated data. An
obvious limitation of this approach is that it relies
on fully labeled data, which is both difficult to adapt
and changing tasks and schemas. Certain films,
songs, and books become more or less popular over
time, and the performance of models trained on out-
dated data will degrade. If not updated, models
trained on live data feeds such as movies, songs and
books become obsolete over time and their accuracy
will degrade. In order to achieve high accuracy con-
tinuously data and even model schemas have to be
refreshed on a regular basis.

To remedy this limitation, we propose a weakly
supervised framework that utilizes the information
available in web click logs. A web click log is a
mapping from a user query to URL link. For ex-
ample, users issuing queries about movies tend to
click on links from the IMDB.com or rottentoma-
toes.com, which provide rich structured data for en-
tities such as title of the movie (“The Matrix”), the
director (“The Wachowski Brothers”), and the re-
lease date (“1999”). Web click logs present an op-
portunity to learn semantic tagging models from
large-scale and naturally occurring user interaction
data (Volkova et al., 2013).

While some previous works (Li et al., 2009) have
applied a similar strategy to incorporate click logs
in slot tagging, they do not employ recent advances
in machine learning to effectively leverage the in-
complete annotations. In this paper, we pursue and
extend learning from partially labeled sequences, in
particular the approach of Täckström et al. (2013).

84



Instead of projecting labels from a high-resource to
a low-resource languages via parallel text and word
alignment, we project annotations from structured
data found in click logs. This can be seen as a bene-
fit since typically a much larger volume of click log
data is available than parallel text for low-resource
languages.

We also extend the constrained lattice training
method of Täckström et al. (2013) from linear CRFs
to non-linear CRFs. We propose a perceptron train-
ing method for hidden unit CRFs (Maaten et al.,
2011) that allows us to train with partially labeled
sequences. We show that combined with a novel pre-
training methodology that leverages large quantities
of unlabeled data, this training method achieves sig-
nificant improvements over several strong baselines.

2 Model definitions and training methods

In this section, we describe the two sequence mod-
els in our experiments: a conditional random field
(CRF) of Lafferty et al. (2001) and a hidden unit
CRF (HUCRF) of Maaten et al. (2011). Note that
since we only have partially labeled sequences, we
need a technique to learn from incomplete data. For
a CRF, we follow a variant of the training method
of Täckström et al. (2013). In addition, we make
a novel extension of their method to train a HU-
CRF from partially labeled sequences. The result-
ing perceptron-style algorithm (Figure 2) is simple
but effective. Furthermore, we propose an initializa-
tion scheme that naturally leverages unlabeled data
for training a HUCRF.

2.1 Partially Observed CRF
A first-order CRF parametrized by θ ∈ Rd de-
fines a conditional probability of a label sequence
y = y1 . . . yn given an observation sequence x =
x1 . . . xn as follows:

pθ(y|x) = exp(θ
>Φ(x, y))∑

y′∈Y(x) exp(θ>Φ(x, y′))

where Y(x) is the set of all possible label se-
quences for x and Φ(x, y) ∈ Rd is a global fea-
ture function that decomposes into local feature
functions Φ(x, y) =

∑n
j=1 φ(x, j, yj−1, yj) by the

first-order Markovian assumption. Given fully la-
beled sequences {(x(i), y(i))}Ni=1, the standard train-

ing method is to find θ that maximizes the log like-
lihood of the label sequences under the model with
l2-regularization:

θ∗ = arg max
θ∈Rd

N∑
i=1

log pθ(y(i)|x(i))− λ2 ||θ||
2

Unfortunately, in our problem we do not have fully
labeled sequences. Instead, for each token xj in se-
quence x1 . . . xn we have the following two sources
of label information:

• A set of allowed label types Y(xj). (Label dic-
tionary)

• A label ỹj transferred from a source data. (Op-
tional: transferred label)

Täckström et al. (2013) propose a different objec-
tive that allows training a CRF in this scenario. To
this end, they define a constrained lattice Y(x, ỹ) =
Y(x1, ỹ1)× . . .× Y(xn, ỹn) where at each position
j a set of allowed label types is given as:

Y(xj , ỹj) =
{ {ỹj} if ỹj is given
Y(xj) otherwise

In addition to these existing constraints, we intro-
duce constraints on the label structure. In our seg-
mentation problem, labels are structured (e.g., some
label types cannot follow certain others). We can
easily incorporate this restriction by disallowing in-
valid label types as a post-processing step of the
form:

Y(xj , ỹj)← Y(xj , ỹj) ∩ Y(xj−1, ỹj−1)

where Y(xj−1, ỹj−1) is the set of valid label types
that can follow Y(xj−1, ỹj−1).

Täckström et al. (2013) define a conditional prob-
ability over label lattices for a given observation se-
quence x:

pθ(Y(x, ỹ)|x) =
∑

y∈Y(x,ỹ)
pθ(y|x)

Given a label dictionary Y(xj) for every token type
xj and training sequences {(x(i), ỹ(i))}Ni=1 where
ỹ(i) is (possibly non-existent) transferred labels for

85



Figure 1: Illustration of CRFs and hidden unit CRFs

x(i) and, the new training method is to find θ that
maximizes the log likelihood of the label lattices:

θ∗ = arg max
θ∈Rd

N∑
i=1

log pθ(Y(x(i), ỹ(i))|x(i))− λ2 ||θ||
2

Since this objective is non-convex, we find a local
optimum with a gradient-based algorithm. The gra-
dient of this objective at each example (x(i), ỹ(i))
takes an intuitive form:

∂

∂θ
log pθ(Y(x(i), ỹ(i))|x(i))− λ2 ||θ||

2

=
∑

y∈Y(x(i),ỹ)
pθ(y|x(i))Φ(x(i), y)

−
∑

y∈Y(x(i))
pθ(y|x(i))Φ(x(i), y)− λθ

This is the same as the standard CRF training except
the first term where the gold features Φ(x(i), y(i))
are replaced by the expected value of features in the
constrained lattice Y(x(i), ỹ).
2.2 Partially Observed HUCRF

While effective, a CRF is still a linear model. To see
if we can benefit from nonlinearity, we use a HU-
CRF (Maaten et al., 2011): a CRF that introduces a

layer of binary-valued hidden units z = z1 . . . zn ∈
{0, 1} for each pair of label sequence y = y1 . . . yn
and observation sequence x = x1 . . . xn. A HUCRF
parametrized by θ ∈ Rd and γ ∈ Rd′ defines a joint
probability of y and z conditioned on x as follows:

pθ,γ(y, z|x) =
exp(θ>Φ(x, z) + γ>Ψ(z, y))∑

z′∈{0,1}n
y′∈Y(x,z′)

exp(θ>Φ(x, z′) + γ>Ψ(z′, y′))

where Y(x, z) is the set of all possible label se-
quences for x and z, and Φ(x, z) ∈ Rd and
Ψ(z, y) ∈ Rd′ are global feature functions that de-
compose into local feature functions:

Φ(x, z) =
n∑
j=1

φ(x, j, zj)

Ψ(z, y) =
n∑
j=1

ψ(zj , yj−1, yj)

In other words, it forces the interaction between
the observations and the labels at each position j to
go through a latent variable zj : see Figure 1 for il-
lustration. Then the probability of labels y is given
by marginalizing over the hidden units,

pθ,γ(y|x) =
∑

z∈{0,1}n
pθ,γ(y, z|x)

As in restricted Boltzmann machines (Larochelle
and Bengio, 2008), hidden units are conditionally
independent given observations and labels. This al-
lows for efficient inference with HUCRFs despite
their richness (see Maaten et al. (2011) for details).

2.2.1 Training with partially labeled sequences
We extend the perceptron training method of Maaten
et al. (2011) to train a HUCRF from partially labeled
sequences. This can be viewed as a modification of
the constrained lattice training method of Täckström
et al. (2013) for HUCRFs.

A sketch of our training algorithm is shown in
Figure 2. At each example, we predict the most
likely label sequence with the current parameters. If
this sequence does not violate the given constrained
lattice, we make no updates. If it does, we pre-
dict the most likely label sequence within the con-

86



Input: constrained lattices {(x(i), ỹ(i))}Ni=1, step size η
Output: HUCRF parameters Θ := {θ, γ}

1. Initialize Θ randomly.

2. Repeatedly select i ∈ {1 . . . N} at random:
(a) y∗ ← arg maxy∈Y(x(i)) pΘ(y|x(i))
(b) If y∗ 6∈ Y(x(i), ỹ(i)):

i. y+ ← arg maxy∈Y(x(i),ỹ(i)) pΘ(y|x(i))
ii. Make parameter updates:

Θ← Θ + η × ∂
∂Θ

(
pΘ(y+, z+|x(i))−

pΘ(y∗, z∗|x(i))
)

where the following hidden units are com-
puted in closed-form (see Gelfand et al.
(2010)):

z+ := arg max
z

pΘ(z|x(i), y+)

z∗ := arg max
z

pΘ(z|x(i), y∗)

Figure 2: A sketch of the perceptron training algorithm
for a partially observed hidden unit CRF.

strained lattice. We treat this as the gold label se-
quence, and perform the perceptron updates accord-
ingly (Gelfand et al., 2010). Even though this train-
ing algorithm is quite simple, we demonstrate its ef-
fectiveness in our experiments.

2.2.2 Initialization from unlabeled data
Rather than initializing the model parameters ran-

domly, we propose an effective initialization scheme
(in a similar spirit to the pre-training methods in neu-
ral networks) that naturally leverages unlabeled data.

First, we cluster observation types in unlabeled
data and treat the clusters as labels. Then we train
a fully supervised HUCRF on this clustered data to
learn parameters θ for the interaction between obser-
vations and hidden units Φ(x, z) and γ for the inter-
action between hidden units and labels Φ(z, y). Fi-
nally, for task/domain specific training, we discard
γ and use the learned θ to initialize the algorithm in
Figure 2. We hypothesize that if the clusters are non-
trivially correlated to the actual labels, we can cap-
ture the interaction between observations and hidden

units in a meaningful way.

3 Mining Click Log Data

We propose using search click logs which consist
of queries and their corresponding web documents.
Clicks are an implicit signal for related entities and
information in the searched document. In this work,
we will assume that the web document is structured
and generated from an underlying database. Due
to the structured nature of the web, this is not an
unrealistic assumption (see Adamic and Huberman
(2002) for discussion). Such structural regularities
make obtaining annotated queries for learning a se-
mantic slot tagger almost cost-free.

As an illustration of how to project annotation,
consider Figure 3, where we present an example
taken from queries about video games. In the fig-
ure, the user queries are connected to a structured
document via a click log, and then the document is
parsed and stored in a structured format. Then anno-
tation types are projected to linked queries through
structural alignment. In the following subsections
we describe each step in our log mining approach in
detail.

3.1 Click Logs

Web search engines keep a record of search queries,
clicked document and URLs which reveal the user
behavior. Such records are proven to be useful in
improving the quality of web search. We focus on
utilizing query-to-URL click logs that are essentially
a mapping from queries to structured web docu-
ments. In this work, we use a year’s worth of query
logs (from July 2013 to June 2014) at a commercial
search engine. We applied a simple URL normaliza-
tion procedure to our log data including trimming
and removal of prefixes, e.g. “www”.

3.2 Parsing Structured Web Document

A simple wrapper induction algorithm described in
Kushmerick (1997) is applied for parsing web docu-
ments. Although it involves manually engineering a
rule-based parser and is therefore website-specific, a
single wrapper often generates large amounts of data
for large structured websites, for example IMDB.
Furthermore, it is very scalable to large quantities of
data, and the cost of writing such a rule-based sys-

87



Figure 3: An example illustrating annotation projection via click-log and wrapper induction.

tem is typically much lower than the annotation cost
of queries.

Figure 4 shows the statistics of parsed web docu-
ments on 24 domains with approximately 500 tem-
plate rules. One of the chosen domains in our ex-
periment, Music, has over 130 million documents
parsed by our approach.

3.3 Annotation Projection via Structural
Alignment

We now turn to the annotation projection step where
structural alignment is used to transfer type annota-
tion from structured data to queries. Note that this is
different from the word-based or phrase-based align-
ment scenario in machine translation since we need
to align a word sequence to a type-value pair.

Let us assume that we are given the user query as
a word sequence, w = w1, w2, . . . , wn and a set of
structured data, s = {s1, s2, . . . , sm}, where si is
a pair of slot-type and value. We define a measure-
ment of dissimilarity between word tokens and slots,
dist(wi, sj) = 1 − sim(wi, sj) where sim(·, ·) is
cosine similarity over character trigrams of wi and
sj . Next we construct a n-by-n score matrix S of
which element is maxj dist(wt′...t, sj) meaning that
a score of the most similar type-value sj and a seg-
ment {t′ . . . t} where 1 ≤ t′ < t ≤ n. Finally,
given this approximate score matrix S, we use a dy-
namic programming algorithm to find the optimal
segments to minimize the objective function:

T (t) = min
t′<t

T (t′)S(t′, t).

Our approach results in a large amount of high-

quality partially-labeled data: 314K, 1.2M, and
1.1M queries for the Game, Movie and Music do-
main, respectively.

4 Experiments

To test the effectiveness of our approach, we per-
form experiments on a suite of three entertainment
domains for slot tagging: queries about movies, mu-
sic, and games. For each domain, we have two types
of data: engineered data and log data. Engineered
data is a set of synthetic queries to mimic the be-
havior of users. This data is created during devel-
opment at which time no log data is available. Log
data is a set of queries created by actual users us-
ing deployed spoken dialogue systems: thus it is di-
rectly transcribed from users’ voice commands with
automatic speech recognition (ASR). In general we
found log data to be fairly noisy, containing many
ASR and grammatical errors, whereas engineered
data consisted of clean, well-formed text.

Not surprisingly, synthetic queries in engineered
data are not necessarily representative of real queries
in log data since it is difficult to accurately simu-
late what users’ queries will be before a fully func-
tioning system is available and real user data can
be gathered. Hence this setting can greatly benefit
from weakly-supervised learning methods such as
ours since it is critical to learn from new incoming
log data. We use search engine log data to project
lattice constraints for weakly supervised learning.

In this setup, a user issues a natural language
query to retrieve movies, music titles, games and/or
information there of. For instance, a user could say

88



M
ill

io
ns

1
2

5
10
20

50
100
200

500

Bu
sin

es
s

Pe
op

le

Co
ns

um
er

_P
ro

du
ct

Vi
de

o

M
us

ic

Im
ag

e

Bu
sin

es
s_

Lis
tin

g

Ev
en

t_
Lis

tin
g

Tra
ve

l

Bo
ok

Pe
op

le_
Lis

tin
g

Pu
bli

ca
tio

n
Fo

od

Ap
pli

ca
tio

n
Fi

lm

Co
m

pu
te

r

Lo
ca

tio
n_

Re
fer

en
ce

Di
nin

g
TV

Ev
en

t

Pr
op

er
ty_

Lis
tin

g

At
tra

cti
on

Co
un

try

Vi
de

o_
Ga

m
e

Figure 4: Statistics of structured web documents. The vertical axis shows the number of documents (in millions); the
horizontal axis shows the web domain types.

“play the latest batman movie” or “find beyonce’s
music”. Our slot sequence tagger is trained with
variants of CRF using lexical features, gazetteers,
Brown clusters and context words. The domains
consist of 35 slot types for movies, 25 for music and
24 for games. Slot types correspond to both named
entities (e.g., game name, music title, movie name)
as well as more general categories (genre, media
type, description). Table 1 shows the size of the
datasets used in our experiments.

Domains Training Test
games 32017 5508
movies 48173 7074
music 46377 8890

Table 1: Labeled data set size for games, movies and mu-
sic domains partitioned into training and test set.

Domains Engineered Log Diff.
games 89.63 68.58 21.05
movies 88.67 74.21 14.45
music 88.77 37.13 51.64
AVG. 89.02 59.97 29.05

Table 2: The difference in F1 performance of CRF mod-
els trained only on engineered data but tested on both en-
gineered and log data.

4.1 Discrepancy between Engineered Data and
Log Data

To empirically highlight the need for learning from
real user queries, we first train a standard CRF on
the (fully labeled) engineered data and test it on the
log data. We have manually annotated some log data
for evaluation purposes. For features in the CRF, we
use n-grams, gazetteer, and clusters. The clusters
were induced from a large body of unlabeled data
which consist of log data and click log data. Table 2
shows the F1 scores in this experiment. They indi-
cate that a model fully supervised with engineered
data performs very poorly on log data. The differ-
ence between the scores within engineered data and
the scores in log data is very large (29.05 absolute
F1).

4.2 Experiments with CRF Variants
Our main contribution is to leverage search log data
to improve slot tagging in spoken dialogue systems.
In this section, we assume that we have no log data
in training slot taggers.1

For parameter estimation, both CRFs and
POCRFs employ L-BFGS, while POHUCRF uses

1In practice, this assumption is not necessarily true because
a deployed system can benefit from actual user logs. However,
this controlled setting allows us to show the benefits of employ-
ing web search click log data.

89



Domains games music movies AVG.
CRF 74.21 37.13 68.58 59.97

POCRF 77.23 44.55 76.89 66.22
POHCRF 78.93 46.81 76.46 67.40

POHCRF+ 79.28 47.35 78.33 68.32

Table 3: The F1 performance of variants of CRF across
three domains, test on log data

average perceptron. We did not see a significant dif-
ference between perceptron and LBFGS in accuracy,
but perceptron is faster and thus favorable for train-
ing complex HUCRF models. We used 100 as the
maximum iteration count and 1.0 for the L2 regular-
ization parameter. The number of hidden variables
per token is set to 300. The same features described
in the previous section are used here.

We perform experiments with the following CRF
variants (see Section 2):

• CRF: A fully supervised linear-chain CRF
trained with manually labeled engineered sam-
ples.

• POCRF: A partially observed CRF of
Täckström et al. (2013) trained with both
manually labeled engineered samples and click
logs.

• POHUCRF: A partially observed hidden unit
CRF (Figure 2) trained with both manually la-
beled engineered samples and click logs.

• POHUCRF+: POHUCRF with pre-training.

Table 3 summarizes the performance of these
CRF variants. All results were tested on log data
only. A standard CRF without click log data yields
59.97% of F1 on average. By using click log data,
POCRF consistently improves F1 scores across do-
mains, resulting into 66.22% F1 measure. Our
model POHUCRF achieves extra gains on games
and music, achieving 67.4% F1 measure on aver-
age. Finally, the pre-training approach yields signif-
icant additional gains across all domains, achieving
68.32% average performance. Overall we achieve
a relative error reduction of about 21% over vanilla
CRFs.

Domain CRF HUCRF HUCRF+
alarm 91.79 91.79 91.96

calendar 87.60 87.65 88.21
communication 91.84 92.49 92.80

note 87.72 88.48 88.72
ondevice 89.37 90.14 90.64

places 88.02 88.64 88.99
reminder 87.72 89.21 89.72
weather 96.93 97.38 97.63
AVG. 90.12 90.75 91.08

Table 4: Performance comparison between HUCRF and
HUCRF with pre-training.

4.3 Weakly-Supervised Learning without
Projected Annotations via Pre-Training

We also present experiments within Cortana per-
sonal assistant domain where the click log data is
not available. The amount of training data we used
was from 50K to 100K across different domains and
the test data was from 5k to 10k. In addition, the
unlabeled log data were used and their amount was
from 100k to 200k.

In this scenario, we have access to both engi-
neered and log data to train a model. However, we
do not have access to web search click log data. The
goal of these experiments is to show the effective-
ness of the HUCRF and pre-training method in the
absence of weakly supervised labels projected via
click logs. Table 4 shows a series of experiments on
eight domains.

For all domains other than alarm, using non-linear
CRF (HUCRF) improve performance from 90.12%
to 90.75% on average. Initializing HUCRF with pre-
training (HUCRF+) boosts the performance up to
91.08%, corresponding to a 10% decrease in error
relative to a original CRF. Notably in the weather
and reminder domains, we have relative error re-
duction of 23 and 16%, respectively. We speculate
that pretraining is helpful because it provides bet-
ter initialization for training HUCRF: initialization
is important since the training objective of HUCRF
is non-convex.

In general, we find that HUCRF delivers better
performance than standard CRF: when the training
procedure is initialized with pretraining (HUCRF+),
it improves further.

90



5 Related Work

Previous works have explored weakly supervised
slot tagging using aligned labels from a database as
constraints. Wu and Weld (2007) train a CRF on
heuristically annotated Wikipedia articles with rela-
tions mentioned in their structured infobox data. Li
et al. (2009) applied a similar strategy incorporating
structured data projected through click-log data as
both heuristic labels and additional features. Knowl-
edge graphs and search logs have been also consid-
ered as extra resources (Liu et al., 2013; El-Kahky et
al., 2014; Anastasakos et al., 2014; Sarikaya et al.,
2014; Marin et al., 2014).

Distant supervision methods (Mintz et al., 2009;
Riedel et al., 2010; Surdeanu et al., 2012; Agichtein
and Gravano, 2000) learn to extract relations from
text using weak supervision from related structured
data sources such as Freebase or Wikipedia. These
approaches rely on named entity recognition as a
pre-processing step to identify text spans corre-
sponding to candidate slot values. In contrast, our
approach jointly segments and predicts slots.

Works on weakly supervised POS tagging are
also closely related to ours (Toutanova and Johnson,
2007; Haghighi and Klein, 2006). Täckström et al.
(2013) investigate weakly supervised POS tagging
in low-resource languages, combining dictionary
constraints and labels projected across languages via
parallel corpora and automatic alignment. Our work
can be seen as an extension of their approach to the
structured-data projection setup presented by Li et
al. (2009). A notable component of our extension is
that we introduce a training algorithm for learning a
hidden unit CRF of Maaten et al. (2011) from par-
tially labeled sequences. This model has a set of bi-
nary latent variables that introduce non-linearity by
mediating between observations and labels.

6 Conclusions

In this paper, we applied weakly-supervised learn-
ing approach for slot tagging, projecting annota-
tions from structured data to user queries by lever-
aging click log data. We extended the Täckström
et al. (2013) model to nonlinear CRFs by introduc-
ing latent variables and applying a novel pre-training
methodology. The proposed techniques provide an
effective way to leverage incomplete and ambiguous

annotations from large amounts of naturally occur-
ring click log data. All of our improvements taken
together result in a 21% error reduction over vanilla
CRFs trained on engineered data used during system
development.

References

Lada A Adamic and Bernardo A Huberman. 2002. Zipfs
law and the internet. Glottometrics, 3(1):143–150.

Eugene Agichtein and Luis Gravano. 2000. Snowball:
Extracting relations from large plain-text collections.
In Proceedings of the fifth ACM conference on Digital
libraries.

Tasos Anastasakos, Young-Bum Kim, and Anoop Deo-
ras. 2014. Task specific continuous word represen-
tations for mono and multi-lingual spoken language
understanding. In Acoustics, Speech and Signal Pro-
cessing (ICASSP), 2014 IEEE International Confer-
ence on, pages 3246–3250. IEEE.

Dipanjan Das and Slav Petrov. 2011. Unsupervised
part-of-speech tagging with bilingual graph-based pro-
jections. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies-Volume 1, pages 600–
609. Association for Computational Linguistics.

Ali El-Kahky, Xiaohu Liu, Ruhi Sarikaya, Gokhan Tur,
Dilek Hakkani-Tur, and Larry Heck. 2014. Extend-
ing domain coverage of language understanding sys-
tems via intent transfer between domains using knowl-
edge graphs and search query click logs. In Acoustics,
Speech and Signal Processing (ICASSP), 2014 IEEE
International Conference on, pages 4067–4071. IEEE.

Andrew Gelfand, Yutian Chen, Laurens Maaten, and Max
Welling. 2010. On herding and the perceptron cycling
theorem. In Advances in Neural Information Process-
ing Systems, pages 694–702.

Aria Haghighi and Dan Klein. 2006. Prototype-driven
learning for sequence models. In Proceedings of
the main conference on Human Language Technology
Conference of the North American Chapter of the As-
sociation of Computational Linguistics.

Nicholas Kushmerick. 1997. Wrapper induction for
information extraction. Ph.D. thesis, University of
Washington.

John Lafferty, Andrew McCallum, and Fernando CN
Pereira. 2001. Conditional random fields: Probabilis-
tic models for segmenting and labeling sequence data.
In Proceedings of the 18th International Conference
on Machine Learning, pages 282–289.

Hugo Larochelle and Yoshua Bengio. 2008. Classifi-
cation using discriminative restricted boltzmann ma-

91



chines. In Proceedings of the 25th international con-
ference on Machine learning.

Xiao Li, Ye-Yi Wang, and Alex Acero. 2009. Extracting
structured information from user queries with semi-
supervised conditional random fields. In Proceedings
of the 32nd international ACM SIGIR conference on
Research and development in information retrieval.

Shen Li, Joao V Graça, and Ben Taskar. 2012. Wiki-
ly supervised part-of-speech tagging. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 1389–1398. Asso-
ciation for Computational Linguistics.

Xiaohu Liu, Ruhi Sarikaya, Chris Brockett, Chris Quirk,
William B Dolan, and Bill Dolan. 2013. Paraphrase
features to improve natural language understanding.
In INTERSPEECH, pages 3776–3779.

Laurens Maaten, Max Welling, and Lawrence K Saul.
2011. Hidden-unit conditional random fields. In In-
ternational Conference on Artificial Intelligence and
Statistics.

Alex Marin, Roman Holenstein, Ruhi Sarikaya, and Mari
Ostendorf. 2014. Learning phrase patterns for text
classification using a knowledge graph and unlabeled
data. In Fifteenth Annual Conference of the Interna-
tional Speech Communication Association.

Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.
2009. Distant supervision for relation extraction with-
out labeled data. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language
Processing of the AFNLP: Volume 2-Volume 2.

Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions with-
out labeled text. In Machine Learning and Knowledge
Discovery in Databases.

Ruhi Sarikaya, Asli Celikyilmaz, Anoop Deoras, and
Minwoo Jeong. 2014. Shrinkage based features for
slot tagging with conditional random fields. In Proc.
of Interspeech.

Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and
Christopher D Manning. 2012. Multi-instance multi-
label learning for relation extraction. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning.

Oscar Täckström, Dipanjan Das, Slav Petrov, Ryan Mc-
Donald, and Joakim Nivre. 2013. Token and type con-
straints for cross-lingual part-of-speech tagging.

Kristina Toutanova and Mark Johnson. 2007. A bayesian
lda-based model for semi-supervised part-of-speech
tagging. In Advances in Neural Information Process-
ing Systems, pages 1521–1528.

Svitlana Volkova, Pallavi Choudhury, Chris Quirk, Bill
Dolan, and Luke S Zettlemoyer. 2013. Lightly super-
vised learning of procedural dialog systems. In ACL.

Fei Wu and Daniel S Weld. 2007. Autonomously se-
mantifying wikipedia. In Proceedings of the sixteenth
ACM conference on Conference on information and
knowledge management.

92


