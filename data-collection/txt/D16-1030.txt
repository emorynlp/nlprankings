



















































TweeTime : A Minimally Supervised Method for Recognizing and Normalizing Time Expressions in Twitter


Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 307–318,
Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics

TweeTime: A Minimally Supervised Method for Recognizing and
Normalizing Time Expressions in Twitter

Jeniya Tabassum, Alan Ritter and Wei Xu
Computer Science and Engineering

Ohio State University
{bintejafar.1,ritter.1492,xu.1265}@osu.edu

Abstract

We describe TweeTIME, a temporal tagger
for recognizing and normalizing time expres-
sions in Twitter. Most previous work in so-
cial media analysis has to rely on tempo-
ral resolvers that are designed for well-edited
text, and therefore suffer from reduced perfor-
mance due to domain mismatch. We present a
minimally supervised method that learns from
large quantities of unlabeled data and requires
no hand-engineered rules or hand-annotated
training corpora. TweeTIME achieves 0.68 F1
score on the end-to-end task of resolving date
expressions, outperforming a broad range of
state-of-the-art systems.1

1 Introduction

Temporal expressions are words or phrases that re-
fer to dates, times or durations. Resolving time ex-
pressions is an important task in information ex-
traction (IE) that enables downstream applications
such as calendars or timelines of events (Derczyn-
ski and Gaizauskas, 2013; Do et al., 2012; Rit-
ter et al., 2012; Ling and Weld, 2010), knowledge
base population (Ji et al., 2011), information re-
trieval (Alonso et al., 2007), automatically schedul-
ing meetings from email and more. Previous work in
this area has applied rule-based systems (Mani and
Wilson, 2000; Bethard, 2013b; Chambers, 2013)
or supervised machine learning on small collections
of hand-annotated news documents (Angeli et al.,
2012; Lee et al., 2014).

1Our code and data are publicly available at https://
github.com/jeniyat/TweeTime.

Figure 1: A tweet published on Friday 5/6/2016 that contains
the temporal expression Monday referring to the date of the

event (5/9/2016), which a generic temporal tagger failed to re-

solve correctly.

Figure 2: A tweet that contains a simple explicit time mention
and an event (Mercury, 5/9/2016) that can be identified by an

open-domain information extraction system.

Social media especially contains time-sensitive
information and requires accurate temporal anal-
ysis, for example, for detecting real-time cyber-
security events (Ritter et al., 2015; Chang et al.,
2016), disease outbreaks (Kanhabua et al., 2012)
and extracting personal information (Schwartz et al.,
2015). However, most work on social media simply
uses generic temporal resolvers and therefore suffers
from suboptimal performance. Recent work on tem-
poral resolution focuses primarily on news articles
and clinical texts (UzZaman et al., 2013; Bethard
and Savova, 2016).

Resolving time expressions in social media is a
non-trivial problem. Besides many spelling varia-
tions, time expressions are more likely to refer to
future dates than in newswire. For the example in

307



Figure 1, we need to recognize that Monday refers
to the upcoming Monday and not the previous one
to resolve to its correct normalized date (5/9/2016).
We also need to identify that the word Sun is not re-
ferring to a Sunday in this context.

In this paper, we present a new minimally super-
vised approach to temporal resolution that requires
no in-domain annotation or hand-crafted rules, in-
stead learning from large quantities of unlabeled text
in conjunction with a database of known events. Our
approach is capable of learning robust time expres-
sion models adapted to the informal style of text
found on social media.

For popular events, some related tweets (e.g. Fig-
ure 2) may contain explicit or other simple time
mentions that can be captured by a generic temporal
tagger. An open-domain information extraction sys-
tem (Ritter et al., 2012) can then identify events (e.g.
[Mercury, 5/9/2016]) by aggregating those tweets.
To automatically generate temporally annotated data
for training, we make the following novel distant su-
pervision assumption:2

Tweets posted near the time of a known
event that mention central entities are
likely to contain time expressions that re-
fer to the date of the event.

Based on this assumption, tweets that contain the
same named entity (e.g. Figure 1) are heuristically
labeled as training data. Each tweet is associated
with multiple overlapping labels that indicate the
day of the week, day of the month, whether the event
is in the past or future and other time properties of
the event date in relation to the tweet’s creation date.
In order to learn a tagger that can recognize temporal
expressions at the word-level, we present a multiple-
instance learning approach to model sentence and
word-level tags jointly and handle overlapping la-
bels. Using heuristically labeled data and the tem-
poral tags predicted by the multiple-instance learn-
ing model as input, we then train a log-linear model
that normalizes time expressions to calendar dates.

Building on top of the multiple-instance learn-
ing model, we further improve performance using

2We focus on resolving dates, arguably the most important
and frequent category of time expressions in social media data,
and leave other phenomenon such as times and durations to tra-
ditional methods or future work.

a missing data model that addresses the problem of
errors introduced during the heuristic labeling pro-
cess. Our best model achieves a 0.68 F1 score when
resolving date mentions in Twitter. This is a 17%
increase over SUTime (Chang and Manning, 2012),
outperforming other state-of-the-art time expression
resolvers HeidelTime (Strötgen and Gertz, 2013),
TempEX (Mani and Wilson, 2000) and UWTime
(Lee et al., 2014) as well. Our approach also pro-
duces a confidence score that allows us to trade re-
call for precision. To the best of our knowledge,
TweeTIME is the first time resolver designed specif-
ically for social media data.3 This is also the first
time that distant supervision is successfully applied
for end-to-end temporal recognition and normaliza-
tion. Previous distant supervision approaches (An-
geli et al., 2012; Angeli and Uszkoreit, 2013) only
address the normalization problem, assuming gold
time mentions are available at test time.

2 System Overview

Our TweeTIME system consists of two major com-
ponents as shown in Figure 3:

1. A Temporal Recognizer which identifies time
expressions (e.g. Monday) in English text and
outputs 5 different temporal types (described in
Table 1) indicating timeline direction, month of
year, date of month, day of week or no temporal
information (NA). It is realized as a multiple-
instance learning model, and in an enhanced
version, as a missing data model.

2. A Temporal Normalizer that takes a tweet
with its creation time and temporal expressions
tagged by the above step as input, and out-
puts their normalized forms (e.g. Monday →
5/9/2016). It is a log-linear model that uses
both lexical features and temporal tags.

To train these two models without corpora man-
ually annotated with time expressions, we leverage
a large database of known events as distant super-
vision. The event database is extracted automati-
cally from Twitter using the open-domain IE system

3The closest work is HeidelTime’s colloquial English ver-
sion (Strötgen and Gertz, 2012) developed from annotated SMS
data and slang dictionary. Our TweeTIME significantly outper-
forms on Twitter data.

308



[RECOGNIZER]

[NORMALIZER]

[EVENT EXTRACTOR]

NER

TempEx

ENTITY DATE
Mercury 5/9/2016

… …
… …

distant 
labeling

model
training

[EVENT DATABASE]

(simple time expressions)

(more and harder time expressions)

LABELS:   DOW=Monday, MOY=May

Figure 3: TweeTIME system diagram of model training.

Temporal Types Possible Values (tags)
Timeline (TL) past, present, future

Day of Week (DOW) Mon, Tue, . . . , Sun
Day of Month (DOM) 1, 2, 3, . . . , 31
Month of Year (MOY) Jan, Feb, . . . , Dec

None (NA) NA
Table 1: Our Temporal Recognizer can extract five different
temporal types and assign one of their values to each word of a

tweet.

proposed by Ritter et al. (2012). Each event con-
sists of one or more named entities, in addition to
the date on which the event takes place, for exam-
ple [Mercury, 5/9/2016]. Tweets are first processed
by a Twitter named entity recognizer (Ritter et al.,
2011), and a generic date resolver (Mani and Wil-
son, 2000). Events are then extracted based on the
strength of association between each named entity
and calendar date, as measured by a G2 test on their
co-occurrence counts. More details of the Event Ex-
tractor can be found in Section 5.1.

The following two sections describe the details of
our Temporal Recognizer and Temporal Normal-
izer separately.

3 Distant Supervision for Recognizing
Time Expressions

The goal of the recognizer is to predict the tempo-
ral tag of each word, given a sentence (or a tweet)
w = w1, . . . , wn. We propose a multiple-instance

learning model and a missing data model that are
capable of learning word-level taggers given only
sentence-level labels.

Our recognizer module in is built using a database
of known events as distant supervision. We assume
tweets published around the time of a known event
that mention a central entity are also likely to contain
time expressions referring to the event’s date. For
each event, such as [Mercury, 5/9/2016], we gather
all tweets that contain the central entity Mercury and
are posted within 7 days of 5/9/2016. We then la-
bel each tweet based on the event date in addition to
the tweet’s creation date. The sentence-level tempo-
ral tags for the tweet in Figure 1 are: TL=future,
DOW=Mon, DOM=9, MOY=May.

3.1 Multiple-Instance Learning Temporal
Tagging Model (MultiT)

Unlike supervised learning, where labeled instances
are provided to the learner, in multiple instance
learning scenarios (Dietterich et al., 1997), the
learner is only provided with bags of instances la-
beled as either positive (where at least one instance
is positive) or all negative. This is a close match to
our problem setting, in which sentences are labeled
with tags that should be assigned to one or more
words.

We represent sentences and their labels using
a graphical model that is divided into word-level
and sentence-level variables (as shown in Figure
4). Unlike the standard supervised tagging prob-

309



z1 z2

…

Watch Mercury Pass In Front Of Sun Monday

z3 z4 z5 z6 z7 z8

t1 t2 tk

Figure 4: Multiple-Instance Learning Temporal Tagging Model
– our approach to learn a word-level tagging model given only

sentence-level labels. In this example a sentence-level vari-

able ta = 1 indicates the temporal tag DOW=Mon must be

present and tb = 1 indicates that the target date is in the future

(TL=future). The multiple instance learning assumption im-

plies that at least one word must be tagged with each of these

present temporal tags. For example, ideally after training, the

model will learn to assign z8 to tag a and z1 to tag b.

lem, we never directly observe the words’ tags (z =
z1, . . . , zn) during learning. Instead, they are la-
tent and we only observe the date of an event men-
tioned in the text, from which we derive sentence-
level binary variables t = t1, . . . , tk corresponding
to temporal tags for the sentence. Following previ-
ous work on multiple-instance learning (Hoffmann
et al., 2011a; Xu et al., 2014), we model the connec-
tion between sentence-level labels and word-level
tags using a set of deterministic-OR factors φsent.

The overall conditional probability of our model
is defined as:

P (t, z|w;θr)

=
1

Z

k∏

i=1

φsent(ti, z)×
n∏

j=1

φword(zj , wj)

=
1

Z

k∏

i=1

φsent(ti, z)×
n∏

j=1

eθ
r ·f(zj ,wj)

(1)

where f(zj , wj) is a feature vector and

φsent(ti, z) =





1 if ti = true ∧ ∃j : zj = i
1 if ti = false ∧ ∀j : zj 6= i
0 otherwise

(2)
We include a standard set of tagging features that

includes word shape and identity in addition to pre-
fixes and suffixes. To learn parameters θr of the
Temporal Tagger, we maximize the likelihood of the
sentence-level heuristic labels conditioned on ob-
served words over all tweets in the training corpus.
Given a training instance w with label t, the gradient
of the conditional log-likelihood with respect to the
parameters is:

∇P (t|w) =
∑

z
P (z|w, t;θr) · f(z,w)

−
∑

t,z
P (t, z|w;θr) · f(z,w)

(3)

This gradient is the difference of two conditional ex-
pectations over the feature vector f: a “clamped” ex-
pectation that is conditioned on the observed words
and tags (w, t) and a “free” expectation that is only
conditioned on the words in the text, w, and ignores
the sentence-level labels. To make the inference
tractable, we use a Viterbi approximation that re-
places the expectations with maximization. Because
each sentence corresponds to more than one tempo-
ral tag, the maximization of the “clamped” maxi-
mization is somewhat challenging to compute. We
use the approximate inference algorithm of Hoff-
mann et al. (2011a), that views inference as a
weighted set cover problem, with worst case running
time (|T | · |W |), where |T | is the number of all pos-
sible temporal tag values and |W | is the number of
words in a sentence.

3.2 Missing Data Temporal Tagging Model
(MiDaT)

While the multiple-instance learning assumption
works well much of the time, it can easily be vio-
lated – there are many tweets that mention entities
involved in an event but that never explicitly men-
tion its date.

The missing data modeling approach to weakly
supervised learning proposed by Ritter et. al. (2013)
addresses this problem by relaxing the hard con-
straints of deterministic-OR factors, such as those
described above, as soft constraints. Our missing-
data model for weakly supervised tagging splits the
sentence-level variables, t into two parts : m which
represents whether a temporal tag is mentioned by at
least one word of the tweet, and t′ which represents

310



whether a temporal tag can be derived from the event
date. A set of pairwise potentials ψ(mj , t′j) are in-
troduced that encourage (but don’t strictly require)
agreement between mj and t′j , that is:

ψ(mj , t
′
j) =

{
αp, if t′j 6= mj
αr, if t′j = mj

(4)

Here, αp (Penalty), and αr (Reward) are param-
eters for the MiDaT model. αp is the penalty for
extracting a temporal tag that is not related to the
event-date and αr is the reward for extracting a tag
that matches the date.

During learning, if the local classifier is very con-
fident, it is possible for a word to be labeled with a
tag that is not derived from the event-date, and also
for a sentence-level tag to be ignored, although ei-
ther case will be penalized by the agreement poten-
tials, ψ(mj , t′j), in the global objective. We use a
local-search approach to inference that was empiri-
cally demonstrated to nearly always yield exact so-
lutions by Ritter et. al. (2013).

4 A Log-Linear Model for Normalizing
Time Expressions

The Temporal Normalizer is built using a log-linear
model which takes the tags t produced by the Tem-
poral Recognizer as input and outputs one or more
dates mentioned in a tweet. We formulate date nor-
malization as a binary classification problem: given
a tweet w published on date dpub, we consider 22
candidate target dates (w, dcandl ) such that d

cand
l =

dpub + l, where l = −10, . . . ,−1, 0,+1, . . . ,+10,
limiting the possible date references that are consid-
ered within 10 days before or after the tweet creation
date, in addition to dcandl = null (the tweet does not
mention a date). 4 While our basic approach has the
limitation, that it is only able to predict dates within
±10 days of the target date, we found that in prac-
tice the majority of date references on social media
fall within this window. Our approach is also able to
score dates outside this range that are generated by
traditional approaches to resolving time expressions,
as described in Section 5.3.3.

4Although the temporal recognizer is trained with tweets
from ±7 days around the event date, we found that extending
the candidate date range to ±10 days for the temporal normal-
izer increased the performance of TweeTIME in the dev set.

The normalizer is similarly trained using the event
database as distant supervision. The probability that
a tweet mentions a candidate date is estimated using
a log-linear model:

P (dcand|w, dpub) ∝ eθn·g(w,dpub,t) (5)
where θn and g are the parameter and feature vector
respectively in the Temporal Normalizer. For every
tweet and candidate date pair (w, dcandl ), we extract
the following set of features:

Temporal Tag Features that indicate whether
the candidate date agrees with the temporal tags
extracted by the Temporal Recognizer. Three cases
can happen here: The recognizer can extract a tag
that can not be derived from the candidate date;
The recognizer can miss a tag derived from the
candidate date; The recognizer can extract a tag that
is derived from the candidate date.

Lexical Features that include two types of binary
features from the tweet: 1) Word Tag features
consist of conjunctions of words in the tweet and
tags associated with the candidate date. We remove
URLs, stop words and punctuation; 2) Word POS
features that are the same as above, but include
conjunctions of POS tags, words and temporal tags
derived from the candidate date.

Time Difference Features are numerical features
that indicate the distance between the creation date
and the candidate date. They include difference of
day ranges form -10 to 10 and the difference of week
ranges from -2 to 2.

5 Experiments

In the following sub-sections we present experi-
mental results on learning to resolve time expres-
sions in Twitter using minimal supervision. We start
by describing our dataset, and proceed to present
our results, including a large-scale evaluation on
heuristically-labeled data and an evaluation compar-
ing against human judgements.

5.1 Data Collection
We collected around 120 million tweets posted in a
one year window starting from April 2011 to May
2012. These tweets were automatically annotated
with named entities, POS tags and TempEx dates
(Ritter et al., 2011).

311



From this automatically-annotated corpus we ex-
tract the top 10, 000 events and their correspond-
ing dates using the G2 test, which measures the
strength of association between an entity and date
using the log-likelihood ratio between a model in
which the entity is conditioned on the date and a
model of independence (Ritter et al., 2012). Events
extracted using this approach then simply consist
of the highest-scoring entity-date pairs, for example
[Mercury, 5/9/2016].

After automatically extracting the database of
events, we next gather all tweets that mention an
entity from the list that are also written within ±7
days of the event. These tweets and the dates of
the known events serve as labeled examples that are
likely to mention a known date.

We also include a set of pseudo-negative exam-
ples, that are unlikely to refer to any event, by gath-
ering a random sample of tweets that do not men-
tion any of the top 10, 000 events and where TempEx
does not extract any date.

5.2 Large-Scale Heuristic Evaluation

We first evaluate our tagging model, by testing how
well it can predict the heuristically generated labels.
As noted in previous work on distant supervision
(Mintz et al., 2009a), this type of evaluation usu-
ally under-estimates precision, however it provides
us with a useful intrinsic measure of performance.

In order to provide even coverage of months in the
training and test set, we divide the twitter corpus into
3 subsets based on the mod-5 week of each tweet’s
creation date. To train system we use tweets that
are created in 1st, 2nd or 3rd weeks. To tune pa-
rameters of the MiDaT model we used tweets from
5th weeks, and to evaluate the performance of the
trained model we used tweets from 4th weeks.

Precision Recall F-value
MultiT 0.61 0.21 0.32
MiDaT 0.67 0.31 0.42

Table 2: Performance comparison of MultiT and MiDaT at pre-
dicting heuristically generated tags on the dev set.

The performance of the MiDaT model varies with
the penalty and reward parameters. To find a (near)
optimal setting of the values we performed a grid
search on the dev set and found that a penalty of

−25 and reward of 500 works best. A comparison
of MultiT and MiDaT’s performance at predicting
heuristically generated labels is shown in Table 2.

The word level tags predicted by the temporal rec-
ognizer are used as the input to the temporal normal-
izer, which predicts the referenced date from each
tweet. The overall system’s performance at predict-
ing event dates on the automatically generated test
set, compared against SUTime, is shown in Table 3.

System Prec. Recall F-value

dev set
TweeTIME 0.93 0.69 0.79
SUTime 0.89 0.64 0.75

test set
TweeTIME 0.97 0.94 0.96
SUTime 0.85 0.75 0.80

Table 3: Performance comparison of TweeTIME and SUTime
at predicting heuristically labeled normalized dates.

5.3 Evaluation Against Human Judgements
In addition to automatically evaluating our tagger
on a large corpus of heuristically-labeled tweets,
we also evaluate the performance of our tagging
and date-resolution models on a random sample of
tweets taken from a much later time period, that
were manually annotated by the authors.

5.3.1 Word-Level Tags
To evaluate the performance of the MiDaT-tagger

we randomly selected 50 tweets and labeled each
word with its corresponding tag. Against this hand
annotated test set, MiDaT achieves Precision=0.54,
Recall=0.45 and F-value=0.49. A few examples of
word-level tags predicted by MiDaT are shown in
Table 4. We found that because the tags are learned
as latent variables inferred by our model, they some-
times don’t line up exactly with our intuitions but
still provide useful predictions, for example in Table
4, Christmas is labeled with the tag MOY=dec.

5.3.2 End-to-end Date Resolution
To evaluate the final performance of our system

and compare against existing state-of-the art time
resolvers, we randomly sampled 250 tweets from
2014-2016 and manually annotated them with nor-
malized dates; note that this is a separate date range
from our weakly-labeled training data which is taken
from 2011-2012. We use 50 tweets as a develop-
ment set and the remaining 200 as a final test set.

312



Tweets and their corresponding word tags (wordtag)
ImNA hellaNA excitedfuture forNA tomorrowfuture

KickNA offNA theNA Newfuture Yearfuture RightNA @NA #ClubLacuraNA #FRIDAYfri !NA

HOSTEDNA BYNA [[NA DCNA YoungNA FlyNA ]]NA

@OxfordTownHallNA ThksNA forNA aNA topNA nightNA atNA ourNA Christmasdec partyNA onNA Fri!fri

ComplimentsNA toNA chef!NA (RoseNA melonNA cantaloupeNA :)NA

ImNA proudNA toNA sayNA thatNA INA breathedpast theNA sameNA airNA asNA HarryNA onNA Marchmar

21,21 2015.NA #KCANA #Vote1DUKNA

C’monpresent let’spresent jackNA Tonightpresent willNA bepresent aNA nightNA toNA remember.NA

Table 4: Example MiDaT tagging output on the test set.

Precision Recall F-value
TweeTIME 0.61 0.81 0.70
- Day Diff. 0.46 0.72 0.56
- Lexical&POS 0.48 0.80 0.60
- Week Diff. 0.49 0.85 0.62
- Lexical 0.50 0.88 0.64
- Temporal Tag 0.57 0.83 0.68

Table 5: Feature ablation of the Temporal Resolver by remov-
ing each individual feature group from the full set.

System Prec. Recall F-value

dev
set

TweeTIME 0.61 0.81 0.70
TweeTIME+SU 0.67 0.83 0.74
SUTime 0.51 0.86 0.64
TempEx 0.58 0.64 0.61
HeidelTime 0.57 0.63 0.60
UWTime 0.49 0.57 0.53

test
set

TweeTIME 0.58 0.70 0.63
TweeTIME+SU 0.62 0.76 0.68
SUTime 0.54 0.64 0.58
TempEx 0.56 0.58 0.57
HeidelTime 0.43 0.52 0.47
UWTime 0.39 0.50 0.44

Table 6: Performance comparison of TweeTIME against state-
of-the-art temporal taggers. TweeTIME+SU uses our proposed

approach to system combination, re-scoring output from SU-

Time using extracted features and learned parameters from

TweeTIME.

We experimented with different feature sets on the
development data. Feature ablation experiments are
presented in Table 5.

The final performance of our system, compared
against a range of state-of-the-art time resolvers is
presented in Table 6. We see that TweeTIME out-

0.0 0.2 0.4 0.6 0.8 1.0

Recall

0.0

0.2

0.4

0.6

0.8

1.0

P
re

ci
si

o
n

TweeTIME

SUTime

HeidelTime

TempEX

UWTime

Figure 5: Precision and recall at resolving time expressions
compared against human judgements. TweeTIME achieves

higher precision at comparable recall than other state-of-the-art

systems.

performs SUTime, Tempex, HeidelTime (using its
COLLOQUIAL mode, which is designed for SMS
text) and UWTime. Brief descriptions of each sys-
tem can be found in Section 6.

5.3.3 System Combination with SUTime
As our basic TweeTIME system is designed to

predict dates within ±10 days of the creation date,
it fails when a tweet refers to a date outside this
range. To overcome this limitation we append the
date predicted by SUTime in the list of candidate
days. We then re-rank SUTime’s predictions using
our log-linear model, and include its output as a pre-
dicted date if the confidence of our normalizer is suf-
ficiently high.

5.3.4 Error Analysis
We manually examined the system outputs and

found 7 typical categories of errors (see examples
in Table 7):

313



Spelling Variations: 45%

Hashtag: 20%

Tokenization: 15%
Missing Rules: 5%

Ambiguity: 15%

SUTime

Spelling Variations: 30%

Hashtag: 45%

Tokenization: 5%

Missing Rules: 15%

Ambiguity: 5%

HeidelTime

Out of Range: 10%
Ambiguity: 20%

Over−Prediction: 70%

TweeTime

Figure 6: Error analyses for different temporal resolvers

Spelling Variation: Twitter users are very creative
in their use of spelling and abbreviations. For ex-
ample, a large number of variations of the word to-
morrow can be found in tweets, including 2morrow,
2mrw, tmrw, 2mrow and so on. Previous temporal
resolvers often fail in these cases, while TweeTIME
significantly reduces such errors.
Ambiguity: In many cases, temporal words like Fri-
day in the tweet Is it Friday yet? may not refer to
any specific event or date, but are often predicted in-
correctly. Also included in this category are cases
where the future and past are confused. For exam-
ple, predicting the past Friday, when it is actually the
coming Friday.
Missing Rule: Cases where specific temporal key-
words, such as April Fools, are not covered by the
rule-based systems.
Tokenization: Traditional systems tend to be very
sensitive to incorrect tokenization and have trouble
to handle expressions such as 9th-december, May
9,2015 or Jan1. For the following Tweet:

JUST IN Delhi high court asks state gov-
ernment to submit data on changes in pol-
lution level since #OddEven rule came
into effect on Jan1

TweeTIME is able to correctly extract 01/01/2016,
whereas HeidelTime, SUTime, TempEX and UW-
Time all failed to extract any dates.
Hashtag: Hashtags can carry temporal information,
for example, #September11. Only our system that is
adapted to social media can resolve these cases.
Out of Range: TweeTIME only predicts dates
within 10 days before or after the tweet. Time ex-
pressions referring to dates outside this range will
not be predicted correctly. System combination with
SUTime (Section 5.3.3) only partially addressed this
problem.

Over-Prediction: Unlike rule-based systems, Twee-
TIME has a tendency to over-predict when there is
no explicit time expression in the tweets, possibly
because of the presence of present tense verbs. Such
mistakes could also happen in some past tense verbs.

Because TweeTIME resolves time expressions us-
ing a very different approach compared to traditional
methods, its distribution of errors is quite distinct, as
illustrated in Figure 6.

6 Related Work

Temporal Resolvers primarily utilize either rule-
based or probabilistic approaches. Notable rule-
based systems such as TempEx (Mani and Wil-
son, 2000), SUTime (Chang and Manning, 2012)
and HeidelTime (Strötgen and Gertz, 2013) pro-
vide particularly competitive performance compared
to the state-of-the-art machine learning methods.
Probabilistic approaches use supervised classifiers
trained on in-domain annotated data (Kolomiyets
and Moens, 2010; Bethard, 2013a; Filannino et al.,
2013) or hybrid with hand-engineered rules (UzZa-
man and Allen, 2010; Lee et al., 2014). UWTime
(Lee et al., 2014) is one of the most recent and com-
petitive systems and uses Combinatory Categorial
Grammar (CCG).

Although the recent research challenge TempEval
(UzZaman et al., 2013; Bethard and Savova, 2016)
offers an evaluation in the clinical domain besides
newswire, most participants used the provided anno-
tated corpus to train supervised models in addition
to employing hand-coded rules. Previous work on
adapting temporal taggers primarily focus on scal-
ing up to more languages. HeidelTime was extended
to multilingual (Strötgen and Gertz, 2015), collo-
quial (SMS) and scientific texts (Strötgen and Gertz,
2012) using dictionaries and additional in-domain

314



Error Category Tweet Gold Date Predicted Date

Spelling I cant believe tmrw is fri..the week flys by 2015-03-06 None (SUTime, Heidel-Time)

Ambiguity RT @Iyaimkatie: Is it Friday yet????? None 2015-12-04 (TweeTime,SUTime, HeidelTime)

Missing Rule #49ers #sanfrancisco 49ers fans should be oh sowary of April Fools pranks 2015-04-01 None (HeidelTime)

Tokenization 100000 - still waiting for that reply from 9th-
december lmao. you’re pretty funny and chill 2015-12-09

None (SUTime, Heidel-
Time)

Hashtag RT @arianatotally: Who listening to the #SAT-
URDAY #Night w/ @AlexAngelo?I’m loving it. 2015-04-11

None (SUTime, Heidel-
Time)

Out of Range
RT @460km: In memory of Constable Christine
Diotte @rcmpgrcpolice EOW: March 12, 2002
#HeroesInLife #HerosEnVie

2002-03-12 2015-03-12 (TweeTime)

Over-Prediction RT @tinatbh: January 2015: this will be my yearDecember 2015: maybe not. None 2015-12-08 (TweeTime)

Table 7: Representative Examples of System (SUTime, HeidelTime, TweeTIME) Errors

annotated data. One existing work used distant su-
pervision (Angeli et al., 2012; Angeli and Uszko-
reit, 2013), but for normalization only, assuming
gold time mentions as input. They used an EM-style
bootstrapping approach and a CKY parser.
Distant Supervision has recently become popu-
lar in natural language processing. Much of the
work has focused on the task of relation extraction
(Craven and Kumlien, 1999; Bunescu and Mooney,
2007; Mintz et al., 2009b; Riedel et al., 2010; Hoff-
mann et al., 2011b; Nguyen and Moschitti, 2011;
Surdeanu et al., 2012; Xu et al., 2013; Ritter et al.,
2013; Angeli et al., 2014). Recent work also shows
exciting results on extracting named entities (Ritter
et al., 2011; Plank et al., 2014), emotions (Purver
and Battersby, 2012), sentiment (Marchetti-Bowick
and Chambers, 2012), as well as finding evidence
in medical publications (Wallace et al., 2016). Our
work is closely related to the joint word-sentence
model that exploits multiple-instance learning for
paraphrase identification (Xu et al., 2014) in Twit-
ter.

7 Conclusions
In this paper, we showed how to learn time re-
solvers from large amounts of unlabeled text, us-
ing a database of known events as distant supervi-
sion. We presented a method for learning a word-
level temporal tagging models from tweets that are
heuristically labeled with only sentence-level labels.
This approach was further extended to account for

the case of missing tags, or temporal properties that
are not explicitly mentioned in the text of a tweet.
These temporal tags were then combined with a va-
riety of other features in a novel date-resolver that
predicts normalized dates referenced in a Tweet. By
learning from large quantities of in-domain data, we
were able to achieve 0.68 F1 score on the end-to-end
time normalization task for social media data, sig-
nificantly outperforming SUTime, TempEx, Heidel-
Time and UWTime on this challenging dataset for
time normalization.

Acknowledgments

We would like to thank the anonymous reviewers
for helpful feedback on a previous draft. This ma-
terial is based upon work supported by the National
Science Foundation under Grant No. IIS-1464128.
Alan Ritter is supported by the Office of the Director
of National Intelligence (ODNI) and the Intelligence
Advanced Research Projects Activity (IARPA) via
the Air Force Research Laboratory (AFRL) contract
number FA8750-16-C-0114. The U.S. Government
is authorized to reproduce and distribute reprints for
Governmental purposes notwithstanding any copy-
right annotation thereon. Disclaimer: The views and
conclusions contained herein are those of the authors
and should not be interpreted as necessarily repre-
senting the official policies or endorsements, either
expressed or implied, of ODNI, IARPA, AFRL, or
the U.S. Government.

315



References

Omar Alonso, Michael Gertz, and Ricardo Baeza-Yates.
2007. On the value of temporal information in infor-
mation retrieval. In ACM SIGIR Forum, volume 41,
pages 35–41. ACM.

Gabor Angeli and Jakob Uszkoreit. 2013. Language-
independent discriminative parsing of temporal ex-
pressions. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguistics
(ACL).

Gabor Angeli, Christopher D Manning, and Daniel Ju-
rafsky. 2012. Parsing time: Learning to interpret time
expressions. In Proceedings of the 2012 Conference
of the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies (NAACL).

Gabor Angeli, Julie Tibshirani, Jean Wu, and Christo-
pher D Manning. 2014. Combining distant and partial
supervision for relation extraction. In Proceedings of
the 2014 Conference on Empirical Methods in Natural
Language Processing (EMNLP).

Steven Bethard and Guergana Savova. 2016. SemEval-
2016 Task 12: Clinical TempEval. In Proceedings of
the 10th International Workshop on Semantic Evalua-
tion (SemEval).

Steven Bethard. 2013a. ClearTK-TimeML: A minimal-
ist approach to TempEval 2013. In Proceedings of the
Seventh International Workshop on Semantic Evalua-
tion (SemEval).

Steven Bethard. 2013b. A synchronous context free
grammar for time normalization. In Proceedings of
the 2013 Conference on Empirical Methods in Natural
Language Processing (EMNLP).

Razvan C. Bunescu and Raymond J. Mooney. 2007.
Learning to extract relations from the Web using min-
imal supervision. In Proceedings of the 45th Annual
Meeting of the Association for Computational Linguis-
tics (ACL).

Nathanael Chambers. 2013. NavyTime: Event and time
ordering from raw text. In Proceedings of the 7th
International Workshop on Semantic Evaluation (Se-
mEval).

Angel X Chang and Christopher D Manning. 2012. SU-
Time: A library for recognizing and normalizing time
expressions. In Proceedings of the 8th International
Conference on Language Resources and Evaluation
(LREC).

Ching-Yun Chang, Zhiyang Teng, and Yue Zhang. 2016.
Expectation-regulated neural model for event mention
extraction. Proccedings of the 2016 Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Technologies (NAACL).

Mark Craven and Johan Kumlien. 1999. Constructing
biological knowledge bases by extracting information
from text sources. In Proceedings of the Seventh Inter-
national Conference on Intelligent Systems for Molec-
ular Biology (ISMB).

Leon Derczynski and Robert J Gaizauskas. 2013. Tem-
poral signals help label temporal relations. In Pro-
ceedings of the 51st Annual Meeting of the Association
for Computational Linguistics (ACL).

Thomas G Dietterich, Richard H Lathrop, and Tomás
Lozano-Pérez. 1997. Solving the multiple instance
problem with axis-parallel rectangles. Artificial intel-
ligence, 89(1).

Quang Xuan Do, Wei Lu, and Dan Roth. 2012. Joint
inference for event timeline construction. In Proceed-
ings of the 2012 Joint Conference on Empirical Meth-
ods in Natural Language Processing and Computa-
tional Natural Language Learning (EMNLP).

Michele Filannino, Gavin Brown, and Goran Nenadic.
2013. ManTIME: Temporal expression identification
and normalization in the TempEval-3 challenge. In
Proceedings of the Seventh International Workshop on
Semantic Evaluation (SemEval).

Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke
Zettlemoyer, and Daniel S. Weld. 2011a. Knowledge-
based weak supervision for information extraction of
overlapping relations. In The 49th Annual Meeting
of the Association for Computational Linguistics: Hu-
man Language Technologies (ACL).

Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke S.
Zettlemoyer, and Daniel S. Weld. 2011b. Knowledge-
based weak supervision for information extraction of
overlapping relations. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics (ACL).

Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-
fitt, and Joe Ellis. 2011. Overview of the tac 2011
knowledge base population track. In Proceedings of
the Fourth Text Analysis Conference (TAC).

Nattiya Kanhabua, Sara Romano, Avaré Stewart, and
Wolfgang Nejdl. 2012. Supporting temporal analyt-
ics for health-related events in microblogs. In Pro-
ceedings of the 21st ACM International Conference on
Information and Knowledge Management (CIKM).

Oleksandr Kolomiyets and Marie-Francine Moens. 2010.
KUL: Recognition and normalization of temporal ex-
pressions. In Proceedings of the 5th International
Workshop on Semantic Evaluation (SemEval).

Kenton Lee, Yoav Artzi, Jesse Dodge, and Luke Zettle-
moyer. 2014. Context-dependent semantic parsing
for time expressions. In Proceedings of 52nd Annual
Meeting of the Association for Computational Linguis-
tics (ACL).

316



Xiao Ling and Daniel S Weld. 2010. Temporal infor-
mation extraction. In Proceedings of the 24th AAAI
Conference on Artificial Intelligence (AAAI).

Inderjeet Mani and George Wilson. 2000. Robust tempo-
ral processing of news. In Proceedings of the 38th An-
nual Meeting on Association for Computational Lin-
guistics (ACL).

Micol Marchetti-Bowick and Nathanael Chambers.
2012. Learning for microblogs with distant supervi-
sion: Political forecasting with Twitter. In Proceed-
ings of the 13th Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL).

Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-
sky. 2009a. Distant supervision for relation extraction
without labeled data. In Proceedings of the Joint Con-
ference of the Association of Computational Linguis-
tics and the International Joint Conference on Natural
Language Processing (ACL-IJCNLP).

Mike Mintz, Steven Bills, Rion Snow, and Daniel Juraf-
sky. 2009b. Distant supervision for relation extrac-
tion without labeled data. In Proceedigns of the 47th
Annual Meeting of the Association for Computational
Linguistics and the 4th International Joint Conference
on Natural Language Processing (ACL).

Truc-Vien T. Nguyen and Alessandro Moschitti. 2011.
End-to-end relation extraction using distant supervi-
sion from external semantic repositories. In Proceed-
ings of the 49th Annual Meeting of the Association for
Computational Linguistics (ACL).

Barbara Plank, Dirk Hovy, Ryan McDonald, and Anders
Søgaard. 2014. Adapting taggers to twitter with not-
so-distant supervision. pages 1783–1792.

Matthew Purver and Stuart Battersby. 2012. Experi-
menting with distant supervision for emotion classi-
fication. In Proceedings of the 13th Conference of
the European Chapter of the Association for Compu-
tational Linguistics (EACL).

Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions without
labeled text. In Proceedigns of the European Confer-
ence on Machine Learning and Principles and Prac-
tice of Knowledge Discovery in Databases (ECML-
PKDD).

Alan Ritter, Mausam, Sam Clark, and Oren Etzioni.
2011. Named entity recognition in Tweets: An ex-
perimental study. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP).

Alan Ritter, Mausam, Oren Etzioni, and Sam Clark.
2012. Open domain event extraction from twitter. In
Proceedings of the 18th ACM SIGKDD international
conference on Knowledge discovery and data mining
(KDD).

Alan Ritter, Luke Zettlemoyer, Mausam, and Oren Et-
zioni. 2013. Modeling missing data in distant su-
pervision for information extraction. Transactions of
the Association for Computational Linguistics (TACL),
1:367–378.

Alan Ritter, Evan Wright, William Casey, and Tom
Mitchell. 2015. Weakly supervised extraction of com-
puter security events from Twitter. In Proceedings of
the 24th International Conference on World Wide Web
(WWW).

H Andrew Schwartz, Greg Park, Maarten Sap, Evan
Weingarten, Johannes Eichstaedt, Margaret Kern,
Jonah Berger, Martin Seligman, and Lyle Ungar.
2015. Extracting human temporal orientation in Face-
book language. In Proceedings of the 2015 Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language
Technologies (NAACL).

Jannik Strötgen and Michael Gertz. 2012. Temporal
tagging on different domains: Challenges, strategies,
and gold standards. In Proceedings of the 8th Interna-
tional Conference on Language Resources and Evalu-
ation (LREC).

Jannik Strötgen and Michael Gertz. 2013. Multilingual
and cross-domain temporal tagging. Language Re-
sources and Evaluation, 47(2):269–298.

Jannik Strötgen and Michael Gertz. 2015. A baseline
temporal tagger for all languages. In Proceedings of
the 2015 Conference on Empirical Methods in Natural
Language Processing (EMNLP).

Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and
Christopher D. Manning. 2012. Multi-instance multi-
label learning for relation extraction. In Proceedings
of the 50th Annual Meeting of the Association for
Computational Linguistics (ACL).

Naushad UzZaman and James F Allen. 2010. TRIPS
and TRIOS system for Tempeval-2: Extracting tem-
poral information from text. In Proceedings of the 5th
International Workshop on Semantic Evaluation (Se-
mEval).

Naushad UzZaman, Hector Llorens, James Allen, Leon
Derczynski, Marc Verhagen, and James Pustejovsky.
2013. SemEval-2013 Task 1: TEMPEVAL-3: Evalu-
ating time expressions, events, and temporal relations.
In Proceedings of the 7th International Workshop on
Semantic Evaluation (SemEval).

Byron C Wallace, Joël Kuiper, Aakash Sharma,
Mingxi Brian Zhu, and Iain J Marshall. 2016. Extract-
ing PICO sentences from clinical trial reports using
supervised distant supervision. Journal of Machine
Learning Research (JMLR).

Wei Xu, Raphael Hoffmann, Zhao Le, and Ralph Grish-
man. 2013. Filling knowledge base gaps for distant

317



supervision of relation extraction. In Proceedings of
the 51th Annual Meeting of the Association for Com-
putational Linguistics (ACL).

Wei Xu, Alan Ritter, Chris Callison-Burch, William B.
Dolan, and Yangfeng Ji. 2014. Extracting lexically
divergent paraphrases from Twitter. Transactions of
the Association for Computational Linguistics (TACL),
2(1).

318


