



















































Conversational Decision-Making Model for Predicting the Kingâ€™s Decision in the Annals of the Joseon Dynasty


Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 956â€“961
Brussels, Belgium, October 31 - November 4, 2018. cÂ©2018 Association for Computational Linguistics

956

Conversational Decision-Making Model for Predicting the Kingâ€™s Decision
in the Annals of the Joseon Dynasty

JinYeong Bak
School of Computing

KAIST
Republic of Korea

jy.bak@kaist.ac.kr

Alice Oh
School of Computing

KAIST
Republic of Korea

alice.oh@kaist.edu

Abstract

Styles of leaders when they make decisions in
groups vary, and the different styles affect the
performance of the group. To understand the
key words and speakers associated with de-
cisions, we initially formalize the problem as
one of predicting leadersâ€™ decisions from dis-
cussion with group members. As a dataset, we
introduce conversational meeting records from
a historical corpus, and develop a hierarchical
RNN structure with attention and pre-trained
speaker embedding in the form of a, Conversa-
tional Decision Making Model (CDMM). The
CDMM outperforms other baselines to pre-
dict leadersâ€™ final decisions from the data. We
explain why CDMM works better than other
methods by showing the key words and speak-
ers discovered from the attentions as evidence.

1 Introduction

Decision making in groups refers to the process of
making choices to resolve issues by discussing the
issues with group members (Lunenburg, 2011).
It has various styles based on the balance of
the participation between the leader and mem-
bers from autocratic, democratic, laissez-faire (let
go) to delegation types of groups (Lewin et al.,
1939; Vroom and Jago, 1988). Social psycholo-
gists note that decision making affects the group
performance and the satisfaction of its members
(Yang, 2010), and that leadership plays a role (Lar-
son Jr et al., 1998). In this paper, we study the key
factors that are closely related to the decision mak-
ing process used by leaders.

First, we build conversational meeting records
from The Annals of the Joseon Dynasty (hence-
forth referred to as the AJD), after which, we for-
malize our research problem as predicting lead-
ersâ€™ decisions in conversational discussions from
the data (Sec 2). The AJD consists of the records
of kings who governed the Korean peninsula from

Facts
Official A

King

Official B

Official C

Meta
information

Title
Time

â€œI propose 
combining two 
local districts.â€

Combining two local districts

â€œIt is a hard problem.â€

â€œIt is reasonable to 
combine the regions.â€

â€œI propose another 
solution.â€

The king follows 
Official Câ€™s suggestion.

Figure 1: Screenshot and structure of an article in
the annals of the Joseon dynasty

1392 to 1910. In the AJD, the kings discuss the
issues with government officials and decide upon
a course of action. Many discussion corpora are
available such as Augmented Multi-party Interac-
tion (AMI) (Carletta et al., 2005) which is meeting
recordings as video, and are used to identify and
summarize decisions in the conversation (Hsueh
and Moore, 2007; FernaÌndez et al., 2008; Bui
et al., 2009). However, the AJD has more speakers
than AMI, and it is a longitudinal corpus spanning
over 400 years.

To predict the decisions in the corpus, we de-
velop a model which we term the Conversa-
tional Decision-Making Model (CDMM) (Sec 3).
CDMM is based on the hierarchical RNN struc-
ture with attention (Yang et al., 2016), but we add
speaker information with pre-trained embedding.
We also devise a way to make the speaker em-
bedding using co-occurrence document network
(Sec 3.3). In comparison with several other meth-
ods, CDMM shows the highest macro-averaged F1
score (Sec 4). We also show why CDMM works
better with key words and speakers by examining
the attention values (Sec 5).



957

Kings Articles Utterances Participants

15 13,216 95,615 4,502

(a) Basic statistics of the corpus

Order 1,996 Accept 1,457
Approve 2,245 Reject 818
Disapprove 468 Discuss 6,214

(b) Distribution of articles over decisions

Table 1: Statistics of a conversational meeting
records and kingâ€™s decisions from the AJD

2 Meeting Records from the AJD

Historiographers recorded the behaviors of kings
and events in the country, and compiled these
records as books when the king died or abdicated
the throne. Each article of the AJD consists of the
time, title, body and meta-information such as cat-
egories.

Meeting articles in the AJD consist of who said
what on an issue in dialogue form, and the kingâ€™s
decision. Figure 1 shows an example of a meeting
record article1. In the article, the king and govern-
ment officials discuss the issue of combining two
local regions. The king asks for a solution to the
issue from the officials, and they state their opin-
ions. At the end of the article, the king decided to
follow official Câ€™s suggestion to solve this issue.

We build a corpus from the AJD using the fol-
lowing process. We crawl the AJD website to re-
trieve the documents and select articles that have
three or more speakers per document. We identify
the kingâ€™s final decision in each article by examin-
ing the final sentence and the title as summarized
by historians. We initially determine whether or
not the final sentence of the subject is that by a
king, as some issues are dealt with by others, such
as the kingâ€™s mother. We also extract the verbs in
the final sentence and the title that indicates the
decisions. From these, we categorize each kingâ€™s
decisions into six types: Order, Approve, Disap-
prove, Accept and Reject. Some articles include a
discussion of an issue, but the kingâ€™s final decision
is not explicitly recorded or the king postpones the
decision. We treat this type of decision as Discuss,
i.e., the sixth category. Finally, we choose fifteen
kings with more than 200 articles that have his fi-
nal decisions. Table 1 shows the basic statistics of

1http://sillok.history.go.kr/id/kda_
10103027_005

ğ‘‘ğ‘‘

Softmax

ğ›¼ğ›¼1 ğ›¼ğ›¼2
ğ›¼ğ›¼ğ‘ˆğ‘ˆ

â„1

â„1

â„2

â„2

â„ğ‘ˆğ‘ˆ

â„ğ‘ˆğ‘ˆ

ğ‘ ğ‘ 2ğ‘¢ğ‘¢2ğ‘ ğ‘ 1ğ‘¢ğ‘¢1 ğ‘ ğ‘ ğ‘ˆğ‘ˆğ‘¢ğ‘¢ğ‘ˆğ‘ˆ
ğ›¼ğ›¼21 ğ›¼ğ›¼22 ğ›¼ğ›¼2ğ‘‡ğ‘‡

â„21

â„21

â„22

â„22

â„2ğ‘‡ğ‘‡

â„2ğ‘‡ğ‘‡

ğ‘¤ğ‘¤22ğ‘¤ğ‘¤21 ğ‘¤ğ‘¤2ğ‘‡ğ‘‡

Word 
encoder

Word 
attention

Utterance 
encoder

Utterance
attention

Final decision

Word embedding Speaker embedding Embeddings

Figure 2: Conversational Decision-Making Model

our meeting records data from the AJD.

3 Conversational Decision Making
Model

This section describes our model, the Con-
versational Decision-Making Model (CDMM),
for identifying leadersâ€™ decisions from meeting
records. CDMM is based on the Hierarchical At-
tention Network (HAN) (Yang et al., 2016), but
we change the sentence level to the utterance level
and use speaker information (described in Section
3.2). To encode the speaker information, we build
the speaker embedding from co-occurrence docu-
ment network (described in Section 3.3).

3.1 Word Encoder

To encode the t-th word of i-th utterance xit,
t âˆˆ {1, . . . , T}, we initially change the word xit to
word vector wit using the word embedding matrix
Ww, wit = Wwxit. We use a bi-directional GRU
(Bahdanau et al., 2014), and concatenate the hid-
den states hit = [

âˆ’â†’
hit;
â†âˆ’
hit]. Then, we use the atten-

tion mechanism in HAN to find important words
to classify the decision. Each word has an atten-
tion value Î±it, and we compute the utterance word
vector, ui =

âˆ‘T
t=1 Î±ithit.

3.2 Utterance Encoder with Speaker

In CDMM, the i-th utterance has word sequence
representation vector ui and speaker vector si.
First, we change the speaker zi to vector si using

http://sillok.history.go.kr/id/kda_10103027_005
http://sillok.history.go.kr/id/kda_10103027_005


958

the speaker embedding matrix Ws, si = Wszi. To
encode a length U of the utterances (ui, si), i âˆˆ
{1, . . . , U}, we suggest encoders based on GRU
(Bahdanau et al., 2014), which can learn ui and si
simultaneously, as follows:

hi = (1âˆ’ zi)ï¿½ hiâˆ’1 + zi ï¿½ hÌƒi
zi = Ïƒ(Wzuui +Wzssi + Uzhiâˆ’1 + bz)

ri = Ïƒ(Wruui +Wrssi + Urhiâˆ’1 + br)

hÌƒi = tanh(Whuui +Whssi + ri ï¿½ (Uhhiâˆ’1) + bh)

Here, hi is the i-th utterance hidden state, and zi
and ri denote the update and reset gate, respec-
tively. This is similar to earlier work (Li et al.,
2016), but we add the speaker vector to the utter-
ance level, not the word level.

As in the word encoder, we use the bi-
directional GRU with the utterance encoder and
concatenate the hidden states hi = [

âˆ’â†’
hi ;
â†âˆ’
hi ]. We

use the same attention mechanism to find impor-
tant utterances. Each utterance has an attention
value of Î±i, and for the conversation vector we use
d =

âˆ‘U
i=1 Î±ihi.

With vector d, CDMM predicts the decision us-
ing softmax p = softmax(Wcd + bc), and a
dropout scheme (Srivastava et al., 2014) to avoid
over-fitting.

3.3 Pre-trained Speaker Embedding

Unlike word embedding which is pre-trained from
news or Wikipedia articles (Mikolov et al., 2013;
Bojanowski et al., 2017), pre-trained speaker em-
bedding for the AJD does not exist. To overcome
this limitation, we suggest the building of speaker
embedding from the co-occurrence document net-
work in the AJD. The AJD contains not only meet-
ing records but also personnel management re-
ports and explanations of the officials. We there-
fore build a co-occurrence network. The vertices
are people, and two individuals are connected if
they appear in the same article. The weight of
the edge is the number of co-occurrences in the
same article. With this network, we realize speaker
embedding using the node2vec algorithm (Grover
and Leskovec, 2016), which generates node vector
representation.

4 Experiments

This section describes the experiments and results
of CDMM as well as other methods for classifying
the kingâ€™s decisions in the AJD.

4.1 Experiment Setting
We split the data as 80/10/10 for train-
ing/validation/test. Because the meeting records
contain fifteen kings, we split the data randomly
for each king and merge each part into the entire
training, validation and test set.

We compare CDMM with the following meth-
ods. The majority of classes predicts all test exam-
ples as the major class, Discuss. We apply Naive
Bayes and the SVM with the linear kernel. To use
these methods, we remove words whose document
frequency is smaller than twenty. To see the power
of the speaker information, we run these baselines
on words and speaker features together. We also
run fastText (Joulin et al., 2017), which is a clas-
sifier with n-gram features and hierarchical soft-
max, and is similar to CBOW (Mikolov et al.,
2013). We use pre-trained Korean word vectors2

(Grave et al., 2018) to fastText and CDMM. We
create the speaker embedding from the AJD. For a
fair comparison, we exclude the valid and test ar-
ticles to construct the co-occurrence network. We
use node2vec implementation3 for speaker embed-
ding. We set the GRU hidden state size to 200, the
dimension of the speaker embedding to 200 and
the dropout probability to 0.5 for CDMM.

4.2 Predictions of the Kingâ€™s Decision Results
Table 2 shows the results. CDMM performs bet-
ter than all other methods for macro-average
and weighted-averaged metrics. The majority of
classes shows the lowest performance. Naive
Bayes and SVM outperform the baseline. fast-
Text with pre-trained word vectors outperforms its
counterpart, in accordance with an earlier result
(Lample et al., 2016). CDMM without a speaker
performs equally to HAN, the only difference be-
ing that HAN encodes sentences and CDMM en-
codes utterances. It does not show good perfor-
mance as it models only the hierarchical struc-
ture of the conversation. However, when we add
speaker information, the performance increases
even with random initialization of speaker embed-
ding. The performances of Naive Bayes and SVM
also increase when they are assigned speakers as
features. These observations signal that speaker
information is helpful for predicting the kingâ€™s de-
cisions. Finally, CDMM with pre-trained speaker

2https://github.com/facebookresearch/
fastText/blob/master/docs/crawl-vectors.
md

3http://snap.stanford.edu/node2vec

https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md
https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md
https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md
http://snap.stanford.edu/node2vec


959

Method Micro F1 Macro Prec Macro Rec Macro F1 W-avg F1

Majority of classes 0.472 0.079 0.167 0.107 0.303
Naive Bayes 0.479 0.173 0.176 0.126 0.321
SVM linear 0.381 0.249 0.246 0.246 0.383
SVM RBF 0.487 0.236 0.186 0.142 0.337
Naive Bayes with speaker 0.466 0.268 0.177 0.135 0.323
SVM linear with speaker 0.423 0.292 0.259 0.243 0.403
SVM RBF with speaker 0.472 0.079 0.167 0.107 0.303
fastText w/o word vector 0.487 0.158 0.193 0.150 0.349
fastText 0.499 0.315 0.225 0.215 0.402
CDMM w/o speaker 0.481 0.176 0.214 0.178 0.379
CDMM with speaker (random init) 0.504 0.258 0.227 0.208 0.401
CDMM with speaker (pre-trained) 0.476 0.329 0.307 0.313 0.456

Table 2: Kingâ€™s decision classification precision, recall and F-measures. Micro F1 is the micro-averaged
value of F-measure, and Macro Prec, Rec and F1 are the macro-averaged values of precision, recall and
F-measure respectively. W-avg F1 is the weighted average according to the number of true examples in
each class. CDMM outperforms all other methods compared.

(a) Word â€œWish to doâ€

(b) Word â€œOkayâ€

Figure 3: Attention weight distribution of words for
each class

embedding shows better results compared to all
other methods.

5 Discussion

Here, we investigate the attention values to de-
termine the important words and speakers for
predicting the kingâ€™s decisions. We also obtain
evidence showing why CDMM with pre-trained
speaker embedding outperforms the others.

5.1 Key Words and Speakers
We investigate the important words using word
attention values. To find the important words,
we compute the mutual information (Christopher
et al., 2008) of words that have the top 10% of at-
tention values in the utterances among the classes.

(a) Word â€œOkayâ€ from kings

(b) Word â€œOkayâ€ from officials

Figure 4: Attention weight distribution of word for
each class from kings and officials

Figure 3 shows the attention weight distribu-
tions of the two examples of the top words â€œWish
to doâ€ and â€œOkayâ€. The word â€œWish to doâ€ is usu-
ally used to make a request to the king. The peak
of the attention weight distribution of â€œWish to doâ€
for the Approve class is around 0.7, whereas it is
around 0.3 for Order and Discuss. We can inter-
pret this to mean that CDMM assigns greater at-
tention to that word to predict Approve compared
to Order and Discuss. The word â€œOkayâ€ is used to
consent to the opinions of others. CDMM assigns
a high attention value to the word to predict Order
and Accept compared to Discuss.

However, the attention values differ according
to the speaker. As shown in Figure 4, CDMM
gives a high attention score to the word â€œOkayâ€ for



960

Name (Eng) Position Class

Sin Sukju Secretary Order
Jeong Changson Secretary Order
Kim Jonkyung Local gov Approve
Kim Neuk Local gov Approve
Gwon Jin Local gov Disapprove
Kim Seup Remonstrator Disapprove
Hwang Hui Central gov Accept
Han Myeonghoe Central gov Accept
Kim Jikyung Remonstrator Reject
Sung Damnyeon Remonstrator Reject

Table 3: Name (translated in English) and position
of the speakers who have high mutual informa-
tion scores for the classes. Local gov is the local
government official and Central gov is the central
government official. Remonstrator is the official
who remonstrates to the king. The position of the
speaker is important to predict the kingâ€™s decision.

Accept as compared to the other classes when the
speaker is king. However, when officials use this
word, CDMM assigns a high attention value to the
word in the Order class. Despite the fact that the
same word is used, the kingâ€™s decision is changed
based on the speaker. This is additional evidence
showing why the speaker information is useful to
predict the decision.

5.2 Position of the Speaker

We investigate the key speakers from utterance at-
tention values. To determine the important person,
we use the same technique of finding important
words.

We find that high ranking personâ€™s positions are
shared for each class. Table 3 shows the top ranked
speakers and their positions for each class. The
chief secretary who takes orders from the king has
a high rank in the Order class. For Approve and
Disapprove, local authorities are highly ranked.
For Accept, central government officials have high
MI values. Interestingly, officials who remonstrate
to the king have high scores in the Disapprove and
Reject class. We can thus say that the kings refuse
admonitions commonly from officials.

From these results, we can gain insight into
why pre-trained speaker embedding is helpful to
predict the kingâ€™s decisions. People in the same
organization are in the same community of co-
occurrence news article network (OÌˆzguÌˆr et al.,

2008). Therefore, the AJD network contains the
community information, and node2vec generates
the nodeâ€™s closeness via embedding. CDMM can
have this knowledge in the model therefore out-
performs the other methods.

6 Conclusion

In this paper, we created conversational meet-
ing data from the Annals of the Joseon Dynasty
(AJD). We presented Conversational Decision-
Making Model (CDMM) to predict leadersâ€™ deci-
sions from the data. We also suggested the use of
speaker embedding from co-occurrence document
network with node2vec. With this data, we showed
that CDMM outperforms other methods in terms
of most metrics. We implemented CDMM using
tensorflow (Abadi et al., 2016), and published the
code and data in public4. We also analyzed the rea-
soning behind the success of CDMM and the key
words and speakers by investigating the concept of
attention.

Studies of small group dynamics can be help-
ful when attempting to understand group deci-
sion making behavior (Backstrom et al., 2006).
Prior work which analyzed small group dynam-
ics relied on a hidden Markov model (Magdon-
Ismail et al., 2003), a dynamic Bayesian network
(Mathur et al., 2012) or a layered probabilistic
model (Cheng et al., 2014) for various datasets
such as networks or recorded video. We suggest
CDMM, which combine two types of data to pre-
dict leadersâ€™ decision. We can also apply this idea
to other group dynamics analyses.

Acknowledgments

We would like to thank Jooyeon Kim for the
helpful discussion and the anonymous reviewers
for the inspiring questions and comments. This
work was supported by Institute for Information
& communications Technology Promotion (IITP)
grant funded by the Korea government (MSIT)
(No.2017-0-01778, Development of Explainable
Human-level Deep Machine Learning Inference
Framework).

References
MartÄ±Ìn Abadi, Paul Barham, Jianmin Chen, Zhifeng

Chen, Andy Davis, Jeffrey Dean, Matthieu Devin,
Sanjay Ghemawat, Geoffrey Irving, Michael Isard,

4https://github.com/NoSyu/CDMM

https://github.com/NoSyu/CDMM


961

et al. 2016. Tensorflow: A system for large-scale
machine learning. In OSDI, pages 265â€“283.

Lars Backstrom, Dan Huttenlocher, Jon Kleinberg, and
Xiangyang Lan. 2006. Group formation in large so-
cial networks: Membership, growth, and evolution.
In Proceedings of the SIGKDD, pages 44â€“54. ACM.

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2014. Neural machine translation by jointly
learning to align and translate. arXiv preprint
arXiv:1409.0473.

Piotr Bojanowski, Edouard Grave, Armand Joulin, and
Tomas Mikolov. 2017. Enriching word vectors with
subword information. TACL, 5:135â€“146.

Trung H Bui, Matthew Frampton, John Dowding, and
Stanley Peters. 2009. Extracting decisions from
multi-party dialogue using directed graphical mod-
els and semantic similarity. In Proceedings of the
SIGDIAL, pages 235â€“243.

Jean Carletta, Simone Ashby, Sebastien Bourban, Mike
Flynn, Mael Guillemot, Thomas Hain, Jaroslav
Kadlec, Vasilis Karaiskos, Wessel Kraaij, Melissa
Kronenthal, et al. 2005. The ami meeting corpus:
A pre-announcement. In International Workshop
on Machine Learning for Multimodal Interaction,
pages 28â€“39. Springer.

Zhongwei Cheng, Lei Qin, Qingming Huang,
Shuicheng Yan, and Qi Tian. 2014. Recognizing
human group action by layered model with multiple
cues. Neurocomputing, 136:124â€“135.

D Manning Christopher, Raghavan Prabhakar, and
Schacetzel Hinrich. 2008. Introduction to informa-
tion retrieval. An Introduction To Information Re-
trieval, 151(177):5.

Raquel FernaÌndez, Matthew Frampton, Patrick Ehlen,
Matthew Purver, and Stanley Peters. 2008. Mod-
elling and detecting decisions in multi-party dia-
logue. In Proceedings of the SIGDIAL, pages 156â€“
163.

Edouard Grave, Piotr Bojanowski, Prakhar Gupta, Ar-
mand Joulin, and Tomas Mikolov. 2018. Learning
word vectors for 157 languages. In Proceedings of
the LREC.

Aditya Grover and Jure Leskovec. 2016. node2vec:
Scalable feature learning for networks. In Proceed-
ings of the SIGKDD, pages 855â€“864. ACM.

Pei-Yun Hsueh and Johanna D Moore. 2007. What de-
cisions have you made?: Automatic decision detec-
tion in meeting conversations. In Proceedings of the
NAACL HLT, pages 25â€“32.

Armand Joulin, Edouard Grave, Piotr Bojanowski, and
Tomas Mikolov. 2017. Bag of tricks for efficient text
classification. In Proceedings of the EACL, pages
427â€“431.

Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
ramanian, Kazuya Kawakami, and Chris Dyer. 2016.
Neural architectures for named entity recognition.
In Proceedings of the NAACL HLT, pages 260â€“270.

James R Larson Jr, Pennie G Foster-Fishman, and Tim-
othy M Franz. 1998. Leadership style and the
discussion of shared and unshared information in
decision-making groups. Personality and Social
Psychology Bulletin, 24(5):482â€“495.

Kurt Lewin, Ronald Lippitt, and Ralph K White. 1939.
Patterns of aggressive behavior in experimentally
created â€œsocial climatesâ€. The Journal of social psy-
chology, 10(2):269â€“299.

Jiwei Li, Michel Galley, Chris Brockett, Georgios Sp-
ithourakis, Jianfeng Gao, and Bill Dolan. 2016. A
persona-based neural conversation model. In Pro-
ceedings of the ACL, pages 994â€“1003.

Frank C Lunenburg. 2011. Decision making in organi-
zations. International journal of management, busi-
ness, and administration, 15(1):1â€“9.

Malik Magdon-Ismail, Mark Goldberg, William Wal-
lace, and David Siebecker. 2003. Locating hid-
den groups in communication networks using hid-
den markov models. In International Conference
on Intelligence and Security Informatics, pages 126â€“
137. Springer.

Shobhit Mathur, Marshall Scott Poole, Feniosky Pena-
Mora, Mark Hasegawa-Johnson, and Noshir Con-
tractor. 2012. Detecting interaction links in a collab-
orating group using manually annotated data. Social
Networks, 34(4):515â€“526.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781.

Arzucan OÌˆzguÌˆr, Burak Cetin, and Haluk Bingol. 2008.
Co-occurrence network of reuters news. Interna-
tional Journal of Modern Physics C, 19(05):689â€“
702.

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: A simple way to prevent neural networks
from overfitting. The Journal of Machine Learning
Research, 15(1):1929â€“1958.

Victor H Vroom and Arthur G Jago. 1988. The
new leadership: Managing participation in organi-
zations. Prentice-Hall, Inc.

Maria C Yang. 2010. Consensus and single leader
decision-making in teams using structured design
methods. Design Studies, 31(4):345â€“362.

Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He,
Alex Smola, and Eduard Hovy. 2016. Hierarchical
attention networks for document classification. In
Proceedings of the 2016 Conference of the NAACL:
HLT, pages 1480â€“1489.


