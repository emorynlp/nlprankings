










































SAGAN: A Machine Translation Approach for Cross-Lingual Textual Entailment


First Joint Conference on Lexical and Computational Semantics (*SEM), pages 721–726,
Montréal, Canada, June 7-8, 2012. c©2012 Association for Computational Linguistics

 SAGAN: A Machine Translation Approach for  

Cross-Lingual Textual Entailment 

 
Julio Castillo1,2 and Marina Cardenas2

 

1UNC-FaMAF, Argentina
 

2UTN-FRC, Argentina 

{jotacastillo, ing.marinacardenas}@gmail.com
 

                      

 
 

  

 

Abstract 

This paper describes our participation in the 

task denominated Cross-Lingual Textual En-

tailment (CLTE) for content synchronization. 

We represent an approach to CLTE  using 

machine translation to tackle the problem of 

multilinguality. Our system resides on ma-

chine learning and in the use of WordNet as 

semantic source knowledge. Results are very 

promising always achieving results above 

mean score.  

1 Introduction 

 
This paper describes the participation of Sagan, a 

TE and CLTE system, in the new task of Cross 

Lingual Textual Entailment for Content Synchro-
nization. 

 The objective of the Recognizing Textual En-

tailment (RTE) task (Dagan et al., 2006) is deter-

mining whether the meaning of a text fragment that 
we call hypothesis H can be inferred from another 

text fragment T. In this manner, we say that T en-

tails H, if a person reading T would infer that H is 
most likely true. Thus, this definition assumes 

common human understanding of language and 

common background knowledge. 

In that context, Cross-Lingual Textual Entail-
ment addresses textual entailment recognition in 

the challenging application scenario of content 

synchronization. Thus, CLTE constitutes a gener-
alization of Textual Entailment task (also Mono-

lingual Textual Entailment) , but envisioning a 

larger number of application areas in NLP, includ-

ing question answering, information retrieval, in-

formation extraction, and document summariza-
tion, across different languages. 

Content synchronization could be used to keep 

consistence among documents written in different 
languages. For example, a CLTE system can be 

used in Wikipedia articles to inform lectors which 

information is absent or inconsistent in comparison 

to other page in a different language. 
This new task has to face more additional issues 

than monolingual TE. Among them, we emphasize 

the ambiguity, polysemy, and coverage of the re-
sources. Another additional problem is the necessi-

ty for semantic inference across languages, and the 

limited availability of multilingual knowledge 
resources.  

The CLTE for content synchronization specifi-

cally consist on determining the entailment rela-

tionship between two text fragment T1 and T2 
which are assumed belong a related topic. 

Four alternatives are possible in this relation-

ship: 
- Bidirectional : It is a semantic equivalence be-

tween T1 and T2. 

- Forward : It is an unidirectional entailment 
from T1 to T2. 

- Backward: It is an unidirectional entailment 

from T2 to T1. 

- No Entailment: It means that there is no en-
tailment between T1 and T2. 

The paper is organized as follows: Section 2 de-

scribes the relevant work done on cross-lingual 
textual entailment and related tasks, Section 3 de-

scribes the architecture of the system, then Section 

4 shows experiments and results; and finally Sec-

721



tion 5 summarize some conclusions and future 

work. 

2 Related work  

In this section we briefly describe two tasks that 

are closely related to CLTE. 
 

2.1 Textual Entailment 
 

The objective of the recognizing textual entail-
ment (RTE) task (Dagan et al., 2006) is determin-

ing whether or not the meaning of a ‘‘hypothesis’’ 

(H) can be inferred from a ‘‘text’’ (T).  

The two-way RTE task consists of deciding 
whether: T entails H, in which case the pair will be 

marked as ‘‘Entailment’’, otherwise the pair will 

be marked as ‘‘No Entailment’’. This definition of 
entailment is based on (and assumes) average hu-

man understanding of language as well as average 

background knowledge. 
Recently the RTE4 Challenge has changed to a 

three-way task (Bentivogli et al, 2009) that consists 

in distinguishing among ‘‘Entailment’’, ‘‘Contra-

diction’’ and ‘‘Unknown’’ when there is no infor-
mation to accept or reject the hypothesis. 

 The RTE challenge has mutated over the years, 

aiming at accomplishing more accurate and specif-
ic solutions; in 2009 the organizers proposed a 

pilot task, the Textual Entailment Search 

(Bentivogli et al, 2009), consisting in finding all 

the sentences in a set of documents that entail a 
given Hypothesis and since 2010 there is a Novelty 

Detection Task, which means that RTE systems are 

required to judge whether the information con-
tained in each H is novel with respect to (i.e., not 

entailed by) the information contained in the cor-

pus. 
Thus, the new CLTE task can be thought as a 

generalized problem of RTE, which has to face 

new challenges as scarcity of resources to multi-

lingual scenario, among others issues. 

2.2 Semantic Textual Similarity 

The pilot task STS was recently defined in 

Semeval 2012 (Aguirre et al., 2012) and has as 

main objective measuring the degree of semantic 
equivalence between two text fragments. STS is 

related to both Recognizing Textual Entailment 

(RTE) and Paraphrase Recognition, but has the 

advantage of being a more suitable model for mul-

tiple NLP applications.  
As mentioned before, the goal of the RTE task 

(Bentivogli et al, 2009) is determining whether the 

meaning of a hypothesis H can be inferred from a 

text T. The main difference with STS is that STS 
consists in determining how similar two text frag-

ments are, in a range from 5 (total semantic 

equivalence) to 0 (no relation). Thus, STS mainly 
differs from TE and Paraphrasing in that the classi-

fication is graded instead of binary and also STS 

assumes bidirectional equivalence but in TE the 
equivalence is only directional. In this manner, 

STS is filling the gap between TE and Paraphrase. 

2.3 Cross-Lingual Textual Entailment 

There are a few previous works on CLTE, the 
first one was the definition of this new task 

(Mehdad et al., 2010). Afterwards, the creation of 

CLTE corpus by using Mechanical Turk is de-
scribed on (Negri et al., 2011) and a corpus freely 

available for CLTE is published (Castillo, 2011). 

To our knowledge, two approach are proposed 

to address this new challenging task, one consist of 
using machine translation to move on towards 

monolingual textual entailment scenario and then 

apply classic techniques for RTE (Mehdad et al., 
2010;  Castillo and Cardenas, 2011), and the other 

is based on exploit databases of paraphrases 

(Mehdad et al., 2011). Both techniques obtained 

similar results and the accuracy achieved by them 
is not a statically significant difference. 

In previous work (Castillo, 2010; Castillo and 

Cardenas, 2011) we addressed the CLTE focusing 
on English-Spanish language pair and released a 

bilingual textual entailment corpus. This paper is 

based on that work in order to tackling the problem 
across different language pairs Spanish-English 

(SPA-ENG), Italian-English (ITA-ENG), French-

English (FRA-ENG) and German-English (GER-

ENG) and we also used an approach based on ma-
chine translation.  
 

3 System architecture  

Sagan is a CLTE system (Castillo and Cardenas, 
2010) which has taken part of several challenges, 

including the Textual Analysis Conference 2009 

and TAC 2010, and the Semantic Textual Similari-

722



ty Semeval 2012 (Aguirre et al., 2012; Castillo and 

Estrella, 2012) and Cross Lingual Textual Entail-
ment for content synchronization as part of the 

Semeval 2012 (Negri et al., 2012). 

 The system is based on a machine learning ap-

proach and it utilizes eight WordNet-based 
(Fellbaum, 1998) similarity measures with the 

purpose of obtaining the maximum similarity be-

tween two concepts. We used SVM as classifier 
with polynomial kernel. The system determines the 

entailment based on the semantic similarity of two 

texts (T,H) viewed as a function of the semantic 
similarity of the constituent words of both phrases. 

Thereby, we expect that combining word to word 

similarity metrics to text level would be a good 

indicator of text to text similarity.  
These text-to-text similarity measures are based 

on the following word-to-word similarity metrics: 

(Resnik, 1995), (Lin, 1997), (Jiang and Conrath, 
1997), (Pirrò and Seco, 2008), (Wu and Palmer, 

1994), Path Metric, (Leacock and Chodorow, 

1998), and a semantic similarity to sentence level 
named SemSim (Castillo and Cardenas, 2010).  

Additional information about how to produce 

feature vectors as well as each word- and sentence-

level metric can be found in (Castillo, 2011). The 
architecture of the system is shown in Figure 1. 

WordNet

* CLTE_DEU-ENG, 

* CLTE_FRA-ENG, 

* CLTE_SPA-ENG, 

*CLTE_ITA-ENG, 

* CLTE_DEU+FRA+SPA+ITA-

ENG, 

*CLTE_DEU+FRA+SPA+ITA-

ENG+RTE3-TS-CL

* CLTE_DEU-ENG, 

* CLTE_FRA-ENG, 

* CLTE_SPA-ENG, 

*CLTE_ITA-ENG

CLTE
Adaptation Layer

TE 

engine

Entailment 

Result

Bidirectional Backward

Google 

Traslate

Forward

Knowledge Resources

Web Resources

Training Sets

Test Sets

RTE3-4C+RTE4-4C

RTE3-4C

Training Sets

No 

Entailment

Pre-Processing

Fig.1. System architecture  

In the preprocessing module we performed 

string normalization across different languages by 
using a lookup table for lexical entries, and then 

date and time normalization is carried out. 

CLTE adaption layer is composed by four ma-

chine translation sub-modules that bring back each 
<Ti ,H> pair into the monolingual case ENG-ENG. 

Where Ti can be given in Spanish, German, Italian 

or French. 
The training set used to the submitted runs are 

whose provided by the organizers of the CLTE for 

Content Synchronization Task and a combination 
of RTE datasets, such as it is described in the Sec-

tion Experiments and Results.  

4 Experiments and Results 

The dataset provided by the organizers consists of 
500 CLTE pairs translated to four languages fol-

lowing the crowdsourcing-based methodology 

proposed in (Negri et al., 2011). Also, for test pur-
pose additional 500 pairs are provided. Both da-

tasets are balanced with respect to the four 

entailment judgments (bidirectional, forward, 

backward, and no entailment). 
We also performed experiments using traditional 

RTE datasets. Because of the RTE datasets are 

binary classified as NO (no-entailment) and YES 
(entailment), then we assumed that NO class is 

"no-entailment" and YES class is "forward" in the 

CLTE task. Certainly, the corpus tagged in this 

way will have contradictory information, since 
several pairs classified as forward should be classi-

fied as bidirectional, and also several pairs classi-

fied as no-entailment could be backwards, but the 
objective is experimenting  whether we can gain 

accuracy in our RTE system despite of these (few) 

contradictory cases.  
Additionally, in our experiments we used an al-

gorithm (Castillo,2010) to generate additional 

training data, in other words to expand a data set. It 

is based on a Double Translation Process (dtp) or 
round-trip translation. Double translation process 

can be defined as the process of starting with an S 

(String in English), translating it to a foreign lan-
guage F(S), for example Spanish, and finally back 

into the English source language F-1(S).  

We applied the algorithm starting with RTE3 

and RTE4 datasets. Thus, the augmented corpus is 
denoted RTE3-4C which is tagged according to the 

three-way task composed of: 340 pairs Contradic-

723



tion, 1520 pairs Yes, and 1114 pairs Unknown. In 

the case of the two-way task, it is composed by 
1454 pairs No, and 1520 pairs Yes. 

The other dataset augmented is denoted RTE4-

4C, and has the following composition: 546 pairs 

Contradiction, 1812 pairs Entailment, and 1272 
pairs Unknown. Therefore, in the two-way task, 

there are 1818 pairs No (No Entailment), and 1812 

pairs Yes (Entailment) in this data set. 
The idea behind using RTE3-4C and RTE3-4C 

is providing to our system an increased dataset 

aiming to acquire more semantic variability. 
In our system submission we report the experi-

ments performed with the test sets provided by 

CLTE organizers which is composed by four da-

tasets of 500 pairs each one.  

4.1 Submission to the CLTE shared task  

With the aims of applying the monolingual textual 

entailment techniques, in the CLTE domain, we 
utilized the Google translate as MT system to bring 

back the <T,H> pairs into the monolingual case. 

Then we generated a feature vector for every 

<T,H> pair with both training and test sets, and 
used monolingual textual entailment engine to 

classify the pairs. First we described the dataset 

used and then explain each submitted run. 
The datasets used are listed below: 

 

 - CLTE_Esp+Fra+Ita+Ger: dataset composed 

by all language pairs. 
 - RTE3-TS-CL: a ENG-SPA cross lingual tex-

tual entailment corpus (Castillo,2011) composed 

by 200 pairs (108 Entailment, 32 Contradiction, 60 
Unknown). 

- RTE3-4C: an augmented dataset based on 

RTE3. 
- RTE4-4C: an augmented dataset based on 

RTE4. 

 

Our participation in the shared task consisted of 
four different runs produced with the same feature 

set, and the main differences rely on the amount 

and type of training data. Each run is described 
below: 

 

 - RUN1: system trained on CLTE_Esp+ 

Fra+Ger+Ita corpus in addition to the RTE3-TS-
CL dataset. 

- RUN2: system trained on CLTE_Esp, 

CLTE_Fra, CLTE_Ger and CLTE_Ita corpus. At 
testing phase, the system chooses the right dataset 

according to the language that it is processing. 

-  RUN3: system trained using all training data 

that came from different language pairs.  
We remark that we can combine the training da-

ta because of we used a machine translation sub-

module that bring back each <T,H> pair into the 
monolingual case ENG-ENG. 

-  RUN4: In RUN4 the training set is com-

posed by all pairs of CLTE_Esp+Fra+Ita+Ger and 
RTE3-4C+ RTE4-4C datasets. 

Ten teams participated in this CLTE task, eight 

submitting runs to all language pairs. For Spanish 

28 runs were submitted and 20 runs were submit-
ted for the other languages. The results achieved 

by our system is showed in Table 1. 

 

Team id 

Team 

system 
id 

Score (Accuracy) Run Rank  

SPA-
ENG 

ITA-
ENG 

FRA-
ENG 

DEU-
ENG 

SPA ITA FRA DEU 

Sagan run1 0.342 0.352 0.346 0.342 16 6 9 9 

Sagan run2 0.328 0.352 0.336 0.310 19 7 11 13 

Sagan run3 0.346 0.356 0.330 0.332 14 5 12 12 

Sagan run4 0.340 0.330 0.310 0.310 17 12 13 14 

System 

Rank 
 7 4 5 6 

    

 

The results reported show that our best run is 
ranking above the average for all languages. The 

same situation occurs when ranking the systems, 

except for Spanish where the system is placed on 

7th among 10 teams. 
We achieved the highest result of 0.356 with 

RUN3 in the pair ITA-ENG which is placed fourth 

among participating systems. 
We also note that, in general, training the system 

with the pairs of all datasets achieved better results 

than training separately for each dataset. Further-
more, if we analyze RUN4 vs. RUN3 we can con-

clude that incorporating additional RTE dataset 

produces a very unbalanced dataset resulting in a 

decrease in performance. In (Castillo, 2011) we 
experimented with these expanded datasets over 

monolingual RTE and CLTE tasks and we showed 

gain in performance, thus we suspect that the de-
crease is more due to unbalanced dataset than to 

noise introduced by the double translation process. 

Interesting, the Corpus RTE3-TS-CL dataset uti-
lized in the RUN1 helps to improve the results in 

FRA-ENG and DEU-ENG language pairs. 

724



The Table 2 shows that our system predict with 

high F-measure to bidirectional and no-entailment 
entailment judgments in all language pairs, but has 

problems to distinguish the forward and backward 

entailment judgments.  

 

 It is probably due to our systems is based on 

semantic overlap between T and H, resulting the 
backwards particularly difficult to predict to our 

system.  
 

Run 
id 

Language 
pair 

Precision 
Recall 

 

F-measure Score 

(Accuracy) 

Mean Score- 

all runs  

F B NE BI F B NE BI F B NE BI 

Run3 SPA-ENG 0.23 0.27 0.42 0.42 0.20 0.22 0.45 0.51 0.21 0.25 0.43 0.46 0.346 0.346 

Run3 ITA-ENG 0.31 0.25 0.40 0.46 0.30 0.22 0.51 0.40 0.30 0.23 0.45 0.43 0.356 0.336 

Run1 FRA-ENG 0.24 0.30 0.39   0.43 0.17 0.34 0.57 0.30 0.20 0.32 0.47 0.36 0.346 0.336 

Run1 DEU-ENG 0.25 0.23 0.41 0.44 0.17 0.26 0.60 0.34 0.20 0.25 0.49 0.39 0.342 0.336 

Table 2. Official results for Precision, Recall and F-measure 

 

5 Conclusions and future work 

In this paper we explained our participation in the 

new challenging task of Cross-Lingual Textual 

Entailment (CLTE) for Content Synchronization. 
This task also could presents benefit as a metric for 

machine translation evaluation, as reported in 

(Castillo and Estrella, 2012). 

  This work focuses on CLTE based on Machine 
translation to bring back the problem into the mon-

olingual Textual Entailment (TE) scenario. This 

decoupled approach between Textual Entailment 
and Machine Translation has several advantages, 

such as taking benefits of the most recent advances 

in machine translation, the ability to test the effi-

ciency of different MT systems, as well as the abil-
ity to scale the system easily to any language pair.  

Results achieved are promising and additional 

work is needed in order to address the problem of 
distinguish among forward, backward and bidirec-

tional entailment judgments.  

Future work will be oriented to tackle the prob-
lem with backwards. Finally, we remark the neces-

sity of bigger corpus tagged in four-way 

classification, for all language pairs. 

References  

Ido Dagan, Oren Glickman and Bernardo Magnini. 

2006. The PASCAL Recognising Textual Entailment 

Challenge. In Quiñonero-Candela, J.; Dagan, I.; 

Magnini, B.; d'Alché-Buc, F. (Eds.) Machine Learn-

ing Challenges. Lecture Notes in Computer Science , 

Vol. 3944, pp. 177-190, Springer. 

M. Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, and 
D. Giampiccolo. 2012. Semeval-2012 Task 8: Cross-

lingual Textual Entailment for Content Synchroniza-

tion. In Proceedings of the 6th International Work-
shop on Semantic Evaluation (SemEval 2012). 

L. Bentivogli, P. Clark, I. Dagan, H. T. Dang, and D. 

Giampiccolo. 2010. The Sixth PASCAL Recognizing 

Textual Entailment Challenge. In TAC 2010 Work-

shop Proceedings, NIST, Gaithersburg, MD, USA. 

Y. Mehdad, M. Negri, and M. Federico. 2010. Towards 

Cross-Lingual Textual Entailment. In Proceedings of 

NAACL-HLT 2010. 

Eneko Agirre, Daniel Cer, Mona Diab and Aitor Gonza-

lez-Agirre. 2012. SemEval-2012 Task 6: A Pilot on 

Semantic Textual Similarity. In Proceedings of the 
6th International Workshop on Semantic Evalua-tion 

(SemEval 2012), in conjunction with the First Joint 

Conference on Lexical and Computational Semantics 

(*SEM 2012).  

Bentivogli, Luisa, Dagan Ido, Dang Hoa, Giampiccolo, 

Danilo, Magnini Bernardo.2009.The Fifth PASCAL 

RTE Challenge. In: Proceedings of the Text Analysis 

Conference.  

Fellbaum C. 1998. WordNet: An Electronic Lexical 

Database, volume 1. MIT Press.  

Castillo Julio. 2011. A WordNet-based semantic ap-

proach to textual entailment and cross-lingual textu-
al entailment. International Journal of Machine 

Learning and Cybernetics - Springer, Volume 2, 

Number 3. 

Castillo Julio and Cardenas Marina. 2010. Using sen-

tence semantic similarity based onWordNet in recog-

nizing textual entailment. Iberamia 2010. In LNCS, 

vol 6433. Springer, Heidelberg, pp 366–375. 

Castillo Julio. 2010. A semantic oriented approach to 

textual entailment using WordNet-based measures. 

MICAI 2010. LNCS, vol 6437. Springer, Heidelberg, 

pp 44–55. 
Castillo Julio. 2010. Using machine translation systems 

to expand a corpus in textual entailment. In: Proceed-

ings of the Icetal 2010. LNCS, vol 6233, pp 97–102. 

M. Negri, L. Bentivogli, Y. Mehdad, D. Giampiccolo, 

and A. Marchetti. 2011. Divide and Conquer: 

Crowdsourcing the Creation of Cross-Lingual Textu-

725



al Entailment Corpora. In Proceedings of the Con-

ference on Empirical Methods in Natural. EMNLP 

2011. 

Resnik P. 1995. Information content to evaluate seman-

tic similarity in a taxonomy. In: Proceedings of IJCAI 

1995, pp 448–453. 
Castillo Julio, Cardenas Marina. 2011. An Approach to 

Cross-Lingual Textual Entailment using Online Ma-

chine Translation Systems. Polibits Journal. Vol 44. 

Castillo Julio and Estrella Paula. 2012. Semantic Textu-

al Similarity for MT evaluation. NAACL 2012 Sev-

enth Workshop on Statistical Machine Translation. 

WMT 2012, Montreal, Canada.  

Lin D. 1997.An information-theoretic definition of simi-

larity. In: Proceedings of Conference on Machine 

Learning, pp 296–304. 

Jiang J, Conrath D.1997. Semantic similarity based on 

corpus statistics and lexical taxonomy. In: Proceed-
ings of the ROCLINGX. 

Pirro G., Seco N. 2008. Design, implementation and 

evaluation of a new similarity metric combining fea-

ture and intrinsic information content. In: ODBASE 

2008, Springer LNCS. 

Wu Z, Palmer M. 1994. Verb semantics and lexical 

selection. In: Proceedings of the 32nd ACL 916. 

Leacock C, Chodorow M. 1998. Combining local con-

text and WordNet similarity for word sense identifi-

cation. MIT Press, pp 265–283. 

Hirst G, St-Onge D . 1998. Lexical chains as represen-
tations of context for the detection and correction of 

malapropisms. MIT Press, pp 305–332. 

Banerjee S, Pedersen T. 2002. An adapted lesk algo-

rithm for word sense disambiguation using WordNet. 

In: Proceeding of CICLING-02. 

William B. Dolan and Chris Brockett.2005. Automati-

cally Constructing a Corpus of Sentential Para-

phrases. Third International Workshop on 

Paraphrasing (IWP2005). Asia Federation of Natural 

Language Processing. 

Castillo Julio and Estrella Paula. 2012. SAGAN: An 

approach to Semantic Textual Similarity based on 
Textual Entailment. In Proceedings of the 6th Inter-

national Workshop on Semantic Evaluation 

(SemEval 2012), in conjunction with the First Joint 

Conference on Lexical and Computational Semantics 

(*SEM 2012).  

Mehdad Y., M. Negri, and M. Federico. 2011. Using 

Parallel Corpora for Cross-lingual Textual Entail-

ment. In Proceedings of ACL-HLT 2011. 

 

 

726


