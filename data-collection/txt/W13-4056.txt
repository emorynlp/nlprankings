



















































Weakly and Strongly Constrained Dialogues for Language Learning


Proceedings of the SIGDIAL 2013 Conference, pages 357–359,
Metz, France, 22-24 August 2013. c©2013 Association for Computational Linguistics

Weakly and Strongly Constrained Dialogues for Language Learning

Claire Gardent
CNRS/LORIA, Nancy

claire.gardent@loria.fr

Alejandra Lorenzo
Université de Lorraine

LORIA, Nancy
alejandra.lorenzo@loria.fr

Laura Perez-Beltrachini
KRDB Research Centre

FUB, Bolzano
laura.perez@loria.fr

Lina Rojas-Barahona
Université de Lorraine

LORIA, Nancy
lina.rojas@loria.fr

Abstract

We present two dialogue systems for lan-
guage learning which both restrict the di-
alog to a specific domain thereby pro-
moting robustness and the learning of a
given vocabulary. The systems vary in how
much they constrain the learner’s answer :
one system places no other constrain on
the learner than that provided by the re-
stricted domain and the dialog context ; the
other provides the learner with an exercise
whose solution is the expected answer.
The first system uses supervised learning
for simulating a human tutor whilst the
second one uses natural language gener-
ation techniques to produce grammar ex-
ercises which guide the learner toward the
expected answer.

1 Introduction

Work on dialog based tutors for language learn-
ing includes both chatbot systems which maintain
a free flowing dialog with the learner (Shawar and
Atwell, 2007; Jia, 2004) and form-focused dia-
log systems which restrict the learner answer e.g.,
by providing her with an answer template to be
filled in for the dialog to continue (Wilske and
Wolska, 2011). While the former encourages lan-
guage practice with a virtual tutor and requires a
good knowledge of the language, the latter focuses
on linguistic forms and usually covers a more re-
stricted lexical field thereby being more amenable
to less advanced learners.

In these notes, we describe a dialog architecture
which (i) supports both free-flowing and form-
focused man/machine dialog ; and (ii) ensures that
in both cases, dialogs are restricted to a specific
lexical field. The free-flowing dialog system uses
supervised classification techniques to predict the
system dialog move based on the learner’s input

and does not explicitely constrain the learner’s an-
swer. In contrast, the dialog system for intermedi-
ate learners provides an exercise which the learner
must solve to construct her answer.

To restrict the dialog to a specific domain and
to improve system robustness, we make use of a
finite-state automaton (FSA) describing the range
of permissible interactions within a given domain.
This FSA serves to guide the collection of human-
human interactions necessary to train the classi-
fier ; to verify and if necessary to adjust the sys-
tem’s predicted answer ; and to support the gener-
ation of the exercise provided in the form-focused
dialog engine.

2 Finite State Automaton and Domain
Representation

To support focused dialog and promote robust-
ness, we make use of the FSA depicted in Fig-
ure 2. This FSA models a generic sequence of
(System Question, Learner Answer, System Re-
action) turns instantiating 4 main question/answer
patterns and two possible system reactions.

The system question systematically formulates
a question which explicitly lists a set of possible
answers.

The learner’s answer is then classified into four
main types. It selects one of the proposed answers ;
it chooses another alternative not mentioned in
the system’s question ; it indicates that the learner
does not know the correct answer or does not un-
derstand the question ; or it meets neither of these
categories.

Finally, for each answer, the system can con-
tinue the dialogue by making a “confirmation”
which is used to reassure the learner in the free
dialogue system and to provide some feedback in
the guided dialogue system ; or just by “inform-
ing” to the learner of the correct answer before
getting into the next question.

Given a specific domain, this generic FSA is

357



>S:Welcome to my house!, I’m the cat. Do you want
to play with me? || ask(ready)
>L:Ok. || answer(ready)
>S:Great! How are you doing? || ask(health)
>L: I’m doing very well, thanks!
|| answer(health, pref-option)
>S: Awesome! || confirm(health,pref-option)
>S: Come! I want to show you the kitchen!
|| inform(health)
>S:In the kitchen we prepare lunch. I prepare
soup very often. Do you prefer soup or salad?
|| ask(pref-meal)
>L:I prefer salad.
|| answer(pref-meal,pref-option)
>S:So do I! || confirm(pref-meal,pref-option)
>S:I also love cheese. || inform(pref-meal)
>S:Where do we usually keep the cheese?
|| ask(cheese where)
>L:In the fridge || answer(cheese where,pref-option)
>S:You are right || confirm(cheese where,pref-option)
>S:In the fridge || inform(cheese where)
...
>S:Thanks for this little chat! See you soon
|| quit

FIGURE 1 – Example of a dialog (translated from
French to English)

instantiated differently for each question/answer
pair making up a dialog. In particular, in the cur-
rent demonstration system, it is instantiated to
model a dialog situated in the kitchen of a virtual
world. Figure 1 shows an example dialog.

3 Situated Dialogues for language
learning

Our dialog systems for language learning are in-
tegrated in a serious game called I-FLEG (Interac-
tive French Learning Game, (Amoia et al., 2012))
in which the learner can trigger grammar exercices
and interactive dialog sessions by clicking on the
objects present in the virtual world.

IFLEG integrates the two dialog systems for
language learning mentioned above namely, a
“free answer dialog system” where the learner an-
swer is guided only by the preceding dialog ex-
changes ; and a “guided dialog system” which re-
stricts the set of permissible answers by providing
the learner with an exercise whose solution pro-
vides a possible answer given the current dialog
context.

3.1 Data collection

To provide the training data necessary to train
the free dialog system, we conducted a Wizard-
of-Oz experiment where language learners were
invited to engage in a conversation with the wiz-
ard, a French tutor. In these experiments, we fol-
lowed the methodology and used the tools for
data collection and annotation presented in (Rojas-
Barahona et al., 2012a). Given an FSA specifiying

a set of 5 questions the learner had to answer, the
wizard guided the learner through the dialog us-
ing this FSA. The resulting corpus consists of 52
dialogues and 1906 sentences.

3.2 Free answer Dialogue System
The free answer dialogue system simulates

the behavior of the wizard tutor by means of
a Logistic-Regression classifier, the FSA and
a generation-by-selection algorithm. The system
first uses the FSA to determine the next question
to be asked. Then for each question, the Logistic-
Regression classifier is used to map the learner an-
swer to a system dialog act. At this stage, the FSA
is used again, in two different ways. First, it is used
to ensure that the predicted system dialog act is
consistent with the states in the FSA. In case of a
mismatch, a valid dialog act is selected in the cur-
rent context. In particular, unpredicted “preferred
options” and “do not know” learner answers are
detected using keyword spotting methods. If the
classifier prediction conflicts with the prediction
made by key word spotting, it is ignored and the
FSA transition is prefereed.

Second, since the system has several consecu-
tive turns, and given that the classifier only pre-
dicts the next one, the FSA is used to determine
the following system dialog acts sequence. For
instance, if the predicted next system dialog act
was “confirm”, according to the FSA the follow-
ing system dialog act is “inform” and then eiher
the next question encoded in the FSA or “quit”.

Training the simulator To train the classifier,
we labeled each learner sentence with the dialog
act caracterising the next system act. The features
used for trainig included context features (namely,
the four previous system dialogue acts) and the set
of content words present in the learner turns af-
ter filtering using tf*idf (Rojas Barahona et al.,
2012b). Given the learner input and the current di-
alog context, the classifier predicts the next system
move.

Generation by Selection Given the system move
predicted by the dialog manager, the system turn
is produced by randomly selecting from the train-
ing corpus an utterance annotated with that dialog
move.

3.3 Guided dialogue system
Unlike the free answer dialogue, the guided di-

alogue strongly constrains the learner answer by
suggesting it in the form of a grammar exercise.

358



FIGURE 2 – Finite-state automata that defines the different states in the dialog for each question Q X. S
defines the system, and P the learner.

In the guided dialogue system, the dialogue
paths contained in the training corpus are used to
decide on the next dialogue move. In a first step,
learner’s moves are labelled with the meaning rep-
resentation associated to them by the grammar un-
derlying the natural language generator used to
produce IFLEG grammar exercises. Given a se-
quence S/L contained in the training corpus with
S, a system turn and L the corresponding learner’s
turn, the system then constructs the exercise pro-
viding the learner’s answer using the methodology
described in (Perez-Beltrachini et al., 2012). First,
a sentence is generated from the meaning repre-
sentation of the learner answer. Next, the linguis-
tic information (syntactic tree, morpho-syntactic
information, lemmas) associated by the generator
with the generated sentence is used to build a shuf-
fle, a fill-in-the-blank or a transformation exercise.
Here is an example interaction produced by the
system :

S : Vous préférez la soupe ou le fromage ? (Do you
prefer soup or salad ?)
Please answer using the following words : { je,
adorer, le, soupe }

This dialogue setting has several benefits. The
dialogue script provides a rich context for each
generated exercise item, learners are exposed to
example communicative interactions, and the sys-
tem can provide feedback by comparing the an-
swer entered by the learner against the expected
one.

4 Sample Dialogue

In this demo, the user will be able to interact
with both dialogue systems, situated in the kitchen
of a virtual world, and where the tutor prompts
the learner with questions about meals, drinks,
and various kitchen related activities such as floor
cleaning and food preferences.

References
M. Amoia, T. Brétaudière, A. Denis, C. Gardent, and

L. Perez-Beltrachini. 2012. A Serious Game for Second
Language Acquisition in a Virtual Environment. Jour-
nal on Systemics, Cybernetics and Informatics (JSCI),
10(1) :24–34.

J. Jia. 2004. The study of the application of a web-based
chatbot system on the teaching of foreign languages. In
Society for Information Technology & Teacher Educa-
tion International Conference, volume 2004, pages 1201–
1207.

L. Perez-Beltrachini, C. Gardent, and G. Kruszewski. 2012.
Generating Grammar Exercises. In NAACL-HLT 7th
Workshop on Innovative Use of NLP for Building Educa-
tional Applications, Montreal, Canada, June.

L. M. Rojas-Barahona, A. Lorenzo, and C. Gardent. 2012a.
Building and exploiting a corpus of dialog interactions be-
tween french speaking virtual and human agents. In Pro-
ceedings of the 8th International Conference on Language
Resources and Evaluation.

L. M. Rojas Barahona, A. Lorenzo, and C. Gardent. 2012b.
An end-to-end evaluation of two situated dialog systems.
In Proceedings of the 13th Annual Meeting of the Special
Interest Group on Discourse and Dialogue, pages 10–19,
Seoul, South Korea, July. ACL.

B. Abu Shawar and E. Atwell. 2007. Chatbots : are they
really useful ? In LDV Forum, volume 22, pages 29–49.

S. Wilske and M. Wolska. 2011. Meaning versus form in
computer-assisted task-based language learning : A case
study on the german dative. JLCL, 26(1) :23–37.

359


