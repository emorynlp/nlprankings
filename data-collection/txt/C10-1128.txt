Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1137–1145,

Beijing, August 2010

1137

Towards a Unified Approach to Simultaneous Single-Document and 

Multi-Document Summarizations 

 

 

Xiaojun Wan 

Institute of Compute Science and Technology 

The MOE Key Laboratory of Computational Linguistics 

Peking University 

wanxiaojun@icst.pku.edu.cn 

Abstract 

Single-document  summarization  and  multi-
document summarization are very closely re-
lated tasks and they have been widely investi-
gated  independently.    This  paper  examines 
the  mutual  influences  between  the  two  tasks 
and proposes a novel unified approach to si-
multaneous 
single-document  and  multi-
document summarizations. The mutual influ-
ences between the two tasks are incorporated 
into a graph model and the ranking scores of a 
sentence for the two tasks can be obtained in 
a  unified  ranking  process.  Experimental  re-
sults on the benchmark DUC datasets demon-
strate  the  effectiveness  of  the  proposed  ap-
proach  for  both  single-document  and  multi-
document summarizations.  

Introduction 

1 
Single-document  summarization  aims  to  pro-
duce a concise and fluent summary for a single 
document,  and  multi-document  summarization 
aims  to  produce  a  concise  and  fluent  summary 
for a document set consisting of multiple related 
documents.  The  two  tasks  are  very  closely  re-
lated in both task definition and solution method. 
Moreover,  both  of  them  are  very  important  in 
many information systems and applications. For 
example,  given  a  cluster  of  news  articles,  a 
multi-document  summary  can  be  used  to  help 
users to understand the whole cluster, and a sin-
gle summary for each article can be used to help 
users to know the content of the specified article.  
To date, single-document and multi-document 
summarizations  have  been  investigated  exten-
sively  and  independently  in  the  NLP  and  IR 
fields. A series of special conferences or work-
shops  on  automatic  text  summarization  (e.g. 

SUMMAC,  DUC,  NTCIR  and  TAC)  have  ad-
vanced the technology and produced a couple of 
experimental online systems. However, the two 
summarization tasks have not yet been simulta-
neously investigated in a unified framework.  

Inspired by the fact that the two tasks are very 
closely related and they can be used simultane-
ously in many applications, we believe that the 
two  tasks  may  have  mutual  influences  on  each 
other.  In  this  study,  we  propose  a  unified  ap-
proach  to  simultaneous  single-document  and 
multi-document  summarizations.  The  mutual 
influences  between  the  two  tasks  are  incorpo-
rated  into  a  graph-based  model.  The  ranking 
scores of sentences for single-document summa-
rization and the ranking scores of sentences for 
multi-document  summarization  can  boost  each 
other,  and  they  can  be  obtained  simultaneously 
in a unified graph-based ranking process. To the 
best of our knowledge, this study is the first at-
tempt  for  simultaneously  addressing  the  two 
summarization  tasks  in  a  unified  graph-based 
framework.  Moreover,  the  proposed  approach 
can be easily adapted for topic-focused summa-
rizations.  

Experiments have been performed on both the 
single-document  and  multi-document  summari-
zation  tasks  of  DUC2001  and  DUC2002.  The 
results  demonstrate  that  the  proposed  approach 
can  outperform  baseline  independent  methods 
for  both  the  two  summarization  tasks.  The  two 
tasks are validated to have mutual influences on 
each other.  

The rest of this paper is organized as follows: 
Section 2 introduces related work. The details of 
the proposed approach are described in Section 
3.  Section  4  presents  and  discusses  the  evalua-
tion  results.  Lastly  we  conclude  our  paper  in 
Section 5. 

1138

for 

Extraction-based  methods 

2  Related Work 
Document summarization methods can be either 
extraction-based  or  abstraction-based.  In  this 
section, we focus on extraction-based methods.  
single-
document  summarization  usually  assign  a  sali-
ency score to each sentence in a document and 
then rank and select the sentences. The score is 
usually  computed  based  on  a  combination  of 
statistical  and  linguistic  features,  such  as  term 
frequency,  sentence  position,  cue  words  and 
stigma  words  (Luhn,  1969;  Edmundson,  1969; 
Hovy  and  Lin,  1997).  Machine  learning  tech-
niques have also been used for sentence extrac-
tion (Kupiec et al., 1995; Conroy and O’Leary, 
2001;  Shen  et  al.,  2007;  Li  et  al.,  2009).  The 
mutual  reinforcement  principle  has  been  ex-
ploited  to  iteratively  extract  key  phrases  and 
sentences from a document (Zha, 2002; Wan et 
al, 2007a). Wan et al. (2007b) propose the Col-
labSum  algorithm  to  use  additional  knowledge 
in  a  cluster  of  documents  to  improve  single 
document summarization in the cluster.   

In recent years, graph-based ranking methods 
have  been  investigated  for  document  summari-
zation, such as TextRank (Mihalcea and Tarau, 
2004;  Mihalcea  and  Tarau,  2005)  and  LexPag-
eRank  (ErKan  and  Radev,  2004).  Similar  to 
PageRank  (Page  et  al.,  1998),  these  methods 
first  build  a graph  based on  the  similarity  rela-
tionships  between  the  sentences  in  a  document 
and then the saliency of a sentence is determined 
by making use of the global information on the 
graph recursively. The basic idea underlying the 
graph-based  ranking  algorithm  is  that  of  “vot-
ing” or “recommendation” between sentences.  

summarization.  A 

Similar  methods  have  been  used  for  generic 
multi-document 
typical 
method is the centroid-based method (Radev et 
al., 2004). For each sentence, the method com-
putes a score based on each single feature (e.g. 
cluster centroids, position and TFIDF) and then 
linearly  combines  all  the  scores  into  an  overall 
sentence  score.  Topic  signature  is  used  as  a 
novel feature for selecting important content in 
NeATS (Lin and Hovy, 2002). Various sentence 
features have been combined by using machine 
learning  techniques  (Wong  et  al.,  2008).  A 
popular way for removing redundancy between 
summary sentences is the MMR algorithm (Car-
bonell and Goldstein, 1998). Themes (or topics, 

clusters) in documents have been discovered and 
used for sentence selection (Harabagiu and La-
catusu,  2005).  Hachey  (2009)  investigates  the 
effect  of  various  source  document  representa-
tions on the accuracy of the sentence extraction 
phase of a multi-document summarization task. 
Graph-based  methods  have  also  been  used  to 
rank sentences in a document set. The methods 
first  construct  a  graph  to  reflect  sentence  rela-
tionships  at  different  granularities,  and  then 
compute  sentence  scores  based  on  graph-based 
learning  algorithms.  For  example,  Wan (2008) 
proposes  to  use  only  cross-document  relation-
ships  for  graph  building  and  sentence  ranking. 
Cluster-level information has been incorporated 
in the graph model to better evaluate sentences 
(Wan and Yang, 2008).  

For  topic-focused  multi-document  summari-
zation, many methods are extensions of generic 
summarization  methods  by  incorporating  the 
information of the given topic or query into ge-
neric summarizers. In recent years, a few novel 
methods  have  been  proposed  for  topic-focused 
summarization  (Daumé  and  Marcu,  2006;  Wan 
et  al.,  2007c;  Nastase  2008;  Li  et  al.,  2008; 
Schilder and Kondadadi, 2008; Wei et al., 2008).   

The  above  previous  graph-based  summariza-
tion  methods  aim  to  address  either  single-
document  summarization  or  multi-document 
summarization, and the two summarization tasks 
have not yet been addressed in a unified graph-
based framework.  
3  The  Unified  Summarization  Ap-

proach 

3.1  Overview 
Given a document set, in which the whole docu-
ment set and each single document in the set are 
required  to  be  summarized,  we  use  local  sali-
ency to indicate the importance of a sentence in 
a  particular  document,  and  use  global  saliency 
to  indicate  the  importance  of  a  sentence  in  the 
whole document set. 

In previous work, the following two assump-
tions are widely made for graph-based summari-
zation models: 

Assumption  1:  A  sentence  is  locally  impor-
tant  in  a  particular  document  if  it  is  heavily 
linked with many locally important sentences in 
the same document.  

1139

Assumption 2: A sentence is globally impor-
tant  in  the  document  set  if  it  is  heavily  linked 
with  many  globally  important  sentences  in  the 
document set.  
   The above assumptions are the basis for Pag-
eRank-like  algorithms  for  single  document 
summarization and multi-document summariza-
tion, respectively.  In addition to the above two 
assumptions,  we  make  the  following  two  as-
sumptions to consider the mutual influences be-
tween the two summarization tasks: 

Assumption  3:  A  sentence  is  locally  impor-
tant  in  a  particular  document,  if  it  is  heavily 
linked  with  many  globally  important  sentences 
in the document set.   

The  above  assumption  is  reasonable  because 
the  documents  in  the  set  are  relevant  and  the 
globally important information in the document 
set will be expressed in many single documents. 
Therefore,  if  a  sentence  is  salient  in  the  whole 
document  set,  the  sentence  may  be  salient  in  a 
particular document in the set. 

Assumption 4: A sentence is globally impor-
tant  in  the  document  set,  if  it  is  heavily  linked 
with many locally important sentences.  

The  above  assumption  is  reasonable  because 
the  documents  in  the  set  are  relevant  and  the 
globally important information in the whole set 
is  the  aggregation  of  the  locally  important  in-
formation in each single document. Therefore, if 
a  sentence  is  salient  in  a  particular  document, 
the sentence has the potential to be salient in the 
whole document set. 

In brief, the local saliency and global saliency 
of a sentence can mutually influence and boost 
each other: high local saliency will lead to high 
global  saliency,  and  high  global  saliency  will 
lead to high local saliency.  

Based  on  the  above  assumptions,  our  pro-
posed approach first builds affinity graphs (each 
graph  is  represented  by  an  affinity  matrix)  to 
reflect  the  different  kinds  of  relationships  be-
tween  sentences,  respectively,  and  then  itera-
tively computes the local saliency scores and the 
global saliency scores of the sentences based on 
the graphs. Finally, the algorithm converges and 
the  local  saliency  score  and  global  saliency 
score  of  each  sentence  are  obtained.  The  sen-
tences with high local saliency scores in a par-
ticular document are chosen into the summary of 
the  single  document,  and  the  sentences  with 

high global saliency scores in the set are chosen 
into the summary of the document set.  

Note that for both summarization tasks, after 
the  saliency  scores  of  sentences  have  been  ob-
tained, the greedy algorithm used in (Wan et al., 
2007c)  is  applied  to  remove  redundancy  and 
finally  choose  both  informative  and  novel  sen-
tences into the summary. 
3.2  Algorithm Details 
Formally, the given document set is denoted as 
D={di|1≤i≤m},  and  the  whole  sentence  set  is 
denoted  as  S={si|1≤i≤n}.    We  let  Infosingle(si)  
denote the local saliency score of sentence si in a 
particular  document  d(si)∈D,  and  it  is  used  to 
select  summary  sentences  for  the  single  docu-
ment  d(si).      And  we  let  Infomulti(si)  denote  the 
global saliency score of sentence si in the whole 
document  set  D,    and  it  is  used  to  select  sum-
mary sentences for the document set D.  

j

j

i

j

j

j

ji

A

ji

sin

gle

gle

multi

multi

multi

multi

The  four  assumptions  in  Section  3.1  can  be 

s
(
s
(
j
s
(
s
(

 
)
 
)
 
)
j
 
)

s
(
gle
s
(
i
s
(
gle
s
(

Info
sin
Info
Info
ji
Info

Info
sin
Info
Info
sin
Info

W
(
)
W
(
)
B
W
(
)
C
j
W
(
)
jiD

rendered as follows: 
∑∝
)
i
∑∝
)
∑∝
)
i
∑∝
)

(1) 
(2) 
(3) 
(4) 
where WA, WB, WC, WD are n×n affinity matrices 
reflecting  the  different  kinds  of  relationships 
between sentences in the document set, where n 
is  the  number  of  all  sentences  in  the  document 
set. The detailed derivation of the matrices will 
be presented later. 

After fusing the above equations, we can ob-

 
(5) 

)
j
s
j
)
s

s
(
multi
s
(

Info
)
ji
Info
Info

tain the following unified forms: 
gle
sin
Info

µ
=
∑
W
Info
s
(
)
)
(
A
gle
i
sin
−+
µ
∑
W
      
          
1(
)
(
C
j
=
µ
∑
W
Info
s
(
(
)
)
multi
B
i
−+
µ
∑
W
          
)
   
1(
(
However,  the  above  summarization  method 
ignores  the  feature  of  sentence  position,  which 
has  been  validated  to  be  very  important  for 
document  summarizations.  In  order  to  incorpo-
rate  this  important  feature,  we  add  one  prior 
score to each computation as follows: 

 
  (6) 

ji
)
jiD

multi

j
(

gle

sin

)

)

(

 

 

ji

j

j

j

j

Info
sin
β
+
∑

i

s
(
gle
W
(
C

)
)

j

=

ji

α
∑
Info

j

W
(
A
s
(

Info
)
ji
⋅+
γ
)

j

j

s
(
gle
sin
prior
sin

)

multi

(

s

i

)

gle

 

 
(7) 

1140

multi

Info
β
+
∑

j

s
(
i
W
(

=

)

)
jiD

α
∑
Info

W
(

j

sin

gle

)
B
s
(

(

Info
multi
⋅+
γ
)

s
)
j
prior

multi

ji

j

 
  (8) 

 

(

s

i

)

where α, β, γ∈[0,1] specify the relative contri-
butions to the final saliency scores from the dif-
ferent  factors,  and  we  have  α+β+γ=1.  pri-
orsingle(si) is the prior score for the local saliency 
of  sentence  si,  and  here  priorsingle(si)    is  com-
puted based on sentence position of si in the par-
ticular  document  d(si).  priormulti(si)  is  the  prior 
score for the global saliency of sentence si, and 
we also compute priormulti(si) based on sentence 
position of si. 
use 

vectors 
ur =[Infosingle(si)]n×1  and  vr =[Infomulti(si)]n×1  to 
denote the local and global saliency scores of all 
the  sentences  in  the  set,  respectively.  And  the 
matrix forms of the above equations are as fol-
lows: 

column 

two 

We 

r

=
=

r
r
vWuWu
T
C
r
r
uWvWv
T
D

α
α

T
A
T
B

+
+

r

pr
sin
s
(

gle
)]

i

×
n
1

[

prior

multi

β
β
=

gle

r
sinp
γ
r
p
γ

+
 (9) 
+
  (10) 
and 
prior
[
sin
 are the prior column vec-

 
 
)]

multi
s
(

×
n
1

gle

i

where 
=
pr
multi
tors. 

The above matrices and prior vectors are con-

structed as follows, respectively: 

⎧
⎪
⎨
⎪
⎩

WA:  This  affinity  matrix  aims  to  reflect  the 
local  relationships  between  sentences  in  each 
single document, which is defined as follows: 
  
(11) 

=
s
s
sim
s
d(
,
d( if  ),
 )
ine
j
i
cos
≠
          
          
and
i  
          
     
   0,
Otherwise

 )
j
j

W
(

   

=

s

(

)

 

A

ij

i

j

j

 

(

ine

cos

⋅
×

=)

sim

r
s
j
r
s

ss
,
i

where  d(si)  refers  to  the  document  containing 
sentence si. simcosine(si,sj) is the cosine similarity 
between sentences si and sj.  
r
s
i
r
s
i

 
(12) 
where 
jsr are the corresponding term vec-
tors of si and sj. Note that we have (WA)ij = (WA)ji, 
and we have (WA)ii =0 to avoid self loops.  
   We  can  see  that  the  matrix  contains  only  the 
within-document  relationships  between  sen-
tences.  

isr  and 

WB:  This  affinity  matrix  aims  to  reflect  the 
global  relationships  between  sentences  in  the 
document set, which is defined as follows: 

W
(

)
ijB

=

sim
⎧
⎨
   0,
⎩

(

ine

ss
,
j
i
cos
Otherwise

d( if  ),

s

≠
 )

i

d(

s

 )

j

  
(13) 

    

    We can see that the matrix contains only the 
cross-document relationships between sentences. 
We  do  not  include  the  within-document  sen-
tence  relationships  in  the  matrix  because  it  has 
been  shown  that  the  cross-document  relation-
ships  are  more  appropriate  to  reflect  the  global 
mutual  influences  between  sentences  than  the 
within-document relationships in (Wan, 2008). 

WC:  This  affinity  matrix  aims  to  reflect  the 
cross-document relationships between sentences 
in the document set. However, the relationships 
in  this  matrix  are  used  for  carrying  the  influ-
ences of the sentences in other documents on the 
local  saliency  of  the  sentences  in  a  particular 
document.  If  we  directly  use  Equation  (13)  to 
compute  the  matrix,  the  mutual  influences 
would be overly used. Because other documents 
might not be sampled from the same generative 
model  as  the  specified  document,  we  probably 
do not want to trust them so much as the speci-
fied document. Thus a confidence value is used 
to reflect out belief that the document is sampled 
from the same underlying model as the specified 
document. Heuristically, we use the cosine simi-
larity  between  documents  as  the  confidence 
value.  And  we  use  the  confidence  value  as  the 
decay  factor  in  the  matrix  computation  as  fol-
lows: 

W
(
c

)

ij

=

×

sim
sim
ss
,
(
)
⎧
ine
j
i
cos
⎪
          
          
          
⎨
⎪
   0,
Otherwise
⎩

sdsd
((
)),
(
ine
j
cos
s
s
d(
d( if
       
)
    

),
≠
 )

i

   

j

i

  
(14) 

WD:  This  affinity  matrix  aims  to  reflect  the 
within-document  relationships  between  sen-
tences. Thus we have WD=WA, which means that 
the global saliency score of a sentence is influ-
enced  only  by  the  local  saliency  scores  of  the 
sentences  in  the  same  document,  without  con-
sidering the sentences in other documents.  

Note that the above four matrices are symmet-
DW  
T
ric and we can replace
by  WA,  WB,  WC  and  WD  in  Equations  (9)  and 
(10), respectively. 

CW and 

AW , 
T

BW , 
T

priorsingle(si):  It  is  computed  under  the  as-
sumption that the first sentences in a document 
are usually more important than other sentences.  

T

(

)

gle

=

s
i

prior
sin

 
(15) 
where position(si) returns the position number of 
sentence si in its document d(si). For example, if 

1
position

+
1)

5.0

s
i

+

 

(

1141

si is the first sentence in its document, position(si) 
is 1.  

The  prior weight is then normalized by: 

prior
sin

 
(16) 
priormulti(si): We  also  let  the  prior  weight  re-

prior
sin
∑
prior
sin

s
i
(

)
s

=

gle

gle

gle

s

)

(

)

(

 

i

i

i

flect the influence of sentence position. 

=

i

i

i

i

i

i

 

 

 

(

)

(

(

)

)

(

)

(

)

s

[

s

s

s

gle

=

  

=

, 

r
p

multi

]
T

multi

multi

T]

prior

(17) 
And  then  the  prior  weight  is  normalized  in  the 
same way. 

prior
sin

multi

The  above  definitions  are  for  generic  docu-
ment  summarizations  and  the  above  algorithm 
can be easily adapted for topic-focused summa-
rizations.  Given  a  topic  q,  the  only  change  for 
the above computation is priormulti(si). The topic 
relevance is incorporated into the prior weight as 
follows: 

W

T
multi

prior

prior

(18) 
 
(19) 
In order to solve the iterative problem defined 
, 

sim
ine
cos
prior
∑

qs
),
i
s
)
(
i
s
(

multi
prior

r =
in Equations (9) and (10), we let 
r
[
βα
W
W
T
   
⎡=
A
⎢
αβ
W
W
T
   
⎢
⎣
D

γ=
γ
r
r
p
single p
  
T

r
r
Tvu
T
T
⎤
C
⎥
T
⎥
⎦
B

,  and 

then  the  iterative  equations  correspond  to  the 
following linear system: 
 
=
+
r
r
r
rWr
p
−
r =
r
p
rWI
)

(20) 
(21) 
To guarantee the solution of the above linear 
system, W is normalized by columns. If all the 
elements  of  a  column  are  zero,  we  replace  the 
elements  with  1/(2n),  where  2n  equals  to  the 
element number of the column. We then multi-
ply W by a decay factor θ (0<θ<1) to scale down 
each  element  in  W,  but  remain  the  meaning  of 
W.  Here,  θ  is  empirically  set  to  0.61.  Finally, 
Equation (21) is rewritten as follows: 

(22) 
Thus,  the  matrix  (I-θW)  is  a  strictly  diago-
nally  dominant  matrix  and  the  solution  of  the 
linear system exists and we can apply the Gauss-
Seidel method used in (Li et al., 2008) to solve 
the  linear  system.  The  GS  method  is  a  well-
know  method  for  numeric  computation 
in 

⋅−
( θ
I

rW
)

r =

r
p

 

 

(

                                                 
1 In  our  pilot  study,  we  can  observe  good  performance 

when θ is in a wide range of [0.4, 0.8]. 

mathematics  and  the  details  of  the  method  is 
omitted here.  
4  Empirical Evaluation 
4.1  Dataset and Evaluation Metric 
Generic  single-document  and  multi-document 
summarizations have been the fundamental tasks 
in DUC 2001 and DUC 2002 (i.e. tasks 1 and 2 
in DUC 2001 and tasks 1 and 2 in DUC 2002), 
and  we  used  the  two  datasets  for  evaluation. 
DUC2001  provided  309  articles,  which  were 
grouped  into  30  document  sets.  Generic  sum-
mary of each article was required to be created 
for task 1, and generic summary of each docu-
ment  set  was  required  to  be  created  for  task  2. 
The  summary  length  was  100  words  or  less. 
DUC  2002  provided  59  document  sets  consist-
ing  of  567  articles  (D088  is  excluded  from  the 
original 60 document sets by NIST) and generic 
summaries  for  each  article  and  each  document 
set  with  a  length  of  approximately  100  words 
were  required  to  be  created.  The  sentences  in 
each  article  have  been  separated  and  the  sen-
tence information has been stored into files.  The 
summary of the two datasets are shown in Table 
1.  
 
Task 
Number of documents 
Number of clusters 
Data source 
summary length 

DUC 2001 
Tasks 1, 2 

DUC 2002
Tasks 1, 2 

TREC-9 
100 words 

TREC-9 
100 words 

309 
30 

567 
59 

  Table 1. Summary of datasets  

We used the ROUGE toolkit2  (Lin and Hovy, 
2003)  for  evaluation,  which  has  been  widely 
adopted  by  DUC  for  automatic  summarization 
evaluation.  It  measured  summary  quality  by 
counting  overlapping  units  such  as  the  n-gram, 
word  sequences  and  word  pairs  between  the 
candidate summary and the reference summary.  
The ROUGE toolkit reported separate recall-
oriented scores for 1, 2, 3 and 4-gram, and also 
for 
co-
occurrences.  We  showed  three  of  the  ROUGE 
metrics  in  the  experimental  results:  ROUGE-1 
(unigram-based),  ROUGE-2 
(bigram-based), 
and  ROUGE-W  (based  on  weighted  longest 
common  subsequence,  weight=1.2).  In  order  to 
truncate summaries longer than the length limit, 
                                                 
2 We used ROUGEeval-1.4.2 in this study. 

subsequence 

common 

longest 

1142

we used the “-l 100” option in ROUGE toolkit. 
We  also  used  the  “-m”  option  for  word  stem-
ming. 
4.2  Evaluation Results 
4.2.1  System Comparison 
In the experiments, the combination weight γ for 
the prior score is fixed at 0.15, as in the PageR-
ank  algorithm.  Therefore,  we  have  α+β=0.85. 
Here,  we  use  α/(α+β)  to  indicate  the  relative 
contributions of the first two parts in Equations 
(9) and (10). We empirically set α/(α+β)=0.4 in 
the experiments.  The proposed unified approach 
(i.e. UnifiedRank) is compared with a few base-
line  approaches  and  the  top  three  participating 
systems.  

The  graph-based  baselines 

single-
document  summarization  are  described  as  fol-
lows: 

BasicRank:  This  baseline  approach  adopts 
the basic PageRank algorithm to rank sentences 
based  on  all  sentence  relationships  in  a  single 
document,  similar  to  previous  work  (Mihalcea 
and Tarau, 2004).  

PositionRank:  This  baseline  approach  im-
proves  the  basic  PageRank  algorithm  by  using 
the  position  weight  of  a  sentence  as  the  prior 
score for the sentence. The position weight of a 
sentence is computed by using Equation (15). 

for 

CollabRank1:  This  baseline  approach  is  the 
“UniformLink(Gold)”  approach  proposed 
in 
(Wan et al. 2007b).  It uses a cluster of multiple 
documents to improve single document summa-
rization by constructing a global affinity graph.   
CollabRank2:  This  baseline  approach  is  the  
“UnionLink(Gold)” approach proposed in (Wan 
et al. 2007b).  

The  graph-based  baselines 

for  multi-
document  summarization  are  described  as  fol-
lows: 

BasicRank:  This  baseline  approach  adopts 
the basic PageRank algorithm to rank sentences 
based on all sentence relationships in document 
set.  Both  within-document  and  cross-document 
sentence relationships are used for constructing 
the affinity graph. 

PositionRank:  Similarly,  this  baseline  ap-
proach  improves  the  basic  PageRank  algorithm 
by using the position weight of a sentence as the 
prior score for the sentence.  

TwoStageRank:  This baseline approach lev-
erages the results of single document summari-
zation  for  multi-document  summarization.  It 
first computes the score of each sentence within 
each single document by using the PositionRank 
method,  and  then  computes  the  final  score  of 
each  sentence  within  the  document  set  by  con-
sidering  the  document-level  sentence  score  as 
the prior score in the improved PageRank algo-
rithm.  

The  top  three  systems  are  the  systems  with 
highest ROUGE scores, chosen from the partici-
pating  systems  on  each  task,  respectively.  Ta-
bles  2  and  3  show  the  comparison  results  for 
single-document  summarization  on  DUC2001 
and  DUC2002,  respectively.  Tables  4  and  5 
show the comparison results for multi-document 
summarization  on  DUC2001  and  DUC2002, 
respectively.  In  the  tables,  SystemX  (e.g.  Sys-
tem28, SystemN) represents one of the top per-
forming systems. The systems are sorted by de-
creasing order of the ROUGE-1 scores.  

For single-document summarization, the pro-
posed  UnifiedRank  approach  always  outper-
forms  the  four  graph-based  baselines  over  all 
three  metrics  on  both  two  datasets.  The  per-
formance differences are all statistically signifi-
cant  by  using 
(p-value<0.05).  The 
ROUGE-1 score of UnifiedRank is higher than 
that  of  the  best  participating  systems  and  the 
ROUGE-2  and  ROUGE-W  scores  of  Unifie-
dRank are comparable to that of the best partici-
pating systems.  

For  multi-document  summarization,  the  pro-
posed UnifiedRank approach outperforms all the 
three  graph-based  baselines  over  all  three  met-
rics on the DUC2001 dataset, and it outperforms 
the 
three  baselines  over  ROUGE-1  and 
ROUGE-W on the DUC2002 dataset. In particu-
lar,  UnifiedRank  can  significantly  outperform 
BasicRank  and  TwoStageRank  over  all  three 
metrics  on  the  DUC2001  dataset  (t-test,  p-
value<0.05).  Moreover, 
the  ROUGE-1  and 
ROUGE-W  scores  of  UnifiedRank  are  higher 
than  that  of  the  best  participating  systems  and 
the  ROUGE-2  score  of  UnifiedRank  is  compa-
rable to that of the best participating systems. 

The  results  demonstrate 

the  single-
document  and  multi-document  summarizations 
can benefit each other by making use of the mu-
tual  influences  between  the  local  saliency  and 

t-test 

that 

1143

improvement 

global  saliency  of  the  sentences.  Overall,  the 
proposed unified graph-based approach is effec-
tive  for  both  single  document  summarization 
and  multi-document  summarization.  However, 
the  performance 
for  single-
document  summarization  is  more  significant 
than  that  for  multi-document  summarization, 
which  shows  that  the  global  information  in  a 
document  set  is  very  beneficial  to  summariza-
tion  of  each  single  document  in  the  document 
set.  
 
System 

ROUGE-W
0.14328 
UnifiedRank 
CollabRank2 
0.13678 
CollabRank1 
0.13676 
PositionRank 
0.13684 
BasicRank 
0.13629 
Table 2. Comparison results for single-document 

ROUGE-2 
0.17649 
0.16229 
0.16213 
0.15936 
0.15696 

ROUGE-1
0.45377 
0.44038 
0.43890 
0.43596 
0.43407 

summarization on DUC20013 

System 

UnifiedRank 
System28 
System21 

ROUGE-2  ROUGE-W
0.21462 
0.16877 
0.17073 
0.22832 
0.16814 
0.22273 
0.16318 
0.20102 
0.20046 
0.16260 
0.16180 
0.19853 
0.16162 
0.20392 
System31 
BasicRank 
0.19457 
0.16018 
Table 3. Comparison results for single-document 

ROUGE-1
0.48478 
0.48049 
0.47754 
0.47187 
0.47028 
0.46618 
0.46506 
0.46261 

CollabRank1 
CollabRank2 
PositionRank 

summarization on DUC2002 

TwoStageRank 

System 

UnifiedRank 
PositionRank 
BasicRank 

ROUGE-1  ROUGE-2  ROUGE-W
0.10950 
0.36360 
0.10798 
0.35733 
0.35527 
0.10641 
0.10515 
0.35221 
SystemN 
0.10240 
0.33910 
SystemP 
0.10068 
0.33332 
SystemT 
0.33029 
0.10215 
Table 4. Comparison results for multi-document 

0.06496 
0.06092 
0.05608 
0.05500 
0.06853 
0.06651 
0.07862 

summarization on DUC2001 

System 

UnifiedRank 
PositionRank 
TwoStageRank 

ROUGE-1  ROUGE-2  ROUGE-W
0.12341 
0.38343 
0.12292 
0.38056 
0.12261 
0.37972 
0.12173 
0.37595 
BasicRank 
0.35151 
0.11448 
System26 
0.11332 
0.34504 
System19 
System28 
0.34355 
0.10956 
Table 5. Comparison results for multi-document 

0.07855 
0.08238 
0.08166 
0.08304 
0.07642 
0.07936 
0.07521 

summarization on DUC2002 

                                                 
3 The  summarization  results  for  participating  systems  on 

DUC2001 are incomplete. 

Influences of Combination Weight 

4.2.2 
In the above experiments, the relative contribu-
tions  from  the  first  two  parts  in  Equations  (9) 
and  (10)  are  empirically  set  as  α/(α+β)=0.4.  In 
this section, we investigate how the relative con-
tributions influence the summarization perform-
ance  by  varying  α/(α+β)  from  0  to  1.  A  small 
value  of  α/(α+β)  indicates  that  the  contribution 
from the same kind of saliency scores of the sen-
tences  is  less  important  than  the  contribution 
from the different kind of saliency scores of the 
sentences, and vice versa. Figures 1-8 show the 
ROUGE-1  and  ROUGE-W  curves  for  single-
document  summarization  and  multi-document 
summarization  on  DUC2001  and  DUC2002, 
respectively.  

For  single  document  summarization,  very 
small value or very large value for α/(α+β) will 
lower the summarization performance values on 
the  two  datasets.  The  results  demonstrate  that 
both  the  two  kinds  of  contributions  are  impor-
tant to the final performance of single document 
summarization. 

trends  of 

the  curves  on 

For  multi-document  summarization,  a  rela-
tively large value (≥0.4) for α/(α+β) will lead to 
relatively  high  performance  values  on 
the 
DUC2001  dataset,  but  a  very  large  value  for 
α/(α+β)  will  decrease  the  performance  values. 
On  the  DUC2002  dataset,  a  relatively  small 
value  (≤0.4)  will  lead  to  relatively  high  per-
formance  values,  but  a  very  small  value  for 
α/(α+β)  will  decrease  the  performance  values. 
Though 
the 
DUC2001  and  DUC2002  datasets  are  not  very 
consistent with each other, the results show that 
both  the  two  kinds  of  contributions  are  benefi-
cial to the final performance of multi-document 
summarization. 
5  Conclusion and Future Work 
In  this  study,  we  propose  a  novel  unified  ap-
proach  to  simultaneous  single-document  and 
multi-document summarization by making using 
of the mutual influences between the two tasks. 
Experimental  results  on  the  benchmark  DUC 
datasets show the effectiveness of the proposed 
approach.  

In  future  work,  we  will  perform  comprehen-
sive  experiments  for  topic-focused  document 

the 

1144

summarizations  to  show  the  robustness  of  the 
proposed approach.  

DUC2001

1
-
E
G
U
O
R

0.458
0.456
0.454
0.452
0.45
0.448
0.446
0.444

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

 
Figure 1. ROUGE-1 vs. combination weight for sin-

α/(α+β)

gle-document summarization on DUC2001 

DUC2001

W
-
E
G
U
O
R

0.1445
0.144
0.1435
0.143
0.1425
0.142
0.1415
0.141
0.1405
0.14

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

 
Figure 2. ROUGE-W vs. combination weight for 
single-document summarization on DUC2001 

α/(α+β)

DUC2002

1
-
E
G
U
O
R

0.486

0.484

0.482

0.48

0.478

0.476

0.474

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

 
Figure 3. ROUGE-1 vs. combination weight for sin-

α/(α+β)

gle-document summarization on DUC2002 

DUC2002

W
-
E
G
U
O
R

0.17

0.169

0.168

0.167

0.166

0.165

0.164

0

0.1

0.2

0.3

0.4

0.5 0.6

0.7

0.8

0.9

1

 
Figure 4. ROUGE-W vs. combination weight for 
single-document summarization on DUC2002 

α/(α+β)

DUC2001

1
-
E
G
U
O
R

0.37

0.365

0.36

0.355

0.35

0.345

0.34

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

α/(α+β)

Figure 5. ROUGE-1 vs. combination weight for 
multi-document summarization on DUC2001 

 

DUC2001

W
-
E
G
U
O
R

0.114

0.112

0.11

0.108

0.106

0.104

0.102

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

 
Figure 6. ROUGE-W vs. combination weight for 

multi-document summarization on DUC2001 

α/(α+β)

DUC2002

1
-
E
G
U
O
R

0.386

0.384

0.382

0.38

0.378

0.376

0.374

0

0.1

0.2

0.3

0.4

0.5

α/(α+β)

0.6

0.7

0.8

0.9

1

Figure 7. ROUGE-1 vs. combination weight for 
multi-document summarization on DUC2002 

 

DUC2002

W
-
E
G
U
O
R

0.125

0.124

0.123

0.122

0.121

0.12

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

 
Figure 8. ROUGE-W vs. combination weight for 

multi-document summarization on DUC2002 

α/(α+β)

Acknowledgments 
This work was supported by NSFC (60873155), 
Beijing  Nova  Program  (2008B03)  and  NCET 
(NCET-08-0006).  

1145

References  
J.  Carbonell,  J. Goldstein.  1998.  The Use of  MMR, 
Diversity-based  Reranking  for  Reordering  Docu-
ments and Producing Summaries. In Proceedings 
of SIGIR1998, 335-336. 

J. M. Conroy, D. P. O’Leary. 2001. Text Summariza-
tion  via  Hidden  Markov  Models.  In  Proceedings 
of SIGIR2001, 406-407. 

H.  Daumé  and  D.  Marcu.  2006.  Bayesian  query-
focused  summarization.  In  Proceedings  of  ACL-
06. 

H. P. Edmundson. 1969. New Methods in Automatic 
Abstracting.  Journal  of  the  Association  for  com-
puting Machinery, 16(2): 264-285. 

G.  ErKan,  D.  R.  Radev.  2004.  LexPageRank:  Pres-
tige  in  Multi-Document  Text  Summarization.  In 
Proceedings of EMNLP2004. 

B.  Hachey.  2009.  Multi-document  summarisation 
using  generic  relation  extraction.  In  Proceedings 
of EMNLP2009. 

S.  Harabagiu  and  F.  Lacatusu.  2005.  Topic  themes 
for  multi-document  summarization.  In  Proceed-
ings of SIGIR-05. 

E. Hovy, C. Y. Lin. 1997. Automated Text Summari-
In  Proceeding  of 
zation 
ACL’1997/EACL’1997  Worshop  on  Intelligent 
Scalable Text Summarization. 

in  SUMMARIST. 

J.  Kupiec,  J.  Pedersen,  F.  Chen.  1995.  A.Trainable 
In  Proceedings  of 

Document  Summarizer. 
SIGIR1995, 68-73. 

W. Li, F. Wei, Q. Lu and Y. He. 2008. PNR2: rank-
ing  sentences  with  positive  and  negative  rein-
forcement  for  query-oriented  update  summariza-
tion. In Proceedings of COLING-08. 

L.  Li,  K.  Zhou,  G.-R.  Xue,  H.  Zha,  Y.  Yu.  2009. 
Enhancing  diversity,  coverage  and  balance  for 
summarization through structure learning. In Pro-
ceedings of WWW-09. 

C..-Y.  Lin  and  E..  H.  Hovy.  2002.  From  Single  to 
Multi-document  Summarization:  A  Prototype 
System  and  its  Evaluation.  In  Proceedings  of 
ACL-02. 

C.-Y. Lin and E.H. Hovy. 2003. Automatic Evalua-
tion of Summaries  Using  N-gram  Co-occurrence 
Statistics. In Proceedings of HLT-NAACL -03. 

H. P. Luhn. 1969. The Automatic Creation of litera-
ture Abstracts. IBM Journal of Research and De-
velopment, 2(2). 

R.  Mihalcea,  P.  Tarau.  2004.  TextRank:  Bringing 
Order into Texts. In Proceedings of EMNLP2004. 
R.  Mihalcea  and  P.  Tarau.  2005.  A  language  inde-
pendent  algorithm  for  single  and  multiple  docu-

ment  summarization.  In  Proceedings  of  IJCNLP-
05. 

V.  Nastase.  2008.  Topic-driven  multi-document 
summarization with encyclopedic knowledge and 
spreading activation. In Proceedings of EMNLP-
08.  

L. Page, S. Brin, R. Motwani, and T. Winograd. 1998. 
The  pagerank  citation  ranking:  Bringing  order  to 
the web. Technical report, Stanford Digital Librar-
ies. 

D. R. Radev, H. Y. Jing, M. Stys and D. Tam. 2004. 
Centroid-based  summarization  of  multiple  docu-
ments. Information Processing and Management, 
40: 919-938. 

F.  Schilder  and  R.  Kondadadi.  2008.  FastSum:  fast 
and  accurate  query-based  multi-document  sum-
marization. In Proceedings of ACL-08: HLT. 

D.  Shen,  J.-T.  Sun,  H.  Li,  Q.  Yang,  and  Z.  Chen. 
2007.  Document  Summarization  using  Condi-
In  Proceedings  of 
tional  Random  Fields. 
IJCAI2007. 

X.  Wan.  2008.  Using  Only  Cross-Document  Rela-
tionships  for  Both  Generic  and  Topic-Focused 
Information 
Multi-Document  Summarizations. 
Retrieval, 11(1): 25-49. 

X. Wan and J. Yang. 2008. Multi-document summa-
rization using cluster-based link analysis. In Pro-
ceedings of SIGIR-08. 

X.  Wan,  J.  Yang  and  J.  Xiao.  2007a.  Towards  an 
Iterative  Reinforcement  Approach  for  Simultane-
ous  Document  Summarization  and  Keyword  Ex-
traction. In Proceedings of ACL2007.  

X.  Wan,  J.  Yang  and  J.  Xiao.  2007b.  CollabSum: 
Exploiting Multiple Document Clustering for Col-
laborative  Single  Document  Summarizations.  In 
Proceedings of SIGIR2007.  

X.  Wan,  J.  Yang  and  J.  Xiao.  2007c.  Manifold-
topic-focused  multi-document 

ranking  based 
summarization. In Proceedings of IJCAI-07.  

F.  Wei,  W.  Li,  Q.  Lu  and  Y.  He.  2008.  Query-
sensitive  mutual  reinforcement  chain  and  its  ap-
plication  in  query-oriented  multi-document  sum-
marization. In Proceedings of SIGIR-08.  

K.-F.  Wong,  M.  Wu  and  W.  Li.  2008.  Extractive 
summarization  using 
semi-
supervised learning. In Proceedings of COLING-
08. 

supervised  and 

H.  Y.  Zha.  2002.  Generic  Summarization  and  Key-
phrase  Extraction  Using  Mutual  Reinforcement 
Principle and Sentence Clustering. In Proceedings 
of SIGIR2002, 113-120. 

 

