



















































Structured Discriminative Model For Dialog State Tracking


Proceedings of the SIGDIAL 2013 Conference, pages 442–451,
Metz, France, 22-24 August 2013. c©2013 Association for Computational Linguistics

Structured Discriminative Model For Dialog State Tracking 

 

 

Sungjin Lee 

Language Technologies Institute,  

Carnegie Mellon University,        

Pittsburgh, Pennsylvania, USA 

sungjin.lee@cs.cmu.edu  

 

  

 

Abstract 

Many dialog state tracking algorithms have 

been limited to generative modeling due to the 

influence of the Partially Observable Markov 

Decision Process framework. Recent analyses, 

however, raised fundamental questions on the 

effectiveness of the generative formulation. In 

this paper, we present a structured 

discriminative model for dialog state tracking 

as an alternative. Unlike generative models, 

the proposed method affords the incorporation 

of features without having to consider 

dependencies between observations. It also 

provides a flexible mechanism for imposing 

relational constraints. To verify the 

effectiveness of the proposed method, we 

applied it to the Let’s Go domain (Raux et al., 

2005). The results show that the proposed 

model is superior to the baseline and 

generative model-based systems in accuracy, 

discrimination, and robustness to mismatches 

between training and test datasets.  

 

1 Introduction 

With the recent remarkable growth of speech-

enabled applications, dialog state tracking has 

become a critical component not only for typical 

telephone-based spoken dialog systems but also 

for multi-modal dialog systems on mobile 

devices and in automobiles. With present 

Automatic Speech Recognition (ASR) and 

Spoken Language Understanding errors, it is 

impossible to directly observe the true user goal 

and action. It is crucial, therefore, to accurately 

estimate the true dialog state from erroneous 

observations as a dialog unfolds.  

Since the Partially Observable Markov 

Decision Process (POMDP) framework has 

offered a well-founded theory for both state 

tracking and decision making, most earlier 

studies adopted generative temporal models, the 

typical way to formulate belief state updates for 

POMDP-based systems (Williams and Young, 

2007). Several approximate methods have also 

emerged to tackle the vast complexity of 

representing and maintaining belief states, e.g., 

partition-based approaches (Gasic and Young, 

2011; Lee and Eskenazi, 2012a; Williams, 2010; 

Young et al., 2010) and Bayesian network (BN)-

based methods (Raux and Ma, 2011; Thomson 

and Young, 2010). 

To verify the effectiveness of these techniques, 

some were deployed in a real user system for the 

Spoken Dialog Challenge (Black et al., 2010). 

The results demonstrated that the use of 

statistical approaches helps estimate the true 

dialog state and achieves increased robustness to 

ASR errors (Thomson et al., 2010b; Lee and 

Eskenazi 2012b; Williams, 2011; Williams, 

2012). However, further analysis also raised 

several fundamental questions about the 

formulation of the belief update as a generative 

temporal model: limitation in modeling 

correlations between observations in different 

time slices; and the insensitive discrimination 

between true and false dialog states (Williams, 

2012). There are more potential downsides of 

generative models, which will be discussed in 

detail in Section 2. 

On the other hand, natural language 

processing, computer vision and other machine 

learning research areas have increasingly 

profited from discriminative approaches. 

Discriminative approaches directly model the 

class posteriors, allowing them to incorporate a 

rich set of features without worrying about their 

dependencies on one another. This could result in 

a deficient probability distribution with 

generative models (Sutton and McCallum, 2006). 

442



The aim of this paper is to describe a first 

attempt to adopt a structured discriminative 

model for dialog state tracking. To handle 

nonlinearity of confidence score and variable 

cardinality of the possible values of output 

variables, the traditional approaches applied to 

other tasks have been modified.  

To verify the effectiveness of the proposed 

method, we applied it to the Let’s Go
1
 domain 

(Raux et al., 2005). The proposed model was 

compared with its unstructured version without 

relational constraints, the baseline system which 

always takes the top ASR hypothesis in the entire 

dialog, and finally the AT&T Statistical Dialog 

Toolkit
2
 (ASDT) which is one of the state-of-the-

art generative model-based systems. 

This paper is structured as follows. Section 2 

describes previous research and the novelty of 

our approach. Section 3 elaborates on our 

proposed structured discriminative approach. 

Section 4 explains the experimental setup. 

Section 5 presents and discusses the results. 

Finally, Section 6 concludes with a brief 

summary and suggestions for future research.  

2 Background and Related Work  

A statistical dialog system needs to update its 

dialog state when taking the action    and 
observing  . Since the POMDP framework 
assumes the Markovian property between states, 

updating a belief state involves only the previous 

belief state, the system action, and the current 

observation: 

 

  (  )     (  |  )∑ (  |    ) ( )

   

 (1) 

 

where  ( )  denotes the probability distribution 
over states  ,  ( | )  the likelihood of   given 
the state  ,  (  |    )  the state transition 
probability, and   is a normalizing constant. 

In practice, however, belief state updates 

(Equation 1) in many domains are often 

computationally intractable due to the 

tremendously large size of the belief state space. 

In order to reduce the complexity of the belief 

states, the following belief state factorization has 

been commonly applied to the belief update 

procedure (Williams et al., 2005): 

 

  (     
    )    (2) 

                                                 
1
 In this task, users call the spoken dialog system to 

2
 http://www2.research.att.com/sw/tools/asdt/ 

 
 (  |  

 )⏟    
                 

  (  
 |     

 )⏟        
                 

  

             

      ∑  (  |    
    

 )⏟        
             

  ∑  ( 
 |    

 )⏟      
          

   

          ∑  (      )   
 

where  ,  ,   , represents the user goal, the 
dialog history, and the user action, respectively. 

Partition-based approaches (Gasic and Young, 

2011; Lee and Eskenazi, 2012; Williams, 2010; 

Young et al., 2010) attempt to group user goals 

into a small number of partitions and split a 

partition only when this distinction is required by 

observations. This property endows it with the 

high scalability that is suitable for fairly complex 

domains. In partition-based approaches, the goal 

model in Equation 2 is further approximated as 

follows: 
 

∑ (  |    
 )  ∑ (  | )

  

 (3) 

  
where   is a partition from the current turn. One 
of the flaws of the partition-based approaches is 

that when one defines a partition to be a 

Cartesian product of subsets of possible values of 

multiple concepts, it will be difficult to adopt 

sophisticated prior distributions over partitions. 

That may lead to either employing very simple 

priors such as uniform distribution or 

maintaining partition structures separately for 

each concept. This is one of the main reasons 

that the previous partition-based approaches 

could not incorporate probabilistic or soft 

relational constraints into the models.  

To allow for relational constraints and 

alleviate the complexity problem at the same 

time, Dynamic Bayesian Networks (DBN) with 

more detailed structures for the user goal have 

also been developed (Thomson and Young, 

2010). Nevertheless, there is still a limitation on 

the types of constraints they can afford. Since 

DBN is a directed network, it is not quite suitable 

for specifying undirected constraints. For 

example, in the Let’s Go domain, users can say 

the same name for the arrival place as the 

departure place if they are distracted, missing the 

prompt for the arrival place and so repeating 

themselves with the departure place. It is also 

possible for some place names with similar 

pronunciations to be recognized as the same (e.g. 

Forbes and Forward). The system can, in this 

443



case, use the constraint that the departure and 

arrival places may not be identical. 

Another drawback of both approaches is that it 

is hard to incorporate a rich set of observation 

features, which are often partly dependent on 

each other. One can create a feature which 

reflects ASR error correlations between 

observations in different time slices. For example, 

a hypothesis that repeats with low confidence 

scores is likely to be a manifestation of ASR 

error correlations. Thus, the highest confidence 

score that a hypothesis has attained so far could 

be a useful feature in preventing repeated 

incorrect hypotheses from defeating the correct 

hypothesis (which had a higher score but was 

only seen once). Another useful feature could be 

the distribution of confidence scores that a 

hypothesis has attained thus far, since it may not 

have the same effect as having a single 

observation with the total score due to the 

potential nonlinearity of confidence scores. 

There are many other potentially useful features. 

The entire list of features is found in Section 3.2. 

Dynamic Probabilistic Ontology Trees (Raux 

and Ma, 2011) is another method based upon 

DBN which does not impose explicit temporal 

structures. Since it does not impose temporal 

structures, it is more flexible in considering 

multiple observations together. However, it is 

still difficult to capture co-dependent features, 

which are exemplified above, without 

introducing probabilistic deficiency due to its 

generative foundation (Appendix E). Moreover, 

the quality of the confidence score will be critical 

to all generative models up to that point since 

they do not usually try to handle potential 

nonlinearity in confidence scores. 

As far as discriminative models are concerned, 

the Maximum Entropy (MaxEnt) model has been 

applied (Bohus and Rudnicky, 2006). But the 

model is limited to a set of separate models for 

each concept, not incorporating relational 

dependencies. Also, it is restricted to maintain 

only top K-best hypotheses where K is a 

predefined parameter, resulting in potential 

degradation of performance and difficulties in 

extending it to structured models. In Section 3, 

our structured discriminative model is described. 

It is designed to take into consideration the 

aforementioned limitations of generative models 

and the previous discriminative approach. 

3 Structured Discriminative Model 

Unlike generative models, discriminative models 

directly model the class posterior given the 

observations. Maximum Entropy is one of most 

powerful undirected graphical models (Appendix 

A). But for some tasks that predict structured 

outputs, e.g. a dialog state, MaxEnt becomes 

impractical as the number of possible outputs 

astronomically grows. For example, in the Lets 

Go domain, the size of possible joint output 

configurations is around 10
17

. To address this 

problem, Conditional Random Field (CRF) was 

introduced which allows dependencies between 

output variables to be incorporated into the 

statistical model (Appendix B).  

3.1 Model Structure for Dialog State 
Tracking 

We now describe our model structure for dialog 

state tracking in detail using the Let’s Go domain 

as a running example. The graphical 

representation of the model is shown in Fig. 1. 

The global output nodes for each concept (clear 

nodes in Fig. 1) are unlike other temporal 

models, where a set of output nodes are newly 

introduced for each time slice. Instead, as a 

dialog proceeds, a set of new observations   
  

(shaded nodes in Fig. 1) are continuously 

attached to the model structure and the feature 

 
 

Figure 1: Factor graph representing the structured discriminative model in the Let’s Go domain. The shaded 

nodes show observed random variables. The smaller solid node is the deterministic parameters and explicitly 

represents parameter sharing between two associated factors.  

 

444



functions are responsible for producing fixed 

length feature vectors. The sequence of 

observations includes not only ASR N-best lists 

but also system actions from the beginning of the 

dialog to the current time slice  . Any output 
node can be freely connected to any other to 

impose desirable constraints between them 

whether or not the connections form a loop (solid 

lines in Fig. 1).  

In practice, models rely extensively on 

parameter tying, e.g., transition parameters in a 

Hidden Markov Model. One specific example of 

relational constraints and parameter tying 

naturally arises in the Let’s Go domain: the 

feature function which indicates whether a place 

is valid on a given route could use the same 

weights for both departure and arrival places (the 

solid node and the associated factor nodes in Fig. 

1). Parameter tying is also implicitly taking 

place. This is crucial for robust estimation of the 

model parameters in spite of data sparseness. 

Some concepts such as from and to can have 

about 10
4
 values but most of them are not seen in 

the training corpus. Thus we aggregate several 

feature functions which differ only by output 

labels into one common feature function so that 

they can gather their statistics together. For 

example, we can aggregate the observation 

feature functions (dotted lines in Fig. 1) 

associated with each output label except for 

None (Section 3.2). Here, None is a special value 

to indicate that the true hypothesis has not yet 

appeared in the ASR N-best lists. Since there are 

generally a large number of values for each 

concept, the probability of the true hypothesis 

will be very small unless the true hypothesis 

appears on the N-best lists. Thus we can make 

inferences on the model very quickly by focusing 

only on the observed hypotheses at the cost of 

little performance degradation. Additionally, the 

feature function aggregation allows for the entire 

observed hypotheses to be incorporated without 

being limited to only the pre-defined number of  

hypotheses.  

3.2 Model Features 

In this section, we describe the model features 

which are central to the performance of 

discriminative models. Features can be broadly 

split into observation features and relational 

features. To facilitate readers’ understanding an 

example of feature extraction is illustrated in Fig. 

2. 

One of the most fundamental features for 

dialog state tracking should exploit the 

confidence scores assigned to an informed 

hypothesis. The simplest form could be direct 

use of confidence scores. But often pre-trained 

confidence measures fail to match the empirical 

distribution of a given dialog domain (Lee and 

Eskenazi, 2012; Thomson et al. 2010a). Also the 

distribution of confidence scores that a 

hypothesis has attained so far may not have the 

same effect as the total score of the confidence 

scores (e.g., in Fig. 2, two observations for 61C 

with confidence score 0.3 vs. 0.6 which is the 

sum of the scores). Thus we create a feature 

function that divides the range of confidence 

scores into bins and returns the frequency of 

observations that fall into the corresponding bin: 
 

       (    
 )  

        {
                 (       (    

 ))

           
   
(4) 

 

where      ( )  returns the set of confidence 

scores whose action informs   in the sequence of 
observations   

 .         (   )  computes the 
frequency of observations that fall into the     
bin. 

There are two types of grounding actions 

which are popular in spoken dialog systems, i.e., 

implicit and explicit confirmation. To leverage 

affirmative or negative responses to such system 

acts, the following feature functions are 

introduced in a similar fashion as the        
feature function: 
 

 
 

Figure 2: A simplified example of feature extraction for the route concept. It shows the values that each feature 

will have when three consecutive user inputs are given. 

 

445



       (    
 )  

       {
                 (       (    

 ))

           
   
(5) 

 

       (    
 )  

       {
                 (       (    

 ))

           
   
(6) 

 

where      ( )  /      ( )  returns the set of 

confidence scores whose associated action 

affirms / negates   in the sequence of 
observations   

 . 
 

           (    
 )  

                         {
                  (    

 )

           
   

(7) 

 

where          ( ) indicates whether or not the 

user has negated the system’s implicit 

confirmation in the sequence of observations   
 . 

Another interesting feature function is the so-

called baseline feature which exploits the output 

of a baseline system. The following feature 

function emulates the output of the baseline 

system which always selects the top ASR 

hypothesis for the entire dialog: 
 

          (    
 )  

      {
            (           (    

 ))

           
   
(8) 

 

where          ( )  returns the maximum 

confidence score whose action informs   in the 
sequence of observations   

 .    (   )  indicates 
whether or not the maximum score falls into the 

    bin. 
Yet another feature function of this kind is the 

accumulated score which adds up all confidence 

scores associated with inform and affirm and 

subtracts the ones with negation: 
 

         (    
 )  

                  

{
 
 

 
              ∑     (    

 )

                           ∑     (    
 )

                           ∑     (    
 )

                 

   
(9) 

 

Note that such feature functions as 

          ( )  and          ( )  are not 
independent of the others defined previously, 

which may cause generative models to produce 

deficient probability distributions (Appendix E). 

It is known that prior information can boost 

the performance (Williams, 2012) if the prior is 

well-estimated. One of advantages of generative 

models is that they provide a natural mechanism 

to incorporate a prior. Discriminative models 

also can exploit a prior by introducing additional 

feature functions: 
 

      (    
 )  

            {
            (            ( ))
           

   
(10) 

 

where           ( ) returns the fraction of 
occurrences of   in the set of true labels. 

If the system cannot process a certain user 

request, it is highly likely that the user change 

his/her goal. The following feature function is 

designed to take care of such cases: 
 

        (    
 )  {

             ( )
           

   (11) 

 

where     ( ) indicates whether or not   is out-
of-coverage. 

As with other log-linear models, we also have 

feature functions for bias: 
 

    (    
 )    

        (    
 )   {

          
            

 
(12) 

 

Note that we have an additional bias term for 

None to estimate an appropriate weight for it. 

Regarding relational constraints, we have 

created two feature functions. To reflect the 

presumption that it is likely for the true 

hypothesis for the place concepts (i.e. from and 

to) to be valid on the true hypothesis for the 

route concept, we have: 
 

              (   )  

                             {
              (   )

                            
   

(13) 

 

where      (   )  indicates whether or not the 
place   is valid on the route  . Another feature 
function considers the situation where the same 

place name for both departure and arrival places 

is given: 
 

               (     )  

        {
           

                  

                                                       
   

(14) 

 

3.3 Inference & Parameter Estimation 

One of the common grounding actions of spoken 

dialog systems is to ask a confirmation question 

about hypotheses which do not have sufficient 

marginal beliefs. This makes marginal inference 

446



to be one of the fundamental reasoning tools for 

dialog state tracking. In treelike graphs, exact 

marginal probabilities are efficiently computable 

by using the Junction Tree algorithm (Lauritzen 

and Spiegelhalter, 1988) but in general it is 

intractable on structured models with loops.  

Since it is highly likely to have loopy 

structures in various domains (e.g. Fig. 1), we 

need to adopt approximate inference algorithms 

instead. Note that CRF (Equation 16) is an 

instance of the exponential family. For the 

exponential family, it is known that the exact 

inference can be formulated as an optimization 

problem (Wainwright and Jordan, 2008). The 

variational formulation opens the door to various 

approximate inference methods. Among many 

possible approximations, we adopt the Tree 

Reweighted Belief Propagation (TRBP) method 

which convexifies the optimization problem that 

it guarantees finding the global solution 

(Appendix C).  

On the other hand, joint inference also 

becomes important for either selecting a 

hypothesis to confirm or determining the final 

joint configuration when there exist strong 

relational dependencies between concepts. 

Moreover, we would like to find not just the best 

configuration but rather the top   configurations. 
Since the number of concept nodes is generally 

moderate, we approximate the inference by 

searching for the top   configurations only 
within the Cartesian product of the top   
hypotheses of each concept. For domains with a 

large number of concepts, one can use more 

advanced methods, e.g., Best Max-Marginal 

First (Yanover and Weiss, 2004) and Spanning 

Tree Inequalities and Partitioning for 

Enumerating Solutions (Fromer and Globerson, 

2009). 

The goal of parameter estimation is to 

minimize the empirical risk. In this paper, we 

adopt the negative of the conditional log 

likelihood (Appendix D). Given the partial 

derivative (Equation 26), we employ the 

Orthant-wise Limited-memory Quasi Newton 

optimizer (Andrew and Gao, 2007) for L1 

regularization to avoid model overfitting.  

4 Experimental Setup 

In order to evaluate the proposed method, two 

variants of the proposed method (discriminative 

model (DM) and structured discriminative model 

(SDM)) were compared with the baseline system, 

which always takes the top ASR hypothesis for 

the entire dialog and outputs the joint 

configuration using the highest average score, 

and the ASDT system as being the state-of-the-

art partition-based model (PBM). To train and 

evaluate the models, two datasets from the 

Spoken Dialog Challenge 2010 are used: a) 

AT&T system (Williams, 2011), b) Cambridge 

system (Thomson et. al, 2010b).  

For discriminative models, we used 10 bins 

for the feature functions that need to discretize 

their inputs (Section 3.2). Parameter tying for 

relational constraints was applied to dataset A 

but not to dataset B. To make sure that TRBP 

produces an upper bound on the original entropy, 

the constants    were set to be     for SDM and 
1 for DM (Appendix C). Also the weights for L1 

regularization were set to be 10 and 2.5 for the 

prior features and the other features, respectively. 

These values were chosen through cross-

validation over several values rather than doing a 

thorough search. For the ASDT system, we 

modified it to process implicit confirmation and 

incorporate the prior distribution which was 

estimated on the training corpus. The prior 

distribution was smoothed by approximate 

Good-Turing estimation on the fly when the 

system encounters an unseen value at run time. 

Two aspects of tracker performance were 

measured at the end of each dialog, i.e. Accuracy 

and Receiver Operating Characteristic (ROC). 

Accuracy measures the percent of dialogs where 

the tracker’s top hypothesis is correct. ROC 

assesses the discrimination of the top 

hypothesis’s score. Note that we considered 

None as being correct if there is no ASR 

hypothesis corresponding to the transcription. If 

all turns are evaluated regardless of context, 

concepts which appear earlier in the dialog will 

be measured more times than concepts later in 

the dialog. In order to make comparisons across 

concepts fair, concepts are only measured when 

 Route From To Date Time Joint 

Training 378 334 309 33 30 378 

Test 379 331 305 54 50 379 
 

(a) Dataset A 
 

 Route From To Date Time Joint 

Training 94 403 353 18 217 227 

Test 99 425 376 18 214 229 
 

(b) Dataset B 
 

Table 1: Counts for each concept represent the 

number of dialogs which have non-empty utterances 

for that concept. From and To concepts add up the 

counts for their sub-concepts. Joint denotes the joint 

configuration of all concepts. 

 

447



they are in focus. It does not, however, allow for 

a tracker to receive score for new estimations 

about concepts that are not in focus. In addition, 

dialogs with more turns will have a greater effect 

than dialogs with fewer turns. Therefore we only 

measure concepts which appear in the dialog at 

the last turn of the dialog before restart. The 

statistics of the training and test datasets are 

summarized in Table 1. 

5 Results and Discussion  

The results indicate that discriminative methods 

outperform the baseline and generative method 

by a large performance gap for both dataset A 

and B (Table 2). Also, SDM exceeds DM, 

demonstrating the effectiveness of using 

relational constraints. Furthermore, the 

performance of SDM surpasses that of the best 

system in the Dialog State Tracking Challenge
3
 

(Lee and Eskenazi, 2013). Even though the 

generative model underperforms discriminative 

models, it is also shown that dialog state tracking 

methods in general are effective in improving 

robustness to ASR errors. Another noteworthy 

result is that the gains for Joint by using 

discriminative models are much larger than those 

for All. Estimating joint configurations correctly 

is crucial to eventually satisfy the user’s request. 

This result implies that the proposed model 

performs evenly well for all concepts and is more 

robust to the traits of each concept. For example, 

PBM works relatively poorly for To on dataset A. 

What makes To different is that the quality of the 

                                                 
3
 http://research.microsoft.com/en-us/events/dstc/ 

ASR hypotheses of the training data is much 

better than that of test data: the baseline accuracy 

on the training data is 84.79% while 77.05% on 

the test data. Even though PBM suffers this 

mismatch, the discriminative models are doing 

well without significant differences, implying 

that the discriminative models achieve 

robustness by considering not just the confidence 

score but also several features together. 

Since there has been no clear evidence that the 

use of N-best ASR hypotheses is helpful for 

dialog state tracking (Williams, 2012), we also 

report accuracies while varying the number of N-

best hypotheses. The results show that the use of 

N-bests helps boost accuracy across all models 

on dataset A. However, interestingly it hampers 

the performance in the case of dataset B. It 

demonstrates that the utility of N-bests depends 

on various factors, e.g., the quality of N-bests 

and dialog policies. The system which yielded 

dataset A employs implicit and explicit 

confirmation much more frequently than the 

system which produced dataset B does. The 

proposed model trained on dataset A without 

confirmation features incorporated actually 

showed a slight degradation in accuracy when 

using more than 3-bests. This result indicates that 

we need to take into consideration the type of 

dialog strategy to determine how many 

hypotheses to use. Thus, it can be conceivable to 

dynamically change the range of N-bests 

according to how a dialog proceeds. That allows 

the system to reduce processing time when a 

dialog goes well. 

 All (%)  Joint 

N-best Baseline PBM DM SDM  Baseline PBM DM SDM 

1-best 74.80 77.93 83.65 83.74  53.56 54.62 60.16 60.69 

3-best 74.80 84.00 88.83 89.10  53.56 64.38 70.18 70.98 

5-best 74.80 84.54 89.54 89.81  53.56 65.70 72.30 73.09 

All 74.80 84.81 89.81 90.26  53.56 65.96 73.09 74.67 
 

(a) Dataset A 

 

 All  Joint 

N-best Baseline PBM DM SDM  Baseline PBM DM SDM 

1-best 65.46 68.73 78.00 80.12  11.35 12.23 26.20 30.13 

3-best 65.46 68.02 78.00 79.51  11.35 11.35 27.51 28.82 

5-best 65.46 67.40 77.92 79.15  11.35 11.79 24.89 25.76 

All 65.46 66.61 78.00 79.24  11.35 11.79 24.89 25.76 
 

(b) Dataset B 
 

Table 2: Accuracy of the comparative models. The best performaces across the models are marked in bold. All 

means a weighted average accuracy across all concepts. 

448



The ROC curves assess the discrimination of 

the top hypothesis’ score (Fig. 3). Note that the 

discriminative models are far better than PBM on 

both dataset A and B. In fact, PBM turns out to 

be even worse than the baseline. The better 

discrimination can give rise to additional values 

of a tracker. For example, it can reduce 

unnecessary confirmations for values with 

sufficiently high belief. Also, it enables a model 

to adapt to test data in an unsupervised manner 

by allowing us to set a proper threshold to 

produce predictive labels.  

6 Conclusion 

In this paper, we presented the first attempt, to 

our knowledge, to create a structured 

discriminative model for dialog state tracking. 

Unlike generative models, the proposed method 

allows for the incorporation of various features 

without worrying about dependencies between 

observations. It also provides a flexible 

mechanism to impose relational constraints. The 

results show that the discriminative models are 

superior to the generative model in accuracy, 

discrimination, and robustness to mismatches 

between training and test datasets. Since we used 

relatively simple features for this work, there is 

much room to boost performance through feature 

engineering. Also, more thorough search for 

regularization weights can give additional 

performance gain. Moreover, one can apply 

different loss functions, e.g., hinge loss to obtain 

structured support vector machine. In order to 

further confirm if the performance improvement 

by the proposed method can be translated to the 

enhancement of the overall spoken dialog 

system, we need to deploy and assess it with real 

users. 

Acknowledgments 

This work was funded by NSF grant IIS0914927. 

The opinions expressed in this paper do not 

necessarily reflect those of NSF. The author 

would like to thank Maxine Eskenazi for helpful 

comments and discussion. 

References  

G. Andrew and J. Gao, 2007. Scalable training of L1-

regularized log-linear models. In Proceedings of 

ICML. 

A. Black et al., 2011. Spoken dialog challenge 2010: 

Comparison of live and control test results. In 

Proceedings of SIGDIAL. 

D. Bohus and A. Rudnicky, 2006. A K hypotheses + 

other belief updating model. In Proceedings of 

AAAI Workshop on Statistical and Empirical 

Approaches for Spoken Dialogue Systems. 

M. Fromer and A. Globerson, 2009. An LP View of 

the M-best MAP problem. Advances in Neural 

Information Processing Systems, 22:567-575. 

M. Gasic and S. Young, 2011. Effective handling of 

dialogue state in the hidden information state 

POMDP-based dialogue manager. ACM 

Transactions on Speech and Language Processing, 

7(3). 

S. Lauritzen and D. J. Spiegelhalter, 1988. Local 

Computation and Probabilities on Graphical 

Structures and their Applications to Expert 

Systems. Journal of Royal Statistical Society, 

50(2):157–224. 

S. Lee and M. Eskenazi, 2012a. Exploiting Machine-

Transcribed Dialog Corpus to Improve Multiple 

Dialog  States Tracking Methods. In Proceedings 

of SIGDIAL, 2012. 

 

 
Figure 3: Weighted average ROC curves across all concepts 

449



S. Lee and M. Eskenazi, 2012b. POMDP-based Let’s 

Go System for Spoken Dialog Challenge. In 

Proceedings of SLT. 

S. Lee and M. Eskenazi, 2013. Recipe For Building 

Robust Spoken Dialog State Trackers: Dialog State 

Tracking Challenge System Description. Submitted 

to SIGDIAL, 2013. 

A. Raux, B. Langner, D. Bohus, A. W Black, and M. 

Eskenazi, 2005. Let’s Go Public! Taking a Spoken 

Dialog System to the Real World. In Proceedings 

of Interspeech. 

A. Raux and Y. Ma, 2011. Efficient Probabilistic 

Tracking of User Goal and Dialog History for 

Spoken Dialog Systems. In Proceedings of 

Interspeech. 

C. Sutton and A. McCallum, 2006. An Introduction to 

Conditional Random Fields for Relational 

Learning. Introduction to Statistical Relational 

Learning. Cambridge: MIT Press. 

B. Thomson and S. Young, 2010. Bayesian update of 

dialogue state: A POMDP framework for spoken 

dialogue systems. Computer Speech & Language, 

24(4):562-588. 

B. Thomson, F. Jurccek, M. Gasic, S. Keizer, F. 

Mairesse, K. Yu, S. Young, 2010a. Parameter 

learning for POMDP spoken dialogue models. In 

Proceedings of SLT.  

B. Thomson, K. Yu, S. Keizer, M. Gasic, F. Jurcicek, 

F. Mairesse, S. Young, 2010b. Bayesian dialogue 

system for the Let's Go spoken dialogue challenge. 

In Proceedings of SLT. 

M. Wainwright and M. Jordan, 2008. Graphical 

Models, Exponential Families, and Variational 

Inference. Foundations and Trends in Machine 

Learning, 1(1-2):1–305. 

J. Williams and S. Young, 2007. Partially observable 

Markov decision processes for spoken dialog 

systems. Computer Speech & Language, 

21(2):393-422. 

J. Williams, 2010. Incremental partition 

recombination for efficient tracking of multiple 

dialog states. In Proceedings of ICASSP. 

J. Williams, 2011. An Empirical Evaluation of a 

Statistical Dialog System in Public Use, In 

Proceedings of SIGDIAL. 

J. Williams, 2012. A Critical Analysis of Two 

Statistical Spoken Dialog Systems in Public Use. 

In Proceedings of SLT. 

C. Yanover and Y. Weiss, 2004. Finding the M Most 

Probable Configurations Using Loopy Belief 

Propagation. In Advances in Neural Information 

Processing Systems 16. MIT Press.  

S. Young, M. Gasic, S. Keizer, F. Mairesse, J. Schatz-

mann, B. Thomson and K. Yu, 2010. The Hidden 

Information State Model: a practical framework for 

POMDP-based spoken dialogue management. 

Computer Speech and Language, 24(2):150–174. 

Appendix A. Maximum Entropy 

Maximum Entropy directly models the class 

posterior given the observations:  
 

 ( | )  
 

 ( )
   (   (   ))   (15) 

 

where  ( ) is a normalization function,   the model 
parameters, and  (   ) the vector of feature functions 
which are key to performance. 

Appendix B. Conditional Random Field 

Let   be a factor graph over outputs  . Then, if 
the distribution  ( | ) factorizes according to   
and   *  +  is the set of factors in  , the 
conditional distribution can be written as: 
 

 ( | )  
 

 ( )
∏    (  

  (     ))

    

 (16) 

 

In practice, models rely extensively on parameter 

tying. To formalize this, let the factors of   be 
partitioned to   *          +, where each    

is a clique template whose parameters are tied. 

Each clique template is a set of factors which has 

an associated vector of feature functions 

  (     )  and parameters   . From these it 

follows (Sutton and McCallum, 2006):  
 

 ( | )  
 

 ( )
∏ ∏    (  

  (     ))

         

 (17) 

 

where the normalizing function is: 
 

 ( )  ∑ ∏ ∏    (  
  (     ))

          

 (18) 

 

Appendix C. Tree-reweighted Belief Propagation 

Unlike treelike graphs, computing exact marginal 

probabilities is in general intractable on 

structured models with loops. Therefore, we need 

to adopt approximate inference algorithms 

instead. Note that CRF (Equation 16) is an 

instance of exponential family: 
 

 (   )      (   ( )   ( )) (19) 
 

where   is a function of the observations   and 
the parameters   above,  ( ) a vector of 
sufficient statistics consisting of indicator 

functions for each configuration of each clique 

and each variable, and  ( ) is the log-partition 

450



function    ∑     (   ( ) ) . For exponential 
family, it is known that the exact inference can 

be formulated as an optimization problem 

(Wainwright and Jordan, 2008): 
 

 ( )     
   

     ( ) (20) 
 

where   *  |       ( )+ is the marginal 
polytope,  ( ) is the mapping from parameters 
to marginals, and  ( ) is the entropy. Applying 
Danskin’s theorem to Equation 20 yields: 
 

 ( )  
  

  
       

   
     ( ) (21) 

 

Thus both the partition function (Equation 20) 

and marginals (Equation 21) can be computed at 

once. The variational formulation opens the door 

to various approximate inference methods: to 

derive a tractable algorithm, one approximates 

the log-partition function  ̃( )  by using a 
simpler feasible region of   and a tractable  ( ). 
Then the approximate marginals are taken as the 

exact gradient of  ̃ . Among many possible 
approximations, we adopt the Tree Reweighted 

Belief Propagation (TRBP) method which 

convexifies the optimization problem that it 

guarantees finding the global solution. TRBP 

takes the local polytope as a relaxation of the 

marginal polytope: 
 

  * |∑ (  )

    

  (   ) ∑ (  )

  

    + (22) 

 

where  and   index each clique and output 
variable, respectively. TRBP approximates the 

entropy as follows: 
 

 ( )  ∑ (  )  ∑    (  )

  

 (23) 

 

where  ( )  denotes the mutual information and 
the constants    need to be selected so that they 
generate an upper bound on the original entropy. 
 

Appendix D. Parameter Estimation For 

Conditional Random Field 

The goal of parameter estimation is to minimize 

the empirical risk: 
 

 ( )  ∑ (       )

 

 (24) 

 

where there is summation over all training 

examples. The loss function  (       ) 
quantifies the difference between the true and 

estimated outputs. In this paper, we adopt the 

negative of the conditional log likelihood: 

 ( )  ∑ ∑   
  (     )

         

     ( ) (25) 

 

The partial derivative of the log likelihood with 

respect to a vector of parameters    associated 

with a clique template    is: 
  

  

   
 ∑   (     )

     

 

              ∑ ∑  (  
    )

  
      

 (  
 |  ) 

(26) 

 

Appendix E. Probabilistic Deficiency 

To include interdependent features in a 

generative model, we have two choices: enhance 

the model to represent dependencies among the 

inputs, or make independence assumptions. The 

first approach is often difficult to do while 

retaining tractability. For example, it is hard to 

model the dependence between        , 
       ,        ,            , and 
         . On the other hand, the second 
approach can hurt performance by resulting in 

poor probability estimates. Let’s consider the 

joint probability  (         )  which the 
generative approach is based on. Because of the 

independence assumption, the joint probability 

can be written as  ( ) (  | )  (  | ) . For 
example, let’s assume that we observe two 

hypotheses 61D and 61B with confidence score 

0.6 and 0.2, respectively. Then the conditional 

probabilities can be written as: 
 

 (                       |   )  
                (         |   )   

                         (             |   )  
 

 (                       |   ) 
          (         |   )   
              (             |   ) 

 

Since           and                have 
a strong correlation, their probability estimates 

should also be positively correlated. To simplify 

the discussion, now suppose 61B and 61D are 

equiprobable,  (   )    (   )  and have 
similar conditional probabilities: 
 

 (         |   )    (         |   ) 
 (             |   )    
                                          (             |   ) 

 

Then, multiplying those conditional probabilities, 

 (         | )   (             | ) , 
will increase or decrease the confidence of the 

classifier too much, even though no new 

evidence has been added. 

451


