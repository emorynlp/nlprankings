










































A Synchronous Context Free Grammar for Time Normalization


Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 821–826,
Seattle, Washington, USA, 18-21 October 2013. c©2013 Association for Computational Linguistics

A synchronous context free grammar for time normalization

Steven Bethard
University of Alabama at Birmingham

Birmingham, Alabama, USA
bethard@cis.uab.edu

Abstract

We present an approach to time normalization
(e.g. the day before yesterday⇒2013-04-12)
based on a synchronous context free grammar.
Synchronous rules map the source language
to formally defined operators for manipulat-
ing times (FINDENCLOSED, STARTATENDOF,
etc.). Time expressions are then parsed using
an extended CYK+ algorithm, and converted
to a normalized form by applying the opera-
tors recursively. For evaluation, a small set
of synchronous rules for English time expres-
sions were developed. Our model outperforms
HeidelTime, the best time normalization sys-
tem in TempEval 2013, on four different time
normalization corpora.

1 Introduction

Time normalization is the task of converting a natural
language expression of time into a formal representa-
tion of a time on a timeline. For example, the expres-
sion the day before yesterday would be normalized
to the formal representation 2013-04-12 (assuming
that today is 2013-04-14) in the ISO-TimeML rep-
resentation language (Pustejovsky et al., 2010). Time
normalization is a crucial part of almost any infor-
mation extraction task that needs to place entities or
events along a timeline. And research into methods
for time normalization has been growing since the
ACE1 and TempEval (Verhagen et al., 2010; UzZa-
man et al., 2013) challenges began to include time
normalization as a shared task.

1http://www.itl.nist.gov/iad/mig/tests/ace/

Most prior work on time normalization has taken
a rule-based, string-to-string translation approach.
That is, each word in a time expression is looked up
in a normalization lexicon, and then rules map this
sequence of lexical entries directly to the normalized
form. HeidelTime (Strötgen and Gertz, 2012), which
had the highest performance in TempEval 2010 and
2013, and TIMEN (Llorens et al., 2012), which re-
ported slightly higher performance in its own experi-
ments, both follow this approach. A drawback of this
approach though is that there is no nesting of rules:
for example, in HeidelTime the rules for yesterday
and the day before yesterday are completely separate,
despite the compositional nature of the latter.

A notable exception to the string-to-string ap-
proach is the work of (Angeli et al., 2012). They de-
fine a target grammar of typed pre-terminals, such as
YESTERDAY (a SEQUENCE) or DAY (a DURATION),
and compositional operations, such as SHIFTLEFT
(a (RANGE, DURATION) → RANGE). They apply
an expectation-maximization approach to learn how
words align to elements of the target grammar, and
achieve performance close to that of the rule-based
systems. However, their grammar does not allow
for non-binary or partially lexicalized rules (e.g. SE-
QUENCE → DURATION before SEQUENCE would
be impossible), and some of their primitive elements
could naturally be expressed using other primitives
(e.g. YESTERDAY as SHIFTLEFT(TODAY, 1 DAY)).

We present a synchronous grammar for time nor-
malization that addresses these shortcomings. We
first define a grammar of formal operations over tem-
poral elements. We then develop synchronous rules
that map time expression words to temporal opera-

821



Source: English

[TIMESPAN]1

[UNIT]2

[NIL]4

the

week

of [TIMESPAN]3

[FIELD]5

[FIELD:MONTH]6

March

[FIELD:DAY]7

[INT:1-31]8

6

Target: Time Operators

[TIMESPAN]1

FINDENCLOSING [TIMESPAN]3

FINDEARLIER PRESENT [FIELD]5

[FIELD:MONTH]6

MONTHOFYEAR 3

[FIELD:DAY]7

DAYOFMONTH [INT:1-31]8

6

[UNIT]2

WEEKS

Figure 1: The synchronous parse from the source language the week of March 6 to the target formal time representation
FINDENCLOSING(FINDEARLIER(PRESENT, MONTHOFYEAR→3, DAYOFMONTH→6), WEEKS). Subscripts on
non-terminals indicate the alignment between the source and target parses.

tors, and perform normalization by parsing with an
extended CYK+ parsing algorithm. We evaluate this
approach to time normalization on the TimeBank,
AQUAINT, Timen and TempEval 2013 corpora.

2 Synchronous grammars

Our time grammar is based on the synchronous con-
text free grammar formalism. Synchronous gram-
mars allow two trees, one in the source language
and one in the target language, to be constructed si-
multaneously. A synchronous context free grammar
has rules of the form X → (S,T, A), where X is a
non-terminal, S is the sequence of terminals and non-
terminals that X expands to in the source language,
T is the sequence of terminals and non-terminals
that X expands to in the target language, and A is
the alignment between the non-terminals of S and T
(which must be the same).

For time normalization, the source side is the nat-
ural language text, and the target side is a formal
grammar of temporal operators. Figure 1 shows a
synchronous parse of the week of March 6 2. The left
side is the source side (an English expression), the
right side is the target side (a temporal operator ex-
pression), and the alignment is shown via subscripts.

2Figure 1 corresponds to an interpretation along the lines of
the week of the last March 6. The full grammar developed in this
article would also produce an interpretation corresponding to the
week of the next March 6, since the phrase is ambiguous.

3 Target time grammar

The right side of Figure 1 shows an example of
our target formal representation: FINDENCLOSING(
FINDEARLIER(PRESENT, MONTHOFYEAR→3,
DAYOFMONTH→6), WEEKS). Each terminal in
the parse is either a numeric value or an opera-
tor like FINDENCLOSING, WEEKS or MONTHOF-
YEAR. Each non-terminal combines terminals or
non-terminals to create a [TIMESPAN], [PERIOD],
[FIELD], [UNIT] or [INT]. The list of rules allowed
by our target grammar (the right-hand side of our
synchronous grammar) is given in Table 1.

Each of the target operators defines a procedure for
creating a temporal object from others. For example,
FINDENCLOSING takes a [TIMESPAN] and a [UNIT]
and expands the start and end of the time span to fill
a period of one unit. This could be used, for exam-
ple, to define today as FINDENCLOSING(PRESENT,
DAYS), where the PRESENT, which is instantaneous,
is expanded out to the enclosing day. Note that we
define things like today and yesterday in terms of
primitive operations, rather than making them primi-
tives themselves as in (Angeli et al., 2012).

The left side of Figure 1 shows the synchronous
parse of the source language. Note that each of the
non-terminals is aligned (shown as a subscript) with
a non-terminal in the target parse3, while terminals
are not aligned and may freely appear or disappear

3We actually allow a slightly asynchronous grammar, where
a non-terminal may be used 0 or more times on the target side.

822



[INT] → integer
[UNIT] → unit
[FIELD] → field [INT]
[FIELD] → [FIELD]*
[PERIOD] → SIMPLE [INT] [UNIT]
[PERIOD] → FRACTIONAL [INT] [INT] [UNIT]
[PERIOD] → UNSPECIFIED [UNIT]
[PERIOD] → WITHMODIFIER [PERIOD] modifier
[TIMESPAN] → PAST
[TIMESPAN] → PRESENT
[TIMESPAN] → FUTURE
[TIMESPAN] → FINDEARLIER [TIMESPAN] [FIELD]
[TIMESPAN] → FINDLATER [TIMESPAN] [FIELD]
[TIMESPAN] → FINDENCLOSING [TIMESPAN] [UNIT]
[TIMESPAN] → FINDENCLOSED [TIMESPAN] [FIELD]
[TIMESPAN] → STARTATENDOF [TIMESPAN] [PERIOD]
[TIMESPAN] → ENDATSTARTOF [TIMESPAN] [PERIOD]
[TIMESPAN] → MOVEEARLIER [TIMESPAN] [PERIOD]
[TIMESPAN] → MOVELATER [TIMESPAN] [PERIOD]
[TIMESPAN] → WITHMODIFIER [TIMESPAN] modifier

Table 1: Rules allowed by the target time grammar.
A “unit” is any java.time.temporal.TemporalUnit,
e.g. SECONDS, WEEKS or DECADES. A “field” is any
java.time.temporal.TemporalField, e.g. HOUR-
OFAMPM, DAYOFMONTH or CENTURY. A “modifier”
is any of the TIMEX3 “mod” values defined in TimeML.

from the source to the target. Each non-terminal thus
corresponds to a synchronous grammar rule that de-
scribes how a source expression should be translated
into the target time grammar. For example the root
nodes correspond to an application of the following
full synchronous rule:

[TIMESPAN]→
source: [UNIT] of [TIMESPAN]
target: FINDENCLOSING [TIMESPAN] [UNIT]

4 Parsing algorithm

Parsing with a synchronous context free grammar is
much the same as parsing with just the source side of
the grammar. Only a small amount of bookkeeping is
necessary to allow the generation of the target parse
once the source parse is complete. We can therefore
apply standard parsing algorithms to this task.

However, we have some additional grammar re-
quirements. As shown in Figure 1, we allow rules
that expand into more than two terminals or non-
terminals, the mixing of terminals and non-terminals
in a production, a special [NIL] non-terminal for the
ignoring of words, and a special [INT] non-terminal
that can match ranges of integers and does not re-
quire all possible integers to be manually listed in

the grammar. This means that we can’t directly use
CYK parsing or even CYK+ parsing (Chappelier and
Rajman, 1998), which allows rules that expand into
more than two terminals or non-terminals, but does
not meet our other requirements.

Algorithm 1 shows our extended version of CYK+
parsing. As with standard CYK+ parsing, two charts
are filled, one for rules that have been completed (C)
and one for rules that have been only partially ad-
vanced (P ). All parses covering 1 terminal are com-
pleted first, then these are used to complete parses
covering 2 terminals, etc. until all parses covering all
terminals are complete.

Our extensions to the standard CYK+ parsing are
as follows. To handle integers, we modify the ini-
tialization to generate new rules on the fly for any
numeric terminals that fit the range of an [INT:X-Y]
non-terminal in the grammar (starts at line 5). To
allow mixing of terminals and non-terminals, we ex-
tend the initialization step to also produce partial
parses (line 17), and extend the parse advancement
step to allow advancing rules with terminals (starting
at line 23). Finally, to handle [NIL] rules, which con-
sume tokens but are not included in the final parse,
we add a step where rules are allowed to advance,
unchanged, past a [NIL] rule (starting at line 35).

5 Parsing example
As an example, consider parsing the week of March
6 with the following source side grammar:

[NIL] → the
[UNIT] → week
[MONTH] → March
[DAY] → [INT:1-31]
[FIELD] → [MONTH][DAY]
[TIMESPAN] → [FIELD]
[TIMESPAN] → [UNIT] of [TIMESPAN]

First the algorithm handles the numeric special case,
completing an [INT] parse for the token 6 at index 4:
C(1,4) ∪= [INT:1-31] → 6

Then it completes parses based on just the terminals:
C(1,0) ∪= [NIL] → the
C(1,1) ∪= [UNIT] → week
C(1,3) ∪= [MONTH] → March

Next, the algorithm starts working on parses that
span 1 token. It can start two partial parses, using the
[UNIT] at C(1,1), and using the [MONTH] at C(1,3):
P(1,1) ∪= [TIMESPAN] → [UNIT] • of [TIMESPAN]
P(1,3) ∪= [FIELD] → [MONTH] • [DAY]

823



Algorithm 1 CYK+ parsing, extended for partially
lexicalized rules, [Nil] rules and numbers
Require: G a set of rules, w a sequence of tokens

1: function PARSE(G,w)
2: C ← a new |w|+ 1 by |w| matrix
3: P ← a new |w|+ 1 by |w| matrix
4: // Generate rules on the fly for numeric tokens
5: for i← 0 . . . (|w| − 1) do
6: if ISNUMBER(wi) then
7: for all [INT:x-y] ∈ non-terminals of G do
8: if x ≤ TONUMBER(wi) ≤ y then
9: C(1,i) ∪= [INT:x-y]→ wi

10: // Start any rules that begin with terminals
11: for i← 0 . . . (|w| − 1) do
12: for all X→ αβ ∈ G do
13: if ∃j | α = wi:j ∧ ¬ISTERMINAL(β0) then
14: if β = � then
15: C(|wi:j |,i) ∪= X→ wi:jα
16: else
17: P(|wi:j |,i) ∪= (|wi:j |,X→ wi:jα)
18: for n← 1 . . . |w|; i← 0 . . . (|w| − n) do
19: // Find all parses of size n starting at i
20: for m← 1 . . . n do
21: for all (p,X→ α) ∈ P(m,i) do
22: // Advance partial parses using terminals
23: if wi+m:i+n = αp:p+n−m then
24: if αp+n−m:|α| = � then
25: C(n,i) ∪= X→ α
26: else
27: P(n,i) ∪= (p+ n−m,X→ α)
28: // Advance partial parses using completes
29: for all αp → β ∈ C(n−m,i+m) do
30: if |α| = p+ 1 then
31: C(n,i) ∪= X→ α
32: else
33: P(n,i) ∪= (p+ 1,X→ α)
34: // Advance complete parses past [Nil] parses
35: for all X→ α ∈ C(m,i) do
36: for all Y→ β ∈ C(n−m,i+m) do
37: if X 6= Nil ∧ Y = Nil then
38: C(n,i) ∪= X→ α
39: else if X = Nil ∧ Y 6= Nil then
40: C(n,i) ∪= Y→ β
41: // Start any rules that begin with a complete parse
42: for all X→ α ∈ C(n,i) do
43: for all Y→ Xα ∈ C(n,i) do
44: if α = � then
45: C(n,i) ∪= Y→ Xα
46: else
47: P(n,i) ∪= (1,Y→ Xα)
48: return C(|w|,0)

(The • is the visual equivalent of the first element in
the partial parse tuples of Algorithm 1, which marks
parsing progress.) And given the [INT:1-31] atC(1,4)
the algorithm can make a complete size 1 parse:
C(1,4) ∪= [DAY] → [INT:1-31]

The algorithm then moves on to create parses that
span 2 tokens. The special handling of [NIL] allows
the [UNIT] at C(1,1) to absorb the [NIL] at C(1,0):

C(2,0) ∪= [UNIT] → week
This [UNIT] then allows the start of a partial parse:
P(2,0) ∪= [TIMESPAN] → [UNIT] • of [TIMESPAN]

The partial parse at P(1,1) can be advanced using of
at position 2, creating another 2 token partial parse:
P(2,1) ∪= [TIMESPAN] → [UNIT] of • [TIMESPAN])

The partial parse at P(1,3) can be advanced using the
[DAY] at C(1,4), completing the 2 token parse:

C(2,3) ∪= [FIELD] → [MONTH][DAY]
This [FIELD] allows completion of a 2 token parse:
C(2,3) ∪= [TIMESPAN] → [FIELD]

The algorithm then moves on to 3 token parses. Only
one is possible: the partial parse at P(2,0) can be
advanced using the of at position 2, yielding:
P(3,0) ∪= [TIMESPAN] → [UNIT] of • [TIMESPAN]

The algorithm moves on to 4 token parses, finding
that the partial parse at P(2,1) can be advanced using
the [TIMESPAN] at C(2,3), completing the parse:

C(4,1) ∪= [TIMESPAN] → [UNIT] of [TIMESPAN]
Finally, the algorithm moves on to 5 token parses,
where (1) the special handling of [NIL] allows the
partial parse at C(4,1) to consume the [NIL] at C(1,0)
and (2) the partial parse at P(3,0) can be advanced
using the [TIMESPAN] at C(2,3). Both of these yield:

C(5,0) ∪= [TIMESPAN] → [UNIT] of [TIMESPAN]

The complete parses in C(5,0) are then determinis-
tically translated into target side parses using the
alignments in the rules of the synchronous grammar.

6 Evaluation

Using our synchronous grammar formalism for time
normalization, we manually developed a grammar
for English time expressions. Following the lead of
TIMEN and HeidelTime, we developed our grammar
by inspecting examples from the AQUAINT4 and

4http://www.ldc.upenn.edu/Catalog/
catalogEntry.jsp?catalogId=LDC2002T31

824



N TIMEN HeidelTime SCFG
AQUAINT 652 69.5 74.7 76.5
TimeBank 1426 67.7 80.9 84.9
Timen 214 67.8 49.1 56.5
TempEval2013 158 74.1 78.5 81.6

Table 2: Performance of TIMEN, HeidelTime and our
synchronous context free grammar (SCFG) on each evalu-
ation corpus. (N is the number of time expressions.)

TimeBank (Pustejovsky et al., 2003) corpora. The
resulting grammar has 354 rules, 192 of which are
only lexical, e.g., [UNIT]→ (seconds, SECONDS).

Our grammar produces multiple parses when the
input is ambiguous. For example, the expression
Monday could mean either the previous Monday or
the following Monday, and the expression the day
could refer either to a period of one day, or to a spe-
cific day in time, e.g. 2013-04-14. For such expres-
sions, our grammar produces both parses. To choose
between the two, we employ a very simple set of
heuristics: (1) prefer [TIMESPAN] to [PERIOD], (2)
prefer an earlier [TIMESPAN] to a later one and (3)
prefer a [TIMESPAN] with QUARTERS granularity
if the anchor time is also in QUARTERS (this is a
common rule in TimeBank annotations).

We evaluate on the AQUAINT corpus, the Time-
Bank corpus, the Timen corpus (Llorens et al., 2012)
and the TempEval 2013 test set (UzZaman et al.,
2013)5. We compare to two6 state-of-the-art systems:
TIMEN and HeidelTime. Table 2 shows the results.
Our synchronous grammar approach outperformed
HeidelTime on all corpora, both on the training cor-
pora (AQUAINT and TimeBank) and on the test cor-
pora (Timen and TempEval 2013). Both our model
and HeidelTime outperformed TIMEN on all corpora
except for the Timen corpus.

To better understand the issues in the Timen cor-
pus, we manually inspected the 33 time expressions
that TIMEN normalized correctly and our approach

5We evaluate normalization accuracy over all time expres-
sions, not the F1 of both finding and normalizing expressions, so
the numbers here are not directly comparable to those reported
by the TempEval 2013 evaluation.

6Though its performance was slightly lower than HeidelTime,
we also intended to compare to the (Angeli et al., 2012) system.
Its authors graciously helped us get the code running, but to date
all models we were able to train performed substantially worse
than their reported results, so we do not compare to them here.

normalized incorrectly. 4 errors were places where
our heuristic was wrong (e.g. we chose the earlier,
not the later Sept. 22). 6 errors were coverage prob-
lems of our grammar, e.g. not handling season, every
time or long ago. 2 errors were actually human an-
notation errors (several years ago was annotated as
PASTREF and daily was annotated as XXXX-XX-
XX, while the guidelines say these should be PXY
and P1D respectively). The remaining 21 errors were
from two new normalization forms not present at all
in the training data: 19 instances of THH:MM:SS
(times were always YYYY-MM-DDTHH:MM:SS
in the training data) and 2 instances of BCYYYY
(years were always YYYY in the training data).

7 Discussion

Our synchronous grammar approach to time normal-
ization, which handles recursive structures better than
existing string-to-string approaches and handles a
wider variety of grammars than existing parsing ap-
proaches, outperforms the HeidelTime system on
four evaluation corpora and outperforms the TIMEN
system on three of the four corpora.

Our time normalization code and models are
freely available. The source code and English
grammar are hosted at https://github.com/
bethard/timenorm, and official releases are pub-
lished to Maven Central (group=info.bethard,
artifact=timenorm).

In future work, we plan to replace the heuristic
for selecting between ambiguous parses with a more
principled approach. It would be a simple extension
to support a probabilistic grammar, as in (Angeli et
al., 2012). But given an expression like Monday, it
would still be impossible to decide whether it refers to
the future or the past, since the surrounding context,
e.g. tense of the governing verb, is needed for such a
judgment. A more promising approach would be to
train a classifier that selects between the ambiguous
parses based on features of the surrounding context.

Acknowledgements

The project described was supported in part by Grant
Number R01LM010090 from the National Library Of
Medicine. The content is solely the responsibility of the
authors and does not necessarily represent the official
views of the National Library of Medicine or the National
Institutes of Health.

825



References
[Angeli et al.2012] Gabor Angeli, Christopher Manning,

and Daniel Jurafsky. 2012. Parsing time: Learning to
interpret time expressions. In Proceedings of the 2012
Conference of the North American Chapter of the As-
sociation for Computational Linguistics: Human Lan-
guage Technologies, pages 446–455, Montréal, Canada,
June. Association for Computational Linguistics.

[Chappelier and Rajman1998] Jean-Cédric Chappelier
and Martin Rajman. 1998. A generalized CYK
algorithm for parsing stochastic CFG. In First
Workshop on Tabulation in Parsing and Deduction
(TAPD98), pages 133–137. Citeseer.

[Llorens et al.2012] Hector Llorens, Leon Derczynski,
Robert Gaizauskas, and Estela Saquete. 2012. TIMEN:
An open temporal expression normalisation resource.
In Proceedings of the Eight International Conference
on Language Resources and Evaluation (LREC’12),
Istanbul, Turkey, May. European Language Resources
Association (ELRA).

[Pustejovsky et al.2003] James Pustejovsky, Patrick
Hanks, Roser Sauri, Andrew See, Robert Gaizauskas,
Andrea Setzer, Dragomir Radev, Beth Sundheim,
David Day, Lisa Ferro, and Marcia Lazo. 2003. The
TIMEBANK corpus. In Corpus Linguistics, pages
647–656, Lancaster, UK.

[Pustejovsky et al.2010] James Pustejovsky, Kiyong Lee,
Harry Bunt, and Laurent Romary. 2010. ISO-TimeML:
An international standard for semantic annotation. In
Proceedings of the Seventh International Conference
on Language Resources and Evaluation (LREC’10),
Valletta, Malta, may. European Language Resources
Association (ELRA).

[Strötgen and Gertz2012] Jannik Strötgen and Michael
Gertz. 2012. Multilingual and cross-domain temporal
tagging. Language Resources and Evaluation.

[UzZaman et al.2013] Naushad UzZaman, Hector Llorens,
Leon Derczynski, James Allen, Marc Verhagen, and
James Pustejovsky. 2013. Semeval-2013 task 1:
Tempeval-3: Evaluating time expressions, events, and
temporal relations. In Second Joint Conference on
Lexical and Computational Semantics (*SEM), Volume
2: Proceedings of the Seventh International Workshop
on Semantic Evaluation (SemEval 2013), pages 1–9,
Atlanta, Georgia, USA, June. Association for Compu-
tational Linguistics.

[Verhagen et al.2010] Marc Verhagen, Roser Sauri, Tom-
maso Caselli, and James Pustejovsky. 2010. SemEval-
2010 task 13: TempEval-2. In Proceedings of the 5th
International Workshop on Semantic Evaluation, page
5762, Uppsala, Sweden, July. Association for Compu-
tational Linguistics.

826


