










































Joint Training and Decoding Using Virtual Nodes for Cascaded Segmentation and Tagging Tasks


Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 187–195,
MIT, Massachusetts, USA, 9-11 October 2010. c©2010 Association for Computational Linguistics

Joint Training and Decoding Using Virtual Nodes for Cascaded
Segmentation and Tagging Tasks

Xian Qian, Qi Zhang, Yaqian Zhou, Xuanjing Huang, Lide Wu
School of Computer Science, Fudan University

825 Zhangheng Road, Shanghai, P.R.China
{qianxian, qz, zhouyaqian, xjhuang, ldwu}@fudan.edu.cn

Abstract

Many sequence labeling tasks in NLP require
solving a cascade of segmentation and tag-
ging subtasks, such as Chinese POS tagging,
named entity recognition, and so on. Tradi-
tional pipeline approaches usually suffer from
error propagation. Joint training/decoding in
the cross-product state space could cause too
many parameters and high inference complex-
ity. In this paper, we present a novel method
which integrates graph structures of two sub-
tasks into one using virtual nodes, and per-
forms joint training and decoding in the fac-
torized state space. Experimental evaluations
on CoNLL 2000 shallow parsing data set and
Fourth SIGHAN Bakeoff CTB POS tagging
data set demonstrate the superiority of our
method over cross-product, pipeline and can-
didate reranking approaches.

1 Introduction

There is a typical class of sequence labeling tasks
in many natural language processing (NLP) applica-
tions, which require solving a cascade of segmenta-
tion and tagging subtasks. For example, many Asian
languages such as Japanese and Chinese which
do not contain explicitly marked word boundaries,
word segmentation is the preliminary step for solv-
ing part-of-speech (POS) tagging problem. Sen-
tences are firstly segmented into words, then each
word is assigned with a part-of-speech tag. Both
syntactic parsing and dependency parsing usually
start with a textual input that is tokenized, and POS
tagged.

The most commonly approach solves cascaded
subtasks in a pipeline, which is very simple to im-
plement and allows for a modular approach. While,

the key disadvantage of such method is that er-
rors propagate between stages, significantly affect-
ing the quality of the final results. To cope with this
problem, Shi and Wang (2007) proposed a rerank-
ing framework in which N-best segment candidates
generated in the first stage are passed to the tag-
ging model, and the final output is the one with the
highest overall segmentation and tagging probabil-
ity score. The main drawback of this method is that
the interaction between tagging and segmentation is
restricted by the number of candidate segmentation
outputs. Razvan C. Bunescu (2008) presented an
improved pipeline model in which upstream subtask
outputs are regarded as hidden variables, together
with their probabilities are used as probabilistic fea-
tures in the downstream subtasks. One shortcom-
ing of this method is that calculation of marginal
probabilities of features may be inefficient and some
approximations are required for fast computation.
Another disadvantage of these two methods is that
they employ separate training and the segmentation
model could not take advantages of tagging infor-
mation in the training procedure.

On the other hand, joint learning and decoding
using cross-product of segmentation states and tag-
ging states does not suffer from error propagation
problem and achieves higher accuracy on both sub-
tasks (Ng and Low, 2004). However, two problems
arises due to the large state space, one is that the
amount of parameters increases rapidly, which is apt
to overfit on the training corpus, the other is that
the inference by dynamic programming could be in-
efficient. Sutton (2004) proposed Dynamic Con-
ditional Random Fields (DCRFs) to perform joint
training/decoding of subtasks using much fewer pa-
rameters than the cross-product approach. How-

187



ever, DCRFs do not guarantee non-violation of hard-
constraints that nodes within the same segment get
a single consistent tagging label. Another draw-
back of DCRFs is that exact inference is generally
time consuming, some approximations are required
to make it tractable.

Recently, perceptron based learning framework
has been well studied for incorporating node level
and segment level features together (Kazama and
Torisawa, 2007; Zhang and Clark, 2008). The main
shortcoming is that exact inference is intractable
for those dynamically generated segment level fea-
tures, so candidate based searching algorithm is
used for approximation. On the other hand, Jiang
(2008) proposed a cascaded linear model which has
a two layer structure, the inside-layer model uses
node level features to generate candidates with their
weights as inputs of the outside layer model which
captures non-local features. As pipeline models, er-
ror propagation problem exists for such method.

In this paper, we present a novel graph structure
that exploits joint training and decoding in the fac-
torized state space. Our method does not suffer
from error propagation, and guards against viola-
tions of those hard-constraints imposed by segmen-
tation subtask. The motivation is to integrate two
Markov chains for segmentation and tagging sub-
tasks into a single chain, which contains two types of
nodes, then standard dynamic programming based
exact inference is employed on the hybrid struc-
ture. Experiments are conducted on two different
tasks, CoNLL 2000 shallow parsing and SIGHAN
2008 Chinese word segmentation and POS tagging.
Evaluation results of shallow parsing task show
the superiority of our proposed method over tradi-
tional joint training/decoding approach using cross-
product state space, and achieves the best reported
results when no additional resources at hand. For
Chinese word segmentation and POS tagging task, a
strong baseline pipeline model is built, experimental
results show that the proposed method yields a more
substantial improvement over the baseline than can-
didate reranking approach.

The rest of this paper is organized as follows: In
Section 2, we describe our novel graph structure. In
Section 3, we analyze complexity of our proposed
method. Experimental results are shown in Section
4. We conclude the work in Section 5.

2 Multi-chain integration using Virtual
Nodes

2.1 Conditional Random Fields
We begin with a brief review of the Conditional Ran-
dom Fields(CRFs). Let x = x1x2 . . . xl denote the
observed sequence, where xi is the ith node in the
sequence, l is sequence length, y = y1y2 . . . yl is a
label sequence over x that we wish to predict. CRFs
(Lafferty et al., 2001) are undirected graphic mod-
els that use Markov network distribution to learn the
conditional probability. For sequence labeling task,
linear chain CRFs are very popular, in which a first
order Markov assumption is made on the labels:

p(y|x) = 1
Z(x)

∏

i

φ(x,y, i)

,where

φ(x,y, i) = exp
(
wT f(x, yi−1, yi, i)

)

Z(x) =
∑
y

∏

i

φ(x,y, i)

f(x, yi−1, yi, i) =
[f1(x, yi−1, yi, i), . . .,fm(x, yi−1, yi, i)]T , each ele-
ment fj(x, yi−1, yi, i) is a real valued feature func-
tion, here we simplify the notation of state feature
by writing fj(x, yi, i) = fj(x, yi−1, yi, i), m is the
cardinality of feature set {fj}. w = [w1, . . . , wm]T
is a weight vector to be learned from the training
set. Z(x) is the normalization factor over all label
sequences for x.

In the traditional joint training/decoding approach
for cascaded segmentation and tagging task, each
label yi has the form si-ti, which consists of seg-
mentation label si and tagging label ti. Let s =
s1s2 . . . sl be the segmentation label sequence over
x. There are several commonly used label sets such
as BI, BIO, IOE, BIES, etc. To facilitate our dis-
cussion, in later sections we will use BIES label set,
where B,I,E represents Beginning, Inside and End of
a multi-node segment respectively, S denotes a sin-
gle node segment. Let t = t1t2 . . . tl be the tagging
label sequence over x. For example, in named entity
recognition task, ti ∈ {PER, LOC, ORG, MISC,
O} represents an entity type (person name, loca-
tion name, organization name, miscellaneous entity

188



x2

s
×
t

2

2

x1

s
×
t

1

1

S-P S-O

x3

s
×
t

3

3

S-O

x4

s
×
t

4

4

B-P

x5

s
×
t

5

5

E-P

Hendrix ’s              girlfriend          Kathy       Etchingham

Figure 1: Graphical representation of linear chain CRFs
for traditional joint learning/decoding

name and other). Graphical representation of lin-
ear chain CRFs is shown in Figure 1, where tagging
label “P” is the simplification of “PER”. For nodes
that are labeled as other, we define si =S, ti =O.

2.2 Hybrid structure for cascaded labeling
tasks

Different from traditional joint approach, our
method integrates two linear markov chains for seg-
mentation and tagging subtasks into one that con-
tains two types of nodes. Specifically, we first
regard segmentation and tagging as two indepen-
dent sequence labeling tasks, corresponding chain
structures are built, as shown in the top and mid-
dle sub-figures of Figure 2. Then a chain of twice
length of the observed sequence is built, where
nodes x1, . . . , xl on the even positions are original
observed nodes, while nodes v1, . . . , vl on the odd
positions are virtual nodes that have no content in-
formation. For original nodes xi, the state space is
the tagging label set, while for virtual nodes, their
states are segmentation labels. The label sequence
of the hybrid chain is y = y1 . . . y2l = s1t1 . . . sltl,
where combination of consecutive labels siti repre-
sents the full label for node xi.

Then we let si be connected with si−1 and si+1
, so that first order Markov assumption is made
on segmentation states. Similarly, ti is connected
with ti−1 and ti+1. Then neighboring tagging and
segmentation states are connected as shown in the
bottom sub-figure of Figure 2. Non-violation of
hard-constraints that nodes within the same seg-
ment get a single consistent tagging label is guar-
anteed by introducing second order transition fea-
tures f(ti−1, si, ti, i) that are true if ti−1 6= ti and
si ∈ {I,E}. For example, fj(ti−1, si, ti, i) is de-

fined as true if ti−1 =PER, si =I and ti =LOC.
In other words, it is true, if a segment is partially
tagging as PER, and partially tagged as LOC. Since
such features are always false in the training corpus,
their corresponding weights will be very low so that
inconsistent label assignments impossibly appear in
decoding procedure. The hybrid graph structure can
be regarded as a special case of second order Markov
chain.

Hendrix ’s              girlfriend          Kathy       Etchingham

x1 x2 x3 x4 x5

s1 s2 s3 s4 s5

S S S B E

x1 x2 x3 x4 x5

t1 t2 t3 t4 t5

P O O P P

x1 x2 x3 x4 x5

t1 t2 t3 t4 t5

P O O P P

s2s1 s3 s4 s5

S S S B E

v1 v2 v3 v4 v5

Integrate

Figure 2: Multi-chain integration using Virtual Nodes

2.3 Factorized features

Compared with traditional joint model that exploits
cross-product state space, our hybrid structure uses
factorized states, hence could handle more flexible
features. Any state feature g(x, yi, i) defined in
the cross-product state space can be replaced by a
first order transition feature in the factorized space:
f(x, si, ti, i). As for the transition features, we
use f(si−1, ti−1, si, i) and f(ti−1, si, ti, i) instead
of g(yi−1, yi, i) in the conventional joint model.

Features in cross-product state space require that
segmentation label and tagging label take on partic-
ular values simultaneously, however, sometimes we

189



want to specify requirement on only segmentation or
tagging label. For example, “Smith” may be an end
of a person name, “Speaker: John Smith”; or a sin-
gle word person name “Professor Smith will . . . ”. In
such case, our observation is that “Smith” is likely a
(part of) person name, we do not care about its seg-
mentation label. So we could define state feature
f(x, ti, i) = true, if xi is “Smith” with tagging la-
bel ti=PER.

Further more, we could define features like
f(x, ti−1, ti, i), f(x, si−1, si, i), f(x, ti−1, si, i),
etc. The hybrid structure facilitates us to use
varieties of features. In the remainder of the
paper, we use notations f(x, ti−1, si, ti, i) and
f(x, si−1, ti−1, si, i) for simplicity.

2.4 Hybrid CRFs
A hybrid CRFs is a conditional distribution that fac-
torizes according to the hybrid graphical model, and
is defined as:

p(s, t|x) = 1
Z(x)

∏

i

φ(x, s, t, i)
∏

i

ψ(x, s, t, i)

Where

φ(x, s, t, i) = exp
(
wT1 f(x, si−1, ti−1, si)

)

ψ(x, s, t, i) = exp
(
wT2 f(x, ti−1, si, ti)

)

Z(x) =
∑

s,t

(∏

i

φ(x, s, t, i)
∏

i

ψ(x, s, t, i)

)

Where w1, w2 are weight vectors.
Luckily, unlike DCRFs, in which graph structure

can be very complex, and the cross-product state
space can be very large, in our cascaded labeling
task, the segmentation label set is often small, so
far as we known, the most complicated segmenta-
tion label set has only 6 labels (Huang and Zhao,
2007). So exact dynamic programming based algo-
rithms can be efficiently performed.

In the training stage, we use second order forward
backward algorithm to compute the marginal proba-
bilities p(x, si−1, ti−1, si) and p(x, ti−1, si, ti), and
the normalization factor Z(x). In decoding stage,
we use second order Viterbi algorithm to find the
best label sequence. The Viterbi decoding can be

Table 1: Time Complexity

Method Training Decoding
Pipeline (|S|2cs + |T |2ct)L (|S|2 + |T |2)U

Cross-Product (|S||T |)2cL (|S||T |)2U
Reranking (|S|2cs + |T |2ct)L (|S|2 + |T |2)NU

Hybrid (|S| + |T |)|S||T |cL (|S| + |T |)|S||T |U

used to label a new sequence, and marginal compu-
tation is used for parameter estimation.

3 Complexity Analysis

The time complexity of the hybrid CRFs train-
ing and decoding procedures is higher than that of
pipeline methods, but lower than traditional cross-
product methods. Let

• |S| = size of the segmentation label set.

• |T | = size of the tagging label set.

• L = total number of nodes in the training data
set.

• U = total number of nodes in the testing data
set.

• c = number of joint training iterations.

• cs = number of segmentation training itera-
tions.

• ct = number of tagging training iterations.

• N = number of candidates in candidate rerank-
ing approach.

Time requirements for pipeline, cross-product, can-
didate reranking and hybrid CRFs are summarized
in Table 1. For Hybrid CRFs, original node xi has
features {fj(ti−1, si, ti)}, accessing all label subse-
quences ti−1siti takes |S||T |2 time, while virtual
node vi has features {fj(si−1, ti−1, si)}, accessing
all label subsequences si−1ti−1si takes |S|2|T | time,
so the final complexity is (|S|+ |T |)|S||T |cL.

In real applications, |S| is small, |T | could be
very large, we assume that |T | >> |S|, so for
each iteration, hybrid CRFs is about |S| times slower
than pipeline and |S| times faster than cross-product

190



Table 2: Feature templates for shallow parsing task

Cross Product CRFs Hybrid CRFs
wi−2yi, wi−1yi, wiyi wi−1si, wisi, wi+1si
wi+1yi, wi+2yi wi−2ti, wi−1ti, witi, wi+1ti, wi+2ti
wi−1wiyi, wiwi+1yi wi−1wisi, wiwi+1si

wi−1witi, wiwi+1ti
pi−2yi, pi−1yi, piyi pi−1si, pisi, pi+1si
pi+1yi, pi+2yi pi−2ti, pi−1ti, pi+1ti, pi+2ti
pi−2pi−1yi, pi−1piyi, pipi+1yi,
pi+1pi+2yi

pi−2pi−1si, pi−1pisi, pipi+1si, pi+1pi+2si

pi−3pi−2ti, pi−2pi−1ti, pi−1piti, pipi+1ti,
pi+1pi+2ti, pi+2pi+3ti, pi−1pi+1ti

pi−2pi−1piyi, pi−1pipi+1yi,
pipi+1pi+2yi

pi−2pi−1pisi, pi−1pipi+1si, pipi+1pi+2si

wipiti
wisi−1si
wi−1ti−1ti, witi−1ti, pi−1ti−1ti, piti−1ti

yi−1yi si−1ti−1si, ti−1siti

method. When decoding, candidate reranking ap-
proach requires more time if candidate number N >
|S|.

Though the space complexity could not be com-
pared directly among some of these methods, hybrid
CRFs require less parameters than cross-product
CRFs due to the factorized state space. This is sim-
ilar with factorized CRFs (FCRFs) (Sutton et al.,
2004).

4 Experiments

4.1 Shallow Parsing

Our first experiment is the shallow parsing task. We
use corpus from CoNLL 2000 shared task, which
contains 8936 sentences for training and 2012 sen-
tences for testing. There are 11 tagging labels: noun
phrase(NP), verb phrase(VP) , . . . and other (O), the
segmentation state space we used is BIES label set,
since we find that it yields a little improvement over
BIO set.

We use the standard evaluation metrics, which are
precision P (percentage of output phrases that ex-
actly match the reference phrases), recall R (percent-
age of reference phrases returned by our system),
and their harmonic mean, the F1 score F1 = 2PRP+R
(which we call F score in what follows).

We compare our approach with traditional cross-
product method. To find good feature templates,
development data are required. Since CoNLL2000
does not provide development data set, we divide
the training data into 10 folds, of which 9 folds for
training and 1 fold for developing. After selecting
feature templates by cross validation, we extract fea-
tures and learn their weights on the whole training
data set. Feature templates are summarized in Table
2, where wi denotes the ith word, pi denotes the ith

POS tag.
Notice that in the second row, feature templates

of the hybrid CRFs does not contain wi−2si, wi+2si,
since we find that these two templates degrade per-
formance in cross validation. However, wi−2ti,
wi+2ti are useful, which implies that the proper con-
text window size for segmentation is smaller than
tagging. Similarly, for hybrid CRFs, the window
size of POS bigram features for segmentation is 5
(from pi−2 to pi+2, see the eighth row in the sec-
ond column); while for tagging, the size is 7 (from
pi−3 to pi+3, see the ninth row in the second col-
umn). However for cross-product method, their win-
dow sizes must be consistent.

For traditional cross-product CRFs and our hybrid
CRFs, we use fixed gaussian prior σ = 1.0 for both
methods, we find that this parameter does not signifi-

191



Table 3: Results for shallow parsing task, Hybrid CRFs
significantly outperform Cross-Product CRFs (McNe-
mar’s test; p < 0.01)

Method Cross-Product
CRFs

Hybrid
CRFs

Training Time 11.6 hours 6.3 hours
Feature Num-
ber

13 million 10 mil-
lion

Iterations 118 141
F1 93.88 94.31

cantly affect the results when it varies between 1 and
10. LBFGS(Nocedal and Wright, 1999) method is
employed for numerical optimization. Experimen-
tal results are shown in Table 3. Our proposed CRFs
achieve a performance gain of 0.43 points in F-score
over cross-product CRFs that use state space while
require less training time.

For comparison, we also listed the results of pre-
vious top systems, as shown in Table 4. Our pro-
posed method outperforms other systems when no
additional resources at hand. Though recently semi-
supervised learning that incorporates large mounts
of unlabeled data has been shown great improve-
ment over traditional supervised methods, such as
the last row in Table 4, supervised learning is funda-
mental. We believe that combination of our method
and semi-supervised learning will achieve further
improvement.

4.2 Chinese word segmentation and POS
tagging

Our second experiment is the Chinese word seg-
mentation and POS tagging task. To facilitate com-
parison, we focus only on the closed test, which
means that the system is trained only with a des-
ignated training corpus, any extra knowledge is not
allowed, including Chinese and Arabic numbers, let-
ters and so on. We use the Chinese Treebank (CTB)
POS corpus from the Fourth International SIGHAN
Bakeoff data sets (Jin and Chen, 2008). The train-
ing data consist of 23444 sentences, 642246 Chinese
words, 1.05M Chinese characters and testing data
consist of 2079 sentences, 59955 Chinese words,
0.1M Chinese characters.

We compare our hybrid CRFs with pipeline and
candidate reranking methods (Shi and Wang, 2007)

Table 4: Comparison with other systems on shallow pars-
ing task

Method F1 Additional Re-
sources

Cross-Product CRFs 93.88
Hybrid CRFs 94.31
SVM combination 93.91
(Kudo and Mat-
sumoto, 2001)
Voted Perceptrons 93.74 none
(Carreras and Mar-
quez, 2003)
ETL (Milidiu et al.,
2008)

92.79

(Wu et al., 2006) 94.21 Extended features
such as token fea-
tures, affixes

HySOL 94.36 17M words unla-
beled

(Suzuki et al., 2007) data
ASO-semi 94.39 15M words unla-

beled
(Ando and Zhang,
2005)

data

(Zhang et al., 2002) 94.17 full parser output
(Suzuki and Isozaki,
2008)

95.15 1G words unla-
beled data

using the same evaluation metrics as shallow pars-
ing. We do not compare with cross-product CRFs
due to large amounts of parameters.

For pipeline method, we built our word segmenter
based on the work of Huang and Zhao (2007),
which uses 6 label representation, 7 feature tem-
plates (listed in Table 5, where ci denotes the ith

Chinese character in the sentence) and CRFs for pa-
rameter learning. We compare our segmentor with
other top systems using SIGHAN CTB corpus and
evaluation metrics. Comparison results are shown
in Table 6, our segmenter achieved 95.12 F-score,
which is ranked 4th of 26 official runs. Except for
the first system which uses extra unlabeled data, dif-
ferences between rest systems are not significant.

Our POS tagging system is based on linear chain
CRFs. Since SIGHAN dose not provide develop-
ment data, we use the 10 fold cross validation de-
scribed in the previous experiment to turning feature
templates and Gaussian prior. Feature templates are
listed in Table 5, where wi denotes the ith word in

192



Table 5: Feature templates for Chinese word segmentation and POS tagging task

Segmentation feature templates
(1.1) ci−2si, ci−1si, cisi, ci+1si, ci+2si
(1.2) ci−1cisi, cici+1si, ci−1ci+1si
(1.3) si−1si
POS tagging feature templates
(2.1) wi−2ti, wi−1ti, witi, wi+1ti, wi+2ti
(2.2) wi−2wi−1ti, wi−1witi, wiwi+1ti, wi+1wi+2ti, wi−1wi+1ti
(2.3) c1(wi)ti, c2(wi)ti, c3(wi)ti, c−2(wi)ti, c−1(wi)ti
(2.4) c1(wi)c2(wi)ti, c−2(wi)c−1(wi)ti
(2.5) l(wi)ti
(2.6) ti−1ti
Joint segmentation and POS tagging feature templates
(3.1) ci−2si, ci−1si, cisi, ci+1si, ci+2si
(3.2) ci−1cisi, cici+1si, ci−1ci+1si
(3.3) ci−3ti, ci−2ti, ci−1ti, citi, ci+1ti, ci+2ti, ci+3ti
(3.4) ci−3ci−2ti, ci−2ci−1ti, ci−1citi, cici+1ti ci+1ci+2ti, ci+2ci+3ti, ci−2citi, cici+2ti
(3.5) cisiti
(3.6) citi−1ti
(3.7) si−1ti−1si, ti−1siti

Table 6: Word segmentation results on Fourth SIGHAN
Bakeoff CTB corpus

Rank F1 Description
1/26 95.89∗ official best, using extra un-

labeled data (Zhao and Kit,
2008)

2/26 95.33 official second
3/26 95.17 official third
4/26 95.12 segmentor in pipeline sys-

tem

Table 7: POS results on Fourth SIGHAN Bakeoff CTB
corpus

Rank Accuracy Description
1/7 94.29 POS tagger in pipeline sys-

tem
2/7 94.28 official best
3/7 94.01 official second
4/7 93.24 official third

the sentence, cj(wi), j > 0 denotes the jth Chinese
character of word wi, cj(wi), j < 0 denotes the jth

last Chinese character, l(wi) denotes the word length
of wi. We compare our POS tagger with other top
systems on Bakeoff CTB POS corpus where sen-
tences are perfectly segmented into words, our POS
tagger achieved 94.29 accuracy, which is the best of
7 official runs. Comparison results are shown in Ta-
ble 7.

For reranking method, we varied candidate num-
bers n among n ∈ {10, 20, 50, 100}. For hybrid
CRFs, we use the same segmentation label set as
the segmentor in pipeline. Feature templates are
listed in Table 5. Experimental results are shown
in Figure 3. The gain of hybrid CRFs over the
baseline pipeline model is 0.48 points in F-score,
about 3 times higher than 100-best reranking ap-
proach which achieves 0.13 points improvement.
Though larger candidate number can achieve higher
performance, such improvement becomes trivial for
n > 20.

Table 8 shows the comparison between our work
and other relevant work. Notice that, such com-
parison is indirect due to different data sets and re-

193



0 20 40 60 80 100
90.3

90.4

90.5

90.6

90.7

90.8

90.9

candidate number

F
 s

co
re

 

 

candidate reranking
Hybrid CRFs

Figure 3: Results for Chinese word segmentation and
POS tagging task, Hybrid CRFs significantly outperform
100-Best Reranking (McNemar’s test; p < 0.01)

Table 8: Comparison of word segmentation and POS tag-
ging, such comparison is indirect due to different data
sets and resources.

Model F1
Pipeline (ours) 90.40
100-Best Reranking (ours) 90.53
Hybrid CRFs (ours) 90.88
Pipeline (Shi and Wang, 2007) 91.67
20-Best Reranking (Shi and Wang,
2007)

91.86

Pipeline (Zhang and Clark, 2008) 90.33
Joint Perceptron (Zhang and Clark,
2008)

91.34

Perceptron Only (Jiang et al., 2008) 92.5
Cascaded Linear (Jiang et al., 2008) 93.4

sources. One common conclusion is that joint mod-
els generally outperform pipeline models.

5 Conclusion

We introduced a framework to integrate graph struc-
tures for segmentation and tagging subtasks into one
using virtual nodes, and performs joint training and
decoding in the factorized state space. Our approach
does not suffer from error propagation, and guards
against violations of those hard-constraints imposed
by segmentation subtask. Experiments on shal-
low parsing and Chinese word segmentation tasks
demonstrate our technique.

6 Acknowledgements

The author wishes to thank the anonymous review-
ers for their helpful comments. This work was
partially funded by 973 Program (2010CB327906),
The National High Technology Research and De-
velopment Program of China (2009AA01A346),
Shanghai Leading Academic Discipline Project
(B114), Doctoral Fund of Ministry of Education of
China (200802460066), National Natural Science
Funds for Distinguished Young Scholar of China
(61003092), and Shanghai Science and Technology
Development Funds (08511500302).

References

R. Ando and T. Zhang. 2005. A high-performance semi-
supervised learning method for text chunking. In Pro-
ceedings of ACL, pages 1–9.

Razvan C. Bunescu. 2008. Learning with probabilistic
features for improved pipeline models. In Proceedings
of EMNLP, Waikiki, Honolulu, Hawaii.

X Carreras and L Marquez. 2003. Phrase recognition by
filtering and ranking with perceptrons. In Proceedings
of RANLP.

Changning Huang and Hai Zhao. 2007. Chinese word
segmentation: A decade review. Journal of Chinese
Information Processing, 21:8–19.

Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan Lu.
2008. A cascaded linear model for joint chinese word
segmentation and part-of-speech tagging. In Proceed-
ings of ACL, Columbus, Ohio, USA.

Guangjin Jin and Xiao Chen. 2008. The fourth interna-
tional chinese language processing bakeoff: Chinese
word segmentation, named entity recognition and chi-
nese pos tagging. In Proceedings of Sixth SIGHAN
Workshop on Chinese Language Processing, India.

Junichi Kazama and Kentaro Torisawa. 2007. A new
perceptron algorithm for sequence labeling with non-
local features. In Proceedings of EMNLP, pages 315–
324, Prague, June.

Taku Kudo and Yuji Matsumoto. 2001. Chunking with
support vector machines. In Proceedings of NAACL.

J. Lafferty, A. McCallum, and F. Pereira. 2001. Con-
ditional random fields: Probabilistic models for seg-
menting and labeling sequence data. In Proceedings
of ICML.

Ruy L. Milidiu, Cicero Nogueira dos Santos, and Julio C.
Duarte. 2008. Phrase chunking using entropy guided
transformation learning. In Proceedings of ACL, pages
647–655.

194



Hwee Tou Ng and Jin Kiat Low. 2004. Chinese part-
ofspeech tagging: One-at-a-time or all-at-once? word-
based or character-based? In Proceedings of EMNLP.

J. Nocedal and S. J. Wright. 1999. Numerical Optimiza-
tion. Springer.

Yanxin Shi and Mengqiu Wang. 2007. A dual-layer crfs
based joint decoding method for cascaded segmenta-
tion and labeling tasks. In Proceedings of IJCAI, pages
1707–1712, Hyderabad, India.

C. Sutton, K. Rohanimanesh, and A. McCallum. 2004.
Dynamic conditional random fields: Factorized prob-
abilistic models for labeling and segmenting sequence
data. In Proceedings of ICML.

Jun Suzuki and Hideki Isozaki. 2008. Semi-supervised
sequential labeling and segmentation using giga-word
scale unlabeled data. In Proceedings of ACL, pages
665–673.

Jun Suzuki, Akinori Fujino, and Hideki Isozaki. 2007.
Semi-supervised structured output learning based on
a hybrid generative and discriminative approach. In
Proceedings of EMNLP, Prague.

Yu-Chieh Wu, Chia-Hui Chang, and Yue-Shi Lee. 2006.
A general and multi-lingual phrase chunking model
based on masking method. In Proceedings of Intel-
ligent Text Processing and Computational Linguistics,
pages 144–155.

Yue Zhang and Stephen Clark. 2008. Joint word seg-
mentation and pos tagging using a single perceptron.
In Proceedings of ACL, Columbus, Ohio, USA.

T. Zhang, F. Damerau, and D. Johnson. 2002. Text
chunking based on a generalization of winnow. ma-
chine learning research. Machine Learning Research,
2:615–637.

Hai Zhao and Chunyu Kit. 2008. Unsupervised segmen-
tation helps supervised learning of character tagging
forword segmentation and named entity recognition.
In Proceedings of Sixth SIGHAN Workshop on Chinese
Language Processing, pages 106–111.

195


