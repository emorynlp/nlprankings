










































Discovering Temporal Narrative Containers in Clinical Text


Proceedings of the 2013 Workshop on Biomedical Natural Language Processing (BioNLP 2013), pages 18–26,
Sofia, Bulgaria, August 4-9 2013. c©2013 Association for Computational Linguistics

Discovering Narrative Containers in Clinical Text

Timothy A. Miller1, Steven Bethard2, Dmitriy Dligach1,
Sameer Pradhan1, Chen Lin1, and Guergana K. Savova1

1 Children’s Hospital Informatics Program, Boston Children’s Hospital and Harvard Medical School
firstname.lastname@childrens.harvard.edu

2 Center for Computational Language and Education Research, University of Colorado Boulder
steven.bethard@colorado.edu

Abstract
The clinical narrative contains a great deal
of valuable information that is only under-
standable in a temporal context. Events,
time expressions, and temporal relations
convey information about the time course
of a patient’s clinical record that must be
understood for many applications of inter-
est. In this paper, we focus on extracting
information about how time expressions
and events are related by narrative con-
tainers. We use support vector machines
with composite kernels, which allows for
integrating standard feature kernels with
tree kernels for representing structured
features such as constituency trees. Our
experiments show that using tree kernels
in addition to standard feature kernels im-
proves F1 classification for this task.

1 Introduction

Clinical narratives are a rich source of unstruc-
tured information that hold great potential for im-
pacting clinical research and clinical care. These
narratives consist of unstructured natural language
descriptions of various stages of clinical care,
which makes them information dense but chal-
lenging to use computationally. Information ex-
tracted from these narratives is already being used
for clinical research tasks such as automatic phe-
notype classification for collecting disease cohorts
retrospectively (Ananthakrishnan et al., 2013),
which can in turn be used for a variety of studies,
including pharmacogenomics (Lin et al., 2012;
Wilke et al., 2011). Future applications may use
information extracted from the clinical narrative at
the point of care to assist physicians in decision-
making in a real time fashion.

One of the most interesting and challenging as-
pects of clinical text is the pervasiveness of tempo-
rally grounded information. This includes a num-
ber of clinical concepts which are events with fi-
nite time spans (e.g., surgery or x-ray), time ex-
pressions (December, postoperatively), and links
that relate events to times or other events. For ex-
ample, surgery last May relates the time last May
with the event surgery via the CONTAINS relation,
while Vicodin after surgery relates the medication
event Vicodin with the procedure event surgery via
the AFTER relation. There are many potential ap-
plications of clinical information extraction that
are only possible with an understanding of the or-
dering and duration of the events in a clinical en-
counter.

In this work we focus on extracting a particu-
lar temporal relation, CONTAINS, that holds be-
tween a time expression and an event expression.
This level of representation is based on the compu-
tational discourse model of narrative containers
(Pustejovsky and Stubbs, 2011), which are time
expressions or events which are central to a sec-
tion of a text, usually manifested by being rela-
tive hubs of temporal relation links. We argue that
containment relations are useful as an intermediate
level of granularity between full temporal relation
extraction and “coarse” temporal bins (Raghavan
et al., 2012) like before admission, on admission,
and after admission. Correctly extracting CON-
TAINS relations will, for example, allow for more
accurate placement of events on a timeline, to
the resolution possible by the number of time ex-
pressions in the document. We suspect that this
finer grained information will also be more useful
for downstream applications like coreference, for
which coarse information was found to be useful.
The approach we develop is a supervised machine

18



learning approach in which pairs of time expres-
sions and events are classified as CONTAINS or
not. The specific approach is a support vector ma-
chine using both standard feature kernels and tree
kernels, a novel approach to this problem in this
domain that has shown promise on other relation
extraction tasks.

This work makes use of a new corpus we devel-
oped as part of the THYME1 project (Temporal
History of Your Medical Events) focusing on tem-
poral events and relations in clinical text. This cor-
pus consists of clinical and pathology notes on col-
orectal cancer from Mayo Clinic. Gold standard
annotations include Penn Treebank-style phrase
structure in addition to clinically relevant temporal
annotations like clinical events, temporal expres-
sions, and various temporal relations.

2 Background and Related Work

2.1 Annotation Methodology
The THYME annotation guidelines2 detail the ex-
tension of TimeML (Pustejovsky et al., 2003b)
to the annotations of events, temporal expres-
sions and temporal relations in the clinical do-
main. In summary, an EVENT is anything that is
relevant to the clinical timeline. Temporal expres-
sions (TIMEX3s) in the clinical domain are simi-
lar to those in the general domain with two excep-
tions. First, TimeML sets and frequencies occur
much more often in the clinical domain, especially
with regard to medications and treatments (Clar-
itin 30mg twice daily). The second deviation is a
new type of TIMEX3 – PREPOSTEXP which covers
temporally complex terms like preoperative, post-
operative, and intraoperative.

EVENTs and TIMEX3s are ordered on a timeline
through temporal TLINKs which range from fairly
coarse (the relation to document time creation) to
fairly granular (the explicit pairwise TLINKs be-
tween EVENTs and/or TIMEX3s). Of note for this
work, the CONTAINS relation between a TIMEX3
and an EVENT means that the span of the EVENT
is completely within the span of the TIMEX3. The
interannotator agreement F1-score for CONTAINS
for the set of documents used here was 0.60.

2.2 Narrative Containers
One relatively new concept for marking temporal
relations is that of narrative containers, as in Puste-

1http://clear.colorado.edu/TemporalWiki
2Annotation guidelines are posted on the THYME wiki.

jovsky and Stubbs (2011). Narrative containers
are time spans which are central to the discourse
and often subsume multiple events and time ex-
pressions. They are often anchored by a time ex-
pression, though more abstract events may also act
as anchors. Using the narrative container frame-
work significantly reduces the number of explicit
TLINK annotations yet retains a relevant degree of
granularity enabling inferencing.

Consider the following clinical text example
with DocTime of February 8.

The patient recovered well after her ini-
tial first surgery on December 16th to
remove the adenocarcinoma, although
on the evening of January 3rd she was
admitted with a fever and treated with
antibiotics.

There are three narrative containers in this snip-
pet – (1) the broad period leading up to the docu-
ment creation time which includes the events of re-
covered and adenocarcinoma, (2) December 16th,
which includes the events of surgery and remove,
and (3) January 3rd, which includes the events of
admitted, fever, and treated.

Using only the relation to the document creation
time would provide too coarse of a timeline result-
ing in collapsing the three narrative containers (the
coarse time bins of Raghavan et al. (2012) would
collapse all events into the before admission cat-
egory). On the other hand, marking explicit links
between every pair of events and temporal expres-
sions would be tedious and redundant. In this ex-
ample, there is no need to explicitly mark that, for
instance, fever was AFTER surgery, because we
know that the fever happened on January 3rd and
that the surgery happened on December 16th, and
that January 3rd is AFTER December 16th. With
the grouping of EVENTs in this way, we can infer
the links between them and reduce annotator ef-
fort. Narrative containers strike the right balance
between parsimony and expressiveness.

2.3 Related Work

Of course, the possibility of annotating temporal
containment relations was allowed by even the ear-
liest versions of the TimeML specification using
TLINKs with the relation type INCLUDES. How-
ever, TimeML is a specification not a guideline,
and as such, the way in which temporal relations
have been annotated has varied widely and no

19



corpus has previously been annotated with narra-
tive containers in mind. In the TimeBank corpus
(Pustejovsky et al., 2003a), annotators annotated
only a sparse, mostly disconnected graph of the
temporal relations that seemed salient to them. In
TempEval 2007 and 2010 (Verhagen et al., 2007;
Verhagen et al., 2010), annotators annotated only
relations in specific constructions – e.g. all pairs
of events and times in a sentence – and used a re-
stricted set of relation types that excluded the IN-
CLUDES relation. TempEval 2013 (UzZaman et
al., 2013) allowed INCLUDES relations, but again
only in particular constructions or when the rela-
tion seemed salient to the annotators. The 2012
i2b2 Challenge3, which provided TimeML anno-
tations on clinical data, annotated the INCLUDES
relation, but merged it with other relations for the
evaluation due to low inter-annotator agreement.

Since no narrative container-annotated corpora
exist, there are also no existing models for extract-
ing narrative container relations. However, we
can draw on the various methods applied to re-
lated temporal relation tasks. Most relevant is the
work on linking events to timestamps. This was
one of the subtasks in TempEval 2007 and 2010,
and systems used a variety of features including
words, part-of-speech tags, and the syntactic path
between the event and the time (Bethard and Mar-
tin, 2007; Llorens et al., 2010). Syntactic path
features were also used in the 2012 i2b2 Chal-
lenge, where they provided gains especially for
intra-sentential temporal links (Xu et al., 2013).

Recent research has also looked to syntac-
tic tree kernels for temporal relation extraction.
Mirroshandel et al. (2009) used a path-enclosed
tree (i.e., selecting only the sub-tree containing
the event and time), and used various weighting
scheme variants of this approach on the Time-
Bank (Pustejovsky et al., 2003a) and Opinion4

corpora. Hovy et al. (2012) used a flat tree struc-
ture for each event-time pair, including only token-
based information (words, part of speech tags) be-
tween the event and time, and found that adding
such tree kernels on top of a baseline set of fea-
tures improved event-time linking performance on
the TempEval 2007 and Machine Reading cor-
pora (Strassel et al., 2010). While Mirroshandel et
al. saw improvements using a representation with
syntactic structure, Hovy et al. used the flat tree

3http://i2b2.org/NLP/TemporalRelations
4Also known as the AQUAINT TimeML corpus –

http://www.timeml.org

structure because they found that “using a full-
parse syntactic tree as input representation did not
help performance.” Thus, it remains an open ques-
tion exactly where and when syntactic tree kernels
will help temporal relation extraction.

3 Methods

Inspired by this prior work, we treat the narrative
container extraction task as a within-sentence rela-
tion extraction task between time and event men-
tions. For each sentence, this approach iterates
over every gold standard annotated EVENT, pair-
ing it with each TIMEX3 in the sentence, and uses
a supervised machine learning algorithm to clas-
sify each pair as related by the CONTAINS relation
or not. Training examples are generated in the
same way, with pairs corresponding to annotated
links marked as positive examples and all others
marked as negative. We investigate a variety of
features for the classifier as well as a variety of
tree kernel combinations.

This straightforward approach does not address
all relation pairs, setting aside event-event rela-
tions and inter-sentential relations, which are both
likely to require different approaches.

3.1 SVM with Tree Kernels

The machine learning approach we use is support
vector machine (SVM) with standard feature ker-
nels, tree kernels, and composite kernels that com-
bine the two. SVMs are used extensively for clas-
sification tasks in natural language processing, due
to robust performance and widely available soft-
ware packages. We take advantage of the ability
in SVMs to represent structured features such as
trees using convolution kernels (Collins and Duffy,
2001), also known as tree kernels. This kernel
computes similarity between two tree structures
by computing the number of common sub-trees,
with a weight parameter to discount the influence
of larger structural similarities. The specific for-
malism we use is sometimes called a subset tree
kernel (Moschitti, 2006), which checks for simi-
larity on subtrees of all sizes, as long as each sub-
tree has its production rule completely expanded.

A useful property of kernels is that a linear com-
bination of two kernels is guaranteed to be a ker-
nel (Cristianini and Shawe-Taylor, 2000). In ad-
dition, the product of two kernels is also a ker-
nel. This means that it is simple to combine tradi-
tional feature-based kernels used in SVMs (linear,

20



polynomial, radial basis function) with tree ker-
nels representing structural information. This ap-
proach of using composite kernels has been widely
used in the task of relation extraction where syn-
tactic information is presumed to be useful, but is
hard to represent as traditional numeric features.

We investigate a few different composite ker-
nels here, including a linear combination:

KC(o1, o2) = τ ∗KT (t1, t2) +KF (f1, f2) (1)

where a composite kernel KC operates on objects
oj composed of features fj and tree tj , by adding
a tree kernel KT weighted by τ to a feature kernel
KF . We also use a composite kernel that takes the
product of kernels:

KC(o1, o2) = KT (t1, t2) ∗KF (f1, f2) (2)

Sometimes it is beneficial to make use of multi-
ple syntactic “views” of the same instance. Below
we will describe many different tree representa-
tions, and the tree kernel framework allows them
to all be used simultaneously, by simply summing
the similarities of the different representations and
taking the combined sum as the tree kernel value:

KT ({t11, t21 . . . , tN1 }, {t12, t22, . . . , tN2 }) =
N∑

i=1

KT (t
i
1, t

i
2) (3)

where i indexes the N different tree views. In all
kernel combinations we compute the normalized
version of both the feature and tree kernels so that
they can be combined on an even footing.

The actual implementations we use for train-
ing are the SVM-LIGHT-TK package (Mos-
chitti, 2006), which is a tree kernel extension to
SVMlight (Joachims, 1999). At test time, we
use the SVM-LIGHT-TK bindings of the ClearTK
toolkit (Ogren et al., 2009) in a module built on
top of Apache cTAKES (Savova et al., 2010), to
take advantage of the pre-processing stages.

3.2 Flat Features
The flat features developed for the standard fea-
ture kernel include the text of each argument as a
whole, the tokens of each argument represented as
a bag of words, the first and last word of each ar-
gument, and the preceding and following words of
each argument as bags of words. The token con-
text between arguments is also represented using

the text span as a whole, the first and last words,
the set of words represented as a bag of words, and
the distance between the arguments. In addition,
part of speech (POS) tag features are extracted for
each mention, with separate bag of POS tag fea-
tures for each argument. The POS features are
generated by the cTAKES POS tagger.

We also include semantic features of each argu-
ment. For event mentions, we include a feature
marking the contextual modality, which can take
on the possible values Actual, Hedged, Hypothet-
ical, or Generic, which is part of the gold stan-
dard annotations. This feature was included as it
was presumed that actual events are more likely
to have definite time spans, and thus be related
to times, than hypothetical or generic mentions of
events. For time mentions we include a feature for
the time class, with possible values of Date, Time,
Duration, Quantifier, Set, or Prepostexp. The time
class feature was used as it was hypothesized that
dates and times are more likely to contain events
than sets (e.g., once a month).

3.3 Tree Kernel Representations

We leverage existing tree kernel representations
for this work, using some directly and others as
starting point to a domain-specific representation.

First, we take advantage of the (relatively) flat
structured tree kernel representations of Hovy et
al. (2012). This representation uses lexical items
such as POS tags rather than constituent struc-
ture, but places them into an ordered tree struc-
ture, which allows tree kernels to use them as a
bag of items while also taking advantage of order-
ing structure when it is useful. Figure 1 shows an
example tree for an event-time pair for which a re-
lation exists, where the lexical information used is
POS tag information for each term (the represen-
tation that Hovy et al. found most useful). We also
used a version of this representation where the sur-
face form is used instead of the POS tag.

While Hovy et al. showed positive results using
this representation over just standard features, it is
still somewhat constrained in its ability to repre-
sent long distance relations. This is because the
subset tree kernel compares only complete rule
productions, and with long distance relations a flat
tree structure will have a production that is too big
to learn. Alternatively, tree kernel representations
can be based on constituent structure, as is com-
mon in the relation extraction literature. This will

21



BOP

Event-Actual

TOK

VBN

TOK

TO

TOK

VB

TOK

NN

Timex-Date

TOK

JJ

TOK

NN

BOW

Event-Actual

TOK

scheduled

TOK

to

TOK

undergo

TOK

surgery

Timex-Date

TOK

next

TOK

week

Figure 1: Two trees indicating the flat tree kernel
representation. Above is the bag of POS tags ver-
sion; below is the bag of words version.

hopefully allow for the representation of longer
distance relations by taking advantage of syntactic
sub-structure with smaller productions. The rep-
resentations used here are known as Feature Trees
(FT), Path Trees (PT) and Path-Enclosed Trees
(PET).

The Feature Tree representation takes the en-
tire syntax tree for the sentence containing both
arguments and inserts semantic information about
those arguments. That information includes the ar-
gument type (EVENT or TIMEX) as an additional
tree node above the constituent enclosing the argu-
ment. We also append semantic class information
to the argument (contextual modality for events,
time class for times), as in the flat features.

The Feature Tree representation is not com-
monly used, as it includes an entire sentence
around the arguments of interest, and that may in-
clude a great deal of unrelated structure that adds
noise to the classifier. Here we include it in an at-
tempt to get to the root of an apparent discrepancy
in the tree kernel literature, as explained in Sec-
tion 2, in which Hovy et al. (2012) report a nega-
tive result and Mirroshandel et al. (2009) report a
positive result for using constituency structure in
tree kernels for temporal relation extraction.

The Path Tree representation uses a sub-tree of
the whole constituent tree, but removes all nodes
that are not along the path between the two argu-
ments. Path information has been used in standard
feature kernels (Pradhan et al., 2008), with each
individual path being a possible boolean feature.

VP

Arg1-Event-Actual

arg1

S

VP

VP

Arg2-Timex-Date

arg2

Figure 2: Path Tree (PT) representation

Another representation making use of the path tree
takes contiguous subsections of the path tree, or
“path n-grams,” in an attempt to combat the spar-
sity of using the whole path (Zheng et al., 2012).
By using the path representation with a tree ker-
nel, the model should get the benefit of all different
sizes of path n-grams, up to the size of the whole
path. This representation is augmented by adding
in argument nodes with event and time features, as
in the Feature Tree. Unlike the Feature Tree and
the PET below, the Path Tree representation does
not include word nodes, because the important as-
pect of this representation is the labels of the nodes
on the path between arguments. Figure 2 shows an
example of what this representation looks like.

The Path-Enclosed Tree representation is based
on the smallest sub-tree that encloses the two pro-
posed arguments. This is a representation that has
shown value in other work using tree kernels for
relation extraction (Zhang et al., 2006; Mirroshan-
del et al., 2009). The information contained in
the PET representation is a superset of that con-
tained in the Path Tree representation, since it in-
cludes the full path between arguments as well
as the structure between arguments and the ar-
gument text. This means that it can take into
account path information while also considering
constituent structure between arguments that may
play a role in determining whether the two ar-
guments are related. For example, temporal cue
words like after or during may occur between ar-
guments and will not be captured by Path Trees.
Like the PT representation, the PET representa-
tion is augmented with the semantic information
specified above in the Feature Tree representation.
Figure 3 shows an example of this representation.

22



VP

Arg1-Event-Actual

VBN

scheduled

VP

TO

to

VP

VB

undergo

NP

NN

surgery

Arg2-Timex-Date

NP

JJ

next

NN

week

Figure 3: Path-Enclosed Tree representation

4 Evaluation

The corpus we used for evaluations was described
in Section 2. There are 78 total notes in the corpus,
with three notes for each of 26 patients. The data
is split into training (50%), development (25%),
and test (25%) sections based on patient number,
so that each patient’s notes are all in the same
section. The combined training and development
set used for final training consists of 4378 sen-
tences with 49,050 tokens, and 7372 events, 849
time expressions, and 2287 CONTAINS relations.
There were 774 positive instances of CONTAINS
in the training data, with 1513 negative instances.
For constituent structure and features we use the
gold standard treebank and event and time features
from our corpus. Preliminary work suggests that
automatic parses from cTAKES do not harm per-
formance very much, but the focus of this work is
on the relation extraction so we use gold standard
parses. All preliminary experiments were done us-
ing the development set for testing.

We designed a set of experiments to exam-
ine several hypotheses regarding extraction of the
CONTAINS relation and the efficacy of different
tree kernel representations. The first two config-
urations test simple rule-based baseline systems,
CLOSEST-P and CLOSEST-R, for distance-related
decision rule systems meant to optimize precision
and recall, respectively. CLOSEST-P hypothesizes
a CONTAINS link between every TIMEX3 and the
closest annotated EVENT, which will make few
links overall. CLOSEST-R hypothesizes a CON-
TAINS link between every EVENT and the closest
TIMEX3, which will make many more links.

The next configuration, Flat Features, uses the
token and part of speech features along with ar-

gument semantics features, as described in Sec-
tion 3. While this feature set may not seem ex-
haustive, in preliminary work many traditional re-
lation extraction features were tried and found to
not have much effect. This particular configura-
tion was tested because it is most comparable to
the bag of word and bag of POS kernels from
Hovy et al. (2012), and should help show whether
the tree kernel is providing anything over an equiv-
alent set of basic features.

We then examine several composite kernels, all
using the same feature kernel, but using different
tree kernel-based representations. First, we use a
composite kernel which uses the bag of word and
bag of POS tree views, as in Hovy et al. (2012).
Next, we add in two additional tree views to the
tree kernel, Path-Enclosed Tree and Path Tree,
which are intended to examine the effect of using
traditional syntax, and the long distance features
that they enable. The final experimental config-
uration replaces the PET and PT representations
from the last configuration with the Feature Tree
representation. This tests the hypothesis that the
difference between positive results for tree kernels
in this task (as in, say, Mirroshandel et al. (2009))
and negative results reported by Hovy et al. (2012)
is the difference between using a full-parse tree
and using standard sub-tree representations.

For the rule-based systems, there are no param-
eters to tune. Our machine-learning systems are
based on support vector machines (SVM), which
require tuning of several parameters, including
kernel type (linear, polynomial, and radial basis
function), the parameters for each kernel, and c,
the cost of misclassification. Tree kernels intro-
duce an additional parameter λ for weighting large
structures, and the use of a composite kernel in-
troduces parameters for which kernel combination
operator to use, and how to weight the different
kernels for the sum operator.

For each machine learning configuration, we
performed a large grid search over the combined
parameter space, where we trained on the train-
ing set and tested on the development set. For
the final experiments, the parameters were chosen
that optimized the F1 score on the development
set. Qualitatively, the parameter tuning strongly
favored configurations which combined the ker-
nels using the sum operator, and recall and pre-
cision were strongly correlated with the SVM pa-
rameter c. Using these parameters, we then trained

23



on the combined training and development sets
and tested on the official test set.

4.1 Evaluation Metrics

The state of evaluating temporal relations has been
evolving over the past decade. This is partially
due to the inferential properties of temporal rela-
tions, because it is possible to define the same set
of relations using different set of axioms. To take
a very simple example, given a gold set of rela-
tions A<B and B<C, and given the system output
A<B, A<C and B<C, if one were to compute a
plain precision/recall metric, then the axiom A<C
would be counted against the system, when one
can easily infer from the gold set of relations that
it is indeed correct. With more relations the infer-
ence process becomes more complex.

Recently there has been some work trying
to address the shortcomings of the plain F1
score (Muller and Tannier, 2004; Setzer et al.,
2006; UzZaman and Allen, 2011; Tannier and
Muller, 2008; Tannier and Muller, 2011). How-
ever, the community has not yet come to a consen-
sus on the best evaluation approach. Two recent
evaluations, TempEval-3 (UzZaman et al., 2013)
and the 2012 i2b2 Challenge (Sun et al., 2013),
used an implementation of the proposal by (Uz-
Zaman and Allen, 2011). However, as described
in Cherry et al. (2013), this algorithm, which uses
a greedy graph minimization approach, is sensi-
tive to the order in which the temporal relations
are presented to the scorer. In addition, the scorer
is not able to give credit for non-redundant, non-
minimum links (Cherry et al., 2013) as with the
the case of the relation A<C mentioned earlier.

Considering that the measures for evaluating
temporal relations are still evolving, we decided to
use plain F-score, with recall and precision scores
also reported. This score is computed across all
intra-sentential EVENT-TIMEX3 pairs in the gold
standard, where precision = # correct predictions# predictions ,

recall = # correct predictions# gold standard relations , and F1 score =
2∗precision∗recall
precision+recall .

4.2 Experimental Results

Results are shown in Table 1. Rule-based base-
lines perform reasonably well, but are heavily bi-
ased in terms of precision or recall. The ma-
chine learning baseline cannot even obtain the
same performance as the CLOSEST-R rule-based
system, though it is more balanced in terms of pre-

System Precision Recall F1
CLOSEST-P 0.754 0.537 0.627
CLOSEST-R 0.502 0.947 0.656
Flat Features (FF) 0.705 0.593 0.645
FF+Bag Trees (BT) 0.649 0.728 0.686
FF+BT+PET+PT 0.770 0.707 0.737
FF+BT+FT 0.691 0.691 0.691

Table 1: Table of results of main experiments.

cision and recall. Using a composite kernel which
adds in the flat token-based tree kernels improves
performance over the standard feature kernel by
4.1 points. Adding in the Path Tree and Path-
Enclosed Tree constituency-based trees along with
the flat trees improves F1 score to our best result
of 73.7. Finally, replacing PT and PET representa-
tions with the Feature Tree representation does not
offer any performance improvement over the Flat
Features + Bag Trees configuration.

4.3 Error Analysis

We performed error analysis on the outputs of the
best-performing system (FF+BT+PET+PT in Ta-
ble 1). First, we note that the parameter search
was optimized for F1. This resulted in the highest-
scoring configuration using a composite kernel
with the sum operator, polynomial kernel for the
secondary kernel, λ = 0.5, tree kernel weight (T )
of 0.1, and c = 10.0. This high value of c and low
value of T results in higher precision and lower
recall, but there were configurations with lower c
and higher T which made the opposite tradeoff,
with only marginally worse F1-score. For the pur-
poses of error analysis, however, this configuration
leads to a focus on false negatives.

First, the false positives contained many rela-
tions that were legitimately ambiguous or possible
annotator errors. An example ambiguous case is
She is currently being treated on the Surgical Ser-
vice for..., in which the system generates the re-
lation CONTAINS(currently, treated), but the gold
standard labels as OVERLAP. This example is am-
biguous because it is not clear from just the lin-
guistic context whether the treatment is wholly
contained in the small time window denoted by
currently, or whether it started a while ago or will
continue into the future. There are many similar
cases where the event is a disease/disorder type,
and the specific nature of the disease is impor-
tant to understanding whether this is a CONTAINS

24



or OVERLAP relation, specifically understanding
whether the disease is chronic or more acute.

Another source of false positives were where
the event and time were clearly related, but not
with CONTAINS. In the example reports that she
has been having intermittent bleeding since May
of 1998, the term since clearly indicates that this
is a BEGINS-ON relation between bleeding and
May of 1998. This is a case where having other
temporal relation classifiers may be useful, as they
can compete and the relation can be assigned to
whichever classifier is more confident.

False negatives frequently occurred in contexts
where the event and time were far apart. Syn-
tactic tree kernels were introduced to help im-
prove recall on longer-distance relations, and were
successful up to a limit. However, certain ex-
amples are so far apart that the algorithm may
have had difficulty sorting noise from important
structure. For example, the system did not find
the CONTAINS(October 27, 2010, oophorectomy)
relation in the sentence:

October 27, 2010, Dr. XXX performed
exploratory laparotomy with an trans-
verse colectomy and Dr. YYY performed
a total abdominal hysterectomy with a
bilateral salpingo-oophorectomy.

Here, while the date may be part of the same sen-
tence as the event, the syntactic relation between
the pair is not what makes the relation; the date is
acting as a kind of discourse marker that indicates
that the following events are contained. This sug-
gests that discourse-level features may be useful
even for the intra-sentential classification task.

Other false negatives occurred where there was
syntactic complexity, even on shorter examples.
The subset tree kernel used here matches com-
plete rule productions, and across complex struc-
ture with large productions, the chances of finding
similarity decreases substantially. Thus, events
within coordination or separated from the time by
clause breaks are more difficult to relate to the
time due to the multiple different ways of relating
these different syntactic elements.

Finally, there are some examples where the an-
chor of a narrative container is an event with mul-
tiple sub-events. In these cases, the system per-
forms well at relating a time expression to the an-
chor event, but may miss the sub-events that are
farther away. This is a case where having an event-

event TLINK classifier, then applying determinis-
tic closure rules, would allow a combined system
to link the sub-events to the time expression.

5 Discussion and Conclusion

In this paper we have developed a system for auto-
matically identifying CONTAINS relations in clini-
cal text. The experiments show first that a machine
learning approach that intelligently integrates con-
stituency information can greatly improve perfor-
mance over rule-based baselines. We also show
that the tree kernel approach, which can model se-
quence better than a bag of tokens-style approach,
is beneficial even when it uses the same features.
Finally, the experiments show that choosing the
correct representation is important for tree kernel
approaches, and specifically that using a full parse
tree may give inferior performance compared to
sub-trees focused on the structure of interest.

In general, there is much work to be done in the
area of representing temporal information in clin-
ical records. Many of the inputs to the algorithm
described in this paper need to be extracted auto-
matically, including time expressions and events.
Work on relations will focus on adding features
to represent discourse information and richer rep-
resentation of event semantics. Discourse infor-
mation may help with the longer-distance errors,
where the time expression acts almost as a topic
for an extended description of events. Better un-
derstanding of event semantics, such as whether
a disease is chronic or acute, or typical duration
for a treatment, may help constrain relations. In
addition, we will explore the effectiveness of us-
ing dependency tree structure, which has been use-
ful in the domain of extracting relations from the
biomedical literature (Tikk et al., 2013).

Acknowledgements

The work described was supported by Tempo-
ral History of Your Medical Events (THYME)
NLM R01LM010090 and Integrating Informat-
ics and Biology to the Bedside (i2b2) NCBO
U54LM008748. Thanks to the anonymous re-
viewers for thorough and insightful comments.

References
Naushad UzZaman, Hector Llorens, et al. 2013. Semeval-

2013 task 1: Tempeval-3: Evaluating time expressions,
events, and temporal relations. In Second Joint Confer-
ence on Lexical and Computational Semantics (*SEM),

25



Volume 2: Proceedings of the Seventh International Work-
shop on Semantic Evaluation (SemEval 2013), pages 1–9,
Atlanta, Georgia, USA, June. Association for Computa-
tional Linguistics.

Ashwin N Ananthakrishnan, Tianxi Cai, et al. 2013. Improv-
ing case definition of Crohn’s disease and ulcerative col-
itis in electronic medical records using natural language
processing: a novel informatics approach. Inflammatory
bowel diseases.

Steven Bethard and James H. Martin. 2007. CU-TMP: Tem-
poral relation classification using syntactic and semantic
features. In Proceedings of the 4th International Work-
shop on Semantic Evaluations (SemEval-2007), pages
129–132.

Colin Cherry, Xiaodan Zhu, et al. 2013. A la recherche du
temps perdu: extracting temporal relations from medical
text in the 2012 i2b2 NLP challenge. Journal of the Amer-
ican Medical Informatics Association, March.

Michael Collins and Nigel Duffy. 2001. Convolution kernels
for natural language. In Neural Information Processing
Systems.

Nello Cristianini and John Shawe-Taylor. 2000. An Introduc-
tion to Support Vector Machines and Other Kernel-based
Learning Methods. Cambridge University Press.

Dirk Hovy, James Fan, et al. 2012. When did that happen?:
linking events and relations to timestamps. In Proceedings
of the 13th Conference of the European Chapter of the As-
sociation for Computational Linguistics, pages 185–193.
Association for Computational Linguistics.

Thorsten Joachims. 1999. Making large scale svm learning
practical. In B. Schlkopf, C. Burges, and A. Smola, edi-
tors, Advances in Kernel Methods - Support Vector Learn-
ing. Universität Dortmund.

Chen Lin, Helena Canhao, et al. 2012. Feature engineering
and selection for rheumatoid arthritis disease activity clas-
sification using electronic medical records. In Proceed-
ings of ICML Workshop on Machine Learning for Clinical
Data.

Hector Llorens, Estela Saquete, and Borja Navarro. 2010.
TIPSem (english and spanish): Evaluating crfs and seman-
tic roles in tempeval-2. In Proceedings of the 5th Interna-
tional Workshop on Semantic Evaluation, pages 284–291.
Association for Computational Linguistics.

Seyed Abolghasem Mirroshandel, M Khayyamian, and
GR Ghassem-Sani. 2009. Using tree kernels for clas-
sifying temporal relations between events. Proc. of the
PACLIC23, pages 355–364.

Alessandro Moschitti. 2006. Efficient convolution kernels
for dependency and constituent syntactic trees. In Ma-
chine Learning: ECML 2006, pages 318–329. Springer.

Philippe Muller and Xavier Tannier. 2004. Annotating and
measuring temporal relations in texts. In Proceedings of
the 20th international conference on Computational Lin-
guistics, COLING ’04, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.

Philip V. Ogren, Philipp G. Wetzler, and Steven J. Bethard.
2009. ClearTK: a framework for statistical natural lan-
guage processing. In Unstructured Information Manage-
ment Architecture Workshop at the Conference of the Ger-
man Society for Computational Linguistics and Language
Technology, 9.

Sameer S Pradhan, Wayne Ward, and James H Martin. 2008.
Towards robust semantic role labeling. Computational
Linguistics, 34(2):289–310.

James Pustejovsky and Amber Stubbs. 2011. Increasing in-
formativeness in temporal annotation. In Proceedings of
the 5th Linguistic Annotation Workshop, pages 152–160.

James Pustejovsky, Patrick Hanks, et al. 2003a. The time-
bank corpus. In Corpus linguistics, volume 2003, page 40.

James Pustejovsky, José Casta no, et al. 2003b. Timeml:
Robust specification of event and temporal expressions in
text. In Fifth International Workshop on Computational
Semantics (IWCS-5).

Preethi Raghavan, Eric Fosler-Lussier, and Albert M Lai.
2012. Temporal classification of medical events. In Pro-
ceedings of the 2012 Workshop on Biomedical Natural
Language Processing, pages 29–37. Association for Com-
putational Linguistics.

Guergana K. Savova, James J. Masanz, et al. 2010. Mayo
clinical text analysis and knowledge extraction system
(cTAKES): architecture, component evaluation and appli-
cations. J Am Med Inform Assoc, 17(5):507–513.

Andrea Setzer, Robert Gaizauskas, and Mark Hepple. 2006.
The role of inference in the temporal annotation and anal-
ysis of text. Language Resources and Evaluation, 39(2-
3):243–265, February.

Stephanie Strassel, Dan Adams, et al. 2010. The DARPA
machine reading program - encouraging linguistic and rea-
soning research with a series of reading tasks. In Proceed-
ings of the Seventh International Conference on Language
Resources and Evaluation (LREC’10), Valletta, Malta.

Weiyi Sun, Anna Rumshisky, and Ozlem Uzuner. 2013.
Evaluating temporal relations in clinical text: 2012 i2b2
challenge. Journal of the American Medical Informatics
Association, April.

Xavier Tannier and Philippe Muller. 2008. Evaluation met-
rics for automatic temporal annotation of texts. Proceed-
ings of the Proceedings of the Sixth International Lan-
guage Resources and Evaluation (LREC’08).

Xavier Tannier and Philippe Muller. 2011. Evaluating tem-
poral graphs built from texts via transitive reduction. J.
Artif. Int. Res., 40(1):375413, January.

Domonkos Tikk, Illés Solt, et al. 2013. A detailed error anal-
ysis of 13 kernel methods for protein-protein interaction
extraction. BMC bioinformatics, 14(1):12.

Naushad UzZaman and James Allen. 2011. Temporal eval-
uation. In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human Lan-
guage Technologies, page 351–356.

Marc Verhagen, Robert Gaizauskas, et al. 2007. Semeval-
2007 task 15: Tempeval temporal relation identification.
In Proceedings of the Fourth International Workshop on
Semantic Evaluations (SemEval-2007), pages 75–80.

Marc Verhagen, Roser Sauri, et al. 2010. Semeval-2010 task
13: Tempeval-2. In Proceedings of the 5th International
Workshop on Semantic Evaluation, pages 57–62, Uppsala,
Sweden, July. Association for Computational Linguistics.

RA Wilke, H Xu, et al. 2011. The emerging role of electronic
medical records in pharmacogenomics. Clinical Pharma-
cology & Therapeutics, 89(3):379–386.

Yan Xu, Yining Wang, et al. 2013. An end-to-end system to
identify temporal relation in discharge summaries: 2012
i2b2 challenge. Journal of the American Medical Infor-
matics Association : JAMIA.

Min Zhang, Jie Zhang, and Jian Su. 2006. Exploring syn-
tactic features for relation extraction using a convolution
tree kernel. In Proceedings of the Human Language Tech-
nology Conference of the North American Chapter of the
ACL, pages 288–295.

Jiaping Zheng, Wendy W Chapman, et al. 2012. A sys-
tem for coreference resolution for the clinical narrative.
Journal of the American Medical Informatics Association,
19:660–667.

26


