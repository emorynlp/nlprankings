



















































Shallow Local Multi-Bottom-up Tree Transducers in Statistical Machine Translation


Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 811–821,
Sofia, Bulgaria, August 4-9 2013. c©2013 Association for Computational Linguistics

Shallow Local Multi Bottom-up Tree Transducers
in Statistical Machine Translation

Fabienne Braune and Nina Seemann and Daniel Quernheim and Andreas Maletti
Institute for Natural Language Processing, University of Stuttgart

Pfaffenwaldring 5b, 70569 Stuttgart, Germany
{braunefe,seemanna,daniel,maletti}@ims.uni-stuttgart.de

Abstract
We present a new translation model in-
tegrating the shallow local multi bottom-
up tree transducer. We perform a large-
scale empirical evaluation of our obtained
system, which demonstrates that we sig-
nificantly beat a realistic tree-to-tree base-
line on the WMT 2009 English→German
translation task. As an additional contribu-
tion we make the developed software and
complete tool-chain publicly available for
further experimentation.

1 Introduction

Besides phrase-based machine translation sys-
tems (Koehn et al., 2003), syntax-based systems
have become widely used because of their abil-
ity to handle non-local reordering. Those systems
use synchronous context-free grammars (Chi-
ang, 2007), synchronous tree substitution gram-
mars (Eisner, 2003) or even more powerful for-
malisms like synchronous tree-sequence substitu-
tion grammars (Sun et al., 2009). However, those
systems use linguistic syntactic annotation at dif-
ferent levels. For example, the systems proposed
by Wu (1997) and Chiang (2007) use no linguis-
tic information and are syntactic in a structural
sense only. Huang et al. (2006) and Liu et al.
(2006) use syntactic annotations on the source lan-
guage side and show significant improvements in
translation quality. Using syntax exclusively on
the target language side has also been success-
fully tried by Galley et al. (2004) and Galley et
al. (2006). Nowadays, open-source toolkits such
as Moses (Koehn et al., 2007) offer syntax-based
components (Hoang et al., 2009), which allow
experiments without expert knowledge. The im-
provements observed for systems using syntactic
annotation on either the source or the target lan-
guage side naturally led to experiments with mod-
els that use syntactic annotations on both sides.

However, as noted by Lavie et al. (2008), Liu et
al. (2009), and Chiang (2010), the integration of
syntactic information on both sides tends to de-
crease translation quality because the systems be-
come too restrictive. Several strategies such as
(i) using parse forests instead of single parses (Liu
et al., 2009) or (ii) soft syntactic constraints (Chi-
ang, 2010) have been developed to alleviate this
problem. Another successful approach has been
to switch to more powerful formalisms, which al-
low the extraction of more general rules. A par-
ticularly powerful model is the non-contiguous
version of synchronous tree-sequence substitu-
tion grammars (STSSG) of Zhang et al. (2008a),
Zhang et al. (2008b), and Sun et al. (2009),
which allows sequences of trees on both sides of
the rules [see also (Raoult, 1997)]. The multi
bottom-up tree transducer (MBOT) of Arnold and
Dauchet (1982) and Lilin (1978) offers a middle
ground between traditional syntax-based models
and STSSG. Roughly speaking, an MBOT is an
STSSG, in which all the discontinuities must oc-
cur on the target language side (Maletti, 2011).
This restriction yields many algorithmic advan-
tages over both the traditional models as well as
STSSG as demonstrated by Maletti (2010). For-
mally, they are expressive enough to express all
sensible translations (Maletti, 2012)1. Figure 2
displays sample rules of the MBOT variant, called
`MBOT, that we use (in a graphical representation
of the trees and the alignment).

In this contribution, we report on our novel sta-
tistical machine translation system that uses an
`MBOT-based translation model. The theoreti-
cal foundations of `MBOT and their integration
into our translation model are presented in Sec-
tions 2 and 3. In order to empirically evaluate the
`MBOT model, we implemented a machine trans-

1A translation is sensible if it is of linear size increase
and can be computed by some (potentially copying) top-down
tree transducer.

811



Sε

NP1

JJ11

Official111

NNS12

forecasts121

VP2

VBD21

predicted211

NP22

QP221

RB2211

just22111

CD2212

322121

NN222

%2221

Figure 1: Example tree t with indicated positions.
We have t(21) = VBD and t|221 is the subtree
marked in red.

lation system that we are going to make available
to the public. We implemented `MBOT inside
the syntax-based component of the Moses open
source toolkit. Section 4 presents the most im-
portant algorithms of our `MBOT decoder. We
evaluate our new system on the WMT 2009 shared
translation task English → German. The trans-
lation quality is automatically measured using
BLEU scores, and we confirm the findings by pro-
viding linguistic evidence (see Section 5). Note
that in contrast to several previous approaches, we
perform large scale experiments by training sys-
tems with approx. 1.5 million parallel sentences.

2 Theoretical Model

In this section, we present the theoretical genera-
tive model used in our approach to syntax-based
machine translation. Essentially, it is the local
multi bottom-up tree transducer of Maletti (2011)
with the restriction that all rules must be shallow,
which means that the left-hand side of each rule
has height at most 2 (see Figure 2 for shallow
rules and Figure 4 for rules including non-shallow
rules). The rules extracted from the training exam-
ple of Figure 3 are displayed in Figure 4. Those
extracted rules are forcibly made shallow by re-
moving internal nodes. The application of those
rules is illustrated in Figures 5 and 6.

For those that want to understand the inner
workings, we recall the principal model in full de-
tail in the rest of this section. Since we utilize syn-
tactic parse trees, let us introduce trees first. Given
an alphabet Σ of labels, the set TΣ of all Σ-trees is
the smallest set T such that σ(t1, . . . , tk) ∈ T for
all σ ∈ Σ, integer k ≥ 0, and t1, . . . , tk ∈ T . In-
tuitively, a tree t consists of a labeled root node σ
followed by a sequence t1, . . . , tk of its children.
A tree t ∈ TΣ is shallow if t = σ(t1, . . . , tk) with
σ ∈ Σ and t1, . . . , tk ∈ Σ.

NP

QP NN
→
( PP

von AP NN

)

S

NP VBD NP
→
( S

NP VAFIN PP VVPP

)

Figure 2: Sample `MBOT rules.

To address a node inside a tree, we use its po-
sition, which is a word consisting of positive in-
tegers. Roughly speaking, the root of a tree is
addressed with the position ε (the empty word).
The position iw with i ∈ N addresses the po-
sition w in the ith direct child of the root. In
this way, each node in the tree is assigned a
unique position. We illustrate this notion in Fig-
ure 1. Formally, the positions pos(t) ⊆ N∗ of
a tree t = σ(t1, . . . , tk) are inductively defined
by pos(t) = {ε} ∪ pos(k)(t1, . . . , tk), where

pos(k)(t1, . . . , tk) =
⋃

1≤i≤k
{iw | w ∈ pos(ti)} .

Let t ∈ TΣ and w ∈ pos(t). The label of t at
position w is t(w), and the subtree rooted at posi-
tion w is t|w. These notions are also illustrated in
Figure 1. A position w ∈ pos(t) is a leaf (in t) if
w1 /∈ pos(t). In other words, leaves do not have
any children. Given a subset N ⊆ Σ, we let

leafN (t) = {w ∈ pos(t) | t(w) ∈ N, w leaf in t}

be the set of all leaves labeled by elements of N .
When N is the set of nonterminals, we call them
leaf nonterminals. We extend this notion to se-
quences t1, . . . , tk ∈ TΣ by

leaf
(k)
N (t1, . . . , tk) =

⋃

1≤i≤k
{iw | w ∈ leafN (ti)}.

Let w1, . . . , wn ∈ pos(t) be (pairwise prefix-
incomparable) positions and t1, . . . , tn ∈ TΣ.
Then t[wi ← ti]1≤i≤n denotes the tree that is ob-
tained from t by replacing (in parallel) the subtrees
at wi by ti for every 1 ≤ i ≤ n.

Now we are ready to introduce our model,
which is a minor variation of the local multi
bottom-up tree transducer of Maletti (2011). Let
Σ and ∆ be the input and output symbols, respec-
tively, and let N ⊆ Σ ∪∆ be the set of nontermi-
nal symbols. Essentially, the model works on pairs
〈t, (u1, . . . , uk)〉 consisting of an input tree t ∈ TΣ

812



and a sequence u1, . . . , uk ∈ T∆ of output trees.
Such pairs are pre-translations of rank k. The pre-
translation 〈t, (u1, . . . , uk)〉 is shallow if all trees
t, u1, . . . , uk in it are shallow.

Together with a pre-translation we typically
have to store an alignment. Given a pre-translation
〈t, (u1, . . . , uk)〉 of rank k and 1 ≤ i ≤ k,
we call ui the ith translation of t. An align-
ment for this pre-translation is an injective map-
ping ψ : leaf(k)N (u1, . . . , uk)→ leafN (t)×N such
that if (w, j) ∈ ran(ψ), then also (w, i) ∈ ran(ψ)
for all 1 ≤ j ≤ i.2 In other words, if an alignment
requests the ith translation, then it should also re-
quest all previous translations.

Definition 1 A shallow local multi bottom-up tree
transducer (`MBOT) is a finite set R of rules to-
gether with a mapping c : R → R such that every
rule, written t →ψ (u1, . . . , uk), contains a shal-
low pre-translation 〈t, (u1, . . . , uk)〉 and an align-
ment ψ for it.

The components t, (u1, . . . , uk), ψ, and c(ρ)
are called the left-hand side, the right-hand
side, the alignment, and the weight of the
rule ρ = t →ψ (u1, . . . , uk). Figure 2 shows two
example `MBOT rules (without weights). Overall,
the rules of an `MBOT are similar to the rules of
an SCFG (synchronous context-free grammar), but
our right-hand sides contain a sequence of trees
instead of just a single tree. In addition, the align-
ments in an SCFG rule are bijective between leaf
nonterminals, whereas our model permits multi-
ple alignments to a single leaf nonterminal in the
left-hand side (see Figure 2).

Our `MBOT rules are obtained automatically
from data like that in Figure 3. Thus, we (word)
align the bilingual text and parse it in both the
source and the target language. In this manner
we obtain sentence pairs like the one shown in
Figure 3. To these sentence pairs we apply the
rule extraction method of Maletti (2011). The
rules extracted from the sentence pair of Figure 3
are shown in Figure 4. Note that these rules
are not necessarily shallow (the last two rules are
not). Thus, we post-process the extracted rules
and make them shallow. The shallow rules corre-
sponding to the non-shallow rules of Figure 4 are
shown in Figure 2.

Next, we define how to combine rules to form
derivations. In contrast to most other models, we

2ran(f) for a mapping f : A→ B denotes the range of f ,
which is {f(a) | a ∈ A}.

S

NP

JJ

Official

NNS

forecasts

VP

VBD

predicted

NP

QP

RB

just

CD

3

NN

%

S

NP

ADJA

Offizielle

NN

Prognosen

VAFIN

sind

VP

PP

APPR

von

AP

ADV

nur

CARD

3

NN

%

VVPP

ausgegangen

Figure 3: Aligned parsed sentences.

only introduce a derivation semantics that does
not collapse multiple derivations for the same
input-output pair.3 We need one final notion.
Let ρ = t →ψ (u1, . . . , uk) be a rule and
w ∈ leafN (t) be a leaf nonterminal (occurrence)
in the left-hand side. The w-rank rk(ρ, w) of the
rule ρ is

rk(ρ, w) = max {i ∈ N | (w, i) ∈ ran(ψ)} .

For example, for the lower rule ρ in Figure 2 we
have rk(ρ, 1) = 1, rk(ρ, 2) = 2, and rk(ρ, 3) = 1.

Definition 2 The set τ(R, c) of weighted pre-
translations of an `MBOT (R, c) is the smallest
set T subject to the following restriction: If there
exist
• a rule ρ = t→ψ (u1, . . . , uk) ∈ R,
• a weighted pre-translation

〈tw, cw, (uw1 , . . . , uwkw)〉 ∈ T

for every w ∈ leafN (t) with
– rk(ρ, w) = kw,4
– t(w) = tw(ε),5 and
– for every iw′ ∈ leaf(k)N (u1, . . . , uk),6

ui(w
′) = uvj (ε) with ψ(iw

′) = (v, j),

then 〈t′, c′, (u′1, . . . , u′k)〉 ∈ T is a weighted pre-
translation, where
• t′ = t[w ← tw | w ∈ leafN (t)],
3A standard semantics is presented, for example,

in (Maletti, 2011).
4If w has n alignments, then the pre-translation selected

for it has to have suitably many output trees.
5The labels have to coincide for the input tree.
6Also the labels for the output trees have to coincide.

813



JJ

Official
→
( ADJA

Offizielle

) NNS

forecasts
→
( NN

Prognosen

) VBD

predicted
→
( VAFIN

sind
,

VVPP

ausgegangen

) RB

just
→
( ADV

nur

) CD

3
→
( CARD

3

) NN

%
→
( NN

%

)

NP

JJ NNS
→
( NP

ADJA NN

) QP

RB CD
→
( AP

ADV CARD

) NP

QP NN
→
( PP

APPR

von

AP NN
) S

NP VP

VBD NP

→
( S

NP VAFIN VP

PP VVPP

)

Figure 4: Extracted (even non-shallow) rules. We obtain our rules by making those rules shallow.

• c′ = c(ρ) ·∏w∈leafN (t) cw, and
• u′i = ui[iw′ ← uvj | ψ(iw′) = (v, j)] for

every 1 ≤ i ≤ k.
Rules that do not contain any nonterminal

leaves are automatically weighted pre-translations
with their associated rule weight. Otherwise, each
nonterminal leaf w in the left-hand side of a rule ρ
must be replaced by the input tree tw of a pre-
translation 〈tw, cw, (uw1 , . . . , uwkw)〉, whose root is
labeled by the same nonterminal. In addition, the
rank rk(ρ, w) of the replaced nonterminal should
match the number kw of components in the se-
lected weighted pre-translation. Finally, the non-
terminals in the right-hand side that are aligned
to w should be replaced by the translation that the
alignment requests, provided that the nontermi-
nal matches with the root symbol of the requested
translation. The weight of the new pre-translation
is obtained simply by multiplying the rule weight
and the weights of the selected weighted pre-
translations. The overall process is illustrated in
Figures 5 and 6.

3 Translation Model

Given a source language sentence e, our transla-
tion model aims to find the best corresponding tar-
get language translation ĝ;7 i.e.,

ĝ = arg maxg p(g|e) .
We estimate the probability p(g|e) through a log-
linear combination of component models with pa-
rameters λm scored on the pre-translations 〈t, (u)〉
such that the leaves of t concatenated read e.8

p(g|e) ∝
7∏

m=1

hm
(
〈t, (u)〉

)λm

Our model uses the following features
hm(〈t, (u1, . . . , uk)〉) for a general pre-translation
τ = 〈t, (u1, . . . , uk)〉:

7Our main translation direction is English to German.
8Actually, t must embed in the parse tree of e; see Sec-

tion 4.

(1) The forward translation weight using the rule
weights as described in Section 2

(2) The indirect translation weight using the rule
weights as described in Section 2

(3) Lexical translation weight source→ target
(4) Lexical translation weight target→ source
(5) Target side language model
(6) Number of words in the target sentences
(7) Number of rules used in the pre-translation
(8) Number of target side sequences; here k times

the number of sequences used in the pre-
translations that constructed τ (gap penalty)

The rule weights required for (1) are relative
frequencies normalized over all rules with the
same left-hand side. In the same fashion the rule
weights required for (2) are relative frequencies
normalized over all rules with the same right-
hand side. Additionally, rules that were extracted
at most 10 times are discounted by multiplying
the rule weight by 10−2. The lexical weights
for (2) and (3) are obtained by multiplying the
word translationsw(gi|ej) [respectively,w(ej |gi)]
of lexically aligned words (gi, ej) accross (possi-
bly discontiguous) target side sequences.9 When-
ever a source word ej is aligned to multiple target
words, we average over the word translations.10

h3(〈t, (u1, . . . , uk)〉)
=

∏

lexical item
e occurs in t

average {w(g|e) | g aligned to e}

The computation of the language model esti-
mates for (6) is adapted to score partial transla-
tions consisting of discontiguous units. We ex-
plain the details in Section 4. Finally, the count c
of target sequences obtained in (7) is actually used
as a score 1001−c. This discourages rules with
many target sequences.

9The lexical alignments are different from the alignments
used with a pre-translation.

10If the word ej has no alignment to a target word, then
it is assumed to be aligned to a special NULL word and this
alignment is scored.

814



Combining a rule with pre-translations:

NP

JJ NNS
→
( NP

ADJA NN

)

JJ

Official
→
( ADJA

Offizielle

) NNS

forecasts
→
( NN

Prognosen

)

Obtained new pre-translation:

NP

JJ

Official

NNS

forecasts

→
(

NP

ADJA

Offizielle

NN

Prognosen

)

Figure 5: Simple rule application.

Combining a rule with pre-translations:

S

NP VBD NP
→
( S

NP VAFIN PP VVPP

)

NP

JJ

Official

NNS

forecasts

→
(

NP

ADJA

Offizielle

NN

Prognosen

) VBD

predicted
→
( VAFIN

sind
,

VVPP

ausgegangen

)

NP

QP

RB

just

CD

3

NN

%
→
(

PP

von AP

ADV

nur

CARD

3

NN

%

)

Obtained new pre-translation:

S

NP

JJ

Official

NNS

forecasts

VBD

predicted

NP

QP

RB

just

CD

3

NN

%

→
(

S

NP

ADJA

Offizielle

NN

Prognosen

VAFIN

sind

PP

von AP

ADV

nur

CARD

3

NN

%

VVPP

ausgegangen

)

Figure 6: Complex rule application.

S

NP VAFIN PP VVPP

Offizielle Prognosen
(

sind , ausgegangen
)

von nur 3 %

Figure 7: Illustration of LM scoring.

815



4 Decoding

We implemented our model in the syntax-based
component of the Moses open-source toolkit
by Koehn et al. (2007) and Hoang et al. (2009).
The standard Moses syntax-based decoder only
handles SCFG rules; i.e, rules with contiguous
components on the source and the target lan-
guage side. Roughly speaking, SCFG rules are
`MBOT rules with exactly one output tree. We
thus had to extend the system to support our
`MBOT rules, in which arbitrarily many output
trees are allowed.

The standard Moses syntax-based decoder uses
a CYK+ chart parsing algorithm, in which each
source sentence is parsed and contiguous spans are
processed in a bottom-up fashion. A rule is appli-
cable11 if the left-hand side of it matches the non-
terminal assigned to the full span by the parser and
the (non-)terminal assigned to each subspan.12 In
order to speed up the decoding, cube pruning (Chi-
ang, 2007) is applied to each chart cell in order
to select the most likely hypotheses for subspans.
The language model (LM) scoring is directly in-
tegrated into the cube pruning algorithm. Thus,
LM estimates are available for all considered hy-
potheses. To accommodate `MBOT rules, we had
to modify the Moses syntax-based decoder in sev-
eral ways. First, the rule representation itself is ad-
justed to allow sequences of shallow output trees
on the target side. Naturally, we also had to ad-
just hypothesis expansion and, most importantly,
language model scoring inside the cube pruning
algorithm. An overview of the modified pruning
procedure is given in Algorithm 1.

The most important modifications are hidden
in lines 5 and 8. The expansion in Line 5 in-
volves matching all nonterminal leaves in the rule
as defined in Definition 2, which includes match-
ing all leaf nonterminals in all (discontiguous) out-
put trees. Because the output trees can remain
discontiguous after hypothesis creation, LM scor-
ing has to be done individually over all output
trees. Algorithm 2 describes our LM scoring in
detail. In it we use k strings w1, . . . , wk to col-
lect the lexical information from the k output com-

11Note that our notion of applicable rules differs from the
default in Moses.

12Theoretically, this allows that the decoder ignores unary
parser nonterminals, which could also disappear when we
make our rules shallow; e.g., the parse tree left in the pre-
translation of Figure 5 can be matched by a rule with left-
hand side NP(Official, forecasts).

Algorithm 1 Cube pruning with `MBOT rules
Data structures:
- r[i, j]: list of rules matching span e[i . . . j]
- h[i, j]: hypotheses covering span e[i . . . j]
- c[i, j]: cube of hypotheses covering span e[i . . . j]
1: for all `MBOT rules ρ covering span e[i . . . j] do
2: Insert ρ into r[i, j]
3: Sort r[i, j]
4: for all (l→ψ r) ∈ r[i, j] do
5: Create h[i, j] by expanding all nonterminals in l with

best scoring hypotheses for subspans
6: Add h[i, j] to c[i, j]
7: for all hypotheses h ∈ c[i, j] do
8: Estimate LM score for h // see Algorithm 2
9: Estimate remaining feature scores

10: Sort c[i, j]
11: Retrieve first α elements from c[i, j] // we use α = 103

ponents (u1, . . . , uk) of a rule. These strings can
later be rearranged in any order, so we LM-score
all of them separately. Roughly speaking, we ob-
tain wi by traversing ui depth-first left-to-right.
If we meet a lexical element (terminal), then we
add it to the end of wi. On the other hand, if we
meet a nonterminal, then we have to consult the
best pre-translation τ ′ = 〈t′, (u′1, . . . , u′k′)〉, which
will contribute the subtree at this position. Sup-
pose that u′j will be substituted into the nontermi-
nal in question. Then we first LM-score the pre-
translation τ ′ to obtain the string w′j correspond-
ing to u′j . This string w

′
j is then appended to wi.

Once all the strings are built, we score them using
our 4-gram LM. The overall LM score for the pre-
translation is obtained by multiplying the scores
for w1, . . . , wk. Clearly, this treats w1, . . . , wk as
k separate strings, although they eventually will
be combined into a single string. Whenever such
a concatenation happens, our LM scoring will au-
tomatically compute n-gram LM scores based on
the concatenation, which in particular means that
the LM scores get more accurate for larger spans.
Finally, in the final rule only one component is al-
lowed, which yields that the LM indeed scores the
complete output sentence.

Figure 7 illustrates our LM scoring for a pre-
translation involving a rule with two (discontigu-
ous) target sequences (the construction of the pre-
translation is illustrated in Figure 6). When pro-
cessing the rule rooted at S, an LM estimate is
computed by expanding all nonterminal leaves. In
our case, these are NP, VAFIN, PP, and VVPP.
However, the nodes VAFIN and VVPP are assem-
bled from a (discontiguous) tree sequence. This
means that those units have been considered as in-

816



Algorithm 2 LM scoring
Data structures:
- (u1, . . . , uk): right-hand side of a rule
- (w1, . . . , wk): k strings all initially empty
1: score = 1
2: for all 1 ≤ i ≤ k do
3: for all leaves ` in ui (in lexicographic order) do
4: if ` is a terminal then
5: Append ` to wi
6: else
7: LM score the best hypothesis for the subspan
8: Expand wi by the corresponding w′j
9: score = score · LM(wi)

dependent until now. So far, the LM scorer could
only score their associated unigrams. However,
we also have their associated strings w′1 and w

′
2,

which can now be used. Since VAFIN and VVPP
now become parts of a single tree, we can perform
LM scoring normally. Assembling the string we
obtain

Offizielle Prognosen sind von nur 3 %
ausgegangen

which is scored by the LM. Thus, we first score
the 4-grams “Offizielle Prognosen sind von”, then
“Prognosen sind von nur”, etc.

5 Experiments

5.1 Setup

The baseline system for our experiments is the
syntax-based component of the Moses open-
source toolkit of Koehn et al. (2007) and Hoang
et al. (2009). We use linguistic syntactic anno-
tation on both the source and the target language
side (tree-to-tree). Our contrastive system is the
`MBOT-based translation system presented here.
We provide the system with a set of SCFG as well
as `MBOT rules. We do not impose any maximal
span restriction on either system.

The compared systems are evaluated on the
English-to-German13 news translation task of
WMT 2009 (Callison-Burch et al., 2009). For
both systems, the used training data is from the
4th version of the Europarl Corpus (Koehn, 2005)
and the News Commentary corpus. Both trans-
lation models were trained with approximately
1.5 million bilingual sentences after length-ratio
filtering. The word alignments were generated
by GIZA++ (Och and Ney, 2003) with the grow-
diag-final-and heuristic (Koehn et al., 2005). The

13Note that our `MBOT-based system can be applied to any
language pair as it involves no language-specific engineering.

System BLEU
Baseline 12.60
`MBOT ∗13.06

Moses t-to-s 12.72

Table 1: Evaluation results. The starred results
are statistically significant improvements over the
Baseline (at confidence p < 0.05).

English side of the bilingual data was parsed us-
ing the Charniak parser of Charniak and John-
son (2005), and the German side was parsed us-
ing BitPar (Schmid, 2004) without the function
and morphological annotations. Our German 4-
gram language model was trained on the Ger-
man sentences in the training data augmented
by the Stuttgart SdeWaC corpus (Web-as-Corpus
Consortium, 2008), whose generation is detailed
in (Baroni et al., 2009). The weights λm in the
log-linear model were trained using minimum er-
ror rate training (Och, 2003) with the News 2009
development set. Both systems use glue-rules,
which allow them to concatenate partial transla-
tions without performing any reordering.

5.2 Results

We measured the overall translation quality with
the help of 4-gram BLEU (Papineni et al., 2002),
which was computed on tokenized and lower-
cased data for both systems. The results of our
evaluation are reported in Table 1. For com-
parison, we also report the results obtained by
a system that utilizes parses only on the source
side (Moses tree-to-string) with its standard fea-
tures.

We can observe from Table 1 that our `MBOT-
based system outperforms the baseline. We ob-
tain a BLEU score of 13.06, which is a gain of
0.46 BLEU points over the baseline. This im-
provement is statistically significant at confidence
p < 0.05, which we computed using the pairwise
bootstrap resampling technique of Koehn (2004).
Our system is also better than the Moses tree-to-
string system. However this improvement (0.34)
is not statistically significant. In the next section,
we confirm the result of the automatic evaluation
through a manual examination of some transla-
tions generated by our system and the baseline.

In Table 2, we report the number of `MBOT
rules used by our system when decoding the test
set. By lex we denote rules containing only lexical

817



lex non-term total
contiguous 23,175 18,355 41,530

discontiguous 315 2,516 2,831

Table 2: Number of rules used in decoding test
(lex: only lexical items; non-term: at least one
nonterminal).

2-dis 3-dis 4-dis
2,480 323 28

Table 3: Number of k-discontiguous rules.

items. The label non-term stands for rules contain-
ing at least one leaf nonterminal. The results show
that approx. 6% of all rules used by our `MBOT-
system have discontiguous target sides. Further-
more, the reported numbers show that the system
also uses rules in which lexical items are com-
bined with nonterminals. Finally, Table 3 presents
the number of rules with k target side components
used during decoding.

5.3 Linguistic Analysis

In this section we present linguistic evidence sup-
porting the fact that the `MBOT-based system sig-
nificantly outperforms the baseline. All exam-
ples are taken from the translation of the test set
used for automatic evaluation. We show that when
our system generates better translations, this is di-
rectly related to the use of `MBOT rules.

Figures 8 and 9 show the ability of our system to
correctly reorder multiple segments in the source
sentence where the baseline translates those seg-
ments sequentially. An analysis of the generated
derivations shows that our system produces the
correct translation by taking advantage of rules
with discontiguous units on target language side.
The rules used in the presented derivations are dis-
played in Figures 10 and 11. In the first example
(Figure 8), we begin by translating “((smuggle)VB
(eight projectiles)NP (into the kingdom)PP)VP” into
the discontiguous sequence composed of (i) “(acht
geschosse)NP” ; (ii) “(in das königreich)PP” and
(iii) “(schmuggeln)VP”. In a second step we as-
semble all sequences in a rule with contiguous tar-
get language side and, at the same time, insert the
word “(zu)PTKZU” between “(in das königreich)PP”
and “(schmuggeln)VP”.

The second example (Figure 9) illustrates a
more complex reordering. First, we trans-

VP

VB NP PP
→
( NP

NP

,
PP

PP

,
VVINF

VVINF

)

S

TO VP
→
( VP

NP PP PTKZU VVINF

)

Figure 10: Used `MBOT rules for verbal reorder-
ing

VP

ADV commented on NP
→
( NP

NP

,
ADV

ADV

,
VPP

kommentiert

)

VP

VBZ VP
→
( NP

NP

,
VAFIN

VAFIN

,
ADV

ADV

,
VPP

VPP

)

TOP

NP VP
→
( TOP

NP VAFIN NP ADV VVPP

)

Figure 11: Used `MBOT rules for verbal reorder-
ing

late “((again)ADV commented on (the problem
of global warming)NP)VP” into the discontigu-
ous sequence composed of (i) “(das problem
der globalen erwärmung)NP”; (ii) “(wieder)ADV”
and (iii) “(kommentiert)VPP”. In a second step,
we translate the auxiliary “(has)VBZ” by in-
serting “(hat)VAFIN” into the sequence. We
thus obtain, for the input segment “((has)VBZ
(again)ADV commented on (the problem of global
warming)NP)VP”, the sequence (i) “(das problem
der globalen erwärmung)NP”; (ii) “(hat)VAFIN”;
(iii) “(wieder)ADV”; (iv) “(kommentiert)VVPP”. In
a last step, the constituent “(president václav
klaus)NP” is inserted between the discontiguous
units “(hat)VAFIN” and “(wieder)ADV” to form the
contiguous sequence “((das problem der glob-
alen erwärmung)NP (hat)VAFIN (präsident václav
klaus)NP (wieder)ADV (kommentiert)VVPP)TOP”.

Figures 12 and 13 show examples where our
system generates complex words in the target
language out of a simple source language word.
Again, an analysis of the generated derivation
shows that `MBOT takes advantage of rules hav-
ing several target side components. Examples of
such rules are given in Figure 14. Through its
ability to use these discontiguous rules, our sys-
tem correctly translates into reflexive or particle
verbs such as “konzentriert sich” (for the English
“focuses”) or “besteht darauf ” (for the English
“insist”). Another phenomenon well handled by
our system are relative pronouns. Pronouns such
as “that” or “whose” are systematically translated

818



. . . geplant hatten 8 geschosse in das königreich zu schmuggeln

. . . had planned to smuggle 8 projectiles into the kingdom

. . . vorhatten zu schmuggeln 8 geschosse in das königreich

Figure 8: Verbal Reordering (top: our system, bottom: baseline)

das problem der globalen erwärmung hat präsident václav klaus wieder kommentiert

president václav klaus has again commented on the problem of global warming

präsident václav klaus hat wieder kommentiert das problem der globalen erwärmung

Figure 9: Verbal Reordering (top: our system, bottom: baseline)

. . . die serbische delegation bestand darauf , dass jede entscheidung . . .

. . . the serbian delegation insisted that every decision . . .

. . . die serbische delegation bestand , jede entscheidung . . .

Figure 12: Relative Clause (top: our system, bot-
tom: baseline)

. . . die roadmap von bali , konzentriert sich auf die bemühungen . . .

. . . the bali roadmap that focuses on efforts . . .

. . . die bali roadmap , konzentriert auf bemühungen . . .

Figure 13: Reflexive Pronoun (top: our system,
bottom: baseline)

into both both, “,” and “dass” or “,” and “deren”
(Figure 12).

6 Conclusion and Future Work

We demonstrated that our `MBOT-based machine
translation system beats a standard tree-to-tree
system (Moses tree-to-tree) on the WMT 2009
translation task English → German. To achieve
this we implemented the formal model as de-
scribed in Section 2 inside the Moses machine
translation toolkit. Several modifications were
necessary to obtain a working system. We publicly
release all our developed software and our com-
plete tool-chain to allow independent experiments
and evaluation. This includes our `MBOT decoder

IN

that
→
( $,

,
,

KOUS

dass

) VBZ

focuses
→
( VVFIN

konzentriert

,
PRF

sich

)

Figure 14: `MBOT rules generating a relative
clause/reflexive pronoun

presented in Section 4 and a separate C++ module
that we use for rule extraction (see Section 3).

Besides the automatic evaluation, we also per-
formed a small manual analysis of obtained trans-
lations and show-cased some examples (see Sec-
tion 5.3). We argue that our `MBOT approach can
adequately handle discontiguous phrases, which
occur frequently in German. Other languages that
exhibit such phenomena include Czech, Dutch,
Russian, and Polish. Thus, we hope that our sys-
tem can also successfully be applied for other lan-
guage pairs, which we plan to pursue as well.

In other future work, we want to investigate
full backwards application of `MBOT rules, which
would be more suitable for the converse transla-
tion direction German→ English. The current in-
dependent LM scoring of components has some
negative side-effects that we plan to circumvent
with the use of lazy LM scoring.

Acknowledgement

The authors thank Alexander Fraser for his ongo-
ing support and advice. All authors were finan-
cially supported by the German Research Founda-
tion (DFG) grant MA 4959 / 1-1.

819



References
André Arnold and Max Dauchet. 1982. Morphismes

et bimorphismes d’arbres. Theoret. Comput. Sci.,
20(1):33–93.

Marco Baroni, Silvia Bernardini, Adriano Ferraresi,
and Eros Zanchetta. 2009. The WaCky Wide
Web: A collection of very large linguistically pro-
cessed web-crawled corpora. Language Resources
and Evaluation, 43(3):209–226.

Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Josh Schroeder. 2009. Findings of the 2009
Workshop on Statistical Machine Translation. In
Proc. 4th Workshop on Statistical Machine Trans-
lation, pages 1–28.

Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and MaxEnt discriminative
reranking. In Proc. 43rd ACL, pages 173–180.

David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computat. Linguist., 33(2):201–228.

David Chiang. 2010. Learning to translate with source
and target syntax. In Proc. 48th ACL, pages 1443–
1452.

Jason Eisner. 2003. Learning non-isomorphic tree
mappings for machine translation. In Proc. 41st
ACL, pages 205–208.

Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What’s in a translation rule?
In Proc. HLT-NAACL, pages 273–280.

Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve Deneefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Proc.
44th ACL, pages 961–968.

Hieu Hoang, Philipp Koehn, and Adam Lopez. 2009.
A unified framework for phrase-based, hierarchical,
and syntax-based statistical machine translation. In
Proc. 6th Int. Workshop Spoken Language Transla-
tion, pages 152–159.

Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proc. 7th Conf. Association
for Machine Translation of the Americas, pages 66–
73.

Philip Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proc.
HLT-NAACL, pages 127–133.

Philipp Koehn, Amittai Axelrod, Alexandra Birch
Mayne, Chris Callison-Burch, Miles Osborne, and
David Talbot. 2005. Edinburgh system description
for the 2005 IWSLT Speech Translation Evaluation.
In Proc. 2nd Int. Workshop Spoken Language Trans-
lation.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proc. ACL, pages 177–180.

Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proc. EMNLP,
pages 388–395.

Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proc. 10th Ma-
chine Translation Summit, pages 79–86.

Alon Lavie, Alok Parlikar, and Vamshi Ambati. 2008.
Syntax-driven learning of sub-sentential translation
equivalents and translation rules from parsed parallel
corpora. In Proc. 2nd ACL Workshop on Syntax and
Structure in Statistical Translation, pages 87–95.

Eric Lilin. 1978. Une généralisation des transducteurs
d’états finis d’arbres: les S-transducteurs. Thèse
3ème cycle, Université de Lille.

Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-
to-string alignment template for statistical machine
translation. In Proc. 44th ACL, pages 609–616.

Yang Liu, Yajuan Lü, and Qun Liu. 2009. Improving
tree-to-tree translation with packed forests. In Proc.
47th ACL, pages 558–566.

Andreas Maletti. 2010. Why synchronous tree sub-
stitution grammars? In Proc. HLT-NAACL, pages
876–884.

Andreas Maletti. 2011. How to train your multi
bottom-up tree transducer. In Proc. 49th ACL, pages
825–834.

Andreas Maletti. 2012. Every sensible extended top-
down tree transducer is a multi bottom-up tree trans-
ducer. In Proc. HLT-NAACL, pages 263–273.

Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computat. Linguist., 29(1):19–51.

Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proc. 41st ACL,
pages 160–167.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei
jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proc. 40th
ACL, pages 311–318.

Jean-Claude Raoult. 1997. Rational tree relations.
Bull. Belg. Math. Soc. Simon Stevin, 4(1):149–176.

Helmut Schmid. 2004. Efficient parsing of highly am-
biguous context-free grammars with bit vectors. In
Proc. 20th COLING, pages 162–168.

820



Jun Sun, Min Zhang, and Chew Lim Tan. 2009. A non-
contiguous tree sequence alignment-based model for
statistical machine translation. In Proc. 47th ACL,
pages 914–922.

Web-as-Corpus Consortium. 2008. SDeWaC — a 0.88
billion word corpus for german. Website: http:
//wacky.sslmit.unibo.it/doku.php.

Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computat. Linguist., 23(3):377–403.

Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li,
Chew Lim Tan, and Sheng Li. 2008a. A tree
sequence alignment-based tree-to-tree translation
model. In Proc. 46th ACL, pages 559–567.

Min Zhang, Hongfei Jiang, Haizhou Li, Aiti Aw, and
Sheng Li. 2008b. Grammar comparison study
for translational equivalence modeling and statis-
tical machine translation. In Proc. 22nd Inter-
national Conference on Computational Linguistics,
pages 1097–1104.

821


