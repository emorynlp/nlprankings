




































A general framework for information extraction using dynamic span graphs


Proceedings of NAACL-HLT 2019, pages 3036–3046
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

3036

A General Framework for Information Extraction
using Dynamic Span Graphs

Yi Luan† Dave Wadden† Luheng He‡ Amy Shah†
Mari Ostendorf† Hannaneh Hajishirzi†∗

†University of Washington
∗Allen Institute for Artificial Intelligence

‡Google AI Language
{luanyi, dwadden, amyshah, ostendor, hannaneh}@uw.edu

luheng@google.com

Abstract

We introduce a general framework for sev-
eral information extraction tasks that share
span representations using dynamically con-
structed span graphs. The graphs are con-
structed by selecting the most confident entity
spans and linking these nodes with confidence-
weighted relation types and coreferences. The
dynamic span graph allows coreference and re-
lation type confidences to propagate through
the graph to iteratively refine the span rep-
resentations. This is unlike previous multi-
task frameworks for information extraction in
which the only interaction between tasks is in
the shared first-layer LSTM. Our framework
significantly outperforms the state-of-the-art
on multiple information extraction tasks across
multiple datasets reflecting different domains.
We further observe that the span enumeration
approach is good at detecting nested span enti-
ties, with significant F1 score improvement on
the ACE dataset.1

1 Introduction

Most Information Extraction (IE) tasks require
identifying and categorizing phrase spans, some
of which might be nested. For example, entity
recognition involves assigning an entity label to
a phrase span. Relation Extraction (RE) involves
assigning a relation type between pairs of spans.
Coreference resolution groups spans referring to
the same entity into one cluster. Thus, we might
expect that knowledge learned from one task might
benefit another.

Most previous work in IE (e.g., (Nadeau and
Sekine, 2007; Chan and Roth, 2011)) employs a
pipeline approach, first detecting entities and then
using the detected entity spans for relation extrac-
tion and coreference resolution. To avoid cascading

1Code and pre-trained models are publicly available at
https://github.com/luanyi/DyGIE.

COREF

Tom’s car broke down as he arrived at Starbucks to meet Mike.                             

“This thing’s useless!” Tom exclaimed as it gave off smoke.                                

PER-SOC
PHYS

VEH

COREF

PER LOCPER PER

VEH PER VEH

PHYS

Figure 1: A text passage illustrating interactions be-
tween entities, relations and coreference links. Some
relation and coreference links are omitted.

errors introduced by pipeline-style systems, recent
work has focused on coupling different IE tasks as
in joint modeling of entities and relations (Miwa
and Bansal, 2016; Zhang et al., 2017), entities and
coreferences (Hajishirzi et al., 2013; Durrett and
Klein, 2014), joint inference (Singh et al., 2013)
or multi-task (entity/relation/coreference) learn-
ing (Luan et al., 2018a). These models mostly
rely on the first layer LSTM to share span repre-
sentations between different tasks and are usually
designed for specific domains.

In this paper, we introduce a general framework
Dynamic Graph IE (DYGIE) for coupling multiple
information extraction tasks through shared span
representations which are refined leveraging con-
textualized information from relations and coref-
erences. Our framework is effective in several do-
mains, demonstrating a benefit from incorporating
broader context learned from relation and corefer-
ence annotations.

Figure 1 shows an example illustrating the po-
tential benefits of entity, relation, and coreference
contexts. It is impossible to predict the entity la-
bels for This thing and it from within-sentence con-
text alone. However, the antecedent car strongly
suggests that these two entities have a VEH type.
Similarly, the fact that Tom is located at Starbucks
and Mike has a relation to Tom provides support for



3037

the fact that Mike is located at Starbucks.
DYGIE uses multi-task learning to identify en-

tities, relations, and coreferences through shared
span representations using dynamically constructed
span graphs. The nodes in the graph are dynam-
ically selected from a beam of highly-confident
mentions, and the edges are weighted according
to the confidence scores of relation types or coref-
erences. Unlike the multi-task method that only
shares span representations from the local con-
text (Luan et al., 2018a), our framework leverages
rich contextual span representations by propagat-
ing information through coreference and relation
links. Unlike previous BIO-based entity recogni-
tion systems (Collobert and Weston, 2008; Lample
et al., 2016; Ma and Hovy, 2016) that assign a text
span to at most one entity, our framework enumer-
ates and represents all possible spans to recognize
arbitrarily overlapping entities.

We evaluate DYGIE on several datasets span-
ning many domains (including news, scientific arti-
cles, and wet lab experimental protocols), achiev-
ing state-of-the-art performance across all tasks and
domains and demonstrating the value of coupling
related tasks to learn richer span representations.
For example, DYGIE achieves relative improve-
ments of 5.7% and 9.9% over state of the art on the
ACE05 entity and relation extraction tasks, and an
11.3% relative improvement on the ACE05 over-
lapping entity extraction task.

The contributions of this paper are threefold.
1) We introduce the dynamic span graph frame-
work as a method to propagate global contextual
information, making the code publicly available.
2) We demonstrate that our framework significantly
outperforms the state-of-the-art on joint entity and
relation detection tasks across four datasets: ACE
2004, ACE 2005, SciERC and the Wet Lab Proto-
col Corpus. 3) We further show that our approach
excels at detecting entities with overlapping spans,
achieving an improvement of up to 8 F1 points on
three benchmarks annotated with overlapped spans:
ACE 2004, ACE 2005 and GENIA.

2 Related Work

Previous studies have explored joint model-
ing (Miwa and Bansal, 2016; Zhang et al., 2017;
Singh et al., 2013; Yang and Mitchell, 2016)) and
multi-task learning (Peng and Dredze, 2015; Peng
et al., 2017; Luan et al., 2018a, 2017a) as methods
to share representational strength across related in-

formation extraction tasks. The most similar to
ours is the work in Luan et al. (2018a) that takes
a multi-task learning approach to entity, relation,
and coreference extraction. In this model, the dif-
ferent tasks share span representations that only
incorporate broader context indirectly via the gra-
dients passed back to the LSTM layer. In contrast,
DYGIE uses dynamic graph propagation to explic-
itly incorporate rich contextual information into the
span representations.

Entity recognition has commonly been cast as
a sequence labeling problem, and has benefited
substantially from the use of neural architectures
(Collobert et al., 2011; Lample et al., 2016; Ma and
Hovy, 2016; Luan et al., 2017b, 2018b). However,
most systems based on sequence labeling suffer
from an inability to extract entities with overlap-
ping spans. Recently Katiyar and Cardie (2018)
and Wang and Lu (2018) have presented methods
enabling neural models to extract overlapping enti-
ties, applying hypergraph-based representations on
top of sequence labeling systems. Our framework
offers an alternative approach, forgoing sequence
labeling entirely and simply considering all possi-
ble spans as candidate entities.

Neural graph-based models have achieved sig-
nificant improvements over traditional feature-
based approaches on several graph modeling tasks.
Knowledge graph completion (Yang et al., 2015;
Bordes et al., 2013) is one prominent example.
For relation extraction tasks, graphs have been
used primarily as a means to incorporate pipelined
features such as syntactic or discourse relations
(Peng et al., 2017; Song et al., 2018; Zhang et al.,
2018). Christopoulou et al. (2018) models all pos-
sible paths between entities as a graph, and refines
pair-wise embeddings by performing a walk on the
graph structure. All these previous works assume
that the nodes of the graph (i.e. the entity candi-
dates to be considered during relation extraction)
are predefined and fixed throughout the learning
process. On the other hand, our framework does
not require a fixed set of entity boundaries as an
input for graph construction. Motivated by state-of-
the-art span-based approaches to coreference res-
olution (Lee et al., 2017, 2018) and semantic role
labeling (He et al., 2018), the model uses a beam
pruning strategy to dynamically select high-quality
spans, and constructs a graph using the selected
spans as nodes.

Many state-of-the-art RE models rely upon



3038

domain-specific external syntactic tools to con-
struct dependency paths between the entities in
a sentence (Li and Ji, 2014; Xu et al., 2015; Miwa
and Bansal, 2016; Zhang et al., 2017). These sys-
tems suffer from cascading errors from these tools
and are hard to generalize to different domains.
To make the model more general, we combine
the multitask learning framework with ELMo em-
beddings (Peters et al., 2018) without relying on
external syntactic tools and risking the cascading
errors that accompany them, and improve the inter-
action between tasks through dynamic graph prop-
agation. While the performance of DyGIE benefits
from ELMo, it advances over some systems (Luan
et al., 2018a; Sanh et al., 2019) that also incorporate
ELMo. The analyses presented here give insights
into the benefits of joint modeling.

3 Model

Problem Definition The input is a document rep-
resented as a sequence of words D, from which we
derive S = {s1, . . . , sT }, the set of all possible
within-sentence word sequence spans (up to length
L) in the document. The output contains three
structures: the entity types E for all spans S, the
relationsR for all span pairs S×S within the same
sentence, and the coreference links C for all spans
in S across sentences. We consider two primary
tasks. First, Entity Recognition is the task of pre-
dicting the best entity type labels ei for each span
si. Second, Relation Extraction involves predicting
the best relation type rij for all span pairs (si, sj).
We provide additional supervision by also training
our model to perform a third, auxiliary task: Coref-
erence resolution. For this task we predict the best
antecedent ci for each span si.

Our Model We develop a general information
extraction framework (DYGIE) to identify and
classify entities, relations, and coreference in a
multi-task setup. DYGIE first enumerates all text
spans in each sentence, and computes a locally-
contextualized vector space representation of each
span. The model then employs a dynamic span
graph to incorporate global information into its
span representations, as follows. At each training
step, the model identifies the text spans that are
most likely to represent entities, and treats these
spans as nodes in a graph structure. It constructs
confidence-weighted arcs for each node according
to its predicted coreference and relation links with
the other nodes in the graph. Then, the span repre-

sentations are refined using broader context from
gated updates propagated from neighboring rela-
tion types and co-referred entities. These refined
span representations are used in a multi-task frame-
work to predict entity types, relation types, and
coreference links.

3.1 Model Architecture
In this section, we give an overview of the main
components and layers of the DYGIE framework,
as illustrated in Figure 2. Details of the graph con-
struction and refinement process will be presented
in the next section.

Token Representation Layer We apply a bidi-
rectional LSTM over the input tokens. The input
for each token is a concatenation of the character
reprensetation, GLoVe (Pennington et al., 2014)
word embeddings, and ELMo embeddings (Peters
et al., 2018). The output token representations are
obtained by stacking the forward and backward
LSTM hidden states.

Span Representation Layer For each span si,
its initial vector representation g0i is obtained by
concatenating BiLSTM outputs at the left and right
end points of si, an attention-based soft “head-
word,” and an embedded span width feature, fol-
lowing Lee et al. (2017).

Coreference Propagation Layer The propaga-
tion process starts from the span representations
g0i . At each iteration t, we first compute an update
vector utC for each span si. Then we use u

t
C to

update the current representation gti , producing the
next span representation gt+1i . By repeating this
process N times, the final span representations gNi
share contextual information across spans that are
likely to be antecedents in the coreference graph,
similar to the process in (Lee et al., 2018).

Relation Propagation Layer The outputs gNi
from the coreference propagation layer are passed
as inputs to the relation propagation layer. Similar
to the coreference propagation process, at each it-
eration t, we first compute the update vectors utR
for each span si, then use it to compute gt+1i . In-
formation can be integrated from multiple relation
paths by repeating this process M times.

Final Prediction Layer We use the outputs of
the relation graph layer gN+Mi to predict the entity
labels E and relation labels R. For entities, we
pass gN+Mi to a feed-forward network (FFNN) to



3039

arrive at StarbuckscarTom

Input document

Span 
enumeration

Final prediction 

of entities and 

relations

Coref.

Tom’s car broke down as he arrived at 
Starbucks to meet Mike.

“This thing’s useless!” Tom exclaimed 
as it gave off smoke.

Sentence-level BiLSTM Sentence-level BiLSTM

Tom car arrive at Starbucks Mike Tomthis thing it

Token 

representations

…

Coref.

car this thing it

Tom Mike Starbucks

PER-SOC PHYS

Mike Tomthis thing it …
PER VEH NULL

PHYS

VEH

Coref.

car this thing it

Final prediction 
of coreferenceIterative inference


and propagation 
for relations

Iterative inference 
and propagation 
for coreference

PER PER

PHYS

VEH

PER-SOC

PHYS Coref.

LOC

M times

… …

N times

…

Figure 2: Overview of our DYGIE model. Dotted arcs indicate confidence weighted graph edges. Solid lines
indicate the final predictions.

produce per-class scores PE(i) for span si. For
relations, we pass the concatenation of gN+Mi and
gN+Mj to a FFNN to produce per-class relation
scores PR(i, j) between spans si and sj . Entity
and relation scores are normalized across the label
space, similar to Luan et al. (2018a). For coref-
erence, the scores between span pairs (si, sj) are
computed from the coreference graph layer outputs
(gNi ,g

N
j ), and then normalized across all possible

antecedents, similar to Lee et al. (2018).

3.2 Dynamic Graph Construction and Span
Refinement

The dynamic span graph facilitates propagating
broader contexts through soft coreference and rela-
tion links to refine span representations. The nodes
in the graph are spans si with vector representa-
tions gti ∈ Rd for the t-th iteration. The edges are
weighted by the coreference and relation scores,
which are trained according to the neural archi-
tecture explained in Section 3.1. In this section,
we explain how coreference and relation links can
update span representations.

Coreference Propagation Similar to (Luan
et al., 2018a), we define a beam BC consisting
of bc spans that are most likely to be in a corefer-
ence chain. We consider PtC to be a matrix of real
values that indicate coreference confidence scores
between these spans at the t-th iteration. PtC is
of size bc × K, where K is the maximum num-
ber of antecedents considered. For the coreference

graph, an edge in the graph is single directional,
connecting the current span si with all its poten-
tial antecedents sj in the coreference beam, where
j < i. The edge between si and sj is weighted by
coreference confidence score at the current itera-
tion P tC(i, j). The span update vector u

t
C(i) ∈ Rd

is computed by aggregating the neighboring span
representations gtj , weighted by their coreference
scores P tC(i, j):

utC(i) =
∑

j∈BC(i)

P tC(i, j)g
t
j (1)

where BC(i) is the set of K spans that are an-
tecedents of si,

P tC(i, j) =
exp(V tC(i, j))∑

j′∈BC(i) exp(V
t
C(i, j))

(2)

V tC(i, j) is a scalar score computed by concate-
nating the span representations [gti,g

t
j ,g

t
i � gtj ],

where � is element-wise multiplication. The con-
catenated vector is then fed as input to a FFNN,
similar to (Lee et al., 2018).

Relation Propagation For each sentence, we
define a beam BR consisting of br entity spans
that are mostly likely to be involved in a rela-
tion. Unlike the coreference graph, the weights
of relation edges capture different relation types.
Therefore, for the t-th iteration, we use a tensor
VtR ∈ RbR×bR×LR to capture scores of each of the
LR relation types. In other words, each edge in the



3040

relation graph connects two entity spans si and sj
in the relation beam BR. VtR(i, j) is a LR-length
vector of relation scores, computed with a FFNN
with [gti,g

t
j ] as the input. The relation update vec-

tor utR(i) ∈ Rd is computed by aggregating neigh-
boring span representations on the relation graph:

utR(i) =
∑
j∈BR

f(VtR(i, j))AR � gtj , (3)

where AR ∈ RLR×d is a trainable linear projection
matrix, f is a non-linear function to select the most
important relations. Because only a small number
of entities in the relation beam are actually linked
to the target span, propagation among all possi-
ble span pairs would introduce too much noise to
the new representation. Therefore, we choose f
to be the ReLU function to remove the effect of
unlikely relations by setting the all negative rela-
tion scores to 0. Unlike coreference connections,
two spans linked via a relation are not expected
to have similar representations, so the matrix AR
helps to transform the embedding gtj according to
each relation type.

Updating Span Representations with Gating
To compute the span representations for the next
iteration t ∈ {1, . . . , N +M}, we define a gating
vector f tx(i) ∈ Rd, where x ∈ {C,R}, to deter-
mine whether to keep the previous span represen-
tation gti or to integrate new information from the
coreference or relation update vectors utx(i). For-
mally,

f tx(i) = g(W
f
x[g

t
i,u

t
x(i)]) (4)

gt+1i = f
t
x(i)� gti + (1− f tx(i))� utx(i),

where Wfx ∈ Rd×2d are trainable parameters, and
g is an element-wise sigmoid function.

3.3 Training
The loss function is defined as a weighted sum of
the log-likelihood of all three tasks:∑

(D,R∗,E∗,C∗)∈D

{
λE logP (E

∗ | C,R,D) (5)

+ λR logP (R
∗ | C,D) + λC logP (C∗ | D)

}
where E∗, R∗ and C∗ are gold structures of the
entity types, relations and coreference, respec-
tively. D is the collection of all training documents
D. The task weights λE, λR, and λC are hyper-
parameters to control the importance of each task.

Domain Docs Ent Rel Coref

ACE04 News 348 7 7 3
ACE05 News 511 7 6 7
SciERC AI 500 6 7 3
WLP Bio lab 622 18 13 7

Table 1: Datasets for joint entity and relation extraction
and their statistics. Ent: Number of entity categories.
Rel: Number of relation categories.

We use a 1 layer BiLSTM with 200-dimensional
hidden layers. All the feed-forward functions have
2 hidden layers of 150 dimensions each. We use 0.4
variational dropout (Gal and Ghahramani, 2016) for
the LSTMs, 0.4 dropout for the FFNNs, and 0.5
dropout for the input embeddings. The hidden layer
dimensions and dropout rates are chosen based on
the development set performance in multiple do-
mains. The task weights, learning rate, maximum
span length, number of propagation iterations and
beam size are tuned specifically for each dataset
using development data.

4 Experiments

DYGIE is a general IE framework that can be ap-
plied to multiple tasks. We evaluate the perfor-
mance of DYGIE against models from two lines of
work: combined entity and relation extraction, and
overlapping entity extraction.

4.1 Entity and relation extraction

For the entity and relation extraction task, we
test the performance of DYGIE on four different
datasets: ACE2004, ACE2005, SciERC and the
Wet Lab Protocol Corpus. We include the rela-
tion graph propagation layer in our models for all
datasets. We include the coreference graph propa-
gation layer on the data sets that have coreference
annotations available.

Data All four data sets are annotated with entity
and relation labels. Only a small fraction of entities
(< 3% of total) in these data sets have a text span
that overlaps the span of another entity. Statistics
on all four data sets are displayed in Table 1.

The ACE2004 and ACE2005 corpora provide
entity and relation labels for a collection of docu-
ments from a variety of domains, such as newswire
and online forums. We use the same entity and
relation types, data splits, and preprocessing as
Miwa and Bansal (2016) and Li and Ji (2014). Fol-
lowing the convention established in this line of
work, an entity prediction is considered correct



3041

Dataset System Entity Relation

ACE04
Bekoulis et al. (2018) 81.6 47.5
Miwa and Bansal (2016) 81.8 48.4
DYGIE 87.4 59.7

ACE05

Miwa and Bansal (2016) 83.4 55.6
Zhang et al. (2017) 83.6 57.5
Sanh et al. (2019) 87.5 62.7
DYGIE 88.4 63.2

SciERC Luan et al. (2018a) 64.2 39.3DYGIE 65.2 41.6

WLPC Kulkarni et al. (2018) 78.0 *54.9DYGIE 79.5 64.1

Table 2: F1 scores on the joint entity and relation ex-
traction task on each test set, compared against the pre-
vious best systems. * indicates relation extraction sys-
tem that takes gold entity boundary as input.

if its type label and head region match those of
a gold entity. We will refer to this version of
the ACE2004 and ACE2005 data as ACE04 and
ACE05. Since the domain and mention span an-
notations in the ACE datasets are very similar to
those of OntoNotes (Pradhan et al., 2012), and
OntoNotes contains significantly more documents
with coreference annotations, we use OntoNotes
to train the parameters for the auxiliary corefer-
ence task. The OntoNotes corpus contains 3493
documents, averaging roughly 450 words in length.

The SciERC corpus (Luan et al., 2018a) pro-
vides entity, coreference and relation annotations
for a collection of documents from 500 AI paper
abstracts. The dataset defines scientific term types
and relation types specially designed for AI domain
knowledge graph construction. An entity predic-
tion is considered correct if its label and span match
with a gold entity.

The Wet Lab Protocol Corpus (WLPC) pro-
vides entity, relation, and event annotations for 622
wet lab protocols (Kulkarni et al., 2018). A wet
lab protocol is a series of instructions specifying
how to perform a biological experiment. Following
the procedure in Kulkarni et al. (2018), we perform
entity recognition on the union of entity tags and
event trigger tags, and relation extraction on the
union of entity-entity relations and entity-trigger
event roles. Coreference annotations are not avail-
able for this dataset.

Baselines We compare DYGIE with current state
of the art methods in different datasets. Miwa and
Bansal (2016) provide the current state of the art
on ACE04. They construct a Tree LSTM using
dependency parse information, and use the repre-

sentations learned by the tree structure as features
for relation classification. Bekoulis et al. (2018)
use adversarial training as regularization for a neu-
ral model. Zhang et al. (2017) cast joint entity and
relation extraction as a table filling problem and
build a globally optimized neural model incorpo-
rating syntactic representations from a dependency
parser. Similar to DYGIE, Sanh et al. (2019) and
Luan et al. (2018a) use a multi-task learning frame-
work for extracting entity, relation and coreference
labels. Sanh et al. (2019) improved the state of
the art on ACE05 using multi-task, hierarchical
supervised training with a set of low level tasks
at the bottom layers of the model and more com-
plex tasks at the top layers of the model. Luan
et al. (2018a) previously achieved the state of the
art on SciERC and use a span-based neural model
like our DYGIE. Kulkarni et al. (2018) provide
a baseline for the WLPC data set. They employ
an LSTM-CRF for entity recognition, following
Lample et al. (2016). For relation extraction, they
assume the presence of gold entities and train a
maximum-entropy classifier using features from
the labeled entities.

Results Table 2 shows test set F1 on the joint
entity and relation extraction task. We observe that
DYGIE achieves substantial improvements on both
entity recognition and relation extraction across the
four data sets and three domains, all in the realistic
setting where no “gold” entity labels are supplied
at test time. DYGIE achieves 7.1% and 7.0% rela-
tive improvements over the state of the art on NER
for ACE04 and ACE05, respectively. For the rela-
tion extraction task, DYGIE attains 25.8% relative
improvement over SOTA on ACE04 and 13.7% rel-
ative improvement on ACE05. For ACE05, the best
entity extraction performance is obtained by switch-
ing the order between CorefProp and RelProp
(RelProp first then CorefProp).

On SciERC, DYGIE advances the state of the
art by 5.9% and 1.9% for relation extraction and
NER, respectively. The improvement of DYGIE
over the previous SciERC model underscores the
ability of coreference and relation propagation to
construct rich contextualized representations.

The results from Kulkarni et al. (2018) estab-
lish a baseline for IE on the WLPC. In that work,
relation extraction is performed using gold entity
boundaries as input. Without using any gold entity
information, DYGIE improves on the baselines by
16.8% for relation extraction and 2.2% for NER.



3042

Domain Docs Ent Overlap Coref

ACE04-O News 443 7 42% 3
ACE05-O News 437 7 32% 7
GENIA Biomed 1999 5 24% 3

Table 3: Datasets for overlapping entity extraction and
their statistics. Ent: Number of entity categories. Over-
lap: Percentage of sentences that contain overlapping
entities.

On the OntoNotes data set used for the auxiliary
coreference task with ACE05, our model achieves
coreference test set performance of 70.4 F1, which
is competitive with the state-of-the-art performance
reported in Lee et al. (2017).

4.2 Overlapping Entity Extraction

There are many applications where the correct iden-
tification of overlapping entities is crucial for cor-
rect document understanding. For instance, in the
biomedical domain, a BRCA1 mutation carrier
could refer to a patient taking part in a clinical
trial, while BRCA1 is the name of a gene.

We evaluate the performance of DYGIE on
overlapping entity extraction in three datasets:
ACE2004, ACE2005 and GENIA. Since relation
annotations are not available for these datasets, we
include the coreference propagation layer in our
models but not the relation layer.2

Data Statistics on our three datasets are listed
in Table 3. All three have a substantial number
(> 20% of total) of overlapping entities, making
them appropriate for this task.

As in the joint case, we evaluate our model on
ACE2004 and ACE2005, but here we follow the
same data preprocessing and evaluation scheme as
Wang and Lu (2018). We refer to these data sets
as ACE04-O and ACE05-O. Unlike the joint en-
tity and relation task in Sec. 4.1, where only the
entity head span need be predicted, an entity pre-
diction is considered correct in these experiments
if both its entity label and its full text span match
a gold prediction. This is a more stringent evalua-
tion criterion than the one used in Section 4.1. As
before, we use the OntoNotes annotations to train
the parameters of the coreference layer.

The GENIA corpus (Kim et al., 2003) provides
entity tags and coreferences for 1999 abstracts from
the biomedical research literature. We only use
the IDENT label to extract coreference clusters.

2We use the pre-processed ACE dataset from previous
work and relation annotation is not available.

Dataset System Entity F1

ACE04-O
Katiyar and Cardie (2018) 72.7
Wang and Lu (2018) 75.1
DYGIE 84.7

ACE05-O
Katiyar and Cardie (2018) 70.5
Wang and Lu (2018) 74.5
DYGIE 82.9

GENIA
Katiyar and Cardie (2018) 73.8
Wang and Lu (2018) 75.1
DYGIE 76.2

Table 4: Performance on the overlapping entity extrac-
tion task, compared to previous best systems. We re-
port F1 of extracted entities on the test sets.

Entity Relation

Model P R F1 P R F1

DYGIE 87.4 86.7 87.1 56.2 60.9 58.4
−CorefProp 86.2 85.2 85.7 64.3 56.7 60.2
−RelProp 87.0 86.7 86.9 60.4 55.8 58.0
Base 86.1 85.7 85.9 59.5 55.7 57.6

Table 5: Ablations on the ACE05 development set with
different graph propagation setups. −CorefProp
ablates the coreference propagation layers, while
−RelProp ablates the relation propagation layers.
Base is the system without any propagation.

We use the same data set split and preprocessing
procedure as Wang and Lu (2018) for overlapping
entity recognition.

Baselines The current state-of-the-art approach
on all three data sets is Wang and Lu (2018), which
uses a segmental hypergraph coupled with neural
networks for feature learning. Katiyar and Cardie
(2018) also propose a hypergraph approach using a
recurrent neural network as a feature extractor.

Results Table 4 presents the results of our over-
lapping entity extraction experiments on the differ-
ent datsets. DYGIE improves 11.6% on the state of
the art for ACE04-O and 11.3% for ACE05-O. DY-
GIE also advances the state of the art on GENIA,
albeit by a more modest 1.5%. Together these re-
sults suggest that DYGIE can be utilized fruitfully
for information extraction across different domains
with overlapped entities, such as bio-medicine.

5 Analysis of Graph Propagation

We use the dev sets of ACE2005 and SciERC to
analyze the effect of different model components.

5.1 Coreference and Relation Graph Layers

Tables 5 and 6 show the effects of graph propa-
gation on entity and relation prediction accuracy,



3043

Entity Relation

Model P R F1 P R F1

DYGIE 68.6 67.8 68.2 46.2 38.5 42.0
−CorefProp 69.2 66.9 68.0 42.0 40.5 41.2
−RelProp 69.1 66.0 67.5 43.6 37.6 40.4
Base 70.0 66.3 68.1 45.4 34.9 39.5

Table 6: Ablations on the SciERC development set on
different graph progation setups. CorefProp has a
much smaller effect on entity F1 compared to ACE05.

0 1 2 3
80

82

84

86

88

90

Num. iterations N

E
nt

ity
F1

(a) Entity F1 with different
number of CorefProp it-
erations N .

0 1 2 3
54

56

58

60

62

64

Num. iterations M

R
el

at
io

n
F1

(b) Relation F1 with differ-
ent number of RelProp it-
erations M .

Figure 3: F1 score of each layer on ACE development
set for different number of iterations. N = 0 or M = 0
indicates no propagation is made for the layer.

where −CorefProp and −RelProp denote ab-
lating the propagation process by setting N = 0
or M = 0, respectively. Base is the base model
without any propagation. For ACE05, we observe
that coreference propagation is mainly helpful for
entities; it appears to hurt relation extraction. On
SciIE, coreference propagation gives a small ben-
efit on both tasks. Relation propagation signifi-
cantly benefits both entity and relation extraction
in both domains. In particular, there are a large por-
tion of sentences with multiple relation instances
across different entities in both ACE05 and Sci-
ERC, which is the scenario in which we expect
relation propagation to help.

Since coreference propagation has more effect
on entity extraction and relation propagation has
more effect on relation extraction, we mainly focus
on ablating the effect of coreference propagation
on entity extraction and relation propagation on
relation extraction in the following subsections.

5.2 Coreference Propagation and Entities

A major challenge of ACE05 is to disambiguate
the entity class for pronominal mentions, which
requires reasoning with cross-sentence contexts.
For example, in a sentence from ACE05 dataset,
“One of [them]PER, from a very close friend of
[ours]ORG.” It is impossible to identity whether
them and ours is a person (PER) or organization
(ORG) unless we have read previous sentences. We

Entity Perf. on Pronouns P R F1

DYGIE 79.0 77.1 78.0
DYGIE−CorefProp 73.8 72.6 73.2

Table 7: Entity extraction performance on pronouns in
ACE05. CorefProp significantly increases entity ex-
traction F1 on hard-to-disambiguate pronouns by allow-
ing the model to leverage cross-sentence contexts.

hypothesize that this is a context where coreference
propagation can help. Table 7 shows the effect
of the coreference layer for entity categorization
of pronouns.3 DYGIE has 6.6% improvement on
pronoun performance, confirming our hypothesis.

Looking further, Table 8 shows the impact on all
entity categories, giving the difference between
the confusion matrix entries with and without
CorefProp. The frequent confusions associated
with pronouns (GPE/PER and PER/ORG, where
GPE is a geopolitical entity) greatly improve, but
the benefit of CorefProp extends to most cate-
gories.

Of course, there are a few instances where
CorefProp causes errors in entity extraction. For
example, in the sentence “[They]ORGPER might have
been using Northshore...”, DYGIE predicted They
to be of ORG type because the most confident an-
tecedent is those companies in the previous sen-
tence: “The money was invested in those compa-
nies.” However, They is actually referring to these
fund managers earlier in the document, which be-
longs to PER category.

In the SciERC dataset, the pronouns are uni-
formly assigned with a Generic label, which ex-
plains why CorefProp does not have much ef-
fect on entity extraction performance.

The Figure 3a shows the effect of number of
iterations for coreference propagation in the entity
extraction task. The figure shows that coreference
layer obtains the best performance on the second
iteration (N = 2).

5.3 Relation Propagation Impact

Figure 4 shows relation scores as a function of num-
ber of entities in sentence for DYGIE and DYGIE
without relation propagation on ACE05. The figure
indicates that relation propagation achieves signifi-
cant improvement in sentences with more entities,
where one might expect that using broader context

3Pronouns included: anyone, everyone, it,
itself, one, our, ours, their, theirs,
them, themselves, they, us, we, who



3044

LOC WEA GPE PER FAC ORG VEH
LOC 5 0 -2 -1 2 -1 0
WEA 0 3 0 0 1 -3 -1
GPE -3 0 31 -26 3 -7 0
PER 0 -2 -3 18 -1 -26 4
FAC 4 -1 2 -3 2 -5 1
ORG 0 0 0 -8 -1 6 0
VEH 0 -2 -1 2 5 -1 1

Table 8: Difference in the confusion matrix counts
for ACE05 entity extraction associated with adding
CorefProp.

2 3 4-5 6-11 12-max

50

60

70

Num. entities in sentence

R
el

at
io

n
F1

DYGIE
DYGIE−RelProp

Figure 4: Relation F1 broken down by number of enti-
ties in each sentence. The performance of relation ex-
traction degrades on sentences containing more entities.
Adding relation propagation alleviates this problem.

could have more impact.
Figure 3b shows the effect of number of itera-

tions for relation propagation in the relation extrac-
tion task. Our model achieves the best performance
on the second iteration (M = 2).

6 Conclusion

We have introduced DYGIE as a general informa-
tion extraction framework, and have demonstrated
that our system achieves state-of-the art results
on entity recognition and relation extraction tasks
across a diverse range of domains. The key con-
tribution of our model is the dynamic span graph
approach, which enhance interaction across tasks
that allows the model to learn useful information
from broader context. Unlike many IE frameworks,
our model does not require any preprocessing using
syntactic tools, and has significant improvement
across different IE tasks including entity, relation
extraction and overlapping entity extraction. The
addition of co-reference and relation propagation
across sentences adds only a small computation
cost to inference; the memory cost is controlled by
beam search. These added costs are small relative
to those of the baseline span-based model. We wel-
come the community to test our model on different
information extraction tasks. Future directions in-
clude extending the framework to encompass more
structural IE tasks such as event extraction.

Acknowledgments
This research was supported by the Office of Naval
Research under the MURI grant N00014-18-1-
2670, NSF (IIS 1616112, III 1703166), Allen Dis-
tinguished Investigator Award, Samsung GRO and
gifts from Allen Institute for AI, Google, Amazon,
and Bloomberg. We also thank the anonymous re-
viewers and the UW-NLP group for their helpful
comments.

References
Giannis Bekoulis, Johannes Deleu, Thomas Demeester,

and Chris Develder. 2018. Adversarial training for
multi-context joint entity and relation extraction. In
Proc. Conf. Empirical Methods Natural Language
Process. (EMNLP), pages 2830–2836.

Antoine Bordes, Nicolas Usunier, Alberto Garcia-
Duran, Jason Weston, and Oksana Yakhnenko.
2013. Translating embeddings for modeling multi-
relational data. In Advances in neural information
processing systems.

Yee Seng Chan and Dan Roth. 2011. Exploiting
syntactico-semantic structures for relation extrac-
tion. In Proc. Annu. Meeting Assoc. for Computa-
tional Linguistics (ACL).

Fenia Christopoulou, Makoto Miwa, and Sophia Ana-
niadou. 2018. A walk-based model on entity graphs
for relation extraction. In Proc. Annu. Meeting As-
soc. for Computational Linguistics (ACL), volume 2,
pages 81–88.

Ronan Collobert and Jason Weston. 2008. A unified
architecture for natural language processing: Deep
neural networks with multitask learning. In Proc.
Int. Conf. Machine Learning (ICML), pages 160–
167.

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011.
Natural language processing (almost) from scratch.
J. Machine Learning Research, 12(Aug):2493–
2537.

Greg Durrett and Dan Klein. 2014. A joint model
for entity analysis: Coreference, typing, and linking.
Trans. Assoc. for Computational Linguistics (TACL),
2:477–490.

Yarin Gal and Zoubin Ghahramani. 2016. A theoret-
ically grounded application of dropout in recurrent
neural networks. In Proc. Annu. Conf. Neural In-
form. Process. Syst. (NIPS).

Hannaneh Hajishirzi, Leila Zilles, Daniel S Weld, and
Luke Zettlemoyer. 2013. Joint coreference res-
olution and named-entity linking with multi-pass
sieves. In Proc. Conf. Empirical Methods Natural
Language Process. (EMNLP), pages 289–299.



3045

Luheng He, Kenton Lee, Omer Levy, and Luke Zettle-
moyer. 2018. Jointly predicting predicates and argu-
ments in neural semantic role labeling. In ACL.

Arzoo Katiyar and Claire Cardie. 2018. Nested
named entity recognition revisited. In Proc. Conf.
North American Assoc. for Computational Linguis-
tics (NAACL).

Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and
Jun’ichi Tsujii. 2003. Genia corpus - a semantically
annotated corpus for bio-textmining. Bioinformat-
ics, 19 Suppl 1:i180–2.

Chaitanya Kulkarni, Wei Xu, Alan Ritter, and Raghu
Machiraju. 2018. An annotated corpus for machine
reading of instructions in wet lab protocols. In
NAACL-HLT.

Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
ramanian, Kazuya Kawakami, and Chris Dyer. 2016.
Neural architectures for named entity recognition.
In Proc. Conf. North American Assoc. for Compu-
tational Linguistics (NAACL).

Kenton Lee, Luheng He, Mike Lewis, and Luke S.
Zettlemoyer. 2017. End-to-end neural coreference
resolution. In EMNLP.

Kenton Lee, Luheng He, and Luke Zettlemoyer. 2018.
Higher-order coreference resolution with coarse-to-
fine inference. In NAACL.

Qi Li and Heng Ji. 2014. Incremental joint extrac-
tion of entity mentions and relations. In Proc.
Annu. Meeting Assoc. for Computational Linguistics
(ACL), volume 1, pages 402–412.

Yi Luan, Chris Brockett, Bill Dolan, Jianfeng Gao,
and Michel Galley. 2017a. Multi-task learning for
speaker-role adaptation in neural conversation mod-
els. In Proc. IJCNLP.

Yi Luan, Luheng He, Mari Ostendorf, and Hannaneh
Hajishirzi. 2018a. Multi-task identification of enti-
ties, relations, and coreference for scientific knowl-
edge graph construction. In Proc. Conf. Empirical
Methods Natural Language Process. (EMNLP).

Yi Luan, Mari Ostendorf, and Hannaneh Hajishirzi.
2017b. Scientific information extraction with semi-
supervised neural tagging. In Proc. Conf. Empirical
Methods Natural Language Process. (EMNLP).

Yi Luan, Mari Ostendorf, and Hannaneh Hajishirzi.
2018b. The uwnlp system at semeval-2018 task 7:
Neural relation extraction model with selectively in-
corporated concept embeddings. In Proc. Int. Work-
shop on Semantic Evaluation (SemEval), pages 788–
792.

Xuezhe Ma and Eduard Hovy. 2016. End-to-end
sequence labeling via bi-directional LSTM-CNNs-
CRF. In Proc. Annu. Meeting Assoc. for Computa-
tional Linguistics (ACL).

Makoto Miwa and Mohit Bansal. 2016. End-to-end re-
lation extraction using lstms on sequences and tree
structures. In Proc. Annu. Meeting Assoc. for Com-
putational Linguistics (ACL), pages 1105–1116.

David Nadeau and Satoshi Sekine. 2007. A survey of
named entity recognition and classification. Lingvis-
ticae Investigationes, 30(1):3–26.

Nanyun Peng and Mark Dredze. 2015. Named en-
tity recognition for chinese social media with jointly
trained embeddings. In Proc. Conf. Empirical Meth-
ods Natural Language Process. (EMNLP), pages
548–554.

Nanyun Peng, Hoifung Poon, Chris Quirk, Kristina
Toutanova, and Wen-tau Yih. 2017. Cross-sentence
n-ary relation extraction with graph lstms. Trans. As-
soc. for Computational Linguistics (TACL), 5:101–
115.

Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. Glove: Global vectors for word rep-
resentation. In Proc. Conf. Empirical Methods Natu-
ral Language Process. (EMNLP), volume 14, pages
1532–1543.

Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt
Gardner, Christopher Clark, Kenton Lee, and Luke
Zettlemoyer. 2018. Deep contextualized word repre-
sentations. In NAACL.

Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
Olga Uryupina, and Yuchen Zhang. 2012. Conll-
2012 shared task: Modeling multilingual unre-
stricted coreference in ontonotes. In Joint Confer-
ence on EMNLP and CoNLL-Shared Task, pages 1–
40. Association for Computational Linguistics.

Victor Sanh, Thomas Wolf, and Sebastian Ruder. 2019.
A hierarchical multi-task approach for learning em-
beddings from semantic tasks. AAAI.

Sameer Singh, Sebastian Riedel, Brian Martin, Jiaping
Zheng, and Andrew McCallum. 2013. Joint infer-
ence of entities, relations, and coreference. In Proc.
of the 2013 workshop on Automated knowledge base
construction, pages 1–6. ACM.

Linfeng Song, Yue Zhang, Zhiguo Wang, and Daniel
Gildea. 2018. N-ary relation extraction using graph-
state lstm. In Proc. Conf. Empirical Methods Natu-
ral Language Process. (EMNLP), pages 2226–2235.

Bailin Wang and Wei Lu. 2018. Neural segmental hy-
pergraphs for overlapping mention recognition. In
EMNLP.

Kun Xu, Yansong Feng, Songfang Huang, and
Dongyan Zhao. 2015. Semantic relation classifica-
tion via convolutional neural networks with simple
negative sampling. In Proc. Conf. Empirical Meth-
ods Natural Language Process. (EMNLP), pages
536–540.



3046

Bishan Yang and Tom M Mitchell. 2016. Joint extrac-
tion of events and entities within a document context.
In Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 289–299.

Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng
Gao, and Li Deng. 2015. Embedding entities and
relations for learning and inference in knowledge
bases. In Proc. Int. Conf. Learning Representations
(ICLR).

Meishan Zhang, Yue Zhang, and Guohong Fu. 2017.
End-to-end neural relation extraction with global op-
timization. In Proc. Conf. Empirical Methods Natu-
ral Language Process. (EMNLP), pages 1730–1740.

Yuhao Zhang, Peng Qi, and Christopher D Man-
ning. 2018. Graph convolution over pruned depen-
dency trees improves relation extraction. In Proc.
Conf. Empirical Methods Natural Language Pro-
cess. (EMNLP).


