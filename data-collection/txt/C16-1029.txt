



















































Consistent Word Segmentation, Part-of-Speech Tagging and Dependency Labelling Annotation for Chinese Language


Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers,
pages 298â€“308, Osaka, Japan, December 11-17 2016.

Consistent Word Segmentation, Part-of-Speech Tagging and 

Dependency Labelling Annotation for Chinese Language 

 Mo Shen
1, Wingmui Li2, Hyunjeong Choe1, Chenhui Chu3,  

Daisuke Kawahara4, Sadao Kurohashi4 
1 Google Inc., California, USA 

2 The Chinese University of Hong Kong, Shatin, Hong Kong 
3 Japan Science and Technology Agency 

4 Graduate School of Informatics, Kyoto University, Kyoto, Japan 

{moshen|wjli|hyunjeongc}@google.com, 

chu@pa.jst.jp, {dk|kuro}@i.kyoto-u.ac.jp 

 

Abstract 

In this paper, we propose a new annotation approach to Chinese word segmentation, part-of-

speech (POS) tagging and dependency labelling that aims to overcome the two major issues in 

traditional morphology-based annotation: Inconsistency and data sparsity. We re-annotate the 

Penn Chinese Treebank 5.0 (CTB5) and demonstrate the advantages of this approach compared 

to the original CTB5 annotation through word segmentation, POS tagging and machine transla-

tion experiments. 

1 Introduction 

The definition of â€œwordâ€ is an open problem in Chinese linguistics. In previous studies of Chinese cor-

pus annotation (Duan et al., 2003; Huang et al., 1997; Xia, 2000), the judgement of word-hood of a 

meaningful string is based on the analysis of morphology: A morpheme in Chinese is defined as the 

smallest combination of meaning and phonetic sound in Chinese language, which can be classified into 

two major types: 

1). Free morphemes, which can either be words by themselves or form words with other morphemes; 

and 

2). Bound morphemes, which can only form words by attaching to other morphemes. 

An issue with word definition using morpheme classification is that, it potentially undermines the 

consistency of the representation of words. For example, â€œè®ºâ€ (theory) is a bound morpheme, therefore 

the string â€œè¿›åŒ–è®ºâ€ (theory of evolution) is treated as a word; on the other hand the string â€œè¿›åŒ– | ç†è®ºâ€ 
(theory of evolution) are treated as two words, despite the fact that the two strings have the same mean-

ing and structure. In another example, â€œè€…â€ (person) is considered as a bound morpheme, therefore â€œå

å¯¹è‡ªç”±è´¸æ˜“è€…â€ (people who are against free trade) is treated as one word, while the string without the 

bound morpheme, i.e. â€œåå¯¹ | è‡ªç”± | è´¸æ˜“â€ (be against free trade), can only be treated as a phrase of 
three words.  

The morphology-based word definition can also make the data sparsity problem worse in corpus an-

notation. As an evidence, in the Penn Chinese Treebank 5.0 (CTB5) which is an annotated corpus widely 

used to train Chinese morphological analysis systems, we found that one of the major sources of the 

out-of-vocabulary (OOV) words is the compounds that end with a monosyllabic bound morpheme. For 

example, compounds åˆ©ç”¨ç‡ (utility rate) and æ¬¡å“ç‡ (rate of defective product) end with the bound 

morpheme ç‡ (rate); å®Œæˆåº¦ (degree of completion) and æ´»è·ƒåº¦ (degree of activity) end with the bound 

morpheme åº¦ (degree); æŒç»­æ€§ (sustainability) and æŒ¥å‘æ€§ (property of volatile) end with the bound 

morpheme æ€§ (property). While these compounds are sparse in the corpus, the morphemes which they  
 

 

This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details:  

http://creativecommons.org/licenses/by/4.0/ 

298



POS Pattern Example 

pronoun + noun æˆ‘æ ¡ (this university)  

locative + noun åé—¨ (back door) 

locative + verb å‰è¿° (described above)  

noun + locative å®¤å†… (indoor)  

pronoun + locative æ­¤å¤– (besides)  

adverb + verb çŒæ­» (sudden death) 

noun + noun å‚æˆ¿ (factory plant) 

noun + measure è½¦è¾† (vehicles) 

adjective + noun ä½³é…¿ (wines) 

adjective + measure é«˜å±‚ (high level) 

verb + verb æŠ½å– (extract) 

verb + particle å†™å®Œ (finish writing) 

verb + adjective æ‰“ç¢ (break) 

verb + locative ç»¼ä¸Š (accordingly) 

verb + noun è¾èŒ (resign) 

adjective + adjective ä¼˜é›… (elegant) 

adverb + adjective æœ€æ–° (latest) 

determiner + noun å„ç•Œ (all walks of life) 

determiner + temporal ç¿Œæ—¥ (the next day)  

Table 1. Disyllabic character-level POS patterns. 

 

CTB5 Example Re-annotation 

å‰¯ä¸»å¸­/NN (vice president) å‰¯/JJ (vice) ä¸»å¸­/NN (president) 

é€æ˜åº¦/NN (transparency) é€æ˜/JJ (transparent) åº¦/SFN (degree) 

éç”Ÿäº§æ€§/NN (unproductiveness) é/JJ (none) ç”Ÿäº§/VV (produce) æ€§/SFN (property) 

ä¸­å¤®é›†æƒå¼/JJ (politically centralized) ä¸­å¤®/NN (center) é›†æƒ/NN (centralization) å¼/SFA (type) 

Table 2. Some examples of the word and POS annotation in the original CTB5 and our re-annotation. 

 

consist of can be frequently observed; this means these OOV words can be observed and learnt by a 

word segmenter if we split the morphemes as individual words in the annotation. 

In this paper, we propose a simple annotation approach for Chinese word segmentation that over-

comes the two issues: inconsistency and data sparsity, which are found in the traditional morphology-

based annotation approach. We further propose a tagset for part-of-speech tagging and a label set for 

dependency labelling, which are consistent with our word segmentation strategy and capture more Chi-

nese-specific syntactic structures. We re-annotate the entire CTB5 using this approach, and through 

word segmentation, POS tagging and machine translation experiments we demonstrate the advantages 

of our annotation approach compared to the original approach adopted in CTB5. 

The remainder of this paper is organized as follows: in section 2 we will describe our proposed anno-

tation approach to word segmentation; in section 3 we will present a POS tagset which is consistent with 

our word segmentation strategy and a new dependency label set; in section 4 we will demonstrate the 

effectiveness of our approach compared to the original CTB5 through experiments; we will conclude 

our work in the last section.  

2 Word Segmentation Annotation 

We categorize the words in CTB5 into three categories: Common words, names, and idioms. For names 

and idioms, we keep them as individual words since their word boundaries are relatively easy to recog-

nize and the consistency in manual annotation can be achieved with less efforts. We will mainly focus 

on describing the treatments of common words in this section. 

299



Tag Description Count in CTB5 Proposed annotation 

NN Noun 134,321 137,816 

PU Punctuation 75,794 75,935 

VV Verb 68,789 75,033 

AD Adverb 36,122 35,922 

NR Proper Noun 29,804 30,985 

P Preposition 17,280 17,721 

CD Cardinal Number 16,030 21,493 

M Measure Word 13,668 18,091 

JJ Adjective 12,979 13,898 

DEC Complementizer 12,310 12,346 

DEG Genitive Marker 12,145 12,145 

NT Temporal Noun 9,467 4,524 

LC Locative 7,676 0 

VA Predicative Adjective 7,630 7,518 

CC Coordinating Conjunction 7,137 7,134 

PN Pronoun 6,536 6,646 

DT Determiner 5,901 5,970 

VC Copula 5,338 5,521 

AS Aspect Particle 4,027 4,033 

VE â€œyou3â€ (â€œhaveâ€) 2,980 2,980 

OD Ordinal Number 1,661 1,661 

MSP Other Particles 1,316 1,316 

ETC â€œdeng3â€ (â€œetc.â€) 1,287 0 

CS Subordinating Conjunction 888 888 

BA Causative Auxiliary 751 756 

DEV Manner Marker 621 627 

SP Sentence-final Particle 466 466 

SB Short Passive Auxiliary 451 451 

DER Resultative Marker 258 258 

LB Long Passive Auxiliary 245 245 

FW Foreign Word 33 391 

IJ Interjection 12 17 

X Unknown 6 6 

SFN* Nominal Suffix 0 13,212 

SFA* Adjectival Suffix 0 438 

SFV* Verbal Suffix 0 129 

Table 3. Proposed tagset for part-of-speech tagging. The underlined characters in the examples cor-

respond to the tags on the left-most column. The CTB POS are also shown. 

 

The key in our method to define the boundaries of common words is the character-level POS pattern. 

Character-level POS has been introduced in previous studies (Zhang et al., 2013; Shen et al., 2014) 

which captures the grammatical roles of Chinese characters inside words; we further develop this idea 

and use it as a criterion in word definition. 

We treat a meaningful disyllabic strings as a word if it falls into one of the character-level POS pat-

terns listed in Table 1. The reason we focus on disyllabic patterns instead of other polysyllabic ones is 

that, based on our observation, meaningful strings with 3 or more syllables (other than names and idi-

oms) are always compounds in Chinese, and therefore can be segmented into a sequence of monosyl-

labic and disyllabic tokens based on their internal structures. On the other hand, the internal structure in 

a disyllabic token, though still exists, is more implicit and harder to describe with syntactical relations; 

we believe that it would increase the difficulties for subsequent tasks, such as dependency parsing, if we 

further segment these disyllabic strings. 

300



Following this strategy, a polysyllabic word can be then segmented based on its structure. This is 

illustrated with examples in Table 2. 

3 Part-of-Speech and Dependency Label Set 

To perform POS tagging re-annotation on CTB5 together with our proposed word segmentation ap-

proach, we use a POS tagset which is derived from the one used in the original CTB5 annotation. We 

show the tagset in Table 3 with comparison of number of occurrences of each tag in the original CTB5 

and the re-annotated version, respectively. The tagset introduces several changes: First, we eliminate 

the use of the â€œLCâ€ tag for locative words. This tag is assigned to all words that indicate locations and 

directions, such as ä¸Š (up), ä¸‹(down), å·¦ (left), å³ (right), å†… (inside), å¤– (outside) etc.. We instead tag 
these words based on their real syntactic roles in sentences, such as â€œNNâ€ (noun), â€œADâ€ (adverb) or 

â€œVVâ€ (verb). Second, we add three new tags into the tagset for suffixes: â€œSFNâ€ (nominal suffix), â€œSFAâ€ 

(adjectival suffix), and â€œSFVâ€ (verbal suffix). These tags are given to monosyllabic tokens appearing at 

the end of compounds, which are the bound morphemes in the traditional view. Based on our observation, 

these tokens have the ability to determine the syntactic role of the entire compound. For example, any 

compound that end with a nominal suffix â€œåº¦â€ (degree) always act as nouns in a sentence. It should be 
noted that because of this characteristic of suffixes, we can tag the children of suffixes in compounds 

based on their meaning but not their syntactic roles. We show some examples in Table 2 to illustrate our 

POS tagging strategy for compounds. 

In Table 4 we present a dependency label set developed based on the Stanford Dependencies (De 

Marneffe et al., 2006) and its Chinese version (Chang et al., 2009), which defines 45 dependency rela-

tions for Chinese sentences. This label set is also closely related to the Universal Dependency1 with 

many of their labels compatible with each other. We explain the major characteristics of our label set in 

the following subsection. 

3.1 Chinese Specific Labels 

dislocated The label â€œdislocatedâ€ is originally defined in the universal dependencies for languages such 

as Japanese to describe the syntactic relation of words in a topicâ€“comment structure, but is not defined 

for Chinese. However, in Chinese it is frequent to see the topicâ€“comment structure in a sentence, for 

example: 

 

1. é€™/this æœ¬/-measure- æ›¸/book ä»–/he è²·/buy çš„/-particle- (This book, he bought it) 
 

In this sentence, è¿™æœ¬ä¹¦ (this book) is the topic and ä»–ä¹°çš„ (he bought) is the comment. One common 

view of the syntactic structure of this sentence is that, ä»– (he) is the subject of the predicate ä»– (buy), 

and ä¹¦ (book) is the direct object. This treatment sees a topicâ€“comment structure as having an OSV 
(object-subject-verb) word order, which is acceptable; it however has some problems in certain cases, 

for example: 

 

2. é€™ /this æœ¬ /-measure- æ›¸ /book ä»– /he è²· /buy çš„ /-particle- æ˜¨å¤© /yesterday ä¸è¦‹ /disappear äº† /-
particle- (This book that he bought disappeared yesterday) 

 

In this sentence, ä¹¦ (book) is still the direct object of ä¹° (buy), while it is also the subject of ä¸è§ 
(disappear). Because of the nature of the dependency grammar we adopted, for such a structure we 

would have to choose one relation for ä¹¦ (book), either â€œnsubjâ€ or â€œdobjâ€, and discard the other relation 
which would cause a loss of the syntactic information encoded in the parse tree.  

Moreover, the OSV word order cannot explain all topic-comment structure such as the following 

example: 

 

3. é€™/this å ´/-measure- ç«/fire å¹¸è™§/fortunately æ¶ˆé˜²/firefighting éšŠ/team ä¾†/come å¾—/-particle- æ—©
/early (This fire, fortunately the firefighters came in time) 

                                                 
1 http://universaldependencies.org/ 

301



Label Description Example Phrase Example Dependency 

acomp adjectival comple-

ment  
é‹æ˜¯å…¨æ–°çš„ (the shoes are 
brand new) 

acomp(æ˜¯ are, å…¨æ–° brand new) 

advmod adverbial modifier ä»–çœ‹ä¸Šå»å¾ˆç–²å€¦ (he looks very 
tired ) 

advmod(ç–²å€¦ tired, å¾ˆ very) 

amod adjectival modifier æ¼‚äº®çš„é¦–é£¾  (cute accessory) amod(é¦–é£¾ accessory, æ¼‚äº® 
cute) 

appos appositional modi-

fier 
ç¸½çµ±å¥§å·´é¦¬ (president Obama) appos(å¥§å·´é¦¬ Obama, ç¸½çµ±

president) 

asp aspect marker ä»–çµ¦äº†æˆ‘ä¸€æœ¬æ›¸ (he gave me a 
book) 

asp(çµ¦ gave,  äº† -aspect-) 

attr attributive modifier  ä»–æ˜¯å€‹é†«ç”Ÿ (he is a doctor) attr(æ˜¯ is, é†«ç”Ÿ doctor) 

aux auxiliary verb å¿…é ˆè§£æ±º (must solve) aux(è§£æ±º solve, å¿…é ˆ must) 

auxpass passive auxiliary ä»–è¢«åˆºæ®ºäº† (he was assassi-
nated) 

auxpass(åˆºæ®º assassinated, è¢« -
auxiliary-) 

auxcaus causative auxiliary æŠŠå•é¡Œè§£æ±º(solve the problem) auxcaus(è§£æ±º solve,  æŠŠ -auxil-
iary-) 

cc coordinating con-

junction 
è°æ˜åˆå¯æ„› (smart and cute) cc(è°æ˜ smart, åˆ and) 

ccomp closed clausal com-

plement 
ä»–èªªä»–å–œæ­¡æ¸¸æ³³ (He said that 
he likes swimming) 

ccomp(èªª said, å–œæ­¡ likes) 
 

conj conjunct è°æ˜åˆå¯æ„› (smart and cute) conj(è°æ˜ smart, å¯æ„› cute) 
csubj clausal subject  èƒ½å¤ ä»£è¡¨ç¥–åœ‹åƒè³½æ˜¯ä»–çš„å¤¢æƒ³ 

(being able to play in the game 

for his country is his dream) 

csubj(æ˜¯ is, åƒè³½ play) 
 

csubjpass clausal passive sub-

ject  
ä»–åœ¨è€ƒè©¦ä¸­ä½œå¼Šè¢«è€å¸«ç™¼ç¾äº† 
(that he cheated during the exam 

is found out by the teacher) 

csubjpass(ç™¼ç¾ find out, ä½œå¼Š 
cheet) 

dep undefined depend-

ency 
æ·»åŠ ä¸€å€‹æ—¥ç¨‹å®‰æ’æ™‚é–“æ˜ŸæœŸäºŒ

åœ°é» 3 æ¨“ (add an event, time 
Tuesday, location 3rd floor) 

dep(æ™‚é–“, æ·»åŠ ) 

det determiner é‚£æœ¬æ›¸ (that book) det(æœ¬ -measure-, é‚£ that) 
discourse discoursal modifier å”‰ï¼Œçµ‚æ–¼åˆ°æ˜ŸæœŸäº”äº† (oh, 

thank God itâ€™s Friday) 

discourse(åˆ° is, å”‰ oh) 

discourse(åˆ° is, äº†-sentence-
final particle-) 

dislocated dislocated modifier æ›¸æ˜¯ä»–è²·çš„ (book he bought) 

é€™å ´ç«å¹¸è™§æ¶ˆé˜²éšŠä¾†å¾—æ—©. 
(this fire, fortunately the fire-

fighters came in time) 

dislocated(æ›¸ book, è²· buy) 

dislocated(ç« fire, ä¾† come) 

dobj direct object è²·äº†ä¸€æœ¬æ›¸(bought a book) dobj(è²· bought, æ›¸ book) 

foreign foreign compound è·æ£’å¤§è¯ç›Ÿï¼ˆMajor League 

Baseballï¼‰ 

foreign(Major, League) 

foreign(Major, Baseball) 

iobj indirect object ä»–çµ¦äº†æˆ‘ä¸€æœ¬æ›¸ (he gave me a 
book) 

iobj(çµ¦ gave, æˆ‘ me) 

list list relation æ·»åŠ ä¸€å€‹æ—¥ç¨‹å®‰æ’æ™‚é–“æ˜ŸæœŸäºŒ

åœ°é» 3 æ¨“ (add an event, time 
Tuesday, location 3rd floor) 

list(æ™‚é–“ time, åœ°é» location) 

mark clause marker ä»–æŠŠä¿¡ä»¶çµ¦æˆ‘ä¹‹å¾Œå°±èµ°äº† (he 
left after he gave me the letter) 

mark(çµ¦ give, ä¹‹å¾Œ after) 

mark(èµ° leave, å°± then) 

mes measure relation ä¸€æœ¬æ›¸(a book) mes(æ›¸ book, æœ¬ -measure-) 

302



ncomp nominal comple-

ment 
ååœ¨æ¤…å­ä¸Š (sit on a chair) ncomp(æ¤…å­ chair, ä¸Š -comple-

mentizer-) 

neg negation modifier ä¸æ“…é•· (be not good at) neg(æ“…é•· be good at, ä¸ not) 

nn noun compound 

modifier 
åŸæ²¹æœŸè²¨åƒ¹æ ¼ (oil futures 
price) 

nn(åƒ¹æ ¼ price, åŸæ²¹ oil) 

nn(åƒ¹æ ¼ price, æœŸè²¨ futures) 
npadvmod noun phrase adver-

bial modifier 
å¤§ç´„åç±³å·¦å³å¯¬ (about 10 m 
wide) 

npadvmod(å¯¬ wide, ç±³ m) 

nsubj nominal subject ä»–çµ¦äº†æˆ‘ä¸€æœ¬æ›¸ (he gave me a 
book) 

nsubj(çµ¦ gave, ä»– he) 

nsubjpass  passive nominal 

subject 
ä»–è¢«åˆºæ®ºäº† (he was assassi-
nated) 

nsubjpass(åˆºæ®º assassinated, ä»– 
he) 

num numeric modifier ä¸€æœ¬æ›¸ (a book) num(æœ¬ -measure-, ä¸€ a) 
p punctuation æ¢¨ã€æ©˜å­å’Œé¦™è•‰ (pears, or-

anges, bananas) 

p(æ¢¨ pears, ã€) 

pcomp prepositional com-

plement 
ç”±æ–¼è·¯ä¸Šäººå¤ªå¤šï¼Œæˆ‘é²åˆ°äº† 
(because it was so crowded, I 

was late) 

pcomp(ç”±æ–¼ because, å¤ªå¤š so 
crowded) 

pobj prepositional object ä»–ååœ¨æ¤…å­ä¸Š (he sits on a 
chair) 

pobj(åœ¨ on, æ¤…å­ chair) 

ps associative marker é€™æ˜¯æˆ‘çš„å®¶ (this is my home) ps(æˆ‘ me, çš„ â€˜s) 

poss possessive modifier é€™æ˜¯æˆ‘çš„å®¶ (this is my home) poss(å®¶ home, æˆ‘ me) 
prep prepositional modi-

fier 
ä»–ååœ¨æ¤…å­ä¸Š (he sits on a 
chair) 

prep(å sits, åœ¨ on) 

prt phrasal verb parti-

cle relation 
ä»–å€‘æ‰“èµ·ä¾†äº† (they started a 
fight) 

æŠŠæ•¸æ“šæ•´ç†æˆå ±å‘Š (summarize 
the data into a report) 

prt(æ‰“ fight, èµ·ä¾† -auxiliary-) 

prt(æ•´ç† summarize, æˆ be-
come) 

rcmodrel relative clause 

complementizer 
ä»–å›ä¾†çš„æ™‚å€™ (by the time he 
came back) 

rcmodrel(å›ä¾† come back, çš„ -
complementizer-) 

é€™æœ¬æ˜¯ä»–è²·çš„æ›¸ (this is the 
book he bought) 

rcmodrel(è²· buy, çš„ -comple-
mentizer-) 

rcmod relative clause 

modifier 
ä»–å›ä¾†çš„æ™‚å€™ (by the time he 
came back) 

rcmod(æ™‚å€™ time, å›ä¾† come 
back) 

é€™æœ¬æ˜¯ä»–è²·çš„æ›¸ (this is the 
book he bought) 

rcmod(æ›¸ book, è²· buy) 

suff suffix relation ç§‘æŠ€ç•Œ (sci-tech industry) suff(ç•Œ industry, ç§‘æŠ€ sci-tech) 
tmod temporal modifier ä»–å›ä¾†çš„æ™‚å€™å¤©å·²ç¶“äº®äº† (it 

was bright outside by the time 

he came back) 

tmod(äº® bright,  æ™‚å€™ time) 

topic topic marker é€™æœ¬æ›¸æ˜¯ä»–è²·çš„ (this is the 
book he bought) 

topic(æ›¸ book, æ˜¯ is) 

é€™æ˜¯ä»–å€‘æ‰€ä¸èƒ½æƒ³åƒçš„ (this is 
what they canâ€™t imagine) 

topic(é€™ this, æ˜¯ is) 

vmod verb modifier ä»–æ‰“é–‹é–€ç™¼ç¾å±‹è£æœ‰äºº (he 
opened the door and found out 

there is somebody inside) 

vmod(ç™¼ç¾ found out, æ‰“é–‹ 
open) 

xcomp open clausal com-

plement 
ä»–ä¸å–œæ­¡æ‰“ç¶²çƒ (he doesnâ€™t 
like to play tennis) 

xcomp(å–œæ­¡ like, æ‰“ play) 

Table 4. Proposed dependency label set. 

303



Unlike in the other two examples, the topic here, é€™å ´ç« (this fire), is not the direct object of the verb 

in the comment, å¹¸è™§æ¶ˆé˜²éšŠä¾†å¾—æ—© (fortunately the firefighters came in time).  
To overcome these difficulties, we employ a different view which treats the topicâ€“comment structure 

as having double subjects in a SSV word order. We define the first subject, è¿™æœ¬ä¹¦ (this book) in ex-

ample 2, as the head in a â€œdislocatedâ€ relation, and the subject-verb phrase, ä»–ä¹°çš„ (he bought) in 
example 2, as the modifier. The head in this dislocated relation can then form a â€œnsubjâ€ (nominal subject) 

relation with the main predicate of the sentence, ä¸è§ (disappear). Similarly, in example 3, the topic and 
the comment still form a dislocated relation even though the topic is not a direct object of the verb in 

the comment. 

prt and prep We define the â€œprtâ€ relation in two ways: 

 

i. A relation between a verb and a particle. For example, æƒ³åƒ (imagine) is the head in a â€œprtâ€ relation 

of æ‰€ (particle) in the sentence é€™æ˜¯ä»–å€‘æ‰€ä¸èƒ½æƒ³åƒçš„ (this is what they canâ€™t imagine).  

ii. A relation between a verb and its succeeding complement. For example, æ‰“æƒ (clean) is the head in 

a â€œprtâ€ relation of å®Œ (finish) in the sentence æˆ¿é–“æ‰“æƒå®Œäº† (the room has been cleaned). 
 

We use the â€œprtâ€ relation in the second case to capture the predicate-complement structure in Chinese. 

The verb å®Œ (finish) in the second example above functions to complement  the meaning of the main 

verb, æ‰“æƒ (clean), and the sentence is still grammatical when the complement verb is removed: æˆ¿é–“

æ‰“æƒäº† (the room is cleaned).  
The complement verb sometimes also functions as a coverb in a serial verb construction, which takes 

its own direct object. For example: 

 

4. æŠŠ/-auxiliary- æ•¸æ“š/data æ•´ç†/summarize æˆ/become å ±å‘Š/report (summarize the data into a report) 
 

Here the two verbs æ•´ç† (summarize) and æˆ(become) form a â€œprtâ€ relation, while they are the heads of 

æ•¸æ“š (data) and å ±å‘Š (report) in the â€œdobjâ€ relation.  
A difficulty with labeling â€œprtâ€ is that, it can be easily confused with the â€œprepâ€ (prepositional modi-

fier) relation. For example, one can argue that æˆ (become) is a preposition instead of a verb and should 

be tagged as IN, so that the relation between æ•´ç† (summarize) and æˆ (become) would be "prep". To 
overcome this ambiguity, we apply a simple test: If the phrase headed by the word with a VV vs. IN 

ambiguity can be moved to a position before the main verb, then this word is a preposition and a prep-

ositional modifier of the main verb; otherwise it is a verb. Here since the phrase â€œæˆ å ±å‘Šâ€ (into report) 

cannot be moved to the position before æ•´ç† (summarize), it should in fact be a verb phrase, not a 
prepositional phrase. 

suff We define the suffix relation in a compound which has a â€œstem-suffixâ€ structure. The suffix word 

with a POS tag SFN, SFA, or SFV is the root of the subtree formed by the words in the compound. It 

has one and only one child in this subtree, which is the head of the â€œstemâ€, and the dependency relation 

between them is labelled as â€œsuffâ€.  

The motivation of employing the â€œsuffâ€ label is to relieve the data sparseness problem of word forms 

in annotated corpora. Compounds, especially those with a â€œstem-suffixâ€ structure, is a major source of 

new words in Chinese language. These compounds, however, often share a set of suffix words which 

has a limited amount of instances. We think it is more effective for a parser to learn from features with 

word forms by treating the suffix words as the heads of compounds. 

4 Evaluation 

4.1 Re-annotated Corpus 

We re-annotated the entire CTB5 with our proposed word segmentation and POS tagging annotation 

strategies. We further re-annotated 3,000 sentences which are randomly sampled from the training set 

of CTB5 using our proposed dependency label set. This re-annotated set is compared with the same 

sentences with the original annotation in a machines translation experiment in section 4.3. 

304



 CTB5 Re-annotated 

Number of tokens 493,938 516,581 

Avg. token length 1.63 1.55 

Ratio of unknown words 14.67% 12.82% 

Ratio of unknown word-POS pairs 15.02% 13.28% 

Table 5. Statistics of the original CTB5 and our re-annotated version. 

 

(a) Word Segmentation Results 

Corpus P R F 

Original 97.21 97.36 97.28 

Re-annotated 97.97 97.56 97.76 

Re-annotated-partial 97.68 97.63 97.65 

 

(b) Joint Segmentation and POS Tagging Results 

Corpus P R F 

Original 93.42 93.56 93.49 

Re-annotated 94.55 94.16 94.35 

Table 6. Experimental results for morphological analysis on CTB5. 

 

To evaluate the consistency of our annotation, 4 trained annotators were divided into two equal groups 

to perform 2-way annotation on a small subset (first 100 sentences in files 301-325), and each pair of 

annotators were assigned with 50 sentences. The inter-annotator agreement is 99.10% for segmentation, 

98.37% for POS tagging, and 95.62% for dependency labeling.  

Table 5 shows some of the statistics of the original and the re-annotated CTB5. We split CTB5 in the 

same data division as in previous studies (Jiang et al., 2008a; Jiang et al., 2008b; Kruengkrai et al., 2009; 

Zhang and Clark, 2010; Sun, 2011). The training, development and test set have 18,089, 350 and 348 

sentences, respectively. Compared to the original CTB5, the re-annotated training set has a lower per-

centage of unknown words and unknown word-POS pairs found in the corresponding test set. This is 

consistent with our observation that compounds with internal structures are one of the major sources of 

OOV words. 

4.2 Morphological Analysis Experiments 

We compared the performance of a state-of-the-art joint word segmentation and part-of-speech tagging 

system (Kruengkrai et al., 2009) on the original and our re-annotated CTB5. We used the position-of-

character (POC) tagset and the baseline feature set described in (Shen et al., 2014). 

We trained all models using the averaged perceptron (Collins, 2002), which is an efficient and stable 

online learning algorithm. The models applied on all test sets are those that result in the best performance 

on the dev sets. To learn the characteristics of unknown words, we built the systemâ€™s lexicon using only 

the words in the training data that appear at least 2 times. 

We use precision, recall and the F-score to measure the performance of the systems. Precision (P) is 

defined as the percentage of output tokens that are consistent with the gold standard test data, and recall 

(R) is the percentage of tokens in the gold standard test data that are recognized in the output. The 

balanced F-score (F) is defined as 
2âˆ™Pâˆ™R

P+R
. 

We compared the performance of the morphological analyzer on the original and the re-annotated 

CTB5. The results of the word segmentation experiment and the joint experiment of segmentation and 

POS tagging are shown in Table 6(a) and Table 6(b), respectively. Each row in these tables shows the 

performance of the same system trained on the corresponding corpus.  

For â€œRe-annotated-partialâ€ in Table 6(a), we applied a different setting in order to directly compare 

the annotation consistency and data sparsity between the two corpora: We used the training set from the 

re-annotated corpus to train the system but the test set from the original corpus in the evaluation. To 

make the evaluation meaningful, we added an extra criterion when calculating the precision and the 

305



System BLEU-4 

Character  31.60 

Original  31.46 

Re-annotated  32.08 

Table 7. Experimental results for Chinese-Japanese machine 

translation on ASPEC corpus using Moses system. 

 

System BLEU-4 

Original  32.00 

Re-annotated  32.97 

Table 8. Experimental results for Chinese-Japanese machine 

translation on ASPEC corpus using KyotoEBMT system. 

 

recall: If the outmost boundaries of a sequence (two or more) of output tokens are consistent with a 

token in the test set, we consider that the output correctly identifies this token in the test set.  

The results show that, the morphological analyzer can obtain higher accuracies in both word segmen-

tation (0.48 points absolute in F-score) and joint (0.86 points absolute in F-score) experiments. Further-

more, in the word segmentation experiment â€œRe-annotated-partialâ€ where we mapped the output of the 

system which is trained using the re-annotated training data to the original CTB5 test set, the accuracy 

is significantly higher2 than that of the â€œOriginalâ€, which demonstrates the better consistency in our re-

annotation corpus. 

4.3 Machine Translation Experiments 

To show that a morphological analysis system and a dependency parsing system can both benefit from 

our re-annotation, we conducted two sets of Chinese-to-Japanese machine translation experiments 

where a morphological analyzer and a dependency parser are used respectively.  

The parallel corpus we used is the Chinese-Japanese part of the Asian Scientific Paper Excerpt Corpus 

(ASPEC)3, containing 672k sentence pairs. We used 2,090 and 2,107 additional sentence pairs for tuning 

and testing, respectively.  

In the first set of experiments, we segmented the Japanese sentences using JUMAN (Kurohashi et al., 

1994), and the Chinese sentences using the same morphological analyzer described in the last subsection. 

For decoding, we used the state-of-the-art phrase based statistical machine translation toolkit Moses 

(Koehn et al., 2007) with default options. We trained the 5-gram language models on the target side of 

the parallel corpora using the SRILM toolkit4 with interpolated Kneser-Ney discounting. Tuning was 

performed by minimum error rate training (MERT) (Och, 2003), and it was re-run for every experiment. 

In the second set of experiments, we used the same morphological analyzers to segment and tag the 

POS of Japanese and Chinese sentences as in the first set. We further parsed the dependency structures 

of the Japanese sentences using KNP (Kawahara and Kurohashi, 2006), a lexicalized probabilistic de-

pendency parser, and for the Chinese sentences we used a second-order graph-based parser proposed in 

(Shen et al., 2012). For decoding, we used the tree-to-tree example-based machine translation frame-

work KyotoEBMT5 (Richardson et al., 2015) with default options. 

We report results on the test set using BLEU-4 score, which was evaluated using the multi-bleu.perl 

script in Moses  based on Juman segmentations. The significance test was performed using the bootstrap 

resampling method proposed by Koehn (2004). 

In Table 7 we compare the performance of three Moses models: In â€œCharacterâ€ we used a simple 

segmentation strategy for the Chinese sentences where we treated each character as a token; in â€œOriginalâ€ 

and â€œRe-annotatedâ€ we segmented the Chinese sentences using the corresponding models described in 

                                                 
2 ğ‘ < 0.05 in McNemarâ€™s test. 
3 http://lotus.kuee.kyoto-u.ac.jp/ASPEC/ 
4 http://www.speech.sri.com/projects/srilm 
5 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?KyotoEBMT 

306



the last subsection. The results show, with the underlying machine translation system being the same, 

the segmenter trained with the original CTB5 failed to support the system to outperform the simple 

character-based segmentation, while on the other hand the system using the segmenter trained with our 

re-annotated CTB5 significantly outperformed both â€œCharacterâ€6 and â€œOriginalâ€7. 

In Table 8 we show the result of the experiment with KyotoEBMT, a tree-to-tree machine translation 

system which requires unlabeled dependency annotation in the model training. 3,000 sentences with 

original and re-annotated dependency labels were used for training the parsers in â€œoriginalâ€ and â€œre-

annotatedâ€ settings, respectively. The result shows that, the model â€œRe-annotatedâ€ which used the train-

ing set with the proposed annotation, it significantly outperformed8 the baseline model â€œOriginalâ€ by 

0.97 point in BLEU-4 score. 

5 Conclusion 

We have proposed a new annotation approach for Chinese word segmentation, part-of-speech tagging, 

and dependency labelling. By re-annotating the CTB5 and conducting word segmentation, POS tagging 

and machine translation experiments, we have demonstrated that this approach has the advantages in 

achieving higher annotation consistency as well as less data sparsity, compared to the original annotation 

of CTB5. We couldnâ€™t show the comparison in dependency parsing experiments as we currently have 

only 3,000 annotated sentences; this experiment will be included in our future work. 

 

Reference 

Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and Christopher D. Manning. 2009. Discriminative Reordering 

with Chinese Grammatical Relations Features. In Proceedings of the Third Workshop on Syntax and Structure 

in Statistical Translation, pages 51-59. 

Michael Collins. 2002. Discriminative Training Methods for Hidden Markov Models: Theory and Experiments 

with Perceptron Algorithms. In Proceedings of EMNLP, pages 1â€“8. 

Daisuke Kawahara and Sadao Kurohashi. 2006. A Fully-Lexicalized Probabilistic Model for Japanese Syntactic 

and Case Structure Analysis. In Proceedings of the Human Language Technology Conference of the NAACL, 

pages 176â€“183. 

HuiMing Duan, XiaoJing Bai, BaoBao Chan, and ShiWen Yu. 2003. Chinese word segmentation at Peking Uni-

versity. In Proceedings of the second SIGHAN workshop on Chinese language processing, pages 152-155. 

ChuRen Huang, KehJiann Chen, FengYi Chen, and LiLi Chang. 1997. Segmentation Standard for Chinese Natural 

Language Processing. Computational Linguistics and Chinese Language Processing vol. 2, no. 2, August 1997, 

pages 47-62. 

Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan LÃ¼. 2008a. A Cascaded Linear Model for Joint Chinese Word 

Segmentation and Part-of-speech Tagging. In Proceedings of ACL. 

Wenbin Jiang, Haitao Mi, and Qun Liu. 2008b. Word Lattice Reranking for Chinese Word Segmentation and Part-

of-speech Tagging. In Proceedings of COLING. 

Philipp Koehn. 2004. Statistical Significance Tests for Machine Translation Evaluation. In Proceedings of EMNLP 

2004, pages 388-395. 

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke 

Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, OndÅ™ej Bojar, Alexandra Constantin, and Evan 

Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the 45th An-

nual Meeting of the Association for Computational Linguistics Companion, Demo and Poster Session, pages 

177-180. 

                                                 
6 p < 0.5 
7 p < 0.1 
8 p < 0.1 

307



Canasai Kruengkrai, Kiyotaka Uchimoto, Junâ€™ichi Kazama, YiouWang, Kentaro Torisawa, and Hitoshi Isahara. 

2009. An Error-Driven Word-Character Hybird Model for Joint Chinese Word Segmentation and POS Tagging. 

In Proceedings of ACL-IJCNLP, pages 513-521. 

Sadao Kurohashi, Toshihisa Nakamura, Yuji Matsumoto, and Nagao Makoto. 1994. Improvements of Japanese 

Morphological Analyzer JUMAN. In Proceedings of the International Workshop on Sharable Natural Language, 

pages 22-28. 

Marie-Catherine de Marneffe, Bill MacCartney and Christopher D. Manning. 2006. Generating Typed Depend-

ency Parses from Phrase Structure Parses. In Proceedings of LREC 2006, pages 449-454. 

Franz Josef Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proceedings of the 

41st Annual Meeting of the Association for Computational Linguistics, pages 160-167. 

John Richardson, Raj Dabre, Chenhui Chu, Fabien CromiÃ¨res, Toshiaki Nakazawa, and Sadao Kurohashi. 2015. 

KyotoEBMT System Description for the 2nd Workshop on Asian Translation. In Proceedings of the 2nd Work-

shop on Asian Translation, pages 54-60. 

Mo Shen, Daisuke Kawahara, and Sadao Kurohashi. 2012. A Reranking Approach for Dependency Parsing with 

Variable-sized Subtree Features. In Proceedings of 26th Pacific Asia Conference on Language Information and 

Computing, pages 308-317. 

Mo Shen, Hongxiao Liu, Daisuke Kawahara, and Sadao Kurohashi. 2014. Chinese Morphological Analysis with 

Character-level POS Tagging. In Proceedings of the 52nd Annual Meeting of the Association for Computational 

Linguistics (Short Papers), pages 253â€“258. 

Weiwei Sun. 2011. A Stacked Sub-word Model for Joint Chinese Word Segmentation and Part-of-speech Tagging. 

In Proceedings of ACL-HLT, pages 1385â€“1394. 

Fie Xia. 2000. The Segmentation Guidelines for the Penn Chinese Treebank (3.0). http://www.cis.upenn.edu/~chi-

nese/segguide.3rd.ch.pdf. 

Meishan Zhang, Yue Zhang, Wanxiang Che, and Ting Liu. 2013. Chinese Parsing Exploiting Characters. In Pro-

ceedings of ACL, page 125-134. 

Yue Zhang and Stephen Clark. 2010. A Fast Decoder for Joint Word Segmentation and POS-tagging Using a 

Single Discriminative Model. In Proceedings of EMNLP, pages 843â€“852. 

308


