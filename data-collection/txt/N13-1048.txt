










































Training MRF-Based Phrase Translation Models using Gradient Ascent


Proceedings of NAACL-HLT 2013, pages 450–459,
Atlanta, Georgia, 9–14 June 2013. c©2013 Association for Computational Linguistics

Training MRF-Based Phrase Translation Models using Gradient Ascent 

 
Jianfeng Gao 

Microsoft Research 
Redmond, WA, USA 

jfgao@microsoft.com 

 
Xiaodong He 

Microsoft Research 
Redmond, WA, USA 

xiaohe@microsoft.com 

 

Abstract 

This paper presents a general, statistical 
framework for modeling phrase translation 
via Markov random fields. The model al-
lows for arbituary features extracted from a 
phrase pair to be incorporated as evidence. 
The parameters of the model are estimated 
using a large-scale discriminative training 
approach that is based on stochastic gradi-
ent ascent and an N-best list based expected 
BLEU as the objective function. The model 
is easy to be incoporated into a standard 
phrase-based statistical machine translation 
system, requiring no code change in the 
runtime engine. Evaluation is performed on 
two Europarl translation tasks, German-
English and French-English. Results show 
that incoporating the Markov random field 
model significantly improves the perfor-
mance of a state-of-the-art phrase-based 
machine translation system, leading to a 
gain of  0.8-1.3 BLEU points. 

1 Introduction 

The phrase translation model, also known as the 
phrase table, is one of the core components of a 
phrase-based statistical machine translation (SMT) 
system. The most common method of constructing 
the phrase table takes a two-phase approach. First, 
the bilingual phrase pairs are extracted heuristical-
ly from an automatically word-aligned training da-
ta. The second phase is parameter estimation, 
where each phrase pair is assigned with some 
scores that are estimated based on counting of 
words or phrases on the same word-aligned train-
ing data. 

There has been a lot of research on improving 
the quality of the phrase table using more princi-
pled methods for phrase extraction (e.g., Lamber 
and Banchs 2005), parameter estimation (e.g., 
Wuebker et al. 2010; He and Deng 2012), or both 
(e.g., Marcu and Wong 2002; Denero et al. 2006). 
The focus of this paper is on the parameter estima-
tion phase. We revisit the problem of scoring a 
phrase translation pair by developing a new phrase 
translation model based on Markov random fields 
(MRFs) and large-scale discriminative training. 
We strive to address the following three primary 
concerns. 

First of all, instead of parameterizing a phrase 
translation pair using a set of scoring functions that 
are learned independently (e.g., phrase translation 
probabilities and lexical weights) we use a general, 
statistical framework in which arbitrary features 
extracted from a phrase pair can be incorporated to 
model the translation in a unified way. To this end, 
we propose the use of a MRF model.  

Second, because the phrase model has to work 
with other component models in an SMT system in 
order to produce good translations and the quality 
of translation is measured via BLEU score, it is de-
sirable to optimize the parameters of the phrase 
model jointly with other component models with 
respect to an objective function that is closely re-
lated to the evaluation metric under consideration, 
i.e., BLEU in this paper. To this end, we resort to a 
large-scale discriminative training approach, fol-
lowing the pioneering work of Liang et al. (2006). 
Although there are established methods of tuning a 
handful of features on small training sets, such as 
the MERT method (Och 2003), the development of 
discriminative training methods for millions of fea-
tures on millions of sentence pairs is still an ongo-
ing area of research. A recent survey is due to 
Koehn (2010). In this paper we show that by using 
stochastic gradient ascent and an N-best list based 

450



expected BLEU as the objective function, large-
scale discriminative training can lead to significant 
improvements. 

The third primary concern is the ease of adop-
tion of the proposed method. To this end, we use a 
simple and well-established learning method, en-
suring that the results can be easily reproduced. 
We also develop the features for the MRF model in 
such a way that the resulting model is of the same 
format as that of a traditional phrase table. Thus, 
the model can be easily incorporated into a stand-
ard phrase-based SMT system, requiring no code 
change in the runtime engine. 

In the rest of the paper, Section 2 presents the 
MRF model for phrase translation. Section 3 de-
scribes the way the model parameters are estimated. 
Section 4 presents the experimental results on two 
Europarl translation tasks. Section 5 reviews pre-
vious work that lays the foundation of this study. 
Section 6 concludes the paper. 

2 Model 

The traditional translation models are directional 
models that are based on conditional probabilities. 
As suggested by the noisy-channel model for SMT 
(Brown et al. 1993): 

�∗ = argmax
�

���|�� = argmax
�

�(�)���|� (1) 

The Bayes rule leads us to invert the conditioning 
of translation probability from a foreign (source) 
sentence � to an English (target) translation �.  

However, in practice, the implementation of 
state-of-the-art phrase-based SMT systems uses a 
weighted log-linear combination of several models 
ℎ(�,�,�)  including the logarithm of the phrase 
probability (and the lexical weight) in source-to-
target and target-to-source directions (Och and Ney 
2004) 

�∗ = argmax
�
∑ 	�ℎ�(�,�,�)����   (2) 

= argmax
�


����(�,�)  
where �  in ℎ(�,�,�)  is a hidden structure that 
best derives � from �, called the Viterbi derivation 
afterwards. In phrase-based SMT, � consists of (1) 
the segmentation of the source sentence into 
phrases, (2) the segmentation of the target sentence 

into phrases, and (3) an alignment between the 
source and target phrases. 

In this paper we use Markov random fields 
(MRFs) to model the joint distribution ��(�, �) 
over a source-target translation phrase pair (�, �), 
parameterized by �. Different from the directional 
translation models, as in Equation (1), the MRF 
model is undirected, which we believe upholds the 
spirit of the use of bi-directional translation proba-
bilities under the log-linear framework. That is, the 
agreement or the compatibility of a phrase pair is 
more effective to score translation quality than a 
directional translation probability which is mod-
eled based on an imagined generative story does. 

2.1 MRF 

MRFs, also known as undirected graphical models, 
are widely used in modeling joint distributions of 
spatial or contextual dependencies of physical phe-
nomena (Bishop 2006). A Markov random field is 
constructed from a graph � . The nodes of the 
graph represent random variables, and edges define 
the independence semantics between the random 
variables. An MRF satisfies the Markov property, 
which states that a node is independent of all of its 
non-neighbors, defined by the clique configura-
tions of �. In modeling a phrase translation pair, 
we define two types of nodes, (1) two phrase nodes 
and (2) a set of word nodes, each for a word in the-
se phrases, such as the graph in Figure 1. Let us 
denote a clique by � and the set of variables in that 
clique by ��, ��� . Then, the joint distribution over 
the random variables in � is defined as 

��(�, �) = �	∏ ��(��, ���;�)�
�(�) , (3) 
where � = ��, … , �|| , � = ��, … , �|�|  and �(�)  is 
the set of cliques in �, and each ��(��, ���;�) is a 
non-negative potential function defined over a 
clique � that measures the compatibility of the var-
iables in �, � is a set of parameters that are used 
within the potential function. �  in Equation (3), 
sometimes called the partition function, is a nor-
malization constant and is given by  

� = ∑ ∑ ∏ ��(��, ���;�)�
�(�)�   (4) 
= ∑ ∑ 
���(�, �)� ,  

which ensures that the distribution ��(�, �) given 
by Equation (3) is correctly normalized. The pres-

451



ence of � is one of the major limitations of MRFs 
because it is generally not feasible to compute due 
to the exponential number of terms in the summa-
tion. However, we notice that �  is a global con-
stant which is independent of � and �. Therefore, in 
ranking phrase translation hypotheses, as per-
formed by the decoder in SMT systems, we can 
drop �  and simply rank each hypothesis by its 
unnormalized joint probability. In our implementa-
tion, we only store in the phrase table for each 
translation pair ��, �� its unnormalized probability, 
i.e., 
���(�, �) as defined in Equation (4). 

It is common to define MRF potential functions 
of the exponential form as �����, ���;�� =
exp (������), where ���� is a real-valued feature 
function over clique � and �� is the weight of the 
feature function. In phrase-based SMT systems, the 
sentence-level translation probability from �  to � 
is decomposed as the product of a set of phrase 
translation probabilities. By dropping the phrase 
segmentation and distortion model components, we 
have  

�(�|�) ≈ max
�
�(�|�,�) (5) 

�(�|�,�) = ∏ �(�|�)(�,)∈� ,  
where �  is the Viterbi derivation. Similarly, the 
joint probability �(�,�) can be decomposed as 

���,�� ≈ max
�
�(�,�,�) (6) 

���,�,�� = ∏ ��(�, �)(�,)∈�   
∝ ∑ log����, ����,�∈�   
∝ ∑ ∑ ���(�)�∈�(�(�,�))��,�∈�   
= ∑ � ∙ �(�, �)��,�∈�   

which is essentially proportional to a weighted lin-
ear combination of a set of features. 

To instantiate an MRF model, one needs to de-
fine a graph structure representing the translation 
dependencies between source and target phrases, 
and a set of potential functions over the cliques of 
this graph.  

2.2 Cliques and Potential Functions 

The MRF model studied in this paper is construct-
ed from the graph � in Figure 1. It contains two 
types of nodes, including two phrase nodes for the 
source and target phrases respectively and word 
nodes, each for a word in these phrases. The 
cliques and their corresponding potential functions 
(or features) attempt to abstract the idea behind 
those translation models that have been proved ef-
fective for machine translation in previous work. In 
this study we focus on three types of cliques. 

First, we consider cliques that contain two 
phrase nodes. A potential function over such a 
clique captures phrase-to-phrase translation de-
pendencies similar to the use the bi-directional 
translation models in phrase-based SMT systems. 
The potential is defined as ����, �� = ����(�, �), 
where the feature ��(�, �), called the phrase-pair 
feature, is an indicator function whose value is 1 if 
� is target phrase and � is source phrase, and 0 oth-
erwise. While the conditional probabilities in a di-
rectional translation model are estimated using rel-
ative frequencies of phrase pairs extracted from 
word-aligned parallel sentences, the parameter of 
the phrase-pair function �� is learned discrimina-
tively, as we will describe in Section 3. 

Second, we consider cliques that contain two 
word nodes, one in source phrase and the other in 
target phrase. A potential over such a clique cap-
tures word-to-word translation dependencies simi-
lar to the use the IBM Model 1 for lexical 
weighting in phrase-based SMT systems (Koehn et 
al. 2003). The potential function is defined as 
����, �� = ����(�, �), where the feature ��(�, �), 
called the word-pair feature, is an indicator func-
tion whose value is 1 if � is a word in target phrase 
� and f is a word in source phrase �, and 0 other-
wise.  

The third type of cliques contains three word 
nodes. Two of them are in one language and the 
third in the other language. A potential over such a 
clique is intended to capture inter-word dependen-

 

Figure 1: A Markov random field model for phrase 
translation of � = ��, �� and � = ��,��,��. 

452



cies for selecting word translations. The potential 
function is inspired by the triplet lexicon model 
(Hasan et al. 2008) which is based on lexicalized 
triplets (�, �, �’) . It can be understood as two 
source (or target) words triggering one target (or 
source) word. The potential function is defined as 
�����, ��, �� = ������(�, ��, �), where the feature 
���(�, ��, �), called the triplet feature, is an indica-
tor function whose value is 1 if � is a word in tar-
get phrase � and � and �’ are two different words 
in source phrase �, and 0 otherwise. 

For any clique � that contains nodes in only one 
language we assume that ���� = 1 for all setting 
of the clique, which has no impact on scoring a 
phrase pair. One may wish to define a potential 
over cliques containing a phrase node and word 
nodes in target language, which could act as a form 
of target language model. One may also add edges 
in the graph so as to define potentials that capture 
more sophisticated translation dependencies. The 
optimal potential set could vary among different 
language pairs and depend to a large degree upon 
the amount and quality of training data. We leave a 
comprehensive study of features to future work. 

3 Training 

This section describes the way the parameters of 
the MRF model are estimated. Although MRFs are 
by nature generative models, it is not always ap-
propriate to train the parameters using convention-
al likelihood based approaches mainly for two rea-
sons. The first is due to the difficulty in computing 
the partition function in Equation (4), especially in 
a task of our scale. The second is due to the metric 
divergence problem (Morgan et al. 2004). That is, 
the maximum likelihood estimation is unlikely to 
be optimal for the evaluation metric under consid-
eration, as demonstrated on a variety of tasks in-
cluding machine translation (Och 2003) and infor-
mation retrieval (Metzler and Croft 2005; Gao et 
al. 2005). Therefore, we propose a large-scale dis-
criminative training approach that uses stochastic 
gradient ascent and an N-best list based expected 
BLEU as the objective function.  

We cast machine translation as a structured 
classification task (Liang et al. 2006). It maps an 
input source sentence �  to an output pair (�,�) 
where �  is the output target sentence and �  the 
Viterbi derivation of � . �  is assumed to be con-
structed during the translation process. In phrase-

based SMT, �  consists of a segmentation of the 
source and target sentences into phrases and an 
alignment between source and target phrases.  

We also assume that translations are modeled 
using a linear model parameterized by a vector �. 
Given a vector �(�,�,�) of feature functions on 
(�,�,�) , and assuming �  contains a component 
for each feature, the output pair (�,�) for a given 
input � are selected using the argmax decision rule 

(�∗,�∗) = argmax
(�,�)

���(�,�,�) (7) 
In phrase-based SMT, computing the argmax ex-
actly is intractable, so it is performed approximate-
ly by beam decoding. 

In a phrase-based SMT system equipped by a 
MRF-based phrase translation model, the parame-
ters we need to learn are � = (�,�), where � is a 
vector of a handful parameters used in the log-
linear model of Equation (2), with one weight for 
each component model; and � is a vector contain-
ing millions of weights, each for one feature func-
tion in the MRF model of Equation (3). Our meth-
od takes three steps to learn �: 

1. Given a baseline phrase-based SMT system 
and a pre-set �, we generate for each source 
sentence in training data an N-best list of 
translation hypotheses. 

2. We fix �, and optimize � with respect to an 
objective function on training data. 

3. We fix �, and optimize � using MERT (Och 
2003) to maximize the BLEU score on de-
velopment data. 

Now, we describe Steps 1 and 2 in detail. 

3.1 N-Best Generation 

Given a set of source-target sentence pairs as train-
ing data ��� ,����,� = 1 …�, we use the baseline 
phrase-based SMT system to generate for each 
source sentence �  a list of 100-best candidate 
translations, each translation �  coupled with its 
Viterbi derivation � , according to Equation (7). 
We denote the 100-best set by GEN(�). Then, each 
output pair ��,��  is labeled by a sentence-level 
BLEU score, denoted by sBLEU, which is comput-
ed according to Equation (8) (He and Deng 2012), 

sBLEU(�,��) =  � × �
�
∑ log!����� , (8) 

453



where ��  is the reference translation, and !� ,� =
1 … 4, are precisions of n-grams. While precisions 
of lower order n-grams, i.e., !� and !� , are com-
puted directly without any smoothing, matching 
counts for higher order n-grams could be sparse at 
the sentence level and need to be smoothed as 

!� = #("#$�ℎ�% �&#") + '!�
�

#(�&#") + ' , for � = 3,4 
where ' is a smoothing parameter and is set to 5, 
and !��  is the prior value of !� , whose value is 
computed as !�� = �!�����/!��� for � = 3 and 4.  �  in Equation (8) is the sentence-level brevity 
penalty, computed as  � = exp (1 − ) �

�
*, which 

differs from its corpus-level counterpart (Papineni 
et al. 2002) in two ways. First, we use a non-
clipped  �, which leads to a better approximation 
to the corpus-level BLEU computation because the 
per-sentence  � might effectively exceed unity in 
corpus-level BLEU computation, as discussed in 
Chiang et al. (2008). Second, the ratio between the 
length of reference sentence r and the length of 
translation hypothesis c is scaled by a factor ) such 
that the total length of the references on training 
data equals that of the 1-best translation hypothe-
ses produced by the baseline SMT system. In our 
experiments, the value of ) is computed, on the N-
best training data, as the ratio between the total 
length of the references and that of the 1-best 
translation hypotheses 

In our experiments we find that using sBLEU 
defined above leads to a small but consistent im-
provement over other variations of sentence-level 
BLEU proposed previously (e.g., Liang et al. 
2006). In particular, the use of the scaling factor ) 
in computing  �  makes  �  of the baseline’s 1-
best output close to perfect on training data, and 
has an effect of forcing the discriminative training 
to improve BLEU by improving n-gram precisions 
rather than by improving brevity penalty.   

3.2 Parameter Estimation 

We use an N-best list based expected BLEU, a var-
iant of that in Rosti et al. (2011), as the objective 
function for parameter optimization. Given the cur-
rent model � , the expected BLEU, denoted by 
xBLEU(�), over one training sample i.e., a labeled 
N-best list GEN(�) generated from a pair of source 
and target sentences (�,��), is defined as 

xBLEU��� 
= ∑ ����|��sBLEU(�,��)�∈�� (!) , (9) 

where sBLEU is the sentence-level BLEU, defined 
in Equation (8), and ����|�� is a normalized trans-
lation probability from �  to �  computed using 
softmax as  

����|�� = "#$(%�&�'��!,��)∑ "#$(%�&�'��!,���)�� , (10) 
where 
����. � is the translation score according 
to the current model � 

������,�� = � ∙ ���,�,�� (11) 

+∑ � ∙ �(�, �)(�,)∈� .  

The right hand side of (11) contains two terms. The 
first term is the score produced by the baseline sys-
tem, which is fixed during phrase model training. 
The second term is the translation score produced 
by the MRF model, which is updated after each 
training sample during training. Comparing Equa-
tions (2) and (11), we can view the MRF model yet 
another component model under the log linear 
model framework with its 	 being set to 1. 

Given the objective function, the parameters of 
the MRF model are optimized using stochastic 
gradient ascent. As shown in Figure 2, we go 
through the training set + times, each time is con-
sidered an epoch. For each training sample, we up-
date the model parameters as 

��') = �&*+ + , ∙ -(�&*+) (12) 
where , is the learning rate, and the gradient - is 
computed as 

���� =
,xBLEU(�)

,�
  (13) 

1 Initialize �, assuming � is fixed during training 

2 For t = 1…T (T = the total number of iterations) 

3    For each training sample (labeled 100-best list) 

4 Compute ����|�� for each translation hypothe-
sis � based on the current model 	 = (�,�) 

5       Update the model via � = � + 
 ∙ �(�), 
where 
 is the learning rate and � the gradient 
computed according to Equations (12) and (13) 

Figure 2: The algorithm of training a MRF-based 
phrase translation model. 
 

454



= ∑ U(�,�)����|���(�,�,�)(�,�) ,   
where U(�,�) = sBLEU��,���− xBLEU���. 

Two considerations regarding the development 
of the training method in Figure 2 are worth men-
tioning. They significantly simplify the training 
procedure without sacrificing much the quality of 
the trained model. First, we do not include a regu-
larization term in the objective function because 
we find early stopping and cross valuation more ef-
fective and simpler to implement. In experiments 
we produce a MRF model after each epoch, and 
test its quality on a development set by first com-
bining the MRF model with other baseline compo-
nent models via MERT and then examining BLEU 
score on the development set. We performed train-
ing for T epochs (+ = 100 in our experiments) and 
then pick the model with the best BLEU score on 
the development set. Second, we do not use the 
leave-one-out method to generate the N-best lists 
(Wuebker et al. 2010). Instead, the models used in 
the baseline SMT system are trained on the same 
parallel data on which the N-best lists are generat-
ed. One may argue that this could lead to over-
fitting. For example, comparing to the translations 
on unseen test data, the generated translation hy-
potheses on the training set are of artificially high 
quality with the derivations containing artificially 
long phrase pairs. The discrepancy between the 
translations on training and test sets could hurt the 
training performance. However, we found in our 
experiments that the impact of over-fitting on the 
quality of the trained MRF models is negligible1. 

4 Experiments 

We conducted our experiments on two Europarl 
translation tasks, German-to-English (DE-EN) and 
French-to-English (FR-EN). The data sets are pub-
lished for the shared task in NAACL 2006 Work-
shop on Statistical Machine Translation (WMT06) 
(Koehn and Monz 2006). 

For DE-EN, the training set contains 751K sen-
tence pairs, with 21 words per sentence on average. 
The official development set used for the shared 

                                                           
1 As pointed out by one of the reviewers, the fact that our 
training works fine without leave-one-out is probably due to 
the small phrase length limit (i.e., 4) we used. If a longer 
phrase limit (e.g., 7) is used the result might be different. We 
leave it to future work. 

task contains 2000 sentences. In our experiments, 
we used the first 1000 sentences as a development 
set for MERT training and optimizing parameters 
for discriminative training, such as learning rate 
and the number of iterations. We used the rest 
1000 sentences as the first test set (TEST1). We 
used the WMT06 test data as the second test set 
(TEST2), which contains 2000 sentences. 

For FR-EN, the training set contains 688K sen-
tence pairs, with 21 words per sentence on average. 
The development set contains 2000 sentences. We 
used 2000 sentences from the WMT05 shared task 
as TEST1, and the 2000 sentences from the 
WMT06 shared task as TEST2. 

Two baseline phrase-based SMT systems, each 
for one language pair, are developed as follows. 
These baseline systems are used in our experi-
ments both for comparison purpose and for gener-
ating N-best lists for discriminative training. First, 
we performed word alignment on the training set 
using a hidden Markov model with lexicalized dis-
tortion (He 2007), then extracted the phrase table 
from the word aligned bilingual texts (Koehn et al. 
2003). The maximum phrase length is set to four. 
Other models used in a baseline system include a 
lexicalized reordering model, word count and 
phrase count, and a trigram language model trained 
on the English training data provided by the 
WMT06 shared task. A fast beam-search phrase-
based decoder (Moore and Quirk 2007) is used and 
the distortion limit is set to four. The decoder is 
modified so as to output the Viterbi derivation for 
each translation hypothesis.  

The metric used for evaluation is case insensi-
tive BLEU score (Papineni et al. 2002). We also 
performed a significance test using the paired t-
test. Differences are considered statistically signif-
icant when the p-value is less than 0.05. Table 1 

                                                           
2  The official results are accessible at 
http://www.statmt.org/wmt06/shared-task/results.html  

Systems DE-EN (TEST2) FR-EN (TEST2) 
Rank-1 system 27.3 30.8 
Rank-2 system 26.0 30.7 
Rank-3 system 25.6 30.5 
Our baseline 26.0 31.4 

Table 1: Baseline results in BLEU. The results of 
top ranked systems are reported in Koehn and 
Monz (2006)2. 
  
 

455



presents the baseline results. The performance of 
our phrase-based SMT systems compares favora-
bly to the top-ranked systems, thus providing a fair 
baseline for our research. 

4.1 Results 

Table 2 shows the main results measured in BLEU 
evaluated on TEST1 and TEST2. 

Row 1 is the baseline system. Rows 2 to 5 are 
the systems enhanced by integrating different ver-
sions of the MRF-based phrase translation model. 
These versions, labeled as MRFf, are trained using 
the method described in Section 3, and differ in the 
feature classes (which are specified by the sub-
script f) incorporated in the MRF-based model. In 
this study we focused on three classes of features, 
as described in Section 2, phrase-pair features (p), 
word-pair features (t) and triplet features (tp). The 
statistics for these features are given in Table 3. 

Table 2 shows that all the MRF models lead to a 
substantial improvement over the baseline system 
across all test sets, with a statistically significant 
margin from 0.8 to 1.3 BLEU points. As expected, 
the best phrase model incorporates all of the three 
classes of features (MRFp+t+tp in Row 2). We also 
find that both MRFp and MRFt, although using 
only one class of features, perform quite well. In 
TEST2 of DE-EN and TEST1 of FR-EN, they are 
in a near statistical tie with MRFp+t and MRFp+t+tp. 

The result suggests that while the MRF models are 
very effective in modeling phrase translations, the 
features we used in this study may not fully realize 
the potential of the modeling technology. 

We also measured the sensitivity of the discrim-
inative training method to different initializations 
and training parameters. Results show that our 
method is very robust. All the MRF models in Ta-
ble 2 are trained by setting the initial feature vector 
to zero, and the learning rate ,=0.01. Figure 3 plots 
the BLEU score on development sets as a function 
of the number of epochs t. The BLEU score im-
proves quickly in the first 5 epochs, and then either 
remains flat, as on the DE-EN data, or keeps in-
creasing but in a much slower pace, as on the FR-
EN data.  

4.2  Comparing Objective Functions 

This section compares different objective functions 
for discriminative training. As shown in Table 4, 
xBLEU is compared to three widely used convex 
loss functions, i.e., hinge loss, logistic loss, and log 
loss. The hinge loss and logistic loss take into ac-
count only two hypotheses among an N-best list 
GEN: the one with the best sentence-level BLEU 
score with respect to its reference translation, de-
noted by (�∗,�∗) , called the oracle candidate 
henceforth, and the highest scored incorrect candi-
date according to the current model, denoted by 
(��,��), defined as 

# Systems DE-EN FR-EN 
TEST1 TEST2 TEST1 TEST2 

1 Baseline 26.0 26.0 31.3 31.4 
2 MRFp+t+tp 27.3

 α 27.1 α 32.4 α 32.2 α 
3 MRFp+t 27.2

 α 26.9 α 32.3 α 32.0 α 
4 MRFp 26.8

 αβ 26.7 αβ 32.2 α 31.8 αβ 
5 MRFt 26.8

 αβ 26.8 α 32.1 α 31.9 αβ 
Table 2: Main results (BLEU scores) of MRF-
based phrase translation models with different 
feature classes. The superscripts α and β indicate 
statistically significant difference (p < 0.05) 
from Baseline and  MRFp+t+tp, respectively. 
 
Feature classes # of features (weights) 

DE-EN FR-EN 
phrase-pair features (p) 2.5M 2.3M 
word-pair features (t) 12.2M 9.7M 
triplet features (tp) 13.4M 13.8M 

Table 3: Statistics of the features used in build-
ing MRF-based phrase translation models. 
 

 

 
Figure 3: BLEU score on development data (y 
axis) for DE-EN (top) and FR-EN (bottom) as a 
function of the number of epochs (x axis). 

25.8

26.0

26.2

26.4

26.6

26.8

27.0

0 20 40 60 80 100

31.2

31.3

31.4

31.5

31.6

31.7

31.8

31.9

0 20 40 60 80 100

456



(��,��) =
argmax��,��∈�� (!)\{(�∗,�∗)} 
���-(�,�,�), 

where 
���-(. ) is defined in Equation (11). Let . = ���,�∗,�∗�− ���,��,��� . The hinge loss 
under the N-best re-ranking framework is defined 
as max (0,1 − ��.) . It is easy to verify that to 
train a model using this version of hinge loss, the 
update rule of Equation (12) can be rewritten as 

��') = /�&*+ ,                   if �0 = �∗�&*+ + ,., �$ℎ��12�3 (14) 
where �0  is the highest scored candidate in GEN . 
Following Shalev-Shwartz (2012), by setting 
 =
1 , we reach the Perceptron-based training algo-
rithm that has been widely used in previous studies 
of discriminative training for SMT (e.g., Liang et 
al. 2006; Simianer et al. 2012).  

The logistic loss log(1 + exp(−��.)) leads to 
an update rule similar to that of hinge loss 

��') = /�
&*+ ,                              if �0 = �∗

�&*+ + ,��(.)., �$ℎ��12�
3 (15) 

where ����� = 1/(1 + exp(	��)). 
The log loss is widely used when a probabilistic 

interpretation of the trained model is desired, as in 
conditional random fields (CRFs) (Lafferty et al. 
2001). Given a training sample, log loss is defined 
as log����∗|��, where �∗ is the oracle translation 
hypothesis with respect to its reference translation. 
����∗|�� is computed as Equation (10). So, unlike 
hinge loss and logistic loss, log loss takes into ac-
count the distribution over all hypotheses in an N-
best list. 

The results in Table 4 suggest that the objective 
functions that take into account the distribution 

over all hypotheses in an N-best list (i.e., xBLEU 
and log loss) are more effective than the ones that 
do not. xBLEU, although it is a non-concave func-
tion, significantly outperforms the others because it 
is more closely coupled with the evaluation metric 
under consideration (i.e., BLEU).  

5 Related Work 

Among the attempts to learning phrase translation 
probabilities that go beyond pure counting of 
phrases on word-aligned corpora, Wuebker et al. 
(2010) and He and Deng (2012) are most related to 
our work. The former find phrase alignment direct-
ly on training data and update the translation prob-
abilities based on this alignment. The latter learn 
phrase translation probabilities discriminatively, 
which is similar to our approach. But He and 
Deng’s method involves multiple stages, and is not 
straightforward to implement3. Our method differs 
from previous work in its use of a MRF model that 
is simple and easy to understand, and a stochastic 
gradient ascent based training method that is effi-
cient and easy to implement. 

A large portion of previous studies on discrimi-
native training for SMT either use a handful of fea-
tures or use small training sets of a few thousand 
sentences (e.g., Och 2003; Shen et al. 2004; 
Watanabe et al. 2007; Duh and Kirchhoff 2008; 
Chiang et al. 2008; Chiang et al. 2009). Although 
there is growing interest in large-scale discrimina-
tive training (e.g., Liang et al. 2006; Tillmann and 
Zhang 2006; Blunsom et al. 2008; Hopkins and 
May 2011; Zhang et al. 2011), only recently does 
some improvement start to be observed (e.g., 
Simianer et al. 2012; He and Deng 2012). It still 
remains uncertain if the improvement is attributed 
to new features, new training algorithms, objective 
functions, or simply large amounts of training data. 
We show empirically the importance of objective 
functions. Gimple and Smith (2012) also analyze 
objective functions, but more from a theoretical 
viewpoint. 

 The proposed MRF-based translation model is 
inspired by previous work of applying MRFs for 
information retrieval (Metzler and Croft 2005), 
query expansion (Metzler et al. 2007; Gao et al. 
2012) and POS tagging (Haghighi and Klein 2006). 
                                                           
3 For comparison, the method of He and Deng (2012) also 
achieved very similar results to ours using the same experi-
mental setting, as described in Section 4. 

# Objective 
functions 

DE-EN FR-EN 
TEST

1 
TEST2 TEST1 TEST2 

1 xBLEU 27.2 26.9 32.3 32.0 
2 hinge loss 26.4α 26.2α 31.8α 31.5α 
3 logistic loss 26.3α 26.2α 31.7α 31.5α 
4 log loss 26.5α 26.2α 32.1 31.7α   

Table 4: BLEU scores of MRF-based phrase trans-
lation models trained using different objective 
functions. The MRF models use phrase-pair and 
word-pair features.  The superscript α indicates 
statistically significant difference (p < 0.05) from 
xBLUE. 
 
 

457



Another undirected graphical model that has been 
more widely used for NLP is a CRF (Lafferty et al. 
2001). An MRF differs from a CRF in that its par-
tition function is no longer observation dependent. 
As a result, learning an MRF is harder than learn-
ing a CRF using maximum likelihood estimation 
(Haghighi and Klein 2006). Our work provides an 
alternative learning method that is based on dis-
criminative training. 

6 Conclusions 

The contributions of this paper are two-fold. First, 
we present a general, statistical framework for 
modeling phrase translations via MRFs, where dif-
ferent features can be incorporated in a unified 
manner. Second, we demonstrate empirically that 
the parameters of the MRF model can be learned 
effectively using a large-scale discriminative train-
ing approach which is based on stochastic gradient 
ascent and an N-best list based expected BLEU as 
the objective function. 

In future work we strive to fully realize the po-
tential of the MRF model by developing features 
that can capture more sophisticated translation de-
pendencies that those used in this study. We will 
also explore the use of MRF-based translation 
models for translation systems that go beyond sim-
ple phrases, such as hierarchical phrase based sys-
tems (Chiang 2005) and syntax-based systems 
(Galley et al. 2004). 

References  

Bishop, C. M. 2006. Patten recognition and ma-
chine learning. Springer.  

Blunsom, P., Cohn, T., and Osborne, M. 2008. A 
discriminative latent variable models for statisti-
cal machine translation. In ACL-HLT. 

Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., 
and Mercer, R. L. 1993. The mathematics of sta-
tistical machine translation: parameter estimation. 
Computational Linguistics, 19(2): 263-311. 

Chiang, D. 2005. A hierarchical phrase-based 
model for statistical machine translation. In ACL, 
pp. 263-270. 

Chiang, D., Knight, K., and Wang, W. 2009. 
11,001 new features for statistical machine trans-
lation. In NAACL-HLT. 

Chiang, D., Marton, Y., and Resnik, P. 2008. 
Online large-margin training of syntactic and 
structural translation features. In EMNLP. 

DeNero, J., Gillick, D., Zhang, J., and Klein, D. 
2006. Why generative phrase models underper-
form surface heuristics. In Workshop on Statisti-
cal Machine Translation, pp. 31-38. 

Duh, K., and Kirchhoff, K. 2008. Beyond log-
linear models: boosted minimum error rate train-
ing for n-best ranking. In ACL. 

Galley, M., Hopkins, M., Knight, K., Marcu, D. 
2004. What's in a translation rule? In HLT-
NAACL, pp. 273-280. 

Gao, J., Xie, S., He, X., and Ali, A. 2012. Learning 
lexicon models from search logs for query ex-
pansion. In EMNLP-CoNLL, pp. 666-676. 

Gao, J., Qi, H., Xia, X., and Nie, J-Y. 2005. Linear 
discriminant model for information retrieval. In 
SIGIR, pp. 290-297. 

Gimpel, K., and Smith, N. A. 2012. Structured 
ramp loss minimization for machine translation. 
In NAACL-HLT. 

Haghighi, A., and Klein, D. 2006. Prototype-driven 
learning for sequence models. In NAACL. 

Hasan, S., Ganitkevitch, J., Ney, H., and Andres-
Fnerre, J. 2008. Triplet lexicon models for statis-
tical machine translation. In EMNLP, pp. 372-
381. 

He, X. 2007. Using word-dependent transition 
models in HMM based word alignment for sta-
tistical machine translation. In Proc. of the Se-
cond ACL Workshop on Statistical Machine 
Translation. 

He, X., and Deng, L. 2012. Maximum expected 
bleu training of phrase and lexicon translation 
models. In ACL, pp. 292-301. 

Hopkins, H., and May, J. 2011. Tuning as ranking. 
In EMNLP. 

Koehn, P. 2010. Statistical machine translation. 
Cambridge University Press. 

Koehn, P., and Monz, C. 2006. Manual and auto-
matic evaluation of machine translation between 
European languages. In Workshop on Statistical 
Machine Translation, pp. 102-121. 

458



Koehn, P., Och, F., and Marcu, D. 2003. Statistical 
phrase-based translation. In HLT-NAACL, pp. 
127-133. 

Lafferty, J., McCallum, A., and Pereira, F. 2001. 
Conditional random fields: probablistic models 
for segmenting and labeling sequence data. In 
ICML. 

Lambert, P., and Banchs, R.E. 2005. Data inferred 
multi-word expressions for statistical machine 
translation. In MT Summit X, Phuket, Thailand. 

Liang, P., Bouchard-Cote, A. Klein, D., and 
Taskar, B. 2006. An end-to-end discriminative 
approach to machine translation. In COLING-
ACL. 

Marcu, D., and Wong, W. 2002. A phrase-based, 
joint probability model for statistical machine 
translation. In EMNLP. 

Metzler, D., and Croft, B. 2005. A markov random 
field model for term dependencies. In SIGIR, pp. 
472-479. 

Metzler, D., and Croft, B. 2007. Latent concept 
expansion using markov random fields. In 
SIGIR, pp. 311-318. 

Morgan, W., Greiff, W., and Henderson, J.  2004.  
Direct maximization of average precision by 
hill-climbing with a comparison to a maximum 
entropy approach.  Technical report.  MITRE. 

Moore, R., and Quirk, C. 2007. Faster beam-search 
decoding for phrasal statistical machine 
translation. In MT Summit XI. 

Och, F., and Ney, H. 2004. The alignment template 
approach to statistical machine translation. Com-
putational Linguistics, 29(1): 19-51. 

Och, F. 2003. Minimum error rate training in 
statistical machine translation. In ACL, pp. 160-
167.  

Papinein, K., Roukos, S., Ward, T., and Zhu W-J. 
2002. BLEU: a method for automatic evaluation 
of machine translation. In ACL. 

Rosti, A-V., Hang, B., Matsoukas, S., and 
Schwartz, R. S. 2011. Expected BLEU training 
for graphs: bbn system description for WMT 
system combination task. In Workshop on 
Statistical Machine Translation. 

Shalev-Shwartz, Shai. 2012. Online learning and 
online convex optimization. Foundations and 
Trends in Machine Learning, 4(2):107-194. 

Shen, L., Sarkar, A., and Och, F. 2004. 
Discriminative reranking for machine 
translation. In HLT/NAACL. 

Simianer, P., Riezler, S., and Dyer, C. 2012. Joint 
feature selection in distributed stochasic learning 
for large-scale discriminative training in SMT. In 
ACL, pp. 11-21. 

Tillmann, C., and Zhang, T. 2006. A 
discriminative global training algorithm for 
statistical MT. In COLING-ACL. 

Watanabe, T., Suzuki, J., Tsukada, H., and Isozaki, 
H. 2007. Online large-margin training for 
statistical machine translation. In EMNLP. 

Wuebker, J., Mauser, A., and Ney, H. 2010. 
Training phrase translation models with leaving-
one-out. In ACL, pp. 475-484. 

Zhang, Y., Deng, L., He, X., and Acero, A., 2011. 
A Novel decision function and the associated 
decision-feedback learning for speech 
translation, in ICASSP. 

 

459


