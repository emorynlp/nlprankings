










































GWC Paper Clue marker


Do not do processing, when you can look up: Towards a Discrimina-

tion Net for WSD 

 

Diptesh Kanojia  

IIT Bombay 

dipteshkanojia@gmail.com 

Pushpak Bhattacharyya  

IIT Bombay 

pb@cse.iitb.ac.in 

 

Raj Dabre  
IIT Bombay 

prajdabre@gmail.com 

Siddhartha Gunti  

IIT Bombay 

siddhartha.gunti191@gmail.com  

Manish Shrivastava 

IIT Bombay 

mani.shrivastava@gmail.com 

 

Abstract 

The task of Word Sense Disambiguation 

(WSD) incorporates in its definition the role of 

‘context’. We present our work on the devel-

opment of a tool which allows for automatic 

acquisition and ranking of ‘context clues’ for 

WSD. These clue words are extracted from the 

contexts of words appearing in a large mono-

lingual corpus. These mined collection of con-

textual clues form a discrimination net in the 

sense that for targeted WSD, navigation of the 

net leads to the correct sense of a word given 

its context.  Utilizing this resource we intend 

to develop efficient and light weight WSD 

based on look up and navigation of memory-

resident knowledge base, thereby avoiding 

heavy computation which often prevents in-

corporation of any serious WSD in MT and 

search. The need for large quantities of sense 

marked data too can be reduced. 

1 Introduction 

Word Sense Disambiguation (WSD) is formally 

defined as the task of computationally identify-

ing senses of a word in a context. Chatterjee et 

al. (2011) showed that contextual evidence is the 

predominant parameter for human (and hence 

machine) sense disambiguation process.  

Joshi et al. (2013) had conducted experiments 

on eye tracking for sense disambiguation in 

which they studied the cognitive aspects of hu-

man sense disambiguation. They demonstrated 

that annotators do not focus on sentential struc-

ture but look for specific words that help identify 

the domain of the word and narrow down the 

number of senses. 

Kanojia et al. (2012) had developed a basic 

WordNet navigation and clue selection tool, 

“Sense Discrimination Tool”, which we have 

studied and improved upon. We realized that this 

tool can be improved to include many useful 

functionalities, the most important being auto-

mated clue word acquisition using word context 

(see section 2) and clue ranking based on the rel-

ative importance of a clue word. Thus, to utilize 

context efficiently we have developed a tool 

which can help mark clues for each word sense 

along with providing weights indicating their 

importance. It can also automatically generate 

clue word suggestions from large monolingual 

corpus; leading to the development of a new re-

source for context based WSD. This tool will 

later evolve into a memory resident knowledge 

base whose look up and navigation can perform 

high quality, light weight WSD. This would 

avoid the need for sense marked data which it is 

expensive to create. Such a static WSD system 

will essentially amount to look up and navigation 

to discriminate amongst word senses, thereby 

avoiding expensive computation.  

2 Clue Marker Tool1 

“Sense Discrimination Tool” developed by Ka-

nojia et al. (2012) provided simple functionality 

of allowing lexicographers to traverse WordNet 

senses and annotate them with clues which were 

added manually during this process. 

The Clue Marker Tool which we present here 

has embedded within it a number of functionali-

                                                 
1
http://www.cfilt.iitb.ac.in/~diptesh/admin/l

ogin.php 

mailto:dipteshkanojia@gmail.com
file:///C:/Users/kasutaja/AppData/Local/Microsoft/Windows/Temporary%20Internet%20Files/Content.Outlook/BDOVAM20/pb@cse.iitb.ac.in
file:///C:/Users/kasutaja/AppData/Local/Microsoft/Windows/Temporary%20Internet%20Files/Content.Outlook/BDOVAM20/prajdabre@gmail.com
file:///C:/Users/kasutaja/AppData/Local/Microsoft/Windows/Temporary%20Internet%20Files/Content.Outlook/BDOVAM20/siddhartha.gunti191@gmail.com
file:///C:/Users/kasutaja/AppData/Local/Microsoft/Windows/Temporary%20Internet%20Files/Content.Outlook/BDOVAM20/mani.shrivastava@gmail.com
http://www.cfilt.iitb.ac.in/~diptesh/admin/login.php
http://www.cfilt.iitb.ac.in/~diptesh/admin/login.php


ties which transcend beyond mere marking 

words with clues. It is language independent and 

we plan to expand it to many other languages 

later. For now we describe our work on Hindi. 

Refer to snapshots attached for each subsection. 

The tool allows for the following actions: 

2.1 Centralized User Management 

In order to track what work was done by which 

lexicographer we created a registration/login 

mechanism (Snapshot 1). This ensures that no 

one can tamper with the data and also determines 

how much work was done by a particular person. 

After the first registration the request is sent to 

the admin who can regulate the tool usage by the 

person. 

2.2 Phonetic Typing and Devanagari Key-
board 

We integrated the Google Transliterate API into 

our tool which simplifies the task of data entry. 

For people who find the phonetic typing difficult 

we have also incorporated a visual Devanagari 

keyboard. 

2.3 WordNet Synsets Navigation 

Wordnets have emerged as crucial resources for 

Natural Language Processing (NLP). They are 

lexical structures composed of synsets and se-

mantic relations (Fellbaum, 1998). Our tool al-

lows one to navigate through the complete Hindi 

WordNet (Narayan et al., 2002). One can pro-

ceed in a sequential manner by viewing previous 

or next synsets. If one wishes to view any arbi-

trary synset they can just type its ‘id’ in a search 

box and get redirected to it. One can also search 

for a word and the tool will display all the 

synsets that contain that word and the user can 

select any one.  

2.4 Add Clues 

Synset words, Gloss and Example are possible 

clue sources. We have provided a mechanism so 

that if a user selects any text on the page, it can 

be added to the clues box with a “add”/“add to 

clues” button (Snapshot 2). After the lexicogra-

pher is sure, she can “submit” the clues to make 

sure they are finally added to the database. Add-

ing clues only from synset words, gloss or exam-

ple can be quite restrictive and thus we incorpo-

rated a corpus search mechanism known as the 

concordancer search. 

2.5 Concordancer Search 

The concordancer is a tool in which, given a cor-

pus and any word to be searched, it returns a set 

of sentences which contain the word (Snapshot 

3). We provided mechanisms to control the num-

ber of sentences to be displayed for lexicogra-

pher’s convenience. Any word from the sentenc-

es returned by the concordancer search results 

can also be added to the clue word list by the 

“add to clues” button. The corpus we used, ini-

tially, consisted of around 0.22 million sentences 

from tourism, health and BBC news corpus
2
. We 

then considered incorporating 0.45 million lines 

of Wikipedia corpus and 0.97 million lines of 

crawled news data. Thus we collated a total of 

approximately 1.4 million lines of monolingual 

corpus for Hindi. 

2.6 Generate Clues automatically 

Even with the above concordancer, the lexicog-

raphers still have to go through a large number of 

sentences to decide on the clue words. The pri-

mary feature of this tool is being able to generate 

clues automatically from concordancer sentences 

(Snapshot 4). To alleviate this problem we de-

veloped a mechanism to automatically generate 

candidate clue words. The lexicographer can 

click on the “search for possible clues” button to 

get a set of words which the tool proposes to be 

prominent clues. The procedure to generate the 

clue words is given below: 

1. Select N sentences (N=10 for the results 

reported here) from the concordancer 

search results by using the first word of 

the synset as a search term. 

2. Run the Hindi part of speech CRF tagger3 

on these sentences. 

3. Select the nouns and verbs from the 

tagged words. 

4. Remove stop words, noise and duplicates. 

We select nouns and verbs because the lexicog-

raphers determined that they are the best candi-

dates for clues. These are, however, not ordered 

by relative importance, which was the objective 

of developing the tool. We thus made investiga-

tions on the association between the clue words 

and the synset words leading to some interesting 

                                                 
2
 www.cfilt.iitb.ac.in/wsd/annotated_corpus/ 

3
http://www.cfilt.iitb.ac.in/tools/POS_tagger

.zip 

 
 

http://www.cfilt.iitb.ac.in/wsd/annotated_corpus/
http://www.cfilt.iitb.ac.in/tools/POS_tagger.zip
http://www.cfilt.iitb.ac.in/tools/POS_tagger.zip


results and insights which are given in the next 

section.  

For each word in the list returned, we calcu-

lated a score and sorted the list based on this 

score. The result is a reordered list of clues pre-

sented to the lexicographers who reject the 

wrong ones. Since the best clues are at the top 

the lexicographers found their task much simpler 

than before. 

 

3 Clue Words Ranking 

We considered a set of 80 synsets and studied 

them to form an idea of the basis of ranking the 

clue words. We used Hindi Synsets for our study. 

For each synset:  

1. Generate the set of possible/candidate 

clue words by corpus searching, POS tag-

ging and filtering as described in section 

2.6. 

2. For each clue word generate scores 

3. Sort list of scored clues in descending or-

der and consider top 10 clues. 

Scoring techniques which include the co-

occurrence factor between two words seemed 

intuitive since they would rate the clues statisti-

cally. We studied some prominent scoring mech-

anisms such as contingency table measure and 

PMI given by Terra et al. (2003) amongst which 

PMI fared better. 

3.1 Pointwise Mutual Information 

PMI, a concept from information theory, is in-

dicative of the degree of association between two 

words, in this case: the current synset member 

and the potential clue word. The formulae used 

are: 

   (                 )      
 (                 )

 (      )  (         )
 

… (3.1) 

 (   ) 
 (                                      )

 (                   )
  

… (3.2) 

 ( ) 
 (                                 )

 (                   )
 

… (3.3) 

 

For words that are independent, then PMI is 0.  

3.2 Results with PMI 

We present in Table 1 above, four synsets for 

which there were strong clues after PMI based 

ranking. The clues in bold are relevant ones. 

Over the complete set of 80 words studied, an 

average of 5 relevant clue words occurred in the 

top 10 after PMI ranking. This situation freed the 

lexicographers from looking for clue words 

manually, by reading sentences from the con-

cordancer search. 

4 Synset reinforced clue ranking 

In PMI based ranking, we would only consider 

the first word of a synset to retrieve clues which 

led the tool to produce the same set of clues for 

all synsets which had this word as the first word. 

We solved this problem by reinforcing the clues 

using other members of the given synset. We 

also use a different metric for clue word selection 

and ranking. 

This modified clue acquisition mechanism, in-

stead of using just the first word of the synset, 

uses the first three words of the synset. Using 

more members of the same synset helps in high-

S. No. Word Clues 

1. 

अपराध 

(aparādha)  

(crime) 

अपराधी (aparādhi - criminal), दण्ड(daṇḍa - penalty), सजा(sajā - punishment), 

हत्या(hatyā - killing), साधुजी(sādhuji - sage), चौंका(cauṅkā - surprised), 

बंगले(bangle - bungalow), लौटा(lautā - return),घटनाक्रम(ghatnākrama – develop-

ment), सोकर(sokar - slept) 

2. 

पषु्पपत 

(puṣpita)  

(flowering)  

आनंद(ānanda - joy), वनस्पति(vanaspati - flora), स्पर्श(sparśa - touch), 

ष्थिरता(sthiratā - stability), सखी(sakhī - girlfriend), सम्पकश (samparka - contact), 

शाांष्त(śānti – silence, peace), पवन(pavana - wind), समतववि (samanvita - incorpo-

rated) 

3. 

अनाि  

(anātha)  

(orphan) 

अनाथों (anātho - orphans), अनाथालय(anāthālaya - orphanage), मां-बाप(maa-baap - 

parents), बताती(batāti - inform), मारती(mārti – to hit), चलाना(calānā – to operate), 

मैनेजर(mainējara - manager), असहाय(asahāya - helpless), खोकर(khokar - lose) 

4. 
अपमान (apamāna)  

(insult, affront)  

जनक(janak - originator), सहन(sahan – to endure), मरना(marnā – to die), 

समझ(samajh - understanding), कहे(kahe - said), भखूों(bhukho - hungry), 

परीष्ित(parikshita - tested), सूचनाओां(sucanao - information), मुुँह(mun h - mouth) 

Table 1: Clues after PMI ranking 



lighting those clues which are more important for 

a given synset.  

As before, we retrieve the sets of candidate 

clue words for each of the 3 synset words and 

then perform further processing. Instead of just 

top 10 clues we now consider as many as possi-

ble to ensure coverage. We find clue word over-

laps between the three different sets of clues ob-

tained. Those candidate clues which are present 

in more than one set are obviously good indica-

tors of sense and are given a higher ranking. This 

added metric counters polysemy, even when first 

synset word is same for different senses, since 

having clues which are generated from members 

of the given synset would help greatly in disam-

biguating using the overlapping clues. Such clue 

overlaps would be able to help us distinguish 

between fine grained word senses and eliminate 

the unrelated sense, thus improving our accuracy. 

Table 2 presents such cases where clue overlaps 

are able to distinguish specifically between the 

different senses for the same word. 

5 Error Analysis 

For every wrong clue generated we studied the 

sentences from the concordancer which lead to 

its coming up. We believe that these wrong clues 

appear due to the following reasons: 

5.1.1 Chance co-occurrence 

Consider for अनाथ (anātha) (orphan) the clue 
word मैनेजर (manager). Here अनाथ mostly oc-
curred with अनाथालय (orphanage) (a strong clue) 
which has an association with मैनेजर; but मैनेजर 
can occur with any organization like banks, 
companies and so on. Similarly, Proper nouns 
can also occur by chance without giving any in-
formation about the senses.  

5.1.2 Lack of Context 

Retrieval of relevant clue words is greatly affect-

ed by the sentences that are chosen to get the 

context. Currently, we are using 10 sentences 

from the concordancer output to get a list of po-

tential clues. Using more sentences can help in 

some cases by providing more relevant clues. We 

have refrained from increasing this number to 

avoid runtime computation time. We expect to 

reduce pre-processing time to enable us to in-

clude more sentences. 

5.1.3 Absence of word in corpus 

The tool cannot provide any clues if the word is 

not present in the monolingual corpus. This can 

happen for two reasons: if the word is rare or if 

the word is not matched by the concordancer due 

to corpus tokenization errors. We realized that 

1.4 million domain specific sentences can be re-

S. No. Word senses Top overlapped clues 

1. 

जन्मा 

(janma)  

(born) 

काल(kaal - time), मतृ्य(ुmrityu - death), रूप(roop – form, shape), आज(aaj - today), 

दषु्नया(duniya - world), युग(yuga - era) 

जन्मा 

(janma)  

(originate)  

प्रयोगशाला(prayogshalaa - laboratory), कारण(kaaran - reason), अनुसांधान(anusandhaan - 

research), अध्ययन(adhyyan - study), भाषा(bhashaa - language), तकक (tarka - argu-

ment) 

2. 

आष्दवासी 

(aadivaasi)  

(tribe) 

अभाव(abhaav - scarcity), कारण(kaaran - reason), प्रदशे(Pradesh - territory), 

ष्शिा(shiksha - education), जनजाष्त(janjaati – tribe, folk), भाषाांतरण(bhashaantaran - 

translation), ष्ववाद(vivaada - debate), अवथिापन(avasthaapan – habitation, abode) 

आष्दवासी 

(aadivaasi)  

(domicile)  

जनसांख्या(janasankhya - population), राज्य(rajya - state), सीमाओ ां(seemaon - borders), 

सांथकृष्त(sanskriti - culture), आकलनों(aakalanon - estimations) 

3. 

यूरोपीय,यूरोपी 

(yuropiya, yuropi) 

(related to Europe) 

सांघ(sangha - union), रूप(roop - form), दशेों(deshon - countries), शष्ि(shakti - power), 

ष्वश्व(vishwa - world) 

यूरोपी,यूरोपीय 

(yuropi , yuropiya) 

(European citizen) 

भाषा(bhasha - language), लोगों(logon - people), पररवार(parivaar - family) 

4. 

जल्दी 

(jaldi) 

(rapidity) 

काम(kaam - work), कारण(kaaran - reason), लोग(log - people), अष्भनय(abhinaya - act-

ing), ष्वषय(vishaya - topic), नुकसान(nuksaan - loss) 

जल्दी, सवेरे 

(jaldi, savere) 

(early morning) 

थनान(snaana - bath), सबुह(subaha - morning), ष्दन(din - day), दधू(doodh - milk), 

दरे(der - delay), व्रत(vrata – fast, fasting) 

 

Table 2: Overlapped clues 



strictive. We are currently in the process of col-

lecting more, clean and good quality, corpus 

from the web.  

6 Discrimination Net 

The tool is expected to produce a structured net 

(Figure 1) with the synset words (green) con-

nected to the clues (yellow), as neighbors, with 

weighted edges given by the scoring mechanism, 

which for now is PMI. Using wordnet sematic 

relations, relevant clues can be brought closer to 

the sense that they indicate. This structured net 

will be further augmented by inclusion of seman-

tic relations from WordNet to result in a Dis-

crimination Net. To disambiguate a word using 

this net, we will calculate a score for all the sens-

es of the word and select the sense with highest 

score based on its clues.  

6.1 Scoring mechanism and sample 

The score for a particular possible sense will be 

progressively calculated by traversing from clue 

words of the given synset in the net, while mov-

ing towards the sense word. We are in the pro-

cess of developing a more efficient scoring 

mechanism than PMI which will help us in as-

signing relevant weightage to edges in the dis-

crimination net and improve the potential clue 

score. 

7 Conclusions and Future work 

We have described the Clue Marker Tool for 

word senses which allows lexicographers to se-

lect relevant clues from a set of ranked candidate 

clues to disambiguate the sense of the word un-

der consideration. This tool, in addition to being 

a wordnet browser, is also a corpus browser by 

way of concordancer based searching. In order to 

generate high quality clues, we applied PMI 

based clue ranking and observed its efficacy. The 

tool is language independent, since by adding 

synsets of another language to the database and 

the POS tagger, the clue gathering process can be 

adapted for the new language. In future we plan 

to study better measures for clue ranking based 

on established statistical methods, along with 

augmenting the corpus to get improvements in 

generated clues. Finally, we plan to devise effi-

cient and light weight WSD methods that will 

use the discrimination net, hopefully, bringing 

about a newer understanding of WSD. 

References  

Pushpak Bhattacharyya, Debasri Chakrabarty, Dipak 

Narayan and Prabhakar Pande. 2002. An Experi-

ence in Building the Indo WordNet- a WordNet for 

Hindi, International Conference on Global Word-

Net (GWC 02), Mysore, India. 

Pushpak Bhattacharyya, Arindam Chatterjee, Salil 

Joshi, Diptesh Kanojia and Akhlesh Meena. 2011. 

A Study of Human Sense annotation process: Man 

v/s Machine. Global WordNet Conference, Matsue, 

Japan. 

Pushpak Bhattacharyya, Arindam Chatterjee, Salil 

Joshi and Diptesh Kanojia. 2012. Discrimination 

Net for Hindi. COLING, Mumbai, India. 

Pushpak Bhattacharyya, Salil Joshi and Diptesh Ka-

nojia.  2013. More than meets the eye: Study of 

Human Cognition in Sense Annotation.  NAACL 

HLT 2013, Atlanta, USA. 

Charles Clarke and Egidio Terra. 2003. Frequency 

Estimates for Statistical Word Similarity Measures. 

NAACL HLT 2003, Edmonton, Canada. 

Christiane Fellbaum. 1998. WordNet: An Electronic 

Lexical Database. Cambridge, MA: MIT Press. 

 

 

Figure 1: Discrimination Net Sample 

http://www.cse.iitb.ac.in/~pb/papers/gwn-2002.ps
http://www.cse.iitb.ac.in/~pb/papers/gwn-2002.ps
http://www.cse.iitb.ac.in/~pb/papers/gwn-2002.ps


 

 

 

 

 

 

  
Snapshot 2: Clue Marker tool home / Data entry 

Snapshot 1: Clue Marker tool user management 



 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Snapshot 4: Clue marker tool automated clue search 

Snapshot 3: Clue marker tool concordancer pane 


