



















































Demonstration of the PARLANCE system: a data-driven incremental, spoken dialogue system for interactive search


Proceedings of the SIGDIAL 2013 Conference, pages 154–156,
Metz, France, 22-24 August 2013. c©2013 Association for Computational Linguistics

Demonstration of the Parlance system: a data-driven,
incremental, spoken dialogue system for interactive search

Helen Hastie, Marie-Aude Aufaure∗, Panos Alexopoulos, Heriberto Cuayáhuitl, Nina Dethlefs,
Milica Gasic, James Henderson, Oliver Lemon, Xingkun Liu, Peter Mika, Nesrine Ben Mustapha,

Verena Rieser, Blaise Thomson, Pirros Tsiakoulis, Yves Vanrompay, Boris Villazon-Terrazas, Steve Young

email: h.hastie@hw.ac.uk. See http://parlance-project.eu for full list of affiliations

Abstract

The Parlance system for interactive
search processes dialogue at a micro-
turn level, displaying dialogue phe-
nomena that play a vital role in hu-
man spoken conversation. These di-
alogue phenomena include more nat-
ural turn-taking through rapid sys-
tem responses, generation of backchan-
nels, and user barge-ins. The Par-
lance demonstration system differen-
tiates from other incremental systems
in that it is data-driven with an infras-
tructure that scales well.

1 Introduction

The Parlance system provides interactive
search through a Spoken Dialogue System
(SDS). This SDS aims to be incremental to al-
low for more natural spoken interaction. Tra-
ditionally, the smallest unit of speech process-
ing for interactive systems has been a full ut-
terance with strict, rigid turn-taking. The
Parlance architecture, however, is an incre-
mental framework that allows for processing
of smaller ‘chunks’ of user input, which en-
ables one to model dialogue phenomena such
as barge-ins and backchannels. This work is
carried out under the FP7 EC project Par-
lance 1, the goal of which is to develop inter-
active search through speech in multiple lan-
guages. The domain for the demonstration
system is interactive search for restaurants in
San Francisco. An example dialogue is given
in Table 1.

∗Authors are in alphabetical order
1http://www.parlance-project.eu

SYS Thank you for calling the Parlance Restaurant
system. You may ask for information by cuisine
type, price range or area. How may I help you?

USR I want to find an Afghan restaurant.........which is
in the cheap price range.

SYS .......................................................[uhuhh]........
The Helmand Palace is a cheerful setting for au-
thentic Afghan cuisine.

USR What is the address and phone number?
SYS The address 2424 Van Ness Ave ....

Table 1: Example dialogue excerpt for restaurant in-
formation in San Francisco

2 Background

Previous work includes systems that can deal
with ‘micro-turns’ (i.e. sub-utterance process-
ing units), resulting in dialogues that are more
fluid and responsive. This has been backed up
by a large body of psycholinguistic literature
that indicates that human-human interaction
is in fact incremental (Levelt, 1989).
It has been shown that incremental dia-

logue behaviour can improve the user experi-
ence (Skantze and Schlangen, 2009; Baumann
et al., 2011; Selfridge et al., 2011) and en-
able the system designer to model several di-
alogue phenomena that play a vital role in
human discourse (Levelt, 1989) but have so
far been absent from systems. These dialogue
phenomena that will be demonstrated by the
Parlance system include more natural turn-
taking through rapid system responses, gener-
ation of backchannels and user barge-ins. The
system differentiates from other incremental
systems in that it is entirely data-driven with
an infrastructure that potentially scales well.

3 System Architecture

Figure 1 gives an overview of the Par-
lance system architecture, which maintains

154



LOCAL SEARCH ENGINE

AUTOMATIC 
SPEECH 

RECOGNITION

NLG

AUDIO I/O

TTS

BACKCHANNEL 
GENERATOR

IM

MIM

HUB

KNOWLEDGE 
BASE

WavePackets

1-Best Words

Segment
label

N-Best Phrase 
List

WavePackets

Micro-Turn Dialogue Act

System Dialogue Act

String Packets

String
Packets

VoIP Interface (PJSIP)

N-best 
Dialogue Act Units

 API call ( + metadata)

Search Response

Partial Dialogue Act 
(in case of 

interruption)

Partial
String

(in case of 
interruption)SPOKEN 

LANGUAGE 
UNDERSTANDING

Decode from t0 to t1

Figure 1: Overview of the Parlance system
architecture

the modularity of a traditional SDS while at
the same time allowing for complex interaction
at the micro-turn level between components.
Each component described below makes use

of the PINC (Parlance INCremental) dialogue
act schema. In this scheme, a complete dia-
logue act is made up of a set of primitive di-
alogue acts which are defined as acttype-item
pairs. The PINC dialogue act scheme supports
incrementality by allowing SLU to incremen-
tally output primitive dialogue acts whenever
a complete acttype-item pair is recognised with
sufficient confidence. The complete dialogue
act is then the set of these primitive acts out-
put during the utterance.

3.1 Recognition and Understanding

The Automatic Speech Recogniser (ASR) and
Spoken Language Understanding (SLU) com-
ponents operate in two passes. The audio in-
put is segmented by a Voice Activity Detec-
tor and then coded into feature vectors. For
the first pass of the ASR2, a fast bigram de-
coder performs continuous traceback generat-
ing word by word output. During this pass,
while the user is speaking, an SLU module
called the “segment decoder” is called incre-

2http://mi.eng.cam.ac.uk/research/dialogue/
ATK_Manual.pdf

mentally as words or phrases are recognised.
This module incrementally outputs the set of
primitive dialogue acts that can be detected
based on each utterance prefix. Here, the ASR
only provides the single best hypothesis, and
SLU only outputs a single set of primitive dia-
logue acts, without an associated probability.
On request from the Micro-turn Interaction

Manager (MIM), a second pass can be per-
formed to restore the current utterance using a
trigram language model, and return a full dis-
tribution over the complete phrase as a con-
fusion network. This is then passed to the
SLU module which outputs the set of alter-
native complete interpretations, each with its
associated probability, thus reflecting the un-
certainty in the ASR-SLU understanding pro-
cess.

3.2 Interaction Management

Figure 1 illustrates the role of the Micro-turn
Interaction Manager (MIM) component in the
overall Parlance architecture. In order to
allow for natural interaction, the MIM is re-
sponsible for taking actions such as listening to
the user, taking the floor, and generating back-
channels at the micro-turn level. Given various
features from different components, the MIM
selects a micro-turn action and sends it to the
IM and back-channel generator component to
generate a system response.

Micro-turn Interaction Manager A
baseline hand-crafted MIM was developed
using predefined rules. It receives turn-taking
information from the TTS, the audio-output
component, the ASR and a timer, and updates
turn-taking features. Based on the current
features and predefined rules, it generates
control signals and sends them to the TTS,
ASR, timer and HUB. In terms of micro-turn
taking, for example, if the user interrupts
the system utterance, the system will stop
speaking and listen to the user. The system
also outputs a short back-channel and stays in
user turn state if the user utterance provides
limited information.

Interaction Manager Once the MIM has
decided when the system should take the floor,
it is the task of the IM to decide what to say.
The IM is based on the partially observable

155



Markov decision process (POMDP) frame-
work, where the system’s decisions can be op-
timised via reinforcement learning. The model
adopted for Parlance is the Bayesian Update
of Dialogue State (BUDS) manager (Thom-
son and Young, 2010). This POMDP-based
IM factors the dialogue state into condition-
ally dependent elements. Dependencies be-
tween these elements can be derived directly
from the dialogue ontology. These elements
are arranged into a dynamic Bayesian network
which allows for their marginal probabilities
to be updated during the dialogue, compris-
ing the belief state. The belief state is then
mapped into a smaller-scale summary space
and the decisions are optimised using the nat-
ural actor critic algorithm.

HUB The HUB manages the high level flow
of information. It receives turn change infor-
mation from the MIM and sends commands
to the SLU/IM/NLG to ‘take the floor’ in the
conversation and generate a response.

3.3 Generation and TTS

We aim to automatically generate language,
trained from data, that is (1) grammatically
well formed, (2) natural, (3) cohesive and (4)
rapidly produced at runtime. Whilst the first
two requirements are important in any dia-
logue system, the latter two are key require-
ments for systems with incremental processing,
in order to be more responsive. This includes
generating back-channels, dynamic content re-
ordering (Dethlefs et al., 2012), and surface
generation that models coherent discourse phe-
nomena, such as pronominalisation and co-
reference (Dethlefs et al., 2013). Incremen-
tal surfacce generation requires rich context
awareness in order to keep track of all that has
been generated so far. We therefore treat sur-
face realisation as a sequence labelling task and
use Conditional Random Fields (CRFs), which
take semantically annotated phrase structure
trees as input, in order to represent long dis-
tance linguistic dependencies. This approach
has been compared with a number of compet-
itive state-of-the art surface realisers (Deth-
lefs et al., 2013), and can be trained from
minimally labelled data to reduce development
time and facilitate its application to new do-
mains.

The TTS component uses a trainable HMM-
based speech synthesizer. As it is a paramet-
ric model, HMM-TTS has more flexibility than
traditional unit-selection approaches and is es-
pecially useful for producing expressive speech.

3.4 Local Search and Knowledge Base

The domain ontology is populated by the local
search component and contains restaurants in
5 regional areas of San Francisco. Restaurant
search results are returned based on their lon-
gitude and latitude for 3 price ranges and 52
cuisine types.

4 Future Work

We intend to perform a task-based evaluation
using crowd-sourced users. Future versions
will use a dynamic Knowledge Base and User
Model for adapting to evolving domains and
personalised interaction respectively.

Acknowledgements
The research leading to this work was funded by the EC
FP7 programme FP7/2011-14 under grant agreement
no. 287615 (PARLANCE).

References
T. Baumann, O. Buss, and D. Schlangen. 2011. Eval-

uation and Optimisation of Incremental Processors.
Dialogue and Discourse, 2(1).

Nina Dethlefs, Helen Hastie, Verena Rieser, and Oliver
Lemon. 2012. Optimising Incremental Generation
for Spoken Dialogue Systems: Reducing the Need
for Fillers. In Proceedings of INLG, Chicago, USA.

N. Dethlefs, H. Hastie, H. Cuayáhuitl, and O. Lemon.
2013. Conditional Random Fields for Responsive
Surface Realisation Using Global Features. In Pro-
ceedings of ACL, Sofia, Bulgaria.

W. Levelt. 1989. Speaking: From Intenion to Articu-
lation. MIT Press.

E. Selfridge, I. Arizmendi, P. Heeman, and J. Williams.
2011. Stability and Accuracy in Incremental Speech
Recognition. In Proceedings of SIGDIAL, Portland,
Oregon.

G. Skantze and D. Schlangen. 2009. Incremental Dia-
logue Processing in a Micro-Domain. In Proceedings
of EACL, Athens, Greece.

B Thomson and S Young. 2010. Bayesian update of
dialogue state: A POMDP framework for spoken
dialogue systems. Computer Speech and Language,
24(4):562–588.

156


