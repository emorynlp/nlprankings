



















































Lattice-Based Minimum Error Rate Training Using Weighted Finite-State Transducers with Tropical Polynomial Weights


Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 116–125,
Donostia–San Sebastián, July 23–25, 2012. c©2012 Association for Computational Linguistics

Lattice-Based Minimum Error Rate Training using Weighted Finite-State
Transducers with Tropical Polynomial Weights

Aurelien Waite‡ Graeme Blackwood∗
‡ Department of Engineering, University of Cambridge, Trumpington Street, CB2 1PZ, U.K.

{aaw35|wjb31}@cam.ac.uk
∗ IBM T.J. Watson Research, Yorktown Heights, NY-10598

blackwood@us.ibm.com

William Byrne‡

Abstract

Minimum Error Rate Training (MERT) is a
method for training the parameters of a log-
linear model. One advantage of this method
of training is that it can use the large num-
ber of hypotheses encoded in a translation lat-
tice as training data. We demonstrate that the
MERT line optimisation can be modelled as
computing the shortest distance in a weighted
finite-state transducer using a tropical polyno-
mial semiring.

1 Introduction

Minimum Error Rate Training (MERT) (Och, 2003)
is an iterative procedure for training a log-linear sta-
tistical machine translation (SMT) model (Och and
Ney, 2002). MERT optimises model parameters
directly against a criterion based on an automated
translation quality metric, such as BLEU (Papineni
et al., 2002). Koehn (2010) provides a full descrip-
tion of the SMT task and MERT.

MERT uses a line optimisation procedure (Press
et al., 2002) to identify a range of points along a line
in parameter space that maximise an objective func-
tion based on the BLEU score. A key property of the
line optimisation is that it can consider a large set of
hypotheses encoded as a weighted directed acyclic
graph (Macherey et al., 2008), which is called a lat-
tice. The line optimisation procedure can also be ap-
plied to a hypergraph representation of the hypothe-
ses (Kumar et al., 2009).

∗The work reported in this paper was carried out while the
author was at the University of Cambridge.

It has been noted that line optimisation over a lat-
tice can be implemented as a semiring of sets of lin-
ear functions (Dyer et al., 2010). Sokolov and Yvon
(2011) provide a formal description of such a semir-
ing, which they denote the MERT semiring. The dif-
ference between the various algorithms derives from
the differences in their formulation and implemen-
tation, but not in the objective they attempt to opti-
mise.

Instead of an algebra defined in terms of trans-
formations of sets of linear functions, we propose
an alternative formulation using the tropical polyno-
mial semiring (Speyer and Sturmfels, 2009). This
semiring provides a concise formalism for describ-
ing line optimisation, an intuitive explanation of the
MERT shortest distance, and draws on techniques
in the currently active field of Tropical Geometry
(Richter-Gebert et al., 2005) 1.

We begin with a review of the line optimisation
procedure, lattice-based MERT, and the weighted
finite-state transducer formulation in Section 2. In
Section 3, we introduce our novel formulation
of lattice-based MERT using tropical polynomial
weights. Section 4 compares the performance of our
approach with k-best and lattice-based MERT.

2 Minimum Error Rate Training

Following Och and Ney (2002), we assume that
we are given a tuning set of parallel sentences
{(r1, f1), ..., (rS , fS)}, where rs is the reference
translation of the source sentence fs. We also as-
sume that sets of hypotheses Cs = {es,1, ..., es,K}

1An associated technical report contains an extended discus-
sion of our approach (Waite et al., 2011)

116



are available for each source sentence fs.
Under the log-linear model formulation with fea-

ture functions hM1 and model parameters λ
M
1 , the

most probable translation in a set Cs is selected as

ê(fs;λ
M
1 ) = argmax

e∈Cs

{
M∑

m=1

λmhm(e, fs)

}
. (1)

With an error function of the form E(rS1 , e
S
1 ) =∑S

s=1E(rs, es), MERT attempts to find model pa-
rameters to minimise the following objective:

λ̂M1 = argmin
λM1

{
S∑

s=1

E(rs, ê(fs;λ
M
1 ))

}
. (2)

Note that for MERT the hypotheses set Cs is
a k-best list of explicitly enumerated hypotheses,
whereas lattice-based MERT uses a larger space.

2.1 Line Optimisation

Although the objective function in Eq. (2) cannot be
solved analytically, the line optimisation procedure
of Och (2003) can be used to find an approxima-
tion of the optimal model parameters. Rather than
evaluating the decision rule in Eq. (1) over all pos-
sible points in parameter space, the line optimisa-
tion considers a subset of points defined by the line
λM1 +γd

M
1 , where λ

M
1 corresponds to an initial point

in parameter space and dM1 is the direction along
which to optimise. Eq. (1) can be rewritten as:

ê(fs; γ) = argmax
e∈Cs

{
(λM1 + γd

M
1 )

ThM1 (e, f s)
}

= argmax
e∈Cs

{∑

m

λmhm(e, f s)

︸ ︷︷ ︸
a(e,fs)

+γ
∑

m

dmhm(e, f s)

︸ ︷︷ ︸
b(e,fs)

}

= argmax
e∈Cs

{a(e, f s) + γb(e, f s)︸ ︷︷ ︸
`e(γ)

} (3)

This decision rule shows that each hypothesis
e ∈ Cs is associated with a linear function of γ:
`e(γ) = a(e, f s) + γb(e, f s), where a(e, f s) is the
y-intercept and b(e, f s) is the gradient. The opti-
misation problem is further simplified by defining a
subspace over which optimisation is performed. The
subspace is found by considering a form of the func-
tion in Eq. (3) defined with a range of real numbers
(Macherey et al., 2008; Och, 2003):

Env(f) = max
e∈C
{a(e, f) + γb(e, f)︸ ︷︷ ︸

`e(γ)

: γ ∈ R} (4)

γ

Env(fs; γ)

`e1
`e2 `e3

`e4

γ

E(rs, ê(fs; γ))
e4

e3

e1

γ1 γ2

Figure 1: An upper envelope and projected error. Note
that the upper envelope is completely defined by hypothe-
ses e4, e3, and e1, together with the intersection points γ1
and γ2 (after Macherey et al. (2008), Fig. 1).

For any value of γ the linear functions `e(γ) associ-
ated with Cs take (up to) K values. The function in
Eq. (4) defines the ‘upper envelope’ of these values
over all γ. The upper envelope has the form of a con-
tinuous piecewise linear function in γ. The piece-
wise linear function can be compactly described by
the linear functions which form line segments and
the values of γ at which they intersect. The example
in the upper part of Figure 1 shows how the upper
envelope associated with a set of four hypotheses
can be represented by three associated linear func-
tions and two values of γ. The first step of line op-
timisation is to compute this compact representation
of the upper envelope.

Macherey et al. (2008) use methods from com-
putational geometry to compute the upper envelope.
The SweepLine algorithm (Bentley and Ottmann,
1979) computes the upper envelope from a set of lin-
ear functions with a complexity of O(K log(K)).

Computing the upper envelope reduces the run-
time cost of line optimisation as the error function
need only be evaluated for the subset of hypotheses
in Cs that contribute to the upper envelope. These
errors are projected onto intervals of γ, as shown in
the lower part of Figure 1, so that Eq. (2) can be
readily solved.

2.2 Incorporation of Line Optimisation into
MERT

The previous algorithm finds the upper envelope
along a particular direction in parameter space over

117



a hypothesis set Cs. The line optimisation algorithm
is then embedded within a general optimisation pro-
cedure. A common approach to MERT is to select
the directions using Powell’s method (Press et al.,
2002). A line optimisation is performed on each co-
ordinate axis. The axis giving the largest decrease
in error is replaced with a vector between the initial
parameters and the optimised parameters. Powell’s
method halts when there is no decrease in error.

Instead of using Powell’s method, the Downhill
Simplex algorithm (Press et al., 2002) can be used
to explore the criterion in Eq. (2). This is done by
defining a simplex in parameter space. Directions
where the error count decreases can be identified by
considering the change in error count at the points
of the simplex. This has been applied to parameter
searching over k-best lists (Zens et al., 2007).

Both Powell’s method and the Downhill Simplex
algorithms are approaches based on heuristics to se-
lect lines λM1 + γd

M
1 . It is difficult to find theoret-

ically sound reasons why one approach is superior.
Therefore Cer et al. (2008) instead choose the di-
rection vectors dM1 at random. They report that this
method can find parameters that are as good as the
parameters produced by more complex algorithms.

2.3 Lattice Line Optimisation
Macherey et al. (2008) describe a procedure for con-
ducting line optimisation directly over a word lattice
encoding the hypotheses in Cs. Each lattice edge is
labelled with a word e and has a weight defined by
the vector of word specific feature function values
hM1 (e, f) so that the weight of a path in the lattice
is found by summing over the word specific feature
function values on that path. Given a line through
parameter space, the goal is to extract from a lattice
its upper envelope and the associated hypotheses.

Their algorithm proceeds node by node through
the lattice. Suppose that for a state q the upper enve-
lope is known for all the partial hypotheses on all
paths leading to q. The upper envelope defines a
set of functions {`ẽ1(γ), ..., `ẽN (γ)} over the partial
hypotheses ẽn. Two operations propagate the upper
envelope to other lattice nodes.

We refer to the first operation as the ‘extend’ op-
eration. Consider a single edge from state q to state
q′. This edge defines a linear function associated
with a single word `e(γ). A path following this edge

transforms all the partial hypotheses leading to q by
concatenating the word e. The upper envelope as-
sociated with the edge from q to q′ is changed by
adding `e(γ) to the set of linear functions. The in-
tersection points are not changed by this operation.

The second operation is a union. Suppose q′

has another incoming edge from a state q′′ where
q 6= q′′. There are now two upper envelopes rep-
resenting two sets of linear functions. The first up-
per envelope is associated with the paths from the
initial state to state q′ via the state q. Similarly the
second upper envelope is associated with paths from
the initial state to state q′ via the state q′′. The upper
envelope that is associated with all paths from the
initial state to state q′ via both q and q′′ is the union
of the two sets of linear functions. This union is no
longer a compact representation of the upper enve-
lope as there may be functions which never achieve
a maximum for any value of γ. The SweepLine al-
gorithm (Bentley and Ottmann, 1979) is applied to
the union to discard redundant linear functions and
their associated hypotheses (Macherey et al., 2008).

The union and extend operations are applied to
states in topological order until the final state is
reached. The upper envelope computed at the final
state compactly encodes all the hypotheses that max-
imise Eq. (1) along the line λM1 + γd

M
1 . Macherey’s

theorem (Macherey et al., 2008) states that an upper
bound for the number of linear functions in the up-
per envelope at the final state is equal to the number
of edges in the lattice.

2.4 Line Optimisation using WFSTs
Formally, a weighted finite-state transducer (WFST)
T = (Σ,∆, Q, I, F,E, λ, ρ) over a semiring
(K,⊕,⊗, 0̄, 1̄) is defined by an input alphabet Σ, an
output alphabet ∆, a set of states Q, a set of initial
states I ⊆ Q, a set of final states F ⊆ Q, a set
of weighted transitions E, an initial state weight as-
signment λ : I → K, and a final state weight assign-
ment ρ : F → K (Mohri et al., 2008). The weighted
transitions of T form the setE ⊆ Q×Σ×∆×K×Q,
where each transition includes a source state fromQ,
input symbol from Σ, output symbol from ∆, cost
from the weight set K, and target state from Q.

For each state q ∈ Q, let E[q] denote the set of
edges leaving state q. For each transition e ∈ E[q],
let p[e] denote its source state, n[e] its target state,

118



and w[e] its weight. Let π = e1 · · · eK denote a
path in T from state p[e1] to state n[eK ], so that
n[ek−1] = p[ek] for k = 2, . . . ,K. The weight as-
sociated by T to path π is the generalised product ⊗
of the weights of the individual transitions:

w[π] =

K⊗

k=1

w[ek] = w[e1]⊗ · · · ⊗ w[eK ] (5)

If P(q) denotes the set of all paths in T start-
ing from an initial state in I and ending in state q,
then the shortest distance d[q] is defined as the gen-
eralised sum ⊕ of the weights of all paths leading to
q (Mohri, 2002):

d[q] = ⊕π∈P(q)w[π] (6)
For some semirings, such as the tropical semir-

ing, the shortest distance is the weight of the short-
est path. For other semirings, the shortest distance
is associated with multiple paths (Mohri, 2002); for
these semirings there are shortest distances but need
not any be shortest paths. That will be the case in
what follows. However, the shortest distance algo-
rithms rely only on general properties of semirings,
and once the semiring is specified, the general short-
est distance algorithms can be directly employed.

Sokolov and Yvon (2011) define the MERT
semiring based on operations described in the pre-
vious section. The extend operation is used for the
generalised product ⊗. The union operation fol-
lowed by an application of the SweepLine algorithm
becomes the generalised sum ⊕. The word lattice
is then transformed for an initial parameter λM1 and
direction dM1 . The weight of edge is mapped from
a word specific feature function hM1 (e, f) to a word
specific linear function `e(γ). The weight of each
path is the generalised product ⊗ of the word spe-
cific feature linear functions. The upper envelope is
the shortest distance of all the paths in the WFST.

3 The Tropical Polynomial Semiring
In this section we introduce the tropical polynomial
semiring (Speyer and Sturmfels, 2009) as a replace-
ment for the MERT semiring (Sokolov and Yvon,
2011). We then provide a full description and a
worked example of our MERT algorithm.

3.1 Tropical Polynomials
A polynomial is a linear combination of a finite
number of non-zero monomials. A monomial con-

sists of a real valued coefficient multiplied by one or
more variables, and these variables may have expo-
nents that are non-negative integers. In this section
we limit ourselves to a description of a polynomial
in a single variable. A polynomial function is de-
fined by evaluating a polynomial:

f(γ) = anγ
n + an−1γn−1 + · · ·+ a2γ2 + a1γ+ a0

A useful property of these polynomials is that they
form a ring2 (Cox et al., 2007) and therefore are can-
didates for use as weights in WFSTs.

Speyer and Sturmfels (2009) apply the defini-
tion of a classical polynomial to the formulation of
a tropical polynomial. The tropical semiring uses
summation for the generalised product ⊗ and a min
operation for the generalised sum ⊕. In this form,
let γ be a variable that represents an element in the
tropical semiring weight set R ∪ {−∞,+∞}. We
can write a monomial of γ raised to an integer expo-
nent as

γi = γ ⊗ · · · ⊗ γ︸ ︷︷ ︸
i

where i is a non-negative integer. The monomial
can also have a constant coefficient: a⊗ γi, a ∈ R.
We can define a function that evaluates a tropical
monomial for a particular value of γ. For example,
the tropical monomial a⊗ γi is evaluated as:

f(γ) = a⊗ γi = a+ iγ
This shows that a tropical monomial is a linear

function with the coefficient a as its y-intercept and
the integer exponent i as its gradient. A tropical
polynomial is the generalised sum of tropical mono-
mials where the generalised sum is evaluated using
the min operation. For example:

f(γ) = (a⊗ γi)⊕ (b⊗ γj) = min(a+ iγ, b+ jγ)
Evaluating tropical polynomials in classical arith-
metic gives the minimum of a finite collection of
linear functions.

Tropical polynomials can also be multiplied by a
monomial to form another tropical polynomial. For
example:

f(γ) = [(a⊗ γi)⊕ (b⊗ γj)]⊗ (c⊗ γk)
= [(a+ c)⊗ γi+k]⊕ [(b+ c)⊗ γj+k]
= min((a+ c) + (i+ k)γ, (b+ c) + (j + k)γ)

2A ring is a semiring that includes negation.

119



Our re-formulation of Eq. (4) negates the feature
function weights and replaces the argmax by an
argmin. This allows us to keep the usual formu-
lation of tropical polynomials in terms of the min
operation when converting Eq. (4) to a tropical rep-
resentation. What remains to be addressed is the role
of integer exponents in the tropical polynomial.

3.2 Integer Realisations for Tropical
Monomials

In the previous section we noted that the function
defined by the upper envelope in Eq. (4) is simi-
lar to the function represented by a tropical poly-
nomial. A significant difference is that the formal
definition of a polynomial only allows integer expo-
nents, whereas the gradients in Eq. (4) are real num-
bers. The upper envelope therefore encodes a larger
set of model parameters than a tropical polynomial.

To create an equivalence between the upper enve-
lope and tropical polynomials we can approximate
the linear functions {`e(γ) = a(e, f s)+γ · b(e, f s)}
that compose segments of the upper envelope. We
define ã(e, f s) = [a(e, f s) · 10n]int and b̃(e, f s) =
[b(e, f s)·10n]int where [x]int denotes the integer part
of x. The approximation to `e(γ) is:

`e(γ) ≈ ˜̀e(γ) =
ã(e, f s)

10n
+ γ · b̃(e, f s)

10n
(7)

The result of this operation is to approximate
the y-intercept and gradient of `e(γ) to n decimal
places. We can now represent the linear function
˜̀
e(γ) as the tropical monomial−ã(e, fs)⊗γ−b̃(e,fs).

Note that ã(e, fs) and b̃(e, fs) are negated since trop-
ical polynomials define the lower envelope as op-
posed to the upper envelope defined by Eq. (4).

The linear function represented by the tropical
monomial is a scaled version of `e(γ), but the up-
per envelope is unchanged (to the accuracy allowed
by n). If for a particular value of γ, `ei(γ) > `ej (γ),
then ˜̀ei(γ) > ˜̀ej (γ). Similarly, the boundary
points are unchanged: if `ei(γ) = `ej (γ), then
˜̀
ei(γ) =

˜̀
ej (γ). Setting n to a very large value re-

moves numerical differences between the upper en-
velope and the tropical polynomial representation,
as shown by the identical results in Table 1.

Using a scaled version of `e(γ) as the basis for a
tropical monomial may cause negative exponents to
be created. Following Speyer and Sturmfels (2009),

γ

f(γ)

0

a⊗ γi

(a⊗ γi)⊕ (b⊗ γj)⊕ (c⊗ γk)

b⊗ γj
c⊗ γk

Figure 2: Redundant terms in a tropical polynomial. In
this case (a⊗γi)⊕(b⊗γj)⊕(c⊗γk) = (a⊗γi)⊕(c⊗γk).

we widen the definition of a tropical polynomial to
allow for these negative exponents.

3.3 Canonical Form of a Tropical Polynomial

We noted in Section 2.1 that linear functions induced
by some hypotheses do not contribute to the upper
envelope and can be discarded. Terms in a tropi-
cal polynomial can have similar behaviour. Figure
2 plots the lines associated with the three terms of
the example polynomial function f(γ) = (a⊗γi)⊕
(b⊗γj)⊕(c⊗γk). We note that the piecewise linear
function can also be described with the polynomial
f(γ) = (a⊗γi)⊕(c⊗γk). The latter representation
is simpler but equivalent.

Having multiple representations of the same poly-
nomial causes problems when implementing the
shortest distance algorithm defined by Mohri (2002).
This algorithm performs an equality test between
values in the semiring used to weight the WFST. The
behaviour of the equality test is ambiguous when
there are multiple polynomial representations of the
same piecewise linear function. We therefore re-
quire a canonical form of a tropical polynomial so
that a single polynomial represents a single function.
We define the canonical form of a tropical polyno-
mial to be the tropical polynomial that contains only
the monomial terms necessary to describe the piece-
wise linear function it represents.

We remove redundant terms from a tropical poly-
nomial after computing the generalised sum. For a
tropical polynomial of one variable we can take ad-
vantage of the equivalence with Lattice MERT and
compute the canonical form using the SweepLine al-
gorithm (Bentley and Ottmann, 1979). Each term

120



corresponds to a linear function; linear functions
that do not contribute to the upper envelope are dis-
carded. Only monomials which correspond to the
remaining linear functions are kept in the canonical
form. The canonical form of a tropical polynomial
thus corresponds to a unique and minimal represen-
tation of the upper envelope.

3.4 Relationship to the Tropical Semiring

Tropical monomial weights can be transformed into
regular tropical weights by evaluating the tropical
monomial for a specific value of γ. For example, a
tropical polynomial evaluated at γ = 1 corresponds
to the tropical weight:

f(1) = −ã(e, fs)⊗ 1−b̃(e,fs) = −ã(e, fs)− b̃(e, fs)
Each monomial term in the tropical polynomial
shortest distance represents a linear function. The
intersection points of these linear functions define
intervals of γ (as in Fig. 1). This suggests an alter-
nate explanation for what the shortest distance com-
puted using the tropical polynomial semiring rep-
resents. Conceptually, there is a continuum of lat-
tices which have identical edges and vertices but
with varying, real-valued edge weights determined
by values of γ ∈ R, so that each lattice in the contin-
uum is indexed by γ. The tropical polynomial short-
est distance agrees with the shortest distance through
each lattice in the continuum.

Our alternate explanation is consistent with the
Theorem of Macherey (Section 2.3), as there could
never be more paths than edges in the lattice. There-
fore the upper bound for the number of monomial
terms in the tropical polynomial shortest distance is
the number of edges in the input lattice.

We can use the mapping to the tropical semiring
to compute the error surface. Let us assume we have
n + 1 intervals separated by n interval boundaries.
We use the midpoint of each interval to transform the
lattice of tropical monomial weights into a lattice of
tropical weights. The sequence of words that label
the shortest path through the transformed lattice is
the MAP hypothesis for the interval. The shortest
path can be extracted using the WFST shortest path
algorithm (Mohri and Riley, 2002). As a technical
matter, the midpoints of the first interval [−∞, γ1)
and last interval [γn,∞) are not defined. We there-
fore evaluate the tropical polynomial at γ = γ1 − 1

and γ = γn + 1 to find the MAP hypothesis in the
first and last intervals, respectively.

3.5 The TGMERT Algorithm

We now describe an alternative algorithm to Lat-
tice MERT that is formulated using the tropical
polynomial shortest distance in one variable. We
call the algorithm TGMERT, for Tropical Geome-
try MERT. As input to this procedure we use a word
lattice weighted with word specific feature functions
hM1 (e, f), a starting point λ

M
1 , and a direction d

M
1 in

parameter space.

1. Convert the word specific feature functions
hM1 (e, f) to a linear function `e(γ) using λ

M
1

and dM1 , as in Eq. (3).
2. Convert `e(γ) to ˜̀e(γ) by approximating y-

intercepts and gradients to n decimal places, as
in Eq. (7).

3. Convert ˜̀e(γ) in Eq. (7) to the tropical mono-
mial −ã(e, fs)⊗ γ−b̃(e,fs).

4. Compute the WFST shortest distance to the exit
states (Mohri, 2002) with generalised sum ⊕
and generalised product ⊗ defined by the trop-
ical polynomial semiring. The resulting trop-
ical polynomial represents the upper envelope
of the lattice.

5. Compute the intersection points of the linear
functions corresponding to the monomial terms
of the tropical polynomial shortest distance.
These intersection points define intervals of γ
in which the MAP hypothesis does not change.

6. Using the midpoint of each interval convert the
tropical monomial−ã(e, fs)⊗γ−b̃(e,fs) to a reg-
ular tropical weight. Find the MAP hypothesis
for this interval by extracting the shortest path
using the WFST shortest path algorithm (Mohri
and Riley, 2002).

3.6 TGMERT Worked Example

This section presents a worked example showing
how we can use the TGMERT algorithm to compute
the upper envelope of a lattice. We start with a three
state lattice with a two dimensional feature vector
shown in the upper part of Figure 3.

We want to optimise the parameters along a line
in two-dimensional feature space. Suppose the ini-
tial parameters are λ21 = [0.7, 0.4] and the direction

121



0 1 2

z/[−0.2, 0.7]′

x/[−1.4, 0.3]′

y/[−0.9,−0.8]′
z/[−0.2,−0.6]′

0 1 2

z/−14⊗ γ−29

x/86⊗ γ27

y/95⊗ γ67
z/38⊗ γ36

Figure 3: The upper part is a translation lattice with 2-
dimensional log feature vector weights hM1 (e, f) where
M = 2. The lower part is the lattice from the upper part
with weights transformed into tropical monomials.

is d21 = [0.3, 0.5]. Step 1 of the TGMERT algorithm
(Section 3.5) maps each edge weight to a word spe-
cific linear function. For example, the weight of the
edge labelled “x” between states 0 and 1 is trans-
formed as follows:

`e(γ) =
2∑

m=1

λmh
M
1 (e, f)

︸ ︷︷ ︸
a(e,f)

+γ

2∑

m=1

dmh
M
1 (e,fs)

︸ ︷︷ ︸
b(e,f)

= 0.7 · −1.4 + 0.4 · 0.3︸ ︷︷ ︸
a(e,f)

+γ · 0.3 · −1.4 + 0.5 · 0.3︸ ︷︷ ︸
b(e,f)

= −0.86− 0.27γ
Step 2 of the TGMERT algorithm converts the

word specific linear functions into tropical mono-
mial weights. Since all y-intercepts and gradients
have a precision of two decimal places, we scale the
linear functions `e(γ) by 102 and negate them to cre-
ate tropical monomials (Step 3). The edge labelled
“x” now has the monomial weight of 86⊗ γ27. The
transformed lattice with weights mapped to the trop-
ical polynomial semiring is shown in the lower part
of Figure 3.

We can now compute the shortest distance
(Mohri, 2002) from the transformed example lattice
with tropical monomial weights. There are three
unique paths through the lattice corresponding to
three distinct hypotheses. The weights associated
with these hypotheses are:

−14⊗ γ−29 ⊗ 38⊗ γ36 = 24⊗ γ7 z z
86⊗ γ27 ⊗ 38⊗ γ36 = 122⊗ γ63 x z
95⊗ γ67 ⊗ 38⊗ γ36 = 133⊗ γ103 y z

0 1 2

z/-2.4

x/75.2

y/68.2

z/23.6

0 1 2

z/55.6

x/21.2

y/-65.8

z/-48.4

Figure 4: The lattice in the lower part of Figure 3 trans-
formed to regular tropical weights: γ = −0.4 (top) and
γ = −1.4 (bottom).

The shortest distance from initial to final state is
the generalised sum of the path weights: (24⊗γ7)⊕
(133⊗ γ103). The monomial term 122⊗ γ63 corre-
sponding to “x z” can be dropped because it is not
part of the canonical form of the polynomial (Sec-
tion 3.3). The shortest distance to the exit state can
be represented as the minimum of two linear func-
tions: min(24 + 7γ, 133 + 103γ).

We now wish to find the hypotheses that define
the error surface by performing Steps 5 and 6 of the
TGMERT algorithm. These two linear functions de-
fine two intervals of γ. The linear functions intersect
at γ ≈ −1.4; at this value of γ the MAP hypothesis
changes. Two lattices with regular tropical weights
are created using γ = −0.4 and γ = −2.4. These
are shown in Figure 4. For the lattice shown in the
upper part the value for the edge labelled “x” is com-
puted as 86⊗−0.427 = 86 + 0.4 · 27 = 75.2.

When γ = −0.4 the lattice in the upper part in
Figure 4 shows that the shortest path is associated
with the hypothesis “z z”, which is the MAP hy-
pothesis for the range γ < 1.4. The lattice in the
lower part of Figure 4 shows that when γ = −2.4
the shortest path is associated with the hypothesis
“y z”, which is the MAP hypothesis when γ > 1.4.

3.7 TGMERT Implementation

TGMERT is implemented using the OpenFst Toolkit
(Allauzen et al., 2007). A weight class is added
for tropical polynomials which maintains them in
canonical form. The ⊗ and ⊕ operations are im-
plemented for piece-wise linear functions, with the
SweepLine algorithm included as discussed.

122



Iteration Arabic-to-English
MERT LMERT TGMERT

Tune Test Tune Test Tune Test

1 36.2 36.2 36.242.1 40.9 39.7 38.9 39.7 38.9

2 42.0 44.5 44.545.1 43.2 45.8 44.3 45.8 44.3

3 44.545.5 44.1

4 45.645.7 44.0

Iteration Chinese-to-English
MERT LMERT TGMERT

Tune Test Tune Test Tune Test

1 19.5 19.5 19.525.3 16.7 29.3 22.6 29.3 22.6

2 16.4 22.5 22.518.9 23.9 31.4 32.1 31.4 32.1

3 23.6 31.6 31.628.2 29.1 32.2 32.5 32.2 32.5

4 29.2 32.2 32.231.3 31.5 32.2 32.5 32.2 32.5

5 31.331.8 32.1

6 32.132.4 32.3

7 32.432.4 32.3

Table 1: GALE AR→EN and ZH→EN BLEU scores
by MERT iteration. BLEU scores at the initial and final
points of each iteration are shown for the Tune sets.

4 Experiments

We compare feature weight optimisation using k-
best MERT (Och, 2003), lattice MERT (Macherey
et al., 2008), and tropical geometry MERT. We refer
to these as MERT, LMERT, and TGMERT, resp.

We investigate MERT performance in the context
of the Arabic-to-English GALE P4 and Chinese-
to-English GALE P3 evaluations3. For Arabic-to-
English translation, word alignments are generated
over around 9M sentences of GALE P4 parallel text.
Following de Gispert et al. (2010b), word align-
ments for Chinese-to-English translation are trained
from a subset of 2M sentences of GALE P3 paral-
lel text. Hierarchical rules are extracted from align-
ments using the constraints described in (Chiang,
2007) with additional count and pattern filters (Igle-

3See http://projects.ldc.upenn.edu/gale/data/catalog.html

sias et al., 2009b). We use a hierarchical phrase-
based decoder (Iglesias et al., 2009a; de Gispert et
al., 2010a) which directly generates word lattices
from recursive translation networks without any in-
termediate hypergraph representation (Iglesias et al.,
2011). The LMERT and TGMERT optimisation al-
gorithms are particularly suitable for this realisation
of hiero in that the lattice representation avoids the
need to use the hypergraph formulation of MERT
given by Kumar et al. (2009).

MERT optimises the weights of the following fea-
tures: target language model, source-to-target and
target-to-source translation models, word and rule
penalties, number of usages of the glue rule, word
deletion scale factor, source-to-target and target-to-
source lexical models, and three count-based fea-
tures that track the frequency of rules in the parallel
data (Bender et al., 2007). In both Arabic-to-English
and Chinese-to-English experiments all MERT im-
plementations start from a flat feature weight initial-
ization. At each iteration new lattices and k-best lists
are generated from the best parameters at the previ-
ous iteration, and each subsequent iteration includes
100 hypotheses from the previous iteration. For
Arabic-to-English we consider an additional twenty
random starting parameters at every iteration. All
translation scores are reported for the IBM imple-
mentation of BLEU using case-insensitive match-
ing. We report BLEU scores for the Tune set at the
start and end of each iteration.

The results for Arabic-to-English and Chinese-
to-English are shown in Table 1. Both TGMERT
and LMERT converge to a small gain over MERT
in fewer iterations, consistent with previous re-
ports (Macherey et al., 2008).

5 Discussion

We have described a lattice-based line optimisation
algorithm which can be incorporated into MERT
for parameter tuning of SMT systems and systems
based on log-linear models. Our approach recasts
the optimisation procedure used in MERT in terms
of Tropical Geometry; given this formulation imple-
mentation is relatively straightforward using stan-
dard WFST operations and algorithms.

123



References

C. Allauzen, M. Riley, J. Schalkwyk, W. Skut, and
M. Mohri. 2007. OpenFst: A general and efficient
weighted finite-state transducer library. In Proceed-
ings of the Ninth International Conference on Imple-
mentation and Application of Automata, pages 11–23.

O. Bender, E. Matusov, S. Hahn, S. Hasan, S. Khadivi,
and H. Ney. 2007. The RWTH Arabic-to-English spo-
ken language translation system. In Automatic Speech
Recognition Understanding, pages 396 –401.

J.L. Bentley and T.A. Ottmann. 1979. Algorithms for
reporting and counting geometric intersections. Com-
puters, IEEE Transactions on, C-28(9):643 –647.

Daniel Cer, Daniel Jurafsky, and Christopher D. Man-
ning. 2008. Regularization and search for minimum
error rate training. In Proceedings of the Third Work-
shop on Statistical Machine Translation, pages 26–34.

David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33.

David A. Cox, John Little, and Donal O’Shea. 2007.
Ideals, Varieties, and Algorithms: An Introduction to
Computational Algebraic Geometry and Commutative
Algebra, 3/e (Undergraduate Texts in Mathematics).

Adrià de Gispert, Gonzalo Iglesias, Graeme Blackwood,
Eduardo R. Banga, and William Byrne. 2010a. Hier-
archical phrase-based translation with weighted finite-
state transducers and shallow-n grammars. Computa-
tional Linguistics, 36(3):505–533.

Adrià de Gispert, Juan Pino, and William Byrne. 2010b.
Hierarchical phrase-based translation grammars ex-
tracted from alignment posterior probabilities. In Pro-
ceedings of the 2010 Conference on Empirical Meth-
ods in Natural Language Processing, pages 545–554.

Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan
Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan,
Vladimir Eidelman, and Philip Resnik. 2010. cdec: A
decoder, alignment, and learning framework for finite-
state and context-free translation models. In Proceed-
ings of the ACL 2010 System Demonstrations, pages
7–12, July.

Gonzalo Iglesias, Adrià de Gispert, Eduardo R. Banga,
and William Byrne. 2009a. Hierarchical phrase-based
translation with weighted finite state transducers. In
Proceedings of HLT: The 2009 Annual Conference of
the North American Chapter of the Association for
Computational Linguistics, pages 433–441.

Gonzalo Iglesias, Adrià de Gispert, Eduardo R. Banga,
and William Byrne. 2009b. Rule filtering by pattern
for efficient hierarchical translation. In Proceedings
of the 12th Conference of the European Chapter of
the Association for Computational Linguistics, pages
380–388.

Gonzalo Iglesias, Cyril Allauzen, William Byrne, Adrià
de Gispert, and Michael Riley. 2011. Hierarchical
phrase-based translation representations. In Proceed-
ings of the 2011 Conference on Empirical Methods in
Natural Language Processing, pages 1373–1383. As-
sociation for Computational Linguistics.

Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press.

Shankar Kumar, Wolfgang Macherey, Chris Dyer, and
Franz Och. 2009. Efficient minimum error rate train-
ing and minimum bayes-risk decoding for translation
hypergraphs and lattices. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP, pages 163–171.

Wolfgang Macherey, Franz Och, Ignacio Thayer, and
Jakob Uszkoreit. 2008. Lattice-based minimum error
rate training for statistical machine translation. In Pro-
ceedings of the 2008 Conference on Empirical Meth-
ods in Natural Language Processing, pages 725–734.

Mehryar Mohri and Michael Riley. 2002. An efficient
algorithm for the n-best-strings problem. In Proceed-
ings of the International Conference on Spoken Lan-
guage Processing 2002.

Mehryar Mohri, Fernando C. N. Pereira, and Michael Ri-
ley. 2008. Speech recognition with weighted finite-
state transducers. Handbook on Speech Processing
and Speech Communication.

Mehryar Mohri. 2002. Semiring frameworks and algo-
rithms for shortest-distance problems. J. Autom. Lang.
Comb., 7(3):321–350.

Franz Josef Och and Hermann Ney. 2002. Discrimi-
native training and maximum entropy models for sta-
tistical machine translation. In Proceedings of the
40th Annual Meeting on Association for Computa-
tional Linguistics, pages 295–302.

Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting on Association for Computa-
tional Linguistics, pages 160–167.

K. A. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
BLEU: a method for automatic evaluation of ma-
chine translation. In Proceedings of the 40th Annual
Meeting on Association for Computational Linguis-
tics, pages 311–318.

W. H. Press, W. T. Vetterling, S. A. Teukolsky, and B. P.
Flannery. 2002. Numerical Recipes in C++: the art
of scientific computing. Cambridge University Press.

J. Richter-Gebert, B. Sturmfels, and T. Theobald. 2005.
First steps in tropical geometry. In Idempotent mathe-
matics and mathematical physics.

Artem Sokolov and François Yvon. 2011. Minimum er-
ror rate training semiring. In Proceedings of the Euro-
pean Association for Machine Translation.

124



David Speyer and Bernd Sturmfels. 2009. Tropical
mathematics. Mathematics Magazine.

Aurelien Waite, Graeme Blackwood, and William Byrne.
2011. Lattice-based minimum error rate training using
weighted finite-state transducers with tropical polyno-
mial weights. Technical report, Department of Engi-
neering, University of Cambridge.

Richard Zens, Sasa Hasan, and Hermann Ney. 2007.
A systematic comparison of training criteria for sta-
tistical machine translation. In Proceedings of the
2007 Joint Conference on Empirical Methods in Natu-
ral Language Processing and Computational Natural
Language Learning, pages 524–532.

125


