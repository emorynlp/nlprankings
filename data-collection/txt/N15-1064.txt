



















































Jointly Modeling Inter-Slot Relations by Random Walk on Knowledge Graphs for Unsupervised Spoken Language Understanding


Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 619–629,
Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics

Jointly Modeling Inter-Slot Relations by Random Walk on Knowledge
Graphs for Unsupervised Spoken Language Understanding

Yun-Nung Chen, William Yang Wang, and Alexander I. Rudnicky
School of Computer Science, Carnegie Mellon University

5000 Forbes Avenue, Pittsburgh, PA 15213-3891, USA
{yvchen, yww, air}@cs.cmu.edu

Abstract

A key challenge of designing coherent seman-
tic ontology for spoken language understand-
ing is to consider inter-slot relations. In prac-
tice, however, it is difficult for domain experts
and professional annotators to define a coher-
ent slot set, while considering various lexi-
cal, syntactic, and semantic dependencies. In
this paper, we exploit the typed syntactic de-
pendency theory for unsupervised induction
and filling of semantics slots in spoken dia-
logue systems. More specifically, we build
two knowledge graphs: a slot-based seman-
tic graph, and a word-based lexical graph.
To jointly consider word-to-word, word-to-
slot, and slot-to-slot relations, we use a ran-
dom walk inference algorithm to combine the
two knowledge graphs, guided by dependency
grammars. The experiments show that con-
sidering inter-slot relations is crucial for gen-
erating a more coherent and compete slot set,
resulting in a better spoken language under-
standing model, while enhancing the inter-
pretability of semantic slots.

1 Introduction

An important requirement for building a success-
ful spoken dialogue system (SDS) is to define a co-
herent slot set and the corresponding slot-fillers for
the spoken language understanding (SLU) compo-
nent. Unfortunately, since the semantic slots are of-
ten mutually-related, it is non-trivial for domain ex-
perts and professional annotators to design a such
slot set for semantic representation of SLU.

Considering a restaurant domain (Henderson et

al., 2012), “restaurant” is the target slot, and impor-
tant adjective modifiers such as “Asian” (the restau-
rant type) and “cheap” (the price of the restaurant)
should be included in the slot set, so that the se-
mantic representation of SLU can be more coherent
and complete. In this case, it is challenging to de-
sign such a coherent and complete slot set manually,
while considering various lexical, syntactic, and se-
mantic dependencies.

Instead of considering slots independently, this
paper takes a data-driven approach to model word-
to-word relations via syntactic dependencies and
further infer slot-to-slot relations. To do this, we
incorporate the typed dependency grammar the-
ory (De Marneffe and Manning, 2008) in a state-
of-the-art frame-semantic driven unsupervised slot
induction framework (Chen et al., 2013b). In par-
ticular, we build two knowledge graphs: a slot-
based semantic knowledge graph, and a word-based
lexical knowledge graph. Using typed dependency
triples, we then study the stochastic relations be-
tween slots and words, using a mutually-reinforced
random walk inference procedure to combine the
two knowledge graphs. In evaluations, we use the
jointly learned inter-slot relations to induce a coher-
ent slot set in an unsupervised fashion. Our contri-
butions are three-fold:

• We are among the first to consider unsuper-
vised spoken language understanding combin-
ing semantic and lexical knowledge graphs;

• We propose a novel typed syntactic dependency
grammar driven random walk model for rela-
tion discovery;

619



• Our experimental results suggest that jointly
considering inter-slot relations helps obtain a
more coherent and complete semantic slot set.

2 Related Work

With the recent success of commercial dialogue sys-
tems and personal assistants (e.g., Microsoft’s Cor-
tana1, Google Now2, Apple’s Siri3, and Amazon’s
Echo4), a key focus on developing spoken under-
standing techniques is the scalability issue.

From the knowledge management perspective,
empowering the system with a large knowledge base
is of crucial significance to modern spoken dia-
logue systems. On this end, our work clearly aligns
with recent studies on leveraging semantic knowl-
edge graphs for SLU modeling (Heck et al., 2013;
Hakkani-Tür et al., 2013; Hakkani-Tür et al., 2014;
El-Kahky et al., 2014; Chen et al., 2014a). While
leveraging external knowledge is the trend, effi-
cient inference algorithms, such as random walk, are
still less-studied for direct inference on knowledge
graphs of the spoken contents.

In the natural language processing literature, Lao
et al. (2011) used a random walk algorithm to con-
struct inference rules on large entity-based knowl-
edge bases, and leveraged syntactic information
for reading the Web (Lao et al., 2012). Even
though this work has important contributions, the
proposed algorithm cannot learn mutually-recursive
relations, and does not to consider lexical items—
in fact, more and more studies show that, in addi-
tion to semantic knowledge graphs, lexical knowl-
edge graphs (Inkpen and Hirst, 2006; Song et al.,
2011; Li et al., 2013b) that model surface-level natu-
ral language realization, multiword expressions, and
context (Li et al., 2013a), are also critical for short
text understanding (Song et al., 2011; Wang et al.,
2014).

From the engineering perspective, quick and easy
development turnaround time for domain-specific
dialogue applications is also critical (Chen and Rud-
nicky, 2014). Prior work shows that it is possible to
use the frame-semantics theory to automatically in-

1http://www.windowsphone.com/en-us/how-to/
wp8/cortana

2http://www.google.com/landing/now
3http://www.apple.com/ios/siri
4http://www.amazon.com/oc/echo

duce and fill semantic slots (Chen et al., 2013b), and
that leveraging distributional semantics helps im-
proving the performance (Chen et al., 2014b). How-
ever, prior works treat each slot independently and
have not considered the inter-slot relations when in-
ducing the semantic slots. To the best of our knowl-
edge, we are the first to use syntactically-informed
random walk algorithms to combine the semantic
and lexical knowledge graphs, and not individually
but globally inducing the semantic slots for building
better unsupervised SLU components.

3 The Proposed Framework

We build our approach on top of the recent suc-
cess of an unsupervised frame-semantic parsing ap-
proach (Chen et al., 2013b). The main motivation
of prior work is to use a FrameNet-trained statis-
tical probabilistic semantic parser to generate ini-
tial frame-semantic parses from automatic speech
recognition (ASR) decodings of the raw audio con-
versation files, and then adapt the FrameNet-style
frames to the semantic slots in the target semantic
space, so that they can be used practically in the
SDSs. Chen et al. formulated the semantic map-
ping and adaptation problem as a ranking problem to
differentiate generic semantic concepts from target
semantic space for task-oriented dialogue systems.
This paper improves the adaptation process by lever-
aging distributed word embeddings associated with
typed syntactic dependencies between words to infer
inter-slot relations (Mikolov et al., 2013b; Mikolov
et al., 2013c; Levy and Goldberg, 2014). The pro-
posed framework is shown in Figure 1. In the re-
mainder of the section, we first introduce frame-
semantic parsing to obtain slot candidates. With slot
candidates, then we train the independent semantic
decoders. The adaptation process, which is the main
focus of this paper, is performed to decide outputted
slots. Finally we can build an SLU model based on
the learned semantic decoders and induced slots.

3.1 Probabilistic Semantic Parsing

FrameNet is a linguistically-principled semantic re-
source that offers annotations of predicate-argument
semantics, and associated lexical units for En-
glish (Baker et al., 1998). FrameNet is developed
based on a semantic theory, Frame Semantics (Fill-

620



Slot 

Ranking 

Model 

SLU Model 

Induced Slots 
Semantic 

Representation 

“can I have a cheap restaurant” 

Slot Induction 

Slot 

Candidates 

Frame-Semantic Parsing 

Semantic Decoder 

Training 

Unlabeled Collection 

Syntactic Dependency Parsing 
Lexical Knowledge Graph 

Semantic Knowledge Graph 

Figure 1: The proposed framework

can i have a cheap restaurant 

Frame: capability 
FT LU: can FE Filler: i 

Frame: expensiveness 
FT LU: cheap 

Frame: locale_by_use 
FT/FE LU: restaurant 

Figure 2: An example of probabilistic frame-semantic
parsing on ASR output. FT: frame target. FE: frame ele-
ment. LU: lexical unit.

more, 1976), which holds that the meaning of most
words can be expressed on the basis of semantic
frames, which encompass three major components:
frame (F), frame elements (FE), and lexical units
(LU). For example, the frame “food” contains words
referring to items of food. A descriptor frame ele-
ment within the food frame indicates the character-
istic of the food. For example, the phrase “low fat
milk” should be analyzed with “milk” evoking the
food frame and “low fat” filling the descriptor FE of
that frame.

In our approach, we parse all ASR-decoded ut-
terances in our corpus using SEMAFOR5, a state-
of-the-art semantic parser for frame-semantic pars-
ing (Das et al., 2010; Das et al., 2013), and ex-
tract all frames from semantic parsing results as slot
candidates, where the LUs that correspond to the
frames are extracted for slot filling. For example,
Figure 2 shows an example of an ASR-decoded text
output parsed by SEMAFOR. SEMAFOR generates
three frames (capability, expensiveness, and lo-
cale by use) for the utterance, which we consider
as slot candidates for training the SLU model. Note
that for each slot candidate, SEMAFOR also in-
cludes the corresponding lexical unit (can i, cheap,

5http://www.ark.cs.cmu.edu/SEMAFOR/

and restaurant), which we consider as possible slot-
fillers.

3.2 Independent Semantic Decoder
With outputted semantic parses, we extract the
frames with the top 50 highest frequency as our slot
candidates for training SLU. The features for train-
ing are generated by word confusion network, where
confusion network features are shown to be useful in
developing more robust systems for SLU (Hakkani-
Tür et al., 2006; Henderson et al., 2012). We
build a vector representation of an utterance as u =
[x1, ..., xj , ...].

xj = E[Cu(n-gramj)]
1/|n-gramj |, (1)

where Cu(n-gramj) counts how many times n-
gramj occurs in the utterance u, E(Cu(n-gramj))
is the expected frequency of n-gramj in u, and
|n-gramj | is the number of words in n-gramj .

For each slot candidate si, we generate a pseudo
training data Di to train a binary classifier Mi for
predicting the existence of si given an utterance,
Di = {(uk, lik) | uk ∈ R+, lik ∈ {−1,+1}}Kk=1,
where lik = +1 when the utterance uk contains the
slot candidate si in its semantic parse, lik = −1 oth-
erwise, and K is the number of utterances.

3.3 Adaptation Process and SLU Model
Since SEMAFOR was trained on FrameNet annota-
tion, which has a more generic frame-semantic con-
text, not all the frames from the parsing results can
be used as the actual slots in the domain-specific dia-
logue systems. For instance, in Figure 2, we see that
the frames “expensiveness” and “locale by use”
are essentially the key slots for the purpose of un-
derstanding in the restaurant query domain, whereas

621



w1 

w2 

w3 

w4 

w5 

w6 

w7 

Lexical Knowledge Graph 

s2 

Semantic Knowledge Graph 

s1 s3 

Figure 3: A simplified example of the two knowledge
graphs, where a slot candidate si is represented as a node
in a semantic knowledge graph and a word wj is repre-
sented as a node in a lexical knowledge graph.

the “capability” frame does not convey particular
valuable information for SLU. With the trained in-
dependent semantic decoders for all slot candidates,
adaptation process computes the prominence of slot
candidates for ranking and then selects a list of in-
duced slots associated with their corresponding se-
mantic decoders for use in domain-specific dialogue
systems, where the detail is described in Section 4.

Then with each induced slot si and its correspond-
ing trained semantic decoderMi, an SLU model can
be built to predict whether the semantic slot occurs
in the given utterance in a fully unsupervised way. In
other words, the SLU model is able to transform the
testing utterance into semantic representations with-
out human involvement.

4 Slot Ranking Model

The purpose of the ranking model is to distinguish
between generic semantic concepts and domain-
specific concepts that are relevant to an SDS. To in-
duce meaningful slots for the purpose of SDS, we
compute the prominence of the slot candidates us-
ing a slot ranking model described below.

With the semantic parses from SEMAFOR, where
each frame is viewed independently, so inter-slot re-
lations are not included, the model ranks the slot
candidates by integrating two information: (1) the
frequency of each slot candidate in the corpus, since
slots with higher frequency may be more important.
(2) the relations between slot candidates. Assuming
that domain-specific concepts are usually related to
each other, globally considering inter-slot relations
induces a more coherent slot set. Here for baseline

can i have a cheap restaurant 

ccomp 

amod 
dobj nsubj det 

capability expensiveness locale_by_use 

Figure 4: The dependency parsing result on an utterance.

scores, we only use the frequency of each slot can-
didate as its prominence.

First we construct two knowledge graphs, one
is a slot-based semantic knowledge graph and an-
other is a word-based lexical knowledge graph, both
of which encode the typed dependency relations in
their edge weights. We also connect two graphs to
model the relations between slot-filler pairs.

4.1 Knowledge Graphs

We construct two undirected graphs, semantic and
lexical knowledge graphs. Each node in the seman-
tic knowledge graph is a slot candidate si outputted
by the frame-semantic parser, and each node in the
lexical knowledge graph is a word wj .

• Slot-based semantic knowledge graph is built
as Gs = 〈Vs, Ess〉, where Vs = {si} and
Ess = {eij | si, sj ∈ Vs}.
• Word-based lexical knowledge graph is built

as Gw = 〈Vw, Eww〉, where Vw = {wi} and
Eww = {eij | wi, wj ∈ Vw}.

With two knowledge graphs, we build the edges
between slots and slot-fillers to integrate them as
shown in Figure 3. Thus the combined graph can be
formulated as G = 〈Vs, Vw, Ess, Eww, Ews〉, where
Ews = {eij | wi ∈ Vw, sj ∈ Vs}. Ess, Eww,
and Ews correspond to slot-to-slot relations, word-
to-word relations, and word-to-slot relations respec-
tively (Chen and Metze, 2012; Chen and Metze,
2013).

4.2 Edge Weight Estimation

Considering the relations in the knowledge graphs,
the edge weights for Eww and Ess are measured
based on the dependency parsing results. The
example utterance “can i have a cheap restau-
rant” and its dependency parsing result are illus-
trated in Figure 4. The arrows denote the de-

622



Typed Dependency Relation Target Word Contexts

Word 〈restaurant, AMOD, cheap〉 restaurant cheap/AMOD
cheap restaurant/AMOD−1

Slot 〈locale by use, AMOD,expensiveness〉 locale by use expensiveness/AMOD
expansiveness locale by use/AMOD−1

Table 1: The contexts extracted for training dependency-based word/slot embeddings from the utterance of Fig. 2.

pendency relations from headwords to their de-
pendents, and words on arcs denote types of the
dependencies. All typed dependencies between
two words are encoded in triples and form a
word-based dependency set Tw = {〈wi, t, wj〉},
where t is the typed dependency between the
headword wi and the dependent wj . For exam-
ple, Figure 4 generates 〈restaurant, AMOD, cheap〉,
〈have, DOBJ, restaurant〉, etc. for Tw. Simi-
larly, we build a slot-based dependency set Ts =
{〈si, t, sj〉} by transforming dependencies between
slot-fillers into ones between slots. For example,
〈restaurant, AMOD, cheap〉 from Tw is transformed
into 〈locale by use, AMOD,expensiveness〉 for
building Ts, because both sides of the non-dotted
line are parsed as slot-fillers by SEMAFOR.

For the edges within a single knowledge graph,
we assign a weight of the edge connecting nodes xi
and xj as r̂(xi, xj), where x is either s or w. Since
the weights are measured based on the relations be-
tween nodes regardless of the directions, we com-
bine the scores of two directional dependencies:

r̂(xi, xj) = r(xi → xj) + r(xj → xi), (2)
where r(xi → xj) is the score estimating the de-
pendency including xi as a head and xj as a depen-
dent. In Section 4.2.1 and 4.2.2, we propose two
scoring functions for r(·), frequency-based as r1(·)
and embedding-based as r2(·) respectively.

For the edges in Ews, we estimate the edge
weights based on the frequency that the slot candi-
dates and the words are parsed as slot-filler pairs. In
other words, the edge weight between the slot-filler
wi and the slot candidate sj , r̂(wi, sj), is equal to
how many times the filler wi corresponds to the slot
candidate sj in the parsing results.

4.2.1 Frequency-Based Measurement
Based on the dependency set Tx, we use t∗xi→xj to

denote the most frequent typed dependency with xi

as a head and xj as a dependent.

t∗xi→xj = arg maxt C(xi −→t xj), (3)

where C(xi −→
t
xj) counts how many times the de-

pendency 〈xi, t, xj〉 occurs in the dependency set Tx.
Then the scoring function that estimates the de-

pendency xi → xj is measured as

r1(xi → xj) = C(xi −−−−→
t∗xi→xj

xj), (4)

which equals to the highest observed frequency of
the dependency xi → xj among all types from Tx.
4.2.2 Embedding-Based Measurement

Most neural embeddings use linear bag-of-words
contexts, where a window size is defined to produce
contexts of the target words (Mikolov et al., 2013c;
Mikolov et al., 2013b; Mikolov et al., 2013a). How-
ever, some important contexts may be missing due
to smaller windows, while larger windows capture
broad topical content. A dependency-based em-
bedding approach was proposed to derive contexts
based on the syntactic relations the word participates
in for training embeddings, where the embeddings
are less topical but offer more functional similarity
compared to original embeddings (Levy and Gold-
berg, 2014).

Table 1 shows the extracted dependency-based
contexts for each target word from the example in
Figure 4, where headwords and their dependents can
form the contexts by following the arc on a word in
the dependency tree, and−1 denotes the directional-
ity of the dependency. After replacing original bag-
of-words contexts with dependency-based contexts,
we can train dependency-based embeddings for all
target words (Yih et al., 2014; Bordes et al., 2011;
Bordes et al., 2013).

For training dependency-based word embeddings,
each word w is associated with a word vector vw ∈

623



Rd and each context c is represented as a context
vector vc ∈ Rd, where d is the embedding dimen-
sionality. We learn vector representations for both
words and contexts such that the dot product vw ·vc
associated with “good” word-context pairs belong-
ing to the training data D is maximized, leading to
the objective function:

arg max
vw,vc

∑
(w,c)∈D

log
1

1 + exp(−vc · vw) , (5)

which can be trained using stochastic-gradient up-
dates (Levy and Goldberg, 2014). Then we can
obtain the dependency-based slot and word embed-
dings using Ts and Tw respectively.

With trained dependency-based embeddings, we
estimate the probability that xi is the headword and
xj is its dependent via the typed dependency t as

P (xi −→
t
xj) =

Sim(xi, xj/t) + Sim(xj , xi/t−1)
2

,

(6)
where Sim(xi, xj/t) is the cosine similarity be-
tween the slot/word embeddings vxi and the context
embeddings vxj/t after normalizing to [0, 1]. Then
we can measure the scoring function r2(·) as
r2(xi → xj) = C(xi −−−−→

t∗xi→xj
xj)·P (xi −−−−→

t∗xi→xj
xj),

(7)
which is similar to (4) but additionally weighted by
the estimated probability. The estimated probability
smooths the observed frequency to avoid overfitting
due to a smaller dataset.

4.3 Random Walk Algorithm
We first compute Lww = [r̂(wi, wj)]|Vw|×|Vw| and
Lss = [r̂(si, sj)]|Vs|×|Vs|, where r̂(wi, wj) and
r̂(si, sj) are either from frequency-based (r1(·))
or embedding-based measurements (r2(·)). Sim-
ilarly, Lws = [r̂(wi, sj)]|Vw|×|Vs| and Lsw =
[r̂(wi, sj)]T|Vw|×|Vs|, where r̂(wi, sj) is the frequency
that sj and wi are a slot-filler pair computed in
Section 4.2. Then we only keep the top N high-
est weights for each row in Lww and Lss (N =
10), which means that we filter out the edges with
smaller weights within the single knowledge graph.
Column-normalization are performed for Lww, Lss,
Lws, Lsw (Shi and Malik, 2000). They can be
viewed as word-to-word, slot-to-slot, and word-to-
slot relation matrices.

4.3.1 Single-Graph Random Walk
Here we run random walk only on the semantic

knowledge graph to propagate the scores based on
inter-slot relations through the edges Ess.

R(t+1)s = (1− α)R(0)s + αLssR(t)s , (8)

where R(t)s denotes the importance scores of the
slot candidates Vs in t-th iteration. In the algo-
rithm, the score is the interpolation of two scores, the
normalized baseline importance of slot candidates
(R(0)s ), and the scores propagated from the neigh-
boring nodes in the semantic knowledge graph based
on slot-to-slot relations via Lss. The algorithm will
converge when R(t+1)s = R

(t)
s = R∗s and (9) can be

satisfied.

R∗s =
(
(1− α)R(0)s eT + αLss

)
R∗s = M1R

∗
s,

(9)
where e = [1, 1, ..., 1]T . It has been shown that
the closed-form solution R∗s of (9) is the dominant
eigenvector of M1 (Langville and Meyer, 2005),
the eigenvector corresponding to the largest abso-
lute eigenvalue of M1. The solution of R∗s de-
notes the updated importance scores for all utter-
ances. Similar to the PageRank algorithm (Brin and
Page, 1998), the solution can also be obtained by it-
eratively updating R(t)s .

4.3.2 Double-Graph Random Walk
Here we borrow the idea from two-layer mutu-

ally reinforced random walk to propagate the scores
based on not only internal importance propagation
within the same graph but external mutual reinforce-
ment between different knowledge graphs (Chen
and Metze, 2012; Chen and Metze, 2013).{

R
(t+1)
s = (1− α)R(0)s + αLssLswR(t)w

R
(t+1)
w = (1− α)R(0)w + αLwwLwsR(t)s

(10)

In the algorithm, they are the interpolations of two
scores, the normalized baseline importance (R(0)s
and R(0)w ) and the scores propagated from another
graph. For the semantic knowledge graph, LswR

(t)
w

is the score from the word set weighted by slot-to-
word relations, and then the scores are propagated
based on slot-to-slot relations via Lss. Similarly,
nodes of the lexical knowledge graph also include

624



the scores propagated from the semantic knowledge
graph. Then R(t+1)s and R

(t+1)
w can be mutually up-

dated by the latter parts in (10) iteratively. When the
algorithm converges, we have R∗s as follows.

R∗s = (1− α)R(0)s (11)
+ αLssLsw

(
(1− α)R(0)w + αLwwLwsR∗s

)
=

(
(1− α)R(0)s eT + α(1− α)LssLswR(0)w eT

+ α2LssLswLwwLws
)
R∗s = M2R

∗
s.

The closed-form solution R∗s of (11) is the dominant
eigenvector of M2.

5 Experiments

We evaluate our approach in two ways. First, we ex-
amine the slot induction accuracy by comparing the
ranked list of induced slots with the reference slots
created by system developers (Young, 2007). Sec-
ondly, with the ranked list of induced slots and their
associated semantic decoders, we can evaluate the
SLU performance. For the experiments, we evaluate
both on ASR transcripts of the raw audio, and on the
manual transcripts.

5.1 Experimental Setup
In this experiment, we used the Cambridge Univer-
sity SLU corpus, previously used on several other
SLU tasks (Henderson et al., 2012; Chen et al.,
2013a). The domain of the corpus is about restaurant
recommendation in Cambridge; subjects were asked
to interact with multiple SDSs in an in-car setting.
The corpus contains a total number of 2,166 dia-
logues, including 15,453 utterances (10,571 for self-
training and 4,882 for testing). The data is gender-
balanced, with slightly more native than non-native
speakers. The vocabulary size is 1868. An ASR sys-
tem was used to transcribe the speech; the word error
rate was reported as 37%. There are 10 slots cre-
ated by domain experts: addr, area, food, name,
phone, postcode, price range, signature, task,
and type.

For parameter setting, the damping factor for ran-
dom walk α is empirically set as 0.9 for all exper-
iments. For training the semantic decoders, we use
SVM with a linear kernel to predict each semantic
slot. We use Stanford Parser to obtain the collapsed

speak on topic addr 
area 

food 

phone 

part orientational 
direction 
locale 
part inner outer 

food 
origin 

contacting 

postcode 

price range 

task 

type 

sending 

commerce scenario 
expensiveness 
range 

seeking 
desiring 
locating 

locale by use 
building 

Figure 5: The mappings from induced slots (within
blocks) to reference slots (right sides of arrows).

typed syntactic dependencies (Socher et al., 2013)
and set the dimensionality of embeddings d = 300
in all experiments.

5.2 Evaluation Metrics

To eliminate the influence of threshold selection
when choosing induced slots, in the following met-
rics, we take the whole ranking list into account and
evaluate the performance by the metrics that are in-
dependent of the selected threshold.

5.2.1 Slot Induction
To evaluate the accuracy of the induced slots, we

measure their quality as the proximity between in-
duced slots and reference slots. Figure 5 shows
the mappings that indicate semantically related in-
duced slots and reference slots (Chen et al., 2013b).
For example, “expensiveness→ price”, “food→
food”, and “direction → area” show that these in-
duced slots can be mapped into the reference slots
defined by experts and carry important semantics in
the target domain for developing the task-oriented
SDS. Since we define the adaptation task as a rank-
ing problem, with a ranked list of induced slots and
associated scores, we can use the standard average
precision (AP) and the area under the precision-
recall curve (PR-AUC) as our metrics, where the in-
duced slot is counted as correct when it has a map-
ping to a reference slot.

5.2.2 SLU Model
While semantic slot induction is essential for pro-

viding semantic categories and imposing semantic
constraints, we are also interested in understanding
the performance of our unsupervised SLU models.

625



Approach
ASR Manual

Slot Induction SLU Model Slot Induction SLU Model
AP PR-AUC WAP AF AP PR-AUC WAP AF

(a) Baseline (Frequency) 56.69 54.67 35.82 43.28 53.01 50.80 36.78 44.20
(b)

Single
Frequency 63.88 62.05 41.67 47.38 63.02 61.10 43.76 48.53

(c) Embedding 69.04 68.25 46.29 48.89 75.15 74.50 54.50 50.86
(d)

Double
Frequency 56.83 55.31 32.64 44.91 52.12 50.54 34.01 45.05

(e) Embedding 71.48 70.84 44.06 47.91 76.42 75.94 52.89 50.40

Table 2: The performance of induced slots and corresponding SLU models (%)

For each induced slot with the mapping to a ref-
erence slot, we can compute an F-measure of the
corresponding semantic decoder, and weight the av-
erage precision with corresponding F-measure as
weighted average precision (WAP) to evaluate the
performance of slot induction and SLU tasks to-
gether. The metric scores the ranking result higher
if the induced slots corresponding to better semantic
decoders are ranked higher. Another metric is the
average F-measure (AF), which is the average micro
F-measure of SLU models at all cut-off positions in
the ranked list. Compared to WAP, AF additionally
considers the slot popularity in the dataset.

5.3 Evaluation Results

Table 5.1 shows the results on both ASR and manual
transcripts. Rows (a) is the baseline only consider-
ing the frequency of each slot candidate for rank-
ing (Chen et al., 2013b). Rows (b) and (c) show
performance after leveraging a semantic knowledge
graph through random walk. Rows (d) and (e) are
the results after combining two knowledge graphs.
We find almost all results are improved by addi-
tionally considering inter-slot relations in terms of
single- and double-graph random walk for both ASR
and manual transcripts.

5.3.1 Slot Induction
For both ASR and manual transcripts, almost

all results outperform the baseline, showing that
inter-slot relations significantly influence the perfor-
mance of slot induction. The best performance is
from the results of double-graph random walk with
the embedding-based measurement, which integrate
a semantic knowledge graph and a lexical knowl-
edge graph together and jointly consider slot-to-slot,
word-to-word, and word-to-slot relations when scor-

ing the prominence of slot candidates to generate a
coherent slot set.

5.3.2 SLU Model

For both ASR and manual transcripts, almost all
results outperform the baseline, which shows the
practical usage for training dialogue systems. The
best performance is from the results of single-graph
random walk with the embedding-based measure-
ment, which only use the semantic knowledge graph
to involve the inter-slot relations. The semantic
knowledge graph is not as precise as the lexical one
and may be influenced by the performance of the se-
mantic parser more. Although the row (e) does not
show better performance than the row (c), double-
graph random walk may be more robust because
it additionally includes the word relations to avoid
only relying on the relations tied with the slot candi-
dates.

5.4 Discussion and Analysis

5.4.1 Comparing Frequency- and
Embedding-Based Measurements

Table 5.1 shows that all results with the
embedding-based measurement perform better than
those with the frequency-based measurement. The
frequency-based measurement also brings large im-
provement for single-graph approaches, but does not
for double-graph ones. The reason is probably that
using observed frequencies in the lexical knowledge
graph may result in overfitting issues due to the
smaller dataset. Additionally including embedding
information can smooth the edge weights and deal
with data sparsity to improve the performance, es-
pecially for the lexical knowledge graph.

626



5.4.2 Comparing Single- and Double-Graph
Approaches

Considering that the embedding-based measure-
ment performs better, we only compare the results
of single- and double-graph random walk using this
measurement (rows (c) and (e)). It can be seen
that the difference between them is not consistent
in terms of slot induction and SLU model.

For evaluating slot induction (AP and PR-AUC),
the double-graph random walk (row (e)) performs
better on both ASR and manual results, which im-
plies that additionally integrating the lexical knowl-
edge graph helps decide a more coherent and com-
plete slot set since we can model the score propa-
gation more precisely (not only slot-level but word-
level information). However, for SLU evaluation
(WAP and AF), the single-graph random walk (row
(c)) performs better, which may imply that the slots
carrying the coherent relations from the row (e) may
not have good semantic decoder performance so that
the performance is decreased a little. For exam-
ple, double-graph random walk scores the slots lo-
cal by use and expensiveness higher than the slot
contacting, while the single-graph method ranks
the latter higher. local by use and expensiveness
are more important on this domain but contacting
has very good performance of its semantic decoder,
so the double-graph approach does not show the im-
provement when evaluating SLU models. This al-
lows us to try an improved method of jointly opti-
mizing the slot coherence and SLU performance in
the future.

5.4.3 Relation Discovery Analysis
To interpret the inter-slot relations, we output the

slot-to-slot relations with highest scores from the
best results (row (e) in Table 5.1) in Table 3, and
the automatically constructed ontology is shown in
Figure 6. It can be shown that the outputted inter-
slot relations are reasonable and usually connect two
important semantic slots in this restaurant domain.
This proves that inter-slot relations help decide a
coherent and complete slot set and enhance the in-
terpretability of semantic slots. Therefore, from a
practical perspective, developers are able to design
the framework of dialogue systems more easily, and
the development of SDS can be speeded up with less
human effort.

Rank Relation
1 〈locale by use, NN, food〉
2 〈food, AMOD,expensiveness〉
3 〈locale by use, AMOD,expensiveness〉
4 〈seeking, PREP FOR, food〉
5 〈food, AMOD, relational quantity〉
6 〈desiring, DOBJ, food〉
7 〈seeking, PREP FOR, locale by use〉
8 〈food, DET,quantity〉

Table 3: The top inter-slot relations learned from the
training set of ASR outputs.

locale_by_use 

food expensiveness 

seeking 

relational_quantity 

PREP_FOR 

PREP_FOR 

NN 
AMOD 

AMOD 

AMOD 

desiring 

DOBJ 

Figure 6: The automatically constructed domain-specific
ontology based on Table 3.

6 Conclusion

The paper proposes an approach of jointly consid-
ering inter-slot relations for slot induction to out-
put a more coherent slot set, where two knowledge
graphs, a slot-based semantic knowledge graph and
a word-based lexical knowledge graph, are built and
combined by a random walk algorithm. The au-
tomatically induced slots carry coherent and inter-
pretable relations and can be used for training better
SLU models of SDSs in an unsupervised fashion.

Acknowledgments

We thank Anatole Gershman for helpful discus-
sions and anonymous reviewers for their useful com-
ments. We are also grateful to MetLife’s support.
Any opinions, findings, and conclusions expressed
in this publication are those of the authors and do not
necessarily reflect the views of funding agencies.

627



References

Collin F Baker, Charles J Fillmore, and John B Lowe.
1998. The Berkeley FrameNet project. In Proceed-
ings of COLING, pages 86–90.

Antoine Bordes, Jason Weston, Ronan Collobert, Yoshua
Bengio, et al. 2011. Learning structured embeddings
of knowledge bases. In Proceedings of AAAI.

Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran,
Jason Weston, and Oksana Yakhnenko. 2013. Trans-
lating embeddings for modeling multi-relational data.
In Advances in Neural Information Processing Sys-
tems, pages 2787–2795.

Sergey Brin and Lawrence Page. 1998. The anatomy of a
large-scale hypertextual web search engine. Computer
networks and ISDN systems, 30(1):107–117.

Yun-Nung Chen and Florian Metze. 2012. Two-layer
mutually reinforced random walk for improved multi-
party meeting summarization. In Proceedings of The
4th IEEE Workshop on Spoken Language Tachnology,
pages 461–466.

Yun-Nung Chen and Florian Metze. 2013. Multi-layer
mutually reinforced random walk with hidden parame-
ters for improved multi-party meeting summarization.
In INTERSPEECH, pages 485–489.

Yun-Nung Chen and Alexander I. Rudnicky. 2014. Dy-
namically supporting unexplored domains in conversa-
tional interactions by enriching semantics with neural
word embeddings. In Proceedings of 2014 IEEE Spo-
ken Language Technology Workshop (SLT),.

Yun-Nung Chen, William Yang Wang, and Alexander I.
Rudnicky. 2013a. An empirical investigation of
sparse log-linear models for improved dialogue act
classification. In Proceedings of ICASSP, pages 8317–
8321.

Yun-Nung Chen, William Yang Wang, and Alexander I
Rudnicky. 2013b. Unsupervised induction and filling
of semantic slots for spoken dialogue systems using
frame-semantic parsing. In Proceedings of 2013 IEEE
Workshop on Automatic Speech Recognition and Un-
derstanding (ASRU), pages 120–125. IEEE.

Yun-Nung Chen, Dilek Hakkani-Tür, and Gokhan Tur.
2014a. Deriving local relational surface forms from
dependency-based entity embeddings for unsuper-
vised spoken language understanding. In Proceedings
of 2014 IEEE Spoken Language Technology Workshop
(SLT),.

Yun-Nung Chen, William Yang Wang, and Alexander I.
Rudnicky. 2014b. Leveraging frame semantics and
distributional semantics for unsupervised semantic slot
induction in spoken dialogue systems. In Proceedings
of 2014 IEEE Spoken Language Technology Workshop
(SLT),.

Dipanjan Das, Nathan Schneider, Desai Chen, and
Noah A Smith. 2010. Probabilistic frame-semantic
parsing. In Proceedings of The Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, pages 948–956.

Dipanjan Das, Desai Chen, André F. T. Martins, Nathan
Schneider, and Noah A. Smith. 2013. Frame-semantic
parsing. Computational Linguistics.

Marie-Catherine De Marneffe and Christopher D Man-
ning. 2008. The Stanford typed dependencies repre-
sentation. In Coling 2008: Proceedings of the work-
shop on Cross-Framework and Cross-Domain Parser
Evaluation, pages 1–8. Association for Computational
Linguistics.

Ali El-Kahky, Derek Liu, Ruhi Sarikaya, Gökhan Tür,
Dilek Hakkani-Tür, and Larry Heck. 2014. Extending
domain coverage of language understanding systems
via intent transfer between domains using knowledge
graphs and search query click logs. In Proceedings of
ICASSP.

Charles J Fillmore. 1976. Frame semantics and the na-
ture of language. Annals of the NYAS, 280(1):20–32.

Dilek Hakkani-Tür, Frédéric Béchet, Giuseppe Riccardi,
and Gokhan Tur. 2006. Beyond ASR 1-best: Using
word confusion networks in spoken language under-
standing. Computer Speech & Language, 20(4):495–
514.

Dilek Hakkani-Tür, Larry Heck, and Gokhan Tur. 2013.
Using a knowledge graph and query click logs for un-
supervised learning of relation detection. In Proceed-
ings of ICASSP, pages 8327–8331.

Dilek Hakkani-Tür, Asli Celikyilmaz, Larry Heck,
Gokhan Tur, and Geoff Zweig. 2014. Probabilistic en-
richment of knowledge graph entities for relation de-
tection in conversational understanding. In Proceed-
ings of INTERSPEECH.

Larry P Heck, Dilek Hakkani-Tür, and Gokhan Tur.
2013. Leveraging knowledge graphs for web-scale un-
supervised semantic parsing. In Proceedings of IN-
TERSPEECH.

Matthew Henderson, Milica Gasic, Blaise Thomson, Pir-
ros Tsiakoulis, Kai Yu, and Steve Young. 2012.
Discriminative spoken language understanding using
word confusion networks. In Proceedings of SLT,
pages 176–181.

Diana Inkpen and Graeme Hirst. 2006. Building and
using a lexical knowledge base of near-synonym dif-
ferences. Computational Linguistics, 32(2):223–262.

Amy N Langville and Carl D Meyer. 2005. A survey
of eigenvector methods for web information retrieval.
SIAM review, 47(1):135–161.

Ni Lao, Tom Mitchell, and William W Cohen. 2011.
Random walk inference and learning in a large scale

628



knowledge base. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing,
pages 529–539. Association for Computational Lin-
guistics.

Ni Lao, Amarnag Subramanya, Fernando Pereira, and
William W Cohen. 2012. Reading the web with
learned syntactic-semantic inference rules. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, pages 1017–
1026. Association for Computational Linguistics.

Omer Levy and Yoav Goldberg. 2014. Dependency-
based word embeddings. In Proceedings of ACL.

Peipei Li, Haixun Wang, Hongsong Li, and Xindong Wu.
2013a. Assessing sparse information extraction us-
ing semantic contexts. In Proceedings of the 22nd
ACM international conference on Conference on infor-
mation & knowledge management, pages 1709–1714.
ACM.

Peipei Li, Haixun Wang, Kenny Q Zhu, Zhongyuan
Wang, and Xindong Wu. 2013b. Computing term
similarity by large probabilistic isa knowledge. In Pro-
ceedings of the 22nd ACM international conference on
Conference on information & knowledge management,
pages 1401–1410. ACM.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word representa-
tions in vector space. In Proceedings of Workshop at
ICLR.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013b. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proceedings of Advances in Neural Information
Processing Systems, pages 3111–3119.

Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013c. Linguistic regularities in continuous space
word representations. In HLT-NAACL, pages 746–
751. Citeseer.

Jianbo Shi and Jitendra Malik. 2000. Normalized cuts
and image segmentation. Pattern Analysis and Ma-
chine Intelligence, IEEE Transactions on, 22(8):888–
905.

Richard Socher, John Bauer, Christopher D Manning, and
Andrew Y Ng. 2013. Parsing with compositional vec-
tor grammars. In Proceedings of the ACL conference.
Citeseer.

Yangqiu Song, Haixun Wang, Zhongyuan Wang, Hong-
song Li, and Weizhu Chen. 2011. Short text con-
ceptualization using a probabilistic knowledgebase. In
Proceedings of the Twenty-Second international joint
conference on Artificial Intelligence-Volume Volume
Three, pages 2330–2336. AAAI Press.

Fang Wang, Zhongyuan Wang, Zhoujun Li, and Ji-Rong
Wen. 2014. Concept-based short text classification

and ranking. In Proceedings of the 23rd ACM Interna-
tional Conference on Conference on Information and
Knowledge Management, pages 1069–1078. ACM.

Wen-tau Yih, Xiaodong He, and Christopher Meek.
2014. Semantic parsing for single-relation question
answering. In Proceedings of ACL.

Steve Young. 2007. CUED standard dialogue acts.
Technical report, Cambridge University Engineering
Department.

629


