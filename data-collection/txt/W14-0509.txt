



















































How well can a corpus-derived co-occurrence network simulate human associative behavior?


Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 43–48,
Gothenburg, Sweden, April 26 2014. c©2014 Association for Computational Linguistics

How Well Can a Corpus-Derived Co-Occurrence Network  
Simulate Human Associative Behavior? 

 
Gemma Bel Enguix Reinhard Rapp Michael Zock 

 
Aix-Marseille Université, Laboratoire d'Informatique Fondamentale 
UMR 7279, Case 901, 163 Avenue de Luminy, F-13288 Marseille 

 
gemma.belenguix@gmail.com reinhardrapp@gmx.de zock@free.fr 

 
 

Abstract 

Free word associations are the words 
people spontaneously come up with in re-
sponse to a stimulus word. Such informa-
tion has been collected from test persons 
and stored in databases.  A well known 
example is the Edinburgh Associative 
Thesaurus (EAT). We will show in this 
paper that this kind of knowledge can be 
acquired automatically from corpora, en-
abling the computer to produce similar 
associative responses as people do. While 
in the past test sets typically consisted of 
approximately 100 words, we will use 
here a large part of the EAT which, in to-
tal, comprises 8400 words. Apart from 
extending the test set, we consider differ-
ent properties of words: saliency, fre-
quency and part-of-speech. For each fea-
ture categorize our test set, and we com-
pare the simulation results to those based 
on the EAT. It turns out that there are 
surprising similarities which supports our 
claim that a corpus-derived co-occur-
rence network can simulate human asso-
ciative behavior, i.e. an important part of 
language acquisition and verbal behavior. 

1 Introduction 
Word associations in general and free word asso-
ciation in particular (Galton, 1879) have been 
used by psychologists of various schools1 to un-
derstand the human mind (memory, cognition, 
language) and the hidden mechanisms driving 
peoples’ thoughts, utterances, and actions. In the 
case of free word associations, a person typically 
hears or reads a word, and is asked to produce 
the first other word coming to mind. Kent & Ro-
sanoff (1910) have used this method for compar-

                                                
1  For example, cognitive psychology (Collins and 

Loftus, 1975,), psycholinguistics (Clark, 1970) and 
psychoanalysis (Freud, 1901; Jung & Riklin, 1906). 

isons, introducing to this end 100 emotionally 
neutral test words. Having conducted the first 
large scale study of word associations (1000 test 
persons) they reached the conclusion that there 
was a great uniformity concerning people's asso-
ciations, that is, speakers of a language share sta-
ble, comparable associative networks (Istifci, 
2010).  

In this paper, we are mainly interested in the 
automatic acquisition of associations by com-
puter. More precisely, we want to check whether 
a corpus-based method allows us to build auto-
matically an associative network akin to the one 
in peoples’ mind, that is, a network able to mim-
ic human behavior. This means, given a stimulus 
word the system is supposed to produce the same 
responses as people do. We know since the old 
Greeks that thoughts and their expressions 
(words) are linked via associations. Yet, what we 
still do not know is the nature of these links. Al-
so, links vary in terms of strength. Associationist 
learning theory (Schwartz & Reisberg, 1991) ex-
plains how these strengths (or weights) are ac-
quired. The strength between two perceived 
events increases by a constant fraction of a max-
imally possible increment at each co-occurrence, 
and decreases in the opposite case.  

Wettler et al. (2005) have shown that this 
mechanism can be replicated by looking at word 
co-occurrence frequencies in large text collec-
tions. But there had been earlier corpus-linguistic 
work: For example, Wettler & Rapp (1989) com-
pared several association measures in order to 
find search terms to be used for queries in infor-
mation retrieval. Church & Hanks (1990) sug-
gested to use mutual information, an information 
theoretic measure, for computing association 
strength. Prior to this, a lot of work had been 
done without reliance of corpora. For example, 
Collins & Loftus (1975) used associative seman-
tic networks to show the distance between words. 
Others (Rosenzweig, 1961:358; Ekpo-Ufot, 
1978) tried to show the universal status of a large 
subset of associations. While all these findings 
are important, we will not consider them further 

43



here. Rather we will focus on the claim that a -
corpus-derived co-occurrence network is able to 
mimic human associative behavior. 

Such a network consists of nodes, which in 
our case correspond to words (or lemmas), and 
of weights connecting the nodes. The strengths 
of these weights are computed on the basis of 
word co-occurrence data, and by optionally ap-
plying an association measure. But there are 
many association measures. Given their number 
and diversity some researchers (Evert & Krenn, 
2001) felt that there was a need to define some 
criteria and methods in order to allow for quanti-
tative comparisons via task-based evaluations. 
Pursuing a similar goal, Pecina & Schlesinger 
(2006) compared 82 different association 
measures for collocation extraction, while Hoang 
et al. (2009) classified them. Michelbacher et al. 
(2011) investigated the potential of asymmetric 
association measures, i.e. "associations whose 
associational strength is significantly greater in 
one direction (e.g., from Pyrrhic to victory) than 
in the other (e.g., from victory to Pyrrhic)". 
Washtell & Markert (2009) tried to determine 
whether word associations should be computed 
via window-based co-occurrence counts or rather 
via a windowless approach measuring the dis-
tances between words. 

Our work is related to previous studies com-
paring human word associations with those de-
rived from corpus statistics (e.g. Wettler et al., 
2005; Tamir, 2005, Seidensticker, 2006). The 
main differences are that we categorize our stim-
ulus words and present results for each class, and 
that we have a stronger focus on the graph aspect 
of our network. 

2 Resources and processing 
In order to simulate human associative behavior 
via corpora, we need them to encode knowledge 
that people typically have, that is, encyclopedic 
or universally shared knowledge (e.g. Paris capi-
tal of France) and episodic knowledge (i.e. 
knowledge momentarily true: Nadal winner of 
the French Open). To meet these goals we de-
cided to use the British National Corpus (BNC, 
Burnard & Aston, 1998) as it is well balanced 
and relatively large (about 100 million words of 
contemporary British English). 

To lemmatize the corpus we used the NLTK 
(Bird et al., 2009) which for this purpose utilizes 
information from WordNet. Hence, inflected 
forms (e.g. wheels or bigger) were replaced by 
their base forms (e.g. wheel or big). This reduces 

noise and data sparsity while improving speed 
and accuracy during evaluation. Since this latter 
is based on exact string matching, our system 
would consider wheels, produced in response to 
car, as a mistake as the primary associative re-
sponse of the test persons is wheel, the singular 
form. Lemmatization solves this problem. Since 
we were interested here only in content words 
(nouns, verbs, and adjectives) we removed all 
other words from the BNC. 

To evaluate the performance of our system we 
compared its results with the associations col-
lected by Kiss et al. (1973), the Edinburgh Asso-
ciative Thesaurus. The association norms of the 
EAT were produced by presenting each stimulus 
word to 100 subjects, and by collecting their re-
sponses. The subjects were 17 to 22 year old 
British students. Table 1 shows the associations 
produced by at least five participants in response 
to the stimulus words bath and cold together with 
the number of participants producing them. 
 

bath cold 
observed 
response 

number of 
subjects 

observed 
response 

number of 
subjects 

water 
tub 

clean 
hot 

20 
8 
5 
5 

hot 
ice 

warm 
water 

34 
10 
7 
5 

Table 1: Extracts from the EAT for the stimulus words bath 
and cold. 

The EAT lists the associations to 8400 stimu-
lus words. Since we were only interested in 
nouns, verbs, and adjectives, we eliminated all 
other words and also multiword units (e.g. a lot). 
After having lemmatized the data with the NLTK 
we obtained a list of 5910 test items which is 
considerably more than the usual 100 used in 
many previous studies (e.g. Wettler et al., 2005). 

3 A graph-based approach for comput-
ing word associations 

Unlike previous work (Wettler et al. 2005; 
Church & Hanks, 1990) which is described in the 
terminology of the well known vector space 
model, in the construction of the current system 
we had a graph-based approach in mind so we 
describe the system in such terms. We built up a 
graph on the basis of the nouns, verbs, and adjec-
tives occurring in the corpus, these tokens being 
the nodes of the graph.2 The links (also called 
                                                
2  As preliminary experiments have shown, including func-

tion words in the graph can create noise in the retrieval of 

44



weights, connections, or edges) between these 
nodes are zero at the beginning, and are incre-
mented by one whenever the two connected 
words co-occur in the corpus as direct neigh-
bors.3 Put differently, the weight of each link 
represents the number of times two words 
(nodes) co-occur in the corpus. 

The associations to a given stimulus word are 
calculated by searching the nodes which are di-
rect neighbors of this stimulus word, and by 
ranking them according to the weights of the 
connections. Given a graph G=V,E with 
V={i,j,…,n} as its set of vertices and E as its set 
of edges linking pairs of nodes over V, we ex-
press by N(i) the neighborhood of a node i ∈V, 
where N(i) is defined as every j∈V | ei,j ∈E. 

4 Results 
Given the way this network is built, one could 
expect the system to retrieve only syntagmati-
cally related words, i.e. words often occurring in 
close proximity (e.g. blue → sky). Yet, to our 
surprise, the system also retrieves many paradig-
matic associations, that is, words which can sub-
stitute each other (e.g. blue → red). 

Table 2 shows some results. While not all 
computed primary responses are identical to the 
ones produced by humans (in the EAT), the re-
sponses seem perfectly plausible. This raises the 
question whether the answers are within the 
bandwidth of variation of human associative be-
havior. 

We measured the quality of our results by 
counting (for all 5910 items) the number of times 
the subjects participating in the creation of the 
EAT had given the same answer as our system. 
This number is 6.2 on average. In comparison, 
the number of other subjects giving the same an-
swer as an average test person is 5.8. If the two 
numbers were identical, our system would be 
perfectly within the range of variation of the hu-
man associative responses, i.e. our system's an-
swers could hardly be distinguished from the 
ones given by a human. This is actually the case. 
The answers of our system are, on average, even 
slightly closer to the ones given by the test per-
sons than the answers of a randomly selected test 
person.  

                                                                       
associations. Hence we preferred to keep only these three 
categories. 

3  Note that this refers to the pre-processed corpus where all 
stopwords have been removed. 

Stimulus 
Word 

Human Prima-
ry Response 

Computed Pri-
mary Response 

afraid fear person 
anger hate frustration 
baby boy mother 
bath water shower 
beautiful ugly woman 
bed sleep hospital 
bible book God 
bitter sweet taste 
black white white 
blossom flower white 

 
Table 2: Comparison between human and computed associ-
ations for the 10 alphabetically first words of the Kent/Ro-
sanoff (1910) list. 

 
In the following subsections we split our set of 

5910 test items into three categories to check 
how well each one of them matches our intuition 
that a corpus-derived co-occurrence network can 
indeed simulate human associative behavior. 

4.1 Word saliency 
Our goal is twofold: find out to what extend the 
saliency of a stimulus word has an effect on the 
homogeneity of human responses, and whether 
these findings can also be replicated in our com-
puter simulation. 

To this end we divided our 5910 EAT stimu-
lus words into six categories, i.e. saliency classes 
(SC). Saliency is defined here as the proportion 
of subjects producing the Primary Associative 
Response (PAR), this latter being the response 
produced by the largest number of subjects.  
  
SC 1:  less than 10% producing the PAR (10.7%)  
SC 2:  10 to 20% producing the PAR (36.0%) 
SC 3:  20 to 30% producing the PAR (24.3%) 
SC 4:  30 to 40% producing the PAR (13.3%) 
SC 5:  40 to 50% producing the PAR (8.0%) 
SC 6:  more than 50% producing the PAR (7.6%) 
 
The percentages at the end of each line denote 
the proportion of words belonging to the respec-
tive saliency class. All classes are reasonably 
well covered. Here are some representative 
words for each class:  
 
SC 1:  leader, professor, yellow  
SC 2:  horse, mountain, semaphore  
SC 3:  chief, jungle, kiss  
SC 4:  driver, monarchy, tornado  
SC 5:  aid, cell, gasoline 
SC 6:  black, aunt, woman  

45



As can be seen from these examples, our intui-
tions do not easily allow us to make predictions 
concerning the saliency classifications of words.  

Figure 1 (blue curve) shows how well our sys-
tem performs for each class. For the words in 
each class we counted the average number of 
times a human subject had come up with the 
same associative response as the system. It ap-
pears that the system's performance is best for 
very salient words, performing less well in the 
opposite case. Note that this correlates perfectly 
well with the observed human associative behav-
ior: Our system tends to produce the same an-
swers as people for stimulus words yielding ho-
mogeneous human responses. Likewise, the sys-
tem’s answers tend to differ in cases where peo-
ples’ answers are heterogeneous. 

The red curve in Figure 1 shows for each sali-
ency class the number of persons giving the same 
associative answer as an average test person. As 
can be seen this line is almost identical to the one 
representing the system's performance, which 
means that the system's behavior is very similar 
to human behavior with respect to saliency.  

 

  
 
Fig. 1: Quality of our system's (blue curve) and an average 
test person's (red curve) performance (measured as the num-
ber of matching responses found in the EAT) with respect to 
saliency. 

4.2 Word frequency 
Encouraged by the findings for saliency, we con-
ducted a similar experiment for word frequency. 
In this case the EAT stimulus words were split 
into frequency classes according to their corpus  
frequencies in the BNC.  

Since a logarithmic scale seems to be appro-
priate for word frequencies (Rapp, 2005; van 
Heuven et al., in press), we used the following 
six frequency classes (FC):  
 
FC1: 1 occurrence BNC (0.5%)  
FC2: from 1 to 10 occurrences BNC (9.2%)  
FC3: form 10 to 100 occurrences BNC (30.2%) 
FC4: from 100 to 1000 occurrences BNC (42.6%) 

FC5: from 1000 to 10000 occurrences BNC (17.3%) 
FC6: from 10000 to 100000 occurrences BNC (0.1%) 
 
As can be seen from the percentages at the end of 
each line, extremes, i.e. very high and very low 
frequencies are covered only marginally.  

In the first group we find words like cornuco-
pia, jewelry4 and quaff, each appearing only once 
in the corpus, while the frequency class 6 con-
tains only high frequency words such as the 
(auxiliary) verbs be, do, have, and make.  

The results obtained for the frequency classes 
are shown in Figure 2.  As can be seen, the gen-
eral tendency is that the results improve with de-
creasing frequency. Our explanation for this is 
that frequent words tend to be more polysemous, 
and that increased ambiguity tends to yield more 
heterogeneous responses. For example, the am-
biguous stimulus word palm is likely to evoke 
not only responses related to its tree sense, but 
also to its hand sense. 

 

 
 

Fig. 2: Quality of our system's (blue curve) and an average 
test person's (red curve) performance with respect to fre-
quency. 
 

Whereas for mid frequency words the results 
for the test persons and in the simulation show a 
high agreement, this is not the case for high fre-
quency and for low frequency words. For high 
frequency words (FC 6) a plausible explanation 
might be the sampling error due to the low sam-
ple size of only 0.1% of the stimulus words in 
the EAT test set. However, for low frequency 
words the sample sizes are larger and the dis-
crepancy is clearly systematic. Our explanation 
is that in this case we might have a systematic 
sampling error concerning the observed frequen-
cies. The simulation has an advantage because 
the frequency classes were set up according to 

                                                
4  Note that this is the American spelling which is rare in the 

BNC. The British spelling is jewellery. 

46



the BNC frequencies rather than according to the 
subjective frequencies (= word familiarities) of 
the test persons. For example, the words of FC 1 
are guaranteed to occur in the BNC, while it is 
not certain at all that the test persons ever en-
countered them. This leads to a systematic bias 
in favor of the simulation results. 

4.3 Part of speech 
In a last experiment we considered the results for 
the three parts of speech used in our system, 
namely nouns, verbs, and adjectives. We as-
signed to each word in the EAT test set its part of 
speech. Syntactically ambiguous words (which 
can belong to several parts of speech) were as-
signed to their most frequently occurring part of 
speech. Of the 5910 EAT items, 89.2% were 
classified as nouns, 2.4% as verbs, and 8.4% as 
adjectives. 
 

 
 
Fig. 3: Quality of our system's (blue curve) and an average 
test person's (red curve) performance with respect to parts 
of the speech. 
 

For the three categories we obtained the re-
sults shown in Figure 3. The results are best for 
nouns and worst for verbs. Our explanation for 
this is once again average word ambiguity which 
is higher for verbs than it is for nouns. As with 
the saliency classes, we have again a high corre-
lation between the results produced by humans 
and the ones produced by machine. 

5 Discussion and conclusion 
We have presented a novel graph-based algo-
rithm for the computation of word associations. 
The goal was to check whether and to what ex-
tent an automatically built association network 
based on a large text corpus would yield similar 
results to the ones produced by humans. The re-
sults were evaluated with a test set comprising all 
nouns, verbs, and adjectives of the EAT stimulus 

words. This test set is considerably larger than 
the ones used in most previous computational as-
sociation studies. 

Contrary to what could be expected our sys-
tem predicts not only syntagmatic but also para-
digmatic relations. For instance, the pairs black 
→ white, bread → butter and boy → girl are cor-
rectly computed. This shows that texts contain 
not only word pairs encoding syntagmatic rela-
tions but also pairs encoding paradigmatic rela-
tions. The results also show that statistical co-
occurrence-based methods are suitable for tasks 
that traditionally were supposed to require more 
sophisticated symbolic approaches. 

In sum, our approach allows not only to cor-
rectly predict thousands of associations, it also 
matches human performance in other respects: 
For the first time it was shown that the predic-
tions for salient words are much better than for 
non-salient ones. Similarly, concerning word 
frequency and part of speech the simulated re-
sults also closely mimic the behavior as found in 
the human data.  

Altogether, our results provide evidence that 
human associative behavior as observed in the 
classical association experiments can be modeled 
by exploiting the co-occurrences of words in 
large text corpora. There seems to be a circulari-
ty: (a) the word co-occurrences found in text and 
speech5 appear to be externalized forms of the 
associations stored in the human brain, and (b) 
the associations stored in the brain appear to be 
internalized forms of the co-occurrences as found 
in text and speech. This contradiction disappears 
as soon as we realize that time has elapsed be-
tween these two events. Hence, one network may 
be fed by the other, and this may go on. 

Note that our corpus-based approach has fur-
ther virtues: (a) it allows to generate associations 
from corpora covering particular time spans; (b) 
it can produce associations based on corpora 
covering specific topics; (c) it accounts for the 
fact that languages, hence associations, change 
over time. Think of the ideas associated with 
Dominique Strauss-Kahn, one of the top candi-
dates before the last presidential campaign in 
France. While the associations prior to May 18, 
2011 were probably IMF, politics or election, the 
ones after the Sofitel event were probably quite 
different, shifting towards a much more delicate 
topic.  

 
                                                
5  Note that the BNC also contains transcribed speech. 

47



Acknowledgments 
This research was supported by the Marie Curie 
Intra European Fellowships DynNetLAc and Au-
toWordNet within the 7th European Community 
Framework Programme. 

References 
Bird, S.; Klein, E. and Loper, E. (2009). Natural Lan-

guage Processing with Python. O'Reilley Media. 

Burnard, L. and Aston, G. (1998). The BNC Hand-
book: Exploring the British National Corpus. Ed-
inburgh: Edinburgh University Press.  

Church, K.W. and Hanks, P. (1990). Word association 
norms, mutual information, and lexicography. 
Computational Linguistics 16 (1), 22–29.  

Clark, H. H. (1970). Word associations and linguistic 
theory. In J. Lyons (Ed.), New horizons in linguis-
tics (pp. 271-286). Baltimore: Penguin.  

Collins, A. M. and Loftus, E. F. (1975). A spreading-
activation theory of semantic processing. Psycho-
logical Review 8. Vol. 82, No. 6, 407-428. 

Ekpo-Ufot, A. (1978). Word associations: a compara-
tive study among college students in Nigeria and 
the United States. Journal of Cross-Cultural Psy-
chology, Vol. 9(4), 455-468.  

Evert, S. and Krenn, B. (2001). Methods for qualita-
tive evaluation of lexical association measures. In 
Proceedings of the 39th Annual Meeting of the As-
sociation of Computational Linguistics, Toulouse, 
France, 188-915.  

Freud, S. (1901/1975). The psychopathology of eve-
ryday life. Harmondsworth: Penguin. http://psych-
classics.yorku.ca/Freud/Psycho/chap5.htm 

Galton, F. (1879). Psychometric experiments. Brain 
(2), 149-162.  

Van Heuven, W.J.B., Mandera, P., Keuleers, E., & 
Brysbaert, M. (in press). Subtlex-UK: A new and 
improved word frequency database for British 
English. Quarterly Journal of Experimental 
Psychology. 

Hoang, H.H, Kim, S. N. and Kan, M.Y. (2009). A re-
examination of lexical association measures. Pro-
ceedings of the Workshop on Multiword Expres-
sions, ACL-IJCNLP 2009, Suntec, Singapore, 31-
39.  

Istifci, I. (2010). Playing with words: a study on word 
association responses. The Journal of International 
Social Research, 3(10), 360–368 

Jung, C. and F. Riklin. 1906. Experimentelle Untersu-
chungen über Assoziationen Gesunder. In Jung, C. 
G., editor, Diagnostische Assoziationsstudien, 7–
145. Barth, Leipzig. 

Kent, G.H. and Rosanoff, A.J. (1910). A study of as-
sociation in insanity. American Journal of Insanity, 
67, 37–96, 317–390.  

Kiss, G.R., Armstrong, C., Milroy, R., and Piper, J. 
(1973). An associative thesaurus of English and its 
computer analysis. In: A. Aitken, R. Beiley, N. 
Hamilton-Smith (eds.): The Computer and Literary 
Studies. Edinburgh University Press.  

Michelbacher, L., Evert, S. and Schütze, H. (2011). 
Asymmetry in corpus-derived and human associa-
tions. Corpus Linguistics and Linguistic Theory, 
Vo. 7, No. 2, 245–276.  

Pecina, P., and Schlesinger, P. (2006). Combining as-
sociation measures for collocation extraction. Pro-
ceedings of the 21th International Conference on 
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguis-
tics (COLING/ACL 2006), Sydney, Australia, 651-
658. 

Rapp, R. (2005). On the relationship between word 
frequency and word familiarity. In: B. Fisseni; H.-
C. Schmitz; B. Schröder; P. Wagner (Hg.): Sprach-
technologie, mobile Kommunikation und linguisti-
sche Ressourcen. Beiträge zur GLDV-Tagung 2005 
in Bonn. Frankfurt: Peter Lang. 249–263. 

Rosenzweig, M. R. (1961). Comparisons among 
word-assocation responses in English, French, 
German, and Italian. The American Journal of Psy-
chology, Vol. 74, No. 3, 347-360. 

Schwartz, B. and Reisberg, D. (1991). Learning and 
Memory. New York: Norton.  

Seidensticker, P. (2006). Simulation von Wortassozia-
tionen mit Hilfe von mathematischen Lernmodellen 
in der Psychologie. Dissertation an der Universität 
Paderborn.  

Tamir, R. (2005). A Random Walk through Human 
Associations. Proceedings of ICDM 2005: 442-
449.  

Washtell, J.; Markert, K. (2009). A comparison of 
windowless and window-based computational as-
sociation measures as predictors of syntagmatic 
human associations. Proceedings of the 2009 Con-
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP '09), Volume 2, 628-
637 

Wettler, M. and Rapp, R. (1989). A connectionist sys-
tem to simulate lexical decisions in information re-
trieval. In: R. Pfeifer, Z. Schreter, F. Fogelman, L. 
Steels (eds.): Connectionism in Perspective. Am-
sterdam: Elsevier, 463–469.  

Wettler, M., Rapp, R. and Sedlmeier, P. (2005). Free 
word associations correspond to contiguities be-
tween words in texts. Journal of Quantitative Lin-
guistics 12(2), 111–122.  

48


