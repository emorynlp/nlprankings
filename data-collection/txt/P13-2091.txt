



















































Joint Modeling of News Readerâ•Žs and Comment Writerâ•Žs Emotions


Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 511–515,
Sofia, Bulgaria, August 4-9 2013. c©2013 Association for Computational Linguistics

Joint Modeling of News Reader’s and Comment Writer’s Emotions


 

 

Huanhuan Liu
†
  Shoushan Li

†‡*
  Guodong Zhou

†
  Chu-Ren Huang

‡
  Peifeng Li

†
 

 
†
Natural Language Processing Lab 

Soochow University, China 
{huanhuanliu.suda,shoushan.li, 

churenhuang}@gmail.com 

 
‡
Department of CBS 

the Hong Kong Polytechnic University 

{gdzhou,pfli}@suda.edu.cn 

 

 

Abstract 

Emotion classification can be generally done 
from both the writer’s and reader’s 
perspectives. In this study, we find that two 
foundational tasks in emotion classification, 
i.e., reader’s emotion classification on the 
news and writer’s emotion classification on 
the comments, are strongly related to each 
other in terms of coarse-grained emotion 
categories, i.e., negative and positive. On the 
basis, we propose a respective way to jointly 
model these two tasks. In particular, a co-
training algorithm is proposed to improve 
semi-supervised learning of the two tasks. 
Experimental evaluation shows the 
effectiveness of our joint modeling 
approach.

*
 

1 Introduction 

Emotion classification aims to predict the emo-

tion categories (e.g., happy, angry, or sad) of a 

given text (Quan and Ren, 2009; Das and Ban-

dyopadhyay, 2009). With the rapid growth of 

computer mediated communication applications, 

such as social websites and miro-blogs, the re-

search on emotion classification has been attract-

ing more and more attentions recently from the 

natural language processing (NLP) community 

(Chen et al., 2010; Purver and Battersby, 2012). 

In general, a single text may possess two kinds 

of emotions, writer’s emotion and reader’s emo-

tion, where the former concerns the emotion ex-

pressed by the writer when writing the text and 

the latter concerns the emotion expressed by a 

reader after reading the text. For example, con-

sider two short texts drawn from a news and cor-

responding comments, as shown in Figure 1. On 

                                                 
* *  Corresponding author 

one hand, for the news text, while its writer just 

objectively reports the news and thus does not 

express his emotion in the text, a reader could 

yield sad or worried emotion. On the other hand, 

for the comment text, its writer clearly expresses 

his sad emotion while the emotion of a reader 

after reading the comments is not clear (Some 

may feel sorry but others might feel careless). 

 
News:  

Today's Japan earthquake could be 
     2011 quake aftershock. …… 

News Writer’s emotion: None 
News Reader’s emotion: sad, worried 

Comments: 
(1) I hope everything is ok, so sad. I still can 
not forget last year. 
(2) My father-in-law got to experience this 
quake... what a suffering. 

Comment Writer’s emotion: sad 
Comment Reader’s emotion: Unknown 

Figure 1: An example of writer’s and reader’s 

emotions on a news and its comments 

 

Accordingly, emotion classification can be 

grouped into two categories: reader’s emotion 

and writer’s emotion classifications. Although 

both emotion classification tasks have been 

widely studied in recent years, they are always 

considered independently and treated separately.  

However, news and their corresponding com-

ments often appear simultaneously. For example, 

in many news websites, it is popular to see a 

news followed by many comments. In this case, 

because the writers of the comments are a part of 

the readers of the news, the writer’s emotions on 

the comments are exactly certain reflection of the 

reader’s emotions on the news. That is, the 

comment writer’s emotions and the news read-

er’s emotions are strongly related. For example, 

511



in Figure 1, the comment writer’s emotion ‘sad’ 

is among the news reader’s emotions. 

Above observation motivates joint modeling 

of news reader’s and comment writer’s emotions. 

In this study, we systematically investigate the 

relationship between the news reader’s emotions 

and the comment writer’s emotions. Specifically, 

we manually analyze their agreement in a corpus 

collected from a news website. It is interesting to 

find that such agreement only applies to coarse-

grained emotion categories (i.e., positive and 

negative) with a high probability and does not 

apply to fine-grained emotion categories (e.g., 

happy, angry, and sad). This motivates our joint 

modeling in terms of the coarse-grained emotion 

categories. Specifically, we consider the news 

text and the comment text as two different views 

of expressing either the news reader’s or com-

ment writer’s emotions. Given the two views, a 

co-training algorithm is proposed to perform 

semi-supervised emotion classification so that 

the information in the unlabeled data can be ex-

ploited to improve the classification performance. 

2 Related Work  

2.1 Comment Writer’s Emotion Classifica-
tion 

Comment writer’s emotion classification has 

been a hot research topic in NLP during the last 

decade (Pang et al., 2002; Turney, 2002; Alm et 

al., 2005; Wilson et al., 2009) and previous stud-

ies can be mainly grouped into two categories: 

coarse-grained and fine-grained emotion classifi-

cation. 

Coarse-grained emotion classification, also 

called sentiment classification, concerns only 

two emotion categories, such as like or dislike 

and positive or negative (Pang and Lee, 2008; 

Liu, 2012). This kind of emotion classification 

has attracted much attention since the pioneer 

work by Pang et al. (2002) in the NLP communi-

ty due to its wide applications (Cui et al., 2006; 

Riloff et al., 2006; Dasgupta and Ng, 2009; Li et 

al., 2010; Li et al., 2011). 

In comparison, fine-grained emotion classifi-

cation aims to classify a text into multiple emo-

tion categories, such as happy, angry, and sad. 

One main group of related studies on this task is 

about emotion resource construction, such as 

emotion lexicon building (Xu et al., 2010; 

Volkova et al., 2012) and sentence-level or doc-

ument-level corpus construction (Quan and Ren, 

2009; Das and Bandyopadhyay, 2009). Besides, 

all the related studies focus on supervised learn-

ing (Alm et al., 2005; Aman and Szpakowicz, 

2008; Chen et al., 2010; Purver and Battersby, 

2012; Moshfeghi et al., 2011), and so far, we 

have not seen any studies on semi-supervised 

learning on fine-grained emotion classification.  

2.2 News Reader’s Emotion Classification 

While comment writer’s emotion classification 

has been extensively studied, there are only a 

few studies on news reader’s emotion classifica-

tion from the NLP and related communities.  

Lin et al. (2007) first describe the task of read-

er’s emotion classification on the news articles 

and then employ some standard machine learning 

approaches to train a classifier for determining 

the reader’s emotion towards a news. Their fur-

ther study, Lin et al. (2008) exploit more features 

and achieve a higher performance. 

Unlike all the studies mentioned above, our 

study is the first attempt on exploring the rela-

tionship between comment writer’s emotion 

classification and news reader’s emotion classifi-

cation.  

3 Relationship between News Reader’s 
and Comment Writer’s Emotions 

To investigate the relationship between news 

reader’s and comment writer’s emotions, we col-

lect a corpus of Chinese news articles and their 

corresponding comments from Yahoo! Kimo 

News (http://tw.news.yahoo.com), where each 

news article is voted with emotion tags from 

eight categories: happy, sad, angry, meaningless, 

boring, heartwarming, worried, and useful. 

These emotion tags on each news are selected by 

the readers of the news. Note that because the 

categories of “useful” and “meaningless” are not 

real emotion categories, we ignore them in our 

study. Same as previous studies of Lin et al. 

(2007) and Lin et al. (2008), we consider the 

voted emotions as reader’s emotions on the news, 

i.e., the news reader’s emotions. We only select 

the news articles with a dominant emotion (pos-

sessing more than 50% votes) in our data. Be-

sides, as we attempt to consider the comment 

writer’s emotions, the news articles without any 

comments are filtered. 

As a result, we obtain a corpus of 3495 news 

articles together with their comments and the 

numbers of the articles of happy, sad, angry, 

boring, heartwarming, and worried are 1405, 

230, 1673, 75, 92 and 20 respectively. For 

coarse-grained categories, happy and heartwarm-

ing are merged into the positive category while 

512



sad, angry, boring and worried are merged into 

the negative category. 

Besides the tags of the reader’s emotions, each 

news article is followed by some comments, 

which can be seen as a reflection of the writer’s 

emotions (Averagely, each news is followed by 

15 comments). In order to know the exact rela-

tionship between these two kinds of emotions, 

we select 20 news from each category and ask 

two human annotators, named A and B, to manu-

ally annotate the writer’s emotion (single-label) 

according to the comments of each news. Table 1 

reports the agreement on annotators and emo-

tions, measured with Cohen’s kappa (κ) value 

(Cohen, 1960). 
 κ  Value 

(Fine-grained 
emotions) 

κ Value 
(Coarse-grained 

emotions) 
Annotators 0.566 0.742 
Emotions 0.504 0.756 

Table 1: Agreement on annotators and emotions 

 

Agreement between two annotators: The 

annotation agreement between the two annota-

tors is 0.566 on the fine-grained emotion catego-

ries and 0.742 on the coarse-grained emotion 

categories.  

Agreement between news reader’s and 

comment writer’s emotions: We compare the 

news reader’s emotion (automatically extracted 

from the web page) and the comment writer’s 

emotion (manually annotated by annotator A). 

The annotation agreement between the two kinds 

of emotions is 0.504 on the fine-grained emotion 

categories and 0.756 on the coarse-grained emo-

tion categories. From the results, we can see that 

the agreement on the fine-grained emotions is a 

bit low while the agreement between the coarse-

grained emotions, i.e., positive and negative, is 

very high. We find that although some fine-

grained emotions of the comments are not con-

sistent with the dominant emotion of the news, 

they belong to the same coarse-grained category.  

In a word, the agreement between news read-

er’s and comment writer’s emotions on the 

coarse-grained emotions is very high, even high-

er than the agreement between the two annota-

tors (0.754 vs. 0.742).  

In the following, we focus on the coarse-

grained emotions in emotion classification. 

4 Joint Modeling of News Reader’s and 
Comment Writer’s Emotions 

Given the importance of both news reader’s and 

comment writer’s emotion classification as de-

scribed in Introduction and the close relationship 

between news reader’s and comment writer’s 

emotions as described in last section, we system-

atically explore their joint modeling on the two 

kinds of emotion classification. 

In semi-supervised learning, the unlabeled da-

ta is exploited to improve the models with a 

small amount of the labeled data. In our ap-

proach, we consider the news text and the com-

ment text as two different views to express the 

news or comment emotion and build the two 

classifiers 
NC  and CC . Given the two-view clas-

sifiers, we perform co-training for semi-

supervised emotion classification, as shown in 

Figure 2, on both news reader’s and comment 

writer’s emotion classification. 

 

 
Input:   

NewsL  the labeled data on the news 

CommentL the labeled data  on the comments 

NewsU the unlabeled data  on the news  

CommentU  the labeled data  on the comments 

Output: 

NewsL New labeled data on the news 

CommentL  New labeled data on the comments 

 

Procedure: 

 

Loop for N iterations until
NewsU   or CommentU   

(1). Learn classifier 
NC  with NewsL  

(2). Use NC  to label the samples from NewsU   

(3). Choose 
1n  positive and 1n negative news 1N  

most confidently predicted by 
NC  

(4). Choose corresponding comments 
1M (the 

comments of the news in 
1N ) 

(5). Learn classifier 
CC  with CommentL  

(6). Use CC  to label the samples from CommentU   

(7). Choose 2n  positive and 2n negative comments 

2M  most confidently predicted by CC  

(8). Choose corresponding comments 2N (the news 

of the comments in 2M ) 

(9). 1 2News NewsL L N N    

1 2Comment CommentL L M M    

(10). 1 2News NewsU U N N  

1 2Comment CommentU U M M    

 
Figure 2: Co-training algorithm for semi-

supervised emotion classification 

513



5 Experimentation 

5.1 Experimental Settings 

Data Setting: The data set includes 3495 news 

articles (1572 positive and 1923 negative) and 

their comments as described in Section 3. Alt-

hough the emotions of the comments are not giv-

en in the website, we just set their coarse-grained 

emotion categories the same as the emotions of 

their source news due to their close relationship, 

as described in Section 3. To make the data bal-

anced, we randomly select 1500 positive and 

1500 negative news with their comments for the 

empirical study. Among them, we randomly se-

lect 400 news with their comments as the test 

data. 

Features: Each news or comment text is treat-

ed as a bag-of-words and transformed into a bi-

nary vector encoding the presence or absence of 

word unigrams. 

Classification algorithm: the maximum en-

tropy (ME) classifier implemented with the pub-

lic tool, Mallet Toolkits
*
. 

5.2 Experimental Results 

News reader’s emotion classifier: The classifier 

trained with the news text. 

Comment writer’s emotion classifier: The 

classifier trained with the comment text. 

Figure 3 demonstrates the performances of the 

news reader’s and comment writer’s emotion 

classifiers trained with the 10 and 50 initial la-

beled samples plus automatically labeled data 

from co-training. Here, in each iteration, we pick 

2 positive and 2 negative most confident samples, 

i.e, 1 2 2n n  . From this figure, we can see that 

our co-training algorithm is very effective: using 

only 10 labeled samples in each category 

achieves a very promising performance on either 

news reader’s or comment writer’s emotion clas-

sification. Especially, the performance when us-

ing only 10 labeled samples is comparable to that 

when using more than 1200 labeled samples on 

supervised learning of comment writer’s emotion 

classification. 

   For comparison, we also implement a self-

training algorithm for the news reader’s and 

comment writer’s emotion classifiers, each of 

which automatically labels the samples from the 

unlabeled data independently. For news reader’s 

emotion classification, the performances of self-

training are 0.783 and 0.79 when 10 and 50 ini-

                                                 
* http://mallet.cs.umass.edu/ 

tial labeled samples are used. For comment writ-

er’s emotion classification, the performances of 

self-training are 0.505 and 0.508. These results 

are much lower than the performances of our co-

training approach, especially on the comment 

writer’s emotion classification i.e., 0.505 and 

0.508 vs. 0.783 and 0.805. 

 

10 Initial Labeled Samples

0.5

0.6

0.7

0.8

0 400 800 1200 1600 2000 2400

Size of the added unlabeled data
A
c
c
u
r
a
c
y

 

50 Initial Labeled Samples

0.65

0.7

0.75

0.8

0.85

0.9

0 400 800 1200 1600 2000 2400

Size of the added unlabeled data data

A
c
c
u
r
a
c
y

The news reader's emotion
classifier (Co-training)
The comment writer's emotion
classifier (Co-training)

 Figure 3: Performances of the news reader’s and 

comment writer’s emotion classifiers using the 

co-training algorithm 

6 Conclusion 

In this paper, we focus on two popular emotion 

classification tasks, i.e., reader’s emotion classi-

fication on the news and writer’s emotion classi-

fication on the comments. From the data analysis, 

we find that the news reader’s and comment 

writer’s emotions are highly consistent to each 

other in terms of the coarse-grained emotion cat-

egories, positive and negative. On the basis, we 

propose a co-training approach to perform semi-

supervised learning on the two tasks. Evaluation 

shows that the co-training approach is so effec-

tive that using only 10 labeled samples achieves 

nice performances on both news reader’s and 

comment writer’s emotion classification.  

514



Acknowledgments 

This research work has been partially supported 

by two NSFC grants, No.61003155, and 

No.61273320, one National High-tech Research 

and Development Program of China 

No.2012AA011102, one General Research Fund 

(GRF) sponsored by the Research Grants Coun-

cil of Hong Kong No.543810, the NSF grant of 

Zhejiang Province No.Z1110551, and one pro-

ject supported by Zhejiang Provin-cial Natural 

Science Foundation of China, No.Y13F020030.  

References  

Alm C., D. Roth and R. Sproat. 2005. Emotions from 
Text: Machine Learning for Text-based Emotion 
Prediction. In Proceedings of EMNLP-05, pp.579-
586. 

Aman S. and S. Szpakowicz. 2008. Using Roget’s 
Thesaurus for Fine-grained Emotion Recognition. 

In Proceedings of IJCNLP-08, pp.312-318. 

Chen Y., S. Lee, S. Li and C. Huang. 2010. Emotion 
Cause Detection with Linguistic Constructions. In 
Proceeding of COLING-10, pp.179-187. 

Cohen J. 1960. A Coefficient of Agreement for Nom-

inal Scales. Educational and Psychological Meas-

urement, 20(1):37–46. 

 Cui H., V. Mittal and M. Datar. 2006. Comparative 

Experiments on Sentiment Classification for 

Online Product Comments. In Proceedings of 

AAAI-06, pp.1265-1270. 

Das D. and S. Bandyopadhyay. 2009. Word to Sen-

tence Level Emotion Tagging for Bengali Blogs. In 

Proceedings of ACL-09, pp.149-152. 

Dasgupta S. and V. Ng. 2009. Mine the Easy, Classify 

the Hard: A Semi-Supervised Approach to Auto-

matic Sentiment Classification. In Proceedings of 

ACL-IJCNLP-09,  pp.701-709, 2009. 

Duin R. 2002. The Combining Classifier: To Train Or 

Not To Train? In Proceedings of 16th International 

Conference on Pattern Recognition (ICPR-02). 

Fumera G. and F. Roli. 2005. A Theoretical and Ex-

perimental Analysis of Linear Combiners for Mul-

tiple Classifier Systems. IEEE Trans. PAMI, vol.27, 

pp.942–956, 2005. 

Li S., Z. Wang, G. Zhou and S. Lee. 2011. Semi-

supervised Learning for Imbalanced Sentiment 

Classification. In Proceeding of IJCAI-11,  pp.826-

1831. 

Li S., C. Huang, G. Zhou and S. Lee.  2010. Employ-

ing Personal/Impersonal Views in Supervised and 

Semi-supervised Sentiment Classification. In Pro-

ceedings of ACL-10,  pp.414-423. 

Lin K., C. Yang and H. Chen. 2007. What Emotions 

do News Articles Trigger in Their Readers? In 

Proceeding of SIGIR-07, poster, pp.733-734. 

Lin K., C. Yang and H. Chen. 2008. Emotion Classi-

fication of Online News Articles from the Reader’s 

Perspective. In Proceeding of the International 

Conference on Web Intelligence and Intelligent 

Agent Technology, pp.220-226. 

 Liu B. 2012. Sentiment Analysis and Opinion Mining 
(Introduction and Survey). Morgan & Claypool 
Publishers, May 2012. 

Kittler J., M. Hatef, R. Duin, and J. Matas. 1998. On 
Combining Classifiers. IEEE Trans. PAMI, vol.20, 
pp.226-239, 1998 

Moshfeghi Y., B. Piwowarski and J. Jose. 2011. Han-

dling Data Sparsity in Collaborative Filtering using 

Emotion and Semantic Based Features. In Proceed-

ings of SIGIR-11, pp.625-634. 

Pang B. and L. Lee. 2008. Opinion Mining and 

Sentiment Analysis: Foundations and Trends. 

Information Retrieval, vol.2(12), 1-135. 

Pang B., L. Lee and S. Vaithyanathan. 2002. Thumbs 

up? Sentiment Classification using Machine 

Learning Techniques. In Proceedings of EMNLP-

02, pp.79-86. 

Purver M. and S. Battersby. 2012. Experimenting 

with Distant Supervision for Emotion Classifica-

tion. In Proceedings of EACL-12, pp.482-491. 

Quan C. and F. Ren. 2009. Construction of a Blog 

Emotion Corpus for Chinese Emotional Expression 

Analysis. In Proceedings of EMNLP-09, pp.1446-

1454. 

Riloff E., S. Patwardhan and J. Wiebe. 2006. Feature 

Subsumption for Opinion Analysis. In Proceedings 

of EMNLP-06, pp.440-448. 

Turney P. 2002. Thumbs up or Thumbs down? 

Semantic Orientation Applied to Unsupervised 

Classification of comments. In Proceedings of 

ACL-02, pp.417-424.  

Vilalta R. and Y. Drissi. 2002. A Perspective View 

and Survey of Meta-learning. Artificial Intelligence 

Review, 18(2): 77–95. 

Volkova S., W. Dolan and T. Wilson. 2012. CLex: A 

Lexicon for Exploring Color, Concept and Emo-

tion Associations in Language. In Proceedings of 

EACL-12, pp.306-314. 

Wilson T., J. Wiebe, and P. Hoffmann. 2009. 

Recognizing Contextual Polarity: An Exploration 

of Features for Phrase-Level Sentiment Analysis. 

Computational Linguistics, vol.35(3), pp.399-433. 

Xu G., X. Meng and H. Wang. 2010. Build Chinese 

Emotion Lexicons Using A Graph-based 

Algorithm and Multiple Resources. In Proceeding 

of COLING-10, pp.1209-1217. 

515


