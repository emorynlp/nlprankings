



















































Refinements to Interactive Translation Prediction Based on Search Graphs


Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 574–578,
Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics

Refinements to Interactive Translation Prediction
Based on Search Graphs

Philipp Koehn�?, Chara Tsoukala? and Herve Saint-Amand?
�Center for Speech and Language Processing, The Johns Hopkins University

?School of Informatics, University of Edinburgh
phi@jhu.edu, ctsoukal@inf.ed.ac.uk, hsamand@inf.ed.ac.uk

Abstract

We propose a number of refinements to the
canonical approach to interactive trans-
lation prediction. By more permissive
matching criteria, placing emphasis on
matching the last word of the user prefix,
and dealing with predictions to partially
typed words, we observe gains in both
word prediction accuracy (+5.4%) and let-
ter prediction accuracy (+9.3%).

1 Introduction

As machine translation enters the workflow of
professional translators, the exact nature of this
human-computer interaction is currently an open
challenge. Instead of tasking translators to post-
edit the output of machine translation systems, a
more interactive approach may be more fruitful.

One such idea is interactive translation predic-
tion (Langlais et al., 2000b): While the user writes
the translation for a sentence, the system makes
suggestions for sequent words. If the user di-
verges from the suggestions, the system recalcu-
lates its prediction, and offers new suggestions.
This input modality is familiar to anybody who
has used auto-complete functions in text editors,
cell phones, or web applications.

The technical challenge is to come up with a
method that predicts words that the user will ac-
cept. The standard approach to this problem uses
the search graph of the machine translation sys-
tem. Such search graphs may be recomputed in a
constraint decoding process restricted to the par-
tial user input (called the prefix), but this is often
too slow with big models and limited computing
resources, so we use static word graphs.

The user prefix is matched against the search
graph. If the user prefix cannot be found in the
search graph, approximate string matching is used
by finding a path with minimal string edit distance,
i.e., a path in the graph with the minimal number
of insertions, deletions and substitutions to match
the user prefix.

This paper presents a number of refinements
to extend this approach, by allowing more per-
missive matching criterion, placing emphasis on
matching the last word of the user prefix, and deal-
ing with predictions to partially typed words. We
show improvements in word prediction accuracy
from 56.1% to 60.5% and letter prediction accu-
racy from 75.2% to 84.5% on a publicly available
benchmark (English-Spanish news translation).

2 Related Work

The interactive machine translation paradigm was
first explored in the TransType and TransType2
projects (Langlais et al., 2000a; Foster et al.,
2002; Bender et al., 2005; Barrachina et al., 2009).
Given the computational cost and need for quick
response time, most current word operates on
search graphs (Och et al., 2003). Such search
graphs can be efficiently represented and pro-
cessed with finite state tools (Civera et al., 2004).
More recently, the approach has been extended to
SCFG-based translation models (González-Rubio
et al., 2013).

There are several ways the sentence completion
predictions can be presented to the user: show-
ing the complete sentence prediction, only a few
words, or multiple choices. User actions may be
also extended to mouse actions to pinpoint the di-
vergence from an acceptable translation (Sanchis-
Trilles et al., 2008), or hand-writing (Alabau et al.,
2011) and speech modalities (Cubel et al., 2009).

3 Properties of Core Algorithm

Our implementation of the core algorithm follows
closely Koehn (2009). It is a dynamic program-
ming solution that computes the minimal cost to
reach each node in the search graph by matching
parts of the user prefix. Cost is measured primar-
ily in terms of string edit distance (number of dele-
tions, insertions and substitutions), and secondary
in terms of translation model score for the matched
path in the graph. Search is done iteratively, with
an increasing number of allowable edits.

574



prefix

time

5 10 15 20 25 30 35 40
0ms

8ms

16ms

24ms

32ms

40ms

48ms

56ms

64ms

72ms

80ms

0 edits

1 edit

2 edits

3 edits

4 edits
5 edits6 edits

7 edits8 edits

Figure 1: Average response time of baseline
method based on length of the prefix and number
of edits: The main bottleneck is the string edit dis-
tance between prefix and path.

3.1 Experimental Setup
Given the large number of proposed variations of
the algorithm, we do not carry out user studies, but
rather use a simulated setting. We predict transla-
tions that were crafted by manual post-editing of
machine translation output. We also use the search
graphs of the system that produced the original
machine translation output.

Such data has been made available by the CAS-
MACAT project1. In the project’s first field trial2,
professional translators corrected machine transla-
tions of news stories from a competitive English–
Spanish machine translation system (Koehn and
Haddow, 2012). This test set consists of 24,444
word predictions and 141,662 letter predictions.

3.2 Prediction Speed
Since the interactive translation prediction process
is used in an interactive setting where each key
stroke of the user may trigger a new request, very
fast response time is needed. According to stan-
dards in usability engineering

0.1 second is about the limit for having
the user feel that the system is reacting
instantaneously (Nielsen, 1993).

So, this is the time limit we have to set ourselves
to predict the next words of a translator.

What are the main factors that influence pro-
cessing time in our core algorithm? See Figure 1
for an illustration. We plot processing time against

1http://www.casmacat.eu/
2http://www.casmacat.eu/uploads/Deliverables/d6.1.pdf

prefix

failure rate

5 10 15 20 25 30 35 40
0%

10%

20%

30%

40%

50%

60%

70%

80%

90%

100%

6 edits
7 edits

9 edits

11 edits

12 edits

13 edits

14 edits
15 edits

Figure 2: Ratio of prefix matching processes aban-
doned due to exceeding the 100ms time limit
(showing only curves with a minimum of 5 edits).

the length of the user prefix and the string edit dis-
tance between the user prefix and the search graph.
The graph clearly shows that the main slowdown
in processing time occurs when the edit rate in-
creases.

To guarantee a response in 100ms, the algo-
rithms aborts when this time is exceeded and re-
lies on a prediction based on string edit distance
against the best path in the graph. The larger the
number of edits, the more often this occurs, as Fig-
ure 2 shows.

3.3 Accuracy

We are mainly interested in the accuracy of the
method: How often does it predict a word that the
user accepts? There is a trade-off between speed
and accuracy.

One way we can balance this trade-off is by re-
moving nodes from the search graph. By thresh-
old pruning (Sanchis-Trilles and Ortiz-Martı́nez,
2014), we remove nodes from the search graph
that are only part of paths that are worse than the
best path by a specified score difference.

See Table 1 how the choice of the score differ-
ence threshold impacts failure rate and accuracy.
A wider threshold has the potential to achieve bet-
ter results (if we allows for up to 1 second of pro-
cessing time), but with the constraint of 100ms re-
sponse time, the optimum is with a threshold of
0.4. Wider thresholds lead to a higher failure rate,
causing overall lower accuracy.

575



Threshold 100ms Max 1000ms Max
Acc. Fail Acc. Fail

0.3 55.8% 4.5% 56.9% 0.0%
0.4 56.1% 6.5% 58.0% 0.0%
0.5 55.9% 9.0% 58.8% 0.0%
0.6 55.5% 11.6% 59.4% 0.0%
0.8 54.4% 17.1% 59.4% 0.0%
1.0 52.7% 21.7% 58.6% 6.5%

Table 1: Impact of threshold pruning on search ac-
curacy and failure rate (i.e., failure to complete
search in given time and resorting to matching
against best translation).

4 Refinements

We now introduce a number of refinements over
the core method. Given the constraints established
in the previous section (maximum response time
of 100ms, pruning threshold 0.4), we set out to
improve accuracy.

4.1 Matching Last Word
The first idea is that it is more important to match
the last word of the user prefix than having mis-
matches in earlier words. We attempt to find the
last word in the predicted path either before or
after the optimal matching position according to
string edit distance.

We combine the matched path in the prefix with
the optimal suffix, and search for the last user pre-
fix word within a window. This means that we
either move words from the suffix to the prefix or
the other way around, without changing the over-
all string along the path.

Table 2 shows the impact on accuracy for differ-
ent window sizes. While we expected some gains
by checking for the word somewhere around the
optimal position in the predicted path, we do see
significant gains by not placing any restrictions to
where the word can be found, except for a bias
to less distant positions. For instance, examining
a window of up to 3 words gives us a word pre-
diction accuracy of 57.2% versus the 56.1% base-
line. Finding the last word anywhere boosts per-
formance to 59.1%.

The table also reports accuracy numbers when
we allow the process to run up to 1 second —
which is basically an exhaustive search but not
practically useful. These numbers shed some light
on why an unlimited window size in matching the
last word helps: the gains come partially from the
cases where the initial search fails. Finding the
last user word anywhere in the machine transla-

Window 100ms Max 1000ms Max
baseline 56.1% 58.0%
1 word 56.6% 58.4%
2 words 56.9% 58.6%
3 words 57.2% 58.9%
5 words 57.8% 59.3%

anywhere 59.1% 59.5%

Table 2: Search for the last prefix word in a win-
dow around the predicted position in the matched
path.

Word Matching 100ms Max 1000ms Max
baseline 59.1% 59.5%

case-insensitive 58.7% 59.4%

Table 3: Search with case-insensitive word match-
ing (say, University and university).

tion output is a better fallback than computing op-
timal string edit distance. Analysis of the data
suggests that gains mainly come from large length
mismatches between user translation and machine
translation, even in the case of first pass searches.

4.2 Case-Insensitive Matching
Some mismatches between words matter less than
others. For instance, if the user prefix differs only
in casing from the machine translation (say, Uni-
versity instead of university), then we may still
want to treat that as a word match in our al-
gorithm. However, as Table 3 shows, allowing
case-insensitive matching leads to lower accuracy
(58.7% vs. 59.1%).

A major reason is computational cost. The most
inner loop in the algorithm compares words. This
is optimized by representing words as integers.
However, if we allow case-insensitive matching,
this simple method does not work anymore. We do
precompute approximate word matches and store
matching words identifiers in a hash map, but still
the ratio of searches that do not complete in 100ms
increases from 6.5% to 9.7%. By extending the al-
lowable time to 1 second, the accuracy gap is re-
duced to 0.1%.

4.3 Approximate Word Matching
When a word in the user translation differs from
a word in the decoder search graph only by a few
letters, then it should be considered a lesser error
than substitutions of completely different words.
Such word differences may be due to casing, mor-
phological variants, or spelling inconsistencies.

We compute word dissimilarity by computing

576



Max. Dissimilarity 100ms Max. 1000ms Max.
baseline 59.1% 59.5%

30% 60.2% 61.0%
20% 60.4% 61.3%
10% 60.6% 61.5%

Table 4: Counting substitutions between similar
words as half an error. Dissimilarity is measured
as letter edit distance

Min Stem / Max Suffix 100ms 1000ms
baseline 59.1% 59.5%

4 / 3 59.4% 60.1%
3 / 3 59.5% 60.2%
2 / 3 59.5% 60.3%

Table 5: Counting substitutions between morpho-
logical variants as half an error. Morphological
variance is approximated by requiring a minimum
number of initial letters to match and a maximum
of final letters to differ.

the ratio of letter edit operations to the length of
the shorter word.3 We now set a threshold for
maximum dissimilarity, under which mismatched
words are considered only half the edit cost of
other edit operations.

Table 4 shows that we get significantly higher
word prediction accuracy than with the baseline
approach (up to 60.6% vs. 59.1%), and the best
performance with a 10% threshold. We observe
the same computational problem as in the previous
section (about 9.2% first pass failures, vs. 6.5%),
reflected in a higher accuracy gap for 100ms and
1000ms time limits.

4.4 Stemmed Matching
We suspected that the main benefit of approximate
word matching is the better handling of morpho-
logical variants. In Spanish, this mainly consti-
tutes itself as different word endings. Thus, we re-
define our word dissimilarity measure by consider
words similar, if they agree in at least a number
of leading letters (presumably the stem), and may
differ in at most a number of trailing letters (pre-
sumably the morpheme).

Table 5 shows that this is successful in increas-
ing the word prediction rate (59.5% vs. 59.1%)
but not as much as with the more general approx-
imate word matching in the previous section (re-
call: 60.6%).

3For instance, if a 6 letter word and a 4 letter word can
be matched with two deletions and one substitution, then the
dissimilarity score is 3

4
= .75.

# Method Word Acc. Letter Acc.
1 baseline 56.0% 75.2%
2 1+matching last word 59.0% 80.6%
3 2+case insensitive 58.7% 80.4%
4 2+dissimilarity 10% 60.5% 80.6%
5 2+stem 2/3 59.4% 80.5%
6 4+desperate 60.5% 84.5%

Table 6: Extending the approach to word com-
pletion. Impact of refinements of letter prediction
accuracy with additional desperate word matching
against the entire vocabulary.

5 Word Completion

Besides word prediction, word completion is also
a useful feature in an interactive translation tool.
When the machine translation system decides for
college over university, but the user types the letter
u, it should change its prediction.

To enable word completion in the canonical al-
gorithm, we allow matching of the final user word
(if not followed by a space character) as a prefix of
any word as a zero cost operation. The predicted
suffix that is returned to the user then starts with
the remaining letters of the word in the path.

Table 6 shows that the refinements that helped
sentence completion also benefit word comple-
tion. From a baseline accuracy of 75.2% correctly
predicted letters, we reach up to 80.6%. Note that
the baseline word prediction accuracy is slightly
lower (56.0% vs. 56.1%) than in the previous ex-
periments, since the previously correctly matched
last word may be mistaken as the prefix of another
word.

We add an additional refinement to this task: If
the potentially incomplete final word of the user
prefix cannot be found in the predicted path, then
we explore the entire vocabulary from the un-
pruned search graph for completions. If multiple
words match, the one with the highest path score
is used. This desperate word completion method
gives significant gains (84.5% over 80.6%).

6 Conclusion and Future Work

We observe most improvements by a focus on
the last word of the user prefix and approximate
word matching. This suggests that there may be
additional gains by a stronger focus on the tail
of the user prefix. Also, the findings from the
time/productivity tradeoffs indicate that more time
efficient algorithms and implementations should
be explored.

577



Acknowledgements

This work was supported under the CASMACAT
project (grant agreement No 287576) by the
European Union 7th Framework Programme
(FP7/2007-2013).

References

Alabau, V., Sanchis, A., and Casacuberta, F. (2011).
Improving on-line handwritten recognition using
translation models in multimodal interactive ma-
chine translation. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Techologies, pages 389–
394, Portland, Oregon, USA. Association for Com-
putational Linguistics.

Barrachina, S., Bender, O., Casacuberta, F., Civera, J.,
Cubel, E., Khadivi, S., Lagarda, A., Ney, H., Tomás,
J., Vidal, E., and Vilar, J.-M. (2009). Statistical ap-
proaches to computer-assisted translation. Compu-
tational Linguistics, 35(1).

Bender, O., Hasan, S., Vilar, D., Zens, R., and Ney,
H. (2005). Comparison of generation strategies for
interactive machine translation. In Proceedings of
the 10th Conference of the European Association for
Machine Translation (EAMT), Budapest.

Civera, J., Cubel, E., Lagarda, A. L., Picó, D.,
González, J., Vidal, E., Casacuberta, F., Vilar, J. M.,
and Barrachina, S. (2004). From machine translation
to computer assisted translation using finite-state
models. In Lin, D. and Wu, D., editors, Proceedings
of EMNLP 2004, pages 349–356, Barcelona, Spain.
Association for Computational Linguistics.

Cubel, E., Khadivi, S., Lagarda, A., Ney, H., Toms,
J., Vidal, E., and Vilar, J.-M. (2009). Statistical ap-
proaches to computer-assisted translation. Compu-
tational Linguistics, 35(1).

Foster, G., Langlais, P., and Lapalme, G. (2002). User-
friendly text prediction for translators. In Proceed-
ings of the Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 148–
155, Philadelphia. Association for Computational
Linguistics.

González-Rubio, J., Ortı́z-Martinez, D., Benedı́, J.-
M., and Casacuberta, F. (2013). Interactive ma-
chine translation using hierarchical translation mod-
els. In Proceedings of the 2013 Conference on Em-
pirical Methods in Natural Language Processing,
pages 244–254, Seattle, Washington, USA. Associ-
ation for Computational Linguistics.

Koehn, P. (2009). A process study of computer-aided
translation. Machine Translation, 23(4):241–263.

Koehn, P. and Haddow, B. (2012). Towards effective
use of training data in statistical machine translation.

In Proceedings of the Seventh Workshop on Statisti-
cal Machine Translation, pages 363–367, Montreal,
Canada. Association for Computational Linguistics.

Langlais, P., Foster, G., and Lapalme, G. (2000a).
Transtype: a computer-aided translation typing sys-
tem. In Proceedings of the ANLP-NAACL 2000
Workshop on Embedded Machine Translation Sys-
tems.

Langlais, P., Foster, G., and Lapalme, G. (2000b). Unit
completion for a computer-aided translation typing
system. In Proceedings of Annual Meeting of the
North American Chapter of the Association of Com-
putational Linguistics (NAACL).

Nielsen, J. (1993). Usability Engineering. Morgan
Kaufmann.

Och, F. J., Zens, R., and Ney, H. (2003). Efficient
search for interactive statistical machine translation.
In Proceedings of Meeting of the European Chap-
ter of the Association of Computational Linguistics
(EACL).

Sanchis-Trilles, G. and Ortiz-Martı́nez, D. (2014). Ef-
ficient wordgraph pruning for interactive translation
prediction. In Annual Conference of the European
Association for Machine Translation (EAMT).

Sanchis-Trilles, G., Ortiz-Martı́nez, D., Civera, J.,
Casacuberta, F., Vidal, E., and Hoang, H. (2008).
Improving interactive machine translation via mouse
actions. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Process-
ing, pages 485–494, Honolulu, Hawaii. Association
for Computational Linguistics.

578


