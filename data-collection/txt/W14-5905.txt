



















































A Rule-Based Approach to Aspect Extraction from Product Reviews


Proceedings of the Second Workshop on Natural Language Processing for Social Media (SocialNLP), pages 28–37,
Dublin, Ireland, August 24 2014.

A Rule-Based Approach to Aspect Extraction from Product Reviews

Soujanya Poria
Dept of Computing Science & Maths

University of Stirling
soujanya.poria@cs.stir.ac.uk

Erik Cambria
School of Computer Engineering

Nanyang Technological University
cambria@ntu.edu.sg

Lun-Wei Ku
Institute of Information Science

Academia Sinica
lwku@iis.sinica.edu.tw

Chen Gui
SenticNet

chen@sentic.net

Alexander Gelbukh
Center for Computing Research
National Polytechnic Institute
gelbukh@cic.ipn.mx

Abstract

Sentiment analysis is a rapidly growing research field that has attracted both academia and in-
dustry because of the challenging research problems it poses and the potential benefits it can
provide in many real life applications. Aspect-based opinion mining, in particular, is one of the
fundamental challenges within this research field. In this work, we aim to solve the problem of
aspect extraction from product reviews by proposing a novel rule-based approach that exploits
common-sense knowledge and sentence dependency trees to detect both explicit and implicit as-
pects. Two popular review datasets were used for evaluating the system against state-of-the-art
aspect extraction techniques, obtaining higher detection accuracy for both datasets.

1 Introduction

In opinion mining, different levels of granularity analysis have been proposed, each one having its own
advantages and disadvantages. Aspect-based opinion mining (Hu and Liu, 2004; Ding et al., 2008)
focuses on the extraction of aspects (or product features) from opinionated text and on the inference of
polarity values associated with these. For example, a sentence like “I love the touchscreen of my phone
but the battery life is so short” contains two aspects or opinion targets, namely touchscreen and battery
life. In this case, applying a sentence level polarity detection technique would mistakenly result in a
polarity value close to neutral, since the two opinions expressed by the users are opposite. Hence, aspect
extraction is necessary to first deconstruct sentences into product features and then assign a separate
polarity value to each of these features.

There are two types of aspects defined in aspect-based opinion mining: explicit and implicit. Explicit
aspects are concepts that explicitly denote targets in the opinionated sentence. For instance, in the above
example, touchscreen and battery life are explicit aspects as they are explicitly mentioned in the sentence.
On the other hand, an aspect can also be expressed indirectly through an implicit aspect clue (IAC), e.g.,
in the sentence “This camera is sleek and very affordable”, which implicitly provides a positive opinion
about the aspects appearance and price of the entity camera.

Explicit aspect extraction has been widely researched and there exists several approaches for this
task. Still, limited work has been done in extracting implicit aspects. This task is very difficult yet very
important because the phenomenon of implicit aspects is present in nearly every opinionated document.
For example, the following document extracted from the corpus (Hu and Liu, 2004) uses only implicit
aspects:

This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings
footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0

28



This is the best phone one could have. It has all the features one would need in a cellphone: It
is lightweight, sleek and attractive. I found it very user-friendly and easy to manipulate; very
convenient to scroll in menu etc.

Here, the word “lightweight” refers to the weight of the phone; the words “sleek” and “attractive” to
its appearance; the compound “user-friendly” to its interface; the phrase “easy to manipulate” to its
functionality; finally, the phrase “to scroll in menu” can be interpreted as a reference to the interface
of the phone or its menu. Even though the aspects appearance, weight and interface do not appear
in the sentence, the context contains clues that permit us to infer them. Namely, the words “sleek,”
“lightweight,” and “user-friendly” that do occur in the context suggest these aspects.

In contrast to the task of identification of explicit aspects, the general scheme for identification of
implicit aspects, a task called implicit aspect extraction, typically involves two steps:

1. Identify IACs (e.g., “sleek”) in the opinionated document.

2. Map them to the corresponding aspects (e.g., appearance).

In this paper, we propose a novel approach to detect explicit aspects and IACs from opinionated
documents. We also map IACs to their respective aspect categories. IACs are either single words,
such as “sleek,” or multi-word expressions, such as “easy to manipulate” as in the above example. Each
IAC can be represented by a different part-of-speech (POS): in the example “This MP3 player is really
expensive,” the IAC “expensive” suggesting the aspect price is an adjective; in “This camera looks
great,” the IAC “look” suggesting appearance is a verb; in “I hate this phone. It only lasted less than six
months!”, the IAC “lasted” suggesting durability of the phone is a verb. In the following examples, IACs
are nouns or noun phrases: “Even if I had paid full price I would have considered this phone a good deal,”
“Not to mention the sleekness of this phone”, “The player keeps giving random errors”, “This phone is a
piece of crap.”

In different contexts, the same implicit aspect can be implied by different IACs, as shown below for
the implicit aspect price:

• This mp3 player is very affordable.
• This mp3 player also costs a lot less than the ipod.
• This mp3 player is quite cheap.
• This mp3 is inexpensive.
• I bought this mp3 for almost nothing!
• This mp3 player has been fairly innovative and reasonably priced.
A common approach for IAC identification is to assume that sentiments or polarity words are good

candidates for IACs: for example, in “This MP3 player is really expensive,” the word “expensive”,
which bears negative polarity, is also the IAC for the aspect price. However, this is not always true.
For example, in “This camera looks great,” the word “looks” implies the appearance of the phone,
while polarity is conveyed through the word “great.” In “I hate this phone. It only lasted less than six
months!”, the word “lasted” is the IAC for durability of the phone, while polarity is indicated by “hate.”
Furthermore, the second sentence of this example could appear without the first one: “This phone only
lasted less than six months” and still constitute a negative opinion of the phone’s durability, but not
expressed by any specific word.

This phenomenon is known in opinion mining as desirable fact: communicating fact that by common-
sense are good or bad, which indirectly implies polarity. For example, the objective fact “The camera can
hold lots of pictures” does not contain any sentiment or polarity word yet gives a positive opinion about
the camera’s memory capacity (IAC “hold”), because it is desirable for a camera to hold many pictures.

29



In this paper, we present a rule-based approach that exploits common-sense knowledge and sentence
dependency trees to detect both implicit and explicit aspects. In particular, the approach draws lessons
from recent developments in common-sense reasoning (Cambria et al., 2011; Cambria et al., 2014a)
and concept-level sentiment analysis (Xia et al., 2013; Poria et al., 2014) to first obtain the dependency
structure of each sentence and, hence, exploit external knowledge to extract aspects and infer the polarity
associated with them. The paper is organized as follows: Section 2 presents the literature in aspect ex-
traction; Section 3 explains the features used for the labeler; Section 4 discusses novelty of the proposed
methodology; Section 5 describes in detail the aspect extraction approach and results of the experimental
evaluation; finally, Section 6 concludes the paper.

2 Related Work

Aspect extraction from opinionated text was first studied by Hu and Liu (Hu and Liu, 2004), who also
introduced the distinction between explicit and implicit aspects. However, the authors only dealt with
explicit aspects by adopting a set of rules based on statistical observations. Hu and Liu’s method was im-
proved by Popescu and Etzioni (Popescu and Etzioni, 2005) and by Blair-Goldensonh (Blair-Goldensohn
et al., 2008). Popescu and Etzioni assumed the product class to be known as priori. Their algorithm
detects whether a noun or noun phrase is a product feature or not by computing PMI between the noun
phrase and the product class. Scaffidi et al. (Scaffidi et al., 2007) presented a method that uses a language
model to identify product features. They assumed that product features are more frequent in product re-
views than in general natural language text. However, their method seems to be very inaccurate in terms
of precision as the retrieved aspects extracted by their method were very noisy.

Aspect extraction can be seen as a general information extraction problem, for which techniques based
on sequential labeling are generally used. The most popular methods in this context, in particular, are
Hidden Markov Models (HMM) and Conditional Random Fields (CRF) (Lafferty et al., 2001). Jin and
Ho (Jin and Ho, 2009) used a lexicalized HMM for joint extraction of opinions along with their explicit
aspects. Niklas and Gurevych (Niklas and Gurevych, 2010) used CRF to extract explicit aspects in a
custom corpus with data of different domains. Li et al. (Li et al., 2010), Choi and Cardie (Choi and
Cardie, 2010) and Huang et al. (Huang et al., 2012) also used CRF for extraction of explicit aspects.

As to the implicit aspects, the OPINE extraction system developed by Popescu and Etzioni (Popescu
and Etzioni, 2005) was the first that leveraged on the extraction of this type of aspects to improve polarity
classification. However, their system is not described in detail and is not publicly available. To the
best of our knowledge, all existing methods for implicit aspect extraction are based on the use, in one
or another way, of what we term IAC. Su (Su et al., 2008) proposed a clustering method to map IACs
(which were assumed to be sentiment words) to their corresponding explicit aspects. The method exploits
the mutual reinforcement relationship between an explicit aspect and a sentiment word forming a co-
occurring pair in a sentence. Hai (Zhen et al., 2011) proposed a two-phase co-occurrence association
rule mining approach to match implicit aspects (which were also assumed to be sentiment words) with
explicit aspects. Finally, Zeng and Li (Zeng and Li, 2013) proposed a rule-based method to extract
explicit aspects and mapped implicit features by using a set of sentiment words and by clustering explicit
feature-word pairs.

3 Method

3.1 Corpus for aspect extraction
In order to evaluate the explicit aspect extraction algorithm, we use the corpus provided by (Hu and
Liu, 2004) and the Semeval 2014 dataset1 (Table 1). As for the implicit aspect extraction algorithm and
lexicon, we use the corpus developed by Cruz-Garcia et al. (Cruz-Garcia et al., 2014), who manually
labeled each IAC and their corresponding aspects in a well-known corpus for opinion mining (Hu and
Liu, 2004). The corpus is publicly available for research purposes.2

1http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools
2Available from www.gelbukh.com/resources/implicit-aspect-extraction-corpus, visited on

March 19, 2014.

30



Table 1: Description of Semeval 2014 dataset
Sentences Containing n aspect terms

Domain Name n = 0 n≥ 1 n≥ 2 total(n≥ 0)
Restaurants 1,732 2,212 881 3,944
Laptops 1,883 2,065 456 3,948

3.2 Pre-Processing
Pre-processing is a key step for aspect parsing. The pre-processing module of the proposed framework
consists of two major steps: firstly, the sentence dependency tree is obtained through Stanford Depen-
dency Parser3; secondly, dependency structure elements are processed by means of Stanford Lemmatizer
for each sentence. It is important to build the dependency tree before lemmatization as swapping the two
steps results in several imprecisions caused by the lower grammatical accuracy of lemmatized sentences.

3.3 Aspect Parser
3.3.1 Implicit aspect lexicon
We use the implicit aspect corpus developed by Cruz-Garcia et al. (Cruz-Garcia et al., 2014), where
IACs are indicated and manually labeled by their corresponding aspect categories. For our task, we
extracted the sentences having implicit aspects and then extracted IACs for each of them, along with
their corresponding labeled categories. For example, in “The car is expensive” the IAC is expensive and
it is labeled by the category price. Below is the list of the aspect categories extracted from the corpus:

• functionality
• weight
• price
• appearance
• behavior
• performance
• quality
• service
• size

For each IAC under every aspect category, synonyms and antonyms were obtained from WordNet (Fell-
baum, 1998) and stored under the same aspect category. For example, expensive and its antonym inex-
pensive both have the same category price. Semantics extracted from SenticNet (Cambria et al., 2014b)
have also been exploited to enlarge the set of conceptually related IACs. Thus, a lexicon of 1,128 IACs
categorized into the above categories was built.

3.3.2 Opinion Lexicon
We use SenticNet 3 as a concept-level opinion lexicon. The common-sense knowledge base contains
30,000 multi-word expressions labeled by their polarity scores. The proposed aspect parser is based on
two general rules:

• Rules for the sentences having subject verb.
• Rules for the sentences which do not have subject verb.
3http://nlp.stanford.edu:8080/parser

31



A dependency relation is a binary relation characterized by the following features:

• The type of the relation that specifies the nature of the (syntactic) link between the two elements in
the relation.

• The head of the relation: this is the element that is the pivot of the relation. Core syntactic and
semantics properties (e.g., agreement) are inherited from the head.

• The dependent is the element that depends on the head and which usually inherits some of its
characteristics (e.g., number, gender in the case of agreement).

Most of the times, the active token is considered in a relation if it acts as the head of the relation, although
there are exceptions. Once the active token has been identified as the trigger for a rule, there are several
ways to compute its contribution, depending on how the dependency relation and the properties of the
tokens match with the rules. The preferred way is not to consider the contribution of the token alone,
but in combination with the other elements in the dependency relation. First of all, Stanford parser is
used to obtain the dependency parse structure of each sentence. Then, hand-crafted dependency rules are
employed on the parse trees to extract aspects.

3.3.3 Subject Noun Rule
Trigger: when the active token is found to be the syntactic subject of a token. Behavior: if an active
token h is in a subject noun relationship with a word t then:

1. if t has any adverbial or adjective modifier and the modifier exists in SenticNet, then t is extracted
as an aspect.

2. if the sentence does not have auxiliary verb, i.e., is, was, would, should, could, then:

• if the verb t is modified by an adjective or an adverb or it is in adverbial clause modifier relation
with another token, then both h and t are extracted as aspects. In (1), battery is in a subject
relation with lasts and lasts is modified by the adjective modifier little, hence both the aspects
last and battery are extracted.

(1) The battery lasts little.

• if t has any direct object relation with a token n and the POS of the token is Noun and n is not
in SenticNet, then n is extracted as an aspect. In (2), like is in direct object relation with lens
so the aspect lens is extracted.

(2) I like the lens of this camera.

• if t has any direct object relation with a token n and the POS of the token n is Noun and n exists
in SenticNet, then the token n extracted as aspect term. In the dependency parse tree of the
sentence, if another token n1 is connected to n using any dependency relation and the POS of
n1 is Noun, then n1 is extracted as an aspect. In (3), like is in direct object relation with beauty
which is connected to screen via a preposition relation. So the aspects screen and beauty are
extracted.

(3) I like the beauty of the screen.

• if t is in open clausal complement relation with a token t1, then the aspect t-t1 is extracted if t-t1
exists in the opinion lexicon. If t1 is connected with a token t2 whose POS is Noun, then t2 is
extracted as an aspect. In (4), like and comment is in clausal complement relation and comment
is connected to camera using a preposition relation. Here, the POS of camera is Noun and,
hence, camera is extracted as an aspect.

(4) I would like to comment on the camera of this phone.

32



3. A copula is the relation between the complement of a copular verb and the copular verb. If the
token t is in copula relation with a copular verb and the copular verb exists in the implicit aspect
lexicon, then t is extract as aspect term. In (5), expensive is extracted as an aspect.

(5) The car is expensive.

4. If the token t is in copula relation with a copular verb and the POS of h is Noun, then h is extracted
as an explicit aspect. In (6), camera is extracted as an aspect.

(6) The camera is nice.

5. If the token t is in copula relation with a copular verb and the copular verb is connected to a token
t1 using any dependency relation and t1 is a verb, then both t1 and t are extracted as implicit aspect
terms, as long as they exist in the implicit aspect lexicon. In (7), lightweight is in copula relation
with is and lightweight is connected to the word carry by open clausal complement relation. Here,
both lightweight and carry are extracted as aspects.

(7) The phone is very lightweight to carry.

3.3.4 Sentences which do not have subject noun relation in their parse tree
For sentences that do not have noun subject relation in their parse trees, aspects are extracted using the
following rules:

1. if an adjective or adverb h is in infinitival or open clausal complement relation with a token t and h
exists in the implicit aspect lexicon, then h is extracted as an aspect. In (8), big is extracted as an
aspect as it is connected to hold using a clausal complement relation.

(8) Very big to hold.

2. if a token h is connected to a noun t using a prepositional relation, then both h and t are extracted as
aspects. In (9) sleekness is extracted as an aspect.

(9) Love the sleekness of the player.

3. if a token h is in a direct object relation with a token t, t is extracted as aspect. In (10), mention is in
a direct object relation with price, hence price is extracted as an aspect.

(10) Not to mention the price of the phone.

3.3.5 Additional Rules
• For each aspect term extracted above, if an aspect term h is in co-ordination or conjunct relation

with another token t, then t is also extracted as an aspect. In (11), amazing is firstly extracted as an
aspect term. As amazing is in conjunct relation with easy, then use is also extracted as an aspect.

(11) The camera is amazing and easy to use.

• A noun compound modifier of an NP is any noun that serves to modify the head noun. If t is
extracted as an aspect and t has noun compound modifier h, then the aspect h-t is extracted and t
is removed from the aspect list. In (12), as chicken and casserole are in noun compound modifier
relation, only chicken casserole is extracted as an aspect.

(12) We ordered the chicken casserole, but what we got were a few small pieces of chicken, all
dark meat and on the bone.

33



4 Novelty of the proposed work

First of all, the proposed method is fully unsupervised and depends on the accuracy of the dependency
parser and the opinion lexicon, rather then a training corpus and supervised learning accuracy. Only
(Qiu et al., 2011) follow an unsupervised learning approach but the proposed method uses an enhanced
set of rules and opinion lexicon. The proposed method also outperforms (Qiu et al., 2011) on the same
dataset they used. Implicit aspects extracted through the proposed method differ from implicit aspect
expressions defined by Liu (Liu, 2012) as “aspect expressions that are not nouns or noun phrases” in that
implicit aspects extracted by the proposed algorithm semantically refer to the values of the pre-defined
aspects, irrespective of their own surface POS. Below are listed some examples where the implicit aspect
terms are either noun or noun phrases.
In (13), the IAC deal is extracted.

(13) Even if I had paid full price I would have considered this phone a good deal.

In (14), sleekness is extracted as an IAC.

(14) Not to mention the sleekness of this phone.

In (15), the IAC errors is extracted by the algorithm.

(15) The player keeps giving random errors.

In (16), piece of crap is a noun phrase and is extracted as an IAC by the proposed algorithm.

(16) This phone is a piece of crap.

A demo of the developed aspect parser is freely available at http://sentic.net/demo.

Table 2: Results on the DVD-player review dataset provided by (Hu and Liu, 2004)
Algorithm Precision Recall
Hu and Liu 75.00% 82.00%
Popescu and Etzioni 89.00% 80.00%
Dependency propagation method 87.00% 81.00%
Proposed approach 89.25% 91.25%

Table 3: Results on the Canon G3 review dataset provided by (Hu and Liu, 2004)
Algorithm Precision Recall
Hu and Liu 71.00% 79.00%
Popescu and Etzioni 87.00% 74.00%
Dependency propagation method 90.00% 81.00%
Proposed approach 90.15% 92.25%

Table 4: Results on the Jukebox review dataset provided by (Hu and Liu, 2004)
Algorithm Precision Recall
Hu and Liu 72.00% 76.00%
Popescu and Etzioni 89.00% 74.00%
Dependency propagation method 90.00% 86.00%
Proposed approach 92.25% 94.15%

34



Table 5: Results on the Nikon Coolpix review dataset provided by (Hu and Liu, 2004)
Algorithm Precision Recall
Hu and Liu 69.00% 82.00%
Popescu and Etzioni 86.00% 80.00%
Dependency propagation method 81.00% 84.00%
Proposed approach 82.15% 86.15%

Table 6: Results on the Nokia-6610 review dataset provided by (Hu and Liu, 2004)
Algorithm Precision Recall
Hu and Liu 74.00% 80.00%
Popescu and Etzioni 90.00% 78.00%
Dependency propagation method 92.00% 86.00%
Proposed approach 93.25% 93.32%

5 Experiments and Results

5.1 Experiment on the dataset provided by (Hu and Liu, 2004)

Experimental evaluation was carried out on the dataset derived from (Hu and Liu, 2004). As discussed
in Section 3, the proposed method is able to extract both explicit and implicit aspects. To the best of our
knowledge, there is no state-of-the-art benchmark to evaluate implicit aspect extraction.

We compare the proposed framework with those in Hu and Liu (Hu and Liu, 2004), Qiu et al. (Qiu et
al., 2011), and Popescu and Etzioni (Popescu and Etzioni, 2005) (which only carried out explicit aspect
extraction). Table 2, Table 3, Table 4, Table 5 and Table 6 show that the proposed framework outperforms
all existing methods in terms of both precision and recall.

6 Conclusion

We have illustrated a method for extracting both explicit and implicit aspects from opinionated text.
The proposed framework only leverages on common-sense knowledge and on the dependency structure
of sentences and, hence, is unsupervised. As future work, we aim to discover more rules for aspect
extraction. Another key future effort is to combine existing rules for complex aspect extraction. To
obtain the aspect categories of IACs, we have developed an aspect knowledge base using WordNet and
SenticNet. We will focus on extending the scalability of such knowledge base and on making it as much
noise-free as possible.

6.1 Experiment on Semeval 2014 dataset

We also carried out experiments on Semeval 2014 aspect based sentiment analysis data obtained from
http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools. Re-
sults are shown in Table 7. We cannot perform a comparative evaluation of such experimental results as
there is no state-of-art approach yet which used this dataset for the same kind of experiment. Overall,
results show high accuracy.

Table 7: Results on the Semeval 2014 dataset
Domain Precision Recall
Laptop 82.15% 84.32%
Restaurants 85.21% 88.15%

35



References
Sasha Blair-Goldensohn, Kerry Hannan, Ryan McDonald, Tyler Neylon, George A. Reis, and Jeff Reynar. 2008.

Building a sentiment summarizer for local service reviews. In Proceedings of WWW-2008 workshop on NLP in
the Information Explosion Era, page 14.

Erik Cambria, Thomas Mazzocco, Amir Hussain, and Chris Eckl. 2011. Sentic medoids: Organizing affective
common sense knowledge in a multi-dimensional vector space. In D Liu, H Zhang, M Polycarpou, C Alippi,
and H He, editors, Advances in Neural Networks, volume 6677 of Lecture Notes in Computer Science, pages
601–610, Berlin. Springer-Verlag.

Erik Cambria, Paolo Gastaldo, Federica Bisio, and Rodolfo Zunino. 2014a. An ELM-based model for affective
analogical reasoning. Neurocomputing.

Erik Cambria, Daniel Olsher, and Dheeraj Rajagopal. 2014b. SenticNet 3: A common and common-sense knowl-
edge base for cognition-driven sentiment analysis. AAAI, pages 1515–1521.

Yejin Choi and Claire Cardie. 2010. Hierarchical sequential learning for extracting opinions and their attributes. In
Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL-2010), pages 268–274.

Ivan Cruz-Garcia, Alexander Gelbukh, and Grigori Sidorov. 2014. Implicit aspect indicator extraction for aspect-
based opinion mining. submitted.

Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A holistic lexicon-based approach to opinion mining. In
Proceedings of First ACM International Conference on Web Search and Data Mining (WSDM-2008), pages
231–240, Stanford University, Stanford, California, USA, Feb.

Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database (Language, Speech, and Communication).
The MIT Press.

Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the ACM
SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 168–177, Aug.

Sheng Huang, Xinlan Liu, Xueping Peng, and Zhendong Niu. 2012. Fine-grained product features extraction and
categorization in reviews opinion mining. In Proceedings of the IEEE 12th International Conference on Data
Mining Workshops, pages 680–686.

Wei Jin and Hung Hay Ho. 2009. A novel lexicalized HMM-based learning framework for web opinion mining.
In Proceedings of International Conference on Machine Learning (ICML-2009), pages 465–472.

John Lafferty, Andrew McCallum, and Fernando C.N. Pereira. 2001. Conditional random fields: probabilistic
models for segmenting and labeling sequence data. In Proceedings of the 18th International Conference on
Machine Learning, pages 282–289. Morgan Kaufmann Publishers.

Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu, Ying-Ju Xia, Shu Zhang, and Hao Yu. 2010. Structure-aware
review mining and summarization. In Proceedings of the 23rd International Conference on Computational
Linguistics (COLING-2010), pages 653–661.

Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Morgan & Claypool Publishers.

Jakob Niklas and Iryna Gurevych. 2010. Extracting opinion targets in a single and cross-domain setting with con-
ditional random fields. In Proceedings of Conference on Empirical Methods in Natural Language Processing
(EMNLP-2010), pages 1035–1045.

Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceed-
ings of Conference on Empirical Methods in Natural Language Processing (EMNLP-2005), pages 3–28.

Soujanya Poria, Erik Cambria, Gregoire Winterstein, and Guang-Bin Huang. 2014. Sentic patterns: Dependency-
based rules for concept-level sentiment analysis. Knowledge-Based Systems.

Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2011. Opinion word expansion and target extraction through
double propagation. Computational linguistics, 37(1):9–27.

Christopher Scaffidi, Kevin Bierhoff, Eric Chang, Mikhael Felker, Herman Ng, and Chun Jin. 2007. Red opal:
product-feature scoring from reviews. In Proceedings of the 8th ACM conference on Electronic commerce,
pages 182–191. ACM.

36



Qi Su, Xinying Xu, Honglei Guo, Zhili Guo, Xian Wu, Xiaoxun Zhang, Bin Swen, and Zhong Su. 2008. Hidden
sentiment association in chinese web opinion mining. In Proceedings of International Conference on World
Wide Web (WWW-2008), pages 959–968.

Rui Xia, Chengqing Zong, Xuelei Hu, and Erik Cambria. 2013. Feature ensemble plus sample selection: A
comprehensive approach to domain adaptation for sentiment classification. IEEE Intelligent Systems, 28(3):10–
18.

Lingwei Zeng and Fang Li. 2013. A classification-based approach for implicit feature identification. In Chinese
Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data. 12th
China National Conference, CCL 2013 and First International Symposium, NLP-NABD 2013, Suzhou, China,
October 10–12, 2013, Proceedings, volume 8202 of Lecture Notes in Computer Science, pages 190–202.

Hai Zhen, Kuiyu Chang, and Jung-jae Kim. 2011. Implicit feature identification via co-occurrence association rule
mining. In Computational Linguistics and Intelligent Text Processing. 12th International Conference, CICLing
2011, Tokyo, Japan, February 20–26, 2011. Proceedings, Part I, volume 6608 of Lecture Notes in Computer
Science, pages 393–404.

37


