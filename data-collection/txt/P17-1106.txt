



















































Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics


Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1150â€“1159
Vancouver, Canada, July 30 - August 4, 2017. cÂ©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-1106

Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1150â€“1159
Vancouver, Canada, July 30 - August 4, 2017. cÂ©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-1106

Visualizing and Understanding Neural Machine Translation

Yanzhuo Dingâ€  Yang Liuâ€ â€¡âˆ—Huanbo Luanâ€  Maosong Sunâ€ â€¡
â€ State Key Laboratory of Intelligent Technology and Systems

Tsinghua National Laboratory for Information Science and Technology
Department of Computer Science and Technology, Tsinghua University, Beijing, China
â€¡Jiangsu Collaborative Innovation Center for Language Competence, Jiangsu, China

djx133@yeah.net, liuyang2011@tsinghua.edu.cn
luanhuanbo@gmail.com, sms@tsinghua.edu.cn

Abstract

While neural machine translation (NMT)
has made remarkable progress in recent
years, it is hard to interpret its inter-
nal workings due to the continuous rep-
resentations and non-linearity of neural
networks. In this work, we propose
to use layer-wise relevance propagation
(LRP) to compute the contribution of
each contextual word to arbitrary hid-
den states in the attention-based encoder-
decoder framework. We show that visu-
alization with LRP helps to interpret the
internal workings of NMT and analyze
translation errors.

1 Introduction

End-to-end neural machine translation (NMT),
which leverages neural networks to directly map
between natural languages, has gained increasing
popularity recently (Sutskever et al., 2014; Bah-
danau et al., 2015). NMT proves to outperform
conventional statistical machine translation (SMT)
significantly across a variety of language pairs
(Junczys-Dowmunt et al., 2016) and becomes the
new de facto method in practical MT systems (Wu
et al., 2016).

However, there still remains a severe challenge:
it is hard to interpret the internal workings of
NMT. In SMT (Koehn et al., 2003; Chiang, 2005),
the translation process can be denoted as a deriva-
tion that comprises a sequence of translation rules
(e.g., phrase pairs and synchronous CFG rules).
Defined on language structures with varying gran-
ularities, these translation rules are interpretable
from a linguistic perspective. In contrast, NMT
takes an end-to-end approach: all internal infor-
mation is represented as real-valued vectors or

âˆ—Corresponding author.

matrices. It is challenging to associate hidden
states in neural networks with interpretable lan-
guage structures. As a result, the lack of inter-
pretability makes it very difficult to understand
translation process and debug NMT systems.

Therefore, it is important to develop new meth-
ods for visualizing and understanding NMT. Ex-
isting work on visualizing and interpreting neu-
ral models has been extensively investigated in
computer vision (Krizhevsky et al., 2012; Mahen-
dran and Vedaldi, 2015; Szegedy et al., 2014; Si-
monyan et al., 2014; Nguyen et al., 2015; Girshick
et al., 2014; Bach et al., 2015). Although visu-
alizing and interpreting neural models for natural
language processing has started to attract attention
recently (Karpathy et al., 2016; Li et al., 2016),
to the best of our knowledge, there is no exist-
ing work on visualizing NMT models. Note that
the attention mechanism (Bahdanau et al., 2015) is
restricted to demonstrate the connection between
words in source and target languages and unable
to offer more insights in interpreting how target
words are generated (see Section 4.5).

In this work, we propose to use layer-wise rel-
evance propagation (LRP) (Bach et al., 2015) to
visualize and interpret neural machine translation.
Originally designed to compute the contributions
of single pixels to predictions for image classi-
fiers, LRP back-propagates relevance recursively
from the output layer to the input layer. In con-
trast to visualization methods relying on deriva-
tives, a major advantage of LRP is that it does
not require neural activations to be differentiable
or smooth (Bach et al., 2015). We adapt LRP
to the attention-based encoder-decoder framework
(Bahdanau et al., 2015) to calculate relevance that
measures the association degree between two ar-
bitrary neurons in neural networks. Case studies
on Chinese-English translation show that visual-
ization helps to interpret the internal workings of

1150

https://doi.org/10.18653/v1/P17-1106
https://doi.org/10.18653/v1/P17-1106


åœ¨ çº½çº¦
zai niuyue

</s>

in New </s>York

source words

source word embeddings

source forward hidden states

source backward hidden states

source hidden states

source contexts

target hidden states 

target word embeddings

target words

attention

Figure 1: The attention-based encoder-decoder
architecture for neural machine translation (Bah-
danau et al., 2015).

NMT and analyze translation errors.

2 Background

Given a source sentence x = x1, . . . , xi, . . . , xI
with I source words and a target sentence y =
y1, . . . , yj , . . . , yJ with J target words, neu-
ral machine translation (NMT) decomposes the
sentence-level translation probability as a product
of word-level translation probabilities:

P (y|x;Î¸) =
Jâˆ

j=1

P (yj |x,y<j ;Î¸), (1)

where y<j = y1, . . . , yjâˆ’1 is a partial translation.
In this work, we focus on the attention-based

encoder-decoder framework (Bahdanau et al.,
2015). As shown in Figure 1, given a source sen-
tence x, the encoder first uses source word embed-
dings to map each source word xi to a real-valued
vector xi.1

Then, a forward recurrent neural network
(RNN) with GRU units (Cho et al., 2014) runs to
calculate source forward hidden states:

âˆ’â†’
h i = f(

âˆ’â†’
h iâˆ’1,xi), (2)

where f(Â·) is a non-linear function.
Similarly, the source backward hidden states

can be obtained using a backward RNN:

â†âˆ’
h i = f(

â†âˆ’
h i+1,xi). (3)

1Note that we use x to denote a source sentence and x to
denote the vector representation of a single source word.

To capture global contexts, the forward and
backward hidden states are concatenated as the
hidden state for each source word:

hi = [
âˆ’â†’
h i;
â†âˆ’
h i]. (4)

Bahdanau et al. (2015) propose an attention
mechanism to dynamically determine the relevant
source context cj for each target word:

cj =

I+1âˆ‘

i=1

Î±j,ihi, (5)

where Î±j,i is an attention weight that indicates
how well the source word xi and the target word
yj match. Note that an end-of-sentence token is
appended to the source sentence.

In the decoder, a target hidden state for the j-th
target word is calculated as

sj = g(sjâˆ’1,yj , cj), (6)

where g(Â·) is a non-linear function, yjâˆ’1 denotes
the vector representation of the (j âˆ’ 1)-th target
word.

Finally, the word-level translation probability is
given by

P (yj |x,y<j ;Î¸) = Ï(yjâˆ’1, sj , cj), (7)

where Ï(Â·) is a non-linear function.
Although NMT proves to deliver state-of-the-

art translation performance with the capability to
handle long-distance dependencies due to GRU
and attention, it is hard to interpret the internal
information such as

âˆ’â†’
h i,
â†âˆ’
h i, hi, cj , and sj in

the encoder-decoder framework. Though project-
ing word embedding space into two dimensions
(Faruqui and Dyer, 2014) and the attention matrix
(Bahdanau et al., 2015) shed partial light on how
NMT works, how to interpret the entire network
still remains a challenge.

Therefore, it is important to develop new meth-
ods for understanding the translation process and
analyzing translation errors for NMT.

3 Approach

3.1 Problem Statement
Recent efforts on interpreting and visualizing neu-
ral models has focused on calculating the contribu-
tion of a unit at the input layer to the final decision
at the output layer (Simonyan et al., 2014; Ma-
hendran and Vedaldi, 2015; Nguyen et al., 2015;

1151



in New </s>York

åœ¨ çº½çº¦ </s> in New

zai niuyue

Figure 2: Visualizing the relevance between the
vector representation of a target word â€œNew Yorkâ€
and those of all source words and preceding target
words.

Girshick et al., 2014; Bach et al., 2015; Li et al.,
2016). For example, in image classification, it is
important to understand the contribution of a sin-
gle pixel to the prediction of classifier (Bach et al.,
2015).

In this work, we are interested in calculating the
contribution of source and target words to the fol-
lowing internal information in the attention-based
encoder-decoder framework:

1.
âˆ’â†’
h i: the i-th source forward hidden state,

2.
â†âˆ’
h i: the i-th source backward hidden state,

3. hi: the i-th source hidden state,

4. cj : the j-th source context vector,

5. sj : the j-th target hidden state,

6. yj : the j-th target word embedding.

For example, as shown in Figure 2, the gener-
ation of the third target word â€œYorkâ€ depends on
both the source context (i.e., the source sentence
â€œzai niuyue </s>â€) and the target context (i.e.,
the partial translation â€œin Newâ€). Intuitively, the
source word â€œniuyueâ€ and the target word â€œNewâ€
are more relevant to â€œYorkâ€ and should receive
higher relevance than other words. The problem
is how to quantify and visualize the relevance be-
tween hidden states and contextual word vectors.

More formally, we introduce a number of defi-
nitions to facilitate the presentation.

Definition 1 The contextual word set of a hidden
state v âˆˆ RMÃ—1 is denoted as C(v), which is a
set of source and target contextual word vectors
u âˆˆ RNÃ—1 that influences the generation of v.

Figure 3: A simple feed-forward network for il-
lustrating layer-wise relevance propagation (Bach
et al., 2015).

For example, the context word set for
âˆ’â†’
h i

is {x1, . . . ,xi}, for â†âˆ’h i is {xi, . . . ,xI+1}, and
for hi is {x1, . . . ,xI+1}. The contextual word
set for cj is {x1, . . . ,xI+1}, for sj and yj is
{x1, . . . ,xI+1,y1, . . . ,yjâˆ’1}.

As both hidden states and contextual words are
represented as real-valued vectors, we need to fac-
torize vector-level relevance at the neuron level.

Definition 2 The neuron-level relevance be-
tween the m-th neuron in a hidden state vm âˆˆ R
and the n-th neuron in a contextual word vector
un âˆˆ R is denoted as runâ†vm âˆˆ R, which satis-
fies the following constraint:

vm =
âˆ‘

uâˆˆC(v)

Nâˆ‘

n=1

runâ†vm (8)

Definition 3 The vector-level relevance between
a hidden state v and one contextual word vector
u âˆˆ C(v) is denoted as Ruâ†v âˆˆ R, which quanti-
fies the contribution of u to the generation of v. It
is calculated as

Ruâ†v =
Mâˆ‘

m=1

Nâˆ‘

n=1

runâ†vm (9)

Definition 4 The relevance vector of a hidden
state v is a sequence of vector-level relevance of
its contextual words:

Rv = {Ru1â†v, . . . , Ru|C(v)|â†v} (10)
Therefore, our goal is to compute relevance vec-

tors for hidden states in a neural network, as shown
in Figure 2. The key problem is how to compute
neuron-level relevance.

3.2 Layer-wise Relevance Propagation
We follow (Bach et al., 2015) to use layer-wise
relevance propagation (LRP) to compute neuron-
level relevance. We use a simple feed-forward net-
work shown in Figure 3 to illustrate the central
idea of LRP.

1152



Input: A neural network G for a sentence pair and a set of hidden states to be visualized V .
Output: Vector-level relevance setR.

1 for u âˆˆ G in a forward topological order do
2 for v âˆˆ OUT(u) do
3 calculating weight ratios wuâ†’v;
4 end
5 end
6 for v âˆˆ V do
7 for v âˆˆ v do
8 rvâ†v = v; // initializing neuron-level relevance
9 end

10 for u âˆˆ G in a backward topological order do
11 ruâ†v =

âˆ‘
zâˆˆOUT(u)wuâ†’zrzâ†v ; // calculating neuron-level relevance

12 end
13 for u âˆˆ C(v) do
14 Ruâ†v =

âˆ‘
uâˆˆu

âˆ‘
vâˆˆv ruâ†v ; // calculating vector-level relevance

15 R = Râˆª {Ruâ†v}; // Update vector-level relevance set
16 end
17 end

Algorithm 1: Layer-wise relevance propagation for neural machine translation.

LRP first propagates the relevance from the out-
put layer to the intermediate layer:

rz1â†v1 =
W

(2)
1,1z1

W
(2)
1,1z1 +W

(2)
2,1z2

v1 (11)

rz2â†v1 =
W

(2)
2,1z2

W
(2)
1,1z1 +W

(2)
2,1z2

v1 (12)

Note that we ignore the non-linear activation func-
tion because Bach et al. (2015) indicate that LRP
is invariant against the choice of non-linear func-
tion.

Then, the relevance is further propagated to the
input layer:

ru1â†v1 =
W

(1)
1,1u1

W
(1)
1,1u1 +W

(1)
2,1u2

rz1â†v1 +

W
(1)
1,2u1

W
(1)
1,2u1 +W

(1)
2,2u2

rz2â†v1 (13)

ru2â†v1 =
W

(1)
2,1u2

W
(1)
1,1u1 +W

(1)
2,1u2

rz1â†v1 +

W
(1)
2,2u2

W
(1)
1,2u1 +W

(1)
2,2u2

rz2â†v1 (14)

Note that ru1â†v1 + ru2â†v1 = v1.

More formally, we introduce the following def-
initions to ease exposition.

Definition 5 Given a neuron u, its incoming neu-
ron set IN(u) comprises all its direct connected
preceding neurons in the network.

For example, in Figure 3, the incoming neuron
set of z1 is IN(z1) = {u1, u2}.
Definition 6 Given a neuron u, its outcoming
neuron set OUT(u) comprises all its direct con-
nected descendant neurons in the network.

For example, in Figure 3, the incoming neuron
set of z1 is OUT(z1) = {v1, v2}.
Definition 7 Given a neuron v and its incoming
neurons u âˆˆ IN(v), the weight ratio that mea-
sures the contribution of u to v is calculated as

wuâ†’v =
Wu,vuâˆ‘

uâ€²âˆˆIN(v)Wuâ€²,vu
â€² (15)

Although the NMT model usually involves
multiple operators such as matrix multiplication,
element-wise multiplication, and maximization,
they only influence the way to calculate weight ra-
tios in Eq. (15).

For matrix multiplication such as v = Wu, its
basic form that is calculated at the neuron level is
given by v =

âˆ‘
uâˆˆIN(v)Wu,vu . We follow Bach

et al. (2015) to calculate the weight ratio using Eq.
(15).

1153



è¿‘ ä¸¤
jin liang

å¹´
nian

æ¥
lai

ï¼Œ ç¾å›½
, meiguo

è¿‘ ä¸¤ å¹´ æ¥ ï¼Œ ç¾å›½

jin liang nian lai , meiguo

1 2 3 4 5 6

1 2 3 4 5 6

Figure 4: Visualizing source hidden states for a
source content word â€œnianâ€ (years).

For element-wise multiplication such as v =
u1â—¦u2, its basic form is given by v =

âˆ
uâˆˆIN(v) u.

We use the following method to calculate its
weight ratio:

wuâ†’v =
uâˆ‘

uâ€²âˆˆIN(v) u
â€² (16)

For maximization such as v = max{u1, u2},
we calculate its weight ratio as follows:

wuâ†’v =
{

1 if u = maxuâ€²âˆˆIN(v){uâ€²}
0 otherwise

(17)

Therefore, the general local redistribution rule
for LRP is given by

ruâ†v =
âˆ‘

zâˆˆOUT(u)
wuâ†’zrzâ†v (18)

Algorithm 1 gives the layer-wise relevance
propagation algorithm for neural machine trans-
lation. The input is an attention-based encoder-
decoder neural network for a sentence pair after
decoding G and a set of hidden states to be visu-
alized V . The output is a set of vector-level rel-
evance between intended hidden states and their
contextual words R. The algorithm first com-
putes weight ratios for each neuron in a forward
pass (lines 1-4). Then, for each hidden state to
be visualized (line 6), the algorithm initializes the
neuron-level relevance for itself (lines 7-9). After
initialization, the neuron-level relevance is back-
propagated through the network (lines 10-12). Fi-
nally, vector-level relevance is calculated based on
neuron-level relevance (lines 13-16). The time
complexity of Algorithm 1 isO(|G|Ã—|V|Ã—Omax),

æˆ‘ å‚æ‹œ æ˜¯ ä¸ºäº† ç¥ˆæ±‚ my

wo canbai shi weile qiqiu

my visit tois pray1 2 3 4 5

1 2 3 4 5 1

Figure 5: Visualizing target hidden states for a tar-
get content word â€œvisitâ€.

where |G| is the number of neuron units in the neu-
ral network G, |V| is the number of hidden states
to be visualized and Omax is the maximum of out-
degree for neurons in the network. Calculating
relevance is more computationally expensive than
computing attention as it involves all neurons in
the network. Fortunately, it is possible to take ad-
vantage of parallel architectures of GPUs and rel-
evance caching for speed-up.

4 Analysis

4.1 Data Preparation
We evaluate our approach on Chinese-English
translation. The training set consists of 1.25M
pairs of sentences with 27.93M Chinese words and
34.51M English words. We use the NIST 2003
dataset as the development set for model selection
and the NIST 2004 dataset as test set. The BLEU
score on NIST 2003 is 32.73.

We use the open-source toolkit GROUNDHOG
(Bahdanau et al., 2015), which implements the
attention-based encoder-decoder framework. Af-
ter model training and selection on the training
and development sets, we use the resulting NMT
model to translate the test set. Therefore, the vi-
sualization examples in the following subsections
are taken from the test set.

4.2 Visualization of Hidden States
4.2.1 Source Side
Figure 4 visualizes the source hidden states for a
source content word â€œnianâ€ (years). For each word
in the source string â€œjin liang nian lai , meiguoâ€
(in recent two years, USA), we attach a number

1154



the ğ¥ğšğ«ğ ğğ¬ğ­ UNK in ğ­ğ¡ğ ğ°ğ¨ğ«ğ¥ğ

zhaiwuguo

ä¸–ç•Œ

2 3 4 5 6 7

æœ€ å¤§ çš„ å€ºåŠ¡å›½* ï¼Œ the largest2 3 4 5 6 7 2 3
dedazuishijie ,

Figure 6: Visualizing target hidden states for a tar-
get UNK word.

to denote the position of the word in the sentence.
For example, â€œnianâ€ (years) is the third word.

We are interested in visualizing the relevance
between the third source forward hidden state

âˆ’â†’
h 3

and all its contextual words â€œjinâ€ (recent) and
â€œliangâ€ (two). We observe that the direct preced-
ing word â€œliangâ€ (two) contributes more to form-
ing the forward hidden state of â€œnianâ€ (years). For
the third source backward hidden state

â†âˆ’
h 3, the

relevance of contextual words generally decreases
with the increase of the distance to â€œnianâ€ (years).
Clearly, the concatenation of forward and back-
ward hidden states h3 capture contexts in both di-
rections.

The situations for function words and punctua-
tion marks are similar but the relevance is usually
more concentrated on the word itself. We omit the
visualization due to space limit.

4.2.2 Target Side
Figure 5 visualizes the target-side hidden states for
the second target word â€œvisitâ€. For comparison,
we also give the attention weights Î±2, which cor-
rectly identifies the second source word â€œcanbaiâ€
(â€œvisitâ€) is most relevant to â€œvisitâ€.

The relevance vector of the source context c2 is
generally consistent with the attention but reveals
that the third word â€œshiâ€ (is) also contributes to the
generation of â€œvisitâ€.

For the target hidden state s2, the contextual
word set includes the first target word â€œmyâ€. We
find that most contextual words receive high val-
ues of relevance. This phenomenon has been fre-
quently observed for most target words in other
sentences. Note that relevance vector is not nor-
malized. This is an essential difference between

vote of confidence

å‚

6 7 8

ä¼— ä¸¤ é™¢5 6 7 8 9
yuanliangzhongcan

in the109

senatethe10

senate </s>11 12

ä¿¡ä»» æŠ•ç¥¨ </s>11 10 11
xinren toupiao </s>

Figure 7: Analyzing translation error: word omis-
sion. The 6-th source word â€œzhongâ€ is untrans-
lated incorrectly.

attention and relevance. While attention is defined
to be normalized, the only constraint on relevance
is that the sum of relevance of contextual words
is identical to the value of intended hidden state
neuron.

For the target word embedding y2, the relevance
is generally consistent with the attention by iden-
tifying that the second source word contributes
more to the generation of â€œvisitâ€. But Ry2 further
indicates that the target word â€œmyâ€ is also very im-
portant for generating â€œvisitâ€.

Figure 6 shows the hidden states of a target
UNK word, which is very common to see in NMT
because of limited vocabulary. It is interesting to
investigate whether the attention mechanism could
put a UNK in the right place in the translation. In
this example, the 6-th source word â€œzhaiwuguoâ€ is
a UNK. We find that the model successfully pre-
dicts the correct position of UNK by exploiting
surrounding source and target contexts. But the
ordering of UNK usually becomes worse if multi-
ple UNK words exist on the source side.

4.3 Translation Error Analysis

Given the visualization of hidden states, it is possi-
ble to offer useful information for analyzing trans-
lation errors commonly observed in NMT such as
word omission, word repetition, unrelated words
and negation reversion.

4.3.1 Word Omission
Given a source sentence â€œbajisitan zongtong muxi-
alafu yingde can zhong liang yuan xinren toupiaoâ€
(pakistani president musharraf wins votes of con-
fidence in senate and house), the NMT model pro-

1155



the history of

ç¾å›½äºº

2 3 4

å†å² ä¸Š æœ‰
1 2 3 4 4

youshanglishimeiguoren

the history
65

of the
5

Figure 8: Analyzing translation error: word repe-
tition. The target word â€œhistoryâ€ occurs twice in
the translation incorrectly.

duces a wrong translation â€œpakistani president win
over democratic vote of confidence in the senateâ€.
One translation error is that the 6-th source word
â€œzhongâ€ (house) is incorrectly omitted for transla-
tion.

As the end-of-sentence token â€œ</s>â€ occurs
early than expected, we choose to visualize its cor-
responding target hidden states. Although the at-
tention correctly identifies the 6-th source word
â€œzhongâ€ (house) to be important for generating
the next target word, the relevance of source con-
text Rc12 attaches more importance to the end-of-
sentence token.

Finally, the relevance of target word Ry12 re-
veals that the end-of-sentence token and the 11-th
target word â€œsenateâ€ become dominant in the soft-
max layer for generating the target word.

This example demonstrates that only using at-
tention matrices does not suffice to analyze the
internal workings of NMT. The values of rele-
vance of contextual words might vary significantly
across different layers.

4.3.2 Word Repetition

Given a source sentence â€œmeiguoren lishi shang
you jiang chengxi de chuantong , you fancuo ren-
cuo de chuantongâ€ (in history , the people of amer-
ica have the tradition of honesty and would not
hesitate to admit their mistakes), the NMT model
produces a wrong translation â€œin the history of the
history of the history of the americans , there is a
tradition of faith in the history of mistakesâ€. The

is to forge ahead . </s>

</s>

æ˜¯

7 8 9 10 11 12

è·¨å¤§è¥¿æ´‹ å…³ç³» ã€‚ </s> is to
9 10 11 12 13 6 7

.guanxikuadaxiyangis

Figure 9: Analyzing translation error: unrelated
words. The 9-th target word â€œforgeâ€ is totally un-
related to the source sentence.

translation error is that â€œhistoryâ€ repeats four times
in the translation.

Figure 8 visualizes the target hidden states of
the 6-th target word â€œhistoryâ€. According to the
relevance of the target word embedding Ry6 , the
first source word â€œmeiguorenâ€ (american), the
second source word â€œlishiâ€ (history) and the 5-th
target word â€œtheâ€ are most relevant to the gen-
eration of â€œhistoryâ€. Therefore, word repetition
not only results from wrong attention but also
is significantly influenced by target side context.
This finding confirms the importance of control-
ling source and target contexts to improve fluency
and adequacy (Tu et al., 2017).

4.3.3 Unrelated Words
Given a source sentence â€œci ci huiyi de yi ge
zhongyao yiti shi kuadaxiyang guanxiâ€ (one the
the top agendas of the meeting is to discuss the
cross-atlantic relations), the model prediction is
â€œa key topic of the meeting is to forge aheadâ€.
One translation error is that the 9-th English word
â€œforgeâ€ is totally unrelated to the source sentence.

Figure 9 visualizes the hidden states of the
9-th target word â€œforgeâ€. We find that while
the attention identifies the 10-th source word
â€œkuadaxiyangâ€ (cross-atlantic) to be most rele-
vant, the relevance vector of the target word Ry9
finds that multiple source and target words should
contribute to the generation of the next target
word.

We observe that unrelated words are more likely
to occur if multiple contextual words have high

1156



we will talk

å°±

11 12 13

è°ˆ ä¸ ä¸Š6 7 8 9 10
shangbutanjiu

about development1514

talkwill12å‘å±• 13
fazhan

Figure 10: Analyzing translation error: negation.
The 8-th negation source word â€œbuâ€ (not) is not
translated.

values in the relevance vector of the target word
being generated.

4.3.4 Negation Reversion
Given a source sentence â€œbu jiejue shengcun wenti
, jiu tan bu shang fa zhan , geng tan bu shang ke
chixu fazhanâ€ (without solution to the issue of sub-
sistence , there will be no development to speak of ,
let alone sustainable development), the model pre-
diction is â€œif we do not solve the problem of liv-
ing , we will talk about development and still less
can we talk about sustainable developmentâ€. The
translation error is that the 8-th negation source
word â€œbuâ€ (not) is untranslated. The omission of
negation is a severe translation error it reverses the
meaning of the source sentence.

As shown in Figure 10, while both attention and
relevance correctly identify the 8-th negation word
â€œbuâ€ (not) to be most relevant, the model still gen-
erates â€œaboutâ€ instead of a negation target word.
One possible reason is that target context words
â€œwill talkâ€ take the lead in determining the next
target word.

4.4 Extra Words

Given a source sentence â€œbajisitan zongtong mux-
ialafu yingde can zhong liang yuan xinren tou-
piaoâ€(pakistani president musharraf wins votes of
confidence in senate and house), the model predic-
tion is â€œpakistani president win over democratic
vote of confidence in the senateâ€ The translation
error is that the 5-th target word â€œdemocraticâ€ is
extra generated.

democratic vote of confidence

ä¸¤

5 6 7 8

é™¢ ä¿¡ä»» æŠ•ç¥¨ </s>
7 8 9 10 11

toupiaoxinrenyuanliang

in the109

win over
3 4

</s>

Figure 11: Analyzing translation error: extra
word. The 5-th target word â€œdemocraticâ€ is an ex-
tra word.

Figure 11 visualizes the hidden states of the
9-th target word â€œforgeâ€. We find that while
the attention identifies the 9-th source word â€œxin-
renâ€(confidence) to be most relevant, the relevance
vector of the target word Ry9 indicates that the
end-of-sentence token and target words contribute
more to the generation of â€œdemocraticâ€.

4.5 Summary of Findings

We summarize the findings of visualizing and an-
alyzing the decoding process of NMT as follows:

1. Although attention is very useful for under-
standing the connection between source and
target words, only using attention is not suf-
ficient for deep interpretation of target word
generation (Figure 9);

2. The relevance of contextual words might vary
significantly across different layers of hidden
states (Figure 9);

3. Target-side context also plays a critical role in
determining the next target word being gen-
erated. It is important to control both source
and target contexts to produce correct trans-
lations (Figure 10);

4. Generating the end-of-sentence token too
early might lead to many problems such as
word omission, unrelated word generation,
and truncated translation (Figures 7 and 9).

1157



5 Related Work

Our work is closely related to previous visualiza-
tion approaches that compute the contribution of
a unit at the input layer to the final decision at
the output layer (Simonyan et al., 2014; Mahen-
dran and Vedaldi, 2015; Nguyen et al., 2015; Gir-
shick et al., 2014; Bach et al., 2015; Li et al.,
2016). Among them, our approach bears most re-
semblance to (Bach et al., 2015) since we adapt
layer-wise relevance propagation to neural ma-
chine translation. The major difference is that
word vectors rather than single pixels are the ba-
sic units in NMT. Therefore, we propose vector-
level relevance based on neuron-level relevance
for NMT. Calculating weight ratios has also been
carefully designed for the operators in NMT.

The proposed approach also differs from (Li
et al., 2016) in that we use relevance rather than
partial derivative to quantify the contributions of
contextual words. A major advantage of using rel-
evance is that it does not require neural activations
to be differentiable or smooth (Bach et al., 2015).

The relevance vector we used is significantly
different from the attention matrix (Bahdanau
et al., 2015). While attention only demonstrates
the association degree between source and target
words, relevance can be used to calculate the as-
sociation degree between two arbitrary neurons in
neural networks. In addition, relevance is effective
in analyzing the effect of source and target con-
texts on generating target words.

6 Conclusion

In this work, we propose to use layer-wise rele-
vance propagation to visualize and interpret neural
machine translation. Our approach is capable of
calculating the relevance between arbitrary hidden
states and contextual words by back-propagating
relevance along the network recursively. Analyses
of the state-of-art attention-based encoder-decoder
framework on Chinese-English translation show
that our approach is able to offer more insights
than the attention mechanism for interpreting neu-
ral machine translation.

In the future, we plan to apply our approach
to more NMT approaches (Sutskever et al., 2014;
Shen et al., 2016; Tu et al., 2016; Wu et al., 2016)
on more language pairs to further verify its effec-
tiveness. It is also interesting to develop relevance-
based neural translation models to explicitly con-
trol relevance to produce better translations.

Acknowledgements

This work is supported by the National Natu-
ral Science Foundation of China (No.61522204),
the 863 Program (2015AA015407), and the
National Natural Science Foundation of China
(No.61432013). This research is also supported by
the Singapore National Research Foundation un-
der its International Research Centre@Singapore
Funding Initiative and administered by the IDM
Programme.

References
Sebastian Bach, Alexander Binder, GreÌgoire Mon-

tavon, Frederick Klauschen, Klaus-Robert MuÌˆller,
and Wojciech Samek. 2015. On pixel-wise explana-
tions for non-linear classifier decisions by layer-wise
relevance propagation. PLoS ONE .

Dzmitry Bahdanau, KyungHyun Cho, and Yoshua
Bengio. 2015. Neural machine translation by jointly
learning to align and translate. In Proceedings of
ICLR.

Davie Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of ACL.

Kyunghyun Cho, Bart van Merrienboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014. Learning
phrase representations using rnn encoderâ€“decoder
for statistical machine translation. In Proceedings
of EMNLP.

Mannal Faruqui and Chris Dyer. 2014. Improving vec-
tor space word representations using multilingual
correlation. In Proceedings of EACL.

Ross Girshick, Jeff Donahue, Trevor Darrell, and Jiten-
dra Malik. 2014. Rich feature hierarchies for accu-
rate object detection and semantic segmentation. In
Proceedings of CVPR.

Marcin Junczys-Dowmunt, Tomasz Dwojak, and Hieu
Hoang. 2016. Is neural machine translation ready
for deployment? a case study on 30 translation di-
rections. arXiv:1610.01108v2.

Andrej Karpathy, Justin Johnson, and Fei-Fei Li. 2016.
Visualing and understanding recurrent networks. In
Proceedings of ICLR Workshop.

Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings
of NAACL.

Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton.
2012. Imagenet classification with deep convolu-
tional nerual networks. In Proceedings of NIPS.

1158



Jiwei Li, Xinlei Chen, Eduard Hovy, and Dan Jurafsky.
2016. Visualizing and understanding neural models
in nlp. In Proceedings of NAACL.

Aravindh Mahendran and Andrea Vedaldi. 2015. Un-
derstanding deep image representations by inverting
them. In Proceedings of CVPR.

Anh Nguyen, Jason Yosinski, and Jeff Clune. 2015.
Deep neural networks are easily fooled: High con-
fidence predictions for unrecignizable images. In
Proceedings of CVPR.

Shiqi Shen, Yong Cheng, Zhongjun He, Wei He, Hua
Wu, Maosong Sun, and Yang Liu. 2016. Minimum
risk training for neural machine translation. In Pro-
ceedings of ACL.

Karen Simonyan, Andrea Vedaldi, and Andrew Zisser-
man. 2014. Deep inside convolutional networks: Vi-
sualizing image classification models and saliency
maps. In Proceedings of ICLR Workshop.

Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.
Sequence to sequence learning with neural net-
works. In Proceedings of NIPS.

Christian Szegedy, Wojciech Zaremba, Ilya Sutskever,
Joan Bruna, Dumitru Erhan, Ian Goodfellow, and
Rob Fergus. 2014. Intriguing properties of neural
networks. In Proceedings of ICLR.

Zhaopeng Tu, Yang Liu, Lifeng Shang, Xiaohua Liu,
and Hang Li. 2017. Context gates for neural ma-
chine translation. Transactions of the ACL .

Zhaopeng Tu, Zhengdong Lu, Yang Liu, Xiaohua Liu,
and Hang Li. 2016. Modeling coverage for neural
machine translation. In Proceedings of ACL.

Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V.
Le, Mohammad Norouzi, Wolfgang Macherey,
Maxim Krikun, Yuan Cao, Qin Gao, Klaus
Macherey, Jeff Klingner, Apurva Shah, Melvin
Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan
Gouws, Yoshikiyo Kato, Taku Kudo, Hideto
Kazawa, Keith Stevens, George Kurian, Nishant
Patil, Wei Wang, Cliff Young, Jason Smith, Ja-
son Riesa, Alex Rudnick, Oriol Vinyals, Greg Cor-
rado, Macduff Hughes, and Jeffrey Dean. 2016.
Googleâ€™s neural machine translation system: Bridg-
ing the gap between human and machine translation.
arXiv:1609.08144v2.

1159


	Visualizing and Understanding Neural Machine Translation

