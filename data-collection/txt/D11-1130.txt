



















































Cross-Cutting Models of Lexical Semantics


Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1405–1415,
Edinburgh, Scotland, UK, July 27–31, 2011. c©2011 Association for Computational Linguistics

Cross-Cutting Models of Lexical Semantics

Joseph Reisinger
Department of Computer Sciences
The University of Texas at Austin

Austin, TX 78712
joeraii@cs.utexas.edu

Raymond Mooney
Department of Computer Sciences
The University of Texas at Austin

Austin, TX 78712
mooney@cs.utexas.edu

Abstract

Context-dependent word similarity can be
measured over multiple cross-cutting dimen-
sions. For example, lung and breath are sim-
ilar thematically, while authoritative and su-
perficial occur in similar syntactic contexts,
but share little semantic similarity. Both of
these notions of similarity play a role in deter-
mining word meaning, and hence lexical se-
mantic models must take them both into ac-
count. Towards this end, we develop a novel
model, Multi-View Mixture (MVM), that rep-
resents words as multiple overlapping clus-
terings. MVM finds multiple data partitions
based on different subsets of features, sub-
ject to the marginal constraint that feature sub-
sets are distributed according to Latent Dirich-
let Allocation. Intuitively, this constraint fa-
vors feature partitions that have coherent top-
ical semantics. Furthermore, MVM uses soft
feature assignment, hence the contribution of
each data point to each clustering view is vari-
able, isolating the impact of data only to views
where they assign the most features. Through
a series of experiments, we demonstrate the
utility of MVM as an inductive bias for captur-
ing relations between words that are intuitive
to humans, outperforming related models such
as Latent Dirichlet Allocation.

1 Introduction

Humans categorize objects using multiple orthogo-
nal taxonomic systems, where category generaliza-
tion depends critically on what features are relevant
to one particular system. For example, foods can be
organized in terms of their nutritional value (high in
fiber) or situationally (commonly eaten for Thanks-

giving; Shafto et al. (2006)). Human knowledge-
bases such as Wikipedia also exhibit such multiple
clustering structure (e.g. people are organized by oc-
cupation or by nationality). The effects of these
overlapping categorization systems manifest them-
selves at the lexical semantic level (Murphy, 2002),
implying that lexicographical word senses and tra-
ditional computational models of word-sense based
on clustering or exemplar activation are too impov-
erished to capture the rich dynamics of word usage.

In this work, we introduce a novel probabilis-
tic clustering method, Multi-View Mixture (MVM),
based on cross-cutting categorization (Shafto et al.,
2006) that generalizes traditional vector-space or
distributional models of lexical semantics (Curran,
2004; Padó and Lapata, 2007; Schütze, 1998; Tur-
ney, 2006). Cross-cutting categorization finds multi-
ple feature subsets (categorization systems) that pro-
duce high quality clusterings of the data. For exam-
ple words might be clustered based on their part of
speech, or based on their thematic usage. Context-
dependent variation in word usage can be accounted
for by leveraging multiple latent categorization sys-
tems. In particular, cross-cutting models can be used
to capture both syntagmatic and paradigmatic no-
tions of word relatedness, breaking up word features
into multiple categorization systems and then com-
puting similarity separately for each system.

MVM leverages primitives from Dirichlet-Process
Mixture Models (DPMMs) and Latent Dirichlet Al-
location (LDA). Each clustering (view) in MVM con-
sists of a distribution over features and data and
views are further subdivided into clusters based on a
DPMM. View marginal distributions are determined
by LDA, allowing data features to be distributed over
multiple views, explaining subsets of features.

1405



We evaluate MVM against several other model-
based clustering procedures in a series of human
evaluation tasks, measuring its ability to find mean-
ingful syntagmatic and paradigmatic structure. We
find that MVM finds more semantically and syntac-
tically coherent fine-grained structure, using both
common and rare n-gram contexts.

2 Mixture Modeling and Lexical
Semantics

Distributional, or vector space methods attempt to
model word meaning by embedding words in a com-
mon metric space, whose dimensions are derived
from, e.g., word collocations (Schütze, 1998), syn-
tactic relations (Padó and Lapata, 2007), or latent
semantic spaces (Finkelstein et al., 2001; Landauer
and Dumais, 1997; Turian et al., 2010). The distribu-
tional hypothesis addresses the problem of modeling
word similarity (Curran, 2004; Miller and Charles,
1991; Schütze, 1998; Turney, 2006), and can be ex-
tended to selectional preference (Resnik, 1997) and
lexical substitution (McCarthy and Navigli, 2007) as
well. Such methods are highly scalable (Gorman
and Curran, 2006) and have been applied in infor-
mation retrieval (Manning et al., 2008), large-scale
taxonomy induction (Snow et al., 2006), and knowl-
edge acquisition (Van Durme and Paşca, 2008).

Vector space models fail to capture the richness
of word meaning since similarity is not a globally
consistent metric. It violates, e.g., the triangle in-
equality: the sum of distances from bat to club and
club to association is less than the distance from bat
to association (Griffiths et al., 2007; Tversky and
Gati, 1982).1 Erk (2007) circumvents this problem
by representing words as multiple exemplars derived
directly from word occurrences and embedded in a
common vector space to capture context-dependent
usage. Likewise Reisinger and Mooney (2010) take
a similar approach using mixture modeling com-
bined with a background variation model to generate
multiple prototype vectors for polysemous words.

Both of these approaches still ultimately embed
all words in a single metric space and hence argue
for globally consistent metrics that capture human

1Similarity also has been shown to violate symmetry (e.g.
people have the intuition that China is more similar to North
Korea than North Korea is to China).

intuitive notions of “similarity.” Rather than assum-
ing a global metric embedding exists, in this work
we simply leverage the cluster assumption, e.g. that
similar words should appear in the same clusters, in
particular extending it to multiple clusterings. The
cluster assumption is a natural fit for lexical seman-
tics, as partitions can account for metric violations.
The end result is a model capable of representing
multiple, overlapping similarity metrics that result
in disparate valid clusterings leveraging the

Subspace Hypothesis: For any pair of
words, the set of “active” features govern-
ing their apparent similarity differs. For
example wine and bottle are similar and
wine and vinegar are similar, but it would
not be reasonable to expect that the fea-
tures governing such similarity computa-
tions to overlap much, despite occurring
in similar documents.

MVM can extract multiple competing notions of sim-
ilarity, for example both paradigmatic, or thematic
similarity, and syntagmatic or syntactic similarity, in
addition to more fine grained relations.

3 Multi-View Clustering with MVM

As feature dimensionality increases, the number of
ways the data can exhibit interesting structure goes
up exponentially. Clustering is commonly used to
explain data, but often there are several equally
valid, competing clusterings, keying off of different
subsets of features, especially in high-dimensional
settings such as text mining (Niu et al., 2010). For
example, company websites can be clustered by sec-
tor or by geographic location, with one particular
clustering becoming predominant when a majority
of features correlate with it. In fact, informative fea-
tures in one clustering may be noise in another, e.g.
the occurrence of CEO is not necessarily discrimi-
native when clustering companies by industry sec-
tor, but may be useful in other clusterings. Multi-
ple clustering is one approach to inferring feature
subspaces that lead to high quality data partitions.
Multiple clustering also improves the flexibility of
generative clustering models, as a single model is
no longer required to explain all the variance in the
feature dimensions (Mansinghka et al., 2009).

1406



exceedingly
sincerely
logically
justly

appropriately

unwilling
willing
reluctant
refusing
glad

about
because

and are ___
which was ___

who are ___

and is ___
we are ___
he is ___

toyota
nissan

mercedes
volvo
audi

samsung
panasonic
toshiba
sony
epson

dunlop
yokohama

toyo
uniroyal
michelin

results for ___
the latest ___

to buy ___

brand new ___
selection of ___

___ for sale

Figure 1: Example clusterings from MVM applied to
Google n-gram data. Top contexts (features) for each
view are shown, along with examples of word clusters.
Although these particular examples are interpretable, in
general the relationship captured by the view’s context
subspace is not easily summarized.

MVM is a multinomial-Dirichlet multiple clus-
tering procedure for distributional lexical seman-
tics that fits multiple, overlapping Dirichlet Process
Mixture Models (DPMM) to a set of word data. Fea-
tures are distributed across the set of clusterings
(views) using LDA, and each DPMM is fit using a
subset of the features. This reduces clustering noise
and allows MVM to capture multiple ways in which
the data can be partitioned. Figure 1 shows a sim-
ple example, and Figure 2 shows a larger sample of
feature-view assignments from a 3-view MVM fit to
contexts drawn from the Google n-gram corpus.

We implement MVM using generative model
primitives drawn from Latent Dirichlet Allocation
(LDA) and the Dirichlet Process (DP). |M | disparate
clusterings (views) are inferred jointly from a set of
data D � twd|d P r1 . . . Dsu. Each data vector
wd is associated with a probability distribution over
views θ|M |d . Empirically, θ

|M |
d is represented as a

set of feature-view assignments zd, sampled via the
standard LDA collapsed Gibbs sampler. Hence, each
view maintains a separate distribution over features.
The generative model for feature-view assignment is

given by

θ
|M |
d |α � Dirichletpαq, d P D,
φm|β � Dirichletpβq, m P |M |,
zdn|θd � Discretepθdq, n P |wd|,
wdn|φzdnm � Discretepφzdnmq, n P |wd|,

where α and β are hyperparameters smoothing the
per-document topic distributions and per-topic word
distributions respectively.

Conditional on the feature-view assignment tzu,
a clustering is inferred for each view using the Chi-
nese Restaurant Process representation of the DP.
The clustering probability is given by

ppc|z,wq 9 pptcmu, z,wq

�
M¹

m�1

|D|¹

d�1

ppw
rz�ms
d |cm, zqppcm|zq.

where ppcm|zq is a prior on the clustering for view
m, i.e. the DPMM, and ppwrz�msd |cm, zq is the like-
lihood of the clustering cm given the data point wd
restricted to the features assigned to view m:

w
rz�ms
d

def
� twid|zid � mu.

Thus, we treat them clusterings cm as conditionally
independent given the feature-view assignments.

The feature-view assignments tzu act as a set of
marginal constraints on the multiple clusterings, and
the impact that each data point can have on each
clustering is limited by the number of features as-
signed to it. For example, in a two-view model,
zid � 1 might be set for all syntactic features (yield-
ing a syntagmatic clustering) while zid � 2 is set for
document features (paradigmatic clustering).

By allowing the clustering model capacity to vary
via the DPMM, MVM can naturally account for the
semantic variance of the view. This provides a novel
mechanism for handling feature noise: noisy fea-
tures can be assigned to a separate view with poten-
tially a small number of clusters. This phenomenon
is apparent in cluster 1, view 1 in the example in
figure 2, where place names and adjectives are clus-
tered together using rare contexts

From a topic modeling perspective, MVM finds
topic refinements within each view, similar to hier-
archical methods such as the nested Chinese Restau-
rant Process (Blei et al., 2003). The main differ-
ence is that the features assigned to the second “re-
fined topics” level are constrained by the higher

1407



word

context

___ hom
e page

___ open this result in
___ w

ho had
a kind of ___

along the ___
and ___ their

are ___ to
be ___ to

but the ___ of
he is ___

in these ___
is an ___

m
any ___ and

m
ight be ___
of ___ have

of being ___
posts by ___
that ___ are

that was ___
the ___ fam

ily
the ___ m

ust be
the ___ of that

the am
erican ___

the very ___
were not ___
w

ho are ___
___ som

e of
a m

ore ___
also ___ the
and ___ his
and are ___

and is ___
and was ___

as ___ as
be ___ or

been ___ and
could be ___

his ___ of
i was ___

is also ___
near the ___
of a ___ and

of the ___ were
she was ___
so m

any ___
the m

ore ___
to be ___ and

was ___ to
we are ___
were ___ in

w
hich ___ the

w
hich was ___

w
ho is ___

you are ___
do not ___

___ high school
___ said that

___ was born
an ___ and
born in ___

by ___ on
by ___ to

create a ___
degree of ___

dsl ___ dsl
from

 the ___ to
going to ___
hotels in ___

in ___ the
in an ___

like ___ and
located in ___

m
essage to ___

nam
e of ___

posted by ___ at
presence of ___

private m
essage to ___

the ___ does not
the city of ___

to ___ a
tow

n of ___
was the ___ of

welcom
e to ___

city of ___
estate in ___

hotels ___ hotels
of ___ m

ay
real estate in ___

way of ___
w

ritten by ___
and an ___

of ___ from
 the

the little ___
___ of hum

an
first ___ of

side of the ___
to an ___

0−0

arbitrary
austin

baltimore
characteristic
comparative

dallas
evolutionary

franklin
fundamental
inadequate

inferior
integral
jackson

kent
likelihood
liverpool
mystical

newcastle
pittsburgh

poetic
proportional

psychological
radical

richmond
singular

0−10

betrayed
conquered

disappointed
divorced

embarked
frustrated

guarded
hated

knocked
murdered

praised
stationed

stole
summoned

wounded

0−77secretly

1−0

arbitrary
betrayed

characteristic
conquered

disappointed
divorced

embarked
evolutionary

examine
franklin

frustrated
fundamental

guarded
hated

inadequate
inferior
integral
jackson

knocked
likelihood
murdered

mystical
poetic

praised
proportional

radical
secretly
singular

stationed
stole

summoned
systematic

wounded

1−34

kent
liverpool

manchester
newcastle

1−94

austin
baltimore
charlotte

dallas
pittsburgh
richmond

2−0

austin
betrayed
charlotte

conquered
disappointed

divorced
embarked
frustrated

guarded
hated

jackson
kent

knocked
murdered
newcastle

praised
richmond

secretly
stationed

stole
summoned

wounded

2−47

arbitrary
characteristic
comparative
evolutionary
fundamental
inadequate

inferior
integral

mystical
poetic

psychological
radical

singular
systematic

View
 1

C
luster 1

C
luster 2

View
 2

C
luster 1

View
 3

C
luster 1

C
luster 2

Figure 2: Topics with Senses: Shows top 20% of features for each view in a 3-view MVM fit to Google n-gram context
data; different views place different mass on different sets of features. Cluster groupings within each view are shown.
View 1 cluster 2 and View 3 cluster 1 both contain past-tense verbs, but only overlap on a subset of syntactic features.

1408



level, similar to hierarchical clustering. Unlike hi-
erarchical clustering, however, the top level top-
ics/views form an admixture, allowing individual
features from a single data point to be assigned to
multiple views.

The most similar model to ours is Cross-cutting
categorization (CCC), which fits multiple DPMMs to
non-overlapping partitions of features (Mansinghka
et al., 2009; Shafto et al., 2006). Unlike MVM,
CCC partitions features among multiple DPMMs,
hence all occurrences of a particular feature will
end up in a single clustering, instead of assigning
them softly using LDA. Such hard feature partition-
ing does not admit an efficient sampling procedure,
and hence Shafto et al. (2006) rely on Metropolis-
Hastings steps to perform feature assignment, mak-
ing the model less scalable.

3.1 Word Representation
MVM is trained as a lexical semantic model on
Web-scale n-gram and semantic context data. N-
gram contexts are drawn from a combination of the
Google n-gram and Google books n-gram corpora,
with the head word removed: e.g. for the term ar-
chitect, we collect contexts such as the of the
house, an is a, and the of the universe. Se-
mantic contexts are derived from word occurrence
in Wikipedia documents: each document a word ap-
pears in is added as a potential feature for that word.
This co-occurrence matrix is the transpose of the
standard bag-of-words document representation.

In this paper we focus on two representations:

1. Syntax-only – Words are represented as bags
of ngram contexts derived slot-filling procedure
described above.

2. Syntax+Documents – The syntax-only repre-
sentation is augmented with additional docu-
ment contexts drawn from Wikipedia.

Models trained on the syntax-only set are only ca-
pable of capturing syntagmatic similarity relations,
that is, words that tend to appear in similar contexts.
In contrast, the syntax+documents set broadens the
scope of modelable similarity relations, allowing for
paradigmatic similarity (e.g. words that are topically
related, but do not necessarily share common syntac-
tic contexts).

Given such word representation data, MVM gener-
ates a fixed set of M context views corresponding to
dominant eigenvectors in local syntactic or seman-
tic space. Within each view, MVM partitions words
into clusters based on each word’s local representa-
tion in that view; that is, based on the set of con-
text features it allocates to the view. Words have a
non-uniform affinity for each view, and hence may
not be present in every clustering (Figure 2). This
is important as different ways of drawing distinc-
tions between words do not necessarily apply to all
words. In contrast, LDA finds locally consistent col-
lections of contexts but does not further subdivide
words into clusters given that set of contexts. Hence,
it may miss more fine-grained structure, even with
increased model complexity.

4 Experimental Setup

4.1 Corpora

We derive word features from three corpora: (1) the
English Google Web n-gram corpus, containing n-
gram contexts up to 5-gram that occur more than 40
times in a 1T word corpus of Web text, (2) the En-
glish Google Books n-gram corpus2, consisting of
n-gram contexts up to 5-gram that occur more than
40 times in a 500B word corpus of books, and (3) a
snapshot of the English Wikipedia3 taken on Octo-
ber 11, 2010 containing over 3M articles.

MVM is trained on a sample of 20k English words
drawn uniformly at random from the top 200k En-
glish terms appearing in Wikipedia (different parts
of speech were sampled from the Google n-gram
corpus according to their observed frequency). Two
versions of the syntax-only dataset are created from
different subsets of the Google n-gram corpora: (1)
the common subset contains all syntactic contexts
appearing more than 200 times in the combined cor-
pus, and (2) the rare subset, containing only contexts
that appear 50 times or fewer.

4.2 Human Evaluation

Our main goal in this work is to find models that
capture aspects of the syntactic and semantic orga-
nization of word in text that are intuitive to humans.

2http://ngrams.googlelabs.com/datasets
3http://wikipedia.org

1409



Context Intrusion

is characterized top of the country to
symptoms of of understood or less
cases of along the a year
in cases of portion of the per day
real estate in side of the or more

Word Intrusion

metal dues humor
floral premiums ingenuity
nylon pensions advertisers
what did delight
ruby damages astonishment

Document Intrusion

Puerto Rican cuisine Adolf Hitler History of the Han Dynasty
Greek cuisine List of General Hospital characters Romance of the Three Kingdoms
ThinkPad History of France List of dog diseases
Palestinian cuisine Joachim von Ribbentrop Conquest of Wu by Jin
Field ration World War I Mongolia

Table 1: Example questions from the three intrusion tasks, in order of difficulty (left to right, easy to hard; computed
from inter-annotator agreement). Italics show intruder items.

According to the use theory of meaning, lexical se-
mantic knowledge is equivalent to knowing the con-
texts that words appear in, and hence being able to
form reasonable hypotheses about the relatedness of
syntactic contexts.

Vector space models are commonly evaluated by
comparing their similarity predictions to a nom-
inal set of human similarity judgments (Curran,
2004; Padó and Lapata, 2007; Schütze, 1998; Tur-
ney, 2006). In this work, since we are evaluating
models that potentially yield many different simi-
larity scores, we take a different approach, scoring
clusters on their semantic and syntactic coherence
using a set intrusion task (Chang et al., 2009).

In set intrusion, human raters are shown a set of
options from a coherent group and asked to identify
a single intruder drawn from a different group. We
extend intrusion to three different lexical semantic
tasks: (1) context intrusion, where the top contexts
from each cluster are used, (3) document intrusion,
where the top document contexts from each clus-
ter are used, and (2) word intrusion, where the top
words from each cluster are used. For each clus-
ter, the top four contexts/words are selected and ap-
pended with another context/word from a different
cluster.4 The resulting set is then shuffled, and the
human raters are asked to identify the intruder, af-

4Choosing four elements from the cluster uniformly at ran-
dom instead of the top by probability led to lower performance
across all models.

ter being given a short introduction (with common
examples) to the task. Table 1 shows sample ques-
tions of varying degrees of difficulty. As the seman-
tic coherence and distinctness from other clusters in-
creases, this task becomes easier.

Set intrusion is a more robust way to account for
human similarity judgments than asking directly for
a numeric score (e.g., the Miller and Charles (1991)
set) as less calibration is required across raters. Fur-
thermore, the additional cluster context significantly
reduces the variability of responses.

Human raters were recruited from Amazon’s Me-
chanical Turk. A total of 1256 raters completed
30438 evaluations for 5780 unique intrusion tasks
(5 evaluations per task). 2736 potentially fraudulent
evaluations from 11 raters were rejected.5 Table 3
summarizes inter-annotator agreement. Overall we
found κ � 0.4 for most tasks; a set of comments
about the task difficulty is given in Table 2, drawn
from an anonymous public message board.

5 Results

We trained DPMM, LDA and MVM models
on the syntax-only and syntax+documents
data across a wide range of settings for M P
t3, 5, 7, 10, 20, 30, 50, 100, 200, 300, 500, 1000u,6

5(Rater Quality) Fraudulent Turkers were identified using
a combination of average answer time, answer entropy, average
agreement with other raters, and adjusted answer accuracy.

6LDA is run on a different range of M settings from MVM
(50-1000 vs 3-100) in order to keep the effective number of

1410



% correct

MVM−100M−0.1−0.01
MVM−50M−0.1−0.01
MVM−30M−0.1−0.01
MVM−20M−0.1−0.01
MVM−10M−0.1−0.005
MVM−10M−0.1−0.01
MVM−5M−0.1−0.005
MVM−5M−0.1−0.01
MVM−3M−0.1−0.01
  
LDA−1000M−0.1−0.01
LDA−1000M−0.1−0.1
LDA−500M−0.1−0.01
LDA−500M−0.1−0.1
LDA−300M−0.1−0.01
LDA−300M−0.1−0.1
LDA−200M−0.1−0.01
LDA−200M−0.1−0.1
LDA−100M−0.1−0.01
LDA−100M−0.1−0.1
LDA−50M−0.1−0.01
LDA−50M−0.1−0.1
 
DPMM−0.1−0.01
DPMM−0.1−0.1

context intrusion

●●●●●●●●●

0.0 0.2 0.4 0.6 0.8 1.0

word intrusion

●●●● ●●●

●● ●●●●●●●

●●●●●●●● ●● ●●

●● ● ●● ●● ●

0.0 0.2 0.4 0.6 0.8 1.0

(a) Syntax-only, common n-gram contexts.

% correct

MVM−100M−0.1−0.01
MVM−50M−0.1−0.01
MVM−30M−0.1−0.01
MVM−20M−0.1−0.01
MVM−10M−0.1−0.005
MVM−10M−0.1−0.01
MVM−5M−0.1−0.005
MVM−5M−0.1−0.01
MVM−3M−0.1−0.01
  
LDA−1000M−0.1−0.01
LDA−1000M−0.1−0.1
LDA−500M−0.1−0.01
LDA−500M−0.1−0.1
LDA−300M−0.1−0.01
LDA−300M−0.1−0.1
LDA−200M−0.1−0.01
LDA−200M−0.1−0.1
LDA−100M−0.1−0.01
LDA−100M−0.1−0.1
LDA−50M−0.1−0.01
LDA−50M−0.1−0.1
 
DPMM−0.1−0.01
DPMM−0.1−0.1

context intrusion

●●●●●

●●●●● ●●●

0.0 0.2 0.4 0.6 0.8 1.0

word intrusion

●●●

●● ●● ●

●●●

●●●●●●●●●●

0.0 0.2 0.4 0.6 0.8 1.0

(b) Syntax-only, rare n-gram contexts.

% correct

MVM−100M−0.1−0.01
MVM−50M−0.1−0.01
MVM−30M−0.1−0.01
MVM−20M−0.1−0.01
MVM−10M−0.1−0.005
MVM−10M−0.1−0.01
MVM−5M−0.1−0.005
MVM−5M−0.1−0.01
MVM−3M−0.1−0.01
  
LDA−1000M−0.1−0.01
LDA−1000M−0.1−0.1
LDA−500M−0.1−0.01
LDA−500M−0.1−0.1
LDA−300M−0.1−0.01
LDA−300M−0.1−0.1
LDA−200M−0.1−0.01
LDA−200M−0.1−0.1
LDA−100M−0.1−0.01
LDA−100M−0.1−0.1
LDA−50M−0.1−0.01
LDA−50M−0.1−0.1
 
DPMM−0.1−0.01
DPMM−0.1−0.1

context intrusion

● ●●●

●●●

●●●●●

0.0 0.2 0.4 0.6 0.8 1.0

document intrusion

●●●● ●●● ●●●

●●●●●●●● ●●

0.0 0.2 0.4 0.6 0.8 1.0

word intrusion

●

● ●●● ●

● ●● ●●●●

●●●●●

● ●●● ●●

●●●●●

●● ●● ●●● ●

0.0 0.2 0.4 0.6 0.8 1.0

(c) Syntax+Documents, common n-gram contexts.

Figure 3: Average scores for each model broken down by parameterization and data source. Error bars depict 95%
confidence intervals. X-axis labels show Model-views-α-β. Dots show average rater scores; bar-charts show standard
quantile ranges and median score.

1411



U1 I just tried 30 of the what doesn’t belong ones.
They took about 30 seconds each due to think-
ing time so not worth it for me.

U2 I don’t understand the fill in the blank ones to
be honest. I just kinda pick one,since I don’t
know what’s expected lol

U3 Your not filling in the blank just ignore the
blank and think about how the words they show
relate to each other and choose the one that
relates least. Some have just words and no
blanks.

U4 These seem very subjective to mw. i hope
there isn’t definite correct answers because
some of them make me go [emoticon of head-
scratching]

U5 I looked and have no idea. I guess I’m a word
idiot because I don’t see the relation between
the words in the preview HIT - too scared to try
any of these.

U6 I didn’t dive in but I did more than I should have
they were just too easy. Most of them I could
tell what did not belong, some were pretty iffy
though.

Table 2: Sample of comments about the task taken verba-
tim from a public Mechanical Turk user message board
(TurkerNation). Overall the raters report the task to be
difficult, but engaging.

α P t0.1, 0.01u, and β P t0.1, 0.05, 0.01u in
order to understand how they perform relatively
on the intrusion tasks and also how sensitive they
are to various parameter settings.7 Models were
run until convergence, defined as no increase in
log-likelihood on the training set for 100 Gibbs
samples. Average runtimes varied from a few hours
to a few days, depending on the number of clusters
or topics. There is little computational overhead
for MVM compared to LDA or DPMM with a similar
number of clusters.

Overall, MVM significantly outperforms both LDA
and DPMM (measured as % of intruders correctly
identified) as the number of clusters increases.
Coarse-grained lexical semantic distinctions are
easy for humans to make, and hence models with
fewer clusters tend to outperform models with more
clusters. Since high granularity predictions are more

clusters (and hence model capacity) roughly comparable.
7We did not compare directly to Cross-cutting categoriza-

tion, as the Metropolis-Hasting steps required that model were
too prohibitively expensive to scale to the Google n-gram data.

model size (clusters)

%
 c

or
re

ct 0.0

0.5

1.0

0.0

0.5

1.0

●●
●

●
● ●
● ●

●
● ●

●

●
●

● ●
● ●●

●●

●●

●
●

●● ●
●● ●●

●

●

●● ●
●

● ●
● ●

102 102.5 103

context intrusion
w

ord intrusion

(a) Syntax-only, common n-gram contexts.

model size (clusters)

%
 c

or
re

ct 0.0

0.5

1.0

0.0

0.5

1.0

●●
●●●
●●

● ● ●
●●

● ●● ●
● ●

●

●
●

●
● ●

●

● ●
●●

●
●

● ●
● ●

● ●
●

101.8 102 102.2 102.4 102.6 102.8 103 103.2

context intrusion
w

ord intrusion

(b) Syntax-only, rare n-gram contexts.

Figure 4: Scatterplot of model size vs. avg score for MVM
(dashed, purple) and LDA (dotted, orange).

useful for downstream tasks, we focus on the inter-
play between model complexity and performance.

5.1 Syntax-only Model

For common n-gram context features, MVM perfor-
mance is significantly less variable than LDA on both
the word intrusion and context intrusion tasks, and
furthermore significantly outperforms DPMM (Fig-
ure 3(a)). For context intrusion, DPMM, LDA, and
MVM average 57.4%, 49.5% and 64.5% accuracy
respectively; for word intrusion, DPMM, LDA, and
MVM average 66.7%, 66.1% and 73.6% accuracy
respectively (averaged over all parameter settings).
These models vary significantly in the average num-
ber of clusters used: 373.5 for DPMM, 358.3 for LDA
and 639.8 for MVM, i.e. the MVM model is signifi-

1412



Model Syntax Syntax+Documents Overall

DPMM 0.30 0.40 0.33
LDA 0.33 0.39 0.35
MVM 0.44 0.49 0.46
Overall 0.37 0.43 0.39

Table 3: Fleiss’ κ scores for various model and data com-
binations. Results from MVM have higher κ scores than
LDA or DPMM; likewise Syntax+Documents data yields
higher agreement, primarily due to the relative ease of the
document intrusion task.

cantly more granular. Figure 4(a) breaks out model
performance by model complexity, demonstrating
that MVM has a significant edge over LDA as model
complexity increases.

For rare n-gram contexts, we obtain similar re-
sults, with MVM scores being less variable across
model parameterizations and complexity (Figure
3(b)). In general, LDA performance degrades faster
as model complexity increases for rare contexts, due
to the increased data sparsity (Figure 4(b)). For
context intrusion, DPMM, LDA, and MVM average
45.9%, 36.1% and 50.9% accuracy respectively;
for word intrusion, DPMM, LDA, and MVM aver-
age 67.4%, 45.6% and 67.9% accuracy; MVM per-
formance does not differ significantly from DPMM,
but both outperform LDA. Average cluster sizes are
more uniform across model types for rare contexts:
384.0 for DPMM, 358.3 for LDA and 391 for MVM.

Human performance on the context intrusion task
is significantly more variable than on the word-
intrusion task, reflecting the additional complexity.

In all models, there is a high correlation between
rater scores and per-cluster likelihood, indicating
that model confidence reflects noise in the data.

5.2 Syntax+Documents Model

With the syntax+documents training set, MVM sig-
nificantly outperforms LDA across a wide range of
model settings. MVM also outperforms DPMM for
word and document intrusion. For context intru-
sion, DPMM, LDA, and MVM average 68.0%, 51.3%
and 66.9% respectively;8 for word intrusion, DPMM,
LDA, and MVM average 56.3%, 64.0% and 74.9%
respectively; for document intrusion, DPMM, LDA,

8High DPMM accuracy is driven by the low number of clus-
ters: 46.5 for DPMM vs. 358.3 for LDA and 725.6 for MVM.

model size (clusters)
%

 c
or

re
ct

0.0

0.5

1.0

0.0

0.5

1.0

0.0

0.5

1.0

●

●
●

●

●

●●●●
● ●

●

●

● ●●
●●

●●
●

●

● ●
●●

●●●

●
●
●

●

● ●
● ●

●
●●●

●

●

●
●
●

●● ●
●

●● ●
●

●
●

● ●● ●
● ●

●

102 102.5 103 103.5

context intrusion
docum

ent intrusion
w

ord intrusion

Figure 5: Scatterplot of model size vs. avg score for
MVM (dashed, purple) and LDA (dotted, orange); Syn-
tax+Documents data.

and MVM average 41.5%, 49.7% and 60.6% re-
spectively. Qualitatively, models trained on syn-
tax+document yield a higher degree of paradig-
matic clusters which have intuitive thematic struc-
ture. Performance on document intrusion is sig-
nificantly lower and more variable, reflecting the
higher degree of world knowledge required. As with
the previous data set, performance of MVM mod-
els trained on syntax+documents data degrades less
slowly as the cluster granularity increases (Figure 5).

One interesting question is to what degree MVM
views partition syntax and document features versus
LDA topics. That is, to what degree do the MVM
views capture purely syntagmatic or purely paradig-
matic variation? We measured view entropy for all
three models, treating syntactic features and docu-
ment features as different class labels. MVM with
M � 50 views obtained an entropy score of 0.045,
while LDA with M � 50 obtained 0.073, and the
best DPMM model 0.082.9 Thus MVM views may in-
deed capture pure syntactic or thematic clusterings.

9The low entropy scores reflect the higher percentage of syn-
tactic contexts overall.

1413



5.3 Discussion
As cluster granularity increases, we find that MVM
accounts for feature noise better than either LDA
or DPMM, yielding more coherent clusters. (Chang
et al., 2009) note that LDA performance degrades
significantly on a related task as the number of top-
ics increases, reflecting the increasing difficulty for
humans in grasping the connection between terms
in the same topic. This suggests that as topics be-
come more ne-grained in models with larger num-
ber of topics, they are less useful for humans. In
this work, we find that although MVM and LDA per-
form similarity on average, MVM clusters are signif-
icantly more interpretable than LDA clusters as the
granularity increases (Figures 4 and 5). We argue
that models capable of making such fine-grained se-
mantic distinctions are more desirable.

The results presented in the previous two sections
hold both for unbiased cluster selection (e.g. where
clusters are drawn uniformly at random from the
model) and when cluster selection is biased based
on model probability (results shown). Biased selec-
tion potentially gives an advantage to MVM, which
generates many more small clusters than either LDA
or DPMM, helping it account for noise.

6 Future Work

Models based on cross-cutting categorization is
a novel approach to lexical semantics and hence
should be evaluated on standard baseline tasks, e.g.
contextual paraphrase or lexical substitution (Mc-
Carthy and Navigli, 2007). Additional areas for fu-
ture work include:

(Latent Relation Modeling) Clusterings formed
from feature partitions in MVM can be viewed as a
form of implicit relation extraction; that is, instead
of relying on explicit surface patterns in text, rela-
tions between words or concepts are identified in-
directly based on common syntactic patterns. For
example, clusterings that divide cities by geography
or clusterings partition adjectives by their polarity.

(Latent Semantic Language Modeling) Genera-
tive models such as MVM can be used to build bet-
ter priors for class-based language modeling (Brown
et al., 1992). The rare n-gram results demonstrate
that MVM is potentially useful for tail contexts; i.e.
inferring tail probabilities from low counts.

(Explicit Feature Selection) In this work we rely on
smoothing to reduce the noise of over-broad extrac-
tion rather than performing feature selection explic-
itly. All of the models in this paper can be combined
with feature selection methods to remove noisy fea-
tures, and it would be particularly interesting to draw
parallels to models of “clutter” in vision.

(Hierarchical Cross-Categorization) Human con-
cept organization consists of multiple overlapping
local ontologies, similar to the loose ontological
structure of Wikipedia. Furthermore, each ontologi-
cal system has a different set of salient properties. It
would be interesting to extend MVM to model hier-
archy explicitly, and compare against baselines such
as Brown clustering (Brown et al., 1992), the nested
Chinese Restaurant Process (Blei et al., 2003) and
the hierarchical Pachinko Allocation Model (Mimno
et al., 2007).

7 Conclusion

This paper introduced MVM, a novel approach to
modeling lexical semantic organization using mul-
tiple cross-cutting clusterings capable of captur-
ing multiple lexical similarity relations jointly in
the same model. In addition to robustly handling
homonymy and polysemy, MVM naturally captures
both syntagmatic and paradigmatic notions of word
similarity. MVM performs favorably compared to
other generative lexical semantic models on a set of
human evaluations, over a wide range of model set-
tings and textual data sources.

Acknowledgements

We would like to thank the anonymous reviewers for
their extensive comments. This work was supported
by a Google PhD Fellowship to the first author.

References

David Blei, Thomas Griffiths, Michael Jordan, and
Joshua Tenenbaum. 2003. Hierarchical topic
models and the nested Chinese restaurant process.
In Proc. NIPS-2003.

Peter F. Brown, Peter V. deSouza, Robert L. Mercer,
Vincent J. Della Pietra, and Jenifer C. Lai. 1992.
Class-based n-gram models of natural language.
Computational Linguistics, 18:467–479.

1414



Jonathan Chang, Jordan Boyd-Graber, Chong Wang,
Sean Gerrish, and David M. Blei. 2009. Reading
tea leaves: How humans interpret topic models.
In NIPS.

James Curran. 2004. From Distributional to Seman-
tic Similarity. Ph.D. thesis, University of Edin-
burgh.

Katrin Erk. 2007. A simple, similarity-based model
for selectional preferences. In Proc. of the ACL.
Association for Computer Linguistics.

Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,
Ehud Rivlin, Zach Solan, Gadi Wolfman, and Ey-
tan Ruppin. 2001. Placing search in context: the
concept revisited. In Proc. of WWW 2001.

James Gorman and James R. Curran. 2006. Scaling
distributional similarity to large corpora. In Proc.
of ACL 2006.

Thomas L. Griffiths, Mark Steyvers, and Joshua B.
Tenenbaum. 2007. Topics in semantic representa-
tion. Psychological Review, 114:2007.

Thomas Landauer and Susan Dumais. 1997. A solu-
tion to Plato’s problem: The latent semantic anal-
ysis theory of acquisition, induction and repre-
sentation of knowledge. Psychological Review,
104(2):211–240.

Christopher D. Manning, Prabhakar Raghavan, and
Hinrich Schütze. 2008. Introduction to Informa-
tion Retrieval. Cambridge University Press.

Vikash K. Mansinghka, Eric Jonas, Cap Petschu-
lat, Beau Cronin, Patrick Shafto, and Joshua B.
Tenenbaum. 2009. Cross-categorization: A
method for discovering multiple overlapping clus-
terings. In Proc. of Nonparametric Bayes Work-
shop at NIPS 2009.

Diana McCarthy and Roberto Navigli. 2007.
SemEval-2007 task 10: English lexical substitu-
tion task. In SemEval ’07: Proceedings of the 4th
International Workshop on Semantic Evaluations.
Association for Computational Linguistics.

George A. Miller and Walter G. Charles. 1991. Con-
textual correlates of semantic similarity. Lan-
guage and Cognitive Processes, 6(1):1–28.

David Mimno, Wei Li, and Andrew McCallum.
2007. Mixtures of hierarchical topics with
pachinko allocation. In ICML.

Gregory L. Murphy. 2002. The Big Book of Con-
cepts. The MIT Press.

Donglin Niu, Jennifer G. Dy, and Michael I. Jor-
dan. 2010. Multiple non-redundant spectral
clustering views. In Johannes Fürnkranz and
Thorsten Joachims, editors, Proceedings of the
27th International Conference on Machine Learn-
ing (ICML-10), pages 831–838.

Sebastian Padó and Mirella Lapata. 2007.
Dependency-based construction of semantic
space models. Computational Linguistics,
33(2):161–199.

Joseph Reisinger and Raymond J. Mooney. 2010.
A mixture model with sharing for lexical seman-
tics. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP-2010).

Philip Resnik. 1997. Selectional preference and
sense disambiguation. In Proceedings of ACL
SIGLEX Workshop on Tagging Text with Lexical
Semantics, pages 52–57. ACL.

Hinrich Schütze. 1998. Automatic word sense
discrimination. Computational Linguistics,
24(1):97–123.

Patrick Shafto, Charles Kemp, Vikash Mansinghka,
Matthew Gordon, and Joshua B. Tenenbaum.
2006. Learning cross-cutting systems of cate-
gories. In Proc. CogSci 2006.

Rion Snow, Daniel Jurafsky, and Andrew Ng. 2006.
Semantic taxonomy induction from heterogenous
evidence. In Proc. of ACL 2006.

Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010. Word representations: a simple and general
method for semi-supervised learning. In Proc. of
the ACL.

Peter D. Turney. 2006. Similarity of semantic rela-
tions. Computational Linguistics, 32(3):379–416.

Amos Tversky and Itamar Gati. 1982. Similarity,
separability, and the triangle inequality. Psycho-
logical Review, 89(2):123–154.

Benjamin Van Durme and Marius Paşca. 2008.
Finding cars, goddesses and enzymes:
Parametrizable acquisition of labeled instances
for open-domain information extraction. In Proc.
of AAAI 2008.

1415


