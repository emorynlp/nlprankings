




































Hierarchical User and Item Representation with Three-Tier Attention for Recommendation


Proceedings of NAACL-HLT 2019, pages 1818â€“1826
Minneapolis, Minnesota, June 2 - June 7, 2019. cÂ©2019 Association for Computational Linguistics

1818

Hierarchical User and Item Representation with
Three-Tier Attention for Recommendation

Chuhan Wu1, Fangzhao Wu2, Junxin Liu1, and Yongfeng Huang1
1Department of Electronic Engineering, Tsinghua University Beijing 100084, China

2Microsoft Research Asia
{wuch15,ljx16,yfhuang}@mails.tsinghua.edu.cn

wufangzhao@gmail.com

Abstract

Utilizing reviews to learn user and item repre-
sentations is useful for recommender systems.
Existing methods usually merge all reviews
from the same user or for the same item into
a long document. However, different reviews,
sentences and even words usually have dif-
ferent informativeness for modeling users and
items. In this paper, we propose a hierarchical
user and item representation model with three-
tier attention to learn user and item representa-
tions from reviews for recommendation. Our
model contains three major components, i.e.,
a sentence encoder to learn sentence represen-
tations from words, a review encoder to learn
review representations from sentences, and a
user/item encoder to learn user/item represen-
tations from reviews. In addition, we incorpo-
rate a three-tier attention network in our model
to select important words, sentences and re-
views. Besides, we combine the user and item
representations learned from the reviews with
user and item embeddings based on IDs as the
final representations to capture the latent fac-
tors of individual users and items. Extensive
experiments on four benchmark datasets vali-
date the effectiveness of our approach.

1 Introduction

Learning accurate user and item representations
is very important for recommender systems (Tay
et al., 2018). Many of existing recommendation
methods learn user and item representations based
on the ratings that users gave to items (Koren et al.,
2009; Mnih and Salakhutdinov, 2008). For exam-
ple, Koren et al. (2009) proposed a matrix factor-
ization method based on SVD to learn latent rep-
resentations of users and items from the rating ma-
trix between users and items. However, since the
numbers of users and items in online platforms are
usually huge, and the rating matrix between users
and items is usually very sparse, it is quite diffi-

ï¼Šï¼Šï¼Šï¼Šåˆ Defrag and cleanup, then you have a great laptop! 

July 4, 2018 

Style: Laptop Only Verified Purchase 

I bought this laptop yesterday. This is a great laptop if you immediately run maintenance checks on it (defrag, 

disk cleanup} and remove a little bloatware. It is not a laptop to game with, but as a working/school laptop, 

you're getting a great bang for your buck. Only giving it four stars just because of the above mentioned things 

I did afterward, but by no means is this a ho ã€Œrible laptop. 

106 people found this helpful 

***** MULTIMEDIA LAPTOP 

June 22, 2018 
Style: Laptop Only Verified Purchase 

This Laptop Great! 

One person found this helpful 

Figure 1: Two example reviews.

cult for those rating based recommendation meth-
ods to learn accurate user and item representa-
tions (Zheng et al., 2017; Tay et al., 2018).

Luckily, in many online platforms such as Ama-
zon and IMDB, there are rich reviews written by
the users to express their opinions on items. These
reviews can provide rich information of items. For
example, if sentences like â€œbad battery lifeâ€ and
â€œbattery capacity is lowâ€ frequently appear in the
reviews of a smartphone, then we can infer the per-
formance of this item in battery life is not good.
The reviews also contain rich information of users.
For example, if a user frequently mentions â€œthe
price is too highâ€ and â€œvery expensiveâ€ in his/her
reviews for different items, then we can infer this
user may be sensitive to price. Thus, these reviews
can help enhance the learning of user and item
representations especially when ratings are sparse,
which is beneficial for improving the performance
of recommender systems (Zheng et al., 2017).

Utilizing reviews to learn user and item repre-
sentations for recommendation has attracted in-
creasing attentions (Zheng et al., 2017; Cather-
ine and Cohen, 2017). For example, Zheng
et al. (2017) proposed a DeepCoNN method
to learn the representations of users and items
from reviews using convolutional neural networks
(CNN), and achieved huge improvement in recom-
mendation performance. These methods usually
concatenate the reviews from the same user or the



1819

same item into a long document. However, differ-
ent reviews usually have different informativeness
in representing users and items. For example, in
Fig. 1 the first review is much more informative
than the second one. Distinguishing informative
reviews from noisy ones can help learn more accu-
rate user and item representations. In addition, dif-
ferent sentences in the same review may also have
different informativeness. For example, in Fig. 1
the sentence â€œit is not a laptop to game withâ€ con-
tains more important information than â€œI bought
this laptop yesterdayâ€. Besides, different words in
the same sentence may also have different impor-
tance. For example, in â€œthis is a great laptop if you
...â€ the word â€œgreatâ€ is more important than â€œyouâ€
in modeling this item.

In this paper, we propose a hierarchical user
and item representation model with three-tier at-
tention (HUITA) to learn informative user and item
representations from reviews for recommendation.
In our approach, the hierarchical user and item
representation model contains three major compo-
nents, i.e., a sentence encoder to learn sentence
representations from words, a review encoder to
learn review representations from sentences, and
a user/item encoder to learn user/item represen-
tations from the all reviews posted by this user
or for this item. In addition, we propose to in-
corporate a three-tier attention network into our
model to select important words, sentences and
reviews to learn more informative user and item
representations. Besides, we combine the user and
item representations learned from the reviews with
the user and item embeddings based on their IDs
as the final representations to capture the latent
factors of each individual users and items. We
conduct extensive experiments on four benchmark
datasets. The results show our approach can ef-
fectively improve the performance of recommen-
dation and outperform many baseline methods.

2 Related Work

Learning user and item representations from re-
views for recommendation has attracted many
attentions (McAuley and Leskovec, 2013; Ling
et al., 2014; Bao et al., 2014; Zhang et al., 2014;
Diao et al., 2014; He et al., 2015; Tan et al., 2016;
Ren et al., 2017). Many of the existing meth-
ods focus on extracting topics from reviews to
model users and items. For example, McAuley
and Leskovec (2013) proposed a Hidden Factors

as Topics (HFT) method to use the topic mod-
eling technique LDA to discover the latent as-
pects of users and items from the reviews. Ling
et al. (2014) proposed a Ratings Meet Reviews
(RMR) method to enhance the representations of
users and items by extracting topics from review
texts and aligning the dimensions of these topics
with the latent user representations obtained from
the rating matrix using matrix factorization. Bao et
al. (2014) proposed a TopicMF approach to jointly
model user and item representations using rating
scores via matrix factorization and using review
texts via non-negative matrix factorization (NMF)
to obtain topics. However, these methods only
extract the topic information from reviews, and a
large amount of important semantic information is
not captured. In addition, these methods are usu-
ally based on topic models and cannot effectively
model the contexts and orders of words in reviews,
both of which are important for inferring user pref-
erences and item properties.

In recent years, several deep learning based
methods have been proposed to learn user and
item representations from reviews for recommen-
dation (Zhang et al., 2016; Zheng et al., 2017;
Catherine and Cohen, 2017; Seo et al., 2017b,a;
Chen et al., 2018; Tay et al., 2018). For exam-
ple, Zheng et al. (2017) proposed a DeepCoNN
method which uses CNN to learn representations
of users and items from their reviews. Catherine
and Cohen (2017) proposed a TransNets method
to learn user and item representations from re-
views using CNN and regularize these represen-
tations to be close to the representations of the re-
view written by the target user to the target item.
Seo et al. (2017b) proposed to learn user and item
representations via CNN network as well as atten-
tion network over word embeddings. These meth-
ods concatenate all the reviews from the same user
or for the same item into a long document, and
cannot distinguish informative reviews from noisy
ones. Chen et al. (2018) proposed to model the
usefulness of reviews using review-level attention
to enhance the learning of user and item represen-
tations. However, their method regards each re-
view as a long sentence, and cannot distinguish
informative sentences and words from less infor-
mative ones. Different from the aforementioned
methods, in our approach we propose a hierarchi-
cal framework to learn user and item represen-
tations from reviews for recommendation. Our



1820

model first learns sentence representations from
words, then learns review representations from
their sentences, and finally learns user/item rep-
resentations from their reviews. Our model also
contains a three-tier attention network to jointly
select important words, sentences and reviews to
learn more informative user and item representa-
tions. Experiments on benchmark datasets vali-
date the advantage of our approach over existing
methods in recommendation.

3 Our Approach

In this section, we introduce our HUITA approach
to learn user and item representations from re-
views for recommendation. The architecture of
our approach is shown in Fig. 2. There are three
major modules in our approach. The first one is
sentence encoder which learns representations of
sentences from words. The second one is review
encoder which learns representations of reviews
from sentences. And the third one is user/item
encoder, which learns the representations of users
and items from their reviews. Next we introduce
each module in detail.

3.1 Sentence Encoder
The sentence encoder module is used to learn rep-
resentations of sentences from words. According
to Fig. 2, there are three layers in this module.

The first layer is word embedding. It is used
to convert a sequence of words into a sequence
of low-dimensional dense vectors which contain
semantic information of these words. Denote a
sentence s contains M words [w1, w2, ..., wM ].
Through the word embedding layer the sen-
tence s is transformed into a vector sequence
[e1, e2, ..., eM ] using a word embedding matrix
E âˆˆ RVÃ—D, where V and D represent the vo-
cabulary size and the word embedding dimension,
respectively. The word embedding matrix E is
initialized using pretrained word embeddings, and
fine-tuned during model training.

The second layer is a convolutional neural net-
work (CNN). CNN is an effective neural architec-
ture for capturing local information (LeCun et al.,
2015). We employ a word-level CNN to capture
the local contexts of words to learn their contex-
tual representations. Denote cwi as the contextual
representation of the word wi, which is computed
as follows:

cwi = ReLU(Uw Ã— e(iâˆ’Kw):(i+Kw) + bw), (1)

where e(iâˆ’Kw):(i+Kw) is the concatenation of the
word embedding vectors from the position iâˆ’Kw
to i + Kw. Uw âˆˆ RNwÃ—(2Kw+1)D and bw âˆˆ
RNw are the parameters of the filters in CNN net-
work, where Nw is the number of CNN filters and
2Kw + 1 is the window size. ReLU is the non-
linear activation function (Glorot et al., 2011). The
output of the CNN layer is a sequence of contex-
tual word representations [cw1 , c

w
2 , ..., c

w
M ].

The third layer is a word-level attention net-
work. Different words in the same sentence may
have different informativeness for modeling users
and items. For example, in the sentence â€œThe lap-
top I bought yesterday is too heavyâ€, the word
â€œheavyâ€ is more informative than the word â€œyes-
terdayâ€ in representing this laptop. Thus, we use
a word-level attention network to help our model
select and attend to important words based on their
contextual representations to build more informa-
tive sentence representations for user and item
modeling. The attention weight of the ith word
in the sentence s is computed as follows:

awi = tanh(vw Ã— cwi + bw), (2)

Î±wi =
exp(awi )âˆ‘M
j=1 exp(a

w
j )
, (3)

where vw âˆˆ RNw and bw âˆˆ R are the param-
eters in the attention network. Î±i indicates the
relative importance of the ith word evaluated by
the attention network. The final representation of
the sentence s is the summation of the contextual
word representations weighted by their attention
weights as follows:

s =
Mâˆ‘
i=1

Î±wi c
w
i . (4)

3.2 Review Encoder
The review encoder module aims to build the rep-
resentations of each review based on the represen-
tation of sentences in these reviews. There are two
major layers in the review encoder module.

The first layer is a sentence-level CNN network.
Neighboring sentences usually have some relat-
edness with each other. For example, in a lap-
top review â€œIt is not a laptop to game with. But
as a working laptop, you will get a great bang
for your buckâ€, the two neighboring sentences
have close relatedness and they both describe the
performance of the laptop in different scenarios.



1821

CNN CNN

CNN

CNN CNN

ğ’–ğ’–ğ’“ğ’“

ï¿½ğ’šğ’š

CNN CNN CNN CNN

ğ’•ğ’•ğ’“ğ’“

Rating 
Prediction

ğ’–ğ’–ğ’…ğ’…

Word
Embedding

Word-level
Attention

Word-level
CNN

Review-level
Attention

Sentence-level
Attention

Sentence-level
CNN

User
ID

Item
ID

User
Embedding

Item
Embedding

ğ’†ğ’†1 ğ’†ğ’†2 ğ’†ğ’†ğ‘€ğ‘€ ğ’†ğ’†1 ğ’†ğ’†2 ğ’†ğ’†ğ‘€ğ‘€ ğ’†ğ’†1 ğ’†ğ’†2 ğ’†ğ’†ğ‘€ğ‘€ ğ’†ğ’†1 ğ’†ğ’†2 ğ’†ğ’†ğ‘€ğ‘€ ğ’†ğ’†1 ğ’†ğ’†2 ğ’†ğ’†ğ‘€ğ‘€ ğ’†ğ’†1 ğ’†ğ’†2 ğ’†ğ’†ğ‘€ğ‘€ ğ’†ğ’†1 ğ’†ğ’†2 ğ’†ğ’†ğ‘€ğ‘€ ğ’†ğ’†1 ğ’†ğ’†2 ğ’†ğ’†ğ‘€ğ‘€

ğ’„ğ’„1ğ‘¤ğ‘¤ ğ’„ğ’„2ğ‘¤ğ‘¤ ğ’„ğ’„ğ‘€ğ‘€ğ‘¤ğ‘¤
ğ›‚ğ›‚1ğ‘¤ğ‘¤ğ›‚ğ›‚2ğ‘¤ğ‘¤ ğ›‚ğ›‚ğ‘€ğ‘€ğ‘¤ğ‘¤

ğ’”ğ’”1 ğ’”ğ’”ğ‘ğ‘ğ’”ğ’”2 ğ’”ğ’”1 ğ’”ğ’”ğ‘ğ‘ğ’”ğ’”2 ğ’”ğ’”1 ğ’”ğ’”ğ‘ğ‘ğ’”ğ’”2 ğ’”ğ’”1 ğ’”ğ’”ğ‘ğ‘ğ’”ğ’”2

CNN CNN CNN

ğ’„ğ’„1ğ‘ ğ‘  ğ’„ğ’„ğ‘ğ‘ğ‘ ğ‘ ğ’„ğ’„2ğ‘ ğ‘ 

ğ›‚ğ›‚1ğ’”ğ’” ğ›‚ğ›‚ğ‘ğ‘
ğ’”ğ’”ğ›‚ğ›‚2ğ’”ğ’” ğ›‚ğ›‚1ğ’”ğ’” ğ›‚ğ›‚ğ‘µğ‘µ

ğ’”ğ’”ğ›‚ğ›‚2ğ’”ğ’”

ğ›‚ğ›‚1ğ’“ğ’“ ğ›‚ğ›‚ğ‘·ğ‘·
ğ’“ğ’“ğ›‚ğ›‚2ğ’“ğ’“

ğ›‚ğ›‚1ğ’”ğ’” ğ›‚ğ›‚ğ‘ğ‘
ğ’”ğ’”ğ›‚ğ›‚2ğ’”ğ’” ğ›‚ğ›‚1ğ’”ğ’” ğ›‚ğ›‚ğ‘ğ‘

ğ’”ğ’”ğ›‚ğ›‚2ğ’”ğ’”

ğ›‚ğ›‚1ğ’“ğ’“ ğ›‚ğ›‚ğ‘·ğ‘·
ğ’“ğ’“ğ›‚ğ›‚2ğ’“ğ’“

ğ’“ğ’“1 ğ’“ğ’“ğ‘ƒğ‘ƒğ’“ğ’“2 ğ’“ğ’“1 ğ’“ğ’“ğ‘·ğ‘·ğ’“ğ’“2

ğ’•ğ’•ğ’…ğ’…

ğ’—ğ’—ğ‘¤ğ‘¤ ğ’—ğ’—ğ‘¤ğ‘¤ ğ’—ğ’—ğ‘¤ğ‘¤ ğ’—ğ’—ğ‘¤ğ‘¤

ğ’—ğ’—ğ’”ğ’” ğ’—ğ’—ğ’”ğ’”

ğ’—ğ’—ğ’“ğ’“ ğ’—ğ’—ğ’“ğ’“

ğ’„ğ’„1ğ‘¤ğ‘¤ ğ’„ğ’„2ğ‘¤ğ‘¤ ğ’„ğ’„ğ‘€ğ‘€ğ‘¤ğ‘¤
ğ›‚ğ›‚1ğ‘¤ğ‘¤ğ›‚ğ›‚2ğ‘¤ğ‘¤ ğ›‚ğ›‚ğ‘€ğ‘€ğ‘¤ğ‘¤

ğ’„ğ’„1ğ‘¤ğ‘¤ ğ’„ğ’„2ğ‘¤ğ‘¤ ğ’„ğ’„ğ‘€ğ‘€ğ‘¤ğ‘¤
ğ›‚ğ›‚1ğ‘¤ğ‘¤ğ›‚ğ›‚2ğ‘¤ğ‘¤ ğ›‚ğ›‚ğ‘€ğ‘€ğ‘¤ğ‘¤

ğ’„ğ’„1ğ‘¤ğ‘¤ ğ’„ğ’„2ğ‘¤ğ‘¤ ğ’„ğ’„ğ‘€ğ‘€ğ‘¤ğ‘¤
ğ›‚ğ›‚1ğ‘¤ğ‘¤ğ›‚ğ›‚2ğ‘¤ğ‘¤ ğ›‚ğ›‚ğ‘€ğ‘€ğ‘¤ğ‘¤

ğ’„ğ’„1ğ‘¤ğ‘¤ ğ’„ğ’„2ğ‘¤ğ‘¤ ğ’„ğ’„ğ‘€ğ‘€ğ‘¤ğ‘¤
ğ›‚ğ›‚1ğ‘¤ğ‘¤ğ›‚ğ›‚2ğ‘¤ğ‘¤ ğ›‚ğ›‚ğ‘€ğ‘€ğ‘¤ğ‘¤

ğ’„ğ’„1ğ‘¤ğ‘¤ ğ’„ğ’„2ğ‘¤ğ‘¤ ğ’„ğ’„ğ‘€ğ‘€ğ‘¤ğ‘¤
ğ›‚ğ›‚1ğ‘¤ğ‘¤ğ›‚ğ›‚2ğ‘¤ğ‘¤ ğ›‚ğ›‚ğ‘€ğ‘€ğ‘¤ğ‘¤

ğ’„ğ’„1ğ‘¤ğ‘¤ ğ’„ğ’„2ğ‘¤ğ‘¤ ğ’„ğ’„ğ‘€ğ‘€ğ‘¤ğ‘¤
ğ›‚ğ›‚1ğ‘¤ğ‘¤ğ›‚ğ›‚2ğ‘¤ğ‘¤ ğ›‚ğ›‚ğ‘€ğ‘€ğ‘¤ğ‘¤

ğ’„ğ’„1ğ‘¤ğ‘¤ ğ’„ğ’„2ğ‘¤ğ‘¤ ğ’„ğ’„ğ‘€ğ‘€ğ‘¤ğ‘¤
ğ›‚ğ›‚1ğ‘¤ğ‘¤ğ›‚ğ›‚2ğ‘¤ğ‘¤ ğ›‚ğ›‚ğ‘€ğ‘€ğ‘¤ğ‘¤

ğ’„ğ’„1ğ‘ ğ‘  ğ’„ğ’„ğ‘ğ‘ğ‘ ğ‘ ğ’„ğ’„2ğ‘ ğ‘  ğ’„ğ’„1
ğ‘ ğ‘  ğ’„ğ’„ğ‘ğ‘ğ‘ ğ‘ ğ’„ğ’„2ğ‘ ğ‘  ğ’„ğ’„1ğ‘ ğ‘  ğ’„ğ’„ğ‘ğ‘ğ‘ ğ‘ ğ’„ğ’„2ğ‘ ğ‘ 

ğ’•ğ’•

ğ‘¤ğ‘¤11

ğ‘¤ğ‘¤1 ğ‘¤ğ‘¤2 ğ‘¤ğ‘¤ğ‘€ğ‘€

Word 
Embedding

ğ‘¤ğ‘¤1 ğ‘¤ğ‘¤2 ğ‘¤ğ‘¤ğ‘€ğ‘€

Word 
Embedding

ğ‘¤ğ‘¤1 ğ‘¤ğ‘¤2 ğ‘¤ğ‘¤ğ‘€ğ‘€

Word 
Embedding

ğ‘¤ğ‘¤1 ğ‘¤ğ‘¤2 ğ‘¤ğ‘¤ğ‘€ğ‘€

Word 
Embedding

ğ‘¤ğ‘¤1 ğ‘¤ğ‘¤2 ğ‘¤ğ‘¤ğ‘€ğ‘€

Word 
Embedding

ğ‘¤ğ‘¤1 ğ‘¤ğ‘¤2 ğ‘¤ğ‘¤ğ‘€ğ‘€

Word 
Embedding

ğ‘¤ğ‘¤1 ğ‘¤ğ‘¤2 ğ‘¤ğ‘¤ğ‘€ğ‘€

Word 
Embedding

ğ‘¤ğ‘¤1 ğ‘¤ğ‘¤2 ğ‘¤ğ‘¤ğ‘€ğ‘€

Word 
Embedding

Review
Encoder

Sentence
Encoder

User/item
Encoder

ğ‘ ğ‘ 1 ğ‘ ğ‘ ğ‘ğ‘ ğ‘ ğ‘ 1 ğ‘ ğ‘ ğ‘ğ‘ ğ‘ ğ‘ 1 ğ‘ ğ‘ ğ‘ğ‘ ğ‘ ğ‘ 1 ğ‘ ğ‘ ğ‘ğ‘ğ‘Ÿğ‘Ÿ1 ğ‘Ÿğ‘Ÿğ‘ƒğ‘ƒ ğ‘Ÿğ‘Ÿ1 ğ‘Ÿğ‘Ÿğ‘ƒğ‘ƒ

ğ’–ğ’–

Figure 2: The framework of our HUITA approach for recommendation.

Thus, we employ a sentence-level CNN network
to learn the contextual sentence representations by
capturing the local contexts of sentences. Denote
a review r contains N sentences [s1, s2, ..., sN ].
Denote the contextual representation of sentence
si as csi , which is computed as follows:

csi = ReLU(Us Ã— s(iâˆ’Ks):(i+Ks) + bs), (5)

where Us âˆˆ RNsÃ—(2Ks+1)Nw and bs âˆˆ RNs
are parameters of the sentence-level CNN filters.
s(iâˆ’Ks):(i+Ks) is the concatenation of sentence
representation vectors from position i âˆ’ Ks to
i + Ks. Ns is the number of filters in sentence
CNN network and 2Ks + 1 is the window size.

The second layer is a sentence-level attention
network. Different sentences in a review may have
different informativeness for modeling users and
items. For example, the sentence â€œit is not a lap-
top to game withâ€ is more informative than the
sentence â€œI bought this laptop yesterdayâ€ in learn-
ing the representation of this laptop. Thus, we use
sentence-level attention network to help our model
select and attend to important sentences to learn
more informative review representations. The at-
tention weight of sentence si in the review r is for-
mulated as follows:

asi = tanh(vs Ã— csi + bs), (6)

Î±si =
exp(asi )âˆ‘N
j=1 exp(a

s
j)
, (7)

where vs âˆˆ RNs and bs âˆˆ R are the parameters
of the attention network. The final contextual rep-
resentation of the review r is the summation of the
contextual representations of sentences weighted
by their attention weights, which is formulated as:

r =
Nâˆ‘
i=1

Î±sic
s
i . (8)

3.3 User/Item Encoder
The user/item encoder module is used to build the
representations of users or items based on the rep-
resentations of their reviews. Different reviews
usually have different informativeness in model-
ing users or items. For example, in Fig. 1, the first
review contains much more information of the lap-
top than the second review, and should has more
contributions in building the representation of this
laptop. Thus, we use a review-level attention net-
work to distinguish informative reviews from less
informative ones. Denote a user u has P reviews
[r1, r2, ...., rP ]. Then the attention weight of the
review ri is computed as follows:

ari = tanh(vr Ã— ri + br), (9)

Î±ri =
exp(ari )âˆ‘P
j=1 exp(a

r
j)
, (10)



1822

where vr âˆˆ RNs and br âˆˆ R are the parameters of
the review-level attention network. The user repre-
sentation learned from the reviews is the summa-
tion of the contextual representations of reviews
weighted by their attention weights:

ur =

Pâˆ‘
i=1

Î±ri ri. (11)

Although the user representation ur learned
from reviews contain rich information of users,
there are some latent characteristics of users which
are not described in their reviews but can be in-
ferred from the rating patterns. Thus, we also
represent users using the embedding of their IDs
to capture the latent factors of users, which are
motivated by traditional recommendation meth-
ods (Koren et al., 2009). The final representation
of user u is the concatenation of the user represen-
tation ur learned from reviews and the user em-
bedding ud inferred from user ID, as follows:

u = [ur,ud]. (12)

The representations of items can be computed in
a similar way. Denote the representation of item t
learned from reviews as tr, and the item embed-
ding inferred from item ID as td. Then the final
representation of this item is as follows:

t = [tr, td]. (13)

3.4 Rating Prediction
In recommender systems the recommendations are
made based on the predicted ratings that a user will
give to an item. In our HUITA approach, the rating
score of a user-item pair is predicted based on the
representations of users and items as follows:

yÌ‚ = ReLU(wT (uï¿½ t) + b), (14)
where ï¿½ is item-wise dot product, w and b are pa-
rameters in the rating prediction layer.

In the model training stage, we optimize the
model parameters to minimize the difference be-
tween gold rating and predicted ratings. We use
the mean squared error as the loss function:

L = 1
NP

NPâˆ‘
i=1

(yÌ‚i âˆ’ yi)2, (15)

where NP denotes the number of user-item pairs
in training data, yÌ‚i and yi are the predicted rating
score and the gold rating score respectively of the
ith user-item pair.

Dataset #users #items #reviews
Toys and Games 19,412 11,924 167,597

Kindle Store 68,223 61,935 982,619
Movies and TV 123,960 50,052 1,679,533

Yelp 2017 199,445 119,441 3,072,129

Table 1: Statistics of datasets used in our experiments.

4 Experiments

4.1 Datasets and Experimental Settings

We conducted experiments on four widely used
benchmark datasets in different domains to eval-
uate the effectiveness of our approach. Follow-
ing (Chen et al., 2018), we used three datasets
from the Amazon collection1(He and McAuley,
2016), i.e., Toys and Games, Kindle Store, and
Movies and TV. Another dataset is from Yelp
Challenge 20172 (denoted as Yelp 2017), which
is a large-scale restaurant review dataset. Follow-
ing (Chen et al., 2018), we only kept the users and
items which have at least 5 reviews. The detailed
statistics of the four datasets are summarized in
Table 1. The ratings in these datasets are in [1, 5].

In our experiments, the dimension of word em-
beddings was set to 300. We used the pre-trained
Google embedding (Mikolov et al., 2013) to ini-
tialize the word embedding matrix. The word-
level CNN has 200 filters and their window size
is 3. The sentence-level CNN has 100 filters
with window size of 3. We applied dropout strat-
egy (Srivastava et al., 2014) to each layer of our
model to mitigate overfitting. The dropout rate
was set to 0.2. Adam (Kingma and Ba, 2014) was
used as the optimization algorithm. The batch size
was set to 20. We randomly selected 80% of the
user-item pairs in each dataset for training, 10%
for validation and 10% for test. All the hyperpa-
rameters were selected according to the validation
set. We independently repeated each experiment
for 5 times and reported the average performance
in Root Mean Square Error (RMSE).

4.2 Performance Evaluation

We evaluate the performance of our approach by
comparing it with several baseline methods. The
methods to be compared include:

â€¢ PMF: Probabilistic Matrix Factorization,
which models users and items based on

1http://jmcauley.ucsd.edu/data/amazon
2https://www.yelp.com/dataset challenge



1823

PMF NMF SVD++ HFT DeepCoNN Attn+CNN NARRE HUITA
Rating score X X X X X X X X
Review text X X X X X

Word context & order X X X X
Review attention X X

Word/sentence attention X* X

Table 2: Information used in different methods. *Only word attention is modeled.

Methods Toys and Games Kindle Store Movies and TV Yelp 2017
PMF 1.3076 0.9914 1.2920 1.3340
NMF 1.0399 0.9023 1.1125 1.2916

SVD++ 0.8860 0.7928 1.0447 1.1735
HFT 0.8925 0.7917 1.0291 1.1699

DeepCoNN 0.8890 0.7876 1.0128 1.1642
Attn+CNN 0.8805 0.7796 0.9984 1.1588

NARRE 0.8769 0.7783 0.9965 1.1559
HUITA 0.8649 0.7464 0.9631 1.1246

Table 3: RMSE scores of different methods on different datasets. Lower RMSE score means better performance.

ratings via matrix factorization (Mnih and
Salakhutdinov, 2008).

â€¢ NMF: Non-negative Matrix Factorization for
recommendation based on rating scores (Lee
and Seung, 2001).

â€¢ SVD++: The recommendation method based
on rating matrix via SVD and similarities be-
tween items (Koren, 2008).

â€¢ HFT: Hidden Factor as Topic (HFT), a
method to combine reviews with ratings via
LDA (McAuley and Leskovec, 2013).

â€¢ DeepCoNN: Deep Cooperative Neural Net-
works, a neural method to jointly model users
and items from their reviews via CNN (Zheng
et al., 2017).

â€¢ Attn+CNN: Attention-based CNN, which
uses both CNN and attention over word em-
beddings to learn user and item representa-
tion from reviews (Seo et al., 2017b).

â€¢ NARRE: Neural Attentional Rating Regres-
sion with Review-level Explanations, which
uses attention mechanism to model the in-
formativeness of reviews for recommenda-
tion (Chen et al., 2018).

â€¢ HUITA: our proposed hierarchical user and
item representation approach with three-tier
attention for recommendation with reviews.

In Table 2, we show a simple comparison of dif-
ferent methods in terms of the information con-
sidered in each method. Traditional recommen-
dation methods such as PMF, NMF and SVD are
solely based on rating scores, and other methods
HFT, DeepCoNN, Attn+CNN, NARRE and HUITA
can exploit both rating scores and reviews for rec-
ommendation. Among the latter methods, HFT
is based on topic models and cannot capture the
contexts and orders of words. DeepCoNN and
Attn+CNN simply concatenate reviews into a long
document, and cannot model the informativeness
of different reviews. Although NARRE can model
review helpfulness via attention, it simply merges
all sentences in a review together, and does not
model the informativeness of different sentences
and words. Different from these methods, our
HUITA approach learns user and item representa-
tions from reviews in a hierarchical manner, and
uses a three-tier attention network to select and at-
tend to important words, sentences and reviews.

The results of different methods are shown in
Table 3. We have several observations from the
results. First, the methods which exploit reviews
(i.e., HFT, DeepCoNN, Attn+CNN, NARRE and
HUITA) usually perform better than the methods
only based on rating scores (i.e., PMF, NMF and
SVD++). It validates reviews can provide rich in-
formation of user preferences and item properties,
and is important to learn informative user and item
representations and can benefit recommendation.



1824

Methods Toys and Games Kindle Store Movies and TV Yelp 2017
All 0.8649 0.7464 0.9631 1.1246

-word attention 0.8721 0.7610 0.9744 1.1337
-sentence attention 0.8714 0.7569 0.9715 1.1308
-review attention 0.8685 0.7523 0.9720 1.1294

Table 4: The effectiveness of different levels of attentions. The evaluation metric is RMSE.

Second, among the method which can exploit
reviews, the neural network based methods (e.g.,
DeepCoNN, Attn+CNN, NARRE and HUITA) usu-
ally outperform the HFT method which is based
on topic models. This is probably because in HFT
the reviews are represented using bag-of-words
features, and the contextual information and the
orders of words are lost. This result validates the
neural network based method can better capture
the semantic information in reviews to model users
and items for recommendation.

Third, the methods considering review help-
fulness (i.e., NARRE) and word importance (i.e.,
Attn+CNN) usually outperform DeepCoNN. This
result implies that different words and different
reviews have different importance for modeling
users and items from reviews. Distinguishing im-
portant reviews and words from less important
ones is beneficial to learn more accurate user and
item representations for recommendation.

Fourth, our approach can consistently outper-
form all the baseline methods compared here. This
is because different from baseline methods such
as Attn+CNN and DeepCoNN which merge all re-
views into a long document and NARRE which
merges all sentences into a long sentence, our
HUITA approach learns user and item representa-
tions in a hierarchical manner. HUITA first learns
sentence representations from words, then learns
review representations from sentences, and finally
learns user/item representations from reviews. Be-
sides, our approach incorporates a three-tier atten-
tion network to jointly select and attend to impor-
tant words, sentences and reviews. Thus, our ap-
proach can learn more informative user and item
representations from reviews for recommendation.

4.3 Effectiveness of Three-Tier Attention
In this section, we conducted experiments to ex-
plore the effectiveness of the three-tier attention
network in our approach. We compare three vari-
ants of our model by removing one kind of atten-
tion each time to evaluate its contribution to the
performance. The results are shown in Table 4.

According to Table 4, the word-level attention
can effectively improve the performance of our ap-
proach. This is because different words in reviews
have different importance in modeling users and
items. Therefore, recognizing and highlighting
the important words using the word-level atten-
tion network can help learn more informative sen-
tence representations. In addition, the sentence-
level attention is also useful. This may be because
different sentences have different informativeness.
For example, in a laptop review the sentence â€œthis
laptop is expensiveâ€ is more informative than â€œI
bought this laptop yesterdayâ€ in representing this
laptop. The sentence-level attention network can
help to select important sentences to build review
representations. Besides, the review-level atten-
tion is also useful in our HUITA approach. This is
because different reviews have different informa-
tiveness in representing users and items. And dis-
tinguishing informative reviews from the less in-
formative ones can help learn more accurate rep-
resentations of users and items. Moreover, com-
bining all the three levels of attentions can further
improve the performance of our approach, which
validates the effectiveness of our three-tier atten-
tion architecture.

4.4 Case Study
In this section, we conducted several case studies
to further explore whether our approach can select
informative words, sentences and reviews to learn
informative user and item representations for rec-
ommendation. First, we want to explore the ef-
fectiveness of the word- and sentence-level atten-
tion networks. The visualization of the attention
weights in the word- and sentence-level attention
networks is shown in Fig. 3. From Fig. 3 we can
see that our word-level attention network can ef-
fectively select and attend to important words. For
example, in Fig. 3(a) the words â€œGoodâ€, â€œqualityâ€
and â€œrecommendâ€ are assigned higher attention
weights than â€œboughtâ€ and â€œdadâ€, since â€œGoodâ€,
â€œqualityâ€ and â€œrecommendâ€ can better model the
properties of the film. In addition, our model can



1825

I bought this for my father.
He loves JCVD.
He already had an old VHS copy of this film.
I bought the dvd version.
Good quality and my dad really enjoyed watching it.
Would recommend this for others.

I purchased this book on a whim. 
I never cared for short stories when I was younger 
but I'm always willing to give something a try again,
if I didn't have a horrible experience before.
From reading I found short stories are still not my style. 
But if you like them, this is a good read. 

(a) Movies and TV

I bought this for my father.
He loves JCVD.
He already had an old VHS copy of this film.
I bought the dvd version.
Good quality and my dad really enjoyed watching it.
Would recommend this for others.

I purchased this book on a whim. 
I never cared for short stories when I was younger 
but I'm always willing to give something a try again,
if I didn't have a horrible experience before.
From reading I found short stories are still not my style. 
But if you like them, this is a good read. 

(b) Kindle Store

Figure 3: Visualization of attention weights in two randomly selected reviews from the Movies and TV and Kin-
dle Store datasets respectively. Red boxes to the left of the reviews represent sentence-level attention weights, and
blue boxes on the individual words represent word-level attention weights. Darker color represents higher attention
weights.

I had to send it back after a month.  It was not working

Great product. Works fantastic. Fires up the Fire in no time. I love 
my Kindle Fire HD and this helps me keep it ready for use. Very 
handy tool to have and worth the price.

I gave my original 2 year old kindle to my spouse when I purchased 
the new HD kindle with points. It did not come with the electric 
charger. so I bought one. Did not want to hassle sharing with my 
spouse (we had a charger for the old kindle).

This charger is a must have, since the kindle fire hd dosent have a 
great battery life and it takes forever for the regular charger to 
charge it .This rapid charger is a life saver.

Have not read yet

Look forward to reading this soon.  I am into the 19th century and 
look forward to this. Have not read anything on the subject though 
I have been fascinated and watched all I can whenever it is on such 
as History Channel.

I am a fan of Rangers both Texas and Arizona (yes Arizona Had 
their Rangers now they are an Honorary Organization)

I wanted more information on Tesla, as I said above his theories 
and very character are used through out Steampunk once you are 
aware of what he did!

Thought I would give it a read

(a) User

I had to send it back after a month.  It was not working

Great product. Works fantastic. Fires up the Fire in no time. I love 
my Kindle Fire HD and this helps me keep it ready for use. Very 
handy tool to have and worth the price.

I gave my original 2 year old kindle to my spouse when I purchased 
the new HD kindle with points. It did not come with the electric 
charger. so I bought one. Did not want to hassle sharing with my 
spouse (we had a charger for the old kindle).

This charger is a must have, since the kindle fire hd dosent have a 
great battery life and it takes forever for the regular charger to 
charge it .This rapid charger is a life saver.

Have not read yet

Look forward to reading this soon.  I am into the 19th century and 
look forward to this. Have not read anything on the subject though 
I have been fascinated and watched all I can whenever it is on such 
as History Channel.

I am a fan of Rangers both Texas and Arizona (yes Arizona Had 
their Rangers now they are an Honorary Organization)

I wanted more information on Tesla, as I said above his theories 
and very character are used through out Steampunk once you are 
aware of what he did!

Thought I would give it a read

(b) Item

Figure 4: Visualization of attention weights of reviews from a randomly selected user and item in the Kindle Store
dataset. Vertical bars represent review-level attention weights and darker color represents higher attention weights.

effectively select informative sentences using the
sentence-level attention network. For example, in
Fig. 3(b) the sentence â€œFrom reading I found short
stories are still not my styleâ€ is assigned high at-
tention weight since it is informative for repre-
senting this user and is important for recommen-
dation, while the sentence â€œI purchased this book
on a whimâ€ has low attention weight since it con-
tains limited information of users and items. Thus,
these results validate that our approach is effective
in selecting informative words and sentences in re-
views for recommendation through the word- and
sentence-level attention networks.

Second, we want to explore the effectiveness
of the review-level attention in our HUITA ap-
proach. The visualization of the review-level at-
tention weights is shown in Fig. 4. From Fig. 4
we can see that our approach can effectively select
and attend to informative reviews. For example,
the second review in Fig. 4(a) is assigned high at-
tention weight by our approach since it reveals rich
information of user preferences. However, the first
review in Fig. 4(a) receives low attention weight
since it contain limited information of users. Thus,
these results validate the effectiveness of our ap-

proach in selecting informative reviews to learn
more accurate representations of users and items
from reviews for recommendation.

5 Conclusion

In this paper, we propose a hierarchical user and
item representation model with three-tier atten-
tion to learn user and item representations from
reviews for recommendation. In our approach,
we use a sentence encoder to learn sentence rep-
resentations from words, a review encoder to
learn review representations from sentences, and
a user/item encoder to learn user/item representa-
tions from reviews. In addition, we incorporate
a three-tier attention network into our model to
select and attend to informative words, sentences
and reviews to learn more accurate representations
of users and items. Besides, we combine the user
and item representations learned from the reviews
with the embeddings of user and item IDs as the
final representations of users and items to capture
the latent factors of individual users and items.
The experiments on four benchmark datasets vali-
date that our approach can effectively improve the
performance of recommendation and consistently



1826

outperform many baseline methods.

Acknowledgments

This work was supported by the National Key Re-
search and Development Program of China un-
der Grant number 2018YFC1604002, and the Na-
tional Natural Science Foundation of China under
Grant numbers U1836204, U1705261, U1636113,
U1536201, and U1536207.

References
Yang Bao, Hui Fang, and Jie Zhang. 2014. Topicmf:

Simultaneously exploiting ratings and reviews for
recommendation. In AAAI, volume 14, pages 2â€“8.

Rose Catherine and William Cohen. 2017. Transnets:
Learning to transform for recommendation. In Rec-
Sys, pages 288â€“296. ACM.

Chong Chen, Min Zhang, Yiqun Liu, and Shaoping
Ma. 2018. Neural attentional rating regression with
review-level explanations. In WWW, pages 1583â€“
1592.

Qiming Diao, Minghui Qiu, Chao-Yuan Wu, Alexan-
der J Smola, Jing Jiang, and Chong Wang. 2014.
Jointly modeling aspects, ratings and sentiments for
movie recommendation (jmars). In KDD, pages
193â€“202.

Xavier Glorot, Antoine Bordes, and Yoshua Bengio.
2011. Deep sparse rectifier neural networks. In Pro-
ceedings of the Fourteenth International Conference
on Artificial Intelligence and Statistics, pages 315â€“
323.

Ruining He and Julian McAuley. 2016. Ups and
downs: Modeling the visual evolution of fashion
trends with one-class collaborative filtering. In
WWW, pages 507â€“517.

Xiangnan He, Tao Chen, Min-Yen Kan, and Xiao
Chen. 2015. Trirank: Review-aware explainable
recommendation by modeling aspects. In CIKM,
pages 1661â€“1670.

Diederik P Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980.

Yehuda Koren. 2008. Factorization meets the neigh-
borhood: a multifaceted collaborative filtering
model. In KDD, pages 426â€“434.

Yehuda Koren, Robert Bell, and Chris Volinsky. 2009.
Matrix factorization techniques for recommender
systems. Computer, (8):30â€“37.

Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.
2015. Deep learning. nature, 521(7553):436.

Daniel D Lee and H Sebastian Seung. 2001. Al-
gorithms for non-negative matrix factorization. In
NIPS, pages 556â€“562.

Guang Ling, Michael R Lyu, and Irwin King. 2014.
Ratings meet reviews, a combined approach to rec-
ommend. In RecSys, pages 105â€“112.

Julian McAuley and Jure Leskovec. 2013. Hidden fac-
tors and hidden topics: understanding rating dimen-
sions with review text. In RecSys, pages 165â€“172.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In NIPS, pages 3111â€“3119.

Andriy Mnih and Ruslan R Salakhutdinov. 2008. Prob-
abilistic matrix factorization. In NIPS, pages 1257â€“
1264.

Zhaochun Ren, Shangsong Liang, Piji Li, Shuaiqiang
Wang, and Maarten de Rijke. 2017. Social collabo-
rative viewpoint regression with explainable recom-
mendations. In WSDM, pages 485â€“494.

Sungyong Seo, Jing Huang, Hao Yang, and Yan Liu.
2017a. Interpretable convolutional neural networks
with dual local and global attention for review rating
prediction. In RecSys, pages 297â€“305. ACM.

Sungyong Seo, Jing Huang, Hao Yang, and Yan Liu.
2017b. Representation learning of users and items
for review rating prediction using attention-based
convolutional neural network. In MLRec.

Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: a simple way to prevent neural networks
from overfitting. Journal of machine learning re-
search, 15(1):1929â€“1958.

Yunzhi Tan, Min Zhang, Yiqun Liu, and Shaoping Ma.
2016. Rating-boosted latent topics: Understanding
users and items with ratings and reviews. In IJCAI,
pages 2640â€“2646.

Yi Tay, Anh Tuan Luu, and Siu Cheung Hui. 2018.
Multi-pointer co-attention networks for recommen-
dation. In KDD, pages 2309â€“2318.

Wei Zhang, Quan Yuan, Jiawei Han, and Jianyong
Wang. 2016. Collaborative multi-level embedding
learning from reviews for rating prediction. In IJ-
CAI, pages 2986â€“2992.

Yongfeng Zhang, Guokun Lai, Min Zhang, Yi Zhang,
Yiqun Liu, and Shaoping Ma. 2014. Explicit fac-
tor models for explainable recommendation based
on phrase-level sentiment analysis. In SIGIR, pages
83â€“92.

Lei Zheng, Vahid Noroozi, and Philip S Yu. 2017. Joint
deep modeling of users and items using reviews for
recommendation. In WSDM, pages 425â€“434. ACM.


