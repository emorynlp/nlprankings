










































IIIT-H: A Corpus-Driven Co-occurrence Based Probabilistic Model for Noun Compound Paraphrasing


Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 153‚Äì157, Atlanta, Georgia, June 14-15, 2013. c¬©2013 Association for Computational Linguistics

IIITH: A Corpus-Driven Co-occurrence Based Probabilistic Model for 

Noun Compound Paraphrasing  

 

Nitesh Surtani, Arpita Batra, Urmi Ghosh and Soma Paul 
Language Technologies Research Centre 

IIIT Hyderabad 

Hyderabad, Andhra Pradesh-500032 

{nitesh.surtaniug08, arpita.batra, urmi.ghosh}@students.iiit.ac.in, soma@iiit.ac.in 

  

Abstract 

This paper presents a system for automatically 

generating a set of plausible paraphrases for a 

given noun compound and rank them in de-

creasing order of their usage represented by 

the confidence value provided by the human 

annotators. Our system implements a corpus-

driven probabilistic co-occurrence based 

model for predicting the paraphrases, that uses 

a seed list of paraphrases extracted from cor-

pus to predict other paraphrases based on their 

co-occurrences. The corpus study reveals that 

the prepositional paraphrases for the noun 

compounds are quite frequent and well cov-

ered but the verb paraphrases, on the other 

hand, are scarce, revealing the unsuitability of 

the model for standalone corpus-driven ap-

proach. Therefore, to predict other paraphras-

es, we adopt a two-fold approach: (i) 

Prediction based on Verb-Verb co-

occurrences, in case the seed paraphrases are 

greater than threshold; and (ii) Prediction 

based on Semantic Relation of NC, otherwise. 

The system achieves a comparabale score of 

0.23 for the isomorphic system while main-

taining a score of 0.26 for the non-isomorphic 

system. 

1 Introduction 

Semeval 2013 Task 4 (Hendrickx et. al., 2013), 

‚ÄúFree Paraphrases of Noun Compounds‚Äù is a pa-

raphrase generation task that requires the system to 

generate multiple paraphrases for a given noun 

compound and rank them to the best approxima-

tion of the human rankings, represented by the cor-

responding confidence value. The task is an 

extension of Semeval 2010 Task 9 (Butnariu et al., 

2010), where the participants were asked to rank 

the set of given paraphrases for each noun com-

pound. Although the ranking task is quite distinct 

from the task of generating paraphrases, however, 

we have taken many insights from the systems de-

veloped for the ranking task, and have reported 

them appropriately in our system description. 

This paper describes a system for generating a 

ranked set of paraphrases for a given NC. A pa-

raphrase can be Prepositional, Verb or Verb + Pre-

positional. Since the prepositional paraphrases are 

easily available in the corpus while the occurrences 

of verb or verb+prep paraphrases is scarce, the task 

of paraphrasing becomes significant in finding out 

a method for predicting reliable paraphrases with 

verbs for a given NC. Our system implements a 

model that is based on co-occurrences of the pa-

raphrases and selects those paraphrases that have a 

higher probability of co-occurring with a set of 

extracted paraphrases which are referred to as Seed 

Paraphrases. Keeping the verb-paraphrase scarcity 

issue in mind, we develop a two-way model: (i) 

Model 1 is used when the seed paraphrases are 

considerable in number i.e., greater than the thre-

shold value. In this case, other verb paraphrases are 

predicted based on their co-occurrence with the set 

of extracted verb paraphrases. (ii) Model 2 is used 

when the size of the seed list falls below the thre-

shold value, in which case, we make use of the 

prepositional paraphrases to predict the relation of 

the noun compound and select verbs that mostly 

co-occur with that relation. Our system achieves an 

isomorphic score of 0.23 with a non-isomorphic of 

0.26 with the human generated paraphrases. The 

next section discusses the system.  

2 System Description 

This section of the paper describes each module of 

the system in detail. The first module of the system 

153



talks about the Seed data extraction using corpus 

search. The next module uses the seed data for 

predicting more verbs that would be used in pa-

raphrasing. The third module uses these predicted 

verbs in template generation for generating NC 

Paraphrasing and the generated paraphrases are 

ranked in the last module. 

2.1 Seed Data Extraction Module 

We have relied mostly on the Google N-gram Cor-

pus for extracting the seed paraphrases. Google has 

publicly released their web data as n-grams, also 

known as Web-1T corpus, via the Linguistic Data 

Consortium (Brants and Franz, 2006). It contains 

sequences of n-terms that occur more than 40 times 

on the web. Since the corpus consists of raw data 

from the web, certain pre-processing steps are es-

sential before it can be used. We extract a set of 

POS templates from the training data, and general-

ize them enough to accommodate the legitimate 

paraphrases extracted from the corpus. The follow-

ing templates are used for extracting n-gram data: 

Head-Mod N-gram: This template includes both 

the head and the modifier in the same regular ex-

pression. A corresponding 5-gram template for a 

NC Amateur-Championship is shown in Table 1. 

Head <*> <*> 

<*>Mod 
championship conducted for the 

amateurs 

Head <*><*>  

Mod <*> 
championship for all amateur 

players 

Head <*>Mod 

<*><*> 
championship where amateur is 

competing 

Table 1: Templates for paraphrase extraction 

The paraphrases obtained from the above template 

are quite useful, but scarce. To overcome the issue 

of coverage of verb paraphrases, a loosely coupled 

analysis and representation of compounds can be 

employed, as suggested by (Li et.al, 2010). We 

retrieve the partial triplets from the n-gram corpus 

in the form of ‚ÄúHead Para‚Äù and ‚ÄúPara Modifier‚Äù. 

 

 

 

Head Template: Head <*> <*> 

Mod Template: <*> <*> Mod; <*> Mod <*> 

But the process of generating paraphrases from 

head and the modifier n-gram incorporates a huge 

amount of noise and produces a lot of irrelevant 

paraphrases. Therefore, these partial paraphrases 

are not directly used for generating the paraphrases 

but are instead used to diagnose the compatibility 

of the selected verb with the head and the modifier 

of the given NC in Section 2.2.2. We also extract 

paraphrases from ANC and BNC corpus. 

2.2 Verb Prediction Module 

This module is the heart of our system. It imple-

ments two models for predicting the verb paraph-

rases: a Verb Co-occurrence model and a Relation 

Prediction model. The decision of selection of 

model for verb prediction is based on the size of 

the seed list. If the number of seed paraphrases is 

above the threshold value, the verb co-occurrence 

model is used whereas the relation prediction mod-

el is used if it is below the threshold value. 

2.2.1 Verb Co-occurrence Model 

This model uses the seed paraphrases extracted 

from the corpus to predict other verb paraphrases 

by computing their co-occurrences. The model 

gains insights from the UCD-PN system (Nulty 

and Costello, 2010) which tries to identify a more 

general paraphrase by computing the co-

occurrence of a paraphrase with other paraphrases. 

But the task of generating paraphrases has two sub-

tle but significant differences: (i) The list of seed 

verb paraphrases for a given NC is usually small, 

with each seed verb having a corresponding proba-

bility of occurrence; and (ii) Not all the seed verbs 

have legitimate representation of the noun com-

pound. Our system incorporates these distinctions 

in the co-occurrence model discussed below. 

Using the training data at hand, we build a Verb-

Verb co-occurrence matrix, a 2-D matrix where 

each cell (i,j) represents the probability of occur-

rence of Vj when Vi has already occurred.  

ùëÉ ùëâùëó  ùëâùëñ =
ùëÉ(ùëâùëñ ,ùëâùëó )

ùëÉ(ùëâùëñ)
=

ùê∂ùëúùë¢ùëõùë°(ùëâùëñ , ùëâùëó )

ùê∂ùëúùë¢ùëõùë°(ùëâùëñ)
 

The verbs used in co-occurrence matrix are stored 

in a List A. Now, for a given test NC, the model 

extracts the seed list of verb paraphrases (referred 

as List B) from the corpus with their corresponding 

probabilities. The above model calculates a score 

for each verb in List A, by computing its co-

occurrence with the verbs in List B. 

ùë†ùëêùëúùëüùëíùëé‚ààùê¥ ùëâùëé =   ùëÉ ùëâùëé  ùëâùëè ‚àó ùëÉ(ùëâùëè)

ùëè‚ààùêµ

 

(Head, Para, ?)  

(?, Para, Mod)  

(Head, Para, Mod)  

154



The term ùëÉ(ùëâùëè) in the above equation represents 
the relative occurrence of the verb ùëâùëè  with the giv-
en NC. The relevance of this term becomes evident 

in the next model. The verbs achieving higher 

score are selected, suggesting a higher probability 

of co-occurrence with the seed verbs.  

2.2.2 Semantic Relation Prediction Model 

This module describes the second model of the 

two-way model, and is used by the system when 

the verbs extracted from the corpus are less than 

the threshold. In this model, we use prepositional 

paraphrases, having a pretty good coverage in the 

corpus, to predict the semantic relation of the com-

pound which helps us in predicting the other pa-

raphrases. The intuition behind using semantic 

class for predicting paraphrases is that they tend to 

capture the behavior of the noun compound and 

can be represented by general paraphrases.  

Noun Compound Relation Paraphrase Sel. 

Prep Verb 

Garden Party Location In, At Held 

Community Life Theme Of, In Made 

Advertising Agency Purpose For, Of, In Doing 

Table 2: Occurrence of Prepositional Paraphrases 

Relation Annotation: Since a supervised ap-

proach is used for identifying the semantic relation 

of the noun compound, we manually annotate the 

noun compounds with a semantic relation. We tag 

each noun compound with one semantic relation 

from the set used in (Moldovan et. al. 2004).  

Prep-Rel and Verb-Rel Co-occurrence: A Prep-

Rel co-occurrence matrix similar to Verb-Verb co-

occurrence matrix discussed in last subsection. 

This 2-D matrix consists of co-occurrence proba-

bilities between the prepositional paraphrases and 

the semantic relation of the compound, where each 

cell (i,j) represents the probability of occurrence of 

preposition Pj with relation Ri. This matrix is used 

as a model to identify semantic relation using pre-

positional paraphrases extracted from the corpus. 

The Verb-Relation co-occurrence matrix is used to 

predict the most co-occurring verbs with the identi-

fied relation. Each cell (i,j) in the matrix represents 

the probability of the verb Vj co-occurring with 

relation Ri. 

Relation Extraction: Research focusing on se-

mantic relation extraction has followed two direc-

tions: (i) Statistical approaches to using very large 

corpus (Berland and Charniak (1999); Hearst 

(1998)); and (ii) Ontology based approaches using 

hierarchical structure of wordnet (Moldovan et. al., 

2004). We employ a statistical model based on the 

Preposition-Relation co-occurrence for identifying 

the relation. The model is quite similar to the one 

used in Section 2.2, but it is here that the model 

reveals its actual power. Since two or more rela-

tions can be represented by same set of preposi-

tional paraphrases, as Theme and Purpose in Table 

2, it is important to take into account the probabili-

ties with which the extracted prepositions occur in 

the corpus. In Table 2, the NC Community Life 

(Theme) occurs frequently with preposition ‚Äûof‚Äü 

whereas the NC Advertising Agency (Purpose) is 

mostly represented by preposition ‚Äûfor‚Äü in the cor-

pus. The term ùëÉ(ùëÉùëù) in the equation below cap-

tures this phenomenon and classifies these two 

NCs in their respective classes. 

ùë†ùëêùëúùëüùëíùëü‚ààùëÖ ùëü =   ùëÉ ùëü ùëÉùëù ‚àó ùëÉ(ùëÉùëù)

ùëù‚ààùëÉ

 

The relation with the highest score is selected as 

the semantic class of the noun compound. A set of 

verbs highly co-occurring with that class are se-

lected, and their compatibility with the correspond-

ing noun compound is judged from their 

occurrences with the partial head and the modifier 

paraphrases as discussed in Section 2.1. The above 

classifier performs moderately and classifies a giv-

en NC with 42.5% accuracy. We have also tried 

the Wordnet based Semantic Scattering model 

(Moldovan et. al., 2004), trained on a set of 400 

instances, but achieved an accuracy of 38%, the 

reason for which can be attributed to the small 

training set. Since the accuracy of identifying the 

correct relation is low, we select some paraphrases 

from the 2
nd

 most probable relation, as assigned by 

the probabilistic classifier.  

2.3 Paraphrase Generator Module  

After predicting a set of verb for a test noun com-

pound, we use the following templates to generate 

the paraphrases: 

a) Head VP Mod 
b) Head VP PP Mod 
c) Head [that|which] VP PP Mod 

The paraphrases that are extracted from the corpus 

are also cleaned using the POS templates extracted 

from the training data. 

155



2.4 Paraphrase Ranker Module  

Motivated by the observations from Nulty and 

Costello (2010) that ‚Äúpeople tend to use general, 

semantically light paraphrases more often than de-

tailed, semantically heavy ones‚Äù, we perform rank-

ing of the paraphrases in two steps: (i) Assigning 

different weights to different type of paraphrases, 

i.e. a light weight prepositional paraphrases achiev-

ing higher score than the verb paraphrases; and (ii) 

Ranking a more general paraphrase with the same 

category higher. A paraphrase A is more general 

that paraphrase B (Nulty and Costello, 2010) if 

ùëÉ ùê¥|ùêµ > ùëÉ(ùêµ|ùê¥) 

For a list of paraphrases A generated for a given 

compound, each paraphrase b in that list is scored 

using the below eq., where more general paraph-

rase achieves a high score and is ranked higher. 

ùë†ùëêùëúùëüùëí ùëè =   ùëÉ ùëè ùëé 

ùëé‚ààùê¥

 

The seed paraphrases extracted from the corpus are 

ranked higher than the predicted paraphrases. 

3 Algorithm  

This section presents the implementation of the 

overall system.  

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 
 

 

 

 

 

 

 

 

 

 

 

4 Results 

The set of generated paraphrases are evaluated on 

two metrics: a) Isomorphic; b) Non-isomorphic. In 

the isomorphic setting, the test paraphrase is 

matched to the closest reference paraphrases, but 

the reference paraphrase is removed from the set 

whereas in non-isomorphic setting, the reference 

paraphrase which is mapped to a test paraphrase 

can still be used for matching other test paraphras-

es. Table 3 presents the scores of the 3 participat-

ing teams who have submitted total of 4 systems.  

Systems Isomorphic Non-Isomorphic 

SFS 0.2313 0.1794 

IIITH 0.2309 0.2583 

MELODI-Pri 0.1298 0.5484 

MELODI-Cont 0.1357 0.536 
Table 3: Results of the submitted systems 

Our system achieves an isomorphic score of 0.23, 

just below the SFS system maintaining a score of 

0.26 for the non-isomorphic system. The two va-

riants of MELODI system get a high score for the 

non-isomorphic metric but low scores for isomor-

phic metric as compared to other systems. 

5 Conclusion 

We have described a system for automatically ge-

nerating a set of paraphrases for a given noun 

compound, based on the co-occurrences of the pa-

raphrases. The system describes an approach for 

handling those 38% cases (calculated for optimum 

threshold value) of NCs where it is not convenient 

to predict the verbs using their co-occurrences with 

the seed verbs, because the size of the seed list is 

below a threshold value. For other cases, the verb 

co-occurrence model is used to predict the verbs 

for NC paraphrasing. The optimum value of thre-

shold parameter investigated from experiments is 

found to be 3, showing that atleast 3 verb paraph-

rases are necessary to capture the concept of a NC. 

// Training Phase ‚Äì Build Co-occurrence Matrices 

Verb_Co-occur = 2-D Matrix  

Prep-Rel_Co-occur = 2-D Matrix  

Verb-Rel_Co-occur = 2-D Matrix  

Verb_List = Verb List extracted from training corpus 

// Testing ‚Äì Extract paraphrases with probabilities 

Ext_Verb = List of extracted verb paraphrase  

VProb = Probability of each Ext_Verb 

Ext_Prep = List of extracted prepositional paraphrases 

PProb = Probability of each Ext_Prep 

Prob_Verb = List // Verbs with their selection score 

Prob_Rel = List // Relations with their selection score 

Threshold = 3 // Verb threshold for two-way model 

if count( Ext_Verb ) > Threshold  

    Candidate_Verbs = {Verb_List } - { Ext_Verbs }      

    foreach Candidate_Verbs Vi : 

        Prob_Verb[Vi] = 0 

        foreach Ext_Verb Vj : 

            Prob_Verb[Vi] += Verb_Co-occur [Vi][Vj] *   

   VProb[Vj] 

else       

    foreach Prep-Rel_Co-occur as rel : 

        Prob_Rel[rel] = 0 

             

            

       foreach Ext_Prep as prep : 

           Prob_Rel[rel] += Prep-Rel_Co-occur[rel][prep]

              * PProb[prep]              

           Rel=select highestProb(Prob_Rel) 

           Prob_Verb = Verb-Rel_Co-occur[Rel] 

sort(Prob_Verb)  

Verb_Predicted = select top(N)   

Paraphrase = generate_paraphrase(verb_predicted) 

rank(Paraphrase) 

156



References  

Matthew Berland and Eugene Charniak. 1999. Finding 

parts in very large. In Proceeding of ACL 1999 

T. Brants and A. Franz. 2006. Web 1T 5-gram Version1. 

Linguistic Data Consortium 

Cristina Butnariu, Su Nam Kim, Preslav Nakov, Di-

armuid O S¬¥ eaghdha, Stan Szpakowicz, and Tony-

Veale. 2010. Semeval-2 task 9: The interpreta-tion of 

noun compounds using paraphrasing verbs and pre-

positions. In Proceedings of the 5th SIGLEX Work-

shop on Semantic Evaluation 

Cristina Butnariu, Su Nam Kim, Preslav Nakov, Di-

armuid O S¬¥eaghdha, Stan Szpakowicz, and Tony-

Veale. 2013. Semeval‚Äô13 task 4: Free Paraphrases of 

Noun Compounds. In Proceedings of the Internation-

al Workshop on Semantic Evaluation, Atlanta, Geor-

gia 

Marti Hearst. 1998. Automated Discovery of Word-Net 

relations. In An Electronic Lexical Database and-

Some of its Applications. MIT Press, Cambridge MA 

Mark Lauer. 1995. Designing Statistical Language-

Learners: Experiments on Noun Compounds. Ph.D. 

Thesis, Macquarie University 

Guofu Li, Alejandra Lopez-Fernandez and Tony Veale. 

2010. UCD-Goggle: A Hybrid System for Noun 

Compound Paraphrasing. In Proceedings of the 5th 

International Workshop on Semantic Evaluation 

(SemEval-2), Uppsala, Sweden 

Dan Moldovan, Adriana Badulescu, Marta Tatu, Daniel 

Antohe, and Roxana Girju. 2004. Models for the Se-

mantic Classification of Noun Phrases. In Proceed-

ings of the HLT-NAACL-04 Workshop on 

Computational Lexical Semantics, pages 60‚Äì67, Bos-

ton, MA 

Paul Nulty and Fintan Costello. 2010. UCD-PN: Select-

ing general paraphrases using conditional probabili-

ty. In Proceedings of the 5th International Workshop 

on Semantic Evaluation (SemEval-2), Uppsala, Swe-

den 

 

157


