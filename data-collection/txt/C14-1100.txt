



















































Automatic Classification of Communicative Functions of Definiteness


Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1059–1070, Dublin, Ireland, August 23-29 2014.

Automatic Classification of Communicative Functions of Definiteness

Archna Bhatia∗,‡ Chu-Cheng Lin∗ Nathan Schneider∗ Yulia Tsvetkov∗
Fatima Talib Al-Raisi∗ Laleh Roostapour∗ Jordan Bender† Abhimanu Kumar∗

Lori Levin∗ Mandy Simons∗ Chris Dyer∗
∗Carnegie Mellon University †University of Pittsburgh

Pittsburgh, PA 15213 Pittsburgh, PA 15260
‡archnab@cs.cmu.edu

Abstract

Definiteness expresses a constellation of semantic, pragmatic, and discourse properties—the
communicative functions—of an NP. We present a supervised classifier for English NPs that
uses lexical, morphological, and syntactic features to predict an NP’s communicative function in
terms of a language-universal classification scheme. Our classifiers establish strong baselines for
future work in this neglected area of computational semantic analysis. In addition, analysis of
the features and learned parameters in the model provides insight into the grammaticalization of
definiteness in English, not all of which is obvious a priori.

1 Introduction

Definiteness is a morphosyntactic property of noun phrases (NPs) associated with semantic and pragmatic
characteristics of entities and their discourse status. Lyons (1999), for example, argues that definite
markers prototypically reflect identifiability (whether a referent for the NP can be identified by the
discourse participants or not); other aspects identified in the literature include uniqueness of the entity
in the world and whether the hearer is already familiar with the entity given the context and preceding
discourse (Roberts, 2003; Abbott, 2006). While some morphosyntactic forms of definiteness are employed
by all languages—namely, demonstratives, personal pronouns, and possessives—languages display a vast
range of variation with respect to the form and meaning of definiteness. For example, while languages
like English make use of definite and indefinite articles to distinguish between the discourse status of
various entities (the car vs. a car vs. cars), many other languages—including Czech, Indonesian, and
Russian—do not have articles (although they do have demonstrative determiners). Sometimes definiteness
is marked with affixes or clitics, as in Arabic. Sometimes it is expressed with other constructions, as in
Chinese (a language without articles), where the existential construction can be used to express indefinite
subjects and the ba- construction can be used to express definite direct objects (Chen, 2004).

Aside from this variation in the form of (in)definite NPs within and across languages, there is also vari-
ability in the mapping between semantic, pragmatic, and discourse functions of NPs and the (in)definites
expressing these functions. We refer to these as communicative functions of definiteness, following
Bhatia et al. (2014). Croft (2003, pp. 6–7) shows that even when two languages have access to the
same morphosyntactic forms of definiteness, the conditions under which an NP is marked as definite
or indefinite (or not at all) are language-specific. He illustrates this by contrasting English and French
translations (both languages use definite as well as indefinite articles) such as:

(1) He showed extreme care. (unmarked)
Il montra un soin extrême. (indef.)

(2) I love artichokes and asparagus. (unmarked)
J’aime les artichauts et les asperges. (def.)

(3) His brother became a soldier. (indef.)
Son frère est devenu soldat. (unmarked)

This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings
footer are added by the organisers. License details: http://creativecommons.org/licenses/by/4.0/

1059



• NONANAPHORA [−A,−B] 999
– UNIQUE [+U] 287

* UNIQUE_HEARER_OLD [+F,−G,+S] 251
· UNIQUE_PHYSICAL_COPRESENCE [+R] 13
· UNIQUE_LARGER_SITUATION [+R] 237
· UNIQUE_PREDICATIVE_IDENTITY [+P] 1

* UNIQUE_HEARER_NEW [−F] 36
– NONUNIQUE [−U] 581

* NONUNIQUE_HEARER_OLD [+F] 169
· NONUNIQUE_PHYSICAL_COPRESENCE [−G,+R,+S] 39
· NONUNIQUE_LARGER_SITUATION [−G,+R,+S] 117
· NONUNIQUE_PREDICATIVE_IDENTITY [+P] 13

* NONUNIQUE_HEARER_NEW_SPEC [−F,−G,+R,+S] 231
* NONUNIQUE_NONSPEC [−G,−S] 181

– GENERIC [+G,−R] 131
* GENERIC_KIND_LEVEL 0
* GENERIC_INDIVIDUAL_LEVEL 131

• ANAPHORA [+A] 1574
– BASIC_ANAPHORA [−B,+F] 795

* SAME_HEAD 556
* DIFFERENT_HEAD 329

– EXTENDED_ANAPHORA [+B] 779
* BRIDGING_NOMINAL [−G,+R,+S] 43
* BRIDGING_EVENT [+R,+S] 10
* BRIDGING_RESTRICTIVE_MODIFIER [−G,+S] 614
* BRIDGING_SUBTYPE_INSTANCE [−G] 0
* BRIDGING_OTHER_CONTEXT [+F] 112

• MISCELLANEOUS [−R] 732
– PLEONASTIC [−B,−P] 53
– QUANTIFIED 248
– PREDICATIVE_EQUATIVE_ROLE [−B,+P] 58
– PART_OF_NONCOMPOSITIONAL_MWE 100
– MEASURE_NONREFERENTIAL 125
– OTHER_NONREFERENTIAL 148

+ − 0 + − 0 + − 0 + − 0
Anaphoric 1574 999 732 Generic 131 1476 1698 Predicative 72 53 3180 Specific 1305 181 1819

Bridging 779 1905 621 Familiar 1327 267 1711 Referential 690 863 1752 Unique 287 581 2437

Figure 1: CFD (Communicative Functions of Definiteness) annotation scheme, with frequencies in the
corpus. Internal (non-leaf) labels are in bold; these are not annotated or predicted. +/− values are shown
for ternary attributes Anaphoric, Bridging, Familiar, Generic, Predicative, Referential, Specific, and
Unique; these are inherited from supercategories, but otherwise default to 0. Thus, for example, the
full attribute specification for UNIQUE_PHYSICAL_COPRESENCE is [−A,−B,+F,−G,0P,+R,+S,+U].
Counts for these attributes are shown in the table at bottom.

A cross-linguistic classification of communicative functions should be able to characterize the aspects
of meaning that account for the different patterns of definiteness marking exhibited in (1–3): e.g., that
(2) concerns a generic class of entities while (3) concerns a role filled by an individual. For more on
communicative functions, see §2.

This paper develops supervised classifiers to predict communicative function labels for English NPs
using lexical, morphological, and syntactic features. The contribution of our work is in both the output of
the classifiers and the models themselves (features and weights). Each classifier predicts communicative
function labels that capture aspects of discourse-newness, uniqueness, specificity, and so forth. Such
functions are useful in a variety of language processing applications. For example, they should usually be
preserved in translation, even when the grammatical mechanisms for expressing them are different. The
communicative function labels also represent the discourse status of entities, making them relevant for
entity tracking, knowledge base construction, and information extraction.

Our log-linear model is a form-meaning mapping that relates syntactic, lexical, and morphological
features to properties of communicative functions. The learned weights of this model can, e.g., gener-
ate plausible hypotheses regarding the form-meaning relationship which can then be tested rigorously
through controlled experiments. This hypothesis generation is linguistically significant as it indicates new
grammatical mechanisms beyond the obvious a and the articles that are used for expressing definiteness
in English.

To build our models, we leverage a cross-lingual definiteness annotation scheme (§2) and annotated
English corpus (§3) developed in prior work (Bhatia et al., 2014). The classifiers, §4, are supervised
models with features that combine lexical and morphosyntactic information and the prespecified attributes
or groupings of the communicative function labels (such as Anaphoric, Bridging, Specific in fig. 1) to
predict leaf labels (the non-bold faced labels in fig. 1); the evaluation measures (§5) include one that
exploits these label groupings to award partial credit according to relatedness. §6 presents experiments
comparing several models and discussing their strengths and weaknesses; computational work and
applications related to definiteness are addressed in §7.

1060



2 Annotation scheme

The literature on definiteness describes functions such as uniqueness, familiarity, identifiability, anaphoric-
ity, specificity, and referentiality (Birner and Ward, 1994; Condoravdi, 1992; Evans, 1977, 1980; Gundel
et al., 1988, 1993; Heim, 1990; Kadmon, 1987, 1990; Lyons, 1999; Prince, 1992; Roberts, 2003; Russell,
1905, inter alia) as being related to definiteness. Reductionist approaches to definiteness try to define
it in terms of one or two of the aforementioned communicative functions. For example, Roberts (2003)
proposes that the combination of uniqueness and a presupposition of familiarity underlie all definite
descriptions. However, possessive definite descriptions (John’s daughter) and the weak definites (the son
of Queen Juliana of the Netherlands) are neither unique nor necessarily familiar to the listener before they
are spoken. In contrast to the reductionist approaches are approaches to grammaticalization (Hopper and
Traugott, 2003) in which grammar develops over time in such a way that each grammatical construction
has some prototypical communicative functions, but may also have many non-prototypical communica-
tive functions. The scheme we are adopting for this work—the annotation scheme for Communicative
Functions of Definiteness (CFD) as described in Bhatia et al. (2014)—assumes that there may be multiple
functions to definiteness. CFD is based on a combination of these functions and is summarized in fig. 1. It
was developed by annotating texts in two languages (English and Hindi) for four different genres—namely
TED talks, a presidential inaugural speech, news articles, and fictional narratives—keeping in mind the
communicative functions that have been associated with definiteness in the linguistic literature.

CFD is hierarchically organized. This hierarchical organization serves to reduce the number of decisions
that an annotator needs to make for speed and consistency. We now highlight some of the major distinctions
in the hierarchy.

At the highest level, the distinction is made between Anaphora, Nonanaphora, and Miscellaneous
functions of an NP (the annotatable unit). Anaphora and Nonanaphora respectively describe whether
an entity is old or new in the discourse; the Miscellaneous function is mainly assigned to various kinds of
nonreferential NPs.

The Anaphora category has two subcategories: Basic_Anaphora and Extended_Anaphora. Ba-
sic_Anaphora applies to NPs referring to entities that have been mentioned before. Extended_Anaphora
applies to any NP whose referent has not been mentioned itself, but is evoked by a previously mentioned
entity. For example, after mentioning a wedding, the bride, the groom, and the cake are considered to be
Extended_Anaphora.

Within the Nonanaphora category, a first distinction is made between Unique, Nonunique, and
Generic. The Unique function applies to NPs whose referent becomes unique in a context for any of
several reasons. For example, Obama can safely be considered unique in contemporary political discourse
in the United States. The function Nonunique applies to NPs that start out with multiple possible referents
and that may or may not become identifiable in a speech situation. For example, a little riding hood of
red velvet in fig. 2 could be annotated with the label Nonunique. Finally, Generic NPs refer to classes
or types of entities rather than specific entities. For example, Dinosaurs in Dinosaurs are extinct. is a
Generic NP.

Another important distinction CFD makes is between Hearer_Old for references to entities that are
familiar to the hearer (e.g., if they are physically present in the speech situation), versus Hearer_New
for nonfamiliar references. This distinction cuts across the two subparts of the hierarchy, Anaphora
and Nonanaphora; thus, labels marking Hearer_Old or Hearer_New also encode other distinctions
(e.g., Unique_Hearer_Old, Unique_Hearer_New, Nonunique_Hearer_Old). For further details on
the annotation scheme, see fig. 1 and Bhatia et al. (2014).

Because the ordering of distinctions determines the tree structure of the hierarchy, the same commu-
nicative functions could have been organized in a superficially different way. In fact, Komen (2013) has
proposed a hierarchy with similar leaf nodes, but different internal structure. Since it is possible that
some natural groupings of labels are not reflected in the hierarchy we used, we also decompose each
label into fundamental communicative functions, which we call attributes. Each label type is associated
with values for attributes Anaphoric, Bridging, Familiar, Generic, Predicative, Referential, Specific, and
Unique. These attributes can have values of +, −, or 0, as shown in fig. 1. For instance, with the Anaphoric

1061



Once upon a time there was a dear little girl who was loved by everyone who looked at her, but most of all by her grandmother,
and there was nothing that she would not have given to the child.

Once she
SAME_HEAD

gave her
DIFFERENT_HEAD

a little riding hood of red velvet
OTHER_NONREFERENTIAL

NONUNIQUE_HEARER_NEW_SPEC

, which suited her
SAME_HEAD

so well that

she
SAME_HEAD

would never wear anything else
QUANTIFIED

; so she
SAME_HEAD

was always called ‘Little Red Riding Hood
UNIQUE_HEARER_NEW

.’

Figure 2: An annotated sentence from “Little Red Riding Hood.” The previous sentence is shown for
context.

attribute, a value of + applies to labels that can never mark NPs new to the discourse, − applies to labels
that can only apply if the NP is new in the discourse, and 0 applies to labels such as Pleonastic (where
anaphoricity is not applicable because there is no discourse referent).

3 Data

We use the English definiteness corpus of Bhatia et al. (2014), which consists of texts from multiple genres
annotated with the scheme described in §2.1 The 17 documents consist of prepared speeches (TED talks
and a presidential address), published news articles, and fictional narratives. The TED data predominates
(75% of the corpus);2 the presidential speech represents about 16%, fictional narratives 5%, and news
articles 4%. All told, the corpus contains 13,860 words (868 sentences), with 3,422 NPs (the annotatable
units). Bhatia et al. (2014) report high inter-annotator agreement, estimating Cohen’s κ = 0.89 within the
TED genre as well as for all genres.

Figure 2 is an excerpt from the “Little Red Riding Hood” annotated with the CFD scheme.

4 Classification framework

To model the relationship between the grammar of definiteness and its communicative functions in a
data-driven fashion, we work within the supervised framework of feature-rich discriminative classification,
treating the functional categories from §2 as output labels y and various lexical, morphological, and
syntactic characteristics of the language as features of the input x. Specifically, we learn two kinds
of probabilistic models. The first is a log-linear model similar to multiclass logistic regression, but
deviating in that logistic regression treats each output label (response) as atomic, whereas we decompose
each into attributes based on their linguistic definitions, enabling commonalities between related labels
to be recognized. Each weight in the model corresponds to a feature that mediates between percepts
(characteristics of the input NP) and attributes (characteristics of the label). This is aimed at attaining
better predictive accuracy as well as feature weights that better describe the form–function interactions we
are interested in recovering. We also train a random forest model on the hypothesis that it would allow us
to sacrifice interpretability of the learned parameters for predictive accuracy.

Our setup is formalized below, where we discuss the mathematical models and linguistically motivated
features.

4.1 Models

We experiment with two classification methods: a log-linear model and a nonlinear tree-based ensemble
model. Due to their consistency and interpretability, linear models are a valuable tool for quantifying and
analyzing the effects of individual features. Non-linear models, while less interpretable, often outperform
logistic regression (Perlich et al., 2003), and thus could be desirable when the predictions are needed for a
downstream task.

1The data can be obtained from http://www.cs.cmu.edu/~ytsvetko/definiteness_corpus.
2The TED talks are from a large parallel corpus obtained from http://www.ted.com/talks/.

1062



4.1.1 Log-linear model
At test time, we model the probability of communicative function label y conditional on an NP x as
follows:

pθθθ(y∣x) = log
expθθθ⊺f(x,y)

∑y′∈Y expθθθ
⊺f(x,y′)

(1)

where θθθ ∈Rd is a vector of parameters (feature weights), and f ∶X ×Y →Rd is the feature function over
input–label pairs. The feature function is defined as follows:

f(x,y) = φφφ(x)× ω̃ωω(y) (2)

where the percept function φφφ ∶X →Rc produces a vector of real-valued characteristics of the input, and
the attribute function ω̃ωω ∶Y → {0,1}a encodes characteristics of each label. There is a feature for every
percept–attribute pairing: so d = c ⋅a and f(i−1)a+ j(x,y) = φi(x)ω̃ j(y),1 ≤ i ≤ c,1 ≤ j ≤ a.3 The contents of
the percept and attribute functions are detailed in §4.2 and §4.3 respectively.

For prediction, having learned weights θ̂θθ we use the Bayes-optimal decision rule for minimizing
misclassification error, selecting the y that maximizes this probability:

ŷ← argmax
y∈Y

pθ̂θθ(y∣x) (3)

Training optimizes θ̂θθ so as to maximize a convex L2-regularized4 learning objective over the training data
D:

θ̂θθ = argmax
θθθ

−λ ∣∣θθθ ∣∣22+ ∑
⟨x,y⟩∈D

log
expθθθ⊺f(x,y)

∑y′∈Y exp(θθθ
⊺f(x,y′))

(4)

With ω̃ωω(y) = the identity of the label, this reduces to standard logistic regression.

4.1.2 Non-linear model
We employ a random forest classifier (Breiman, 2001), an ensemble of decision tree classifiers learned
from many independent subsamples of the training data. Given an input, each tree classifier assigns a
probability to each label; those probabilities are averaged to compute the probability distribution across
the ensemble.

An important property of the random forests, in addition to being an effective tool in prediction, is
their immunity to overfitting: as the number of trees increases, they produce a limiting value of the
generalization error.5 Thus, no hyperparameter tuning is required. Random forests are known to be
robust to sparse data and to label imbalance (Chen et al., 2004), both of which are challenges with the
definiteness dataset.

4.2 Percepts
The characteristics of the input that are incorporated in the model, which we call percepts to distinguish
them from model features linking inputs to outputs, see §4.1, are intended to capture the aspects of English
morphosyntax that may be relevant to the communicative functions of definiteness.

After preprocessing the text with a dependency parser and coreference resolver, which is described in
§6.1, we extract several kinds of percepts for each NP.

4.2.1 Basic
Words of interest. These are the head within the NP, all of its dependents, and its governor (external to
the NP). We are also interested in the attached verb, which is the first verb one encounters when traversing
the dependency path upward from the head. For each of these words, we have separate percepts capturing:
the token, the part-of-speech (POS) tag, the lemma, the dependency relation, and (for the head only) a

3Chahuneau et al. (2013) use a similar parametrization for their model of morphological inflection.
4As is standard practice with these models, bias parameters (which capture the overall frequency of percepts/attributes) are

excluded from regularization.
5See Theorem 1.2 in Breiman (2001) for details.

1063



binary indicator of plurality (determined from the POS tag). As there may be multiple dependents, we
have additional features specific to the first and the last one. Moreover, to better capture tense, aspect
and modality, we collect the attached verb’s auxiliaries. We also make note of the negative particle (with
dependency label neg) if it is a dependent of the verb.
Structural. The structural percepts are: the path length from the head up to the root, and to the attached
verb. We also have percepts for the number of dependents, and the number of dependency relations that
link non-neighbors. Integer values were binarized with thresholding.
Positional. These percepts are the token length of the NP, the NP’s location in the sentence (first or
second half), and the attached verb’s position relative to the head (left or right). 12 additional percept
templates record the POS and lemma of the left and right neighbors of the head, governor, and attached
verb.

4.2.2 Contextual NPs
When extracting features for a given NP (call it the “target”), we also consider NPs in the following
relationship with the target NP: its immediate parent, which is the smallest NP whose span fully subsumes
that of the target; the immediate child, which is the largest NP subsumed within the target; the immediate
precedent and immediate successor within the sentence; and the nearest preceding coreferent mention.

For each of these related NPs, we include all of their basic percepts conjoined with the nature of the
relation to the target.

4.3 Attributes
As noted above, though CFD labels are organized into a tree hierarchy, there are actually several dimensions
of commonality that suggest different groupings. These attributes are encoded as ternary characteristics;
for each label (including internal labels), every one of the 8 attributes is assigned a value of +, −, or 0
(refer to fig. 1). In light of sparse data, we design features to exploit these similarities via the attribute
vector function

ωωω(y) = [y,A(y),B(y),F(y),G(y),P(y),R(y),S(y),U(y)]⊺ (5)

where A ∶Y → {+,−,0} returns the value for Anaphoric, B(y) for Bridging, etc. The identity of the label
is also included in the vector so that different labels are always recognized as different by the attribute
function. The categorical components of this vector are then binarized to form ω̃ωω(y); however, instead
of a binary component that fires for the 0 value of each ternary attribute, there is a component that fires
for any value of the attribute—a sort of bias term. The weights assigned to features incorporating + or −
attribute values, then, are easily interpreted as deviations relative to the bias.

5 Evaluation

The following measures are used to evaluate our predictor against the gold standard for the held-out
evaluation (dev or test) set E :
• Exact Match: This accuracy measure gives credit only where the predicted and gold labels are identical.
• By leaf label: We also compute precision and recall of each leaf label to determine which categories

are reliably predicted.
• Soft Match: This accuracy measure gives partial credit where the predicted and gold labels are

related. It is computed as the proportion of attributes-plus-full-label whose (categorical) values match:
∣ωωω(y)∩ωωω(y′)∣/9.

6 Experiments

6.1 Experimental Setup
Data splits. The annotated corpus of Bhatia et al. (2014) (§3) contains 17 documents in 3 genres:
13 prepared speeches (mostly TED talks),6 2 newspaper articles, and 2 fictional narratives. We arbitrarily
choose some documents to hold out from each genre; the resulting test set consists of 2 TED talks

6We have combined the TED talks and presidential speech genres since both involved prepared speeches.

1064



Condition ∣θθθ ∣ λ Exact Match Acc. Soft Match Acc.
Majority baseline — — 12.1 47.8
Log-linear classifier, attributes only 473,064 100 38.7 77.1
Log-linear classifier, labels only 413,931 100 40.8 73.6
Full log-linear classifier (labels + attributes) 926,417 100 43.7 78.2
Random forest classifier 20,363 — 49.7 77.5

Table 1: Classifiers and baseline, as measured on the test set. The first two columns give the number of
parameters and the tuned regularization hyperparameter, respectively; the third and fourth columns give
accuracies as percentages. The best in each column is bolded.

(“Alisa_News”, “RobertHammond_park”), 1 newspaper article (“crime1_iPad_E”), and 1 narrative
(“Little Red Riding Hood”). The test set then contains 19,28 tokens (111 sentences), in which there are
511 annotated NPs; while the training set contains 2,911 NPs among 11,932 tokens (757 sentences).

Preprocessing. Automatic dependency parses and coreference information were obtained with the
parser and coreference resolution system in Stanford CoreNLP v. 3.3.0 (Socher et al., 2013; Recasens
et al., 2013) for use in features (§4.2). Syntactic features were extracted from the Basic dependencies
output by the parser. To evaluate the performance of Stanford system on our data, we manually inspected
the dependencies and coreference information for a subset of sentences from our corpus (using texts
from TED talks and fictional narratives genres) and recorded the errors. We found that about 70% of the
sentences had all correct dependencies, and only about 0.04% of the total dependencies were incorrect
for our data. However, only 62.5% of the coreference links were correctly identified by the coreference
resolver. The rest of them were either missing or incorrectly identified. We believe this may have caused a
portion of the classifier errors while predicting the Ananphoic labels.

Throughout our experiments (training as well as testing), we use the gold NP boundaries identified by
the human annotators. The automatic dependency parses are used to extract percepts for each gold NP.
If there is a conflict between the gold NP boundaries and the parsed NP boundaries, to avoid extracting
misleading percepts, we assign a default value.

Learning. The log-linear model variants are trained with an in-house implementation of supervised
learning with L2-regularized AdaGrad (Duchi et al., 2011). Hyperparameters are tuned on a development
set formed by holding out every tenth instance from the training set (test set experiments use the full
training set): the power of 10 giving the highest Soft Match accuracy was chosen for λ .7 The Python
scikit-learn toolkit (Pedregosa et al., 2011) was used for the random forest classifier.8

6.2 Results

Measurements of overall classification performance appear in table 1. While far from perfect, our
classifiers achieve promising accuracy levels given the small size of the training data and the number of
labels in the annotation scheme. The random forest classifier is the most accurate in Exact Match, likely
due to the robustness of that technique under conditions where the data are small and the frequencies
of individual labels are imbalanced. By the Soft Match measure, our attribute-aware log-linear models
perform very well. The most successful of the log-linear models is the richest model, which combines the
fine-grained communicative function labels with higher-level attributes of those labels. But notably the
attribute-only model, which decomposes the semantic labels into attributes without directly considering
the full label, performs almost as well as the random forest classifier in Soft Match. This is encouraging
because it suggests that the model has correctly exploited known linguistic generalizations to account for
the grammaticalization of definiteness in English.

Table 2 reports the precision and recall of each leaf label predicted. Certain leaf labels are found
to be easier for the classifier to predict: e.g., the communicative function label Pleonastic has a high
F1 score. This is expected as the Ploenastic CFD for English is quite regular and captured by the EX

7Preliminary experiments with cross-validation on the training data showed that the value of λ was stable across folds.
8Because it is a randomized algorithm, the results may vary slightly between runs; however, a cross-validation experiment on

the training data found very little variance in accuracy.

1065



Leaf label N P R F1 Leaf label N P R F1
Pleonastic 44 100 78 88 Part_of_Noncompositional_MWE 88 20 17 18
Bridging_Restrictive_Modifier 552 58 84 68 Bridging_Nominal 33 33 10 15
Quantified 213 57 57 57 Generic_Individual_Level 113 14 11 13
Unique_Larger_Situation 97 52 58 55 Nonunique_Nonspec 173 9 25 13
Same_Head 452 41 41 41 Bridging_Other_Context 96 33 6 11
Measure_Nonreferential 98 88 26 40 Bridging_Event 9 — 0 —
Nonunique_Hearer_New_Spec 190 36 46 40 Nonunique_Physical_Copresence 36 0 0 —
Other_Nonreferential 134 39 36 37 Nonunique_Predicative_Identity 10 — 0 —
Different_Head 271 32 33 32 Predicative_Nonidentity 57 0 0 —
Nonunique_Larger_Situation 97 29 25 27 Unique_Hearer_New 26 — 0 —

Table 2: Number of training set instances and precision, recall, and F1 percentages for leaf labels.

part-of-speech tag. The classifier finds predictions of certain CFD labels, such as Bridging_Event,
Bridging_Nominal and Nonunique_Nonspecific, to be more difficult due to data sparseness: it appears
that there were not enough training instances for the classifier to learn the generalizations corresponding
to these CFDs. Bridging_Other_Context was hard to predict as this was a category which referred not
to the entities previously mentioned but to the whole speech event from the past. There seem to be no
clear morphosyntactic cues associated with this CFD, so to train a classifier to predict this category label,
we would need to model more complex semantic and discourse information. This also applies to the
classifier confusion between the Same_Head and Different_Head, since both of these labels share all
the semantic attributes used in this study.

An advantage of log-linear models is that inspecting the learned feature weights can provide useful
insights into the model’s behavior. Figure 3 lists 10 features that received the highest positive weights
in the full model for the + and − values of the Specific attribute. These confirm some known properties
of English definites and indefinites. The definite article, possessives (PRP$), proper nouns (NNP), and the
second person pronoun are all associated with specific NPs, while the indefinite article is associated with
nonspecific NPs. The model also seems to have picked up on the less obvious but well-attested tendency
of objects to be nonspecific (Aissen, 2003).

In addition to confirming known grammaticalization patterns of definiteness, we can mine the highly-
weighted features for new hypotheses: e.g., in figs. 3 and 4, the model thinks that objects of “from” are
especially likely to be Specific, and that NPs with comparative adjectives (JJR) are especially likely to be
nonspecific (fig. 3). From fig. 3, we also know that Num. of dependents, dependent’s POS: 1,PRP$ has
a higher weight than, say, Num. of dependents, dependent’s POS: 2,PRP$. This observation suggests a
hypothesis that in English the NPs which have possessive pronouns immediately preceding the head are
more likely to be specific than the NPs which have intervening words between the possessive pronoun
and the head. Similarly, looking at another example in fig. 4, the following two percepts get high weights
for the NP the United States of America to be Specific: last dependent’s POS: NNP and first dependent’s
lemma: the. Since frequency and other factors affect the feature weights learned by the classifier, these
differences in weights may or may not reflect an inherent association with Specificity. Whether these
are general trends, or just an artifact of the sentences that happened to be in the training data and our
statistical learning procedure, will require further investigation, ideally with additional datasets and more
rigorous hypothesis testing.

Finally, we can remove features to test their impact on predictive performance. Notably, in experiments
ablating features indicating articles—the most obvious exponents of definiteness in English—we see
a decrease in performance, but not a drastic one. This suggests that the expression of communicative
functions of definiteness is in fact much richer than morphological definiteness.
Errors. Several labels are unattested or virtually unattested in the training data, so the models unsurpris-
ingly fail to predict them correctly at test time. Same_Head and Different_Head, though both common,
are confused quite frequently. Whether the previous coreferent mention has the same or different head is a
simple distinction for humans; low model accuracy is likely due to errors propagated from coreference
resolution. This problem is so frequent that merging these two categories and retraining the random
forest model improves Exact Match accuracy by 8% absolute and Soft Match accuracy by 5% absolute.

1066



Percepts
+Specific −Specific

First dependent’s POS PRP$ First dependent’s lemma a
Head’s left neighbor’s POS PRP$ Last dependent’s lemma a
Last dependent’s lemma you Num. of dependents, dependent’s lemma 1,a
Num. of dependents, dependent’s lemma 1,you Head’s left neighbor’s POS JJR
Num. of dependents, dependent’s POS 1,PRP$ Last dependent’s POS JJR
Governor’s right neighbor’s POS PRP$ Num. of dependents, dependent’s lemma 2,a
Last dependent’s POS NNP First dependent’s lemma new
Last dependent’s POS PRP$ Last dependent’s lemma new
First dependent’s lemma the Num. of dependents, dependent’s POS 2,JJR
Governor’s lemma from Governor’s left neighbor’s POS VB

Figure 3: Percepts receiving highest positive weights in association with values of the Specific attribute.

Example Relevant percepts from fig. 3 CFD annotation

This is just for the United States of America. Last dependent’s POS: NNP
First dependent’s lemma: the

Unique_Larger_Situation

We were driving from our home in Nashville
to a little farm we have 50 miles east of
Nashville — driving ourselves.

First dependent’s POS: PRP$
Head’s left neighbor’s POS: PRP$
Governor’s right neighbor’s POS: PRP$
Governor’s lemma: from

Bridging_Restrictive_Modifier

Figure 4: Sentences from our corpus illustrating percepts fired for gold NPs and their CFD annotations.

Another common confusion is between the highly frequent category Unique_Larger_Situation and the
rarer category Unique_Hearer_New; the latter is supposed to occur only for the first occurrence of a
proper name referring to a entity that is not already part of the knowledge of the larger community. In
other words, this distinction requires world knowledge about well-known entities, which could perhaps be
mined from the Web or other sources.

7 Related Work

Because semantic/pragmatic analysis of referring expressions is important for many NLP tasks, a compu-
tational model of the communicative functions of definiteness has the potential to leverage diverse lexical
and grammatical cues to facilitate deeper inferences about the meaning of linguistic input. We have used
a coreference resolution system to extract features for modeling definiteness, but an alternative would be
to predict definiteness functions as input to (or jointly with) the coreference task. Applications such as
information extraction and dialogue processing could be expected to benefit not only from coreference
information, but also from some of the semantic distinctions made in our framework, including specificity
and genericity.

Better computational processing of definiteness in different languages stands to help machine translation
systems. It has been noted that machine translation systems face problems when the source and the target
language use different grammatical strategies to express the same information (Stymne, 2009; Tsvetkov
et al., 2013). Previous work on machine translation has attempted to deal with this in terms of either
(a) preprocessing the source language to make it look more like the target language (Collins et al., 2005;
Habash, 2007; Nießen and Ney, 2000; Stymne, 2009, inter alia); or (b) post-processing the machine
translation output to match the target language, (e.g., Popović et al., 2006). Attempts have also been made
to use syntax on the source and/or the target sides to capture the syntactic differences between languages
(Liu et al., 2006; Yamada and Knight, 2002; Zhang et al., 2007). Automated prediction of (in)definite
articles has been found beneficial in a variety of applications, including postediting of MT output (Knight
and Chander, 1994), text generation (Elhadad, 1993; Minnen et al., 2000), and identification and correction
of ESL errors (Han et al., 2006; Rozovskaya and Roth, 2010). More recently, Tsvetkov et al. (2013)
trained a classifier to predict where English articles might plausibly be added or removed in a phrase, and
used this classifier to improve the quality of statistical machine translation.

While definiteness morpheme prediction has been thoroughly studied in computational linguistics,

1067



studies on additional, more complex aspects of definiteness are limited. Reiter and Frank (2010) exploit
linguistically-motivated features in a supervised approach to distinguish between generic and specific
NPs. Hendrickx et al. (2011) investigated the extent to which a coreference resolution system can resolve
the bridging relations. Also in the context of coreference resolution, Ng and Cardie (2002) and Kong
et al. (2010) have examined anaphoricity detection. To the best of our knowledge, no studies have been
conducted on automatic prediction of semantic and pragmatic communicative functions of definiteness
more broadly.

Our work is related to research in linguistics on the modeling of syntactic constructions such as dative
shift and the expression of possession with “of” or “’s”. Bresnan and Ford (2010) used logistic regression
with semantic features to predict syntactic constructions. Although we are doing the opposite (using
syntactic features to predict semantic categories), we share the assumption that reductionist approaches (as
mentioned earlier) are not able to capture all the nuances of a linguistic phenomenon. Following Hopper
and Traugott (2003) we observe that grammaticalization is accompanied by function drift, resulting in
multiple communicative functions for each grammatical construction. Other attempts have also been made
to capture, using classifiers, (propositional as well as non propositional) aspects of meaning that have
been grammaticalized: see, for instance, Reichart and Rappoport (2010) for tense sense disambiguation,
Prabhakaran et al. (2012) for modality tagging, and Srikumar and Roth (2013) for semantics expressed by
prepositions.

8 Conclusion

We have presented a data-driven approach to modeling the relationship between universal communicative
functions associated with (in)definiteness and their lexical/grammatical realization in a particular language.
Our feature-rich classifiers can give insights into this relationship as well as predict communicative
functions for the benefit of NLP systems. Exploiting the higher-level semantic attributes, our log-linear
classifier compares favorably to the random forest classifier in Soft Match accuracy. Further improvements
to the classifier may come from additional features or better preprocessing. This work has focused on
English, but in future work we plan to build similar models for other languages—including languages
without articles, under the hypothesis that such languages will rely on other, subtler devices to encode
many of the functions of definiteness.

Acknowledgments

This work was sponsored by the U. S. Army Research Laboratory and the U. S. Army Research Office
under contract/grant number W911NF-10-1-0533. We thank the reviewers for their useful comments.

References
Barbara Abbott. 2006. Definite and indefinite. In Keith Brown, editor, Encyclopedia of Language and Linguistics,

pages 3–392. Elsevier.

Judith Aissen. 2003. Differential object marking: iconicity vs. economy. Natural Language & Linguistic Theory,
21(3):435–483.

Archna Bhatia, Mandy Simons, Lori Levin, Yulia Tsvetkov, Chris Dyer, and Jordan Bender. 2014. A unified anno-
tation scheme for the semantic/pragmatic components of definiteness. In Proc. of LREC. Reykjavík, Iceland.

Betty Birner and Gregory Ward. 1994. Uniqueness, familiarity and the definite article in English. In Proc. of the
Twentieth Annual Meeting of the Berkeley Linguistics Society, pages 93–102.

Leo Breiman. 2001. Random forests. Machine Learning, 45(1):5–32.

Joan Bresnan and Marilyn Ford. 2010. Predicting syntax: Processing dative constructions in American and Aus-
tralian varieties of English. Language, 86(1):168–213.

Victor Chahuneau, Eva Schlinger, Noah A. Smith, and Chris Dyer. 2013. Translating into morphologically rich
languages with synthetic phrases. In Proc. of EMNLP, pages 1677–1687. Seattle, Washington, USA.

1068



Chao Chen, Andy Liaw, and Leo Breiman. 2004. Using random forest to learn imbalanced data. University of
California, Berkeley.

Ping Chen. 2004. Identifiability and definiteness in Chinese. Linguistics, 42:1129–1184.

Michael Collins, Philipp Koehn, and Ivona Kucerova. 2005. Clause restructuring for statistical machine translation.
In Proc. of ACL, pages 531–540. Ann Arbor, Michigan.

Cleo Condoravdi. 1992. Strong and weak novelty and familiarity. In Proc. of SALT II, pages 17–37.

William Croft. 2003. Typology and Universals. Cambridge University Press.

John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic
optimization. Journal of Machine Learning Research, 12(Jul):2121–2159.

Michael Elhadad. 1993. Generating argumentative judgment determiners. In Proc. of AAAI, pages 344–349.

Gareth Evans. 1977. Pronouns, quantifiers and relative clauses. Canadian Journal of Philosophy, 7(3):46.

Gareth Evans. 1980. Pronouns. Linguistic Inquiry, 11.

Jeanette K. Gundel, Nancy Hedberg, and Ron Zacharski. 1988. The generation and interpretation of demonstrative
expressions. In Proc. of XIIth International Conference on Computational Linguistics, pages 216–221.

Jeanette K. Gundel, Nancy Hedberg, and Ron Zacharski. 1993. Cognitive status and the form of referring expres-
sions in discourse. Language, 69:274–307.

Nizar Habash. 2007. Syntactic preprocessing for statistical machine translation. In MT Summit XI, pages 215–222.
Copenhagen.

Na-Rae Han, Martin Chodorow, and Claudia Leacock. 2006. Detecting errors in english article usage by non-native
speakers. Natural Language Engineering, 12:115–129.

Irene Heim. 1990. E-type pronouns and donkey anaphora. Linguistics and Philosophy, 13:137–177.

Iris Hendrickx, Orphée De Clercq, and Véronique Hoste. 2011. Analysis and reference resolution of bridge
anaphora across different text genres. In Iris Hendrickx, Sobha Lalitha Devi, Antonio Horta Branco, and Ruslan
Mitkov, editors, DAARC, volume 7099 of Lecture Notes in Computer Science, pages 1–11. Springer.

Paul J. Hopper and Elizabeth Closs Traugott. 2003. Grammaticalization. Cambridge University Press.

Nirit Kadmon. 1987. On unique and non-unique reference and asymmetric quantification. Ph.D. thesis, University
of Massachusetts.

Nirit Kadmon. 1990. Uniqueness. Linguistics and Philosophy, 13:273–324.

Kevin Knight and Ishwar Chander. 1994. Automated postediting of documents. In Proc. of the National Conference
on Artificial Intelligence, pages 779–779. Seattle, WA.

Erwin Ronald Komen. 2013. Finding focus: a study of the historical development of focus in English. LOT,
Utrecht.

Fang Kong, Guodong Zhou, Longhua Qian, and Qiaoming Zhu. 2010. Dependency-driven anaphoricity determi-
nation for coreference resolution. In Proc. of COLING, pages 599–607. Beijing, China.

Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-string alignment template for statistical machine translation.
In Proc. of COLING/ACL, pages 609–616. Sydney, Australia.

Christopher Lyons. 1999. Definiteness. Cambridge University Press.

Guido Minnen, Francis Bond, and Ann Copestake. 2000. Memory-based learning for article generation. In Proc. of

1069



the 2nd Workshop on Learning Language in Logic and the 4th Conference on Computational Natural Language
Learning, pages 43–48.

Vincent Ng and Claire Cardie. 2002. Identifying anaphoric and non-anaphoric noun phrases to improve coreference
resolution. In Proc. of COLING. Taipei, Taiwan.

Sonja Nießen and Hermann Ney. 2000. Improving SMT quality with morpho-syntactic analysis. In Proc. of
COLING, pages 1081–1085.

Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Math-
ieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cour-
napeau, Matthieu Brucher, M. Perrot, and Edouard Duchesnay. 2011. Scikit-learn: Machine learning in Python.
Journal of Machine Learning Research, 12:2825–2830.

Claudia Perlich, Foster Provost, and Jeffrey S. Simonoff. 2003. Tree induction vs. logistic regression: a learning-
curve analysis. Journal of Machine Learning Research, 4:211–255.

Maja Popović, Daniel Stein, and Hermann Ney. 2006. Statistical machine translation of German compound words.
In Advances in Natural Language Processing, pages 616–624. Springer.

Vinodkumar Prabhakaran, Michael Bloodgood, Mona Diab, Bonnie Dorr, Lori Levin, Christine D. Piatko, Owen
Rambow, and Benjamin Van Durme. 2012. Statistical modality tagging from rule-based annotations and crowd-
sourcing. In Proc. of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics,
ExProM ’12, pages 57–64.

Ellen F. Prince. 1992. The ZPG letter: Subjects, definiteness and information status. In S. Thompson and W. Mann,
editors, Discourse description: diverse analyses of a fund raising text, pages 295–325. John Benjamins.

Marta Recasens, Marie-Catherine de Marneffe, and Christopher Potts. 2013. The life and death of discourse
entities: identifying singleton mentions. In Proc. of NAACL-HLT, pages 627–633. Atlanta, Georgia, USA.

Roi Reichart and Ari Rappoport. 2010. Tense sense disambiguation: A new syntactic polysemy task. In Proc. of
EMNLP, EMNLP ’10, pages 325–334.

Nils Reiter and Anette Frank. 2010. Identifying generic noun phrases. In Proc. of ACL, pages 40–49. Uppsala,
Sweden.

Craig Roberts. 2003. Uniqueness in definite noun phrases. Linguistics and Philosophy, 26:287–350.

Alla Rozovskaya and Dan Roth. 2010. Training paradigms for correcting errors in grammar and usage. In Proc.
of NAACL-HLT, pages 154–162.

Bertrand Russell. 1905. On denoting. Mind, New Series, 14:479–493.

Richard Socher, John Bauer, Christopher D. Manning, and Andrew Y. Ng. 2013. Parsing with compositional vector
grammars. In Proc. of ACL, pages 455–465. Sofia, Bulgaria.

Vivek Srikumar and Dan Roth. 2013. An inventory of preposition relations. CoRR, abs/1305.5785.

Sara Stymne. 2009. Definite noun phrases in statistical machine translation into Danish. In Proc. of Workshop on
Extracting and Using Constructions in NLP, pages 4–9.

Yulia Tsvetkov, Chris Dyer, Lori Levi, and Archna Bhatia. 2013. Generating English determiners in phrase-based
translation with synthetic translation options. In Proc. of WMT.

Kenji Yamada and Kevin Knight. 2002. A decoder for syntax-based statistical MT. In Proc. of ACL, pages 303–310.
Philadelphia, Pennsylvania, USA.

Yuqi Zhang, Richard Zens, and Hermann Ney. 2007. Improved chunk-level reordering for statistical machine
translation. In IWSLT 2007: International Workshop on Spoken Language Translation, pages 21–28.

1070


