



















































Extracting Opinion Targets and Opinion Words from Online Reviews with Graph Co-ranking


Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 314‚Äì324,
Baltimore, Maryland, USA, June 23-25 2014. c¬©2014 Association for Computational Linguistics

Extracting Opinion Targets and Opinion Words from Online Reviews
with Graph Co-ranking

Kang Liu, Liheng Xu and Jun Zhao
National Laboratory of Pattern Recognition

Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China
{kliu, lhxu, jzhao}@nlpr.ia.ac.cn

Abstract

Extracting opinion targets and opinion
words from online reviews are two fun-
damental tasks in opinion mining. This
paper proposes a novel approach to col-
lectively extract them with graph co-
ranking. First, compared to previous
methods which solely employed opinion
relations among words, our method con-
structs a heterogeneous graph to model
two types of relations, including seman-
tic relations and opinion relations. Next,
a co-ranking algorithm is proposed to es-
timate the confidence of each candidate,
and the candidates with higher confidence
will be extracted as opinion targets/words.
In this way, different relations make coop-
erative effects on candidates‚Äô confidence
estimation. Moreover, word preference
is captured and incorporated into our co-
ranking algorithm. In this way, our co-
ranking is personalized and each candi-
date‚Äôs confidence is only determined by its
preferred collocations. It helps to improve
the extraction precision. The experimen-
tal results on three data sets with differ-
ent sizes and languages show that our ap-
proach achieves better performance than
state-of-the-art methods.

1 Introduction

In opinion mining, extracting opinion targets and
opinion words are two fundamental subtasks.
Opinion targets are objects about which users‚Äô
opinions are expressed, and opinion words are
words which indicate opinions‚Äô polarities. Ex-
tracting them can provide essential information
for obtaining fine-grained analysis on customers‚Äô
opinions. Thus, it has attracted a lot of attentions
(Hu and Liu, 2004b; Liu et al., 2012; Moghaddam
and Ester, 2011; Mukherjee and Liu, 2012).

To this end, previous work usually employed a
collective extraction strategy (Qiu et al., 2009; Hu
and Liu, 2004b; Liu et al., 2013b). Their intuition
is: opinion words usually co-occur with opinion
targets in sentences, and there are strong modifi-
cation relationship between them (called opinion
relation in (Liu et al., 2012)). If a word is an
opinion word, other words with which that word
having opinion relations will have highly proba-
bility to be opinion targets, and vice versa. In this
way, extraction is alternatively performed and mu-
tual reinforced between opinion targets and opin-
ion words. Although this strategy has been widely
employed by previous approaches, it still has sev-
eral limitations.

1) Only considering opinion relations is in-
sufficient. Previous methods mainly focused on
employing opinion relations among words for
opinion target/word co-extraction. They have in-
vestigated a series of techniques to enhance opin-
ion relations identification performance, such as
nearest neighbor rules (Liu et al., 2005), syntactic
patterns (Zhang et al., 2010; Popescu and Etzioni,
2005), word alignment models (Liu et al., 2012;
Liu et al., 2013b; Liu et al., 2013a), etc. How-
ever, we are curious that whether merely employ-
ing opinion relations among words is enough for
opinion target/word extraction? We note that there
are additional types of relations among words. For
example, ‚ÄúLCD‚Äù and ‚ÄúLED‚Äù both denote the same
aspect ‚Äúscreen‚Äù in TV set domain, and they are
topical related. We call such relations between
homogeneous words as semantic relations. If we
have known ‚ÄúLCD‚Äù to be an opinion target, ‚ÄúLED‚Äù
is naturally to be an opinion target. Intuitively,
besides opinion relations, semantic relations may
provide additional rich clues for indicating opin-
ion targets/words. Which kind of relations is more
effective for opinion targets/words extraction? Is it
beneficial to consider these two types of relations
together for the extraction? To our best knowl-

314



edge, these problems have seldom been studied
before (see Section 2).

2) Ignoring word preference. When employ-
ing opinion relations to perform mutual reinforc-
ing extraction between opinion targets and opin-
ion words, previous methods depended on opin-
ion associations among words, but seldom consid-
ered word preference. Word preference denotes
a word‚Äôs preferred collocations. Intuitively, the
confidence of a candidate being an opinion tar-
get (opinion word) should mostly be determined
by its word preferences rather than all words hav-
ing opinion relations with it. For example

‚ÄúThis camera‚Äôs price is expensive for me.‚Äù
‚ÄúIt‚Äôs price is good.‚Äù
‚ÄúCanon 40D has a good price.‚Äù

In these three sentences, ‚Äúprice‚Äù is modified by
‚Äúgood‚Äù more times than ‚Äúexpensive‚Äù. In tradi-
tional extraction strategy, opinion associations are
usually computed based on the co-occurrence fre-
quency. Thus, ‚Äúgood‚Äù has more strong opinion
association with ‚Äúprice‚Äù than ‚Äúexpensive‚Äù, and it
would have more contributions on determining
‚Äúprice‚Äù to be an opinion target or not. It‚Äôs un-
reasonable. ‚ÄúExpensive‚Äù actually has more re-
latedness with ‚Äúprice‚Äù than ‚Äúgood‚Äù, and ‚Äúexpen-
sive‚Äù is likely to be a word preference for ‚Äúprice‚Äù.
The confidence of ‚Äúprice‚Äù being an opinion target
should be influenced by ‚Äúexpensive‚Äù in greater ex-
tent than ‚Äúgood‚Äù. In this way, we argue that the
extraction will be more precise.

ùëÇùëÇùëÇùëÇ4 ùëÇùëÇùëÇùëÇ6 ùëÇùëÇùëÇùëÇ5 ùëÇùëÇùëÇùëÇ1 ùëÇùëÇùëÇùëÇ3 ùëÇùëÇùëÇùëÇ2 

ùëáùëáùëÇùëÇ2 ùëáùëáùëÇùëÇ4 ùëáùëáùëÇùëÇ3 ùëáùëáùëÇùëÇ5 ùëáùëáùëÇùëÇ6 ùëáùëáùëÇùëÇ1 

ùê∫ùê∫ùë°ùë°ùë°ùë° 

ùê∫ùê∫ùëúùëúùëúùëú 

ùê∫ùê∫ùë°ùë°ùëúùëú 

Figure 1: Heterogeneous Graph: OC means opin-
ion word candidates. TC means opinion target
candidates. Solid curves and dotted lines respec-
tively mean semantic relations and opinion rela-
tions between two candidates.

Thus, to resolve these two problems, we present
a novel approach with graph co-ranking. The col-
lective extraction of opinion targets/words is per-
formed in a co-ranking process. First, we oper-
ate over a heterogeneous graph to model seman-
tic relations and opinion relations into a unified
model. Specifically, our heterogeneous graph is

composed of three subgraphs which model differ-
ent relation types and candidates, as shown in Fig-
ure 1. The first subgraph Gtt represents semantic
relations among opinion target candidates, and the
second subgraph Goo models semantic relations
among opinion word candidates. The third part
is a bipartite subgraph Gto, which models opinion
relations among different candidate types and con-
nects the above two subgraphs together. Then we
perform a random walk algorithm onGtt, Goo and
Gto separately, to estimate all candidates‚Äô confi-
dence, and the entries with higher confidence than
a threshold are correspondingly extracted as opin-
ion targets/words. The results could reflect which
type of relation is more useful for the extraction.

Second, a co-ranking algorithm, which incor-
porates three separate random walks on Gtt, Goo

and Gto into a unified process, is proposed to
perform candidate confidence estimation. Differ-
ent relations may cooperatively affect candidate
confidence estimation and generate more global
ranking results. Moreover, we discover each can-
didate‚Äôs preferences through topics. Such word
preference will be different for different candi-
dates. We add word preference information into
our algorithm and make our co-ranking algorithm
be personalized. A candidate‚Äôs confidence would
mainly absorb the contributions from its word
preferences rather than its all neighbors with opin-
ion relations, which may be beneficial for improv-
ing extraction precision.

We perform experiments on real-world datasets
from different languages and different domains.
Results show that our approach effectively im-
proves extraction performance compared to the
state-of-the-art approaches.

2 Related Work

There are many significant research efforts on
opinion targets/words extraction (sentence level
and corpus level). In sentence level extraction,
previous methods (Wu et al., 2009; Ma and Wan,
2010; Li et al., 2010; Yang and Cardie, 2013)
mainly aimed to identify all opinion target/word
mentions in sentences. They regarded it as a se-
quence labeling task, where several classical mod-
els were used, such as CRFs (Li et al., 2010) and
SVM (Wu et al., 2009).

This paper belongs to corpus level extraction,
and aims to generate a sentiment lexicon and a
target list rather than to identify mentions in sen-

315



tences. Most of previous corpus-level methods
adopted a co-extraction framework, where opin-
ion targets and opinion words reinforce each other
according to their opinion relations. Thus, how
to improve opinion relations identification perfor-
mance was their main focus. (Hu and Liu, 2004a)
exploited nearest neighbor rules to mine opinion
relations among words. (Popescu and Etzioni,
2005) and (Qiu et al., 2011) designed syntactic
patterns to perform this task. (Zhang et al., 2010)
promoted Qiu‚Äôs method. They adopted some spe-
cial designed patterns to increase recall. (Liu et
al., 2012; Liu et al., 2013a; Liu et al., 2013b) em-
ployed word alignment model to capture opinion
relations rather than syntactic parsing. The exper-
imental results showed that these alignment-based
methods are more effective than syntax-based ap-
proaches for online informal texts. However, all
aforementioned methods only employed opinion
relations for the extraction, but ignore consider-
ing semantic relations among homogeneous can-
didates. Moreover, they all ignored word prefer-
ence in the extraction process.

In terms of considering semantic relations
among words, our method is related with sev-
eral approaches based on topic model (Zhao et
al., 2010; Moghaddam and Ester, 2011; Moghad-
dam and Ester, 2012a; Moghaddam and Ester,
2012b; Mukherjee and Liu, 2012). The main
goals of these methods weren‚Äôt to extract opin-
ion targets/words, but to categorize all given as-
pect terms and sentiment words. Although these
models could be used for our task according to the
associations between candidates and topics, solely
employing semantic relations is still one-sided and
insufficient to obtain expected performance.

Furthermore, there is little work which consid-
ered these two types of relations globally (Su et
al., 2008; Hai et al., 2012; Bross and Ehrig, 2013).
They usually captured different relations using co-
occurrence information. That was too coarse to
obtain expected results (Liu et al., 2012). In ad-
dition, (Hai et al., 2012) extracted opinion tar-
gets/words in a bootstrapping process, which had
an error propagation problem. In contrast, we per-
form extraction with a global graph co-ranking
process, where error propagation can be effec-
tively alleviated. (Su et al., 2008) used heteroge-
neous relations to find implicit sentiment associ-
ations among words. Their aim was only to per-
form aspect terms categorization but not to extract

opinion targets/words. They extracted opinion tar-
gets/words in advanced through simple phrase de-
tection. Thus, the extraction performance is far
from expectation.

3 The Proposed Method

In this section, we propose our method in detail.
We formulate opinion targets/words extraction as
a co-ranking task. All nouns/noun phrases are re-
garded as opinion target candidates, and all ad-
jectives/verbs are regarded as opinion word candi-
dates, which are widely adopted by pervious meth-
ods (Hu and Liu, 2004a; Qiu et al., 2011; Wang
and Wang, 2008; Liu et al., 2012). Then each can-
didate will be assigned a confidence and ranked,
and the candidates with higher confidence than a
threshold will be extracted as the results.

Different from traditional methods, besides
opinion relations among words, we additionally
capture semantic relations among homogeneous
candidates. To this end, a heterogeneous undi-
rected graph G = (V,E) is constructed. V =
V t ‚à™ V o denotes the vertex set, which includes
opinion target candidates vt ‚àà V t and opinion
word candidates vo ‚àà V o. E denotes the edge
set, where eij ‚àà E means that there is a relation
between two vertices. Ett ‚äÇ E represents the se-
mantic relations between two opinion target candi-
dates. Eoo ‚äÇ E represents the semantic relations
between two opinion word candidates. Eto ‚äÇ E
represents the opinion relations between opinion
target candidates and opinion word candidates.
Based on different relation types, we used three
matrices Mtt ‚àà R|V t|√ó|V t|, Moo ‚àà R|V o|√ó|V o|
and Mto ‚àà R|V t|√ó|V o| to record the association
weights between any two vertices, respectively.
Section 3.4 will illustrate how to construct them.

3.1 Only Considering Opinion Relations

To estimate the confidence of each candidate, we
use a random walk algorithm on our graph to per-
form co-ranking. Most previous methods (Hu and
Liu, 2004a; Qiu et al., 2011; Wang and Wang,
2008; Liu et al., 2012) only considered opinion
relations among words. Their basic assumption is
as follows.

Assumption 1: If a word is likely to
be an opinion word, the words which
it has opinion relation with will have
higher confidence to be opinion targets,
and vice versa.

316



In this way, candidates‚Äô confidences (vt or vo) are
collectively determined by each other iteratively.
It equals to making random walk on subgraph
Gto = (V,Eto) of G. Thus we have

Ct = (1‚àí ¬µ)√óMto √ó Co + ¬µ√ó It
Co = (1‚àí ¬µ)√óMTto √ó Ct + ¬µ√ó Io

(1)

where Ct and Co respectively represent confi-
dences of opinion targets and opinion words.
mtoi,j ‚ààMto means the association weight between
the ith opinion target and the jth opinion word ac-
cording to their opinion relations.

It‚Äôs worthy noting that It and Io respectively de-
note prior confidences of opinion target candidates
and opinion word candidates. We argue that opin-
ion targets are usually domain-specific, and there
are remarkably distribution difference of them on
different domains (in-domain Din vs. out-domain
Dout). If a candidate is salient inDin but common
in Dout, it‚Äôs likely to be an opinion target in Din.
Thus, we use a domain relevance measure (DR)
(Hai et al., 2013) to compute It.

DR(t) =
R(t,Din)
R(t,Dout)

(2)

where R(t,D) = wÃÑtst √ó
‚àëN

j=1(wtj ‚àí 1Wj √ó‚àëWj
k=1wkj) represents candidate relevance with

domain D. wtj = (1 + logTFtj) √ó log NDFt
is a TF-IDF-like weight of candidate t in doc-
ument j. TFtj is the frequency of the candi-
date t in the jth document, and DFt is docu-
ment frequency. N means the document num-
ber in domain D. R(t,D) includes two mea-
sures to reflect the salient of a candidate in D. 1)
wtj ‚àí 1Wj √ó

‚àëWj
k=1wkj reflects how frequently a

term is mentioned in a particular document. Wj
denotes the word number in document j. 2) wÃÑtst
quantifies how significantly a term is mentioned
across all documents in D. wÃÑt = 1N √ó

‚àëN
k=1wtk

denotes average weight across all documents for

t. st =
‚àö

1
N √ó

‚àëN
j=1 (wtj ‚àí wÃÑj)2 denotes the

standard variance of term t. We use the given
reviews as in-domain collection Din and Google
n-gram corpus1 as out-domain collection Dout.
Finally, each entry in It is a normalized DR(t)
score. In contrast, opinion words are usually
domain-independent. Users may use same words
to express theirs opinions, like ‚Äúgood‚Äù, ‚Äúbad‚Äù, etc.
But there are still some domain-dependent opinion

1http://books.google.com/ngrams/datasets

words, like ‚Äúdelicious‚Äù in the restaurant domain,
‚Äúpowerful‚Äù in the car domain. It‚Äôs difficult to dis-
criminate them from other words by using statisti-
cal information. So we simply set all entries in Io
to be 1. ¬µ ‚àà [0, 1] in Eq.1 determines the impact
of the prior confidence on results.

3.2 Only Considering Semantic Relations
To estimate candidates‚Äô confidences by only con-
sidering semantic relations among words, we
make two separately random walks on the sub-
graphs of G, Gtt = (V,Ett) and Goo = (V,Eoo).
The basic assumption is as follows:

Assumption 2: If a word is likely to
be an opinion target (opinion word), the
words which it has strong semantic rela-
tion with will have higher confidence to
be opinion targets (opinion words).

In this way, the confidence of the candidate is
determined only by its homogeneous neighbours.
There is no mutual reinforcement between opinion
targets and opinion words. Thus we have

Ct = (1‚àí ŒΩ)√óMtt √ó Ct + ŒΩ √ó It
Co = (1‚àí ŒΩ)√óMoo √ó Co + ŒΩ √ó Io

(3)

where ŒΩ has the same role as ¬µ in Eq.1.

3.3 Considering Semantic Relations and
Opinion Relations Together

To jointly model semantic relations and opinion
relations for opinion targets/words extraction, we
couple two random walking algorithms mentioned
above together. Here, Assumption 1 and As-
sumption 2 are both satisfied. Thus, an opinion
target/word candidate‚Äôs confidence is collectively
determined by its neighbours according to differ-
ent relation types. Meanwhile, each item may
make influence on it‚Äôs neighbours. It‚Äôs an iterative
reinforcement process. Thus, we have

Ct = (1‚àí Œª‚àí ¬µ)√óMto √ó Co
+ Œª√óMtt √ó Ct + ¬µ√ó It

Co = (1‚àí Œª‚àí ¬µ)√óMTto √ó Ct
+ Œª√óMoo √ó Co + ¬µ√ó Io

(4)

where Œª ‚àà [0, 1] determines which type of rela-
tions dominates candidate confidence estimation.
Œª = 0 means that each candidate‚Äôs confidence
is estimated by only considering opinion relations
among words, which equals to Eq.1. Otherwise,
when Œª = 1, candidate confidence estimation only

317



considers semantic relations among words, which
equals to Eq.3. ¬µ, Io and It have the same meaning
in Eq.1. Our algorithm will run iteratively until it
converges or in a fixed iteration number Iter. In
experiments, we set Iter = 200.

Obtaining Word Preference. The co-ranking
algorithm in Eq.4 is based on a standard random
walking algorithm, which randomly selects a link
according to the association matrix Mto, Mtt and
Moo, or jumps to a random node with prior confi-
dence value. However, it generates a global rank-
ing over all candidates without taking the node
preference (word preference) into account. As
mentioned in the first section, each opinion tar-
get/word has its preferred collocations, it‚Äôs reason-
able that the confidence of an opinion target (opin-
ion word) candidate should be preferentially de-
termined by its preferences, rather than all of its
neighbors with opinion relations.

To obtain the word preference, we resort to top-
ics. We believe that if an opinion word vio is
topical related with a target word vjt, vio can be
regarded as a word preference for vjt, and vice
versa. For example, ‚Äúprice‚Äù and ‚Äúexpensive‚Äù are
topically related in phone‚Äôs domain, so they are a
word preference for each other.

Specifically, we use a vector P Ti =
[P Ti1 , ..., P

Ti
k , ..., P

Ti
|V o|]1√ó|V o| to represent word

preference of the ith opinion target candidate.
P Tik means the preferred probability of the ith
potential opinion target for the kth potential
opinion words. To compute P Tik , we first use
Kullback-Leibler divergence to measure the
semantic distance between any two candidates on
the bridge of topics. Thus, we have

D(vi, vj) =
1
2

Œ£z(KLz(vi||vj) +KLz(vj ||vi))

whereKLz(vi||vj) = p(z|vi)log p(z|vi)p(z|vj) means the
KL-divergence from candidate vi to vj based on
topic z. p(z|v) = p(v|z)p(z)p(v) , where p(v|z) is the
probability of the candidate v to topic z (see Sec-
tion 3.4). p(z) is the probability that topic z in
reviews. p(v) is the probability that a candidate
occurs in reviews. Then, a logistic function is used
to map D(vi, vj) into [0, 1].

SA(vi, vj) =
1

1 + eD(vi,vj)
(5)

Then, we calculate P Tik by normalize SA(vi, vj)

score, i.e. P Tik =
SA(vti ,v

o
k)‚àë|V o|

p=1 SA(v
t
i ,v

o
p)

. For demon-

stration, we give some examples in Table 1, where
each entry denotes a SA(vi, vj) score between two
candidates. We can see that using topics can suc-
cessfully capture the preference information for
each opinion target/word.

expensive good long colorful
price 0.265 0.043 0.003 0.000
LED 0.002 0.035 0.007 0.098
battery 0.000 0.015 0.159 0.001

Table 1: Examples of Calculated Word Preference

And we use a vector POj =
[POj1 , ..., P

Oj
q , ..., P

Oj
|V t|]1√ó|V t| to represent

the preference information of the jth opin-
ion word candidate. Similarly, we have

P
Oj
q =

SA(vtq ,v
o
j )‚àë|V t|

k=1 SA(v
t
k,v

o
j )

.

Incorporating Word Preference into Co-
ranking. To consider such word preference in
our co-ranking algorithm, we incorporate it into
the random walking on Gto. Intuitively, prefer-
ence vectors will be different for different can-
didates. Thus, the co-ranking algorithm would
be personalized. It allows that the candidate
confidence propagates to other candidates only
in its preference cluster. Specifically, we make
modification on original transition matrix Mto =
(M to1 ,M

to
2 , ...,M

to
|V t|) and add each candidate‚Äôs

preference in it. Let MÃÇto = (MÃÇ to1 , MÃÇ
to
2 , ..., MÃÇ

to
|V t|)

be the modified transition matrix, which records
the associations between opinion target candi-
dates and opinion word candidates. Here M tok ‚àà
R1√ó|V o| and MÃÇ tok ‚àà R1√ó|V

o| denotes the kth col-
umn vector in Mto and MÃÇto, respectively. And
let Diag(P Tk) denote a diagonal matrix whose
eigenvalue is vector P Tk , we have

MÃÇ tok = M
to
k Diag(P

Tk)

Similarly, let U tok ‚àà R1√ó|V
t| and UÃÇ tok ‚àà R1√ó|V

t|

denotes the kth row vector in MTto and MÃÇ
T
to, re-

spectively. Diag(POk) denote a diagonal matrix
whose eigenvalue is vector POk . Then we have

UÃÇ tok = U
to
k Diag(P

Ok)

In this way, each candidate‚Äôs preference is in-
corporated into original associations based on
opinion relation Mto through Diag(POk) and
Diag(P Tk). And candidates‚Äô confidences will
mainly come from the contributions of its prefer-
ences. Thus, Ct and Co in Eq.4 become:

318



Ct = (1‚àí Œª‚àí ¬µ)√ó MÃÇto √ó Co
+ Œª√óMtt √ó Ct + ¬µ√ó It

Co = (1‚àí Œª‚àí ¬µ)√ó MÃÇTto √ó Ct
+ Œª√óMoo √ó Co + ¬µ√ó Io

(6)

3.4 Capturing Semantic and Opinion
Relations

In this section, we explain how to capture seman-
tic relations and opinion relations for constructing
transition matrices Mtt, Moo and Mto.

Capturing Semantic Relations: For captur-
ing semantic relations among homogenous candi-
dates, we employ topics. We believe that if two
candidates share similar topics in the corpus, there
is a strong semantic relation between them. Thus,
we employ a LDA variation (Mukherjee and Liu,
2012), an extension of (Zhao et al., 2010), to dis-
cover topic distribution on words, which sampled
all words into two separated observations: opinion
targets and opinion words. It‚Äôs because that we are
only interested in topic distribution of opinion tar-
gets/words, regardless of other useless words, in-
cluding conjunctions, prepositions etc. This model
has been proven to be better than the standard
LDA model and other LDA variations for opinion
mining (Mukherjee and Liu, 2012).

After topic modeling, we obtain the proba-
bility of the candidates (vt and vo) to topic z,
i.e. p(z|vt) and p(z|vo), and topic distribution
p(z). Then, a symmetric Kullback-Leibler diver-
gence as same as Eq.5 is used to calculate the se-
mantical associations between any two homoge-
nous candidates. Thus, we obtain SA(vt, vt) and
SA(vo, vo), which correspond to the entries in
Mtt and Moo, respectively.

Capturing Opinion Relations: To capture
opinion relations among words and construct the
transition matrix Mto, we used an alignment-
based method proposed in (Liu et al., 2013b).
This approach models capturing opinion relations
as a monolingual word alignment process. Each
opinion target can find its corresponding mod-
ifiers in sentences through alignment, in which
multiple factors are considered globally, such as
co-occurrence information, word position in sen-
tence, etc. Moreover, this model adopted a par-
tially supervised framework to combine syntac-
tic information with alignment results, which has
been proven to be more precise than the state-of-
the-art approaches for opinion relations identifica-
tion (Liu et al., 2013b).

After performing word alignment, we obtain
a set of word pairs composed of a noun (noun
phrase) and its corresponding modified word.
Then, we simply employ Pointwise Mutual Infor-
mation (PMI) to calculate the opinion associations
among words as the entries in Mto. OA(vt, vo) =
log p(v

t,vo)
p(vt)p(vo) , where v

t and vo denote an opinion
target candidate and an opinion word candidate,
respectively. p(vt, vo) is the co-occurrence prob-
ability of vt and vo based on the opinion relation
identification results. p(vt) and p(vo) give the in-
dependent occurrence probability of of vt and vo,
respectively

4 Experiments

4.1 Datasets and Evaluation Metrics

Datasets: To evaluate the proposed method, we
used three datasets. The first one is Customer
Review Datasets (CRD), used in (Hu and Liu,
2004a), which contains reviews about five prod-
ucts. The second one is COAE2008 dataset22,
which contains Chinese reviews about four prod-
ucts. The third one is Large, also used in (Wang
et al., 2011; Liu et al., 2012; Liu et al., 2013a),
where two domains are selected (Mp3 and Hotel).
As mentioned in (Liu et al., 2012), Large con-
tains 6,000 sentences for each domain. Opinion
targets/words are manually annotated, where three
annotators were involved. Two annotators were
required to annotate out opinion words/targets in
reviews. When conflicts occur, the third annota-
tor make final judgement. In total, we respectively
obtain 1,112, 1,241 opinion targets and 334, 407
opinion words in Hotel, MP3.

Pre-processing: All sentences are tagged to
obtain words‚Äô part-of-speech tags using Stanford
NLP tool3. And noun phrases are identified using
the method in (Zhu et al., 2009) before extraction.

Evaluation Metrics: We select precision(P),
recall(R) and f-measure(F) as metrics. And a sig-
nificant test is performed, i.e., a t-test with a de-
fault significant level of 0.05.

4.2 Our Method vs. The State-of-the-art
Methods

To prove the effectiveness of the proposed method,
we select some state-of-the-art methods for com-
parison as follows:

2http://ir-china.org.cn/coae2008.html
3http://nlp.stanford.edu/software/tagger.shtml

319



Methods D1 D2 D3 D4 D5 Avg.P R F P R F P R F P R F P R F F
Hu 0.75 0.82 0.78 0.71 0.79 0.75 0.72 0.76 0.74 0.69 0.82 0.75 0.74 0.80 0.77 0.758
DP 0.87 0.81 0.84 0.90 0.81 0.85 0.90 0.86 0.88 0.81 0.84 0.82 0.92 0.86 0.89 0.856

Zhang 0.83 0.84 0.83 0.86 0.85 0.85 0.86 0.88 0.87 0.80 0.85 0.82 0.86 0.86 0.86 0.846
SAS 0.80 0.79 0.79 0.82 0.76 0.79 0.79 0.74 0.76 0.77 0.78 0.77 0.80 0.76 0.78 0.778
Liu 0.84 0.85 0.84 0.87 0.85 0.86 0.88 0.89 0.88 0.81 0.85 0.83 0.89 0.87 0.88 0.858
Hai 0.77 0.87 0.83 0.79 0.86 0.82 0.79 0.89 0.84 0.72 0.88 0.79 0.74 0.88 0.81 0.818
CR 0.84 0.86 0.85 0.87 0.85 0.86 0.87 0.90 0.88 0.81 0.87 0.83 0.89 0.88 0.89 0.862

CR WP 0.86 0.86 0.86 0.88 0.86 0.87 0.89 0.90 0.89 0.81 0.87 0.83 0.91 0.89 0.90 0.870

Table 2: Results of Opinion Targets Extraction on Customer Review Dataset

Methods Camera Car Laptop Phone Mp3 Hotel Avg.P R F P R F P R F P R F P R F P R F F
Hu 0.63 0.65 0.64 0.62 0.58 0.60 0.51 0.67 0.58 0.69 0.60 0.64 0.61 0.68 0.64 0.60 0.65 0.62 0.587
DP 0.71 0.70 0.70 0.72 0.65 0.68 0.58 0.69 0.63 0.78 0.66 0.72 0.69 0.70 0.69 0.67 0.69 0.68 0.683

Zhang 0.71 0.78 0.74 0.69 0.68 0.68 0.57 0.80 0.67 0.80 0.71 0.75 0.67 0.77 0.72 0.67 0.76 0.71 0.712
SAS 0.72 0.72 0.72 0.71 0.64 0.67 0.59 0.72 0.65 0.78 0.69 0.73 0.69 0.75 0.72 0.69 0.74 0.71 0.700
Liu 0.75 0.81 0.78 0.71 0.71 0.71 0.61 0.85 0.71 0.83 0.74 0.78 0.70 0.82 0.76 0.71 0.80 0.75 0.749
Hai 0.68 0.84 0.76 0.69 0.75 0.72 0.58 0.86 0.72 0.75 0.76 0.76 0.65 0.83 0.74 0.62 0.82 0.75 0.742
CR 0.75 0.83 0.79 0.72 0.74 0.73 0.60 0.85 0.70 0.83 0.77 0.80 0.70 0.84 0.76 0.71 0.83 0.77 0.758

CR WP 0.78 0.84 0.81 0.74 0.75 0.74 0.64 0.85 0.73 0.84 0.76 0.80 0.74 0.84 0.79 0.74 0.82 0.78 0.773

Table 3: Results of Opinion Targets Extraction on COAE 2008 and Large

Hu extracted opinion targets/words using asso-
ciation mining rules (Hu and Liu, 2004a).

DP used syntax-based patterns to capture opin-
ion relations in sentences, and then used a boot-
strapping process to extract opinion targets/words
(Qiu et al., 2011),.

Zhang is proposed by (Zhang et al., 2010).
They also used syntactic patterns to capture opin-
ion relations between words. Then a HITS (Klein-
berg, 1999) algorithm is employed to extract opin-
ion targets.

Liu is proposed by (Liu et al., 2013a), an ex-
tension of (Liu et al., 2012). They employed a
word alignment model to capture opinion relations
among words, and then used a random walking al-
gorithm to extract opinion targets.

Hai is proposed by (Hai et al., 2012), which is
similar to our method. They employed both of se-
mantic relations and opinion relations to extract
opinion words/targets in a bootstrapping frame-
work. But they captured relations only using co-
occurrence statistics. Moreover, word preference
was not considered.

SAS is proposed by (Mukherjee and Liu, 2012),
an extended lda-based model of (Zhao et al.,
2010). The top K items for each aspect are ex-
tracted as opinion targets/words. It means that
only semantic relations among words are consid-
ered in SAS. And we set aspects number to be 9 as
same as (Mukherjee and Liu, 2012).

CR: is the proposed method in this paper by us-
ing co-ranking, referring to Eq.4. CR doesn‚Äôt con-
sider word preference.

CR WP: is the full implementation of our
method, referring to Eq.6.

Hu, DP, Zhang and Liu are the methods which
only consider opinion relations among words.
SAS is the methods which only consider seman-
tic relations among words. Hai, CR and CR WP
consider these two types of relations together. The
parameter settings of state-of-the-art methods are
same as their original paper. In CR and CR WP,
we set Œª = 0.4 and ¬µ = 0.1. The experimental
results are shown in Table 2, 3, 4 and 5, where the
last column presents the average F-measure scores
for multiple domains. Since Liu and Zhang aren‚Äôt
designed for opinion words extraction, we don‚Äôt
present their results in Table 4 and 5. From exper-
imental results, we can see.

1) Our methods (CR and CR WP) outperform
other methods not only on opinion targets extrac-
tion but on opinion words extraction in most do-
mains. It proves the effectiveness of the proposed
method.

2) CR and CR WP have much better perfor-
mance than Liu and Zhang, especially on Recall.
Liu and Zhang also use a ranking framework like
ours, but they only employ opinion relations for
extraction. In contrast, besides opinion relations,
CR and CR WP further take semantic relations
into account. Thus, more opinion targets/words
can be extracted. Furthermore, we observe that
CR and CR WP outperform SAS. SAS only ex-
ploits semantic relations, but ignores opinion re-
lations among words. Its extraction is performed
separately and neglects the reinforcement between
opinion targets and opinion words. Thus, SAS has
worse performance than our methods. It demon-
strates the usefulness of considering multiple rela-
tion types.

320



Methods D1 D2 D3 D4 D5 Avg.P R F P R F P R F P R F P R F F
Hu 0.57 0.75 0.65 0.51 0.76 0.61 0.57 0.73 0.64 0.54 0.62 0.58 0.62 0.67 0.64 0.624
DP 0.64 0.73 0.68 0.57 0.79 0.66 0.65 0.70 0.67 0.61 0.65 0.63 0.70 0.68 0.69 0.666

SAS 0.64 0.68 0.66 0.55 0.70 0.62 0.62 0.65 0.63 0.60 0.61 0.60 0.68 0.63 0.65 0.632
Hai 0.62 0.77 0.69 0.52 0.80 0.64 0.60 0.74 0.67 0.56 0.69 0.62 0.66 0.70 0.68 0.660
CR 0.62 0.75 0.68 0.57 0.79 0.67 0.64 0.75 0.69 0.63 0.69 0.66 0.68 0.69 0.69 0.678

CR WP 0.65 0.75 0.70 0.59 0.80 0.68 0.65 0.74 0.70 0.66 0.68 0.67 0.71 0.70 0.70 0.690

Table 4: Results of Opinion Words Extraction on Customer Review Dataset

Methods Camera Car Laptop Phone Mp3 Hotel Avg.P R F P R F P R F P R F P R F P R F F
Hu 0.72 0.74 0.73 0.70 0.71 0.70 0.66 0.70 0.68 0.70 0.70 0.70 0.48 0.67 0.56 0.52 0.69 0.59 0.660
DP 0.80 0.73 0.76 0.79 0.71 0.75 0.75 0.69 0.72 0.78 0.68 0.73 0.60 0.65 0.62 0.61 0.66 0.63 0.702

SAS 0.73 0.70 0.71 0.75 0.68 0.71 0.72 0.68 0.69 0.71 0.66 0.68 0.64 0.62 0.63 0.66 0.61 0.63 0.675
Hai 0.76 0.74 0.75 0.72 0.74 0.73 0.69 0.72 0.70 0.72 0.70 0.71 0.61 0.69 0.64 0.59 0.68 0.64 0.690
CR 0.80 0.75 0.77 0.77 0.74 0.75 0.73 0.71 0.72 0.75 0.71 0.73 0.63 0.69 0.64 0.63 0.68 0.66 0.710

CR WP 0.80 0.75 0.77 0.80 0.74 0.77 0.77 0.71 0.74 0.78 0.72 0.75 0.66 0.68 0.67 0.67 0.69 0.68 0.730

Table 5: Results of Opinion Words Extraction on COAE 2008 and Large

3) CR and CR WP both outperform Hai. We
believe the reasons are as follows. First, CR and
CR WP considers multiple relations in a unified
process by using graph co-ranking. In contrast,
Hai adopts a bootstrapping framework which per-
forms extraction step by step and may have the
problem of error propagation. It demonstrates
that our graph co-ranking is more suitable for this
task than bootstrapping-based strategy. Second,
our method captures semantic relations using topic
modeling and captures opinion relations through
word alignments, which are more precise than Hai
which merely uses co-occurrence information to
indicate such relations among words. In addition,
word preference is not handled in Hai, but pro-
cessed in CR WP. The results show the usefulness
of word preference for opinion targets/words ex-
traction.

4) CR WP outperforms CR, especially on pre-
cision. The only difference between them is that
CR WP considers word preference when perform-
ing graph ranking for candidate confidence esti-
mation, but CR does not. Each candidate confi-
dence estimation in CR WP gives more weights
for this candidate‚Äôs preferred words than CR.
Thus, the precision can be improved.

4.3 Semantic Relation vs. Opinion Relation

In this section, we discuss which relation type
is more effective for this task. For comparison,
we design two baselines, called OnlySA and On-
lyOA. OnlyOA only employs opinion relations
among words, which equals to Eq.1. OnlySA only
employs semantic relations among words, which
equals to Eq.3. Moreover, Combine is our method
which considers both of opinion relations and se-
mantic relations together, referring to Eq.4 with

 

MP3 Hotel Laptop Phone

R
e
c
a
ll

.65

.70

.75

.80

.85

.90

.95
OnlySA

OnlyOA

Combine

(a) Opinion Target Extraction Results

 

MP3 Hotel Laptop Phone
R

e
c
a
ll

.60

.65

.70

.75

.80
OnlySA

OnlyOA

Combine

(b) Opinion Word Extraction Results

Figure 2: Semantic Relations vs. Opinion Rela-
tions

Œª = 0.5. Figure 2 presents experimental results.
The left graph presents opinion targets extraction
results and the right graph presents opinion words
extraction results. Because of space limitation, we
only shown the results of four domains (MP3, Ho-
tel, Laptop and Phone).

From results, we observe that OnlyOA outper-
forms OnlySA in all domains. It demonstrates
that employing opinion relations are more useful
than semantic relations for co-extracting opinion
targets/words. And it is necessary to utilize the
mutual reinforcement relationship between opin-
ion words and opinion targets. Moreover, Com-
bine outperforms OnlySA and OnlyOA in all do-
mains. It indicates that combining different rela-
tions among words together is effective.

4.4 The Effectiveness of Considering Word
Preference

In this section, we try to prove the necessity of
considering word preference in Eq.6. Besides the
comparison between CR and CR WP performed

321



in the main experiment in Section 4.2, we fur-
ther incorporate word preference in aforemen-
tioned OnlyOA, named as OnlyOA WP, which
only employs opinion relations among words and
equals to Eq.6 with Œª = 0. Experimental results
are shown in Figure 3. Because of space limita-
tion, we only show the results of the same domains
in section 4.3,

Form results, we observe that CR WP out-
performs CR, and OnlyOA WP outperforms On-
lyOA in all domains, especially on precision.
These observations demonstrate that considering
word preference is very important for opinion tar-
gets/words extraction. We believe the reason is
that exploiting word preference can provide more
fine information for opinion target/word candi-
dates‚Äô confidence estimation. Thus the perfor-
mance can be improved.

 

MP3 Hotel Laptop Phone

P
re

c
is

io
n

.60

.65

.70

.75

.80

.85

.90
OnlyOA

OnlyOA_WP

CR

CR_WP

 

MP3 Hotel Laptop Phone

R
e
c
a
ll

.70

.75

.80

.85

.90

.95
OnlyOA

OnlyOA_WP

CR

CR_WP

(a) Opinion Target Extraction Results

 

MP3 Hotel Laptop Phone

P
re

c
is

io
n

.60

.65

.70

.75

.80
OnlyOA

OnlyOA_WP

CR

CR_WP

 

MP3 Hotel Laptop Phone

R
e
c
a
ll

.60

.65

.70

.75

.80
OnlyOA

OnlyOA_WP

CR

CR_WP

(b) Opinion Word Extraction Results

Figure 3: Experimental results when considering
word preference

4.5 Parameter Sensitivity

In this subsection, we discuss the variation of ex-
traction performance when changing Œª and ¬µ in
Eq.6. Due to space limitation, we only show the
F-measure of CR WP on four domains. Experi-
mental results are shown in Figure 4 and Figure
5. The left graphs in Figure 4 and 5 present the
performance variation of CR WP with varying Œª
from 0 to 0.9 and fixing ¬µ = 0.1. The right graphs
in Figure 4 and 5 present the performance varia-
tion of CR WP with varying ¬µ from 0 to 0.6 and
fixing Œª = 0.4.

In the left graphs in Figure 4 and 5, we observe
the best performance is obtained when Œª = 0.4.
It indicates that opinion relations and semantic re-
lations are both useful for extracting opinion tar-
gets/words. The extraction performance is benefi-

cial from their combination. In the right graphs in
Figure 4 and 5, the best performance is obtained
when ¬µ = 0.1. It indicates prior knowledge is
useful for extraction. When ¬µ increases, perfor-
mance, however, decreases. It demonstrates that
incorporating more prior knowledge into our al-
gorithm would restrain other useful clues on esti-
mating candidate confidence, and hurt the perfor-
mance.

 

0.0 .1 .2 .3 .4 .5 .6 .7 .8 .9

F
-M

e
a

s
u

re

.60

.65

.70

.75

.80

.85

MP3

Hotel 

Laptop

Phone

 

0.0 .1 .2 .3 .4 .5 .6

F
-M

e
a

s
u

re

.65

.70

.75

.80

.85

MP3

Hotel 

Laptop

Phone

Figure 4: Opinion targets extraction results

 

0.0 .1 .2 .3 .4 .5 .6 .7 .8 .9

F
-M

e
a

s
u

re

.55

.60

.65

.70

.75

.80

MP3

Hotel 

Laptop

Phone

 

0.0 .1 .2 .3 .4 .5 .6

F
-M

e
a

s
u

re

.50

.55

.60

.65

.70

.75

.80

MP3

Hotel 

Laptop

Phone

Figure 5: Opinion words extraction results

5 Conclusions

This paper presents a novel method with graph co-
ranking to co-extract opinion targets/words. We
model extracting opinion targets/words as a co-
ranking process, where multiple heterogenous re-
lations are modeled in a unified model to make co-
operative effects on the extraction. In addition, we
especially consider word preference in co-ranking
process to perform more precise extraction. Com-
pared to the state-of-the-art methods, experimental
results prove the effectiveness of our method.

Acknowledgement

This work was sponsored by the National
Basic Research Program of China (No.
2014CB340500), the National Natural Sci-
ence Foundation of China (No. 61272332
and No. 61202329), the National High Tech-
nology Development 863 Program of China
(No. 2012AA011102), and CCF-Tencent Open
Research Fund.

References
Juergen Bross and Heiko Ehrig. 2013. Automatic con-

struction of domain and aspect specific sentiment

322



lexicons for customer review mining. In Proceed-
ings of the 22nd ACM international conference on
Conference on information &#38; knowledge man-
agement, CIKM ‚Äô13, pages 1077‚Äì1086, New York,
NY, USA. ACM.

Zhen Hai, Kuiyu Chang, and Gao Cong. 2012. One
seed to find them all: mining opinion features via
association. In CIKM, pages 255‚Äì264.

Zhen Hai, Kuiyu Chang, Jung-Jae Kim, and Christo-
pher C. Yang. 2013. Identifying features in opinion
mining via intrinsic and extrinsic domain relevance.
IEEE Transactions on Knowledge and Data Engi-
neering, 99(PrePrints):1.

Mingqin Hu and Bing Liu. 2004a. Mining opinion fea-
tures in customer reviews. In Proceedings of Con-
ference on Artificial Intelligence (AAAI).

Minqing Hu and Bing Liu. 2004b. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, KDD ‚Äô04, pages
168‚Äì177, New York, NY, USA. ACM.

Jon M. Kleinberg. 1999. Authoritative sources in a
hyperlinked environment. J. ACM, 46(5):604‚Äì632,
September.

Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu,
Yingju Xia, Shu Zhang, and Hao Yu. 2010.
Structure-aware review mining and summarization.
In Chu-Ren Huang and Dan Jurafsky, editors, COL-
ING, pages 653‚Äì661. Tsinghua University Press.

Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: analyzing and comparing opin-
ions on the web. In Allan Ellis and Tatsuya Hagino,
editors, WWW, pages 342‚Äì351. ACM.

Kang Liu, Liheng Xu, and Jun Zhao. 2012. Opin-
ion target extraction using word-based translation
model. In Proceedings of the 2012 Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, pages 1346‚Äì1356, Jeju Island, Korea,
July. Association for Computational Linguistics.

Kang Liu, Liheng Xu, Yang Liu, and Jun Zhao. 2013a.
Opinion target extraction using partially supervised
word alignment model.

Kang Liu, Liheng Xu, and Jun Zhao. 2013b. Syntactic
patterns versus word alignment: Extracting opinion
targets from online reviews.

Tengfei Ma and Xiaojun Wan. 2010. Opinion tar-
get extraction in chinese news comments. In Chu-
Ren Huang and Dan Jurafsky, editors, COLING
(Posters), pages 782‚Äì790. Chinese Information Pro-
cessing Society of China.

Samaneh Moghaddam and Martin Ester. 2011. Ilda:
Interdependent lda model for learning latent aspects
and their ratings from online product reviews. In

Proceedings of the 34th International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, SIGIR ‚Äô11, pages 665‚Äì674, New
York, NY, USA. ACM.

Samaneh Moghaddam and Martin Ester. 2012a.
Aspect-based opinion mining from product reviews.
In Proceedings of the 35th International ACM SIGIR
Conference on Research and Development in In-
formation Retrieval, SIGIR ‚Äô12, pages 1184‚Äì1184,
New York, NY, USA. ACM.

Samaneh Moghaddam and Martin Ester. 2012b. On
the design of lda models for aspect-based opinion
mining. In CIKM, pages 803‚Äì812.

Arjun Mukherjee and Bing Liu. 2012. Aspect extrac-
tion through semi-supervised modeling. In Proceed-
ings of the 50th Annual Meeting of the Association
for Computational Linguistics: Long Papers - Vol-
ume 1, ACL ‚Äô12, pages 339‚Äì348, Stroudsburg, PA,
USA. Association for Computational Linguistics.

Ana-Maria Popescu and Oren Etzioni. 2005. Ex-
tracting product features and opinions from reviews.
In Proceedings of the conference on Human Lan-
guage Technology and Empirical Methods in Natu-
ral Language Processing, HLT ‚Äô05, pages 339‚Äì346,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.

Guang Qiu, Bing Liu, Jiajun Bu, and Chun Che. 2009.
Expanding domain sentiment lexicon through dou-
ble propagation.

Guang Qiu, Bing Liu 0001, Jiajun Bu, and Chun Chen.
2011. Opinion word expansion and target extraction
through double propagation. Computational Lin-
guistics, 37(1):9‚Äì27.

Qi Su, Xinying Xu, Honglei Guo, Zhili Guo, Xian
Wu, Xiaoxun Zhang, Bin Swen, and Zhong Su.
2008. Hidden sentiment association in chinese web
opinion mining. In Jinpeng Huai, Robin Chen,
Hsiao-Wuen Hon, Yunhao Liu, Wei-Ying Ma, An-
drew Tomkins, and Xiaodong Zhang 0001, editors,
WWW, pages 959‚Äì968. ACM.

Bo Wang and Houfeng Wang. 2008. Bootstrapping
both product features and opinion words from chi-
nese customer reviews with cross-inducing.

Hongning Wang, Yue Lu, and ChengXiang Zhai. 2011.
Latent aspect rating analysis without aspect key-
word supervision. In Chid Apt, Joydeep Ghosh,
and Padhraic Smyth, editors, KDD, pages 618‚Äì626.
ACM.

Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.
2009. Phrase dependency parsing for opinion min-
ing. In EMNLP, pages 1533‚Äì1541. ACL.

Bishan Yang and Claire Cardie. 2013. Joint infer-
ence for fine-grained opinion extraction. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long

323



Papers), pages 1640‚Äì1649, Sofia, Bulgaria, August.
Association for Computational Linguistics.

Lei Zhang, Bing Liu, Suk Hwan Lim, and Eamonn
O‚ÄôBrien-Strain. 2010. Extracting and ranking
product features in opinion documents. In Chu-
Ren Huang and Dan Jurafsky, editors, COLING
(Posters), pages 1462‚Äì1470. Chinese Information
Processing Society of China.

Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and Xiaom-
ing Li. 2010. Jointly modeling aspects and opin-
ions with a maxent-lda hybrid. In Proceedings of
the 2010 Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP ‚Äô10, pages 56‚Äì
65, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.

Jingbo Zhu, Huizhen Wang, Benjamin K. Tsou, and
Muhua Zhu. 2009. Multi-aspect opinion polling
from textual reviews. In David Wai-Lok Cheung,
Il-Yeol Song, Wesley W. Chu, Xiaohua Hu, and
Jimmy J. Lin, editors, CIKM, pages 1799‚Äì1802.
ACM.

324


