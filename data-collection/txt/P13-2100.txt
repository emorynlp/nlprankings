



















































Using Integer Linear Programming in Concept-to-Text Generation to Produce More Compact Texts


Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 561–566,
Sofia, Bulgaria, August 4-9 2013. c©2013 Association for Computational Linguistics

Using Integer Linear Programming in Concept-to-Text Generation to
Produce More Compact Texts

Gerasimos Lampouras and Ion Androutsopoulos
Department of Informatics

Athens University of Economics and Business
Patission 76, GR-104 34 Athens, Greece

http://nlp.cs.aueb.gr/

Abstract

We present an ILP model of concept-to-
text generation. Unlike pipeline archi-
tectures, our model jointly considers the
choices in content selection, lexicaliza-
tion, and aggregation to avoid greedy de-
cisions and produce more compact texts.

1 Introduction

Concept-to-text natural language generation
(NLG) generates texts from formal knowledge
representations (Reiter and Dale, 2000). With the
emergence of the Semantic Web (Antoniou and
van Harmelen, 2008), interest in concept-to-text
NLG has been revived and several methods
have been proposed to express axioms of OWL
ontologies (Grau et al., 2008) in natural language
(Bontcheva, 2005; Mellish and Sun, 2006; Gala-
nis and Androutsopoulos, 2007; Mellish and Pan,
2008; Schwitter et al., 2008; Schwitter, 2010;
Liang et al., 2011; Williams et al., 2011).

NLG systems typically employ a pipeline archi-
tecture. They usually start by selecting the logi-
cal facts to express. The next stage, text planning,
ranges from simply ordering the selected facts to
complex decisions about the rhetorical structure
of the text. Lexicalization then selects the words
and syntactic structures that will realize each fact,
specifying how each fact can be expressed as a
single sentence. Sentence aggregation then com-
bines sentences into longer ones. Another compo-
nent generates appropriate referring expressions,
and surface realization produces the final text.

Each stage of the pipeline is treated as a lo-
cal optimization problem, where the decisions of
the previous stages cannot be modified. This ar-
rangement produces texts that may not be optimal,
since the decisions of the stages have been shown
to be co-dependent (Danlos, 1984; Marciniak and
Strube, 2005; Belz, 2008). For example, content

selection and lexicalization may lead to more or
fewer sentence aggregation opportunities.

We present an Integer Linear Programming
(ILP) model that combines content selection, lex-
icalization, and sentence aggregation. Our model
does not consider text planning, nor referring ex-
pression generation, which we hope to include in
future work, but it is combined with an external
simple text planner and a referring expression gen-
eration component; we also do not discuss sur-
face realization. Unlike pipeline architectures, our
model jointly examines the possible choices in the
three NLG stages it considers, to avoid greedy local
decisions. Given an individual (entity) or class of
an OWL ontology and a set of facts (OWL axioms)
about the individual or class, we aim to produce a
text that expresses as many of the facts in as few
words as possible. This is important when space is
limited or expensive (e.g., product descriptions on
smartphones, advertisements in search engines).

Although the search space of our model is very
large and ILP problems are in general NP-hard, ILP
solvers can be used, they are very fast in practice,
and they guarantee finding a global optimum. Ex-
periments show that our ILP model outperforms,
in terms of compression, an NLG system that uses
the same components, but connected in a pipeline,
with no deterioration in fluency and clarity.

2 Related work

Marciniak and Strube (2005) propose a general
ILP approach for language processing applications
where the decisions of classifiers that consider
particular, but co-dependent, subtasks need to be
combined. They also show how their approach
can be used to generate multi-sentence route di-
rections, in a setting with very different inputs and
processing stages than the ones we consider.

Barzilay and Lapata (2005) treat content selec-
tion as an optimization problem. Given a pool of
facts and scores indicating the importance of each

561



fact or pair of facts, they select the facts to express
by formulating an optimization problem similar
to energy minimization. In other work, Barzilay
and Lapata (2006) consider sentence aggregation.
Given a set of facts that a content selection stage
has produced, aggregation is viewed as the prob-
lem of partitioning the facts into optimal subsets.
Sentences expressing facts that are placed in the
same subset are aggregated to form a longer sen-
tence. An ILP model is used to find the partitioning
that maximizes the pairwise similarity of the facts
in each subset, subject to constraints limiting the
number of subsets and the facts in each subset.

Althaus et al. (2004) show that ordering a set
of sentences to maximize sentence-to-sentence co-
herence is equivalent to the traveling salesman
problem and, hence, NP-complete. They also show
how an ILP solver can be used in practice.

Joint optimization ILP models have also been
used in multi-document text summarization and
sentence compression (McDonald, 2007; Clarke
and Lapata, 2008; Berg-Kirkpatrick et al., 2011;
Galanis et al., 2012; Woodsend and Lapata, 2012),
where the input is text, not formal knowledge rep-
resetations. Statistical methods to jointly perform
content selection, lexicalization, and surface real-
ization have also been proposed in NLG (Liang et
al., 2009; Konstas and Lapata, 2012a; Konstas and
Lapata, 2012b), but they are currently limited to
generating single sentences from flat records.

To the best of our knowledge, this article is the
first one to consider content selection, lexicaliza-
tion, and sentence aggregation as an ILP joint opti-
mization problem in the context of multi-sentence
concept-to-text generation. It is also the first arti-
cle to consider ILP in NLG from OWL ontologies.

3 Our ILP model of NLG

Let F = {f1, . . . , fn} be the set of all the facts fi
(OWL axioms) about the individual or class to be
described. OWL axioms can be represented as sets
of RDF triples of the form 〈S,R,O〉, where S is an
individual or class, O is another individual, class,
or datatype value, and R is a relation (property)
that connects S to O. Hence, we can assume that
each fact fi is a triple 〈Si, Ri, Oi〉.1

For each fact fi, a set Pi = {pi1, pi2, . . . }
of alternative sentence plans is available. Each

1We actually convert the RDF triples to simpler message
triples, so that each message triple can be easily expressed by
a simple sentence, but we do not discuss this conversion here.

sentence plan pik specifies how to express fi =
〈Si, Ri, Oi〉 as an alternative single sentence. In
our work, a sentence plan is a sequence of slots,
along with instructions specifying how to fill the
slots in; and each sentence plan is associated
with the relations it can express. For example,
〈exhibit12,foundIn,athens〉 could be ex-
pressed using a sentence plan like “[ref (S)]
[findpast] [in] [ref (O)]”, where square brackets
denote slots, ref (S) and ref (O) are instructions
requiring referring expressions for S and O in
the corresponding slots, and “findpast” requires the
simple past form of “find”. In our example, the
sentence plan would lead to a sentence like “Ex-
hibit 12 was found in Athens”. We call elements
the slots with their instructions, but with “S”
and “O” accompanied by the individuals, classes,
or datatype values they refer to; in our exam-
ple, the elements are “[ref (S: exhibit12)]”,
“[findpast]”, “[in]”, “[ref (O: athens)]”. Dif-
ferent sentence plans may lead to more or fewer
aggregation opportunities; for example, sentences
with the same verb are easier to aggregate. We use
aggregation rules (Dalianis, 1999) that operate on
sentence plans and usually lead to shorter texts.

Let s1, . . . , sm be disjoint subsets of F , each
containing 0 to n facts, with m < n. A single
sentence is generated for each subset sj by aggre-
gating the sentences (more precisely, the sentence
plans) expressing the facts of sj .2 An empty sj
generates no sentence, i.e., the resulting text can
be at most m sentences long. Let us also define:

ai =

{
1, if fact fi is selected
0, otherwise (1)

likj =





1, if sentence plan pik is used to express
fact fi, and fi is in subset sj

0, otherwise
(2)

btj =

{
1, if element et is used in subset sj
0, otherwise (3)

and let B be the set of all the distinct elements (no
duplicates) from all the available sentence plans
that can express the facts of F . The length of an
aggregated sentence resulting from a subset sj can
be roughly estimated by counting the distinct el-
ements of the sentence plans that have been cho-
sen to express the facts of sj ; elements that occur
more than once in the chosen sentence plans of sj

2All the sentences of every possible subset sj can be ag-
gregated, because all the sentences share the same subject,
the class or individual being described. If multiple aggrega-
tion rules apply, we use the one that leads to a shorter text.

562



are counted only once, because they will probably
be expressed only once, due to aggregation.

Our objective function (4) maximizes the num-
ber of selected facts fi and minimizes the number
of distinct elements in each subset sj , i.e., the ap-
proximate length of the corresponding aggregated
sentence; an alternative explanation is that by min-
imizing the number of distinct elements in each sj ,
we favor subsets that aggregate well. By a and b
we jointly denote all the ai and btj variables. The
two parts (sums) of the objective function are nor-
malized to [0, 1] by dividing by the total number
of available facts |F | and the number of subsets m
times the total number of distinct elements |B|. In
the first part of the objective, we treat all the facts
as equally important; if importance scores are also
available for the facts, they can be added as mul-
tipliers of αi. The parameters λ1 and λ2 are used
to tune the priority given to expressing many facts
vs. generating shorter texts; we set λ1 + λ2 = 1.

max
a,b

λ1 ·
|F |∑

i=1

ai
|F | − λ2 ·

m∑

j=1

|B|∑

t=1

btj
m · |B| (4)

subject to:

ai =

m∑

j=1

|Pi|∑

k=1

likj , for i = 1, . . . , n (5)

∑

et∈Bik

btj ≥ |Bik| · likj , for
i = 1, . . . , n
j = 1, . . . ,m
k = 1, . . . , |Pi|

(6)

∑

pik∈P (et)
likj ≥ btj , for t = 1, . . . , |B|j = 1, . . . ,m (7)

|B|∑

t=1

btj ≤ Bmax, for j = 1, . . . ,m (8)

|Pi|∑

k=1

likj +

|Pi′ |∑

k′=1

li′k′j ≤ 1, for
j = 1, . . . ,m, i = 2, . . . , n
i′ = 1, . . . , n− 1; i 6= i′
section(fi) 6= section(f ′i)

(9)

Constraint 5 ensures that for each selected fact,
only one sentence plan in only one subset is se-
lected; if a fact is not selected, no sentence plan
for the fact is selected either. |σ| denotes the car-
dinality of a set σ. In constraint 6, Bik is the set of
distinct elements et of the sentence plan pik. This
constraint ensures that if pik is selected in a subset
sj , then all the elements of pik are also present in
sj . If pik is not selected in sj , then some of its el-
ements may still be present in sj , if they appear in
another selected sentence plan of sj .

In constraint 7, P (et) is the set of sentence plans
that contain element et. If et is used in a subset sj ,

then at least one of the sentence plans of P (et)
must also be selected in sj . If et is not used in sj ,
then no sentence plan of P (et) may be selected in
sj . Lastly, constraint 8 limits the number of ele-
ments that a subset sj can contain to a maximum
allowed number Bmax, in effect limiting the max-
imum length of an aggregated sentence.

We assume that each relation R has been man-
ually mapped to a single topical section; e.g., re-
lations expressing the color, body, and flavor of
a wine may be grouped in one section, and rela-
tions about the wine’s producer in another. The
section of a fact fi = 〈Si, Ri, Oi〉 is the section
of its relation Ri. Constraint 9 ensures that facts
from different sections will not be placed in the
same subset sj , to avoid unnatural aggregations.

4 Experiments

We used NaturalOWL (Galanis and Androutsopou-
los, 2007; Galanis et al., 2009; Androutsopoulos
et al., 2013), an NLG system for OWL ontologies
that relies on a pipeline of content selection, text
planning, lexicalization, aggregation, referring ex-
pression generation, and surface realization.3 We
modified content selection, lexicalization, and ag-
gregation to use our ILP model, maintaining the
aggregation rules of the original system.4 For re-
ferring expression generation and surface realiza-
tion, the new system, called ILPNLG, invokes the
corresponding components of NaturalOWL.

The original system, called PIPELINE, assumes
that each relation has been mapped to a topical
section, as in ILPNLG. It also assumes that a man-
ually specified order of the sections and the rela-
tions of each section is available, which is used
by the text planner to order the selected facts (by
their relations). The subsequent components of the
pipeline are not allowed to change the order of the
facts, and aggregation operates only on sentence
plans of adjacent facts from the same section. In
ILPNLG, the manually specified order of sections
and relations is used to order the sentences of each
subset sj (before aggregating them), the aggre-
gated sentences in each section (each aggregated
sentence inherits the minimum order of its con-
stituents), and the sections (with their sentences).

We used the Wine Ontology, which had been
3All the software and data we used are freely available

from http://nlp.cs.aueb.gr/software.html.
We use version 2 of NaturalOWL.

4We use the Branch and Cut implementation of GLPK; see
sourceforge.net/projects/winglpk/.

563



used in previous experiments with PIPELINE.5 We
kept the 2 topical sections, the ordering of sec-
tions and relations, and the sentence plans that
had been used in the previous experiments, but we
added more sentence plans to ensure that 3 sen-
tence plans were available per fact. We gener-
ated texts for the 52 wine individuals of the on-
tology; we did not experiment with texts describ-
ing classes of wines, because we could not think
of multiple alternative sentence plans for many of
their axioms. For each individual, there were 5
facts on average and a maximum of 6 facts.

PIPELINE has a parameter M specifying the
maximum number of facts it is allowed to report
per text. When M is smaller than the number of
available facts |F | and all the facts are treated as
equally important, as in our experiments, it se-
lects randomly M of the available facts. We re-
peated the generation of PIPELINE’s texts for the
52 individuals for M = 2, 3, 4, 5, 6. For each M ,
the texts of PIPELINE for the 52 individuals were
generated three times, each time using one of the
different alternative sentence plans of each rela-
tion. We also generated the texts using a variant of
PIPELINE, dubbed PIPELINESHORT, which always
selects the shortest (in elements) sentence plan
among the available ones. In all cases, PIPELINE
and PIPELINESHORT were allowed to form ag-
gregated sentences containing up to Bmax = 22
distinct elements, which was the number of dis-
tinct elements of the longest aggregated sentence
in the previous experiments, where PIPELINE was
allowed to aggregate up to 3 original sentences.

With ILPNLG, we repeated the generation of the
texts of the 52 individuals using different values
of λ1 (λ2 = 1 − λ1), which led to texts express-
ing from zero to all of the available facts. We set
the maximum number of fact subsets to m = 3,
which was the maximum number of aggregated
sentences observed in the texts of PIPELINE and
PIPELINESHORT. Again, we set Bmax = 22.

We compared ILPNLG to PIPELINE and PIPELI-
NESHORT by measuring the average number of
facts they reported divided by the average text
length (in words). Figure 1 shows this ratio as a
function of the average number of reported facts,
along with 95% confidence intervals (of sample
means). PIPELINESHORT achieved better results
than PIPELINE, but the differences were small.

For λ1 < 0.2, ILPNLG produces empty texts,

5See www.w3.org/TR/owl-guide/wine.rdf.

Figure 1: Facts/words ratio of the generated texts.

since it focuses on minimizing the number of dis-
tinct elements of each text. For λ1 ≥ 0.225, it per-
forms better than the other systems. For λ1 ≈ 0.3,
it obtains the highest fact/words ratio by select-
ing the facts and sentence plans that lead to the
most compressive aggregations. For greater val-
ues of λ1, it selects additional facts whose sen-
tence plans do not aggregate that well, which is
why the ratio declines. For small numbers of facts,
the two pipeline systems select facts and sentence
plans that offer very few aggregation opportuni-
ties; as the number of selected facts increases,
some more aggregation opportunities arise, which
is why the facts/words ratio of the two systems
improves. In all the experiments, the ILP solver
was very fast (average: 0.08 sec, worst: 0.14 sec).
Experiments with human judges also showed that
the texts of ILPNLG cannot be distinguished from
those of PIPELINESHORT in terms of fluency and
text clarity. Hence, the highest compactness of the
texts of ILPNLG does not come at the expense of
lower text quality. Space does not permit a more
detailed description of these experiments.

We show below texts produced by PIPELINE
(M = 4) and ILPNLG (λ1 = 0.3).

PIPELINE: This is a strong Sauternes. It is made from Semil-

lon grapes and it is produced by Chateau D’ychem.

ILPNLG: This is a strong Sauternes. It is made from Semillon

grapes by Chateau D’ychem.

PIPELINE: This is a full Riesling and it has moderate flavor.

It is produced by Volrad.

ILPNLG: This is a full sweet moderate Riesling.

In the first pair, PIPELINE uses different verbs for
the grapes and producer, whereas ILPNLG uses the
same verb, which leads to a more compressive ag-
gregation; both texts describe the same wine and
report 4 facts. In the second pair, ILPNLG has cho-
sen to express the sweetness instead of the pro-
ducer, and uses the same verb (“be”) for all the
facts, leading to a shorter sentence; again both
texts describe the same wine and report 4 facts.

564



In both examples, some facts are not aggregated
because they belong in different sections.

5 Conclusions

We presented an ILP model for NLG that jointly
considers the choices in content selection, lexical-
ization, and aggregation to avoid greedy local de-
cisions and produce more compact texts. Exper-
iments verified that our model can express more
facts per word, compared to a pipeline, which is
important when space is scarce. An off-the-shelf
ILP solver took approximately 0.1 sec for each
text. We plan to extend our model to include text
planning and referring expressions generation.

Acknowledgments

This research has been co-financed by the Euro-
pean Union (European Social Fund – ESF) and
Greek national funds through the Operational Pro-
gram “Education and Lifelong Learning” of the
National Strategic Reference Framework (NSRF)
– Research Funding Program: Heracleitus II. In-
vesting in knowledge society through the Euro-
pean Social Fund.

References
E. Althaus, N. Karamanis, and A. Koller. 2004. Com-

puting locally coherent discourses. In 42nd Annual
Meeting of ACL, pages 399–406, Barcelona, Spain.

I. Androutsopoulos, G. Lampouras, and D. Gala-
nis. 2013. Generating natural language descrip-
tions from OWL ontologies: the NaturalOWL sys-
tem. Technical report, Natural Language Processing
Group, Department of Informatics, Athens Univer-
sity of Economics and Business.

G. Antoniou and F. van Harmelen. 2008. A Semantic
Web primer. MIT Press, 2nd edition.

R. Barzilay and M. Lapata. 2005. Collective content
selection for concept-to-text generation. In HLT-
EMNLP, pages 331–338, Vancouver, BC, Canada.

R. Barzilay and M. Lapata. 2006. Aggregation via
set partitioning for natural language generation. In
HLT-NAACL, pages 359–366, New York, NY.

A. Belz. 2008. Automatic generation of weather
forecast texts using comprehensive probabilistic
generation-space models. Natural Language Engi-
neering, 14(4):431–455.

T. Berg-Kirkpatrick, D. Gillick, and D. Klein. 2011.
Jointly learning to extract and compress. In 49th
Annual Meeting of ACL, pages 481–490, Portland,
OR.

K. Bontcheva. 2005. Generating tailored textual sum-
maries from ontologies. In 2nd European Semantic
Web Conf., pages 531–545, Heraklion, Greece.

J. Clarke and M. Lapata. 2008. Global inference for
sentence compression: An integer linear program-
ming approach. Journal of Artificial Intelligence Re-
search, 1(31):399–429.

H. Dalianis. 1999. Aggregation in natural language
generation. Comput. Intelligence, 15(4):384–414.

L. Danlos. 1984. Conceptual and linguistic decisions
in generation. In 10th COLING, pages 501–504,
Stanford, CA.

D. Galanis and I. Androutsopoulos. 2007. Generating
multilingual descriptions from linguistically anno-
tated OWL ontologies: the NaturalOWL system. In
11th European Workshop on Natural Lang. Genera-
tion, pages 143–146, Schloss Dagstuhl, Germany.

D. Galanis, G. Karakatsiotis, G. Lampouras, and I. An-
droutsopoulos. 2009. An open-source natural lan-
guage generator for OWL ontologies and its use in
Protégé and Second Life. In 12th Conf. of the Euro-
pean Chapter of ACL (demos), Athens, Greece.

D. Galanis, G. Lampouras, and I. Androutsopoulos.
2012. Extractive multi-document summarization
with Integer Linear Programming and Support Vec-
tor Regression. In COLING, pages 911–926, Mum-
bai, India.

B.C. Grau, I. Horrocks, B. Motik, B. Parsia, P. Patel-
Schneider, and U. Sattler. 2008. OWL 2: The next
step for OWL. Web Semantics, 6:309–322.

I. Konstas and M. Lapata. 2012a. Concept-to-text gen-
eration via discriminative reranking. In 50th Annual
Meeting of ACL, pages 369–378, Jeju Island, Korea.

I. Konstas and M. Lapata. 2012b. Unsupervised
concept-to-text generation with hypergraphs. In
HLT-NAACL, pages 752–761, Montréal, Canada.

P. Liang, M. Jordan, and D. Klein. 2009. Learning
semantic correspondences with less supervision. In
47th Meeting of ACL and 4th AFNLP, pages 91–99,
Suntec, Singapore.

S.F. Liang, R. Stevens, D. Scott, and A. Rector. 2011.
Automatic verbalisation of SNOMED classes using
OntoVerbal. In 13th Conf. AI in Medicine, pages
338–342, Bled, Slovenia.

T. Marciniak and M. Strube. 2005. Beyond the
pipeline: Discrete optimization in NLP. In 9th Con-
ference on Computational Natural Language Learn-
ing, pages 136–143, Ann Arbor, MI.

R. McDonald. 2007. A study of global inference al-
gorithms in multi-document summarization. In Eu-
ropean Conference on Information Retrieval, pages
557–564, Rome, Italy.

565



C. Mellish and J.Z. Pan. 2008. Natural language di-
rected inference from ontologies. Artificial Intelli-
gence, 172:1285–1315.

C. Mellish and X. Sun. 2006. The Semantic Web as a
linguistic resource: opportunities for nat. lang. gen-
eration. Knowledge Based Systems, 19:298–303.

E. Reiter and R. Dale. 2000. Building Natural Lan-
guage Generation Systems. Cambridge Univ. Press.

R. Schwitter, K. Kaljurand, A. Cregan, C. Dolbear, and
G. Hart. 2008. A comparison of three controlled
nat. languages for OWL 1.1. In 4th OWL Experi-
ences and Directions Workshop, Washington DC.

R. Schwitter. 2010. Controlled natural languages for
knowledge representation. In 23rd COLING, pages
1113–1121, Beijing, China.

S. Williams, A. Third, and R. Power. 2011. Levels
of organization in ontology verbalization. In 13th
European Workshop on Natural Lang. Generation,
pages 158–163, Nancy, France.

K. Woodsend and M. Lapata. 2012. Multiple aspect
summarization using integer linear programming. In
EMNLP-CoNLL, pages 233–243, Jesu Island, Ko-
rea.

566


