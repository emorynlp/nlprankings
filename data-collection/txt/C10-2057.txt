498

Coling 2010: Poster Volume, pages 498–506,

Beijing, August 2010

(cid:115)(cid:136)(cid:149)(cid:142)(cid:156)(cid:136)(cid:142)(cid:140)(cid:84)(cid:122)(cid:151)(cid:140)(cid:138)(cid:144)(cid:141)(cid:144)(cid:138)(cid:71)(cid:122)(cid:140)(cid:149)(cid:155)(cid:144)(cid:148)(cid:140)(cid:149)(cid:155)(cid:71)(cid:104)(cid:149)(cid:136)(cid:147)(cid:160)(cid:154)(cid:144)(cid:154)(cid:71)(cid:144)(cid:149)(cid:71)(cid:116)(cid:150)(cid:153)(cid:151)(cid:143)(cid:150)(cid:147)(cid:150)(cid:142)(cid:144)(cid:138)(cid:136)(cid:147)(cid:147)(cid:160)(cid:71)

(cid:121)(cid:144)(cid:138)(cid:143)(cid:71)(cid:115)(cid:136)(cid:149)(cid:142)(cid:156)(cid:136)(cid:142)(cid:140)(cid:154)(cid:71)

Hayeon Jang 

Dept. of Linguistics 
Seoul National University 
hyan05@snu.ac.kr

Hyopil Shin 

Dept. of Linguistics 
Seoul National University 
hpshin@snu.ac.kr

Abstract

In  this  paper,  we  propose  language-
specific methods of sentiment analysis in 
morphologically  rich  languages.  In  con-
trast of previous works confined to statis-
tical  methods,  we  make  use  of  various 
linguistic features effectively. In particu-
lar,  we  make  chunk  structures  by  using 
the  dependence  relations  of  morpheme 
sequences  to  restrain  semantic  scope  of 
influence  of  opinionated  terms.  In  con-
clusion, our linguistic structural methods 
using  chunking  improve  the  results  of 
sentiment  analysis  in  Korean  news  cor-
pus.  This  approach  will  aid  sentiment 
analysis  of  other  morphologically  rich 
languages like Japanese and Turkish. 

Introduction 

1
The Internet is a global forum where citizens of 
the  world  gather  to  express  their  opinions.  On-
line services exist for users to share their person-
al  thoughts  while  the  use  of  blogs  and  Twitter 
substitutes  for  private  diaries.  For  this  reason, 
sentiment  analysis  which  automatically  extracts 
and  analyzes  the  subjectivities  and  sentiments 
(or polarities) in written texts has recently been 
receiving attention in the field of NLP. 

Sentiment  analysis  of  English  employs  vari-
ous statistical and linguistic methods referencing 
such linguistic resources as The Berkeley Parser 
and SentiWordNet. In the case of Korean, how-
ever, most previous works have been confined to 
statistical methods which focus either on the fre-
quency  of  words  or  relevance  of  co-occurring 
words  only.  This  is  because  it  is  hard  to  find 
proper  resources  due  to  the  nature  of  Korean, 

exhibiting such features as rich functional  mor-
phemes,  a  relatively  free  word-order  and  fre-
quent deletion of primary elements of sentences 
like the subject and object. The major drawbacks 
of statistical-based approaches are the facts that 
the ‘real’ meaning of the expressions which we 
feel  when  we  read  them  cannot  be  reflected  in 
the analysis, and that complex statistical measur-
ing methods are computationally taxing. 

In  this  paper,  in  order  to  overcome  previous 
shortcomings, while making use of Korean case 
studies we propose a new approach for morpho-
logically rich languages that makes effective use 
of  linguistic  information  such  as  the  semantic 
classes  of  words,  semantic  scope  of  negation 
terms like not, no, and the functional meaning of 
modal  affixes.  Especially,  this  approach  makes 
chunk structures by using dependency relation of 
morpheme sequences to limit the semantic scope 
of influence of opinionated terms. This chunking 
method  is  simpler  and  more  efficient  than  total 
syntactic parsing. In addition, we utilize subjec-
tivity clues and contextual shifters whose effec-
tiveness is established in previous references. 

The  contents  of  this  paper  are  as  follows: 
firstly, we review previous works related to our 
approaches.  We  follow  up  by  introducing  the 
framework and main processes of our approach 
are introduced. Finally, we describe our experi-
ments  and  show  how  a  linguistic  approach  is 
feasible  in  sentiment  analysis  of  Korean  as  a 
morphologically rich language. 
2 Related Work
Sentiment analysis research has been performed 
to  distinguish  the  authors’  polarity  (sentiment 
orientation)  on  certain  topics  from  document-
level (Turney, 2002: Pang et al., 2002; Dave et 
al.,  2003)  to  sentence-level  (Hu  and  Liu,  2004; 

499

Figure 1. Sentiment Analysis Framework 

Kim  and  Hovy,  2004).    We  will  focus  on  sen-
tence-level sentiment classification with our pre-
supposition  that  the  polarity  of  sentences  in  a 
single  document  can  be  diversified  due  to  the 
inclusion of various subtopics. 

 Recently, much research has focused on sub-
jectivity1 extraction  that  divides  objective  facts 
from  subjective  opinions  in  data.  Pang  and  Ri-
loff (2005) and Yu and Hatzivassiloglou (2003) 
trained sentence-level subjectivity classifiers and 
proved  that  performing  sentiment  analysis  tar-
geting  selected  subjective  sentences  only  gets 
higher results. We adopt a method of Wiebe and 
Riloff  (2005)’s  methods  which  classifies  sen-
tences  containing  more  than  two  lexical  items 
associated  with  subjectivity  and  compare  the 
result  of  the  experiments  on  full  and  extracted 
subjective corpora. 

The core of the proposed new approach is the 
use of structural information in morphologically 
rich languages in the process of sentiment analy-
sis.  Choi  et  al.  (2005)  and  Mao  and  Leba-
non(2006)  are  representative  of  the  structured 
sentiment analysis approach which takes advan-
tage  of  Conditional  Random  Fields  (CRF)  to 
determine  sentiment  flow.  McDonald  et  al. 
(2007) also dealt with sentiment analysis, via the 
global  joint-structural  approach.  Furthermore, 
since there are a lot of good parsers for English 
data,  Meena  and  Prabhakr  (2007)  and  Liu  and 
Seneff (2009) utilized sentiment structure infor-
mation by such parsers such as Berkeley Parser.  

1 The term ‘subjectivity’ is equivalent to Quick et al. 
(1985)’s private state which was defined as the words and 
phrases expressing individual mental and emotional states. 

In the case of Korean, much research applies 
dependency grammars for reducing the complex-
ity  of  sentences  to  match  the  characteristics  of 
Korean (Kim and Lee, 2005; Nam et al., 2008) 
but  this  still  causes  problems  which  prohibit 
wide use. Therefore we suggest a new morpho-
logical chunking method that binds semantically 
related concatenations of morphemes. This helps 
to define boundaries of semantic scopes of opi-
nionated  terms  and  is  faster,  simpler  and  more 
efficient on sentiment analysis than a general full 
parser. 

 Our approach focuses on the role of contex-
tual shifters as well. In this paper, the term ‘con-
textual shifter’ covers both negation shifters and 
flow  shifters:  the  former  refers  to  the  terms 
which can change semantic orientation of other 
terms  from  positive  to  negative  and  vise  versa, 
the latter the terms which can control sentiment 
flow  in  sentences,  for  example,  in  English  not,
nobody  (negation  shifters),  however,  but  (flow 
shifters). Kennedy and Inkpen (2006) did senti-
ment analysis of movie and product reviews by 
utilizing 
information. 
Miyoshi  and  Nakagami  (2007)  also  used  this 
method to see the advancement of the result on 
sentimental  analysis  of  electric  product  reviews 
in  Japanese.  In  this  work,  we  make  use  of  the 
functions of each shifter to properly modify the 
value of the terms in the sentences and limit the 
number  of  the  features  which  have  to  be  ob-
served  in  the  analysis  process  to  increase  effi-
ciency. 

the  contextual  shifter 

500

Sentiment Analysis Framework 

3
The process of sentiment analysis in this paper is 
described in Figure 1. In this section, we explain 
each step of the process in detail. 
3.1 Morphological Analysis 
Korean is an agglutinative language where roots 
and  affixes  which  have  their  own  functional 
meaning combine to form complete words. Con-
sequently,  sufficient  morphological  analysis  is 
very  important  to  catch  the  precise  and  deep 
meaning  of  such  expressions.  If  a  certain  sen-
tence is misunderstood by wrong morphological 
analysis,  there  will  be  a  strong  possibility  that 
opinionated terms in the sentence cannot be cor-
rectly analyzed.  

We  used  the  KTS 2  which  is  open-source 
probability based Korean morphological analyz-
er. Although the probabilistic rules established in 
KTS are elaborate, the main source of inaccura-
cy  is  rooted  in  the  inadequacy  of  the  lexicon. 
After  categorizing  all  listed  words  in  the  sen-
tence, the remaining words are mostly classified 
as  general  nouns.  In  this  case,  the  terms  which 
should  play  a  role  as  important  features  in  the 
process  of  sentiment  analysis  will  be  probably 
misunderstood. 

(cid:8970)(cid:14591)

(1) (cid:9054)(cid:11658) (cid:15386)(cid:12246)(cid:18354)
    too  stale-AD3  content 
(2) (cid:9054)(cid:11658)/a   (cid:15386)(cid:12246)/ncs  (cid:18350)/xpa

nemu cinpuha-n nayyong
‘too stale contents’ 

nemu/a4 cinpu/ncs ha/xpa 
(cid:3488)/exm (cid:8970)(cid:14591)/nc
n/exm nayyong/nc

(3) (cid:9054)/npp (cid:11658)(cid:15386)/nc (cid:12246)/nc

ne/npp mucin/nc pu/nc 
(cid:18354)/nc (cid:8970)(cid:14591)/nc
han/nc nayyong/nc 

2 http://kldp.net/projects/kts/ 
3 Abbrebiates: AD(adnominal suffix), NM(nominative  
particle), IN(instrumental particle), SC(subordinative  
conjuctive suffix), CP(conjunctive particle), PST(past  
tense suffix), DC(declarative final suffix), RE(retrospect- 
ive suffix), CN(conjectural suffix), PR(pronoun), PP(pr- 
opositive suffix), AC(auxiliary conjunctive suffix), GE 
(genitive particle) 

4 POS tags of KTS: a(adverb), ncs(stative common noun),  
xpa(adjective-derived suffix), exm(adnominal suffix),nc 
(common noun), npp(personal pronoun) 

‘you Mujin(place name) 
wealth resentment con-
tents’

For example, if sentence (1) which has to be 
analyzed  as  in  (2)  is  incorrectly  analyzed  as  in 
(3). This fault result ignores original spacing and 
randomly conjoins syllables in order to find the 
lexical items included in the dictionary because 
of the lack of lexicon. As the result, we cannot 
grasp the intended sentiment cinbu ‘stale’ in re-
spect to the object nayyong ‘contents’ in the sen-
tence.  In  order  to  solve  such  problems,  we  ex-
panded  the  lexicon  of  KTS  by  adding  53,800 
lexical  items  which  are  included  in  the  Sejong5
dictionary. 
3.2
News corpora have no marks representing polar-
ity  of  sentences  as  exist  in  the  grading  systems 
found in movie review corpora. In addition news 
data contain relatively more objective sentences 
which corpora tend to refer to as facts, as com-
pared  with  reviews.  Therefore  in  the  case  of 
news corpora there is a need to process the anno-
tation  of  subjectivity  and  polarity  tags  for  each 
sentence manually. 

Subjectivity and Polarity Tagging 

In  our  work,  two  native  Korean  annotators 
manually  attached  polarity  labels  to  each  sen-
tence.  Sentences  are  classified  as  subjective 
when they contain opinions pertaining to a cer-
tain object. Even if the opinion is not expressed 
on the surface using direct sentiment terms, the 
sentences  are  classified  as  subjective  when  the 
annotator  can  feel  the  subjectivity  through  the 
tone of voice. In the case of sentences containing 
common sense polarity value words such as do-
nation,  murder,  etc,  terms  do  not  work  as  the 
judgment  criterion,  rather  the  annotator’s  judg-
ment  about  the  main  theme  of  the  sentence  is 
applied.  Only  when  the  sentences  are  classified 
as subjective, the polarity tags are attached. The 
agreement rate of the two annotators in the ma-
nual annotation of polarity is 71%. 

5 The 21 st century Sejong Project is one of the Korean in-
formation policies run by the Ministry of Culture and 
Tourism of Korea. The project was named after King Se-
jong the Great who invented Hangeul. 
(http://www.sejong.or.kr/) 

501

Label 
Positive

Negative
Cynical 
Intensifier 

Conjectural

Obligative
Quotative 

Number of items 

2,285 (1838 nouns, 133 verbs , 314 ad-

2,964 (2300 nouns, 359 verbs , 305 ad-

jectives)

jective)

21 (adverbs) 

91 (80 adverbs, 10 nouns, 1 interjections)
19 (13 final suffixes, 4 pre-final suffixes, 

2 adnominal suffixes)

6 (4 final suffixes,  2 auxiliary conjunc-

tive suffixes)

5 (final suffixes)

Lexical items 

Coh/pa ‘good’, kelcak/nc ‘masterpiece’,
chincel/ncs ‘kind’
Nappu/pa ‘bad’, ssuleki/nc ‘trash’, 
koylophi/pv ‘harass’ 
celday/a ‘Never’, kyeu/a ‘barely’
acu/a ‘very’, hancung/a ‘more’,
tanyeonkho/a ‘decisively’
keyss/efp  CN, lthenteyo/ef CN,
l/exm CN
eya/ecx ‘must’, eyacyo/ef PP
ntanunkun/ef  DC, tayyo/ef DC 

Table 1. Polarity Dictionary 

Subjectivity Extraction 

3.3
The  subjective  lexicon  used  in  subjectivity  ex-
traction  contains  2,469  lexical  items  which  in-
cludes  1,851  nouns,  201  verbs,  247  adjectives, 
124 adverbs, 44 suffixes, and 2 conjunctive par-
ticles. The lemmas of Sejong dictionary are clas-
sified by a total of 581 semantic classes. Among 
them are 23 subjectivity-related semantic classes 
which 
include  Abusive  Language,  External 
Mental  State,  Internal  Mental  State  etc.  Firstly, 
we  have  registered  those  lexical  items  –nouns, 
adjectives,  verbs-  under  subjectivity-related  se-
mantic classes. Since they will be compared with 
morphologically analyzed data before subjectivi-
ty  classification,  all  items  were  registered  as 
tagged forms. Nouns took the biggest portion in 
the lexicon through this process, since adjectives 
and  verbs  which  consist  respectively  of  stative 
nouns (ncs) and active nouns (nca) plus derived 
suffixes (xpa, xpv) were all registered as nouns. 
In Korean, sentiment can also be judged from 

particles and affixes having modal meaning.  

(4)(cid:14955)(cid:12246)(cid:7766) (cid:11658)(cid:14759)(cid:9547)(cid:14738)(cid:10930) (cid:9558)(cid:14759)(cid:18354)(cid:15382)

3 (cid:14802)(cid:14794)(cid:8942) (cid:15382)(cid:8962)(cid:9530).
jengpwu-ka mwuungtap-ulo
tayungha-nci 3il-ina   cina-
ss-ta.
Government-NM no response-IN 
action-SC    3days-CP  pass-
PST-DC
‘It already passed 3 days af-
ter government did not re-
sponse’

(5) (cid:8270) (cid:11910)(cid:14598)(cid:7766) (cid:14238) (cid:8942)(cid:14506)(cid:9642)(cid:10706)(cid:11466)

(cid:15073)(cid:14254)(cid:14746)(cid:17318)(cid:9670).
ku paywu-ka an-nao-ass-te-
lamyen coh-ass-ltheyntey
   the actor-NM not-star-PST-
RE-if nice-PST-CN 
  ‘It were nice, if the actor 
would not have starred the 
main character’ 

(6) (cid:8270)(cid:7878) (cid:14955)(cid:11302) (cid:11313)(cid:14814)(cid:14366)(cid:7926)(cid:9530).

ku-ke   cengmal masiss-ess-
keyss-ta
that-PR  really delicious-
PST-CN-DC
‘That must have been really 
delicious’

For example, conjunctive particle -(i)na in the 
sentence  (4),  final  suffix  -ltheyntey in  (5), and
pre-final suffix -keyss in (6) are very influential 
in  judging  the  subjectivity  of  sentences.  There-
fore, we added those functional terms in the sub-
jective lexicon. 

We  classified  the  sentences  which  contains 
more  than  two  subjective  items  as  subjective. 
When the sentence contained less than five mor-
phemes, however, we manage to judge the sen-
tence as subjective even when only one subjec-
tive  item  shows.  The  result  of  subjectivity  ex-
traction  is  confirmed  by  the  widely  used  statis-
tical method, TFIDF, in the following section. 
3.4
In our process of sentiment analysis, every term 
gets its own values by using polarity dictionaries 
and contextual shifters. In this section we intro-
duce our polarity dictionary and contextual shif-

Term Weighting 

502

ters,  and  their  lexical  items.  Also,  the  term- 
weighting methods of our approach is described. 
Polarity  dictionary:  Table 1 shows our po-
larity dictionary used in sentiment classification. 
In the same way as a subjective lexicon, all lexi-
cal items are registered in the shape of a tagged 
morpheme.  In  addition,  every  item  has  labels 
with its own functional categories.  

First, Positive and Negative refer to the basic 
polarity  value  of  individual  terms  of  sentences. 
The terms that are neither positive nor negative 
are  classified  as  neutral.  We  registered  nouns, 
adjectives  and  verbs  included  in  Sejong  dictio-
nary’s  semantic  class  related  with  emotion  or 
evaluation  such  as  Positive  Property  Human, 
Negative  Property  Human,  etc.  After  that,  we 
selected the terms that are generally used to ex-
press  polarity  from  other  review  corpora  and 
added them to the dictionary. Since we deal with 
on-line  texts,  we  also  added  acronyms,  neolog-
isms  and  new  words  which  are  frequently  used 
to express opinion online. 

Next  we  add  various  functional  lexical  items 
that are from other parts of speech to the polarity 
dictionary.  Cynical  items  play  a  role  of  adding 
negative  nuance  to  sentences.  Intensifiers  em-
phasize  the  meaning  of  following  expressions. 
Conjectural,  Obligative  and  Quotative  items  re-
fer to something other than the author’s opinion. 
Conjectural  and  Obligative  means  that  the  opi-
nion included in the expressions is not actual but 
hypothetical.  Quotative  means  that  opinionated 
terms which are in same phrase express another 
person’s opinions. 

To  determine  the  value  of  the  terms,  our  ap-
proach  uses  a  very  simple  measuring  method. 
Every  term  initially  gets  +1  if  Positive,  -1  if 
Negative. All other words receive a value of 0. 
In the next step, the contexts of the sentences are 
examined  and  the  values  are  modified.  In  the 
case  of  simple  classification  which  does  not  go 
through  the  chunking  process,  we  consider  the 
distance  of  content  words  in  Korean  sentences 
which  have  various  auxiliaries  and  affixes,  and 
set  a  [-2,  +2]  window.  In  the  case  of  structural 
classification,  we  take  advantage  of  structures 
made  by  chunking.  If  Positives  and  Negatives 
are  neighboring,  we  modify  the  values  of  the 
terms to reflect the fact that they influence each 
other. When Cynical items appear with Positives, 
we  multiply  by  -1  to  the  value  of  Positives. 

When Cynicals appear with Negative items, we 
intensify  the  value  of  Negative  by  multiplying 
by 2. If Cynicals appear with neutral terms, we 
change the value of neutral terms to -1. The val-
ue of the terms which are affected by the Inten-
sifier  doubles,  whereas  the  values  of  the  terms 
which are in the scope of Conjectural, Obligative 
and Quotative items are reduced to half. In this 
way  we  control  the  importance  of  the  terms  in 
the sentence. 

Contextual  Shifters:  contextual  shifters  in 
Korean  consist  of  13  negation  shifters  (adverbs 
such as an/a ‘not’, mos/a ‘cannot’ and  auxiliary 
verbs such as anh/px ‘not’, mal/px ‘stop’) and 23 
flow shifters (sentence-conjunctive adverbs such 
as kulena/ajs, haciman/ajs ‘but, though’, subor-
suffixes  pnitaman/ecs, 
dinative 
ntey/ecs  CN  and  conjunctive  suffixes  such  as 
eto/ecx AC).

conjuctive 

Since negation shifters play the role of shift-
ing  the  polarity  of  the  sentiment  terms  in  our 
approach, we multiply them by -1. In the case of 
flow shifters, we limit the number of features to 
the terms after the shifter appears. We deemed it 
more important to understand an author’s empa-
thetic  point,  rather  than  to  catch  full  sentiment 
flow  in  the  sentences.  Also  such  emphasized 
contents  mostly  exist  after  the  flow  shifters. 
Therefore we utilize this characteristic to reduce 
the  work  load  and  to  prevent  confusions  which 
are caused by other minor sentiment terms.  

(7) (cid:14754)(cid:14235)(cid:9754) (cid:15073)(cid:7990) (cid:14423)(cid:13079)(cid:9754) (cid:15073)(cid:14254)(cid:9450)(cid:9670)

(cid:13562)(cid:17398)(cid:11266)(cid:7766) (cid:12058)(cid:10930)(cid:14422)(cid:9530).
umak-to  coh-ko yengsang-to 
coh-ass-nuntey sutholi-ka 
pyello-yess-ta
music-also good-CN image-
also good-CN story-NM not 
so good-PST-DC 
so good though, story is
not so good,’ 

  ‘music was good and image al-

For example, in the sentence (7) -nuntey func-
tions  as  a  flow  shifter.  Dealing  with  the  words 
after  –nuntey,  we  can  limit  the  object  mor-
phemes  to  5  out  of  14.  Therefore,  measuring 
load  is  significantly  reduced,  and  furthermore, 
we can prevent the confusion from two positive 
terms coh ‘good’ before the flow shifter.  

503

Figure 2. Chunking structure of the below sentence. (A short movie reviews) 

(cid:16114)(cid:9114)(cid:14766) (cid:13198)(cid:14634)(cid:14794) (cid:18862)(cid:10818)(cid:9754) (cid:8883)(cid:8942)(cid:15382) (cid:14240)(cid:9450) (cid:11854)(cid:14490)(cid:14766) (cid:13058)(cid:10727)

 chen-nyen-uy seywel-i hulu-eto kkuthna-ci anh-nun miwan-uy salang

1000-year-GE time-NM flow-CN finish-CN not-AD incomplete-GE love 

‘an incomplete love that has not finished even after 1000 years’

3.5 Chunking  using  morphological  depen-

dency relation 

In  our  approach,  instead  of  complete  syntactic 
parsing we use a chunking method based on the 
dependency  relation  of  morpheme  sequences  in 
terms of the provision that it is important to limit 
the  semantic  influential  scopes  of  main  opinio-
nated expressions. 

Korean  is  a  head-final  language:  in  terms  of 
dependency  grammar,  governors  are  always  lo-
cated after their dependents. We reflect upon this 
characteristic to form a relation if a certain mor-
pheme  acts  as  the  governor  of  a  previous  mor-
pheme. Chunks (small and mid nodes shown in 
figure  2.)  are  formed  until  an  unrelated  mor-
pheme appears. The terms in a single chunk ex-
ert great semantic influence to control the value 
of  each  other.  After  determining  the  values  of 
every  morpheme  in  each  chunk,  this  process  is 
replicated  at  a  higher  level  and  finally  the  ulti-
mate  values  of  every  term  in  the  sentence  are 
determined. 

For  example 

in  Figure  2, 
[seywel+i] 

the  structure 
[[chen+nyen]+uy] 
[hulu+eto] 
[kkuthna+ci+anh+nun]  [miwan+uy]  [sarang]
is the result of the chunking process of the sen-
tence chen-nyen-uy seywel-i hulu-eto kkuthna-ci 
anh-nun  miwan-uy  salang  1000-year-GE  time-
NM flow-CN finish-CN not-AD incomplete-GE 
love ‘an  incomplete  love  that  has  not  finished 
even after 1000 years’. If we focus on the terms 
after  the  flow  shifter  -eto,  the  negation  shifter 
anh ‘not’ in the first phrase only influences the 
verb kkuthna-  ‘finish’  in  the  same  chunk.  This 
limitation of semantic scope of the negation shif-
ter  eliminates  the  possibility  that  it  excessively 
modifies the values of other unrelated elements. 
Since  the  simple  classification  has  a  [-2,  +2] 

window, miwan  ‘incomplete’  is  also  influenced 
by  -anh.  Then  the  value  of  miwan  becomes  +1 
which  is  classified  as  a  positive  term,  and  the 
whole  expression  miwan-uy  salang  ‘an  incom-
plete love’ is misclassified as positive. 
4 Experiment
4.1 Corpora
Since  movie  review  data  is  commonly used  for 
sentiment analysis, we primarily collected movie 
reviews. Following the comments of many pre-
vious  works  that  it  is  hard  to  separate  the  sen-
tences  which  mention  the  plot  of  movies  from 
opinion  sentences,  especially  short  movie  re-
views  which  containing  1~2  sentences  delibe-
rately selected. The reason is that short reviews 
having  limited  space  probably  include  opinions 
only. Movie review data of less than 20 charac-
ters  was  crawled  from  a  representative  movie 
site  in  Korea,  Cine216.  It  contains  185,405  re-
views  ranging  from  December  31,  2003  to  De-
cember 28, 2009 (total 19.5MB). 

Next, we collected 79,390 news articles from 
January  1,  2009 
to  April  7,  2010  (total 
146.6MB) from the web site of the daily news-
paper, The Hankyoreh7. The news data includes 
both  objective  and  subjective  sentences,  and  is 
categorized into 3 groups by the following cha-
racteristics:  71,612  general  news  articles,  3,743 
opinionated news articles having subjective sub-
topics  such  as  ‘Yuna  Kim,  terrorism,  etc.’  and 
3,432  editorial  articles  including  columns  and 
contributions.  After  randomly  extracting  100 
articles from each data group a Korean annotator 
attached subjectivity and polarity labels to each 

6 http://www.cine21.com/ 
7 http://www.hani.co.kr/ 

504

Method 

total 

subjective 

Accuracy (%) 

F-measure8 (%)

Accuracy 

TFIDF 
NO chunking NO shifter 
NO chunking YES shifters 
YES chunking NO shifter 
YES chunking YES shifters 

90.02 
90.034 
90.018 
87.29 
87.29 
Table 2. Sentiment analysis of short movie review corpora 

87.67 
87.676 
87.674 
83.212 
83.212 

93.431 
93.432 
93.433 
90.835 
90.835 

F-measure
94.748 
94.757 
94.745 
93.214 
93.214 

Method 

TFIDF

Data 

Accuracy (%) 

Total 

Subjective 

News articles 
Subtopic News 

63.032 
82.00 
61.95 
73.332 
57.53 
87.23 
Table 3. Subjectivity extraction of news corpora 

Editorial articles

Subjective 

Subjective 

articles

Total 

Total 

F-measure (%) 

28.532 
89.919 
32.287 
84.44 
73.04 
93.18 

Experiment 1: Short Movie Reviews 

sentence.  The  collection  of  sample  sentences 
consists of 1,225 general news sentences, 1,185 
subtopic news sentences and 2,592 sentences of 
editorial articles. 
4.2
 Table 2 shows the result of a 5-fold cross varia-
tion  experiment  on  the  sentiment  analysis  of 
short  movie  review  data  using  SVMlight.  The 
numbers in bold face are the values being larger 
than  the  baseline,  the  results  using  TFIDF.  A 
subjectivity  extraction  experiment  was  not  car-
ried out because of the presumption that all mov-
ie  reviews  used  in  this  work  are  subjective.  
(There  were  a  few  reviews  containing  quotes 
from  the  movies  or  meaningless  words  only. 
Such cases, however, were ignored.)  In the case 
of movie review data, selected subjective data is 
regarded as having stronger subjectivity. 

When  subjective  data  is  compared  with  total 
data  by  the  same  experimental  methods,  there 
are consistent improvements in sentiment analy-
sis for the subjective data. It is no surprise that 
the sentences that contain a more intense level of 
subjectivity  can  be  easily  classified  as  correct 
polarity. 

In  addition,  contrary  to  our  expectations,  the 
application  of  the  simple  classification  method 
(NO chunking) gets the higher results in compar-
ison  with  the  structural  classification  method 
(YES chunking) regardless of the use of contex-

8 F-measure = 2*precision*recall/(precision+recall) 

tual shifters. This phenomenon can be analyzed 
based  on  the  limited  length  of  reviews  and  the 
characteristics  of  online  data.  First,  most  sen-
tences have a simple structure like the sequence 
of nouns or noun phrases due to restricted writ-
ing space. For this reason, the effect of chunking 
and  contextual  shifters  on  sentiment  classifica-
tion  is  insignificant.  Second,  the  data  includes 
various terms only seen on the Internet, vulgar-
isms  and  ungrammatical  words.  Furthermore, 
there are the problems of word spacing and spel-
ling. Because of these drawbacks of online data, 
morphological  analysis  errors  frequently  oc-
curred.  The  errors  are  further  propagated  to 
structures as a result of chunking. For this reason, 
when  the  chunking  method  is  used,  contextual 
shifters are ineffective at all as shown the results 
using the chunking method in Table 1. 
4.3
Subjectivity Extraction: The results of a 5-fold 
cross variation experiment of subjectivity extrac-
tion using SVMlight are described in Table 3. In 
this experiment, we use the commonly used sta-
tistical method TFIDF to compare total data with 
subjective data in the three groups in the subjec-
tivity classification task. In conclusion, the cho-
sen  subjective  data  of  all  groups  get  higher  re-
sults. Especially in the cases of news articles and 
subtopic news articles which are less subjective 
than editorial articles, F-measure value is greatly 
increased. 

Experiment 2: News articles 

505

Figure 3. Sentiment analysis of  news corpora 

Sentiment Analysis: The results of sentiment 
analysis  on  the  three  groups  of  news  data  are 
summarized  in  Figure  3.  The  white  points  in 
Figure  3  are  the  values  being  larger  than  the 
baseline, the results using TFIDF. 

First  of  all,  all  of  our  proposed  classification 
methods get higher results than TFIDF, except in 
the case of F-measure of subjective News data. 
This shows that using language-specific features 
which  inflect  the  target  language’s  linguistic 
characteristics well, without complex mathemat-
ical  measuring  techniques,  we  could  get  better 
results than statistical methods in sentiment clas-
sification.

Secondly,  similar  to  the  result  of  movie  re-
view  corpora,  mostly  subjective  data  shows 
greatly  improved  results  in  experimental  me-
thods  overall.  This  means  that  our  subjectivity 
extraction works successfully. 

Finally,  in  contrast  to  the  results  of  experi-
ment 1, we get higher values of sentiment classi-
fication  by  using  chunking  and  contextual  shif-
ters. This implies that the restriction on semantic 
scope of opinionated terms and the methods re-
ducing  features  and  properly  modifying  values 
of  polarity  terms  by  using  contextual  shifters 
also  have  merits  in  sentiment  analysis  of  data 
such as news which has complex sentence struc-
ture like news. Furthermore, this tendency is no-
ticeable particularly in the subjective data of all 
three groups. This confirms the effectiveness of 

utilizing  linguistic  methods  in  subjectivity  ex-
traction  and  sentiment  analysis  for  news  data 
which tries to maintain objectivity. 
5 Discussion and Further Work 
In  this  paper,  we  verified  that  simple  measure-
ments  utilizing  language-specific  features  can 
improve the results of sentiment analysis. Partic-
ularly the chunking method using morphological 
dependency relations and the lexicon which con-
tains  suffixes  and  particles  having  important 
functional  meanings  is  expected  to  aid  the  sen-
timent analysis of other agglutinative languages 
such  as  Turkish  and  Japanese.  In  addition,  this 
approach of sentiment analysis can be applied to 
various applications for extracting important in-
formation  on  the  Internet  to  monitor  a  certain 
brand(cid:709)s reputations or to make social network for 
peoples who have similar opinions. 

We  have  plans  to  confirm  the  results  of  this 
paper by experiments on corpora which are ex-
panded in size and type in future work. We will 
also increase the number of lexical items of sub-
jectivity  lexicon  and  polarity  dictionary.  Fur-
thermore,  we  will  utilize  other  linguistic  infor-
mation such as synonym lists of Korean ontolo-
gy  and  elaborate  measuring  methods  using  lin-
guistic-specific features of morphologically rich 
languages effectively. 

506

References 
Choi,  Y.,  C.  Cardie,  E.  Riloff,  and  S.  Patwardhan. 
2005. Identifying sources of opinions with condi-
tional  random  fields  and  extraction  patterns.  In 
Proceedings of the HLT/EMNLP.

Dave,  K.,  S.  Lawrence,  and  D.  M.  Pennock.  2003. 
Mining the peanut gallery: Opinion extraction and 
semantic classification of product reviews. In Pro-
ceedings of the WWW-2003.

Hu, Minqing, and Bing Liu. 2004. Mining and sum-
marizingcustomer  reviews.  In  Proceedings  of  the 
KDD.
Kennedy, A., and D. Inkpen. 2006. Sentiment Classi-
fication  of  Movie  and  Product  Reviews  Using 
Contextual Valence Shifters. Computational Intel-
ligence, 22(2):110–125. 

Kim, Mi-Yong, and Jong-Hyeok Lee. 2005. Syntactic 
Analysis  based  on  Subject-Clause  Segmentation. 
In  Proceedings  of  the  KCC  2005,  32(9):936-947. 
In Korean. 

Kim, S. M., and E. Hovy. 2004. Determining the sen-
timent of opinions. In Preceeding of the COLING.
Liu,  Jingjing,  and  Stephanie  Seneff.  2009.  Review 
sentiment scoring via a parse-and-paraphrase para-
digm.  In  Proceedings  of  the  2009  Conference  on 
Empirical  Methods 
in  Natural  Language 
Processing, 1(1). 

Mao, Y., and G. Lebanon. 2006. Isotonic conditional 
random  fields  and  local  sentiment  flow.  In  Pro-
ceedings of the NIPS.

McDonald, R., K. Hannan, T. Neylon, M. Wells, and 
J.  Reynar.  2007.  Structured  Models  for  Fine-to-
Coarse Sentiment Analysis. In Proceedings of the 
45th Annual Meeting of the Association of Compu-
tational Linguistics, 432—439. 

Meena,  Arun,  and  T. V.  Prabhakar.  2007.  Sentence 
Level Sentiment Analysis in the Presence of Con-
juncts Using Linguistic Analysis. Lecture Notes in 
Computer Science, 573-580. Springer. 

Nam, Sang-Hyub, Seung-Hoon Na, Yeha Lee, Yong-
Hun Lee, Jungi Kim, and Jong-Hyeok Lee. 2008. 
Semi-Supeervised  Learning  for  Sentiment  Phrase 
Extraction  by  Combining  Generative  Model  and 
Discriminative  Model.  In  Proceedings  of  the 
KCC(Korea  Computer  Congress)  2008,  35(1):268-
273. in Korean. 

Pang,  Bo,  Lillian  Lee,  and  Shivakumar  Vaithyana-
than.  2002.  Thumbs  up?  Sentiment  classification 
using machine learning techniques. In Proceedings 

of the ACL-2002 conference on Empirical methods 
in natural language processing, 10. 

Pang, Bo, and Lillian Lee.  2004. A sentimental edu-
cation: Sentiment analysis using subjectivity sum-
marization  based  on  minimum  cuts.  In  Proceed-
ings of the ACL-2004.

Polanyi, Livia,  and Annie Zaenen. 2004.  Contextual 
valence shifters. In Proceedings of the AAAI Sym-
posium  on  Exploring  Attitude  and  Affect  in  Text: 
Theories and Applications.

Ptaszynski,  Michal, 

Pawel  Dybala, Wenhan 
Shi, Rafal Rzepka, and Kenji Araki. 2010. Contex-
tual  affect  analysis:  a  system  for  verification  of 
emotion  appropriateness  supported  with  Contex-
tual  Valence  Shifters.  International  Journal  of 
Biometrics, 2(2):134-154. 

Quirk, R., S. Greenbaum, G. Leech, and J. Svartvik. 
1985.  A  Comprehensive  Grammar  of  the  English 
Language. Longman, New York. 

Riloff, Ellen, and Janyce Wiebe. 2003. Learning ex-
traction  patterns  for  subjective  expressions.  In 
Proceedings of the 2003 Conference on Empirical 
Methods  in  Natural  Language  Processing,  105-
112. 

Tetsuya,  Miyoshi,  and  Nakagami  Yu.  2007.  Senti-
ment classification of customer reviews on electric 
products. In Proceeding of the IEEE International 
Conference  on  Systems  Man  and  Cybernetics,
2028-2033. 

Turney,  P.  D.  2002.  Thumbs  up  or  thumbs  down? 
Semantic orientation applied to unsupervised clas-
sification  of  reviews.  In  Proceedings  of  the  40th 
Annual  Meeting  of  the  Association  for  Computa-
tional Linguistics (ACL'02), 417-424. 

Wiebe, Janyce, Theresa Wilson, Rebecca Bruce, Mat-
thew  Bell,  and  Melanie  Martin.  2004.  Learning 
subjective  language.  Computational  Linguistics,
30(3). 

Wiebe, Janyce, and E. Riloff. 2005. Creating subjec-
tive and objective sentence classifiers from unan-
notated texts. In Proceedings of the CICLing 2005,
486-497. 

Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann. 
2005.  Recognizing  Contextual  Polarity  in Phrase-
Level  Sentiment  Analysis.  In  Proceedings  of  the 
HLT/EMNLP, 347-354. 

Yu, H., and Hatzivassiloglou V. 2003. Towards ans-
wering  opinion  questions:  Separating  facts  from 
opinions  and  identifying  the  polarity  of  opinion 
sentences. In Proceedings of EMNLP, 32.

