



















































A Graph-based Readability Assessment Method using Word Coupling


Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 411–420,
Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.

A Graph-based Readability Assessment Method using Word Coupling

Zhiwei Jiang, Gang Sun, Qing Gu∗, Tao Bai, Daoxu Chen
State Key Laboratory for Novel Software Technology

Nanjing University, Nanjing 210023, China
jiangzhiwei@outlook.com, sungangnju@163.com,

guq@nju.edu.cn, bt@xjau.edu.cn, cdx@nju.edu.cn

Abstract

This paper proposes a graph-based read-
ability assessment method using word
coupling. Compared to the state-of-the-
art methods such as the readability for-
mulae, the word-based and feature-based
methods, our method develops a coupled
bag-of-words model which combines the
merits of word frequencies and text fea-
tures. Unlike the general bag-of-words
model which assumes words are indepen-
dent, our model correlates the words based
on their similarities on readability. By
applying TF-IDF (Term Frequency and
Inverse Document Frequency), the cou-
pled TF-IDF matrix is built, and used in
the graph-based classification framework,
which involves graph building, merging
and label propagation. Experiments are
conducted on both English and Chinese
datasets. The results demonstrate both ef-
fectiveness and potential of the method.

1 Introduction

Readability assessment is a task that aims to eval-
uate the reading difficulty or comprehending easi-
ness of text documents. It is helpful for education-
ists to select texts appropriate to the reading/grade
levels of the students, and for web designers to or-
ganize texts on web pages for the users doing per-
sonalized searches for information retrieval.

Research on readability assessment starts from
the early 20th century (Dale and Chall, 1948).
Many useful readability formulae have been devel-
oped since then (Dale and Chall, 1948; McLaugh-
lin, 1969; Kincaid et al., 1975). Currently, due to
the development of natural language processing,
the methods on readability assessment have made
a great progress (Zakaluk and Samuels, 1988;

∗Corresponding author.

Benjamin, 2012; Gonzalez-Dios et al., 2014). The
word-based methods compute word frequencies in
documents to estimate their readability (Collins-
Thompson and Callan, 2004; Kidwell et al., 2009).
The feature-based methods extract text features
from documents and train classification models
to classify the readability (Schwarm and Osten-
dorf, 2005; Feng et al., 2010; François and Fairon,
2012; Hancke et al., 2012).

In this paper, we propose a graph-based method
using word coupling, which combines the mer-
its of both word frequencies and text features
for readability assessment. We design a cou-
pled bag-of-words model, which correlates words
based on their similarities on sentence-level read-
ability computed using text features. The model
is used in a graph-based classification frame-
work, which involves graph building, graph merg-
ing/combination, and label propagation. We per-
form experiments on datasets of both English and
Chinese. The results demonstrate both effective-
ness and potential of our method.

The rest of this paper is organized as follows:
Section 2 introduces backgrounds of our work.
Section 3 presents the details of the method. Sec-
tion 4 designs the experiments and explains the re-
sults. Finally, Section 5 concludes the paper with
planned future work.

2 Background

In this section, we introduce briefly three research
topics relevant to our work: readability assess-
ment, the bag-of-words model and the graph-
based label propagation method.

2.1 Readability Assessment

Research on readability assessment has devel-
oped three types of methods: the readability for-
mula, the word-based methods and the feature-
based methods (Kincaid et al., 1975; Collins-
Thompson and Callan, 2004; Schwarm and Os-

411



tendorf, 2005). During the early time, many
well-known readability formulae have been devel-
oped to assess the readability of text documents
(Dale and Chall, 1948; McLaughlin, 1969; Kin-
caid et al., 1975). Surface text features are de-
fined in these formulae to measure both lexical
and grammatical complexities of a document. The
word-based methods focus on words and their fre-
quencies in a document to assess its readability,
which mainly include the unigram/bigram/n-gram
models (Collins-Thompson and Callan, 2004;
Schwarm and Ostendorf, 2005) and the word
acquisition model (Kidwell et al., 2009). The
feature-based methods focus on extracting text
features from a document and training a classifi-
cation model to classify its readability (Feng et
al., 2010; François and Fairon, 2012; Hancke et
al., 2012). Suitable text features are usually essen-
tial to the success of these methods. The Support
vector machine and logistic regression model are
two classification models commonly used in these
methods.

2.2 The Bag-of-Words Model
The bag-of-words model is mostly used for doc-
ument classification. It constructs a feature space
that contains all the distinct words in a language
(or the document set). A document is repre-
sented by a vector, whose components reflect the
weight of every distinct word contained in the doc-
ument. Normally, it assumes the words are inde-
pendent. Now the capturing of the relationship
among words has attracted considerable attention
(Wong et al., 1985; Cheng et al., 2013). Inspired
by these works, this paper adopts the bag-of-words
model in readability assessment, and refines the
model by computing similarity among words on
reading difficulty.

2.3 The Graph-based Label Propagation
Method

Graph-based label propagation is applied on a
graph to propagate class labels from labeled nodes
to unlabeled ones (Kim et al., 2013). It has been
successfully applied in various applications, such
as dictionary construction (Kim et al., 2013), word
segmentation and tagging (Zeng et al., 2013), and
sentiment classification (Ponomareva and Thel-
wall, 2012). Typically, a graph-based label propa-
gation method consists of two main steps: graph
construction and label propagation (Zeng et al.,
2013). During the first step, a similarity function

is required to build edges and compute weights
between pairs of the nodes (Daitch et al., 2009).
Some form of edge pruning is required to refine
the graph (Jebara et al., 2009). After that, effective
algorithms have been developed to propagate the
label distributions to all the nodes (Subramanya et
al., 2010; Kim et al., 2013).

3 The Proposed Method

In this section, we present GRAW (Graph-based
Readability Assessment method using Word cou-
pling), which constructs a coupled bag-of-words
model by exploiting the correlation of readabil-
ity among the words. Unlike the general bag-of-
words model which models document relationship
on topic, the coupled bag-of-words model extends
it to model the relationship among documents on
readability. In the following sections, we describe
in detail how to build the coupled bag-of-words
model. The model is then used in the graph-
based classification framework for readability as-
sessment.

3.1 The General Bag-of-Words Model
TF-IDF (Term Frequency and Inverse Document
Frequency) is the most popular scheme of the bag-
of-words model. Given the set of documents D,
the TF-IDF matrix M can be calculated based on
the logarithmically scaled term (i.e. word) fre-
quency (Salton and Buckley, 1988) as follows.

Mt,d = tft,d · idft,d
= (1 + log f(t, d)) · log |D||{d|t ∈ d}|

(1)

where f(t, d) is the number of times that a term
(word) t occurs in a document d ∈ D.
3.2 The Coupled Bag-of-Words Model
As shown in Figure 1, three main stages are
required to construct the coupled bag-of-words
model: per-sentence readability estimation, word
coupling matrix construction and coupled TF-IDF
matrix calculation. The following sections de-
scribe the details of these stages.

3.2.1 Per-Sentence Readability Estimation
Two steps are required for the per-sentence read-
ability estimation. The first is to compute a read-
ing score of a sentence by heuristic functions. The
second is to determine the difficulty level of the
sentence by discretizing the score.

412



Documents

 

Corpus

Extract 

documents

Calculate coupled 

TF-IDF matrix

Label the nodes

Estimate the 

readability of 

sentences

Construct word 

coupling  matrix

Construct      

TF-IDF matrix

Levels

 

Sentences

Levels

 

DocumentsTerms

T
e

rm
s

Label 

propagation

Documents

T
e

rm
s

Build graph

Documents

T
e

rm
s

Figure 1: The Framework of GRAW

Step 1. Given a sentence s, its reading diffi-
culty can be quantified as a reading score which is
a continuous variable denoted by r(s). The more
difficult s is, the greater r(s) will be. Based on
text features of s, r(s) can be computed by one of
the eight heuristic functions listed in Table 1 which
are grouped into three aspects.

Aspect Function Description

Surface

len(s) the length of the sentence s.

ans(s)
the average number of syllables (or strokes for
Chinese) per word (or character for Chinese) in
s.

anc(s) the average number of characters per word in s.

Lexical
lv(s)

the number of distinct types of POS, i.e. part of
speech, in s.

atr(s) the ratio of adjectives in s.
ntr(s) the ratio of nouns in s.

Syntatic
pth(s) the height of the syntax parser tree of s.

anp(s)
the average number of (noun, verb, and preposi-
tion) phrases in s.

Table 1: Three aspects of estimating reading diffi-
culty of sentences using heuristic functions

Step 2. Let η denote the pre-determined number
of difficulty levels, rmax and rmin denote the max-
imum and minimum reading score respectively of
all the sentences in D. To determine the difficulty
level l∗(s) (l∗(s) ∈ [1, η]) of a sentence s, the
range [rmin, rmax] is divided into η intervals, so
that each interval contains the reading scores of 1η
of all the sentences. The assumption is that all the
sentences are equally distributed among the diffi-
culty levels. l∗(s) will be i, if the reading score
r(s) resides in the i-th interval.

For each of the three aspects, we compute one
l∗(s) for a sentence s by combining the heuristic
functions using the following equations. The as-
sumption is that the reading difficulty of a sentence
may be determined by the maximum measure on
the text features.

lsur(s) = max [llen(s), lans(s), lanc(s)]

llex(s) = max [llv(s), latr(s), lntr(s)]

lsyn(s) = max [lpth(s), lanp(s)]

(2)

3.2.2 Word Coupling Matrix Construction
Let V denote the set of all the words, a word cou-
pling matrix is defined as C∗ ∈ R|V|×|V|, the ele-
ment of which reflects the correlation between two
words (i.e. terms). Two steps are required to con-
struct this matrix. The first is to count the difficulty
distributions of words, and the second is to com-
pute the correlation between each pair of words
according to the similarity of their difficulty dis-
tributions.

Step 1. Let S denote the set of all the sen-
tences, pt denote the difficulty distribution of a
word (term) t. pt is a vector containing η (i.e. the
number of difficulty levels) values, the i-th part of
which can be calculated by the following formula.

pt(i) =
1
nt
·
∑
s∈S

δ(t ∈ s) · δ(l∗(s) = i) (3)

where nt refers to the number of sentences in
which t appears. The indicator function δ(x) re-
turns 1 if x is true and 0 otherwise. l∗(s) refers to
one of the functions lsur(s), llex(s) or lsyn(s).

Step 2. Given two words (terms) t1 and
t2, whose level distributions are pt1 and pt2 re-
spectively, we measure the distribution difference
cKL(t1, t2) using the Kullback-Leibler divergence
(Kullback and Leibler, 1951), computed by the
following formula.

cKL(t1, t2) =
1
2

(KL(pt1 ||pt2) +KL(pt2 ||pt1))
(4)

where KL(p||q) = ∑i p(i) log p(i)q(i) . After that,
the logistic function is applied on the computed
difference to get the normalized distribution simi-
larity, i.e.

sim(t1, t2) =
2

1 + ecKL(t1,t2)
(5)

Given a word ti, only λ other words with high-
est correlation (similarity) are selected to build the

413



neighbor set of ti, denoted as N (ti). If a word tj
is not selected (i.e. tj /∈ N (ti)), the correspond-
ing sim(ti, tj) will be assigned 0. After that, the
word coupling matrix (i.e. C∗) with sim(ti, tj)
as elements is normalized along the rows so that
the sum of each row is 1. Based on three different
l∗(s), we construct three word coupling matrices
Csur, C lex and Csyn.

3.2.3 Coupled TF-IDF Matrix Calculation
In the general bag-of-words model, the words are
treated as independent of each other. However, for
readability assessment, words may be correlated
according to the similarity of their difficulty dis-
tributions. To improve the TF-IDF matrix M de-
scribed in Section 3.1, we multiply it by the word
coupling matrix C∗, so that the term frequencies
are shared among the highly correlated (coupled)
words. We denote the coupled TF-IDF matrix as
M∗, obtained by the following formula.

M∗ = C∗ ·M (6)

Specifically, three homogenous coupled TF-
IDF matrices M sur, M lex and M syn can be built
according to the three word coupling matrices C∗.

3.3 Graph-based Readability Assessment

We employ the coupled bag-of-words model for
readability assessment under the graph-based clas-
sification framework as described in the previ-
ous work (Zhu and Ghahramani, 2002). Firstly,
we construct a graph representing the readabil-
ity relationship among documents by using the
coupled bag-of-words model to compute the rela-
tions among these documents. Secondly, we esti-
mate reading levels of documents by applying la-
bel propagation on the graph.

3.3.1 Graph Construction
We build a directed graphG∗ to represent the read-
ability relation among documents, where nodes
represent documents, and edges are weighted by
the similarities between pairs of documents. Given
a similarity function, we link documents di to dj
with an edge of weight G∗ij , defined as:

G∗i,j =

{
sim(di, dj) if dj ∈ N (di)
0 otherwise

(7)

where N (di) is the set of k-nearest neighbors of
di determined by the similarity function.

common neighbors

candidate neighbors

0
2 0

4
1

v

3

Figure 2: Illustration of the graph merging strategy

Given the coupled matrix M∗ ∈ Rm×|D| which
maps each document into a m-dimension feature
space, the similarity function sim(di, dj) can be
defined by the Euclidean distance as follows.

sim(di, dj) =
1√∑m

k=1 (Mk,i −Mk,j)2 + �
(8)

where � is a small constant to avoid zero denomi-
nators.

Merge the three graphs Refer to Section 3.2,
the three coupled TF-IDF matrices will lead to
three different document graphs, denoted as Gsur,
Glex and Gsyn respectively. To take advantage of
the three aspects at one time, we need to merge the
three graphs into one, denoted as Gc.

In Gc, each node also keeps k neighbors, and
some edges shall be filtered out from the three
graphs. The basic idea is to remove edges con-
taining redundant information, as shown in Fig-
ure 2. For each node v, we firstly select the neigh-
bors which are common in all the three graphs (i.e.
N sur(v)∩N lex(v)∩N syn(v)). Secondly, for the
rest candidate nodes, which are the neighbors of
v in at least one graph, we select one by one the
node which possesses the least number of com-
mon neighbors (from all the three graphs) with the
nodes that are already selected in N c(v). The ob-
jective is to keep the number of triangles in Gc to
a minimum. The edge weights of Gc are averaged
on the corresponding edges appeared in the three
graphs.

Combine with the feature-based graph Previ-
ous studies usually extract text features from doc-
uments to assess the readability using classifica-
tion models. Here, we also take into consideration
the feature-based graph, where similarities among
documents are computed on text features. We use
the features defined in (Jiang et al., 2014), where
the model based features are eliminated since the

414



computation depends on pre-assigned class labels,
and represent a document as a vector of the feature
values. We compute the similarity between any
pair of documents using the Euclidean distance,
and built the feature-based graph (denoted as Gf )
in the same way as above.

Additionally, to take advantage of both graphs,
we combine them into one (denoted as Gcf ) using
the following formula.

Gcfi,j = max [G
c
i,j , G

f
i,j ] (9)

3.3.2 Graph Propagation
Given a graphG∗ constructed in previous sections,
its nodes are divided into two sets: the labeled set
Vl and the unlabeled set Vu. The goal of label
propagation is to propagate class labels from the
labeled nodes (i.e. documents) to the entire graph.
Here, we use a simplified version of the label prop-
agation method presented in (Subramanya et al.,
2010), which has been proved effective (Kim et
al., 2013). The method iteratively updates the la-
bel distribution on a document node using the fol-
lowing equation.

p
(i)
d (l) =

1

κd

p0d(l)δ(d ∈ Vl) + ∑
v∈N(d)

Gd,vp
(i−1)
v (l)

 (10)
At the left side of Eq.10, p(i)d (l) is the afterward
probability of l (i.e. the class label) on a node d at
the i-th iteration. At the right side, κd is the nor-
malizing constant to make sure the sum of all the
probabilities is 1, and p0d(l) is the initial probabil-
ity of l on d if d is initially labeled (i.e. belonging
to the labeled set Vl). δ(x) is the indicator func-
tion. N (d) denotes the set of neighbors of d. The
iteration stops when the changes in p(i)d (l) for all
the nodes and label values are small enough (e.g.
less than e−3), or i exceeds a predefined number
(e.g. greater than 30).

4 Empirical Studies

In this section, we conduct experiments on
datasets of both English and Chinese, to investi-
gate the following three research questions:

RQ1: Whether the proposed method (i.e.
GRAW) outperforms the state-of-the-art methods
for readability assessment?

RQ2: What are the effects of adding the
word coupling matrix to the general bag-of-words
model?

RQ3: Whether the graph merging strategy is
effective, and whether the performance can be

further improved by combining the feature-based
graph.

4.1 Corpus and Metrics

To evaluate our proposed method, we collected
two datasets. The first is CPT (Chinese primary
textbook) (Jiang et al., 2014), which contains Chi-
nese documents of six reading levels. The second
is ENCT (English New Concept textbook) which
contains English documents of four reading levels.
Both datasets are built from well-known textbooks
where documents are labeled as grade levels by
credible educationists. The details of the datasets
are listed in Table 2.

Dataset Language #Grade #Doc #Sent #Word
CPT Chinese 6 637 16145 234372

ENCT English 4 279 4671 62921

Table 2: Statistics of the datasets on both English
and Chinese

We conduct experiments on both datasets us-
ing the cross-validation which randomly divides a
dataset into labeled (training) and unlabeled (test)
sets. The labeling proportion is varied to inves-
tigate the performance of GRAW under differ-
ent circumstances. To reduce variability, given
certain labeling proportion, 100 rounds of cross-
validation are performed, and the validation re-
sults are averaged over all the rounds. We choose
the precision (P), recall (R) and F1-measure (F1)
as the performance metrics.

4.2 Comparison to the State-of-the-Art
Methods

To address RQ1, we implement the follow-
ing readability assessment methods and compare
GRAW to them: (1) SMOG (McLaughlin, 1969)
and FK (Kincaid et al., 1975) are two widely used
readability formulae. We reserve their core mea-
sures (i.e. text features, and number of strokes for
Chinese instead of number of syllables), and refine
the coefficients on both datasets to befit the read-
ing (grade) levels. (2) SUM (Collins-Thompson
and Callan, 2004) is a word-based method, which
trains one unigram model for each grade level, and
applies model smoothing both inter and intra the
grade levels. (3) LR and SVM refer to two feature-
based methods which incorporate text features de-
fined in (Jiang et al., 2014) to represent documents
as instances. The logistic regression model and

415



Dataset Level Metric MethodsSMOG FK SUM LR SVM GRAWc GRAWcf

CPT (Chinese)

Gr.1
P 57.48 74.07 71.76 71.87 73.18 73.26 75.29
R 17.31 9.69 36.31 71.17 67.28 73.28 83.17
F1 26.14 15.25 47.67 71.23 69.70 72.98 78.89

Gr.2
P 34.73 31.44 37.94 51.62 50.78 52.05 55.83
R 31.06 28.00 29.73 56.48 59.45 57.36 66.06
F1 32.66 29.42 33.13 53.67 54.53 54.40 60.37

Gr.3
P 20.05 20.79 28.12 44.15 48.89 46.33 51.72
R 58.84 75.53 25.06 43.94 49.94 58.59 68.41
F1 29.89 32.40 26.35 43.72 49.04 51.57 58.74

Gr.4
P 25.06 28.94 25.60 33.35 33.92 39.90 44.15
R 41.06 31.82 28.76 31.82 33.64 35.42 28.88
F1 31.03 29.69 26.91 32.24 33.58 37.32 34.57

Gr.5
P 33.57 45.00 28.71 37.70 37.30 45.02 37.33
R 4.00 2.71 34.41 36.12 34.29 27.12 19.00
F1 7.02 4.95 31.10 36.61 35.47 33.35 24.45

Gr.6
P 0.00 6.67 32.21 40.47 46.53 45.91 44.24
R 0.00 0.35 45.81 39.03 43.48 51.81 54.06
F1 0.00 0.67 37.55 39.48 44.65 48.38 48.15

Avg.
P 28.48 34.48 37.39 46.53 48.43 50.41 51.43
R 25.38 24.68 33.35 46.43 48.01 50.60 53.26
F1 21.12 18.73 33.78 46.16 47.83 49.67 50.86

ENCT (English)

Gr.1
P 54.65 60.79 96.59 88.60 90.74 95.42 95.53
R 67.50 73.50 84.77 89.32 85.45 83.77 83.95
F1 60.18 66.36 90.09 88.64 87.76 89.01 89.18

Gr.2
P 50.11 56.23 78.30 85.51 90.80 88.60 89.03
R 59.28 63.93 35.07 86.07 92.86 96.76 96.86
F1 54.17 59.69 48.11 85.54 91.68 92.42 92.70

Gr.3
P 29.49 32.09 40.53 88.31 89.08 85.36 89.73
R 24.22 26.94 68.33 86.17 84.78 94.17 96.56
F1 26.40 29.15 50.77 86.94 86.16 89.40 92.92

Gr.4
P 85.73 94.00 69.30 89.79 81.20 91.70 95.26
R 14.64 18.21 97.64 87.07 85.21 77.93 85.36
F1 24.06 29.46 80.81 88.02 81.79 83.84 89.81

Avg.
P 55.00 60.78 71.18 88.05 87.95 90.27 92.39
R 41.41 45.65 71.45 87.16 87.08 88.16 90.68
F1 41.20 46.16 67.44 87.28 86.85 88.67 91.15

Table 3: The average Precision, Recall and F1-measure (%) per reading level of the seven methods for
readability assessment on both datasets when the labeling proportion is 0.7

support vector machine are used as the classifiers
respectively.

For GRAW, we implement label propagation on
both the merged graph Gc and the final graph Gcf

(Section 3.3), denoted as GRAWc and GRAWcf
respectively. Table 3 gives the average perfor-
mance measure per reading level resulted by the
implemented methods on both datasets. Unless
otherwise specified, we fixed η to 3, and λ to 2800
for CPT and 2000 for ENCT. The proportion of
the labeled (training) set is set to 0.7.

In Table 3, the precision, recall and F1-measure
of all the seven methods are calculated per read-
ing (grade) level on both English and Chinese
datasets. The values marked in bold in each row
refer to the maximum (best) measure gained by
the methods.

From Table 3, the readability formulae (SMOG
and FK) perform poorly on either the precision
or recall measure, and their F1-measure values
are generally the poorest. Both SMOG and FK
are designed for English, and have acceptable per-
formance on the English dataset ENCT. The un-
igram model (SUM) performs a little better than
the readability formulae. On ENCT, It has rel-
atively good performance on grade levels 1 and
4, while on the Chinese dataset CPT, the perfor-
mance is not satisfactory. The feature-based meth-
ods (LR and SVM) perform well on both ENCT

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0.1

0.2

0.3

0.4

0.5

0.6

Proportion of the labeled set

F
1
−

m
e
a
s
u
re

 (
C

h
in

e
s
e
)

SMOG

FK

SUM

SVM

LR

GRAW
c

GRAW
cf

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Proportion of the labeled set

F
1
−

m
e
a
s
u
re

 (
E

n
g
lis

h
)

SMOG

FK

SUM

SVM

LR

GRAW
c

GRAW
cf

Figure 3: The average F1-measure of the seven
methods on both datasets with the labeling pro-
portion varied from 0.1 to 0.9

and CPT, which means both the text features de-
veloped and the classifiers trained are useful. In
general, GRAWc performs better than both LR and
SVM, which demonstrates the effectiveness of our
method. In addition, by combining the feature-
based graph (GRAWcf ), GRAW can be improved,
and performs the best on all the three metrics over
the majority of reading levels on both datasets.
The only exception is on level 5 in CPT, which
suggests the requirement of further improvements.

We study the effect of labeling proportion on the
performance of these methods on both datasets.
The F1-measure averaged over the reading levels
is used, since it is a good representative of the three
metrics according to Table 3. Figure 3 depicts the
performance trends of all the methods.

From Figure 3, neither SMOG nor FK benefits

416



0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0

0.1

0.2

0.3

0.4

0.5

0.6

Proportion of the labeled set

F
1
−

m
e
a
s
u
re

 (
C

h
in

e
s
e
)

TF−IDF

M
sur

M
lex

M
syn

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0.65

0.7

0.75

0.8

0.85

0.9

Proportion of the labeled set

F
1
−

m
e
a
s
u
re

 (
E

n
g
lis

h
)

TF−IDF

M
sur

M
lex

M
syn

(a) Comparison of the average F1-measure between the cou-
pling and general TF-IDF matrices

G1
G2

G3
G4

G5
G6

0

0.2

0.4

0.6

0.8

1

Msyn

Graph

Mlex

Msur

TF−IDF

R
e
c
a
ll 

(C
h
in

e
s
e
)

Reading level

G1

G2

G3

G4

0

0.2

0.4

0.6

0.8

1

Msyn

Graph

Mlex

Msur

TF−IDF

R
e
c
a
ll 

(E
n
g
lis

h
)

Reading level

(b) Comparison of the Recall rate per reading level between
the coupling and general TF-IDF matrices

400 800 1200 1600 2000 2400 2800 3200 3600 4000
0.35

0.375

0.4

0.425

0.45

0.475

0.5

Number of neighbors (λ)

F
1
−

m
e
a
s
u
re

 (
C

h
in

e
s
e
)

η=2

η=3

η=4

η=5

η=6

η=7

η=8

η=9

200 400 600 800 1000 1200 1400 1600 1800 2000
0.76

0.78

0.8

0.82

0.84

0.86

0.88

0.9

Number of neighbors (λ)

F
1
−

m
e
a
s
u
re

 (
E

n
g
lis

h
)

η=2

η=3

η=4

η=5

η=6

η=7

η=8

η=9

(c) The effects of η and λ on the performance of the word
coupling matrix

0 10 20 30 40 50 60 70 80
0

0.1

0.2

0.3

0.4

0.5

Ratio of removed documents

F
1
−

m
e
a
s
u
re

 (
C

h
in

e
s
e
)

M
syn

0 10 20 30 40 50 60 70 80
0.65

0.7

0.75

0.8

0.85

0.9

Ratio of removed documents

F
1
−

m
e
a
s
u
re

 (
E

n
g
lis

h
)

M
syn

(d) The effect of corpus size on the performance of the word
coupling matrix

Figure 4: Four perspectives on the effectiveness of the word coupling matrices

from the increasing size of the labeled set. This
suggests that the performance of the readability
formulae can hardly be improved by accumulat-
ing training data. The other 5 methods achieve
better performance on larger labeled set, and out-
perform the two formulae even if the labeling pro-
portion is small. Both LR and SVM perform bet-
ter than SUM, but the performance is not good
when the labeling proportion is less than 0.3, es-
pecially on the Chinese dataset. On the Chinese
dataset, SVM performs better than LR, while on
the English dataset, the situation is reversed. Both
versions of GRAW outperform the other methods
over the labeling ranges on both datasets. In ad-
dition, GRAW performs well when the labeling
proportion is still small. Again, by combining the
feature-based graph, the performance of GRAW is
consistently improved.

In summary, GRAW can outperform the state-
of-the-art methods for readability assessment on
both English and Chinese datasets. By combin-
ing the feature-based graph, the performance of
GRAW can be further improved.

4.3 Effects of the Word Coupling Matrix

For RQ2, we firstly compare the coupled bag-of-
words model to the general model in the process
of graph construction. Four graphs are built by us-
ing each of the three word coupling matrices (i.e.
M sur, M lex and M syn) and the TF-IDF matrix

respectively. Label propagation is applied on each
graph to predict reading levels of unlabeled docu-
ments. The labeling proportion is varied from 0.1
to 0.9 on both the English and Chinese datasets.
Figure 4(a) depicts the average F1-measure re-
sulted from the four graphs.

From Figure 4(a), the three word coupling ma-
trices greatly outperform the TF-IDF matrix, espe-
cially on the Chinese dataset. This demonstrates
that the word coupling matrices are very effective
in improving the performance of the general bag-
of-words model for readability assessment.

Secondly, we investigate the performance of the
four matrices per reading level. Figure 4(b) de-
picts the recall rate per reading level of the four
corresponding graphs in bar charts. The labeling
proportion is set to 0.7. The recall rate is used
because it makes the reason evident that the TF-
IDF matrix performs poorly. From Figure 4(b), on
the Chinese dataset, nearly all the unlabeled docu-
ments are classified as level 1 by the TF-IDF ma-
trix, in which the word frequencies are too few to
make meaningful discrimination among the read-
ing levels. On the English dataset, the TF-IDF
matrix performs better, but still prefers to classify
documents into lower levels.

As described in Section 3.2.2, η (the number of
difficulty levels of sentences) and λ (the number
of neighbors pertained for each document node)
are two parameters in building the word coupling

417



matrices. To investigate their effects on the per-
formance of the built matrices, we vary the val-
ues of both η and λ, and compute the average F1-
measure on the two datasets. Figure 4(c) depicts
the results in line charts, where η varies from 2 to 9
step by 1, while λ varies from 400 to 4000 step by
400 on Chinese and from 200 to 2000 step by 200
on English (the difference is due to the dissimilar
number of documents between the two datasets).
The three word coupling matrices exhibit similar
behavior during experiments, hence, only M syn is
depicted.

From Figure 4(c), a small η (e.g. 2 or 3) is good
on the Chinese dataset. However, on the English
dataset, η = 2 leads to the poorest performance. It
seems the increasing of η causes vibrated perfor-
mance, and the trend is further complicated when
involving λ. Above all, η = 3 gives a prefer-
able option on both datasets. For λ, most of the
lines exhibit a similar trend that rises first and then
keeps stable on both datasets, although some may
drop when λ is too large. This suggests that mak-
ing a relatively large number of the other words as
the neighbors of one (i.e. λ = 2800 on the Chi-
nese dataset and λ = 2000 on the English dataset)
will make an effective word coupling matrix.

The word coupling matrix constructed in
GRAW uses the whole corpus on either English
or Chinese. To investigate if the corpus size takes
effects on the performance of GRAW, we vary
the proportion of the corpus used by randomly re-
moving documents from each reading level. Fig-
ure 4(d) depicts the average F1-measure resulted
by M syn. The removing ratio is selected from
{0, 0.05, 0.1, 0.2, 0.4, 0.8}. Both the mean values
and deviations are shown on the line chart.

From Figure 4(d), on the Chinese dataset, the
performance of GRAW suffers little from remov-
ing documents, even if only 20% documents are
left for building the word coupling matrix. How-
ever, on the English dataset, the mean perfor-
mance drops sharply and the deviation increases
evidently. This suggests that cumulating sufficient
corpus is required for building a suitable word
coupling matrix in GRAW, and factors other than
number of documents may influence the corpus
quality, which deserves further study.

In summary, the word coupling matrix plays an
essential role in GRAW. For building a suitable
word coupling matrix, the number of difficulty
levels of sentences (η) can be set to 3, and a rel-

atively large number of the other words should be
selected as the neighbors of a word. A sufficient
corpus is required for refining the matrix.

4.4 Effectiveness of Graph Combination
For RQ3, we compare graphs built on each sin-
gular word coupling matrix (i.e. M sur, M lex and
M syn) to the merged graph (i.e. GRAWc) and the
combined graph (i.e. GRAWcf ). Figure 5 depicts
the average F1-measure resulted after applying la-
bel propagation on these graphs with labeling pro-
portion varied from 0.1 to 0.9. The feature-based
graph (i.e. Gf ) is also depicted for comparison.

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0.3

0.35

0.4

0.45

0.5

0.55

Proportion of the labeled set

F
1
−

m
e
a
s
u
re

 (
C

h
in

e
s
e
)

M
sur

M
lex

M
syn

G
f

GRAW
c

GRAW
cf

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0.7

0.75

0.8

0.85

0.9

Proportion of the labeled set

F
1
−

m
e
a
s
u
re

 (
E

n
g
lis

h
)

M
sur

M
lex

M
syn

G
f

GRAW
c

GRAW
cf

Figure 5: The average F1-measure of differ-
ent types of graphs on the English and Chinese
datasets

From Figure 5, the merged graph GRAWc out-
performs the three basic graphs on both datasets
in most cases. Within the three, M syn performs
best, especially on the English dataset, where it
can outperform GRAWc slightly when the label-
ing proportion is small (0.2− 0.4). By combining
the feature-based graph, GRAWcf performs even
better on both datasets, although Gf performs
poorest among all the graphs. In summary, the
graph merging strategy is effective, and by com-
bining the feature-based graph, the performance
of GRAW can be improved. This demonstrates the
potential of GRAW.

5 Conclusion

In this paper, we propose a graph-based readabil-
ity assessment method using word coupling. The
coupled bag-of-words model is designed, which
exploits the correlation of readability among the
words, and by applying TF-IDF, models the rela-
tionship among documents on reading levels. The
model is employed in the graph-based classifica-
tion framework for readability assessment, which
involves graph building, merging, and label prop-
agation. Experiments are conducted on both Chi-
nese and English datasets. The results show that
our method can outperform the commonly used

418



methods for readability assessment. In addition,
the evaluation demonstrates the potential of the
coupled bag-of-words model and the graph com-
bination/merging strategies.

In our future work, we plan to verify the sound-
ness of the results by applying our method on large
volume corpus of both English and Chinese. In ad-
dition, we will investigate other ways of comput-
ing the word coupling matrices, such as incorpo-
rating word coherency or semantics, and develop
efficient merging strategies which can be used for
training classification models, as well as for build-
ing graphs.

Acknowledgments

This work was supported by the National NSFC
projects under Grant Nos. 61373012, 61321491,
and 91218302.

References
Rebekah George Benjamin. 2012. Reconstructing

readability: Recent developments and recommenda-
tions in the analysis of text difficulty. Educational
Psychology Review, 24(1):63–88.

Xin Cheng, Duoqian Miao, Can Wang, and Longbing
Cao. 2013. Coupled term-term relation analysis for
document clustering. In Proceedings of the 2013
International Joint Conference on Neural Networks,
pages 1–8. IEEE.

Kevyn Collins-Thompson and James P Callan. 2004.
A language modeling approach to predicting reading
difficulty. In Proceedings of the 2004 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 193–200. Association for Computa-
tional Linguistics.

Samuel I Daitch, Jonathan A Kelner, and Daniel A
Spielman. 2009. Fitting a graph to vector data.
In Proceedings of the 26th Annual International
Conference on Machine Learning, pages 201–208.
ACM.

Edgar Dale and Jeanne S. Chall. 1948. A formula for
predicting readability. Educational Research Bul-
letin, 27(1):11–28.

Lijun Feng, Martin Jansche, Matt Huenerfauth, and
Noémie Elhadad. 2010. A comparison of features
for automatic readability assessment. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics: Posters, pages 276–284. As-
sociation for Computational Linguistics.

Thomas François and Cédrick Fairon. 2012. An ai
readability formula for french as a foreign language.
In Proceedings of the 2012 Joint Conference on

Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning,
pages 466–477. Association for Computational Lin-
guistics.

Itziar Gonzalez-Dios, Marıa Jesús Aranzabe,
Arantza Dıaz de Ilarraza, and Haritz Salaberri.
2014. Simple or complex? assessing the readability
of basque texts. In Proceedings of the 25th Inter-
national Conference on Computational Linguistics,
pages 334–344. Association for Computational
Linguistics.

Julia Hancke, Sowmya Vajjala, and Detmar Meurers.
2012. Readability classification for german using
lexical, syntactic, and morphological features. In
Proceedings of the 24th International Conference on
Computational Linguistics, pages 1063–1080. Asso-
ciation for Computational Linguistics.

Tony Jebara, Jun Wang, and Shih-Fu Chang. 2009.
Graph construction and b-matching for semi-
supervised learning. In Proceedings of the 26th An-
nual International Conference on Machine Learn-
ing, pages 441–448. ACM.

Zhiwei Jiang, Gang Sun, Qing Gu, and Daoxu Chen.
2014. An ordinal multi-class classification method
for readability assessment of chinese documents. In
Knowledge Science, Engineering and Management,
pages 61–72. Springer.

Paul Kidwell, Guy Lebanon, and Kevyn Collins-
Thompson. 2009. Statistical estimation of word ac-
quisition with application to readability prediction.
In Proceedings of the 2009 Conference on Empiri-
cal Methods in Natural Language Processing, pages
900–909. Association for Computational Linguis-
tics.

Doo Soon Kim, Kunal Verma, and Peter Z Yeh. 2013.
Joint extraction and labeling via graph propaga-
tion for dictionary construction. In Proceedings of
the 27th AAAI Conference on Artificial Intelligence,
pages 510–517.

J Peter Kincaid, Robert P Fishburne Jr, Richard L
Rogers, and Brad S Chissom. 1975. Derivation of
new readability formulas (automated readability in-
dex, fog count and flesch reading ease formula) for
navy enlisted personnel. Technical report, Naval Air
Station, Memphis, TN.

Solomon Kullback and Richard A Leibler. 1951. On
information and sufficiency. The annals of mathe-
matical statistics, 22(1):79–86.

G Harry McLaughlin. 1969. Smog grading: A new
readability formula. Journal of reading, 12(8):639–
646.

Natalia Ponomareva and Mike Thelwall. 2012. Do
neighbours help?: an exploration of graph-based al-
gorithms for cross-domain sentiment classification.
In Proceedings of the 2012 Joint Conference on

419



Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning,
pages 655–665. Association for Computational Lin-
guistics.

Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval. In-
formation processing and management, 24(5):513–
523.

Sarah E Schwarm and Mari Ostendorf. 2005. Read-
ing level assessment using support vector machines
and statistical language models. In Proceedings of
the 43rd Annual Meeting on Association for Com-
putational Linguistics, pages 523–530. Association
for Computational Linguistics.

Amarnag Subramanya, Slav Petrov, and Fernando
Pereira. 2010. Efficient graph-based semi-
supervised learning of structured tagging models.
In Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing, pages
167–176. Association for Computational Linguis-
tics.

S. K. Michael Wong, Wojciech Ziarko, and P. C. N.
Wong. 1985. Generalized vector space model in
information retrieval. In Proceedings of the 8th An-
nual International ACM SIGIR Conference on Re-
search and Development in Information Retrieval,
pages 18–25. ACM.

Beverley L. Zakaluk and S. Jay Samuels. 1988. Read-
ability: Its Past, Present, and Future. ERIC.

Xiaodong Zeng, Derek F Wong, Lidia S Chao, and Is-
abel Trancoso. 2013. Graph-based semi-supervised
model for joint chinese word segmentation and part-
of-speech tagging. In Proceeding of the 51st Annual
Meeting of the Association for Computational Lin-
guistics, pages 770–779. Association for Computa-
tional Linguistics.

Xiaojin Zhu and Zoubin Ghahramani. 2002. Learn-
ing from labeled and unlabeled data with label prop-
agation. Technical Report CMU-CALD-02-107,
Carnegie Mellon University.

420


