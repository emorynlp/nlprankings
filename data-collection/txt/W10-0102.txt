










































Active Semi-Supervised Learning for Improving Word Alignment


Proceedings of the NAACL HLT 2010 Workshop on Active Learning for Natural Language Processing, pages 10–17,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

Active Semi-Supervised Learning for Improving Word Alignment

Vamshi Ambati, Stephan Vogel and Jaime Carbonell
{vamshi,vogel,jgc}@cs.cmu.edu

Language Technologies Institute, Carnegie Mellon University
5000 Forbes Avenue, Pittsburgh, PA 15213, USA

Abstract

Word alignment models form an important
part of building statistical machine transla-
tion systems. Semi-supervised word align-
ment aims to improve the accuracy of auto-
matic word alignment by incorporating full
or partial alignments acquired from humans.
Such dedicated elicitation effort is often ex-
pensive and depends on availability of bilin-
gual speakers for the language-pair. In this
paper we study active learning query strate-
gies to carefully identify highly uncertain or
most informative alignment links that are pro-
posed under an unsupervised word alignment
model. Manual correction of such informative
links can then be applied to create a labeled
dataset used by a semi-supervised word align-
ment model. Our experiments show that using
active learning leads to maximal reduction of
alignment error rates with reduced human ef-
fort.

1 Introduction

The success of statistical approaches to Machine
Translation (MT) can be attributed to the IBM mod-
els (Brown et al., 1993) that characterize word-
level alignments in parallel corpora. Parameters of
these alignment models are learnt in an unsupervised
manner using the EM algorithm over sentence-level
aligned parallel corpora. While the ease of auto-
matically aligning sentences at the word-level with
tools like GIZA++ (Och and Ney, 2003) has enabled
fast development of statistical machine translation
(SMT) systems for various language pairs, the qual-
ity of alignment is typically quite low for language

pairs that diverge from the independence assump-
tions made by the generative models. Also, an im-
mense amount of parallel data enables better estima-
tion of the model parameters, but a large number of
language pairs still lack parallel data.

Two directions of research have been pursued for
improving generative word alignment. The first is to
relax or update the independence assumptions based
on more information, usually syntactic, from the
language pairs (Cherry and Lin, 2006). The sec-
ond is to use extra annotation, typically word-level
human alignment for some sentence pairs, in con-
junction with the parallel data to learn alignment in
a semi-supervised manner. Our research is in the
direction of the latter, and aims to reduce the effort
involved in hand-generation of word alignments by
using active learning strategies for careful selection
of word pairs to seek alignment.

Active learning for MT has not yet been explored
to its full potential. Much of the literature has ex-
plored one task – selecting sentences to translate
and add to the training corpus (Haffari et al., 2009).
In this paper we explore active learning for word
alignment, where the input to the active learner is
a sentence pair (sJ1 , t

I
1), present in two different lan-

guages S = {s∗} and T = {t∗}, and the annotation
elicited from human is a set of links {(j, i) : j =
0 · · · J ; i = 0 · · · I}. Unlike previous approaches,
our work does not require elicitation of full align-
ment for the sentence pair, which could be effort-
intensive. We use standard active learning query
strategies to selectively elicit partial alignment infor-
mation. This partial alignment information is then
fed into a semi-supervised word aligner which per-

10



forms an improved word alignment over the entire
parallel corpus.

Rest of the paper is organized as follows. We
present related work in Section 2. Section 3 gives
an overview of unsupervised word alignment mod-
els and its semi-supervised improvisation. Section 4
details our active learning framework with discus-
sion of the link selection strategies in Section 5. Ex-
periments in Section 6 have shown that our selection
strategies reduce alignment error rates significantly
over baseline. We conclude with discussion on fu-
ture work.

2 Related Work

Semi-supervised learning is a broader area of Ma-
chine Learning, focusing on improving the learn-
ing process by usage of unlabeled data in conjunc-
tion with labeled data (Chapelle et al., 2006). Many
semi-supervised learning algorithms use co-training
framework, which assumes that the dataset has mul-
tiple views, and training different classifiers on a
non-overlapping subset of these features provides
additional labeled data (Zhu, 2005). Active query
selection for training a semi-supervised learning al-
gorithm is an interesting method that has been ap-
plied to clustering problems. Tomanek and Hahn
(2009) applied active semi supervised learning to
the sequence-labeling problem. Tur et al. (2005) de-
scribe active and semi-supervised learning methods
for reducing labeling effort for spoken language un-
derstanding. They train supervised classification al-
gorithms for the task of call classification and apply
it to a large unlabeled dataset to select the least con-
fident instances for human labeling.

Researchers have begun to explore semi-
supervised word alignment models that use both
labeled and unlabeled data. Fraser and Marcu
(2006) pose the problem of alignment as a search
problem in log-linear space with features coming
from the IBM alignment models. The log-linear
model is trained on the available labeled data
to improve performance. They propose a semi-
supervised training algorithm which alternates
between discriminative error training on the la-
beled data to learn the weighting parameters and
maximum-likelihood EM training on unlabeled
data to estimate the parameters. Callison-Burch et

al. (2004) also improve alignment by interpolating
human alignments with automatic alignments. They
observe that while working with such datasets,
alignments of higher quality should be given a much
higher weight than the lower-quality alignments.
Wu et al. (2006) learn separate models from labeled
and unlabeled data using the standard EM algo-
rithm. The two models are then interpolated as a
learner in the semi-supervised AdaBoost algorithm
to improve word alignment.

Active learning has been applied to various fields
of Natural Language Processing like statistical pars-
ing, entity recognition among others (Hwa, 2004;
Tang et al., 2001; Shen et al., 2004). In case of
MT, the potential of active learning has remained
largely unexplored. For Statistical Machine Transla-
tion, application of active learning has been focused
on the task of selecting the most informative sen-
tences to train the model, in order to reduce cost
of data acquisition. Recent work in this area dis-
cussed multiple query selection strategies for a Sta-
tistical Phrase Based Translation system (Haffari et
al., 2009). Their framework requires source text to
be translated by the system and the translated data
is used in a self-training setting to train MT models.
To our knowledge, we are not aware of any work
that has looked at reducing human effort by selec-
tive elicitation of alignment information using active
learning techniques.

3 Word Alignment

3.1 IBM models
IBM models provide a generative framework for
performing word alignment of parallel corpus.
Given two strings from source and target languages
sJ1 = s1, · · · , sj , · · · sJ and tI1 = t1, · · · , ti, · · · tI ,
an alignment A is defined as a subset of the Carte-
sian product of the word indices as shown in Eq 1.
In IBM models, since alignment is treated as a func-
tion, all the source positions must be covered exactly
once (Brown et al., 1993).

A ⊆ {(j, i) : j = 0 · · · J ; i = 0 · · · I} (1)

For the task of translation, we would ideally want
to model P (sI1|tJ1 ), which is the probability of ob-
serving source sentence sI1 given target sentence t

J
1 .

This requires a lot of parallel corpus for estimation

11



and so it is then factored over the word alignment
A for the sentence pair, which is a hidden variable.
Word alignment is therefore a by-product in the pro-
cess of modeling translation. We can also represent
the same under some parameterization of θ, which
is the model we are interested to estimate.

P (sJ1 |tI1) =
∑
aJ1

Pr(sJ1 , A|tJ1 ) (2)

=
∑
A

pθ(sJ1 , A|tI1) (3)

Given a parallel corpus U of sentence pairs
{(sk, tk) : k = 1, · · · ,K} the parameters can be
estimated by maximizing the conditional likelihood
over the data. IBM models (Brown et al., 1993) from
1 to 5 are different ways of factoring the probability
model to estimate the parameter set θ. For example
in the simplest of the models, IBM model 1, only the
lexical translation probability is considered treating
each word being translated independent of the other
words.

θ̂ = arg max
θ

K∏
k=1

∑
A

pθ(sk, A|tk) (4)

The parameters of the model above are estimated
as θ̂, using the EM algorithm. We can also extract
the Viterbi alignment ,Â, for all the sentence pairs,
which is the alignment with the highest probability
under the current model parameters θ:

Â = arg max
A

pθ̂(s
J
1 , A|tI1) (5)

The alignment models are asymmetric and dif-
fer with the choice of translation direction. We can
therefore perform the above after switching the di-
rection of the language pair and obtain models and
Viterbi alignments for the corpus as represented be-
low:

θ̂ = arg max
θ

K∏
k=1

∑
a

pθ(tk, a|sk) (6)

Â = arg max
A

pθ̂(t
I
1, A|sJ1 ) (7)

Given the Viterbi alignment for each sentence
pair in the parallel corpus, we can also compute the
word-level alignment probabilities using simple rel-
ative likelihood estimation for both the directions.

As we will discuss in Section 5, the alignments and
the computed lexicons form an important part of our
link selection strategies.

P (sj/ti) =
∑

s count(ti, sj ; Â)∑
s count(ti)

(8)

P (ti/sj) =
∑

s count(ti, sj ; Â)∑
s count(sj)

(9)

We perform all our experiments on a symmetrized
alignment that combines the bidirectional align-
ments using heuristics as discussed in (Koehn et al.,
2007). We represent this alignment as A = {aij :
i = 0 · · · J ∈ sJ1 ; j = 0 · · · I ∈ tI1}.

3.2 Semi-Supervised Word Alignment
We use an extended version of MGIZA++ (Gao
and Vogel, 2008) to perform the constrained semi-
supervised word alignment. To get full benefit
from the manual alignments, MGIZA++ modifies all
alignment models used in the standard training pro-
cedure, i.e. the IBM1, HMM, IBM3 and IBM4 mod-
els. Manual alignments are incorporated in the EM
training phase of these models as constraints that
restrict the summation over all possible alignment
paths. Typically in the EM procedure for IBM mod-
els, the training procedure requires for each source
sentence position, the summation over all positions
in the target sentence. The manual alignments al-
low for one-to-many alignments and many-to-many
alignments in both directions. For each position i
in the source sentence, there can be more than one
manually aligned target word. The restricted train-
ing will allow only those paths, which are consistent
with the manual alignments. Therefore, the restric-
tion of the alignment paths reduces to restricting the
summation in EM.

4 Active Learning for Word Alignment

Active learning attempts to optimize performance
by selecting the most informative instances to la-
bel, where ‘informativeness’ is defined as maximal
expected improvement in accuracy. The objective
is to select optimal instance for an external expert
to label and then run the learning method on the
newly-labeled and previously-labeled instances to
minimize prediction or translation error, repeating
until either the maximal number of external queries

12



is reached or a desired accuracy level is achieved.
Several studies (Tong and Koller, 2002; Nguyen
and Smeulders, 2004; Donmez and Carbonell, 2008)
show that active learning greatly helps to reduce the
labeling effort in various classification tasks.

We discuss our active learning setup for word
alignment in Algorithm 1. We start with an un-
labeled dataset U = {(Sk, Tk)}, indexed by k,
and a seed pool of partial alignment links A0 =
{akij , ∀si ∈ Sk, tj ∈ Tk}. Each akij represents an
alignment link from a sentence pair k that connects
source word si with tj .

This is usually an empty set at iteration t = 0. We
iterate for T iterations. We take a pool-based active
learning strategy, where we have access to all the au-
tomatically aligned links and we can score the links
based on our active learning query strategy. The
query strategy uses the automatically trained align-
ment model θt from the current iteration t, for scor-
ing the links. Re-training and re-tuning an SMT sys-
tem for each link at a time is computationally infea-
sible. We therefore perform batch learning by se-
lecting a set of N links scored high by our query
strategy. We seek manual corrections for the se-
lected links and add the alignment data to the cur-
rent labeled dataset. The word-level aligned labeled
dataset is then provided to our semi-supervised word
alignment algorithm, which uses it to produces the
alignment model θt+1 for U .

Algorithm 1 AL FOR WORD ALIGNMENT
1: Unlabeled Data Set: U = {(sk, tk)}
2: Manual Alignment Set : A0 = {akij ,∀si ∈
Sk, tj ∈ Tk}

3: Train Semi-supervised Word Alignment using
(U , A0)→ θ0

4: N : batch size
5: for t = 0 to T do
6: Lt = LinkSelection(U ,At,θt,N )
7: Request Human Alignment for Lt
8: At+1 = At + Lt
9: Re-train Semi-Supervised Word Align-

ment on (U,At+1)→ θt+1
10: end for

We can iteratively perform the algorithm for a de-
fined number of iterations T or until a certain desired
performance is reached, which is measured by align-

ment error rate (AER) (Fraser and Marcu, 2007) in
the case of word alignment. In a more typical sce-
nario, since reducing human effort or cost of elici-
tation is the objective, we iterate until the available
budget is exhausted.

5 Query Strategies for Link Selection

We propose multiple query selection strategies for
our active learning setup. The scoring criteria is
designed to select alignment links across sentence
pairs that are highly uncertain under current au-
tomatic translation models. These links are diffi-
cult to align correctly by automatic alignment and
will cause incorrect phrase pairs to be extracted in
the translation model, in turn hurting the transla-
tion quality of the SMT system. Manual correction
of such links produces the maximal benefit to the
model. We would ideally like to elicit the least num-
ber of manual corrections possible in order to reduce
the cost of data acquisition. In this section we dis-
cuss our link selection strategies based on the stan-
dard active learning paradigm of ‘uncertainty sam-
pling’(Lewis and Catlett, 1994). We use the au-
tomatically trained translation model θt for scoring
each link for uncertainty. In particular θt consists of
bidirectional lexicon tables computed from the bidi-
rectional alignments as discussed in Section 3.

5.1 Uncertainty based: Bidirectional
Alignment Scores

The automatic Viterbi alignment produced by the
alignment models is used to obtain translation lexi-
cons, as discussed in Section 3. These lexicons cap-
ture the conditional distributions of source-given-
target P (s/t) and target-given-source P (t/s) prob-
abilities at the word level where si ∈ S and tj ∈ T .
We define certainty of a link as the harmonic mean
of the bidirectional probabilities. The selection strat-
egy selects the least scoring links according to the
formula below which corresponds to links with max-
imum uncertainty:

Score(aij/sI1, t
J
1 ) =

2 ∗ P (tj/si) ∗ P (si/tj)
P (tj/si) + P (si/tj)

(10)

5.2 Confidence Based: Posterior Alignment
probabilities

Confidence estimation for MT output is an interest-
ing area with meaningful initial exploration (Blatz

13



et al., 2004; Ueffing and Ney, 2007). Given a sen-
tence pair (sI1, t

J
1 ) and its word alignment, we com-

pute two confidence metrics at alignment link level –
based on the posterior link probability and a simple
IBM Model 1 as seen in Equation 13. We select the
alignment links that the initial word aligner is least
confident according to our metric and seek manual
correction of the links. We use t2s to denote com-
putation using higher order (IBM4) target-given-
source models and s2t to denote source-given-target
models. Targeting some of the uncertain parts of
word alignment has already been shown to improve
translation quality in SMT (Huang, 2009). In our
current work, we use confidence metrics as an ac-
tive learning sampling strategy to obtain most infor-
mative links. We also experiment with other con-
fidence metrics as discussed in (Ueffing and Ney,
2007), especially the IBM 1 model score metric
which showed some improvement as well.

Pt2s(aij , tJ1 /s
I
1) =

pt2s(tj/si, aij ∈ A)∑M
i pt2s(tj/si)

(11)

Ps2t(aij , sI1/t
J
1 ) =

ps2t(si/tj , aij ∈ A)∑N
i pt2s(tj/si)

(12)

Conf(aij/S, T ) =
2 ∗ Pt2s ∗ Ps2t
Pt2s + Ps2t

(13)

5.3 Agreement Based: Query by Committee

The generative alignments produced differ based on
the choice of direction of the language pair. We use
As2t to denote alignment in the source to target di-
rection and At2s to denote the target to source direc-
tion. We consider these alignments to be two experts
that have two different views of the alignment pro-
cess. We formulate our query strategy to select links,
where the agreement differs across these two align-
ments. In general query by committee is a standard
sampling strategy in active learning(Freund et al.,
1997), where the committee consists of any number
of experts with varying opinions, in this case align-
ments in different directions. We formulate a query
by committee sampling strategy for word alignment
as shown in Equation 14. In order to break ties, we
extend this approach to select the link with higher
average frequency of occurrence of words involved
in the link.

Language Sentences Words
Src Tgt

Ch-En 21,863 424,683 524,882
Ar-En 29,876 630,101 821,938

Table 1: Corpus Statistics of Human Data

Alignment Automatic Links Manual Links
Ch-En 491,887 588,075
Ar-En 786,223 712,583

Table 2: Alignment Statistics of Human Data

Score(aij) = α where (14)

α =


2 aij ∈ At2s ∩At2s
1 aij ∈ At2s ∪At2s
0 otherwise

6 Experiments

6.1 Data Analysis
To run our active learning and semi-supervised word
alignment experiments iteratively, we simulate the
setup by using a parallel corpus for which the
gold standard human alignment is already available.
We experiment with two language pairs - Chinese-
English and Arabic-English. Corpus-level statistics
for both language pairs can be seen in Table 1 and
their alignment link level statistics can be seen in
Table 2. Both datasets were released by LDC as part
of the GALE project.

Chinese-English dataset consists of 21,863 sen-
tence pairs with complete manual alignment. The
human alignment for this dataset is much denser
than the automatic word alignment. On an aver-
age each source word is linked to more than one
target word. Similarly, the Arabic-English dataset
consisting of 29,876 sentence pairs also has a denser
manual alignment. Automatic word alignment in
both cases was computed as a symmetrized version
of the bidirectional alignments obtained from using
GIZA++ (Och and Ney, 2003) in each direction sep-
arately.

6.2 Word Alignment Results
We first perform an unsupervised word alignment of
the parallel corpus. We then use the learned model

14



Figure 1: Chinese-English: Link Selection Results

in running our link selection algorithm over the en-
tire alignments to determine the most uncertain links
according to each active learning strategy. The links
are then looked up in the gold standard human align-
ment database and corrected. In scenarios where
an alignment link is not present in the gold stan-
dard data for the source word, we introduce a NULL
alignment constraint, else we select all the links as
given in the gold standard. The aim of our work is to
show that active learning can help in selecting infor-
mative alignment links, which if manually labeled
can reduce the overall alignment error rate of the
given corpus. We, therefore measure the reduction
of alignment error rate (AER) of a semi-supervised
word aligner that uses this extra information to align
the corpus. We plot performance curves for both
Chinese-English, Figure 1 and Arabic-English, Fig-
ure 2, with number of manual links elicited on x-axis
and AER on y-axis. In each iteration of the experi-
ment, we gradually increase the number of links se-
lected from gold standard and make them available
to the semi-supervised word aligner and measure the
overall reduction of AER on the corpus. We com-
pare our link selection strategies to a baseline ap-
proach, where links are selected at random for man-
ual correction.

All our approaches perform equally or better than
the baseline for both language pairs. Query by
committee (qbc) performs similar to the baseline in
Chinese-English and only slightly better for Arabic-

Figure 2: Arabic-English: Link Selection Results

English. This could be due to our committee con-
sisting of two alignments that differ only in direc-
tion and so are not sufficient in deciding for uncer-
tainty. We will be exploring alternative formulations
to this strategy. Confidence based and uncertainty
based metrics perform significantly better than the
baseline in both language pairs. We can interpret the
improvements in two ways. For the same number
of manual alignments elicited, our selection strate-
gies select links that provide higher reduction of er-
ror when compared to the baseline. An alternative
interpretation is that assuming a uniform cost per
link, our best selection strategy achieves similar per-
formance to the baseline, at a much lower cost of
elicitation.

6.3 Translation Results
We also perform end-to-end machine translation ex-
periments to show that our improvement of align-
ment quality leads to an improvement of translation
scores. For Chinese-English, we train a standard
phrase-based SMT system (Koehn et al., 2007) over
the available 21,863 sentences. We tune on the MT-
Eval 2004 dataset and test on a subset of MT-Eval
2005 dataset consisting of 631 sentences. The lan-
guage model we use is built using only the English
side of the parallel corpus. We understand that this
language model is not the optimal choice, but we
are interested in testing the word alignment accu-
racy, which primarily affects the translation model.

15



Cn-En BLEU METEOR
Baseline 18.82 42.70

Human Alignment 19.96 44.22
Active Selection 20% 19.34 43.25

Table 3: Effect of Alignment on Translation Quality

We first obtain the baseline score by training in an
unsupervised manner, where no manual alignment
is used. We also train a configuration, where we
substitute the final word alignment with gold stan-
dard manual alignment for the entire parallel corpus.
This is an upper bound on the translation accuracy
that can be achieved by any alignment link selec-
tion algorithm for this dataset. We now take our
best link selection criteria, which is the confidence
based method and re-train the MT system after elic-
iting manual information for only 20% of the align-
ment links. We observe that at this point we have
reduced the AER from 37.09 to 26.57. The trans-
lation accuracy reported in Table 3, as measured by
BLEU (Papineni et al., 2002) and METEOR (Lavie
and Agarwal, 2007), also shows significant improve-
ment and approaches the quality achieved using gold
standard data. We did not perform MT experiments
with Arabic-English dataset due to the incompatibil-
ity of tokenization schemes between the manually
aligned parallel corpora and publicly available eval-
uation sets.

7 Conclusion

Word-Alignment is a particularly challenging prob-
lem and has been addressed in a completely unsuper-
vised manner thus far (Brown et al., 1993). While
generative alignment models have been successful,
lack of sufficient data, model assumptions and lo-
cal optimum during training are well known prob-
lems. Semi-supervised techniques use partial man-
ual alignment data to address some of these issues.
We have shown that active learning strategies can
reduce the effort involved in eliciting human align-
ment data. The reduction in effort is due to care-
ful selection of maximally uncertain links that pro-
vide the most benefit to the alignment model when
used in a semi-supervised training fashion. Experi-
ments on Chinese-English have shown considerable
improvements.

8 Future Work

In future, we wish to work with word alignments for
other language pairs as well as study the effect of
manual alignments by varying the size of available
parallel data. We also plan to obtain alignments from
non-experts over online marketplaces like Amazon
Mechanical Turk to further reduce the cost of an-
notation. We will be experimenting with obtain-
ing full-alignment vs. partial alignment from non-
experts. Our hypothesis is that, humans are good
at performing tasks of smaller size and so we can
extract high quality alignments in the partial align-
ment case. Cost of link annotation in our current
work is assumed to be uniform, but this needs to
be revisited. We will also experiment with active
learning techniques for identifying sentence pairs
with very low alignment confidence, where obtain-
ing full-alignment is equivalent to obtaining multi-
ple partial alignments.

Acknowledgments

This research was partially supported by DARPA
under grant NBCHC080097. Any opinions, find-
ings, and conclusions expressed in this paper are
those of the authors and do not necessarily reflect the
views of the DARPA. The first author would like to
thank Qin Gao for the semi-supervised word align-
ment software and help with running experiments.

References
John Blatz, Erin Fitzgerald, George Foster, Simona Gan-

drabur, Cyril Goutte, Alex Kulesza, Alberto Sanchis,
and Nicola Ueffing. 2004. Confidence estimation for
machine translation. In Proceedings of Coling 2004,
pages 315–321, Geneva, Switzerland, Aug 23–Aug
27. COLING.

Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
ics of statistical machine translation: parameter esti-
mation. Computational Linguistics, 19(2):263–311.

Chris Callison-Burch, David Talbot, and Miles Osborne.
2004. Statistical machine translation with word- and
sentence-aligned parallel corpora. In ACL 2004, page
175, Morristown, NJ, USA. Association for Computa-
tional Linguistics.

O. Chapelle, B. Schölkopf, and A. Zien, editors. 2006.
Semi-Supervised Learning. MIT Press, Cambridge,
MA.

16



Colin Cherry and Dekang Lin. 2006. Soft syntactic
constraints for word alignment through discriminative
training. In Proceedings of the COLING/ACL on Main
conference poster sessions, pages 105–112, Morris-
town, NJ, USA.

Pinar Donmez and Jaime G. Carbonell. 2008. Opti-
mizing estimated loss reduction for active sampling in
rank learning. In ICML ’08: Proceedings of the 25th
international conference on Machine learning, pages
248–255, New York, NY, USA. ACM.

Alexander Fraser and Daniel Marcu. 2006. Semi-
supervised training for statistical word alignment. In
ACL-44: Proceedings of the 21st International Con-
ference on Computational Linguistics and the 44th
annual meeting of the Association for Computational
Linguistics, pages 769–776, Morristown, NJ, USA.
Association for Computational Linguistics.

Alexander Fraser and Daniel Marcu. 2007. Measuring
word alignment quality for statistical machine transla-
tion. Comput. Linguist., 33(3):293–303.

Yoav Freund, Sebastian H. Seung, Eli Shamir, and Naf-
tali Tishby. 1997. Selective sampling using the query
by committee algorithm. Machine. Learning., 28(2-
3):133–168.

Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, pages 49–57, Columbus, Ohio,
June. Association for Computational Linguistics.

Gholamreza Haffari, Maxim Roy, and Anoop Sarkar.
2009. Active learning for statistical phrase-based ma-
chine translation. In Proceedings of HLT NAACL
2009, pages 415–423, Boulder, Colorado, June. As-
sociation for Computational Linguistics.

Fei Huang. 2009. Confidence measure for word align-
ment. In Proceedings of the Joint ACL and IJCNLP,
pages 932–940, Suntec, Singapore, August. Associa-
tion for Computational Linguistics.

Rebecca Hwa. 2004. Sample selection for statistical
parsing. Comput. Linguist., 30(3):253–276.

Philipp Koehn, Hieu Hoang, Alexandra Birch Mayne,
Christopher Callison-Burch, Marcello Federico,
Nicola Bertoldi, Brooke Cowan, Wade Shen, Chris-
tine Moran, Richard Zens, Chris Dyer, Ondrej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open source toolkit for statistical machine
translation. In ACL Demonstration Session.

Alon Lavie and Abhaya Agarwal. 2007. Meteor: an au-
tomatic metric for mt evaluation with high levels of
correlation with human judgments. In WMT 2007,
pages 228–231, Morristown, NJ, USA.

David D. Lewis and Jason Catlett. 1994. Heterogeneous
uncertainty sampling for supervised learning. In In

Proceedings of the Eleventh International Conference
on Machine Learning, pages 148–156. Morgan Kauf-
mann.

Hieu T. Nguyen and Arnold Smeulders. 2004. Active
learning using pre-clustering. In ICML.

Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, pages 19–51.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalua-
tion of machine translation. In ACL 2002, pages 311–
318, Morristown, NJ, USA.

Dan Shen, Jie Zhang, Jian Su, Guodong Zhou, and Chew-
Lim Tan. 2004. Multi-criteria-based active learning
for named entity recognition. In ACL ’04: Proceed-
ings of the 42nd Annual Meeting on Association for
Computational Linguistics, page 589, Morristown, NJ,
USA. Association for Computational Linguistics.

Min Tang, Xiaoqiang Luo, and Salim Roukos. 2001. Ac-
tive learning for statistical natural language parsing. In
ACL ’02, pages 120–127, Morristown, NJ, USA.

Katrin Tomanek and Udo Hahn. 2009. Semi-supervised
active learning for sequence labeling. In Proceedings
of the Joint Conference of the 47th Annual Meeting
of the ACL and the 4th International Joint Conference
on Natural Language Processing of the AFNLP, pages
1039–1047, Suntec, Singapore, August. Association
for Computational Linguistics.

Simon Tong and Daphne Koller. 2002. Support vector
machine active learning with applications to text clas-
sification. Journal of Machine Learning, pages 45–66.

Gokhan Tur, Dilek Hakkani-Tr, and Robert E. Schapire.
2005. Combining active and semi-supervised learning
for spoken language understanding. Speech Commu-
nication, 45(2):171 – 186.

Nicola Ueffing and Hermann Ney. 2007. Word-level
confidence estimation for machine translation. Com-
put. Linguist., 33(1):9–40.

Hua Wu, Haifeng Wang, and Zhanyi Liu. 2006. Boosting
statistical word alignment using labeled and unlabeled
data. In Proceedings of the COLING/ACL on Main
conference poster sessions, pages 913–920, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.

X. Zhu. 2005. Semi-Supervised Learning Lit-
erature Survey. Technical Report 1530, Com-
puter Sciences, University of Wisconsin-Madison.
http://www.cs.wisc.edu/∼jerryzhu/pub/ssl survey.pdf.

17


