










































Recent adventures with emotion-reading technology


Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, page 1,
Atlanta, Georgia, 14 June 2013. cÂ©2013 Association for Computational Linguistics

Recent adventures with emotion-reading technology

Rosalind W. Picard
MIT Media Lab, E14-374G

75 Amherst St; Cambridge, MA 02139
picard@media.mit.edu

1 Abstract of the talk

This talk will share stories from recent investiga-
tions at the MIT Media Lab in creating technol-
ogy to recognize and better communicate emotion.
Examples include automating facial affect recogni-
tion online for sharing media experiences, gather-
ing the worlds largest sets of natural expressions
(instead of lab-elicited data) and training machine
learning models to predict liking of the experience
based on expression dynamics throughout the expe-
rience. We also have found that most people have
difficulty discriminating peak smiles of frustration
from peak smiles of delight in static images. With
machine learning and dynamic features, we were
able to teach the computer to be highly accurate at
discriminating these. These kinds of tools can po-
tentially help many people with nonverbal learning
disabilities, limited vision, social phobia, or autism
who find it challenging to read the faces of those
around them. I will also share recent findings from
people wearing physiological sensors 24/7, and how
weve been learning about connections between the
emotion system, sleep and seizures. Finally, I will
share some of our newest work related to crowd
sourcing cognitive-behavioral therapy and computa-
tional empathy, where sentiment analysis could be
of huge benefit.

1


