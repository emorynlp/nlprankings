










































Semi-automatic Acquisition of Lexical Resources and Grammars for Event Extraction in Bulgarian and Czech


Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language Processing, pages 110–118,
Sofia, Bulgaria, 8-9 August 2013. c©2010 Association for Computational Linguistics

Semi-automatic Acquisition of Lexical Resources and Grammars for
Event Extraction in Bulgarian and Czech

Hristo Tanev
Joint Research Centre
European Commission
via Fermi 2749, Ispra

Italy
hristo.tanev@jrc.ec.europa.eu

Josef Steinberger
University of West Bohemia
Faculty of Applied Sciences

Department of Computer Science and Engineering
NTIS Centre Univerzini 8, 30614 Plzen

Czech Republic
jstein@kiv.zcu.cz

Abstract

In this paper we present a semi-automatic
approach for acqusition of lexico-syntactic
knowledge for event extraction in two
Slavic languages, namely Bulgarian and
Czech. The method uses several weakly-
supervised and unsupervised algorithms,
based on distributional semantics. More-
over, an intervention from a language ex-
pert is envisaged on different steps in the
learning procedure, which increases its ac-
curacy, with respect to unsupervised meth-
ods for lexical and grammar learning.

1 Introduction

Automatic detection and extraction of events from
online news provide means for tracking the devel-
opments in the World politics, economy and other
important areas of life.

Event extraction is a branch of information ex-
traction, whose goal is the automatic retrieval of
structured information about events described in
natural language texts. Events include interac-
tions among different entities, to each of which
an event-specific semantic role can be assigned.
This role reflects the way in which the entity par-
ticipates in the event and interacts with the other
entities. For example, in the fragment “Three peo-
ple were injured in a building collapse”, the phrase
“three people” may be assigned a semantic role
injured − victim. The list of semantic roles de-
pends on the adopted event model.

The event extraction technology may decrease
the information overload, it allows automatic con-
version of unstructured text data into structured
one, it can be used to pinpoint interesting news ar-
ticles, also extracted entities and their correspond-
ing semantic roles can provide brief summaries of
the articles.

Using lexico-syntactic knowledge is one of

the promising directions in modeling the event-
specific semantic roles (Hogenboom et al., 2011).
While for English linear patterns seem to work
quite well (Tanev et al., 2008), for other lan-
guages,where word ordering is more free, cas-
caded grammars proved to improve the results
(Zavarella et al., 2008). In particular, Slavic lan-
guages are more free-order than English; conse-
quently, using cascaded grammars may be consid-
ered a relevant approach.

In this paper we present an ongoing effort
to build event extraction cascaded grammars for
Bulgarian and Czech in the domain of violent
news. To achieve this goal we put forward a
semi-automatic approach for building of event ex-
traction grammars, which uses several weakly-
supervised algorithms for acquisition of lexical
knowledge, based on distributional semantics and
clustering. Moreover, the lexical knowledge is
learned in the form of semantic classes, which then
can be used as a basis for building of a domain-
specific ontology.

To the best of our knowledge, there are no
previous attempts to perform event extraction for
Slavic languages, apart from the work presented in
(Turchi et al., 2011).

The importance of Czech and Bulgarian lan-
guages comes from the geopolitical positions of
the countries where they are spoken: Czech Re-
public is in a central geographical position be-
tween Eastern and Western Europe; Bulgaria is on
the borders of the European Union, on a crossroad
between Europe and Asia, surrounded by different
cultures, languages and religions. These geopo-
litical factors contribute to the importance of the
news from Czech Republic and Bulgaria and con-
sequently make automatic event extraction from
these news an useful technology for political an-
alysts.

The paper has the following structure: In sec-
tion 2 we make a short overview of the related ap-

110



proaches; in section 3 we describe our method for
lexical and grammar learning; section 4 presents
our experiments and evaluation for Bulgarian and
Czech languages and section 5 discusses the out-
come of the experiments and some future direc-
tions.

2 Related Work

There are different approaches for event extrac-
tion. Most of the work up to now has aimed
at English (see among the others (Naughton et
al., 2006) and (Yangarber et al., 2000)), however
(Turchi et al., 2011) presented automatic learning
of event extraction patterns for Russian, English
and Italian.

Our work is based on weakly supervised algo-
rithms for learning of semantic classes and pat-
terns, presented in (Tanev et al., 2009) and (Tanev
and Zavarella, 2013); these approaches are based
on distributional semantics. There are different
other methods which use this paradigm: A con-
cept and pattern learning Web agent, called NELL
(Never Ending Language Learning) is presented in
(Carlson et al., 2010). Parallel learning of seman-
tic classes and patterns was presented in (Riloff
and Jones, 1999). However these approaches do
not try to derive grammars from the acquired re-
sources, but stop at purely lexical level.

Relevant to our approach are the grammar learn-
ing approaches. A survey of supervised and unsu-
pervised approaches is presented in (D’Ulizia et
al., 2011). The supervised ones require annotation
of big amounts of data which makes the develop-
ment process long and laborious. On the other
hand, unsupervised methods try to generalize all
the training data by using different heuristics like
the minimal description length. Since for event
extraction only specific parts of the text are ana-
lyzed, in order to use unsupervised grammar ac-
quisition methods for learning of event extraction
grammars, one should collect the exact phrases
which describe the events. In practice, this would
transform the unsupervised methods into super-
vised ones. With respect to the state-of-the art
grammar inference approaches, our method allows
for more interaction between the grammar expert
and the learning system. Moreover, our learning
starts from lexical items and not from annotated
texts, which decreases the development efforts.

3 Semi-automatic Learning of Lexica
and Grammars

The event extraction grammar, exploited in our ap-
proach is a cascaded grammar which on the first
levels detects references to entities, like people,
groups of people, vehicles, etc. On the upper lev-
els our cascaded grammar detects certain events
in which these entities participate: In the domain
of violent news, people may get killed, wounded,
kidnapped, arrested, etc. If we consider as an ex-
ample the following Bulgarian text: �Ãðóïà ïðî-
òåñòèðàùè áÿõà àðåñòóâàíè â÷åðà ïî âðåìå
íà äåìîíñòðàöèè â öåíòúðà íà ñòîëèöàòà�
(“A group of protesters were arrested yesterday
during demonstrations in the centre of the capi-
tal”), our grammar will detect first that �Ãðóïà
ïðîòåñòèðàùè� (“A group of protesters”) refers
to a group of people and then, it will find that
�Ãðóïà ïðîòåñòèðàùè áÿõà àðåñòóâàíè'’ (“A
group of protesters were arrested”) refers to an ar-
rest event where the aforementioned group of peo-
ple is assigned the semantic role arrested.

In order to build such a grammar, we acquire
semi-automatically the following resources:

1. a dictionary of words which refer to peo-
ple and other entities in the required domain-
specific context, e.g. �âîéíèê� , “voják” (
“soldier” in Bulgarian and Czech), �æåíà� ,
��zena� ( “woman” in Bulgarian and Czech),
etc.

2. a list of modifiers and other words which
appear in phrases referring to those entities,
e.g. �öèâèëåí� , “civilnı́” (“civil” in Bulgar-
ian and Czech), �ÍÀÒÎ� (“NATO”), etc.

3. grammar rules for parsing entity-referring
phrases. For example, a simple rule can be:
PERSON PHRASE → PER
connector ORG
where PER and ORG are words and multi-
words, referring to people and organizations,
connector → �îò� for Bulgarian or
connector → “” (empty string) for Czech.
This rule can parse phrases like �âîéíèê îò
ÍÀÒÎ� or “voják NATO” (“NATO soldier”)

4. a list of words which participate in event
patterns like �àðåñòóâàí� , “zadržen” (“ar-
rested” in Bulgarian and Czech) or �óáèò� ,
“zabit” ( “killed” in Bulgarian and Czech).

111



5. a set of grammar rules which parse event-
description phrases. For example, a simple
rule can be:
KILLING → PER connector
KILLED PARTICIPLE
where connector → �áåøå� for Bulgarian
or connector → �byl� for Czech.
This rule will recognize phrases like �Âîé-
íèê îò ÍÀÒÎ áåøå óáèò� or “Voják
NATO byl zabit” (“A NATO soldier was
killed” in Bulgarian and Czech”)

In order to acquire this type of domain lexica
and a grammar, we make use of a semi-automatic
method which acquires in parallel grammar rules
and dictionaries. Our method exploits several
state-of-the-art algorithms for expanding of se-
mantic classes, distributional clustering, learning
of patterns and learning of modifiers, described in
(Tanev and Zavarella, 2013). The semantic class
expansion algorithm was presented also in (Tanev
et al., 2009). These algorithms are multilingial and
all of them are based on distributional semantics.
They use a non-annotated text corpus for training.

We integrated these algorithms in a semi-
automatic schema for grammar learning, which is
still in phase of development. Here is the basic
schema of the approach:

1. The user provides a small list of seed words,
which designate people or other domain-
specific entities, e.g.“ soldiers”,“civilians”,
“fighters” (We will use only English-
language examples for short, however the
method is multilingual and consequently ap-
plicable for Czech and Bulgarian).

2. Using the multilingual semantic class ex-
pansion algorithm (Tanev et al., 2009)
other words are learned (e.g. “policemen”,
“women”, etc.), which are likely to belong
to the same semantic class. First, the algo-
rithm finds typical contextual patterns for the
seed words from not annotated text. For ex-
ample, all the words, referring to people tend
to appear in linear patterns like [PEOPLE]
were killed, thousands of [PEOPLE] , [PEO-
PLE] are responsible, etc. Then, other words
which tend to participatre in the same con-
textual patterns are extracted from the unan-
notated text corpus. In such a way the al-
gorithm learns additional words like “police-

men”, “killers”, “terrorists”, “women”, “chil-
dren”, etc.

3. Since automatic approaches for learning of
semantic classes always return some noise
in the output, a manual cleaning by a do-
main expert takes place as a next step of our
method.

4. Learning modifiers: At this step, for each se-
mantic class learned at the previous step (e.g.
PEOPLE, we run the modifier learning algo-
rithm, put forward by (Tanev and Zavarella,
2013) , which learns domain-specific syn-
tactic modifiers. Regarding the class PEO-
PLE), the modifiers will be words like “
Russian”, “American”, “armed”, “unarmed”,
“masked”, etc. The modifier learning algo-
rithm exploits the principle that the context
distribution of words from a semantic class
is most likely similar to the context distribu-
tion of these words with syntactic modifiers
attached. The algorithm uses this heuristic
and does not use any morphological infor-
mation to ensure applications in multilingual
settings.

5. Manual cleaning of the modifier list

6. Adding the following grammar rule at the
first level of the cascaded grammar, which
uses the semantic classes and modifiers,
learned at the previous steps:
Entity(class : C) → (LModif(class :
C))∗ Word(class : C) (RModif(class :
C))∗
This rule parses phrases, like “masked gun-
men from IRA”, referring to an entity from
a semantic class C, e.g. PERSON. It should
consist of a sequence of 0 or more left mod-
ifiers for this class, e.g. “masked”, a word
from this class (“gunmen” in this example)
and a sequence of 0 or more right modifiers
(“from IRA” in the example”).

7. Modifiers learned by the modifier learning
algorithm do not cover all the variations in
the structure of the entity-referring phrases,
since sometimes the structure is more com-
plex and cannot be encoded through a list of
lexical patterns. Consider, for example, the
following phrase “soldiers from the special
forces of the Russian Navy”. There is a little

112



chance that our modifier learning algorithm
acquires the string “from the special forces
of the Russian Navy”, on the other hand
the following two grammar rules can do the
parsing:
RIGHT PEOPLE MODIFIER →
“from′′MILITARY FORMATION
MILITARY FORMATION →
LeftModMF ∗ MFW RightModMF∗
where MILITARY FORMATION is a
phrase which refers to some organization (in
the example, shown above, the phrase is “the
special forces of the Russian Navy”), MFW
is a term which refers to a military formation
(“the special forces”) and LeftModMF and
RightModMF are left and right modifiers
of the military formation entity (for example,
a right modifier is“of the Russian Navy”).

In order to learn such more complex struc-
ture, we propose the following procedure:

(a) The linguistic expert chooses seman-
tic classes, for which more elaborated
grammar rules should be developed.
Let’s take for example the class PEO-
PLE.

(b) Using the context learning sub-
algorithm of the semantic class expan-
sion, used in step 2, we find contextual
patterns which tend to co-occur with
this class. Apart from the patterns
shown in step 2, we also learn patterns
like [PEOPLE] from the special forces,
[PEOPLE] from the Marines, [PEO-
PLE] from the Russian Federation,
[PEOPLE] from the Czech Republic,
[PEOPLE] with guns, [PEOPLE] with
knives, [PEOPLE] with masks, etc.

(c) We generalize contextual patterns, in or-
der to create grammar rules. In the first
step we create automatically syntactic
clusters separately for left and right
contextual patterns. Syntactic clustering
puts in one cluster patterns where the
slot and the content-bearing words are
connected by the same sequence of stop
words. In the example, shown above,
we will have two syntactic clusters of
patterns: The first consists of patterns
which begin with [PEOPLE] from the
and the second contains the patterns,
which start with [PEOPLE] with. These

clusters can be represented via grammar
rules in the following way:
RIGHT PEOPLE MODIFIER →“from
the” X
X→ (special forces | Marines | Russian
Federation | Czech Republic)
RIGHT PEOPLE MODIFIER →
“with” Y
Y→ (knives | guns | masks)

(d) Now, several operations can be done
with the clusters of words inside the
grammar rules:

• Words inside a cluster can be clus-
tered further on the basis of their
semantics. In our system we use
bottom up agglomerative cluster-
ing, where each word is represented
as a vector of its context features.
Manual cleaning and merging of
the clusters may be necessary af-
ter this automatic process. If words
are not many, only manual clus-
tering can also be an option. In
the example above “special forces”
and “Marines” may form one clus-
ter, since both words designate the
class MILITARY FORMATION and
the other two words designate coun-
tries and also form a separate seman-
tic class.
• In the grammar introduce new non-

terminal symbols, corresponding to
the newly learnt semantic classes.
Then, in the grammar rules substi-
tute lists of words with references
to these symbols. (Still we do
modification of the grammar rules
manually, however we envisage to
automate this process in the future).
For example, the rule

X → (special forces | Marines
| Russian Federation | Czech Re-
public)
will be transformed into
X → (MILITARY FORMATION |
COUNTRY)
MILITARY FORMATION → (spe-
cial forces | Marines)
COUNTRY → (Russian Federation

113



PEOPLE→ (NUMBER îò (from) )? PEOPLEa
Example: �äâàìà îò áúëãàðñêèòå âîéíèöè� (“two of the Bulgarian soldiers”)

PEOPLEa→ PEOPLEb ((îò (from) | íà (of) | â (in)) (ORG | PLACE ))*
Example: �ñëóæèòåëè íà ÌÂÐ� (“staff from the MVR (Ministry of the Internal Affairs)”)

PEOPLEb→ LeftPM* PEOPLE W RightPM*
Example: �íåèçâåñòíè íàïàäàòåëè ñ êà÷óëêè� (“unknown attackers with hoods”)

Table 1: Rules for entity recognition for the Bulgarian language

| Czech Republic)
• Clusters can be expanded by using

the semantic class expansion algo-
rithm, introduced before, followed
by manual cleaning. In our example,
this will add other words for MIL-
ITARY FORMATION and COUN-
TRY. Consequently, the range of the
phrases, parsable by the grammar
rules will be augmented.

(e) The linguistic expert may choose a sub-
set of the semantic classes, obtained
on the previous step, (e.g. the the se-
mantic class MILITARY FORMATION)
to be modeled further via extending the
grammar with rules about their left and
right modifiers. Then, the semantic class
is recursively passed to the input of this
grammar learning procedure.

8. Learning event patterns: In this step we learn
patterns like [PEOPLE] �áÿõà àðåñòóâàíè�
or [PEOPLE] “byl zadržen” ([PEOPLE]
were/was arrested in Bulgarian and Czech).
The pattern learning algorithm collects con-
text patterns for one of the considered en-
tity categories (e.g. [PEOPLE]. This is done
through the context learning sub-algorithm
described in step 2. Then, it searches for
such context patterns, which contain words,
having distributional similarity to words, de-
scribing the target event (e.g. �àðåñòóâàíè� ,
“zadržen” (“arrested”)).

For example, if we want to learn patterns for
arrest events in Bulgarian, the algorithm first
learns contexts of [PEOPLE]. These con-
texts are [PEOPLE] áÿõà óáèòè ([PEO-
PLE] were killed), õèëÿäè [PEOPLE]
(thousands of [PEOPLE]), [PEOPLE] áÿõà
çàëîâåíè ([PEOPLE] were captured), etc.

Then, we pass to the semantic expansion al-
gorithm (see step 2) seed words which ex-
press the event arrest, namely �çàäúðæàíè�,
�àðåñòóâàíè� (“apprehended”, “arrested”),
etc. Then, it will discover other similar words
like �çàëîâåíè� (“captured”). Finally, the
algorithm searches such contextual patterns,
which contain any of the seed and learnt
words. For example, the pattern [PEOPLE]
áÿõà çàëîâåíè ([PEOPLE] were captured)
is one of the newly learnt patterns for arrest
events.

9. Generalizing the patterns: In this step we ap-
ply a generalization algorithm, described in
step 7 to learn grammar rules which parse
events. For example, two of the learned rules
for parsing of arrest events in Bulgarian are:

ARREST → PEOPLE �áÿõà� (“were”)
ARREST PARTICIPLE
ARREST PARTICIPLE → ( �àðåñòóâàíè�
(�arrested�) | �çàëîâåíè�(�captured�) |
�çàêîï÷àíè� (�handcu�ed�) )

The outcome of this learning schema is a gram-
mar and dictionaries which recognize descriptions
of different types of domain-specific entities and
events, which happened with these entities. More-
over, the dictionaries describe semantic classes
from the target domain and can be used further for
creation of a domain ontology.

4 Experiments and Evaluation

In our experiments, we applied the procedure
shown above to learn grammars and dictionaries
for parsing of phrases, referring to people, groups
of people and violent events in Bulgarian and
Czech news. We used for training 1 million news
titles for Bulgarian and Czech, downloaded from

114



KILLING→ KILL VERB (a (and) | i (and) | jeden (one) | jeden z (one of) )? [PEOPLE]
KILL VERB→ (zabit (killed) | zabila | zahynul (died) | zabiti | ubodal (stabbed) | ubodala | ...)
KILLING→ KILL ADJ [PEOPLE]
KILL ADJ→ (mrtvou (dead) | mrtvého (dead) | ...)
KILLING→ [PEOPLE] KILL VERBa
KILL VERBa→ (zahynul (died) | zamřel (died) | ...)
KILLING→ [PEOPLE] byl (was) KILL VERBb
KILL VERBb→ (zabit (killed) | ...)

Table 2: Rules for parsing of killing events and their victims in Czech

the Web and a small number of seed terms, refer-
ring to people and actions. We had more available
time to work for the Bulgarian language, that is
why we learned more complex grammar for Bul-
garian. Both for Czech and Bulgarian, we learned
grammar rules parsing event description phrases
with one participating entity, which is a person or
a group of people. This is simplification, since of-
ten an event contains more than one participant,
in such cases our grammar can detect the separate
phrases with their corresponding participants, but
currently it is out of the scope of the grammar to
connect these entities. The event detection rules
in our grammar are divided into semantic classes,
where each class of rules detects specific type of
events like arrest, killing, wounding, etc. and also
assigns an event specific semantic role to the par-
ticipating entity, e.g. victim, perpetrator, arrested,
kidnapped.

In order to implement our grammars, we used
the EXPRESS grammar engine (Piskorski, 2007).
It is a tool for building of cascaded grammars
where specific parts of the parsed phrase are as-
signed semantic roles. We used this last feature of
EXPRESS to assign semantic roles of the partici-
pating person entities.

For Czech we learned a grammar which de-
tects killings and their victims. For Bulgarian, we
learned a grammar, which parses phrases referring
to killings, woundings and their victims, arrests
and who is arrested, kidnappings and other violent
events with their perpetrators and targeted people.

4.1 Learning people-recognition rules

For Czech our entity extraction grammar was rel-
atively simple, since we learned just a dictionary
of left modifiers. Therefore, we skipped step 7 in
the learning schema, via which more elaborated
entity recognition grammars are learned. Thus,
the Czech grammar for recognizing phrases,

referring to people contains the following rules:
PEOPLE→ LeftMod* PEOPLE TERM
LeftMod → (“mladou” (“young”) |
“neznámému”(“unknown”) | “staršı́” (“old”) |
...)
PEOPLE TERM → (“vojáci” (“soldiers”) |
“civilisté”(“civilians”) | “ženu” (“woman”) |
...)

This grammar recognizes phrases like “mladou
ženu” (“young woman” in Czech). Two dictionar-
ies were acquired in the learning process: A dic-
tionary of nouns, referring to people and left mod-
ifiers of people. The dictionary of people-referring
nouns contains 268 entries, obtained as a result
of the semantic class expansion algorithm. We
used as a seed set 17 words like “muži” (“men”),
“voiáci” (“soldiers”), etc. The algorithm learned
1009 new words and bigrams, 251 of which were
correct (25%), that is refer to people. One problem
here was that not all morphological forms were
learned by our class expansion algorithm. In a
language with rich noun morphology, as Czech is,
this influenced on the coverage of our dictionaries.

After manual cleaning of the output from the
modifier learning algorithm, we obtained 603
terms; the learning accuracy of the algorithm was
found to be 55% .

For Bulgarian we learned a more elaborated
people recognition grammar, which is able to
parse more complex phrases like �åäèí îò ìàñêè-
ðàíèòå íàïàäàòåëè� (“one of the masked attack-
ers”) and �áîéöè îò áúëãàðñêèÿ êîíòèíãåíò â
Èðàê� (“soldiers from the Bulgarian contingent
in Iraq”). The most important rules which we
learned are shown in Table 1. In these rules PEO-
PLE W encodes a noun or a bigram which refers
to people, ORG is an organization; we learned
mostly organizations, related to the domain of se-
curity, such as different types of military and other
armed formations like �ñèëèòå íà ðåäà� (“secu-

115



rity forces”), also governmental organizations, etc.
PLACE stands for names of places and common
nouns, referring to places such as �ñòîëèöàòà�
(“the capital”). We also learned modifiers for these
categories and added them to the grammar. (For
simplicity, we do not show the grammar rules for
parsing ORG abd PLACE; we will just mention
that both types of phrases are allowed to have a se-
quence of left modifiers, one or more nouns from
the corresponding class and a sequence of 0 or
more right modifiers.) Both categories PLACE
and ORG were obtained in step 7 of the learn-
ing schema, when exploring the clusters of words
which appear as modifiers after the nouns, refer-
ring to people, like in the following example �áîé-
öè îò áúëãàðñêèÿ êîíòèíãåíò� (“soldiers from
the Bulgarian contingent” ); then, we applied man-
ual unification of the clusters and their subsequent
expansion, using the semantic class expansion al-
gorithm.

Regarding the semantic class expansion, with
20 seed terms we acquired around 2100 terms,
from which we manually filtered the wrong ones
and we left 1200 correct terms, referring to peo-
ple; the accuracy of the algorithm was found to be
57% in this case.

We learned 1723 nouns for organizations and
523 place names and common nouns. We did not
track the accuracy of the learning for these two
classes. We also learned 319 relevant modifiers
for people-referring phrases; the accuracy of the
modifier learning algorithm was found to be 67%
for this task.

4.2 Learning of event detection rules

This learning takes place in step 8 and 9 of
our learning schema. As it was explained, first
linear patterns like [PEOPLE] “byl zadržen”
([PEOPLE] was arrested ) are learned, then
through a semi-automatic generalization process
these patterns are transformed into rules like:
ARREST→ PEOPLE “byl” ARREST VERB

In our experiments for Czech we learned gram-
mar rules and a dictionary which recognize dif-
ferent syntactic constructions, expressing killing
events and the victims. These rules encode 156
event patterns. The most important of these rules
are shown in Table 2. Part of the event rule learn-
ing process is expansion of a seed set of verbs, and
other words, referring to the considered event (in

this case killing).For this task the semantic class
expansion algorithm showed significantly lower
accuracy with respect to expanding sets of nouns -
only 5%. Nevertheless, the algorithm learned 54
Czech words, expressing killing and death.

For Bulgarian we learned rules for detection of
killing and its victims, but also rules for parsing of
wounding events, arrests, targeting of people in vi-
olent events, kidnapping, and perpetrators of vio-
lent events. These rules encode 605 event patterns.
Some of the rules are shown in Table 3.

4.3 Evaluation of event extraction

In order to evaluate the performance of our gram-
mars, we created two types of corpora: For the
precision evaluation we created bigger corpus of
randomly picked excerpts of news from Bulgar-
ian and Czech online news sources. More pre-
cisely, we used 7’550 news titles for Czech and
12’850 news titles in Bulgarian. We also car-
ried out a preliminary recall evaluation on a very
small text collection: We manually chose sen-
tences which report about violent events of the
types which our grammars are able to capture. We
selected 17 sentences for Czech and 28 for Bul-
garian. We parsed the corpora with our EXPRESS
grammars and evaluated the correctness of the ex-
tracted events. Since each event rule has assigned
an event type and a semantic role for the partic-
ipating people reference, we considered a correct
match only when both a correct event type and a
correct semantic role are assigned to the matched
text fragment. Table 4 shows the results from our
evaluation. The low recall in Czech was mostly
due to the insufficient lexicon for people and the
too simplistic grammar.

Language Precision Recall
Bulgarian 93% 39%
Czech 88% 6%

Table 4: Event extraction accuracy

5 Discussion

In this paper we presented a semi-automatic ap-
proach for learning of grammar and lexical knowl-
edge from unannotated text corpora. The method
is multilingual and relies on distributional ap-
proaches for semantic clustering and class expan-
sion.

116



KILLING→ KILL VERB (áÿõà (were) | ñà (are)) [PEOPLE]
KILL VERB→ (çàãèíàëè (killed) | óáèòè (killed) | çàñòðåëÿíèòå (shot to death) | ...)
KILLING→ KILL PHRASE íà (of) [PEOPLE]
KILL PHRASE→ (îòíå æèâîòà (took the life) | ïðè÷èíè ñìúðòòà (caused the death) | ...)
WOUNDING→ WOUND VERB (áÿõà (were) | ñà (are)) [PEOPLE]
WOUND VERB→ (ðàíåíè (wounded) | ïîñòðàäàëèòå (injured) | ...)
ARREST→ [PEOPLE] ARREST VERB
ARREST VERB→ (àðåñòóâàíè (arrested) | çàäúðæàíè (detained) | ...)

Table 3: Some event parsing rules for Bulgarian

We are currently developing event extraction
grammars for Czech and Bulgarian. Preliminary
evaluation shows promising results for the preci-
sion, while the recall is still quite low. One of
the factors which influences the law recall was
the insufficient number of different morphological
word variations in the learned dictionaries. The
morphological richness of Slavic languages can be
considered by adding morphological dictionaries
to the system or creating an automatic procedure
which detects the most common endings of the
nouns and other words and expands the dictionar-
ies with morphological forms.

Another problem in the processing of the
Slavic languages is their relatively free order.
To cope with that, often the grammar engineer
should introduce additional variants of already
learned grammar rules. This can be done semi-
automatically, where the system may suggest ad-
ditional rules to the grammar developer. This can
be done through development of grammar meta-
rules.

With respect to other approaches, grammars
provide transparent, easy to expand model of the
domain. The automatically learned grammars can
be corrected and extended manually with hand-
crafted rules and linguistic resources, such as mor-
phological dictionaries. Moreover, one can try
to introduce grammar rules from already existing
grammars. This, of course, is not trivial because of
the different formalisms exploited by each gram-
mar. It is noteworthy that the extracted semantic
classes can be used to create an ontology of the
domain. In this clue, parallel learning of a domain-
specific grammars and ontologies could be an in-
teresting direction for future research.

The manual efforts in the development of the
grammars and the lexical resources were mainly
cleaning of already generated lists of words and
manual selection and unification of word clus-

ters. Although we did not evaluate precisely the
invested manual efforts, one can estimate them
by the size of the automatically acquired word
lists and their accuracy, given in section Semi-
automatic Learning of Lexica and Grammars.

We plan to expand the Czech grammar with
rules for more event types. Also, we think to ex-
tend both the Bulgarian and the Czech event ex-
traction grammars and the lexical resources, so
that it will be possible to detect also disasters, hu-
manitarian crises and their consequences. This
will increase the applicability and usefulness of
our event extraction grammars.

Acknowledgments

This work was partially supported by project
“NTIS - New Technologies for Information
Society”, European Center of Excellence,
CZ.1.05/1.1.00/02.0090.

References
A. Carlson, J. Betteridge, B. Kisiel, B. Settles, R. Este-

vam, J. Hruschka, and T. Mitchell. 2010. Toward an
architecture for never-ending language learning. In
Proceedings of the Twenty-Fourth AAAI Conference
on Artificial Intelligence (AAAI-10).

A. D’Ulizia, F. Ferri, and P. Grifoni. 2011. A survey of
grammatical inference methods for natural language
learning. Artificial Intelligence Review vol. 36 issue
1.

F. Hogenboom, F. Frasincar, U. Kaymak, and F. Jong.
2011. An overview of event extraction from text.
In Workshop on Detection, Representation, and Ex-
ploitation of Events in the Semantic Web (DeRiVE
2011) at ISWC 2011.

M. Naughton, N. Kushmerick, and J. Carthy.
2006. Event Extraction from Heterogeneous News
Sources. In Proceedings of the AAAI 2006 workshop
on Event Extraction and Synthesis, Menlo Park, Cal-
ifornia, USA.

117



J. Piskorski. 2007. ExPRESS – Extraction Pattern
Recognition Engine and Specification Suite. In Pro-
ceedings of FSMNLP 2007.

E. Riloff and R. Jones. 1999. Learning dictionaries for
information extraction by multi-level bootstrapping.
In Proceedings of the Sixteenth National Conference
on Artificial Intelligence (AAAI 99).

H. Tanev and V. Zavarella. 2013. Multilingual learn-
ing and population of event ontologies. a case study
for social media. In P. Buitelaar and P. Cimiano, ed-
itors, Towards Multilingual Semantic Web (in press).
Springer, Berlin & New York.

H. Tanev, J. Piskorski, and M. Atkinson. 2008. Real-
Time News Event Extraction for Global Crisis Mon-
itoring. In Proceedings of NLDB 2008., pages 207–
218.

H. Tanev, V. Zavarella, J. Linge, M. Kabadjov, J. Pisko-
rski, M. Atkinson, and R. Steinberger. 2009. Ex-
ploiting Machine Learning Techniques to Build an
Event Extraction System for Portuguese and Span-
ish. Linguamática: Revista para o Processamento
Automático das Lı́nguas Ibéricas, 2:550–566.

M. Turchi, V. Zavarella, and H. Tanev. 2011. Pat-
tern learning for event extraction using monolingual
statistical machine translation. In Proceedings of
Recent Advances in Natural Language Processing
(RANLP 2011), Hissar, Bulgaria.

R. Yangarber, R. Grishman, P. Tapanainen, and S. Hut-
tunen. 2000. Unsupervised Discovery of Scenario-
Level Patterns for Information Extraction. In
Proceedings of ANLP-NAACL 2000, Seattle, USA,
2000.

V. Zavarella, H. Tanev, and J. Piskorski. 2008. Event
Extraction for Italian using a Cascade of Finite-State
Grammars. In Proceedings of FSMNLP 2008.

118


