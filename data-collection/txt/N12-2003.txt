










































Beauty Before Age? Applying Subjectivity to Automatic English Adjective Ordering


Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 11–16,
Montréal, Canada, June 3-8, 2012. c©2012 Association for Computational Linguistics

Beauty Before Age? 

Applying Subjectivity to Automatic English Adjective Ordering  

    
Felix Hill 

Dept. of Theoretical & Applied Linguistics  

and Computer Laboratory 

University of Cambridge 

Cambridge CB3 9DA, UK 
fh295@cam.ac.uk 

 

 

 
 

Abstract 
The preferred order of pre-nominal adjectives 

in English is determined primarily by seman-

tics.  Nevertheless, Adjective Ordering (AO) 

systems do not generally exploit semantic fea-

tures.  This paper describes a system that or-

ders adjectives with significantly above-

chance accuracy (73.0%) solely on the basis 

of semantic features pertaining to the cogni-

tive-semantic dimension of subjectivity.  The 

results indicate that combining such semantic 

approaches with current methods could result 

in more accurate and robust AO systems. 

1 Introduction 

As a significant body of linguistic research has 

observed (see e.g. Quirk et al. (1985)), English pre-

nominal adjective strings exhibit subtle order re-

strictions.  Although example (2), below, does not 

represent a clear-cut violation of established 

grammatical principles, it would sound distinctly 

unnatural to native speakers in the majority of con-

texts, in contrast to the entirely unproblematic (1).  

(1)    He poked it with a long metal fork   

(2) ? He poked it with a metal long fork 

The problem of determining the principles that go-

vern Adjective Ordering (henceforth, AO) in Eng-

lish has been studied from a range of academic 

perspectives, including philosophy, linguistics, 

psychology and neuroscience. AO is also of inter-

est in the field of Natural Language Processing 

(NLP), since a method that consistently selects 

felicitous orders would serve to improve the output 

of language modeling and generation systems.  

Previous NLP approaches to AO infer the 

ordering of adjective combinations from instances 

of the same, or superficially similar, combinations 

in training corpora (Shaw & Hatzivassiloglou, 

1999) (Malouf, 2000), or from distributional ten-

dencies of the adjectives in multiple-modifier 

strings (Mitchell, 2009) (Dunlop, Mitchell, & 

Roark, 2010).  Such methods are susceptible to 

data sparseness, since the combinations from 

which they learn are rare in everyday language.  

By contrast, the approach taken here deter-

mines AO based on semantic features of adjec-

tives, guided by the theoretical observation that the 

cognitive notion of subjectivity governs ordering in 

the general case (Adamson, 2000).  The semantic 

features developed are each highly significant pre-

dictors of AO, and they combine to classify com-

binations with 73.0% accuracy. These preliminary 

results indicate that semantic AO systems can per-

form comparably to existing systems, and that 

classifiers exploiting semantic and direct evidence 

might surpass the current best-performing systems.  

2 Previous research 

The subtle nature of human ordering preferences 

makes AO a particularly challenging NLP task.  In 

perhaps the first specific attempt to address the 

problem, Shaw and Hatzivassiloglou (1999) apply 

a direct evidence method.  For a given adjective 

combination in the test data, their system searches 

a training corpus and selects the most frequent or-

dering of that combination.  Because there is no 

basis to determine the order of adjective combina-

tions that are not in the training data, Shaw and 

Hatzivassiloglou extend the domain of the classifi-

11



er by assuming transitivity in the order relation, 

increasing the coverage with only a small reduc-

tion in accuracy.  Nevertheless, the system remains 

highly dependent on the domain and quantity of 

training data.  For example, accuracy is 92% when 

training and test data are both within the medical 

domain but only 54% in cross-domain contexts.     

Malouf (2000) combines a direct evidence 

approach with an alternative method for extending 

the domain of his classifier.  His system infers the 

order of unseen combinations from ‘similar’ seen 

combinations, where similarity is defined purely in 

terms of morphological form.  The method works 

by exploiting a degree of correlation between form 

and order (e.g. capital letters indicate nominal 

modifiers, which typically occur to the right). 

Mitchell (2009) applies a less ‘direct’ ap-

proach, clustering adjectives based on their posi-

tion in multiple-modifier strings. Although 

Mitchell’s classifier requires no direct evidence, 

data sparseness is still an issue because the strings 

from which the system learns are relatively infre-

quent in everyday language.  Dunlop et al. (2010) 

apply Multiple Sequence Alignment (MSA), a sta-

tistical technique for automatic sequence ordering, 

which, as with Malouf’s system, quantifies word-

similarity based solely on morphological features.  

Despite the greater sophistication of these more 

recent approaches, Mitchell et al. (2011) showed 

that a simple n-gram (direct evidence) classifier 

trained on 170 million words of New York Times 

and Wall Street Journal text and tested on the 

Brown Corpus  (82.3% accuracy) outperforms both 

the clustering (69.0%) and MSA (81.8%) methods. 

Wulff (2003) uses Linear Discriminant 

Analysis (LDA) to quantify the effects of various 

potential AO correlates, and confirms that seman-

tic features are better predictors than morphologi-

cal and syntactic features.  The features, extracted 

from the 10-million word Spoken British National 

Corpus (BNC) and weighted by LDA, combine to 

predict unseen adjective orders with 72% accuracy.   

Wulff’s study is unique in applying seman-

tics to the problem, although her focus is theoreti-

cal and several features are implemented manually.  

The next section describes the theoretical basis for 

a fully-automated semantic approach to AO that 

could help to resolve the issues of data sparsity and 

domain dependence associated with the direct evi-

dence methods described above.  

 

2.1 The subjectivity hypothesis 

Although phonetic, morphological and syntactic 

factors influence AO in specific contexts, there is 

consensus in the theoretical literature that seman-

tics is the determining factor in the general case 

(see Quirk et al. (1985) for further discussion).  

Several semantic theories of AO make use of the 

cognitive linguistic notion of subjectivity (Quirk et 

al. 1985; Hetzron, 1978; Adamson 2000).  Subjec-

tivity in this context refers to the degree to which 

an utterance can or cannot be interpreted indepen-

dently of the speaker’s perspective (Langacker, 

1991).  For example, the deictic utterance (3) is 

more subjective than (4) since its truth depends on 

the speaker’s location at the time of utterance.   

(3) James is sitting across the table 

(4) James is sitting opposite Sam 

In relation to AO, Quirk et al, Hetzron and Adam-

son each support some form of the subjectivity hy-

pothesis: that more subjective modifiers generally 

occur to the left of less subjective modifiers in pre-

nominal strings.  For example, in (5) the adjective 

big tells us about the relation between the car and 

the speaker’s idea of typical car size.  This ascrip-

tion is less objectively verifiable than that of car 

color, so big occurs further from the head noun.  

The position of oncoming in (6) reflects the high 

inherent subjectivity of deictic modifiers.   

(5)  A big red Italian car        (BNC) 

(6)  An oncoming small black car (BNC) 

 

 

 

 

 

 

 

 

Figure 1:  Diachronic variation of preferred AO 

 

To illustrate a process of changing AO preferences 

that can be explained in a compelling way by the 

subjectivity hypothesis, the 1 trillion-word Google 

n-Gram Viewer was queried (Figure 1).  The two 

Frequency 

(% corpus)  

Year  

“gay young man”  

“young gay man”  

12



lines indicate the frequency of the strings ‘gay 

young man’ and ‘young gay man’ in the Corpus 

from 1950 to 2000, as the pre-eminent meaning of 

gay evolved from the subjective merry to the cate-

gorical, well-defined homosexual.  As the graph 

shows, this reduction in subjectivity has been ac-

companied by a marked increase in the tendency of 

gay to appear closer to the noun in such strings.  

3 System design 

The AO system described below applies the theo-

retical findings presented above by extracting from 

training data various subjectivity features of adjec-

tives and applying this information to classify in-

put orderings as correct or incorrect.
1
  System 

operation and evaluation consisted of 5 stages.  

Extracting feature profiles:  The 200 highest-

frequency adjectives in the BNC were extracted.  

Following Wulff (2003, p. 6), three items, other, 

only and very were removed from this list because 

they occur in right-branching structures.  For the 

remaining adjectives, a ‘profile’ of feature values 

(c.f. Table 1, below), was extracted from 24 mil-

lion words (Sections A-C) of the written BNC. 

Generating gold-standard orderings:  From the 

197 adjectives, 19,306 unordered pairs ��� , ��� 
were generated. The bigram frequencies of the 

strings ��� , ��	 and ��� , ��	 were then extracted 
from the 1 billion-word Google n-gram Corpus.  

From this data, the 12,000 pairs ��� , ��� with the 
largest proportional difference in frequency be-

tween ��� , ��	 and ��� , ��	 were selected. 
Defining test and training sets: A set of 12,000 

ordered triples 
�� , �� , ��� ,��	� was generated, 
where ��� ,��	 is an indicator function taking the 
value 1 if ��� , ��	 is the preferred ordering in the 
Google corpus and 0 if ��� , ��	 is preferred.  
Some of the triples were re-ordered at random to 

leave an equal number of preferred and dispre-

ferred orderings in the data.  These triples were 

populated with feature profiles, to create vectors 


��� , … , ��� , ���� , … ���� , ��� ,��	 � 

                                                           
1 The system operates on adjectival and nominal modifiers but 

not on articles, determiners, degree modifiers and other non-

adjectival pre-modifiers.   

where ���� is the value of the ��� feature of the ad-
jective ��, and n is the total number of features.  
The set of vectors was then randomly partitioned in 

the ratio 80:20 for training and testing respectively.  

Training the classifier:  A logistic regression was 

applied to the set of training vectors, in which the 

first 2n elements of the vectors were independent 

variables and the final element was the dependent 

variable.    Logistic regression has been shown to 

be preferable to alternatives such as Ordinary Least 

Squares and LDA for binary outcome classification 

if, as in this case, the independent variables are not 

normally distributed (Press & Wilson, 1978). 

Evaluation: Performance was determined by the 

number of pairs in the test data correctly ordered 

by the classifier.  Steps 3-5 were repeated 4 times 

(5-fold cross-validation), with the scores averaged.   

3.1 The Features 

Of the features included in the model, 

COMPARABILITY and POLARITY are shown to 

correlate with human subjectivity judgments by 

Wiebe and colleagues (see e.g. Hatzivassiloglou & 

Wiebe, 2000). The remainder are motivated by 

observations in the theoretical literature.   

MODIFIABILITY:  Gradable adjectives, such as 

hot or happy, tend to be more subjective than pro-

totypically categorical adjectives, such as square 

or black (Hetzron, 1978).  Unlike categorical ad-

jectives they admit modification by intensifiers 

(Paradis, 1997).  Therefore, the feature 

MODIFIABILITY is defined as the conditional 

probability that an adjective occurs immediately 

following an intensifier given that it occurs at all.
2
   

 

����������� !"�#   =   ∑ �&'("�), �	#*∈,�&'("�#  
 

� = ��'-&'' )�����'&.�    
�/, !	  �.   ℎ' ��-&�) ′1�&� / �����1'� �! 1�&� !′ 
 

COMPARABILITY:  Gradable adjectives also 

have comparative and superlative forms, whereas 

prototypically categorical adjectives do not.  Given 

the association between gradability and subjectivi-

ty, the feature COMPARABILITY is defined as the 

probability of an adjective occurring in compara-

tive or superlative form given it occurs at all.   

                                                           
2 The set of intensifiers is taken from (Paradis, 1997). 

13



 new good old different local 

MODIF 0.0010 0.0529 0.0208 0.0887 0.0004 

COM 0.0079 0.4881 0.2805 0.0011 0.0045 

PRED 0.0100 0.1018 0.0289 0.0806 0.0069 

POL 0.0000 1.0000 0.0000 0.0000 0.0000 

ADV 0.0220 0.0008 0.0000 0.0318 0.0478 

NOM 0.2900 0.0999 0.0113 0.0000 0.0212 

Table 1:  Example feature profiles 

2�)3�&����� !"�#   =   �&'("�4# +  �&'("�6#�&'("�# + �&'("�4# +  �&'("�6# 
 

  �4 = 7�)3�&� �8' ��&) �� �       �6 = .93'&�� �8' ��&) �� �     
 

PREDICATIVITY: Adjectives can be applied in 

both attributive (‘the red car’), and predicative 

(‘the car is red’) constructions.  Bolinger (1967) 

suggests that predicative constructions are concep-

tualized more dynamically or temporarily than at-

tributive constructions.  Since dynamic properties 

are generally ascribed more subjectively than per-

manent properties (Langacker, 1991), Bolinger’s 

intuition implies an association between subjectivi-

ty and predicative constructions.  Indeed, many 

objective modifiers sit uncomfortably in predica-

tive contexts, as shown by (7) and (8). 

(7)    I live in a brick house 

(8) ? The house I live in is brick  

The feature PREDICATIVITY is therefore defined 

as the probability that an adjective occurs in a pre-

dicative construction given that it occurs at all.  

The measure is implemented by counting the num-

ber of times the adjective immediately follows 

some form of an English copula verb.
3
   

 

:&'��7� �8�!"�# =   ∑ �&'("�7, �	#;∈<�&'("�#  
 
2 = .'  �� =>-��.ℎ 7�39�� 8'&�. �> ��� �>��'7 '� ��&). 
     

POLARITY: An adjective is said to be polar if it 

typically attributes a positive (kind, healthy, 

strong) or negative (poor, selfish, rotten) characte-

ristic.  Semi-supervised methods for automatically 

detecting adjective polarity have been developed 

(Hatzivassiloglou & McKeown, 1997), and applied 

to subjectivity analysis by Wiebe (2000).  

POLARITY is implemented as a binary feature, 

whose value depends on whether or not the adjec-

tive appears in a list of 1,300 polar adjectives ex-

tracted by Hatzivassiloglou & Mackeown. 

 

:���&� !"�# =  ? 1   �� � ∈ A⋃C0    �� � ∉ A⋃C F 
 

A = � ��G'7 �8'. ���'��'� �. 3�.� �8'�         
C = ���G'7 �8'. ���'��'� �. >'-� �8'� 
 

                                                           
3 The copula verbs list was compiled manually by the author. 

ADVERBIABILITY:  Quirk (1985, p 1339) notes 

that evaluative adjectives tend to develop derived 

adverbial forms, whereas more objective adjectives 

do not.  For example, nice, beautiful and, careful 

correspond to the adverbs nicely, beautifully, and 

carefully, whereas no such derived forms exist for 

the more objective adjectives male, English and 

brown. The ADVERBIABILITY of an adjective is 

defined as the ratio of derived adverbial forms to 

total base and adverbial forms in the corpus.    

 

��8'&������� !"�#   =   �&'("�
∗#

�&'("�# + �&'("�∗# 
 
�∗ = ��8'&���� ��&) �'&�8'� �&�) �     
 

NOMINALITY:  Wullf (2003) reports statistical 

evidence that more ‘noun-like’ modifiers appear 

closer to the head in modifying strings.  Combina-

tions such as ‘bread knife’ or ‘police car’, often 

analyzed as noun-noun compounds rather than 

modifier/noun combinations, represent the clearest 

such examples.  Amongst more prototypical adjec-

tives, some, such as green, or male have nominal 

senses (‘village green’, ‘unidentified male’), whe-

reas others do not.  Separately, Hatzivassiloglou 

and Wiebe (2000) report a statistical correlation 

between the number of adjectives in a text and 

human judgments of subjectivity.  These observa-

tions suggest that adjectives are inherently more 

subjective than nouns, and further that noun-like 

‘behavior’ might indicate relative objectivity with-

in the class of adjectives.  Consequently, the fea-

ture NOMINALITY is defined, following Wulff, as 

the probability that an adjective is tagged as a noun 

given that it is tagged as either an adjective or a 

noun. It is the only feature that is expected to exhi-

bit an inverse correlation with subjectivity.   

I�)�>��� !"�#   =   �&'(" �>#�&'("��# + �&'(" �># 
 
 �� = ��G'7 �8' �  �--'� �. >�9>        �J = ��G'7 �8' �  �--'� �. ��G'7 �8' 

14



O
b
se
rv
ed

 

Predicted 
  Training Data 
  Incorrect Correct % Correct 

Incorrect 2773 1637 62.9 

Correct 1120 4101 78.5 

Overall%     71.4 

  Test Data 
  Incorrect Correct % Correct 

Incorrect 696 370 65.3 

Correct 270 1031 79.2 

Overall%     73.0 

Table 2:  Overall results of model cross-validation  

Fea-

ture  

Regression 

Coefficient 

Predictor 
Signifi-

cance 

Perform-
ance in 

Isolation 

Compari-

son of  
A1 / A2 

Means 

MODIF 5.205 .000 62.9% 0.000 

COM .177 .381 58.7% 0.000 

PRED 3.630 .000 68.6% 0.000 

POL .339 .000 60.4% 0.000 

ADV 1.503 .000 62.8% 0.000 

NOM -.405 .000 58.4% 0.000 

Table 3:  Influence of individual features 

4 Results  

The performance of the classifier is promising with 

respect to the intuition that semantic features can 

be usefully applied to AO systems.  A chi-square 

test reveals the features collectively to be highly 

significant predictors of AO (K� = 2257.25, 3 <
0.001∗∗∗#. Once trained, the system orders unseen 
combinations in the test data with accuracy of 

73.0%, as detailed in Table 2.  This figure is not 

directly comparable with previous work because of 

differences in the evaluation framework. 

It is notable that the accuracy of the classifi-

er rises to 86.2% when the test data is hand-picked 

as the 3000 pairs for which the strength of ordering 

preference is highest.
4
  This suggests that the ap-

proach could be particularly effective at detecting 

highly unnatural combinations.  Moreover, the per-

formance when tested on the 3000 (unseen) pairs 

with the lowest ordering preference is 70.1%, indi-

cating the potential to cope well with marginal cas-

es and rare combinations.   

As Table 3 shows, all features apart from 

COMPARABILITY are statistically significant pre-

dictors in the model "3 < 0.001∗∗∗#. In addition, 
the mean value of each feature over adjectives in 

first position �� differs significantly from the mean 
over adjectives in second position �� (  ≥ 28.07 
in each case, �� = 11,283).  Whilst relatively the 
weakest predictor, COMPARABILITY in isolation 

does predict AO at above-chance 

cy "58.7%, 3 < 0.001∗∗∗# 
                                                           
4 The 3000 pairs for which the proportional preference for one 

ordering over another in the Google n-Gram corpus is highest 

and for which the total frequency of the pair exceeds 500. 

. Its low significance in the overall model re-

flects its high level of interaction with other fea-

tures; in particular, MODIFIABILITY (Pearson 

Correlation: .367, 3 < 0.001∗∗∗).  The relative 
magnitude of the model coefficients is not infor-

mative, since the  measurement scale is not com-

mon to all features.  Nevertheless, the negative 

regression coefficient of NOMINALITY confirms 

that this feature correlates inversely with distance 

from the noun.    

To test the influence of the training corpus size on 

system performance, features were extracted from 

BNC Section A (7 million words) rather than Sec-

tions A-C (24 million words) in a separate experi-

ment. This adjustment resulted in a reduction in 

classifier accuracy from 73.0% to 71.4%, indicat-

ing that performance could be significantly im-

proved by training on the full BNC or even larger 

corpora.  Further improvements could be achieved 

through the combination of semantic and ‘direct’ 

features.  To illustrate this, the feature 

LEFTTENDENCY, a measure of the likelihood that 

an adjective occurs immediately to the left of 

another adjective in the training data, was added. 

This adjustment raised the classifier accuracy from 

73.0% to 76.3%.  It should also be noted that many 

of the features in the current system are extracted 

via measures that approximate syntactic dependen-

cy with bigram context.  It is an empirical question 

whether the additional complexity associated with 

more precise measures (for example, applying de-

pendency parsing) would be justified by perfor-

mance improvements.  

 

 

15



5 Conclusion 

This paper has tested the efficacy of applying au-

tomatic subjectivity quantification to the problem 

of AO.  The reported results highlight the utility of 

such semantically oriented approaches.  Although 

direct comparison with existing systems was 

beyond the scope of this study, exploratory analys-

es suggested that a refined version of this system 

might compare favorably with reported bench-

marks, if trained on a corpus of comparable size.  

Nevertheless, the comparatively weak per-

formance of the present system on previously seen 

examples (‘underfitting’, see Table 2) is strong 

evidence that six features alone are insufficient to 

capture the complexity of ordering patterns.  

Therefore, beyond the adjustments discussed 

above, the next stage in this research will evaluate 

the effects of combining semantic features with 

direct evidence in a single system.  Other future 

work might apply subjectivity features to cluster 

adjectives into classes pertinent to AO, perhaps in 

combination with independent distributional meas-

ures of semantic similarity.  Finally, the approach 

presented here for English AO could have applica-

tions across languages, and may also be applicable 

to related tasks, such as ordering binomials
5
, pars-

ing noun phrases (‘wild animal hunt’ vs. ‘wild 

birthday party’) and selecting thematically appro-

priate modifiers for a given head noun. 

Some interesting theoretical insights also 

emerge as a corollary to the results of this study.  

The supposition that gradability, polarity, adver-

biability, predicativity and ‘nouniness’ can be as-

sociated, either positively or negatively, with 

subjectivity, was confirmed. Moreover, the per-

formance of the classifier lends support to the sta-

tus of subjectivity as a determining principle of 

AO, and an important dimension of adjective se-

mantics in general.   As such, the reason we say 

beautiful English rose, (c.240,000 direct matches 

on Google) and not English beautiful rose 

(c.2,730) is because beauty is in the eye of the be-

holder, whereas nationality, evidently, is not. 

 

                                                           
5 Binomials are noun or adjective combinations separated by 

coordinating conjunctions, such as tired and emotional and 

salt and pepper.  Quirk et al. (1985, p. 1342) observe connec-

tions between binomial ordering and AO.   

Acknowledgments 

Thanks to Anna Korhonen, Paula Buttery and Syl-

via Adamson for helpful guidance and comments. 

References  

Adamson, S.  2000.  Word Order Options and Category 

Shift in the Premodifying String.  In O. Fischer,  

Pathways of Change: Grammaticalization in English 

(pp. 39-66).  Amsterdam: John Benjamins. 

Bolinger, D.  1967.  Adjectives in English: Attribution 

and Predication.  Lingua 18 ,  1-34. 

Dunlop, A., Mitchell, M. & Roark, B.  2010. 

Prenominal Modifier Ordering via Multiple Sequence 

Alignment.  2010 Annual Conference of the .orth 

American Chapter of the ACL (HLT-.AACL 2010). 

Hatzivassiloglou, V. & McKeown, K.  1997. Predicting 

the Semantic Orientation of Adjectives. Annual 

Meeting Assoc. Comp.Ling. ACL '97, 174-181. 

Hatzivassiloglou, V. & Wiebe, J.  2000.  Effects of 

Adjective Orientation and Gradability on Sentence 

Subjectivity.  International Conference on 

Computational Linguistics, COLI.G- '00.  

Hetzron, R.  1978. On the Relative Order of Adjectives. 

In I. H. (Ed.),  Language Universals. Tübingen: Narr. 

Langacker, R. 1991. Foundations of Cognitive 

Grammar. Stanford, CA: Stanford University Press. 

Malouf, R.  2000.  The Order of Prenominal Adjectives 

in Natural Language Generation.  Proc. 38
th

 Annual 

Meeting, Assoc. Comp. Linguistics, ACL ’00, 85–92. 

Mitchell, M.  2009.  Class-based Ordering of 

Prenominal Modifiers.  Proc.12
th

 European 

Workshop, .at.Lang. Generation, E.LG '09, 50–57. 

Mitchell, M. Dunlop, A. & Roark, B.  2011.  Semi-

Supervised Modeling for Prenominal Modifier 

Ordering.  Proc. 49
th

 Annual Meeting of the Assoc. 

Comp. Ling., ACL '11,  236–241. 

Paradis, C.  1997.  Degree Modifiers of Adjectives in 

Spoken British English.  Lund: Lund University Press. 

Press, S. J. & Wilson, S.  1978.  Choosing Between 

Logistic Regression and Discriminant Analysis. 

Journal of American Statistical Association,  699-705. 

Quirk, R. Greenbaum, A. Leech, G. & Svartvik, J.  

1985.  A Comprehensive Grammar of the English 

Language.  London: Longmans. 

Shaw, J. & Hatzivassiloglou, V. 1999. Ordering Among 

Premodifiers.  Proc. 37
th

 Annual Meeting, Association 

of Computational Linguistics, ACL ’99 , 135–143. 

Wiebe, J.  2000.  Learning Subjective Adjectives from 

Corpora.  Proc. 17
th

 .ational Conference on Artificial 

Intelligence (AAAI-2000). 

Wulff, S.  2003.  A Multifactorial Analysis of Adjective 

Order in English.  International Journal of Corpus 

Linguistics, 245–282. 

 

16


