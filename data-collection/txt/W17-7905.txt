The Proceedings of the First Workshop on Human-Informed Translation and Interpreting Technology (HiT-IT), pages 36‚Äì43,

36

Varna, Bulgaria, Sept 7, 2017

https://doi.org/10.26615/978-954-452-042-7_005

Interpreting Strategies Annotation in the WAW Corpus

Irina Temnikova1, Ahmed Abdelali1, Samy Hedaya2,

Stephan Vogel1, and Aishah Al Daher2

1Qatar Computing Research Institute, HBKU, Doha, Qatar
2Translation and Interpreting Institute, HBKU, Doha, Qatar

1,2{itemnikova,aabdelali,shedaya,svogel,aaldaher}@hbku.edu.qa

Abstract

With the aim to teach our automatic
speech-to-text translation system human
interpreting strategies, our Ô¨Årst step is to
identify which interpreting strategies are
most often used in the language pair of our
interest (English-Arabic).
In this article
we run an automatic analysis of a corpus
of parallel speeches and their human inter-
pretations, and provide the results of man-
ually annotating the human interpreting
strategies in a sample of the corpus. We
give a glimpse of the corpus, whose value
surpasses the fact that it contains a high
number of scientiÔ¨Åc speeches with their
interpretations from English into Arabic,
as it also provides rich information about
the interpreters. We also discuss the dif-
Ô¨Åculties, which we encountered on our
way, as well as our solutions to them: our
methodology for manual re-segmentation
and alignment of parallel segments, the
choice of annotation tool, and the anno-
tation procedure. Our annotation Ô¨Åndings
explain the previously extracted speciÔ¨Åc
statistical features of the interpreted cor-
pus (compared with a translation one) as
well as the quality of interpretation pro-
vided by different interpreters.

1

Introduction

As manual translation is slow, often repetitive, and
requires a lot of cognitive efforts and the use of
additional resources (e.g. dictionaries, encyclope-
dias, etc.), part of it is now done automatically.
Thanks to these recent advances in technology,
translation is done in a much faster and sometimes
more accurate way. One of the automatic trans-
lation tools, Machine Translation (MT) (Hutchins

and Somers, 1992) in its present state is used
(with pre- and post-editing) in many companies
and public institutions.

Despite recent improvements in MT (e.g. Neu-
ral MT), automatic MT systems still lack the pre-
cision and Ô¨Çuency of human translators and inter-
preters (Shimizu et al., 2013), and are often criti-
cized because of that. Due to this, we want to teach
our in-house speech-to-text (S2T) machine trans-
lation system (Dalvi et al., 2017) the techniques
human interpreters use.

Human interpreters run several heavy-load pro-
cesses in parallel (e.g. processing speaker‚Äôs input,
translating and pronouncing the previously heard
input, monitoring their own speech, and correct-
ing previous errors (Kroll and De Groot, 2009).
To overcome time and brain processing limita-
tions, and the inability to go back and correct their
own output, they use many strategies (Kroll and
De Groot, 2009; Al-Khanji et al., 2000; Liontou,
1996).

Before learning which human interpreting
strategies can improve our S2T system, we run a
corpus analysis.

We use a corpus of transcripts of conference
speeches, their simultaneous interpretations (per-
formed by professional interpreters), and their
manual translations. We Ô¨Årst extract surface fea-
tures (Section 4). Next, we manually annotate
coarse-grained interpreting strategies (Section 6)
in a sample of the corpus.

The rest of this article is structured as follows:
Section 2 summarizes the related work; Section
3 presents our WAW corpus, Section 4 presents
some corpus statistics; Section 5 describes the cor-
pus segmentation and alignment methods; Section
6 provides the annotation procedure. Section 7
presents the annotation results, and Section 8 is
the Conclusion.

37

2 Related Work
Before being able to identify which Interpreters‚Äô
Strategies (IS) could beneÔ¨Åt our speech-to-text
translation system, we Ô¨Årst studied the existing
work on Interpreting Strategies in Interpreting
Studies.

There is substantial research in this area (es-
pecially corpus-based), e.g.
(Roderick, 2002;
Shlesinger, 1998; Bart≈Çomiejczyk, 2006; Liontou,
2012; Hu, 2016; Wang, 2012; Bendazzoli and San-
drelli, 2009; Lederer, 1978; Al-Khanji et al., 2000;
Liontou, 1996; Tohyama and Matsubara, 2006).

The research outlines a number of strategies
interpreters use in order to alleviate the work-
ing memory overload and time shortage. Al-
though different researchers divide and classify
them differently,
the strategies can be roughly
classiÔ¨Åed (Kalina, 1998; Al-Khanji et al., 2000)
into:

1. Comprehension strategies (e.g. prepara-
tion, gathering of
ter-
minology check-up, anticipation, chunking
a.k.a. segmentation or salami-technique),

topic information,

2. Target-text production strategies

(e.g.
source-text conditioned strategies, such as
transcoding;
target-text conditioned strate-
gies, such as ear-voice span manipulation,
expansion, and compression or simpliÔ¨Å-
cation techniques ‚Äì such as: passivization
and omission; self-correction, decision for
no-self-correction),

3. Other strategies (e.g. buying time by pro-
nouncing generic utterances or delaying the
response, self-monitoring),

4. Compensatory strategies (e.g. approxima-

tion, Ô¨Åltering, omissions, substitutions).

Some researchers investigate language-pair-
speciÔ¨Åc strategies, e.g. Tohyama and Matsubara
(2006); Liontou (1996).

MT researchers‚Äô interest on applying inter-
preters skills to MT was driven by the advances
in automatic Speech Translation (ST). Languages
with different syntax and word order are a prob-
lem for real time and simultaneous ST. Paulik and
Waibel (2009) exploited the availability of paral-
lel recordings to leverage on the scarcity of paral-
lel text between English and Spanish. In this way
they achieved better than expected performance
in MT. Their Ô¨Åndings were a motivation to ex-
ploit the data produced by interpreters in order to

further improve MT. Shimizu et al. (2013) used
information learned from simultaneous interpre-
tation data to improve their MT system between
Japanese and English, as these two languages have
very different grammatical structure and word or-
der. Results showed that emulating the simultane-
ous interpreters style helped both to improve the
accuracy of the system while minimizing the de-
lay before translation generation. Sridhar et al.
(2013) made a corpus analysis for simultaneity,
hesitations, compression, the lag between source
language and target language words, and the use of
deixis. He et al. (2016) also made corpus analysis
to discover which strategies interpreters use and
analysed segmentation, passivization, generalisa-
tion, and summarization. Finally, Hauenschild and
Heizmann (1997) are a collection of papers from
the time of VerbMobil, which contains MT papers
inspired by translation and interpreting, as well
as translation and interpreting papers, which con-
tribute to MT.

3 The WAW Corpus

The corpus we use in our experiment is a corpus of
recordings of speeches/lectures from conferences
held in Doha, Qatar. The WAW corpus contains
521 recorded sessions (127h 10min 38sec) col-
lected during talks at WISE 2013 (World Inno-
vation Summit for Education)1, ARC‚Äô14 (Qatar
Foundation‚Äôs Annual Research Conference, a gen-
eral conference on many topics)2, and WISH 2014
(World Innovation Summit for Health)3 research
conferences in Doha, Qatar. Both speeches in En-
glish as a source language (subsequently trans-
lated into Modern Standard Arabic), and in Ara-
bic as a source language (subsequently translated
into English) are present. From the ethical point
of view, all conference speakers signed a release
form to transfer the ownership to the conferences
organisers (Qatar Foundation). The names of in-
terpreters are not published.

The speeches contained in the corpus have

been:

1. Interpreted by professional

interpreters

hired by the conference organisers.

2. Transcribed by professional transcribers,

1http://www.wise-qatar.org/2013-summit-reinventing-

education-life.

2http://marhaba.qa/qatar-foundations-annual-research-

conference-arc14-calls-on-local-research-expertise/.

3http://www.wish-qatar.org.

38

according to our guidelines.

3. Translated by professional

translators.
The transcripts of both the original speakers
and their interpretations have been translated
by professional translators, according to our
guidelines, into Arabic (if the original lan-
guage was English) or into English (if the
original language was Arabic).

95% of the source/original speeches were in En-

glish.

Figure 1 shows the resulting corpus composi-
tion. For each speech, we have two audios and
four corresponding texts (Original transcript, In-
terpretation transcript, translation of the source
language original transcript and the translation for
the target language interpretation transcript).

Out of the 521 recorded sessions, 266 sessions
(63h 48min 05sec) contain the complete pack of
translations of both source speech transcripts and
interpreted target language transcripts.

In total, there were 12 interpreters. Accord-
ing to information from the conference organisers,
most of the interpreters were experienced, but we
do not have any details about their level of proÔ¨Å-
ciency or areas of expertise.

Figure 1: WAW Corpus Composition.

Out of this data, we have mainly used the origi-

nal speakers‚Äô and interpreters‚Äô transcripts.

4 WAW Corpus‚Äô Assessment
Table 1 shows WAW‚Äôs size in number of Ô¨Åles, time
recorded, number of lines/segments, and number
of words.

The different number of Segments between
the Arabic transcripts and the English ones was
due to the fact that the initial segmentations of the
original speakers‚Äô audios and interpreters‚Äô audios,
as received by the companies were done indepen-
dently by different transcribers.

Figure 2 shows the different segmentation of the
same original speech transcript and its interpreta-
tion (both audios with a length of around 50 sec).

Figure 2:
Transcripts Segmentation Differences.

Original Speaker‚Äôs vs Interpreter‚Äôs

The segmentation difference was one of the dif-
Ô¨Åculties we encountered on our way to manually
annotating the transcripts. Our solution is ex-
plained in Section 5.

The different number of Words between En-
glish and Arabic, which can be observed in Ta-
ble 1 is another very interesting point. As Arabic
is an agglutinative language, it has fewer words.
Thus, it has been observed that the average ratio
between English and Arabic words in the original
texts and their translations is around 1.5 (Salameh
et al., 2011). We have computed this ratio both
for the transcripts (original vs interpreted, as vis-
ible in Figure 1 horizontally, i.e. A1 vs B1), and
for the manual translations vs the transcripts (ver-
tically, A1 vs B2 and B1 vs A2) to test if this ratio
is conÔ¨Årmed in our cases. We have found that ver-
tically, in A1 vs B2 and B1 vs A2, the average ra-
tios are around 1.5, which conÔ¨Årms the previously
observed, and that there is a very small divergence.
However, Table 1 shows that horizontally, the ratio

39

Language N. of Ô¨Åles Total Time N. of Segments N. of Words N. of Words Translation

Arabic
English
Totals.

133
133
266

31:54:33
31:54:33
63:49:05

9,555
26,824
36,379

159,657
289,109
448,766

198,588
224,296
422,884

Table 1: WAW Corpus‚Äô Size.

between English and Arabic words in interpreters‚Äô
vs original speakers‚Äô transcripts is higher, around
1.8 (289,109/159,657 = 1.81). Our hypothesis is
that interpreters add more words than translators
do.

Figure 3 shows the horizontal (A1 vs B1) word
ratios for each interpreter. Comparing to the re-
sults for manual translations, where there is less
variety and all ratios tend to be close to 1.5, we
see larger differences for some interpreters (longer
colored rectangle). This shows that the same inter-
preter added a different number of words in Ara-
bic vs. English in the different speeches he/she
interpreted. E.g. interpreters I07 and I09 have the
largest variety, while I01 and I08 have the smallest
variety.

This word ratios higher variety further moti-
vated our wish to have a more detailed look into
the behaviour of single interpreters via manual an-
notation (see Sections 6 and 7).

Figure 3: Word Ratios between Original Speakers‚Äô
transcripts and Interpreters‚Äô Transcripts, per Inter-
preter.

5 Document Segmentation and

Alignment

As said earlier, the original segmentation differ-
ence was one of the difÔ¨Åculties on our way, as we
wanted to align parallel segments so the annotator

annotates both the original and the interpretation
segments in parallel, and later we learn automati-
cally the segments correspondence.

Table 2 shows examples of Ô¨Åles from the same
session/lectures. E.g., File 2 has 286 English seg-
ments, and only 94 Arabic segments. The same
happens with all the Ô¨Åles.

For our annotation experiment, we worked on
a corpus sample, composed by the parts of 4 Ô¨Åles
with a total of 7500 words, interpreted by 2 inter-
preters (I09 and I10). I10 did the most interpre-
tations across the three conferences. This made
us hypothesize that he/she was the most expert.
I09 had the average words ratio closest to written
translation (1.5) and had a high words ratio vari-
ety. We hypothesized that this interpreter could be
a beginner.

First, we attempted to automatically re-align the
texts using automatic alignment tools (Varga et al.,
2006; Ma, 2010; Braune and Fraser, 2010). The
results were unsatisfactory as interpreters change
both the word order and lexical choice by para-
phrasing or summarizing the original speaker, so
alignment tools could not Ô¨Ånd enough parallel seg-
ments.

Manual re-segmentation and alignment was
done by one expert, native speaker of Arabic with
advanced level of English, who was a specialist in
video subtitles segmentation. The process took in
total 7h 49min 16sec. Besides the obvious learn-
ing curve for this highly speciÔ¨Åc task, the average
speed was 0.17 English w/sec (words/second) and
0.10 Arabic w/sec.

Another difÔ¨Åculty was Ô¨Ånding an appropri-
ate tool for both re-segmentation, alignment,
and annotation. We split this task into 1. Re-
segmentation and alignment and 2. Annotation.
For (1), our expert used Excel spreadsheet and
then our in-house web-based editing tool which
better visualizes the parallel segments and outputs
an unique merged Ô¨Åle. The procedure was to 1.
Segment the original speaker‚Äôs transcript, 2. Align
and segment the interpreter‚Äôs transcript, according
to (1).

3.0

2.5

2.0

1.5

1.0

)
r

/

A
n
E

(
 
o

i
t

a
R

Interpreter

I01
I02
I03
I04
I05
I06
I07
I08
I09
I10
I11
I12

I01 I02 I03 I04 I05 I06 I07 I08 I09 I10 I11 I12

Interpreter

40

File
1
2
3
4

Interpreter
I10
I09
I10
I09

time (sec) En Segments En Words Ar Segments Ar Words Ratio
1.69
1.69
2.33
1.82

231
1296
2050
1101

559
3315
5557
3147

331
1963
2386
1728

19
94
163
89

43
286
444
274

Table 2: Expert Evaluation Data.

Initially, we followed video subtitles segmenta-
tion rules, but this resulted in too short segments,
which created problems for aligning, as often the
interpreters were changing the whole structure and
the order of clauses and phrases.

Next, we have set as main rule to have an
aligned segment in Arabic, while keeping the
length of the original English sentence as short as
possible.

The manually re-segmented and aligned version
of Figure 2 is shown in Figure 4. The empty lines
are left when there is no correspondence in the
other language.

The Ô¨Ånal WAW re-segmentation and alignment

guidelines are available online4.

Figure 4: Manually Re-Segmented and Re-
Aligned Transcript.

6 Annotation
Our annotator was a professional translator with
expertise in annotating translation strategies, na-
tive speaker of Arabic, and Ô¨Çuent in English. The
annotator passed a training on annotating around
1500 words. Training annotation was done using
Word. Four strategies have been explored: Sum-
marizing, Omission affecting the meaning, Omis-
sion not affecting the meaning and Correction.

The annotation categories for main annotation
were selected: 1) out of the interpreting strate-
gies listed in the Section 2, 2) Ô¨Åltered during an-

4Link: http://goo.gl/hjyhAz.

notator‚Äôs training, 3) coarse-grained. We have
also asked the expert to evaluate whether some of
these strategies were needed (‚Äútolerant‚Äù) or un-
necessary (‚Äúintolerant‚Äù). Our Ô¨Ånal annotation cat-
egories are: Summarizing, Omissions (tolerant,
out-of-delay, and intolerant), intolerant Additions,
and Self-correction.

Finding an annotation tool was also one of our
difÔ¨Åculties, as we needed to Ô¨Ånd a way for both
aligned segments to be annotated in parallel. Af-
ter asking in corpora mailing list 5, we found our
own solution. After producing a merged Ô¨Åle (Sec-
tion 5) with both parallel segments one after the
other, we used GATE 6. Our annotation guidelines
are available online 7 .

Four Ô¨Åles with a total of 4941 words in English
and respectively 2767 words in Arabic were anno-
tated. The source language in all Ô¨Åles was English
and the target ‚Äì Arabic. Here are our annotation
categories with their (expert‚Äôs) deÔ¨Ånitions and an
example for each category.

Summarizing (Table 3): The interpreter com-
bines two clauses into one clause capturing the
main idea and conforming to the structure of Ara-
bic. A single longer clause may also be summa-
rized by the interpreter.

Original Speaker‚Äôs Transcript

So for instance we now from
my group have spin out, they
do mental health assessment

Interpreter‚Äôs Transcript

	Ô¨Ç

¬´ ≈ì 

  
Ô¨Å


	 R	Ô¨Å	¬∏(

)	
Ô¨Ç 
+ ≈ì 

	\Àö¬∏
Translation:
In my group,
for instance, we assessed the
psychological health.

Table 3: Summarizing Strategy Example

Self-correction (Table 4): The interpreter usu-
 
(‚Äù (or) or repetition to alter a lexical

ally uses ‚Äú 
choice or correct a mispronounced word.

5https://mailman.uib.no/public/corpora/2017-

May/026526.html.

6https://gate.ac.uk/.
7Link: http://goo.gl/hjyhAz.

41

Original Speaker‚Äôs Transcript

We know where to focus on
our clinical interventions.

	  	3¬ª3 	 ‚Äù	

Interpreter‚Äôs Transcript
 
 
3¬ª
)	 Àö¬´
	 
(
(
 
( 	 	C(;  ≈ì 
	Ô¨Ç
	Ô¨Ç  
)	
+ 	C;
 ≈ì 
 
	 3 3T¬∏(

Translation:We have to be
more concentrated on inter-
ventions or on our clinical in-
terventions.

Original Speaker‚Äôs Transcript
And they examined it, and
they came out
They were extremely con-
cerned about the Dutch sys-
tem
And also the system in Ore-
gon and some of the states in
the United States.

Interpreter‚Äôs Transcript

Table 4: Self-correction Strategy Example

Table 7: Omission-out-of-delay-intolerant Strat-
egy Example

Omission-tolerant (Table 5): This strategy
is used when the information introduced by the
speaker seems to not have essential effect on the
entire meaning of the context. May also result
from the speakers frequent repetitions of the same
idea or clause.

Original Speaker‚Äôs Transcript
Thank you very much.

Interpreter‚Äôs Transcript

Table 5: Omission-tolerant Strategy Example

Omission-intolerant (Table 6): These omis-
sions affect
the overall meaning of the con-
text. They stem from interpreter‚Äôs delay, mis-
comprehension, lack of anticipation, or/and the
speaker‚Äôs speed.

Original Speaker‚Äôs Transcript

So I deal with individuals
who have traditional, you can
say traditional cultural values

Interpreter‚Äôs Transcript
 
(


	 	Ô¨Ç)
Ô¨Å¬∏( 	 )RÀá) 	)‚Äú


	 +S*  (

 
( 

)	

Translation: And I deal with
Islamic cultural questions/
issues.

Table 6: Omission-intolerant Strategy Example

Omission-out of delay-intolerant (Table 7):
This omission usually results from a long period of
delay. The interpreter loses information because
he/she may be unable to comprehend what is be-
ing said or because of the speaker‚Äôs speed.

Addition-unnecessary (Table 8): The inter-
preter adds information that seems out of context
(usually happens out of delay). However, some
interpreters use this strategy to provide more ex-
planations to the audience.

7 Annotation Results

182 instances out of 1047 segments were an-
notated (around 17%).
these, 135

Out of

Original Speaker‚Äôs Transcript

I did some work for our
Royal College of Physicians
on professionalism

And we thought very deep
and hard about what is pro-
fessionalism.

 
(

)	

	¬´ )(cid:220)  (cid:223)(:

Interpreter‚Äôs Transcript
0;
 

	 	≈íÀá(
(
	‚Äπ(3
C*( 
Translation:
I am always
taking about being profes-
sional and professionalism
		 

	 ¬∫ )¬´ 
W‚Äú 3‚Äù	Ô¨Å	
 
	 	≈íÀá(

Translation: And we think
deeply about what is profes-
sionalism

Table 8: Addition unnecessary Strategy Example

were ‚ÄúOmission‚Äù; 21 were ‚ÄúAddition‚Äù; 16 ‚ÄúSelf-
correction‚Äù and 10 ‚ÄúSummarizing‚Äù.
Figure 5
shows the tags distribution per Ô¨Åle. The annota-
tion provided some insights about our initial ob-
servations. In the cases when the num. of words
ratio was high (File 3 in Table 2), the annotations
showed a high amount of ‚ÄúOmissions‚Äù in the Ara-
bic interpretation vs. the original English speech.
‚ÄúSummarizing‚Äù contributes to this too, as shown
in Figure 5. Omissions are the major cause of
information loss ‚ÄúAddition‚Äù and ‚ÄúSelf-correction‚Äù
could balance this loss, but they are a too low num-
ber to compensate. File 1 was an exception. The
length of the Ô¨Åle (231 sec only, vs. 1000-2000 sec
the other Ô¨Åles, each) could potentially be the rea-
son why we did not observe much.

8 Conclusions & Future Work

The WAW corpus is a collection of parallel lec-
tures translated and interpreted from English into
Arabic (mostly) and vice-versa. In the process of
exploiting this resource for teaching a S2T auto-
matic translation system, we investigated the char-
acteristics of professional interpretation. An ex-
pert translator annotated the professional inter-
preters‚Äô strategies in a sample of the corpus by
following our guidelines to segment, align and an-

42

Machine translation and translation theory, vol-
ume 1. Walter de Gruyter.

He He, Jordan L Boyd-Graber, and Hal Daum¬¥e III.
2016.
Interpretese vs. translationese: The unique-
ness of human strategies in simultaneous interpreta-
tion. In HLT-NAACL. pages 971‚Äì976.

Kaibao Hu. 2016. Corpus-based interpreting studies.
In Introducing Corpus-based Translation Studies,
Springer, pages 193‚Äì221.

William John Hutchins and Harold L Somers. 1992.
An introduction to machine translation, volume 362.
Academic Press, London.

Sylvia Kalina. 1998. Strategische Prozesse beim Dol-
metschen: Theoretische Grundlagen, empirische
Fallstudien, didaktische Konsequenzen, volume 18.
G. Narr.

Judith F Kroll and Annette MB De Groot. 2009. Hand-
book of bilingualism: Psycholinguistic approaches.
Oxford University Press.

Marianne Lederer. 1978. Simultaneous interpretatio-
nunits of meaning and other features. In Language
interpretation and communication, Springer, pages
323‚Äì332.

Konstantina Liontou. 1996. Strategies in German-to-
Greek simultaneous interpreting: A corpus-based
approach. Gramma: Journal of Theory & Criticism
19:37‚Äì56.

Konstantina Liontou. 2012. Anticipation in German to
Greek simultaneous interpreting. Ph.D. thesis, Uni-
wien.

Xiaoyi Ma. 2010. Champollion: A robust parallel text
sentence aligner. In LREC 2006: Fifth International
Conference on Language Resources and Evaluation.
pages 489‚Äì492.

Matthias Paulik and Alex Waibel. 2009. Automatic
translation from parallel speech: Simultaneous inter-
pretation as mt training data. In Automatic Speech
Recognition & Understanding, 2009. ASRU 2009.
IEEE Workshop on. IEEE, pages 496‚Äì501.

Jones Roderick. 2002. Conference Interpreting Ex-
St.

plained (Translation Practices Explained).
Jerome Publishing.

Mohammad Salameh, Rached Zantout, and Nashat
Mansour. 2011. Improving the accuracy of english-
arabic statistical sentence alignment. In Int. Arab J.
Inf. Technol.. volume 8, pages 171‚Äì177.

Hiroaki Shimizu, Graham Neubig, Sakriani Sakti,
Tomoki Toda, and Satoshi Nakamura. 2013. Con-
structing a speech translation system using simulta-
neous interpretation data. In Proceedings of Inter-
national Workshop on Spoken Language Translation
(IWSLT).

Miriam Shlesinger. 1998.

Corpus-based interpret-
ing studies as an offshoot of corpus-based transla-
tion studies. Meta: journal des traducteurs/Meta:
Translators‚Äô Journal 43(4):486‚Äì493.

Vivek Kumar Rangarajan Sridhar, John Chen, and
Srinivas Bangalore. 2013. Corpus analysis of simul-
taneous interpretation data for improving real time

Figure 5: Distribution of Annotation Tags per
Transcript.

notate the transcripts. The Ô¨Åndings from this pi-
lot experiment conÔ¨Årmed and explained the previ-
ously observed anomalies. The discovered strate-
gies will be tested within our in-house S2T trans-
lation system. The WAW corpus can be used by
student interpreters to learn real, quality interpre-
tation, by researchers in related Ô¨Åelds, as well as
to improve MT. We aim to expand these tasks fur-
ther, as well as to automatize some of the previous
steps. For future work, we are in the process of
involving more annotators, better deÔ¨Åning the an-
notation guidelines, and processing more texts.

References
Raja Al-Khanji, Said El-Shiyab, and Riyadh Hussein.
2000. On the use of compensatory strategies in
simultaneous interpretation. Meta: Journal des
traducteurs/Meta: Translators‚Äô Journal 45(3):548‚Äì
557.

Magdalena Bart≈Çomiejczyk. 2006. Strategies of simul-
taneous interpreting and directionality. Interpreting
8(2):149‚Äì174.

Claudio Bendazzoli and Annalisa Sandrelli. 2009.
Corpus-based interpreting studies: Early work and
future prospects. Tradum`atica: traducci¬¥o i tecnolo-
gies de la informaci¬¥o i la comunicaci¬¥o (7).

Fabienne Braune and Alexander Fraser. 2010.

Im-
proved unsupervised sentence alignment for sym-
metrical and asymmetrical parallel corpora. In Pro-
ceedings of the 23rd International Conference on
Computational Linguistics: Posters. Association for
Computational Linguistics, pages 81‚Äì89.

Fahim Dalvi, Yifan Zhang, Sameer Khurana, Nadir
Durrani, Hassan Sajjad, Ahmed Abdelali, Hamdy
Mubarak, Ahmed Ali, and Stephan Vogel. 2017.
Qcri live speech translation system. EACL 2017
page 61.

Christa Hauenschild and Susanne Heizmann. 1997.

s
t

n
u
o
C

30

20

10

0

Tags

Addition
Omission
Self‚àícorrection
Summarizing

1

2
3
Transcript

4

43

speech translation. In INTERSPEECH. pages 3468‚Äì
3472.

Hitomi Tohyama and Shigeki Matsubara. 2006. Col-
lection of simultaneous interpreting patterns by us-
ing bilingual spoken monologue corpus.
In Pro-
ceedings of the Language Resources and Evaluation
Conference (LREC).

D¬¥aniel Varga, L¬¥aszl¬¥o N¬¥emeth, P. Halcsy, Andr¬¥as Ko-
rnai, Viktor Tr¬¥on, and Viktor Nagy. 2006. Parallel
corpora for medium density languages. In Proceed-
ings of the RANLP 2005. pages 590‚Äì596.

Binhua Wang. 2012. Interpreting strategies in real-life

interpreting .

