










































Coreference Resolution System using Maximum Entropy Classifier


Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 127–130,
Portland, Oregon, 23-24 June 2011. c©2011 Association for Computational Linguistics

1 

 

 Coreference Resolution System using Maximum Entropy Classifier 

 
 

Weipeng Chen,Muyu Zhang,Bing Qin  

                                                               Center for Information Retrieval 

Harbin Institute of Technology 
                                     {wpchen,myzhang,bing.qin}@ir.hit.edu.cn 

  
  

 
 

Abstract 

In this paper, we present our supervised 

learning approach to coreference resolution 

in ConLL corpus. The system relies on a 

maximum entropy-based classifier for pairs 

of mentions, and adopts a rich linguisitical- 

ly motivated feature set, which mostly has 

been introduced by Soon et al (2001), and 

experiment with alternaive resolution proc- 

ess, preprocessing tools,and classifiers. We 

optimize the system’s performance for M- 

UC (Vilain et al, 1995), BCUB (Bagga and 

Baldwin, 1998) and CEAF (Luo, 2005) .  

1. Introduction 

The coreference resolution is the task in which all  

expressions refer to the same entity in a discourse 

will be identified. As the core of natural language 

processing, coreference resolution is significant to 

message understanding, information extraction, 

text summarization, information retrieval, informa-

tion filtration, and machine translation. 

A considerable engineering efforts is needed for 

the full coreference resolution task, and a signifi-

cant part of this effort concerns feature engineering.  

The backbone of our system can be split into two 

subproblems: mention detection and creation of 

entitly. We train a mention detector on the training 

texts. Once the mentions are identified, coreference 

resolution involves partitioning them into subsets 

corresponding to the same entity. This problem is 

cast into the binary classification problem of decid-

ing whether two given mentions are coreferent. 

Our system relies on maximum entropy-based 

classifier for pairs of mentions. Our system relies 

on a rich linguistically motivated feature set. Our 

system architecture makes it possible to define 

other kinds of features: atmoic word and markable 

features. This approach to feature engineering is 

suitable not only for knowledge-rich but also for 

knowledge-poor datasets. Finally, we use the best-

first clustering to create the coreference chains. 

 

2. System Description  

This section briefly describes our system. First the 

mention detection is presented. Next, the features 

which we import are described. Finally, we de-

scribled the learning and encoding methods. 

2.1 Mention Detector  

The first stage of the coreference resolution 

process try to identify the occurrence of mentions 

in document. To detect system mention from a test 

text, we train a mention detector on the training 

data. We formulate the mention problem as a clas-

sification, by assigning to each token in the text a 

label, indicating whether it is a mention or not. 

Hence, to learn the detector, we create one training 

text and derive its class value (one of b, i, o) from 

the annotated data. Each instance represents the   , 
the token under consideration, and consists of 19 

linguistic features, many of which are modeled af-

ter the systems of Bikel et al. (1999) and Florian et 

al. (2004) , as describled below. 

(1) Lexical: Tokens in the windows of  three 
words before and after the target word: 

{     ,…,    }. 
(2) Capitalization: Determine whether    is 

IsAllCaP (all the characters of word are ca-

pitalized, such as “BBN”), IsInitCap (the 

word starts with a capitalized character, 

127



2 

 

such as “Sally” ), IsCapPeriod (more than 

one characters of word are capitalized but 

not all, and the first character is not capita-

lized too, such “M.” ), and IsAllLower (all 

the character of word aren’t capitalized, 

such as “can” ) (see Bikel et al.  (1999)). 

(3) Grammatical: The single POS tags of the 
tokens in the window of three words before 

and after the target word{    ,…,    }. 
(4) Semantic: The  named entity (NE) tag and  

the Noun Phrase tag of   .  
We employ maximum entropy-based classifier, for 

training the mention detector. These detected 

mentions are to be used as system mentions in our 

coreference experiment. 

2.2 Features 

To determine which mentions belong to same en-

titly, we need to devise a set of features that is use-

ful in determining whether two mentions corefer or 

not. All the feature value are computed automati-

cally, without any manual intervention. 

     

(1) Distance Feature: A non-negative integer 
feature capture the distance between anap- 

hor and antecedent. If anaphor and antece-

dent are in the same sentence, the value is 

0; If their sentence distance is 1, the value 

is 1, and so on. 

(2) Antecedent-pronoun Feature: A Boolean 
feature capture whether the antecedent is p- 

ronoun or not. True if the antecedent is a p- 

ronoun. Pronouns include reflexive prono-

uns, personal pronouns, and possessive pr- 

onouns.  

(3) Anaphor-pronoun Feature: A Boolean f- 
eature capture whether  the anaphor is pro-

noun or not. True if the anaphor is a pron- 

oun. 

(4) String Match Feature: A non-negative in-
teger feature. If one candidate is a substrin-

g of another, its value is 0, else the value is 

0 plus the edit distance. 

(5) Anaphor Definite Noun Phrase Feature: 
A Boolean feature capture whether the ana- 

phor is a definite noun phrase or not. True 

if the anaphor is a pronoun. In our definiti- 

on, a definite noun phrase is someone that 

start with the word “the”. 

(6) Anaphor Demonstrative Noun Phrase F-
eature:  A Boolean feature capture wheth- 

er the anaphor is a demonstractive  noun or 

not. True if the anaphor is a demonstractive  

noun. In our definition, a demonstractive  n 

oun is someone that start with the word, su- 

ch as this, that, those, these. 

(7) ProperName Feature: A Boolean feature. 
True if  anphor and antecedent both are pr- 

oper name. 

(8) Gender Feature: Its value are true, false   
or  unknow. If gender of pair of  instance   

matches, its value is true,else if  the value  

is umatches, the value is false; If one of the 

pair instance’s gender is unknown, the val-

ue is uknown.  

(9) Number Feature: A Boolean feature. True 
if the  number of pair of instance is match-

es; 

(10)  Alias Feature: A Boolean feature. True if 
two markables refer to the same entity usi- 

ng different notation(acronyms, shorthands, 

etc), its value is true. 

(11)  Semantic Feature: Its value are true, fals- 
e, or unknown. If semantic class relateness 

of a pair instance is the same, or one is the 

parent of other, its value is true; Else if the- 

y are unmatch,the value is false; If one of t- 

he the pair instance’s semantic class is unk- 

nown, the value is unknown. 

 

2.3 Learning   

We did not make any effort to optimize the nu- 

mber of training instances for the pair-wise learne- 

r: a positive instance for each adjacent coreferent 

markable pair and negative training instances for a 

markable m and all markables disreferent with m 

that occur before m (Soon et al.,2001). For decod-

ing it generates all the possible links inside a win-

dow of 100 markables. 

Our system integrate many machine learning m 

ethods, such as maximum entropy (Tsuruoka,  200- 

6) , Descision Tree,Support Vector Machine  (Joa- 

chims, 2002) . We compare the result using differ- 

ent method in our system, and decide to rely on m-

aximum entropy-based classifier, and it led to the 

best results. 

2.4 Decoding 

In the decoding step, the coreference chains are 

created by the best-first clustering. Each mention is 

128



3 

 

compared with all of its previous mentions with 

probability greater than a fixed threshold, and is 

clustered with the one hightest probability. If none 

has probability greater than the threshold, the men-

tion becomes a new cluster. 
      

3. Setting and data 

3.1 Setting 

Our system has participated in the closed settings 

for English. Which means all the knowledge re-

quired by the mention detector and feature detector   

is obtained from the annotation of the corpus(see 

Pradhan et al.  (2007)), with the exception of Wor- 

dNet.  

 

3.2 Data  

We selecte all ConLL training data and develop-

ment data, contain “gold” files and “auto” file, to 

train our final system. The "gold" indicates that 

the annotation is that file is hand-annotated and 

adjudicated quality, whereas the second means it 

was produced using a combination of automatic 

tools. The training data distribution is shown in 

Table 1. 
 

Category bc bn mz nw wb 

Quantity 40 1708 142 1666 190 

  Table 1: Final system’s training data distribution 

 

 

In this paper, we report the results from our dev- 

elopment system, which were trained on the traini- 

ng data and tested on the development set. The de- 

tail is shown in Table 2,3. 
 

Category bc bn mz nw wb 

Quantity 32 1526 128 1490 166 

  Table 2: Experiment system’s training data distribution 

  

 

Category bc bn mz nw wb 

Quantity 8 182 14 176 24 

   Table 3: Experiment system’s test set distribution 
 

 

4. Evaluation  

First, we have evaluated our mention detector mo- 

dule, which is train by the ConLL training data. It 

regards all the token as the candidate, and cast it i- 

nto the mention detector, and the detector decides 

it is  mention or not. The mention detector’s result 

is shown in Table4. 

 

 

Metric R P F 

Value 63.6 55.26 59.14 
Table 4: Performance of  mention detector on the de-

velopment set 

 

Second, we have evaluated our system with the 

system mention, and we use the previous mention 

detector to determine the mention boundary. As fo- 

llow, we list the system perfomance  of using MUC, 

B-CUB,CEAF (E) , CEAF (M) , BLANC (Recasens a- 

nd Hovy, in prep)  in Table 5 . 

 

Metric R P F 

MUC 45.53 47.00 46.25 

BCUB 61.29 68.07 64.50 

CEAF(M) 47.47 47.47 47.47 

CEAF(E) 39.23 37.91 38.55 

BLANC 64.00 68.31 65.81 
Table 5 :Result using  system mentions 

 

 

Finally, we  have evaluated our system with the 

gold mentions, which mention’s boundary is corect. 

The system performance is shown in Table 6: 

 

Metric R P F 

MUC 50.15 80.49 61.78 

BCUB 48.87 85.75 62.62 

CEAF(M) 54.50 54.50 54.50 

CEAF(E) 67.38 32.72 44.05 

BLANC 66.03 78.41 70.02 
Table6:Result using  gold mentions 

 

 

Result of system shows a big difference  betwee- 

n using gold mentions and using system mentions. 

In comparison to the system using system mention- 

s, we see that the F-score rises significantly by 

4.21- 15.53 for the system using gold mentions. It  

is worth noting that the F-scorer when using the B- 

CUB metric, the system using system mention rise- 

129



4 

 

s 2.12 for system using gold mention. Although t- 

his is surprising, in my opinion this correlation is 

because the mention detection recall more candid- 

ate mention, and the BCUB metric is benefit for t- 

he mention which is merge into the erroneous 

chain.  

5. Conclusion 

In this paper, we have presented a new modular 

system for coreference in English. We train a men-

tion detector to find the mention’s boundary based 

on maximum entropy classifier to decide pairs of 

mention refer to or not.  

     Due to the flexible architecture, it allows us ex-

tend the system to multi-language. And if it is ne-

cessary, we can obtain other modules to support 

the system. The results obtained confirm the feasi-

bility of our system. 

 

 

References  

Wee Meng Soon,Hwee You Ng,and Daniel Chung 

Yong Lim.2001.A machine learing approach to core-

ference resolution of noun phrases.Computational 

Linguistic(special Issue on Computational Anaphora 

Resolution),27(4):521-544 

Marc Vilain,John Burger,John Aberdeen,Dennis Con-

nolly,and Lynette Hirschman.1995.A modeltheoretic 

coreference scoring scheme.In Proceedings of the 6
th
 

Message Understanding Conference,pages 45-52. 

Amit Bagga and Breck baldwin.1998.Algorithms for 

scoring coreference chains.In Proceedings of the lin-

guistic Coreference Workshoop at the International 

Conference on Language Resources and Evalua-

tion(LREC-1998),pages 563-566. 

Xiaoqiang Luo.2005.On coreference resoluton perfor-

mance metrics.In Proceeddings of the Annual Meet-

ing of the North American Chapter of the Association 

for Computational Linguistics-Human Language 

Technology Conference(NAACL/HLY-2005),pages 

25-32 

Josef Steinberger,Massimo Poesio,Mijail A.kabadjov- 

b,and Karel jezek.2007.Two uses of anaphora resolu-

tion in summarization.In Information Processing and 

management,Special issue on Summarization,pages 

1663-1680 

Bikel,R.Schwartz,and R.Weischedel.1999.An algorithm 

that learns what's in a name.Machine Learning,34(1-

3):pages211-231 

Florian,H.Hassan,A.Ittycheriah,H.Jing,N.Kambhatla, X. 

Luo,N.Nicolov,and I.Zitouni.2004.A statistical model 

for multilingual entity detection and tracking.In 

Proc.of HLA/NAACL. 

Sameer Pradhan and Lance Ramshaw and Ralph Wei-

schedel and Jessica MacBride and Linnea Micciulla. 
2007.Unrestricted Coreference: Identifying Entities 

and Events in OntoNotes. In Proceedings of the IEEE 

International Conference on Semantic Computing 

(ICSC), Irvine, CA 

Marta Recasens and Eduard Hovy.in prep.BLAN- 

C:Implementing the rand index for coreference eval-

uation. 

Yoshimasa Tsuruoka.2006.A simple c++ library for 

maxium entropy classifiction.Ysujii laboratory,Dep- 

artment of Computer Science,University of Tokyo. 

Throsten Joachims.1999.Making large-scale SVM 

learning practical.In B.Scholkopf,C.Burges,and A.S- 

mola,editors,Advances in Kernel Methods-Support 

Vector Learning.MIT-Press. 

 

 

 

 

 

 

 

 

 

 

 

 

 

130


