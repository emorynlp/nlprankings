










































Discriminative Pruning for Discriminative ITG Alignment


Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 316â€“324,
Uppsala, Sweden, 11-16 July 2010. cÂ©2010 Association for Computational Linguistics

Discriminative Pruning for Discriminative ITG Alignment 

Shujie Liu
â€ 
, Chi-Ho Li

â€¡
 and Ming Zhou

â€¡
 

â€ 
School of Computer Science and Technology 

Harbin Institute of Technology, Harbin, China 

shujieliu@mtlab.hit.edu.cn 
â€¡
Microsoft Research Asia, Beijing, China 

{chl, mingzhou}@microsoft.com 
  

 

Abstract 

While Inversion Transduction Grammar (ITG) 

has regained more and more attention in recent 

years, it still suffers from the major obstacle of 

speed. We propose a discriminative ITG prun-

ing framework using Minimum Error Rate 

Training and various features from previous 

work on ITG alignment. Experiment results 

show that it is superior to all existing heuristics 

in ITG pruning. On top of the pruning frame-

work, we also propose a discriminative ITG 

alignment model using hierarchical phrase 

pairs, which improves both F-score and Bleu 

score over the baseline alignment system of 

GIZA++. 

1 Introduction 

Inversion transduction grammar (ITG) (Wu, 1997) 

is an adaptation of SCFG to bilingual parsing. It 

does synchronous parsing of two languages with 

phrasal and word-level alignment as by-product. 

For this reason ITG has gained more and more 

attention recently in the word alignment commu-

nity (Zhang and Gildea, 2005; Cherry and Lin, 

2006; Haghighi et al., 2009). 
A major obstacle in ITG alignment is speed. 

The original (unsupervised) ITG algorithm has 

complexity of O(n
6
). When extended to super-

vised/discriminative framework, ITG runs even 

more slowly. Therefore all attempts to ITG 

alignment come with some pruning method. For 

example, Haghighi et al. (2009) do pruning based 

on the probabilities of links from a simpler 

alignment model (viz. HMM); Zhang and Gildea 

(2005) propose Tic-tac-toe pruning, which is 

based on the Model 1 probabilities of word pairs 

inside and outside a pair of spans. 

As all the principles behind these techniques 

have certain contribution in making good pruning 

decision, it is tempting to incorporate all these 

features in ITG pruning. In this paper, we pro-

pose a novel discriminative pruning framework 

for discriminative ITG. The pruning model uses 

no more training data than the discriminative ITG 

parser itself, and it uses a log-linear model to in-

tegrate all features that help identify the correct 

span pair (like Model 1 probability and HMM 

posterior). On top of the discriminative pruning 

method, we also propose a discriminative ITG 

alignment system using hierarchical phrase pairs.  

In the following, some basic details on the ITG 

formalism and ITG parsing are first reviewed 

(Sections 2 and 3), followed by the definition of 

pruning in ITG (Section 4). The â€œDiscriminative 

Pruning for Discriminative ITGâ€ model (DPDI) 

and our discriminative ITG (DITG) parsers will 

be elaborated in Sections 5 and 6 respectively. 

The merits of DPDI and DITG are illustrated 

with the experiments described in Section 7.  

2 Basics of ITG 

The simplest formulation of ITG contains three 

types of rules: terminal unary rules ğ‘‹ â†’ ğ‘’/ğ‘“ , 
where ğ‘’  and ğ‘“  represent words (possibly a null 
word, Îµ) in the English and foreign language 
respectively, and the binary rules ğ‘‹ â†’  ğ‘‹, ğ‘‹  and 
ğ‘‹ â†’  ğ‘‹, ğ‘‹ , which refer to that the component 
English and foreign phrases are combined in the 

same and inverted order respectively. 

From the viewpoint of word alignment, the 

terminal unary rules provide the links of word 

pairs, whereas the binary rules represent the reor-

dering factor. One of the merits of ITG is that it 

is less biased towards short-distance reordering. 

Such a formulation has two drawbacks. First of 

all, it imposes a 1-to-1 constraint in word align-

ment. That is, a word is not allowed to align to 

more than one word. This is a strong limitation as 

no idiom or multi-word expression is allowed to 

align to a single word on the other side. In fact 

there have been various attempts in relaxing the 

1-to-1 constraint. Both ITG alignment 

316



approaches with and without this constraint will 

be elaborated in Section 6.  

Secondly, the simple ITG leads to redundancy 

if word alignment is the sole purpose of applying 

ITG. For instance, there are two parses for three 

consecutive word pairs, viz. [ğ‘/ğ‘â€™ [ğ‘/ğ‘â€™ ğ‘/
ğ‘â€™] ]  and [[ğ‘/ğ‘â€™ ğ‘/ğ‘â€™] ğ‘/ğ‘â€™] . The problem of re-
dundancy is fixed by adopting ITG normal form. 

In fact, normal form is the very first key to speed-

ing up ITG. The ITG normal form grammar as 

used in this paper is described in Appendix A. 

3 Basics of ITG Parsing 

Based on the rules in normal form, ITG word 

alignment is done in a similar way to chart pars-

ing (Wu, 1997). The base step applies all relevant 

terminal unary rules to establish the links of word 

pairs. The word pairs are then combined into 

span pairs in all possible ways. Larger and larger 

span pairs are recursively built until the sentence 

pair is built.  

Figure 1(a) shows one possible derivation for a 

toy example sentence pair with three words in 

each sentence. Each node (rectangle) represents a 

pair, marked with certain phrase category, of for-

eign span (F-span) and English span (E-span) 

(the upper half of the rectangle) and the asso-

ciated alignment hypothesis (the lower half). 

Each graph like Figure 1(a) shows only one deri-

vation and also only one alignment hypothesis.  

The various derivations in ITG parsing can be 

compactly represented in hypergraph (Klein and 

Manning, 2001) like Figure 1(b). Each hypernode 

(rectangle) comprises both a span pair (upper half) 

and the list of possible alignment hypotheses 

(lower half) for that span pair. The hyperedges 

show how larger span pairs are derived from 

smaller span pairs. Note that a hypernode may 

have more than one alignment hypothesis, since a 

hypernode may be derived through more than one 

hyperedge (e.g. the topmost hypernode in Figure 

1(b)). Due to the use of normal form, the hypo-

theses of a span pair are different from each other.  

4 Pruning in ITG Parsing 

The ITG parsing framework has three levels of 

pruning: 

1) To discard some unpromising span pairs; 
2) To discard some unpromising F-spans 

and/or E-spans; 

3) To discard some unpromising alignment 
hypotheses for a particular span pair. 

The second type of pruning (used in Zhang et. 

al. (2008)) is very radical as it implies discarding 

too many span pairs. It is empirically found to be 

highly harmful to alignment performance and 

therefore not adopted in this paper.  

The third type of pruning is equivalent to mi-

nimizing the beam size of alignment hypotheses 

in each hypernode. It is found to be well handled 

by the K-Best parsing method in Huang and 

Chiang (2005). That is, during the bottom-up 

construction of the span pair repertoire, each span 

pair keeps only the best alignment hypothesis. 

Once the complete parse tree is built, the k-best 

list of the topmost span is obtained by minimally 

expanding the list of alignment hypotheses of 

minimal number of span pairs. 

The first type of pruning is equivalent to mi-

nimizing the number of hypernodes in a hyper-

graph. The task of ITG pruning is defined in this 

paper as the first type of pruning; i.e. the search 

for, given an F-span, the minimal number of E-

spans which are the most likely counterpart of 

that F-span.
1
 The pruning method should main-

tain a balance between efficiency (run as quickly 

as possible) and performance (keep as many cor-

rect span pairs as possible).  

                                                 
1
 Alternatively it can be defined as the search of the minimal 

number of E-spans per F-span. That is simply an arbitrary 

decision on how the data are organized in the ITG parser.  

B:[e1,e2]/[f1,f2]

{e1/f2,e2/f1}

C:[e1,e1]/[f2,f2]

{e1/f2}

C:[e2,e2]/[f1,f1]

{e2/f1}

C:[e3,e3]/[f3,f3]

{e3/f3}

A:[e1,e3]/[f1,f3]

{e1/f2,e2/f1,e3/f3}

(a) 

C:[e2,e2]/[f2,f2]

{e2/f2}

C:[e1,e1]/[f1,f1]

{e1/f1}

C:[e3,e3]/[f3,f3]

{e3/f3}

C:[e2,e2]/[f1,f1]

{e2/f1}

C:[e1,e1]/[f2,f2]

{e1/f2}

B:[e1,e2]/[f1,f2]

{e1/f2}

A:[e1,e2]/[f1,f2]

{e2/f2}

A:[e1,e3]/[f1,f3]

{e1/f2,e2/f1,e3/f3} , 

{e1/f1,e2/f2,e3,f3}

(b)

Bâ†’<C,C> Aâ†’[C,C]

Aâ†’[A,C]Aâ†’[B,C]

 
Figure 1:  Example ITG parses in graph (a) and hypergraph (b). 

317



A naÃ¯ve approach is that the required pruning 

method outputs a score given a span pair. This 

score is used to rank all E-spans for a particular 

F-span, and the score of the correct E-span 

should be in general higher than most of the in-

correct ones.  

5 The DPDI Framework 

DPDI, the discriminative pruning model pro-

posed in this paper, assigns score to a span pair 

 ğ‘“ , ğ‘’   as probability from a log-linear model: 

ğ‘ƒ ğ‘’  ğ‘“  =
ğ‘’ğ‘¥ğ‘(  ğœ†ğ‘–ğ›¹ğ‘– ğ‘“ , ğ‘’  ğ‘– )

 ğ‘’ğ‘¥ğ‘(  ğœ†ğ‘–ğ›¹ğ‘–(ğ‘“ , ğ‘’ â€²))ğ‘–ğ‘’ â€²âˆˆğ¸  
 (1) 

where each ğ›¹ğ‘–(ğ‘“ , ğ‘’ )  is some feature about the 
span pair, and each ğœ† is the weight of the corres-
ponding feature. There are three major questions 

to this model:  

1) How to acquire training samples? (Section 
5.1) 

2) How to train the parameters ğœ† ? (Section 5.2) 
3) What are the features? (Section 5.3) 

5.1 Training Samples 

Discriminative approaches to word alignment use 

manually annotated alignment for sentence pairs. 

Discriminative pruning, however, handles not 

only a sentence pair but every possible span pair. 

The required training samples consist of various 

F-spans and their corresponding E-spans. 

Rather than recruiting annotators for marking 

span pairs, we modify the parsing algorithm in 

Section 3 so as to produce span pair annotation 

out of sentence-level annotation. In the base step, 

only the word pairs listed in sentence-level anno-

tation are inserted in the hypergraph, and the re-

cursive steps are just the same as usual.  

If the sentence-level annotation satisfies the 

alignment constraints of ITG, then each F-span 

will have only one E-span in the parse tree. How-

ever, in reality there are often the cases where a 

foreign word aligns to more than one English 

word. In such cases the F-span covering that for-

eign word has more than one corresponding E-

spans. Consider the example in Figure 2, where 

the golden links in the alignment annotation are 

ğ‘’1/ğ‘“1, ğ‘’2/ğ‘“1, and ğ‘’3/ğ‘“2; i.e. the foreign word 
ğ‘“1 aligns to both the English words ğ‘’1 and ğ‘’2. 
Therefore the F-span  ğ‘“1, ğ‘“1  aligns to the E-
span  ğ‘’1, ğ‘’1  in one hypernode and to the E-span 
 ğ‘’2, ğ‘’2  in another hypernode. When such situa-
tion happens, we calculate the product of the in-

side and outside probability of each alignment 

hypothesis of the span pair, based on the proba-

bilities of the links from some simpler alignment 

model
2
. The E-span with the most probable hypo-

thesis is selected as the alignment of the F-span.  

Aâ†’[C,C]

Cw:

[e1,e1]/[f1,f1]

{e1/f1}

Ce:

[e1]/Îµ

Cw:

[e2,e2]/[f1,f1]

Ce:

[e2]/Îµ

Cw:

[e3,e3]/[f2,f2]

C:

[e1,e2]/[f1,f1]

{e2/f1}

C:

[e2,e3]/[f2,f2]

{e3/f2}

A:

[e1,e3]/[f1,f2]

{e1/f1,e3/f2},{e2/f1,e3/f2}

Câ†’ [Ce,Cw]

Aâ†’[C,C]

Câ†’ [Ce,Cw]

{e1/f1} {e1/f1}

(a) (b)

[f1,f1]

[e1,e1]

[e1,e2]

[e2,e2]

[f2,f2]
[e2,e3]

[e3,e3]

[f1,f2] [e1,e3]

Figure 2: Training sample collection. 

Table (b) lists, for the hypergraph in (a), the candidate 

E-spans for each F-span. 

It should be noted that this automatic span pair 

annotation may violate some of the links in the 

original sentence-level alignment annotation. We 

have already seen how the 1-to-1 constraint in 

ITG leads to the violation. Another situation is 

the â€inside-outâ€Ÿ alignment pattern (c.f. Figure 3). 

The ITG reordering constraint cannot be satisfied 

unless one of the links in this pattern is removed. 

f1      f2      f3      f4

e1     e2      e3      e4
 

Figure 3: An example of inside-out alignment 

The training samples thus obtained are positive 

training samples. If we apply some classifier for 

parameter training, then negative samples are 

also needed. Fortunately, our parameter training 

does not rely on any negative samples. 

5.2 MERT for Pruning 

Parameter training of DPDI is based on Mini-

mum Error Rate Training (MERT) (Och, 2003), a 

widely used method in SMT. MERT for SMT 

estimates model parameters with the objective of 

minimizing certain measure of translation errors 

(or maximizing certain performance measure of 

translation quality) for a development corpus. 

Given an SMT system which produces, with 

                                                 
2
 The formulae of the inside and outside probability of a 

span pair will be elaborated in Section 5.3. The simpler 

alignment model we used is HMM. 

318



model parameters ğœ†1
ğ‘€, the K-best candidate trans-

lations ğ‘’ (ğ‘“ğ‘ ; ğœ†1
ğ‘€) for a source sentence ğ‘“ğ‘ , and an 

error measure ğ¸(ğ‘Ÿğ‘  , ğ‘’ğ‘ ,ğ‘˜) of a particular candidate 
ğ‘’ğ‘ ,ğ‘˜ with respect to the reference translation ğ‘Ÿğ‘  , 
the optimal parameter values will be:  

ğœ† 1
ğ‘€ = ğ‘ğ‘Ÿğ‘”ğ‘šğ‘–ğ‘›

ğœ†1
ğ‘€

  ğ¸ ğ‘Ÿğ‘  , ğ‘’  ğ‘“ğ‘ ; ğœ†1
ğ‘€  

ğ‘†

ğ‘ =1

  

 = ğ‘ğ‘Ÿğ‘”ğ‘šğ‘–ğ‘›
ğœ†1

ğ‘€
   ğ¸ ğ‘Ÿğ‘  , ğ‘’ğ‘ ,ğ‘˜ ğ›¿(ğ‘’  ğ‘“ğ‘ ; ğœ†1

ğ‘€ , ğ‘’ğ‘ ,ğ‘˜)

ğ¾

ğ‘˜=1

ğ‘†

ğ‘ =1

   

DPDI applies the same equation for parameter 

tuning, with different interpretation of the com-

ponents in the equation. Instead of a development 

corpus with reference translations, we have a col-

lection of training samples, each of which is a 

pair of F-span (ğ‘“ğ‘ ) and its corresponding E-span 
(ğ‘Ÿğ‘ ). These samples are acquired from some ma-
nually aligned dataset by the method elaborated 

in Section 5.1. The ITG parser outputs for each fs  
a K-best list of E-spans ğ‘’  ğ‘“ğ‘ ; ğœ†1

ğ‘€  based on the 
current parameter values ğœ†1

ğ‘€.  

The error function is based on the presence and 

the rank of the correct E-span in the K-best list:  

ğ¸  ğ‘Ÿğ‘  , ğ‘’  ğ‘“ğ‘ ; ğœ†1
ğ‘€  =  

âˆ’ğ‘Ÿğ‘ğ‘›ğ‘˜ ğ‘Ÿğ‘   ğ‘–ğ‘“ ğ‘Ÿğ‘  âˆˆ ğ‘’  ğ‘“ğ‘ ; ğœ†1
ğ‘€ 

ğ‘ğ‘’ğ‘›ğ‘ğ‘™ğ‘¡ğ‘¦      ğ‘œğ‘¡ğ‘•ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’          
  

(2)    

where ğ‘Ÿğ‘ğ‘›ğ‘˜ ğ‘Ÿğ‘   is the (0-based) rank of the cor-
rect E-span ğ‘Ÿğ‘  in the K-best list  ğ‘’  ğ‘“ğ‘ ; ğœ†1

ğ‘€ . If  ğ‘Ÿğ‘  is 
not in the K-best list at all, then the error is de-

fined to be ğ‘ğ‘’ğ‘›ğ‘ğ‘™ğ‘¡ğ‘¦, which is set as -100000 in 
our experiments. The rationale underlying this 

error function is to keep as many correct E-spans 

as possible in the K-best lists of E-spans, and 

push the correct E-spans upward as much as 

possible in the K-best lists. 

This new error measure leads to a change in 

details of the training algorithm. In MERT for 

SMT, the interval boundaries at which the per-

formance or error measure changes are defined 

by the upper envelope (illustrated by the dash 

line in Figure 4(a)), since the performance/error 

measure depends on the best candidate transla-

tion. In MERT for DPDI, however, the error 

measure depends on the correct E-span rather 

than the E-span leading to the highest system 

score. Thus the interval boundaries are the inter-

sections between the correct E-span and all other 

candidate E-spans (as shown in Figure 4(b)). The 

rank of the correct E-span in each interval can 

then be figured out as shown in Figure 4(c). Fi-

nally, the error measure in each interval can be 

calculated by Equation (2) (as shown in Figure 

4(d)).  All other steps in MERT for DPDI are the 

same as that for SMT. 

Î£Î»mfm

 

-index

loss

Î»k

-8
-9

-10

-8

-9

-100,000

gold

Î£Î»mfm

Î»k

(a)

(b)

(c)

(d)

Î»k

Î»k

 

Figure 4: MERT for DPDI 
Part (a) shows how intervals are defined for SMT and 

part (b) for DPDI. Part (c) obtains the rank of correct 

E-spans in each interval and part (d) the error measure. 

Note that the beam size (max number of E-spans) for 

each F-span is 10. 

5.3 Features 

The features used in DPDI are divided into three 

categories:  

1) Model 1-based probabilities. Zhang and Gil-
dea (2005) show that Model 1 (Brown et al., 

1993; Och and Ney., 2000) probabilities of 

the word pairs inside and outside a span pair 

( ğ‘’ğ‘–1 , ğ‘’ğ‘–2 /[ğ‘“ğ‘—1 , ğ‘“ğ‘—2]) are useful. Hence these 

two features: 

a) Inside probability (i.e. probability of 
word pairs within the span pair): 

ğ‘ğ‘–ğ‘›ğ‘  ğ‘’ğ‘–1,ğ‘–2 ğ‘“ğ‘—1,ğ‘—2 

=   
1

 ğ‘—2 âˆ’ ğ‘—1 
ğ‘ğ‘€1 ğ‘’ğ‘– ğ‘“ğ‘— 

ğ‘—âˆˆ ğ‘—1,ğ‘—2 ğ‘–âˆˆ ğ‘–1,ğ‘–2 

 

b) Outside probability (i.e. probability of 
the word pairs outside the span pair): 

ğ‘ğ‘œğ‘¢ğ‘¡  ğ‘’ğ‘–1,ğ‘–2 ğ‘“ğ‘—1,ğ‘—2 

=   
1

 ğ½ âˆ’ ğ‘—2 + ğ‘—1 
ğ‘ğ‘€1 ğ‘’ğ‘– ğ‘“ğ‘— 

ğ‘— âˆ‰ ğ‘—1,ğ‘—2 ğ‘–âˆ‰ ğ‘–1,ğ‘–2 

   

where ğ½ is the length of the foreign sen-
tence. 

2) Heuristics. There are four features in this cat-
egory. The features are explained with the 

319



example of Figure 5, in which the span pair 

in interest is  ğ‘’2, ğ‘’3 /[ğ‘“1, ğ‘“2]. The four links 
are produced by some simpler alignment 

model like HMM. The word pair  ğ‘’2/ğ‘“1  is 
the only link in the span pair. The links 

ğ‘’4/ğ‘“2  and ğ‘’3/ğ‘“3 are inconsistent with the 
span pair.

3
  

f1      f2      f3      f4

e1     e2      e3      e4
 

Figure 5: Example for heuristic features 

a) Link ratio: 
2Ã—#ğ‘™ğ‘–ğ‘›ğ‘˜ğ‘ 

ğ‘“ğ‘™ğ‘’ğ‘› +ğ‘’ğ‘™ğ‘’ğ‘›
 

where #ğ‘™ğ‘–ğ‘›ğ‘˜ğ‘   is the number of links in 
the span pair, and ğ‘“ğ‘™ğ‘’ğ‘› and ğ‘’ğ‘™ğ‘’ğ‘› are the 
length of the foreign and English spans 

respectively. The feature value of the ex-

ample span pair is (2*1)/(2+2)=0.5. 

b) inconsistent link ratio: 
2Ã—#ğ‘™ğ‘–ğ‘›ğ‘˜ğ‘  ğ‘–ğ‘›ğ‘ğ‘œğ‘›

ğ‘“ğ‘™ğ‘’ğ‘› +ğ‘’ğ‘™ğ‘’ğ‘›
  

where #ğ‘™ğ‘–ğ‘›ğ‘˜ğ‘ ğ‘–ğ‘›ğ‘ğ‘œğ‘›  is the number of links 
which are inconsistent with the phrase 

pair according to some simpler alignment 

model (e.g. HMM). The feature value of 

the example is (2*2)/(2+2) =1.0. 

c) Length ratio: 
ğ‘“ğ‘™ğ‘’ğ‘›

ğ‘’ğ‘™ğ‘’ğ‘›
âˆ’ ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘ğ‘£ğ‘”   

where ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘ğ‘£ğ‘”  is defined as the average 

ratio of foreign sentence length to Eng-

lish sentence length, and it is estimated to 

be around 1.15 in our training dataset. 

The rationale underlying this feature is 

that the ratio of span length should not be 

too deviated from the average ratio of 

sentence length. The feature value for the 

example is |2/2-1.15|=0.15. 

d) Position Deviation: ğ‘ğ‘œğ‘ ğ‘“ âˆ’ ğ‘ğ‘œğ‘ ğ‘’    
where ğ‘ğ‘œğ‘ ğ‘“  refers to the position of the 

F-span in the entire foreign sentence, and 

it is defined as 
1

2ğ½
 ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ğ‘“ + ğ‘’ğ‘›ğ‘‘ğ‘“  , 

ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ğ‘“  /ğ‘’ğ‘›ğ‘‘ğ‘“  being the position of the 

first/last word of the F-span in the for-

eign sentence. ğ‘ğ‘œğ‘ ğ‘’  is defined similarly. 
The rationale behind this feature is the 

monotonic assumption, i.e. a phrase of 

the foreign sentence usually occupies 

roughly the same position of the equiva-

lent English phrase. The feature value for 

                                                 
3
 An inconsistent link connects a word within the phrase pair 

to some word outside the phrase pair. C.f. Deng et al. (2008) 

the example is |(1+2)/(2*4)-(2+3)/(2*4)| 

=0.25. 

3) HMM-based probabilities. Haghighi et al. 
(2009) show that posterior probabilities from 

the HMM alignment model is useful for 

pruning. Therefore, we design two new fea-

tures by replacing the link count in link ratio 

and inconsistent link ratio with the sum of the 

linkâ€Ÿs posterior probability. 

6 The DITG Models 

The discriminative ITG alignment can be con-

ceived as a two-staged process. In the first stage 

DPDI selects good span pairs. In the second stage 

good alignment hypotheses are assigned to the 

span pairs selected by DPDI. Two discriminative 

ITG (DITG) models are investigated. One is 

word-to-word DITG (henceforth W-DITG), 

which observes the 1-to-1 constraint on align-

ment. Another is DITG with hierarchical phrase 

pairs (henceforth HP-DITG), which relaxes the 1-

to-1 constraint by adopting hierarchical phrase 

pairs in Chiang (2007).  

Each model selects the best alignment hypo-

theses of each span pair, given a set of features. 

The contributions of these features are integrated 

through a log linear model (similar to Liu et al., 

2005; Moore, 2005) like Equation (1). The dis-

criminative training of the feature weights is 

again MERT (Och, 2003). The MERT module 

for DITG takes alignment F-score of a sentence 

pair as the performance measure. Given an input 

sentence pair and the reference annotated align-

ment, MERT aims to maximize the F-score of 

DITG-produced alignment. Like SMT (and un-

like DPDI), it is the upper envelope which de-

fines the intervals where the performance meas-

ure changes. 

6.1 Word-to-word DITG 

The following features about alignment link are 

used in W-DITG: 

1) Word pair translation probabilities trained 
from HMM model (Vogel, et.al., 1996) 

and IBM model 4 (Brown et.al., 1993; 

Och and Ney, 2000). 

2) Conditional link probability (Moore, 2005). 
3) Association score rank features (Moore et 

al., 2006). 

4) Distortion features: counts of inversion 
and concatenation. 

5) Difference between the relative positions 
of the words. The relative position of a 

word in a sentence is defined as the posi-

320



tion of the word divided by sentence 

length.  

6) Boolean features like whether a word in 
the word pair is a stop word.  

6.2 DITG with Hierarchical Phrase Pairs 

The 1-to-1 assumption in ITG is a serious limita-

tion as in reality there are always segmentation or 

tokenization errors as well as idiomatic expres-

sions. Wu (1997) proposes a bilingual segmenta-

tion grammar extending the terminal rules by 

including phrase pairs. Cherry and Lin (2007) 

incorporate phrase pairs in phrase-based SMT 

into ITG, and Haghighi et al. (2009) introduce 

Block ITG (BITG), which adds 1-to-many or 

many-to-1 terminal unary rules.  

It is interesting to see if DPDI can benefit the 

parsing of a more realistic ITG. HP-DITG ex-

tends Cherry and Linâ€Ÿs approach by not only em-

ploying simple phrase pairs but also hierarchical 

phrase pairs (Chiang, 2007). The grammar is 

enriched with rules of the format: ğ‘‹ï‚®ğ‘’ ğ‘–/ğ‘“ ğ‘– 
where ğ‘’ ğ‘–  and ğ‘“ ğ‘–  refer to the English and foreign 
side of the i-th (simple/hierarchical) phrase pair 

respectively.  

As example, if there is a simple phrase pair 

ğ‘‹ï‚®  ğ‘ğ‘œğ‘Ÿğ‘¡ğ‘• ğ¾ğ‘œğ‘Ÿğ‘’ğ‘,åŒ— æœé²œ , then it is trans-
formed into the ITG rule ğ¶ï‚®"North Korea"/

"åŒ— æœé²œ". During parsing, each span pair does 
not only examine all possible combinations of 

sub-span pairs using binary rules, but also checks 

if the yield of that span pair is exactly the same as 

that phrase pair. If so, then the alignment links 

within the phrase pair (which are obtained in 

standard phrase pair extraction procedure) are 

taken as an alternative alignment hypothesis of 

that span pair.  

For a hierarchical phrase pair like 

ğ‘‹ï‚®  ğ‘‹1 ğ‘œğ‘“ ğ‘‹2 , ğ‘‹2 çš„ ğ‘‹1 , it is transformed into 

the ITG rule  ğ¶ï‚®"ğ‘‹1 ğ‘œğ‘“ ğ‘‹2"/"ğ‘‹2 çš„ ğ‘‹1"  during 
parsing, each span pair checks if it contains the 

lexical anchors "of" and "çš„", and if the remain-
ing words in its yield can form two sub-span 

pairs which fit the reordering constraint among 

ğ‘‹1 and ğ‘‹2. (Note that span pairs of any category 
in the ITG normal form grammar can substitute 

for ğ‘‹1 or ğ‘‹2 .) If both conditions hold, then the 
span pair is assigned an alignment hypothesis 

which combines the alignment links among the 

lexical anchors (ğ‘™ğ‘–ğ‘˜ğ‘’ ğ‘œğ‘“/çš„)  and those links 
among the sub-span pairs.  

HP-ITG acquires the rules from HMM-based 

word-aligned corpus using standard phrase pair 

extraction as stated in Chiang (2007). The rule 

probabilities and lexical weights in both English-

to-foreign and foreign-to-English directions are 

estimated and taken as features, in addition to 

those features in W-DITG, in the discriminative 

model of alignment hypothesis selection.  

7 Evaluation 

DPDI is evaluated against the baselines of Tic-

tac-toe (TTT) pruning (Zhang and Gildea, 2005) 

and Dynamic Program (DP) pruning (Haghighi et 

al., 2009; DeNero et al., 2009) with respect to 

Chinese-to-English alignment and translation. 

Based on DPDI, HP-DITG is evaluated against 

the alignment systems GIZA++ and BITG. 

7.1 Evaluation Criteria 

Four evaluation criteria are used in addition to 

the time spent on ITG parsing. We will first eva-

luate pruning regarding the pruning decisions 

themselves. That is, the first evaluation metric, 

pruning error rate (henceforth PER), measures 

how many correct E-spans are discarded. The 

major drawback of PER is that not all decisions 

in pruning would impact on alignment quality, 

since certain F-spans are of little use to the entire 

ITG parse tree.  

An alternative criterion is the upper bound on 

alignment F-score, which essentially measures 

how many links in annotated alignment can be 

kept in ITG parse. The calculation of F-score up-

per bound is done in a bottom-up way like ITG 

parsing. All leaf hypernodes which contain a cor-

rect link are assigned a score (known as hit) of 1. 

The hit of a non-leaf hypernode is based on the 

sum of hits of its daughter hypernodes. The max-

imal sum among all hyperedges of a hypernode is 

assigned to that hypernode. Formally,  

ğ‘•ğ‘–ğ‘¡ ğ‘‹ ğ‘“ , ğ‘’   = 

ğ‘šğ‘ğ‘¥
ğ‘Œ,ğ‘,ğ‘“ 1 ,ğ‘’ 1 ,ğ‘“ 2 ,ğ‘’ 2

(ğ‘•ğ‘–ğ‘¡ ğ‘Œ ğ‘“ 1, ğ‘’ 1  + ğ‘•ğ‘–ğ‘¡[ğ‘“ 2, ğ‘’ 2]) 

ğ‘•ğ‘–ğ‘¡ ğ¶ğ‘¤  ğ‘¢, ğ‘£  =  
1      ğ‘–ğ‘“  ğ‘¢, ğ‘£ âˆˆ ğ‘…
0        ğ‘œğ‘¡ğ‘•ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ 

  

ğ‘•ğ‘–ğ‘¡ ğ¶ğ‘’ = 0; ğ‘•ğ‘–ğ‘¡ ğ¶ğ‘“ = 0 

where ğ‘‹, ğ‘Œ, ğ‘ are variables for the categories in 
ITG grammar, and ğ‘… comprises the golden links 
in annotated alignment. ğ¶ğ‘¤ , ğ¶ğ‘’ , ğ¶ğ‘“  are defined in 

Appendix A. 

Figure 6 illustrates the calculation of the hit 

score for the example in Section 5.1/Figure 2. 

The upper bound of recall is the hit score divided 

by the total number of golden links. The upper 

321



ID pruning beam size pruning/total time cost PER F-UB F-score 

1 DPDI 10 72â€Ÿâ€Ÿ/3â€Ÿ03â€Ÿâ€Ÿ 4.9% 88.5% 82.5% 

2 TTT 10 58â€™â€™/2â€™38â€™â€™ 8.6% 87.5% 81.1% 

3 TTT 20 53â€Ÿâ€Ÿ/6â€Ÿ55â€Ÿâ€Ÿ 5.2% 88.6% 82.4% 

4 DP -- 11â€Ÿâ€Ÿ/6â€Ÿ01â€Ÿâ€Ÿ 12.1% 86.1% 80.5% 

Table 1: Evaluation of DPDI against TTT (Tic-tac-toe) and DP (Dynamic Program) for W-DITG 

ID pruning beam size pruning/total time cost PER F-UB F-score 

1 DPDI 10 72â€Ÿâ€Ÿ/5â€Ÿ18â€Ÿâ€Ÿ 4.9% 93.9% 87.0% 

2 TTT 10 58â€™â€™/4â€™51â€™â€™ 8.6% 93.0% 84.8% 

3 TTT 20 53â€Ÿâ€Ÿ/12â€Ÿ5â€Ÿâ€Ÿ 5.2% 94.0% 86.5% 

4 DP -- 11â€Ÿâ€Ÿ/15â€Ÿ39â€Ÿâ€Ÿ 12.1% 91.4% 83.6% 

Table 2: Evaluation of DPDI against TTT (Tic-tac-toe) and DP (Dynamic Program) for HP-DITG. 

bound of precision, which should be defined as 

the hit score divided by the number of links pro-

duced by the system, is almost always 1.0 in 

practice. The upper bound of alignment F-score 

can thus be calculated as well.  

Aâ†’[C,C]

Cw:

[e1,e1]/[f1,f1]

hit=1

Ce:

[e1]/Îµ

Cw:

[e2,e2]/[f1,f1]

Ce:

[e2]/Îµ

Cw:

[e3,e3]/[f2,f2]

C:

[e1,e2]/[f1,f1]

hit=max{0+1}=1

C:

[e2,e3]/[f2,f2]

hit=max{0+1}=1

A:

[e1,e3]/[f1,f2]

hit=max{1+1,1+1}=2

Câ†’ [Ce,Cw]

Aâ†’[C,C]

Câ†’ [Ce,Cw]

hit=1 hit=1hit=0 hit=0
 

Figure 6: Recall Upper Bound Calculation 

Finally, we also do end-to-end evaluation us-

ing both F-score in alignment and Bleu score in 

translation. We use our implementation of hierar-

chical phrase-based SMT (Chiang, 2007), with 

standard features, for the SMT experiments.  

7.2 Experiment Data 

Both discriminative pruning and alignment need 

training data and test data. We use the manually 

aligned Chinese-English dataset as used in Hag-

highi et al. (2009). The 491 sentence pairs in this 

dataset are adapted to our own Chinese word 

segmentation standard. 250 sentence pairs are 

used as training data and the other 241 are test 

data. The corresponding numbers of F-spans in 

training and test data are 4590 and 3951 respec-

tively.  

In SMT experiments, the bilingual training da-

taset is the NIST training set excluding the Hong 

Kong Law and Hong Kong Hansard, and our 5-

gram language model is trained from the Xinhua 

section of the Gigaword corpus. The NISTâ€Ÿ03 

test set is used as our development corpus and the 

NISTâ€Ÿ05 and NISTâ€Ÿ08 test sets are our test sets.  

7.3 Small-scale Evaluation 

The first set of experiments evaluates the perfor-

mance of the three pruning methods using the 

small 241-sentence set. Each pruning method is 

plugged in both W-DITG and HP-DITG. IBM 

Model 1 and HMM alignment model are re-

implemented as they are required by the three 

ITG pruning methods.  

The results for W-DITG are listed in Table 1. 

Tests 1 and 2 show that with the same beam size 

(i.e. number of E-spans per F-span), although 

DPDI spends a bit more time (due to the more 

complicated model), DPDI makes far less incor-

rect pruning decisions than the TTT. In terms of 

F-score upper bound, DPDI is 1 percent higher. 

DPDI achieves even larger improvement in ac-

tual F-score. 

To enable TTT achieving similar F-score or F-

score upper bound, the beam size has to be 

doubled and the time cost is more than twice the 

original (c.f. Tests 1 and 3 in Table 1) . 

The DP pruning in Haghighi et.al. (2009) per-

forms much poorer than the other two pruning 

methods. In fact, we fail to enable DP achieve the 

same F-score upper bound as the other two me-

thods before DP leads to intolerable memory 

consumption. This may be due to the use of dif-

ferent HMM model implementations between our 

work and Haghighi et.al. (2009).  

Table 2 lists the results for HP-DITG. Roughly 

the same observation as in W-DITG can be made. 

In addition to the superiority of DPDI, it can also 

be noted that HP-DITG achieves much higher F-

score and F-score upper bound. This shows that 

322



hierarchical phrase is a powerful tool in rectify-

ing the 1-to-1 constraint in ITG. 

Note also that while TTT in Test 3 gets rough-

ly the same F-score upper bound as DPDI in Test 

1, the corresponding F-score is slightly worse. A 

possible explanation is that better pruning not 

only speeds up the parsing/alignment process but 

also guides the search process to focus on the 

most promising region of the search space. 

7.4 Large-scale End-to-End Experiment 

ID Prun-

ing 

beam 

size 

time 

cost 

Bleu-

05 

Bleu-

08 

1 DPDI 10 1092h 38.57 28.31 

2 TTT 10 972h 37.96 27.37 

3 TTT 20 2376h 38.13 27.58 

4 DP -- 2068h 37.43 27.12 

Table 3:  Evaluation of DPDI against TTT and 

DP for HP-DITG  

ID WA-

Model 

F-Score Bleu-05 Bleu-08 

1 HMM 80.1% 36.91 26.86 

2 Giza++ 84.2% 37.70 27.33 

3 BITG 85.9% 37.92 27.85 

4 HP-DITG 87.0% 38.57 28.31 

Table 4:  Evaluation of DPDI against HMM, Gi-

za++ and BITG 

Table 3 lists the word alignment time cost and 

SMT performance of different pruning methods.  

HP-DITG using DPDI achieves the best Bleu 

score with acceptable time cost. Table 4 com-

pares HP-DITG to HMM (Vogel, et al., 1996), 

GIZA++ (Och and Ney, 2000) and BITG (Hag-

highi et al., 2009). It shows that HP-DITG (with 

DPDI) is better than the three baselines both in 

alignment F-score and Bleu score. Note that the 

Bleu score differences between HP-DITG and the 

three baselines are statistically significant (Koehn, 

2004). 

An explanation of the better performance by 

HP-DITG is the better phrase pair extraction due 

to DPDI. On the one hand, a good phrase pair 

often fails to be extracted due to a link inconsis-

tent with the pair. On the other hand, ITG prun-

ing can be considered as phrase pair selection, 

and good ITG pruning like DPDI guides the sub-

sequent ITG alignment process so that less links 

inconsistent to good phrase pairs are produced. 

This also explains (in Tables 2 and 3) why DPDI 

with beam size 10 leads to higher Bleu than TTT 

with beam size 20, even though both pruning me-

thods lead to roughly the same alignment F-score.  

8 Conclusion and Future Work 

This paper reviews word alignment through ITG 

parsing, and clarifies the problem of ITG pruning. 

A discriminative pruning model and two discri-

minative ITG alignments systems are proposed. 

The pruning model is shown to be superior to all 

existing ITG pruning methods, and the HP-DITG 

alignment system is shown to improve state-of-

the-art alignment and translation quality.  

The current DPDI model employs a very li-

mited set of features. Many features are related 

only to probabilities of word pairs. As the success 

of HP-DITG illustrates the merit of hierarchical 

phrase pair, in future we should investigate more 

features on the relationship between span pair 

and hierarchical phrase pair. 

Appendix A. The Normal Form Grammar 

Table 5 lists the ITG rules in normal form as 

used in this paper, which extend the normal form 

in Wu (1997) so as to handle the case of align-

ment to null. 

1  ğ‘†  â†’ ğ´|ğµ|ğ¶ 
2  ğ´  â†’  ğ´ ğµ | ğ´ ğ¶ | ğµ ğµ | ğµğ¶ | ğ¶ ğµ | ğ¶ ğ¶  

3  ğµ  â†’  ğ´ ğ´ | ğ´ ğ¶ | ğµ ğ´ | ğµ ğ¶  

  ğµ  â†’   ğ¶ ğ´ | ğ¶ ğ¶  

4  ğ¶  â†’ ğ¶ğ‘¤ |ğ¶ğ‘“ğ‘¤ |ğ¶ğ‘’ğ‘¤  

5  ğ¶  â†’  ğ¶ğ‘’ğ‘¤  ğ¶ğ‘“ğ‘¤   

6 ğ¶ğ‘¤  â†’ ğ‘¢/ğ‘£ 

7 ğ¶ğ‘’   â†’ ğœ€/ğ‘£; ğ¶ğ‘“ â†’ ğ‘¢/ğœ€ 

8 ğ¶ğ‘’ğ‘š â†’ ğ¶ğ‘’| ğ¶ğ‘’ğ‘š  ğ¶ğ‘’ ; ğ¶ğ‘“ğ‘š â†’ ğ¶ğ‘“ | ğ¶ğ‘“ğ‘š  ğ¶ğ‘“  

9 ğ¶ğ‘’ğ‘¤ â†’  ğ¶ğ‘’ğ‘š  ğ¶ğ‘¤  ; ğ¶ğ‘“ğ‘¤ â†’  ğ¶ğ‘“ğ‘š  ğ¶ğ‘¤   
 

Table 5: ITG Rules in Normal Form 

In these rules, ğ‘† is the Start symbol; ğ´ is the 

category for concatenating combination whereas 

ğµ for inverted combination. Rules (2) and (3) are 

inherited from Wu (1997). Rules (4) divide the 

terminal category ğ¶  into subcategories. Rule 

schema (6) subsumes all terminal unary rules for 

some English word ğ‘¢  and foreign word ğ‘£ , and 

rule schemas (7) are unary rules for alignment to 

null. Rules (8) ensure all words linked to null are 

combined in left branching manner, while rules 

(9) ensure those words linked to null combine 

with some following, rather than preceding, word 

pair. (Note: Accordingly, all sentences must be 

ended by a special token  ğ‘’ğ‘›ğ‘‘ , otherwise the 
last word(s) of a sentence cannot be linked to 

null.) If there are both English and foreign words 

linked to null, rule (5) ensures that those English 

323



words linked to null precede those foreign words 

linked to null. 

References  

Peter F. Brown, Stephen A. Della Pietra, Vincent J. 

Della Peitra, Robert L. Mercer. 1993. The Mathe-

matics of Statistical Machine Translation: Pa-

rameter Estimation. Computational Linguistics, 
19(2):263-311. 

Colin Cherry and Dekang Lin. 2006. Soft Syntactic 

Constraints for Word Alignment through Dis-

criminative Training. In Proceedings of ACL-
COLING.  

Colin Cherry and Dekang Lin. 2007. Inversion 

Transduction Grammar for Joint Phrasal 

Translation Modeling. In Proceedings of SSST, 
NAACL-HLT, Pages:17-24.  

David Chiang. 2007. Hierarchical Phrase-based 

Translation. Computational Linguistics, 33(2). 

John DeNero, Mohit Bansal, Adam Pauls, and Dan 

Klein. 2009. Efficient Parsing for Transducer 

Grammars. In Proceedings of NAACL, Pag-
es:227-235. 

Alexander Fraser and Daniel Marcu. 2006. Semi-

Supervised Training for StatisticalWord 

Alignment. In Proceedings of ACL, Pages:769-
776. 

Aria Haghighi, John Blitzer, John DeNero, and Dan 

Klein. 2009. Better Word Alignments with Su-

pervised ITG Models. In Proceedings of ACL, 
Pages: 923-931. 

Liang Huang and David Chiang. 2005. Better k-best 

Parsing. In Proceedings of IWPT 2005, Pag-
es:173-180. 

Franz Josef Och and Hermann Ney. 2000. Improved 

statistical alignment models. In Proceedings of 
ACL. Pages: 440-447 

Franz Josef Och. 2003. Minimum error rate train-

ing in statistical machine translation. In Pro-
ceedings of ACL,  Pages:160-167. 

Dan Klein and Christopher D. Manning. 2001. Pars-

ing and Hypergraphs. In Proceedings of IWPT, 
Pages:17-19 

Philipp Koehn. 2004. Statistical Significance Tests 

for Machine Translation Evaluation. In Pro-
ceedings of EMNLP,  Pages: 388-395. 

Yang Liu, Qun Liu and Shouxun Lin. 2005. Log-

linear models for word alignment. In Proceed-
ings of ACL, Pages: 81-88. 

Robert Moore. 2005. A Discriminative Framework 

for Bilingual Word Alignment. In Proceedings of 
EMNLP 2005, Pages: 81-88. 

Robert Moore, Wen-tau Yih, and Andreas Bode. 2006. 

Improved Discriminative Bilingual Word 

Alignment. In Proceedings of ACL, Pages: 513-
520. 

Stephan Vogel, Hermann Ney, and Christoph Till-

mann. 1996. HMM-based word alignment in 

statistical translation. In Proceedings of COL-
ING, Pages: 836-841. 

Stephan Vogel. 2005. PESA: Phrase Pair Extrac-

tion as Sentence Splitting.  In Proceedings of MT 
Summit. 

Dekai Wu. 1997. Stochastic Inversion Transduc-

tion Grammars and Bilingual Parsing of Pa-

rallel Corpora. Computational Linguistics, 23(3). 

Hao Zhang and Daniel Gildea. 2005. Stochastic Lex-

icalized Inversion Transduction Grammar for 

Alignment. In Proceedings of ACL.  

Hao Zhang, Chris Quirk, Robert Moore, and Daniel 

Gildea. 2008. Bayesian learning of non-

compositional phrases with synchronous pars-

ing. In Proceedings of ACL, Pages: 314-323. 

 

324


