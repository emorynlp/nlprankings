



















































Punctuation Prediction with Transition-based Parsing


Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 752â€“760,
Sofia, Bulgaria, August 4-9 2013. cÂ©2013 Association for Computational Linguistics

Punctuation Prediction with Transition-based Parsing 

Dongdong Zhang1, Shuangzhi Wu2, Nan Yang3, Mu Li1 
 

1Microsoft Research Asia, Beijing, China 
2Harbin Institute of Technology, Harbin, China 

3University of Science and Technology of China, Hefei, China 

{dozhang,v-shuawu,v-nayang,muli}@microsoft.com 

 

Abstract 

Punctuations are not available in automatic 

speech recognition outputs, which could cre-

ate barriers to many subsequent text pro-

cessing tasks. This paper proposes a novel 

method to predict punctuation symbols for the 

stream of words in transcribed speech texts. 

Our method jointly performs parsing and 

punctuation prediction by integrating a rich set 

of syntactic features when processing words 

from left to right. It can exploit a global view 

to capture long-range dependencies for punc-

tuation prediction with linear complexity. The 

experimental results on the test data sets of 

IWSLT and TDT4 show that our method can 

achieve high-level performance in punctuation 

prediction over the stream of words in tran-

scribed speech text. 

1 Introduction 

Standard automatic speech recognizers output un-

structured streams of words. They neither perform 

a proper segmentation of the output into sentences, 

nor predict punctuation symbols. The unavailable 

punctuations and sentence boundaries in tran-

scribed speech texts create barriers to many sub-

sequent processing tasks, such as summarization, 

information extraction, question answering and 

machine translation. Thus, the segmentation of 

long texts is necessary in many real applications. 

For example, in speech-to-speech translation, 

continuously transcribed speech texts need to be 

segmented before being fed into subsequent ma-

chine translation systems (Takezawa et al., 1998; 

Nakamura, 2009). This is because current ma-

chine translation (MT) systems perform the trans-

lation at the sentence level, where various models 

used in MT are trained over segmented sentences 

and many algorithms inside MT have an exponen-

tial complexity with regard to the length of inputs. 

The punctuation prediction problem has at-

tracted research interest in both the speech pro-

cessing community and the natural language pro-

cessing community. Most previous work primar-

ily exploits local features in their statistical mod-

els such as lexicons, prosodic cues and hidden 

event language model (HELM) (Liu et al., 2005; 

Matusov et al., 2006; Huang and Zweig, 2002; 

Stolcke and Shriberg, 1996). The word-level mod-

els integrating local features have narrow views 

about the input and could not achieve satisfied 

performance due to the limited context infor-

mation access (Favre et al., 2008). Naturally, 

global contexts are required to model the punctu-

ation prediction, especially for long-range de-

pendencies. For instance, in English question sen-

tences, the ending question mark is long-range de-

pendent on the initial phrases (Lu and Ng, 2010), 

such as â€œcould youâ€ in Figure 1. There has been 

some work trying to incorporate syntactic features 

to broaden the view of hypotheses in the punctua-

tion prediction models (Roark et al., 2006; Favre 

et al., 2008). In their methods, the punctuation 

prediction is treated as a separated post-procedure 

of parsing, which may suffer from the problem of 

error propagation. In addition, these approaches 

are not able to incrementally process inputs and 

are not efficient for very long inputs, especially in 

the cases of long transcribed speech texts from 

presentations where the number of streaming 

words could be larger than hundreds or thousands. 

In this paper, we propose jointly performing   

punctuation prediction and transition-based de-

pendency parsing over transcribed speech text. 

When the transition-based parsing consumes the 

stream of words left to right with the shift-reduce 

decoding algorithm, punctuation symbols are pre-

dicted for each word based on the contexts of the 

parsing tree. Two models are proposed to cause 

the punctuation prediction to interact with the 

transition actions in parsing. One is to conduct 

transition actions of parsing followed by punctua-

tion predictions in a cascaded way. The other is to 

associate the conventional transition actions of 

parsing with punctuation perditions, so that pre-

dicted punctuations are directly inferred from the 

752



 

(a). The transcribed speech text without punctuations 

 

  

 

 

 

 

(b). Transition-based parsing trees and predicted punctuations over transcribed text 

 

 

(c). Two segmentations are formed when inserting the predicted punctuation symbols into the transcribed text 

Figure 1. An example of punctuation prediction. 

parsing tree. Our models have linear complexity 

and are capable of handling streams of words with 

any length. In addition, the computation of models 

use a rich set of syntactic features, which can im-

prove the complicated punctuation predictions 

from a global view, especially for the long range 

dependencies.  

Figure 1 shows an example of how parsing 

helps punctuation prediction over the transcribed 

speech text. As illustrated in Figure 1(b), two 

commas are predicted when their preceding words 

act as the adverbial modifiers (advmod) during 

parsing. The period after the word â€œmenuâ€ is pre-

dicted when the parsing of an adverbial clause 

modifier (advcl) is completed. The question mark 

at the end of the input is determined when a direct 

object modifier (dobj) is identified, together with 

the long range clue that the auxiliary word occurs 

before the nominal subject (nsubj). Eventually, 

two segmentations are formed according to the 

punctuation prediction results, shown in Figure 

1(c).  

The training data used for our models is adapted 

from Treebank data by excluding all punctuations 

but keeping the punctuation contexts, so that it can 

simulate the unavailable annotated transcribed 

speech texts. In decoding, beam search is used to 

get optimal punctuation prediction results. We 

conduct experiments on both IWSLT data and 

TDT4 test data sets. The experimental results 

show that our method can achieve higher perfor-

mance than the CRF-based baseline method. 

The paper is structured as follows: Section 2 

conducts a survey of related work. The transition-

based dependency parsing is introduced in Section 

3. We explain our approach to predicting punctu-

ations for transcribed speech texts in Section 4. 

Section 5 gives the results of our experiment. The 

conclusion and future work are given in Section 6. 

2 Related Work 

Sentence boundary detection and punctuation pre-

diction have been extensively studied in the 

speech processing field and have attracted re-

search interest in the natural language processing 

field as well. Most previous work exploits local 

features for the task. Kim and Woodland (2001), 

Huang and Zweig (2002), Christensen et al. 

(2001), and Liu et al. (2005) integrate both pro-

sodic features (pitch, pause duration, etc.) and lex-

ical features (words, n-grams, etc.) to predict 

punctuation symbols during speech recognition, 

where Huang and Zweig (2002) uses a maximum 

entropy model, Christensen et al. (2001) focus on 

finite state and multi-layer perceptron methods, 

and Liu et al. (2005) uses conditional random 

fields. However, in some scenarios the prosodic 

cues are not available due to inaccessible original 

raw speech waveforms. Matusov et al. (2006) in-

tegrate segmentation features into the log-linear 

model in the statistical machine translation (SMT) 

framework to improve the translation perfor-

mance when translating transcribed speech texts. 

Lu and Ng (2010) uses dynamic conditional ran-

dom fields to perform both sentence boundary and 

sentence type prediction. They achieved promis-

ing results on both English and Chinese tran-

scribed speech texts. The above work only ex-

anyway you may find your favorite if you go through the menu so could you tell me your choice 

                   anyway you may find your favorite if you go  through the menu so could you tell me your choice 

, N N N N N N N N N N . , N N N N N ? 

anyway, you may find your favorite if you go through the menu. so, could you tell me your choice? 

nsubj nsubj poss 
aux

mark pobj 

iobj 

advmod 

advcl 

nsubj dobj 

det poss aux prep 

advmod dobj 

753



ploits local features, so they were limited to cap-

turing long range dependencies for punctuation 

prediction. 

It is natural to incorporate global knowledge, 

such as syntactic information, to improve punctu-

ation prediction performance. Roark et al. (2006) 

use a rich set of non-local features including par-

ser scores to re-rank full segmentations. Favre et 

al. (2008) integrate syntactic information from a 

PCFG parser into a log-linear and combine it with 

local features for sentence segmentation. The 

punctuation prediction in these works is per-

formed as a post-procedure step of parsing, where 

a parse tree needs to be built in advance. As their 

parsing over the stream of words in transcribed 

speech text is exponentially complex, their ap-

proaches are only feasible for short input pro-

cessing. Unlike these works, we incorporate punc-

tuation prediction into the parsing which process 

left to right input without length limitations. 

Numerous dependency parsing algorithms 

have been proposed in the natural language pro-

cessing community, including transition-based 

and graph-based dependency parsing. Compared 

to graph-based parsing, transition-based parsing 

can offer linear time complexity and easily lever-

age non-local features in the models (Yamada and 

Matsumoto, 2003; Nivre et al., 2006b; Zhang and 

Clark, 2008; Huang and Sagae, 2010). Starting 

with the work from (Zhang and Nivre, 2011), in 

this paper we extend transition-based dependency 

parsing from the sentence-level to the stream of 

words and integrate the parsing with punctuation 

prediction.  

Joint POS tagging and transition-based de-

pendency parsing are studied in (Hatori et al., 

2011; Bohnet and Nivre, 2012). The improve-

ments are reported with the joint model compared 

to the pipeline model for Chinese and other richly 

inflected languages, which shows that it also 

makes sense to jointly perform punctuation pre-

diction and parsing, although these two tasks of 

POS tagging and punctuation prediction are dif-

ferent in two ways: 1). The former usually works 

on a well-formed single sentence while the latter 

needs to process multiple sentences that are very 

lengthy. 2). POS tags are must-have features to 

parsing while punctuations are not. The parsing 

quality in the former is more sensitive to the per-

formance of the entire task than in the latter. 

3 Transition-based dependency parsing 

In a typical transition-based dependency parsing 

process, the shift-reduce decoding algorithm is 

applied and a queue and stack are maintained 

(Zhang and Nivre, 2011). The queue stores the 

stream of transcribed speech words, the front of 

which is indexed as the current word. The stack 

stores the unfinished words which may be linked 

with the current word or a future word in the 

queue. When words in the queue are consumed 

from left to right, a set of transition actions is ap-

plied to build a parse tree. There are four kinds of 

transition actions conducted in the parsing process 

(Zhang and Nivre, 2011), as described in Table 1.  

 

Action Description 

Shift Fetches the current word from the 

queue and pushes it to the stack 

Reduce Pops the stack 

LeftArc Adds a dependency link from the cur-

rent word to the stack top, and  pops the 

stack 

RightArc Adds a dependency link from the stack 

top to the current word, takes away the 

current word from the queue and 

pushes it to the stack 

Table 1. Action types in transition-based parsing 

The choice of each transition action during the 

parsing is scored by a linear model that can be 

trained over a rich set of non-local features ex-

tracted from the contexts of the stack, the queue 

and the set of dependency labels. As described in 

(Zhang and Nivre, 2011), the feature templates 

could be defined over the lexicons, POS-tags and 

the combinations with syntactic information. 

In parsing, beam search is performed to search 

the optimal sequence of transition actions, from 

which a parse tree is formed (Zhang and Clark, 

2008). As each word must be pushed to the stack 

once and popped off once, the number of actions 

needed to parse a sentence is always 2n, where n 

is the length of the sentence. Thus, transition-

based parsing has a linear complexity with the 

length of input and naturally it can be extended to 

process the stream of words. 

4 Our method 

4.1 Model 

In the task of punctuation prediction, we are given 

a stream of words from an automatic transcription 

of speech text, denoted by ğ‘¤1
ğ‘›: = ğ‘¤1, ğ‘¤2, â€¦ , ğ‘¤ğ‘› . 

We are asked to output a sequence of punctuation 

symbols ğ‘†1
ğ‘›: = ğ‘ 1, ğ‘ 2, â€¦ , ğ‘ ğ‘›  where ğ‘ ğ‘–  is attached 

to ğ‘¤ğ‘– to form a sentence like Figure 1(c). If there 
are no ambiguities, ğ‘†1

ğ‘›  is also abbreviated as ğ‘†, 

754



similarly for ğ‘¤1
ğ‘› as ğ‘¤. We model the search of the 

best sequence of predicted punctuation symbols 

ğ‘†âˆ— as: 
 

             ğ‘†âˆ— = argmaxSğ‘ƒ(ğ‘†1
ğ‘›|ğ‘¤1

ğ‘›)                     (1) 
 

We introduce the transition-based parsing tree 

ğ‘‡ to guide the punctuation prediction in Model (2), 
where parsing trees are constructed over the tran-

scribed text while containing no punctuations. 

  

ğ‘†âˆ— = argmaxğ‘† âˆ‘ ğ‘ƒ(ğ‘‡|ğ‘¤1
ğ‘›) Ã— ğ‘ƒ(ğ‘†1

ğ‘›|ğ‘‡, ğ‘¤1
ğ‘›)ğ‘‡     (2) 

 

Rather than enumerate all possible parsing trees, 

we jointly optimize the punctuation prediction 

model and the transition-based parsing model 

with the form:  

 

(ğ‘†âˆ—, ğ‘‡âˆ—) = argmax(ğ‘†,ğ‘‡)ğ‘ƒ(ğ‘‡|ğ‘¤1
ğ‘›) Ã—

                                                ğ‘ƒ(ğ‘†1
ğ‘›|ğ‘‡, ğ‘¤1

ğ‘›)           (3) 
 

Let ğ‘‡1
ğ‘– be the constructed partial tree when ğ‘¤1

ğ‘–  

is consumed from the queue. We decompose the 

Model (3) into:  

 

(ğ‘†âˆ—, ğ‘‡âˆ—) =

argmax(ğ‘†,ğ‘‡) âˆ ğ‘ƒ(ğ‘‡1
ğ‘–|ğ‘‡1

ğ‘–âˆ’1, ğ‘¤1
ğ‘–) Ã— ğ‘ƒ(ğ‘ ğ‘–|ğ‘‡1

ğ‘–, ğ‘¤1
ğ‘–)ğ‘›ğ‘–=1                                              

(4) 

 

It is noted that a partial parsing tree uniquely 

corresponds to a sequence of transition actions, 

and vice versa. Suppose ğ‘‡1
ğ‘– corresponds to the ac-

tion sequence ğ´1
ğ‘–  and let ğ‘ğ‘– denote the last action 

in ğ´1
ğ‘– . As the current word ğ‘¤ğ‘–  can only be con-

sumed from the queue by either Shift or RightArc 

according to Table 1, we have ğ‘ğ‘– âˆˆ
{ğ‘†â„ğ‘–ğ‘“ğ‘¡, ğ‘…ğ‘–ğ‘”â„ğ‘¡ğ´ğ‘Ÿğ‘} . Thus, we synchronize the 
punctuation prediction with the application of 

Shift and RightArc during the parsing, which is ex-

plained by Model (5).  

 

(ğ‘†âˆ—, ğ‘‡âˆ—) = argmax(ğ‘†,ğ‘‡) âˆ ğ‘ƒ(ğ‘‡1
ğ‘– , ğ´1

ğ‘– |ğ‘‡1
ğ‘–âˆ’1, ğ‘¤1

ğ‘–)
ğ‘›

ğ‘–=1

Ã— ğ‘ƒ(ğ‘ ğ‘–|ğ‘ğ‘– , ğ‘‡1
ğ‘– , ğ‘¤1

ğ‘–) 

                                                                      (5) 

 

The model is further refined by reducing the 

computation scope. When a full-stop punctuation 

is determined (i.e., a segmentation is formed), we 

discard the previous contexts and restart a new 

                                                           
1 Specially, ğ‘ğ‘– is equal to 1 if there are no previous full-stop 
punctuations. 

procedure for both parsing and punctuation pre-

diction over the rest of words in the stream. In this 

way we are theoretically able to handle the unlim-

ited stream of words without needing to always 

keep the entire context history of streaming words. 

Let ğ‘ğ‘– be the position index of last full-stop punc-

tuation1 before ğ‘–, ğ‘‡ğ‘ğ‘–
ğ‘–  and ğ´ğ‘ğ‘–

ğ‘– the partial tree and 

corresponding action sequence over the words 

ğ‘¤ğ‘ğ‘–
ğ‘– , Model (5) can be rewritten by: 

 
(ğ‘†âˆ—, ğ‘‡âˆ—) =
argmax(ğ‘†,ğ‘‡) âˆ ğ‘ƒ(ğ‘‡ğ‘ğ‘–

ğ‘– , ğ´ğ‘ğ‘–
ğ‘– |ğ‘‡ğ‘ğ‘–

ğ‘–âˆ’1, ğ‘¤ğ‘ğ‘–
ğ‘– ) Ã—ğ‘›ğ‘–=1

                                ğ‘ƒ(ğ‘ ğ‘–|ğ‘ğ‘– , ğ‘‡ğ‘ğ‘–
ğ‘– , ğ‘¤ğ‘ğ‘–

ğ‘– )                     (6) 

 

With different computation of Model (6), we 

induce two joint models for punctuation predic-

tion: the cascaded punctuation prediction model 

and the unified punctuation prediction model.  

4.2 Cascaded punctuation prediction model 
(CPP) 

In Model (6), the computation of two sub-models 

is independent. The first sub-model is computed 

based on the context of words and partial trees 

without any punctuation knowledge, while the 

computation of the second sub-model is condi-

tional on the context from the partially built pars-

ing tree ğ‘‡ğ‘ğ‘–
ğ‘–  and the transition action. As the words 

in the stream are consumed, each computation of 

transition actions is followed by a computation of 

punctuation prediction. Thus, the two sub-models 

are computed in a cascaded way, until the optimal 

parsing tree and optimal punctuation symbols are 

generated. We call this model the cascaded punc-

tuation prediction model (CPP). 

4.3 Unified punctuation prediction model 
(UPP) 

In Model (6), if the punctuation symbols can be 

deterministically inferred from the partial tree, 

ğ‘ƒ(ğ‘ ğ‘–|ğ‘ğ‘–, ğ‘‡ğ‘ğ‘–
ğ‘– , ğ‘¤ğ‘ğ‘–

ğ‘– ) can be omitted because it is al-

ways 1. Similar to the idea of joint POS tagging 

and parsing (Hatori et al., 2011; Bohnet and Nivre, 

2012), we propose attaching the punctuation pre-

diction onto the parsing tree by embedding ğ‘ ğ‘– into 
ğ‘ğ‘– . Thus, we extend the conventional transition 
actions illustrated in Table 1 to a new set of tran-

sition actions for the parsing, denoted by ï¿½Ì‚ï¿½: 
 

755



ï¿½Ì‚ï¿½ = {ğ¿ğ‘’ğ‘“ğ‘¡ğ´ğ‘Ÿğ‘, ğ‘…ğ‘’ğ‘‘ğ‘¢ğ‘ğ‘’} âˆª {ğ‘†â„ğ‘–ğ‘“ğ‘¡(ğ‘ )|ğ‘  âˆˆ ğ‘„}
âˆª {ğ‘…ğ‘–ğ‘”â„ğ‘¡ğ´ğ‘Ÿğ‘(ğ‘ )|ğ‘  âˆˆ ğ‘„} 

 

where Q is the set of punctuation symbols to be 

predicted, ğ‘  is a punctuation symbol belonging to 
Q, Shift(s) is an action that attaches s to the current 

word on the basis of original Shift action in pars-

ing, RightArc(s) attaches ğ‘  to the current word on 
the basis of original RightArc action. 

With the redefined transition action set ï¿½Ì‚ï¿½, the 
computation of Model (6) is reformulated as:  

  
(ğ‘†âˆ—, ğ‘‡âˆ—) =

argmax(ğ‘†,ğ‘‡) âˆ ğ‘ƒ (ğ‘‡ğ‘ğ‘–
ğ‘– , ï¿½Ì‚ï¿½

ğ‘ğ‘–

ğ‘–
|ğ‘‡ğ‘ğ‘–

ğ‘–âˆ’1, ï¿½Ì‚ï¿½ğ‘ğ‘–
ğ‘–âˆ’1

, ğ‘¤ğ‘ğ‘–
ğ‘– )ğ‘›ğ‘–=1        (7) 

 

Here, the computation of parsing tree and punc-

tuation prediction is unified into one model where 

the sequence of transition action outputs uniquely 

determines the punctuations attached to the words. 

We refer to it as the unified punctuation predic-

tion model (UPP). 

 

 

 

 

 

 

 
 

(a). Parsing tree and attached punctuation symbols 

 
Shift(,), Shift(N), Shift(N), LeftArc, LeftArc, LeftArc, 

Shift(N), RightArc(?), Reduce, Reduce 
 

(b). The corresponding sequence of transition actions 

Figure 2. An example of punctuation prediction 

using the UPP model, where N is a null type punc-

tuation symbol denoting no need to attach any 

punctuation to the word. 

Figure 2 illustrates an example how the UPP 

model works. Given an input â€œso could you tell 

meâ€, the optimal sequence of transition actions in 

Figure 2(b) is calculated based on the UPP model 

to produce the parsing tree in Figure 2(a). Accord-

ing to the sequence of actions, we can determine 

the sequence of predicted punctuation symbols 

like â€œ,NNN?â€ that have been attached to the words 

shown in Figure 2(a). The final segmentation with 

the predicted punctuation insertion could be â€œso, 

could you tell me?â€. 

4.4 Model training and decoding 

In practice, the sub-models in Model (6) and (7) 

with the form of ğ‘ƒ(ğ‘Œ|ğ‘‹) is computed with a linear 
model ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘Œ, ğ‘‹) as 
 

ğ‘†ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘Œ, ğ‘‹) = ğ›·(ğ‘Œ, ğ‘‹) âˆ™ ğœ† 
 

where ğ›·(ğ‘Œ, ğ‘‹)  is the feature vector extracted 

from the output ğ‘Œ and the context ğ‘‹, and ğœ† is the 
weight vector. For the features of the models, we 

incorporate the bag of words and POS tags as well 

as tree-based features shown in Table 2, which are 

the same as those defined in (Zhang and Nivre, 

2011).  

 

(a) ws; w0; w1; w2; ps; p0; p1; p2; wsps; w0p0; w1p1; 

w2p2; wspsw0p0; wspsw0; wspsp0; wsw0p0; 

psw0p0; wsw0; psp0; p0p1; psp0p1; p0p1p2; 

(b) pshpsp0; pspslp0; pspsrp0; psp0p0l; wsd; psd; w0d; 

p0d; wsw0d; psp0d; wsvl; psvl; wsvr; psvr; w0vl; 

p0vl; wsh; psh; ts; w0l; p0l; t0l; w0r; p0r; t0r; w1l; 

p1l; t1l; wsh2; psh2; tsh; wsl2; psl2; tsl2; wsr2; psr2; 

tsr2; w0l2; p0l2; t0l2; pspslpsl2; pspsrpsr2; pspshpsh2; 

p0p0lp0l2; wsTl; psTl; wsTr; psTr; w0Tl; p0Tl; 

Table 2. (a) Features of the bag of words and POS 

tags. (b). Tree-based features. wï€­word; pï€­POS 

tag; dï€­distance between ws and w0; vï€­number of 

modifiers; tï€­dependency label; Tï€­set of depend-

ency labels; s, 0, 1 and 2 index the stack top and 

three front items in the queue respectively; hï€­head; 

lï€­left/leftmost; rï€­right/rightmost; h2ï€­head of a 

head; l2ï€­second leftmost; r2ï€­second rightmost. 

The training data for both the CPP and UPP 

models need to contain parsing trees and punctu-

ation information. Due to the absence of annota-

tion over transcribed speech data, we adapt the 

Treebank data for the purpose of model training. 

To do this, we remove all types of syntactic infor-

mation related to punctuation symbols from the 

raw Treebank data, but record what punctuation 

symbols are attached to the words. We normalize 

various punctuation symbols into two types: Mid-

dle-paused punctuation (M) and Full-stop punctu-

ation (F). Plus null type (N), there are three kinds 

of punctuation symbols attached to the words. Ta-

ble 3 illustrates the normalizations of punctuation 

symbols. In the experiments, we did not further 

distinguish the type among full-stop punctuation 

because the question mark and the exclamation 

mark have very low frequency in Treebank data. 

so could you tell me 

, N N N ? 

nsubj iobj 
aux

advmod 

756



But our CPP and UPP models are both independ-

ent regarding the number of punctuation types to 

be predicted. 

 

Punctuations Normalization 

Period, question mark, 

exclamation mark 

Full-stop punctuation 

(F) 

Comma, Colon, semi-

colon 

Middle-paused punctu-

ation (M) 

Multiple Punctuations 

(e.g., !!!!?) 

Full-stop punctuation 

(F) 

Quotations, brackets, 

etc. 

Null (N) 

Table 3. Punctuation normalization in training 

data 

As the feature templates are the same for the 

model training of both CPP and UPP, the training 

instances of CPP and UPP have the same contexts 

but with different outputs. Similar to work in 

(Zhang and Clark, 2008; Zhang and Nivre, 2011), 

we train CPP and UPP by generalized perceptron 

(Collins, 2002).  

In decoding, beam search is performed to get 

the optimal sequence of transition actions in CPP 

and UPP, and the optimal punctuation symbols in 

CPP. To ensure each segment decided by a full-

stop punctuation corresponds to a single parsing 

tree, two constraints are applied in decoding for 

the pruning of deficient search paths. 

(1) Proceeding-constraint: If the partial pars-
ing result is not a single tree, the full-stop 

punctuation prediction in CPP cannot be 

performed. In UPP, if Shift(F) or 

RightArc(F) fail to result in a single parsing 

tree, they cannot be performed as well. 

(2) Succeeding-constraint: If the full-stop 
punctuation is predicted in CPP, or Shift(F) 

and RightArc(F) are performed in UPP, the 

following transition actions must be a se-

quence of Reduce actions until the stack 

becomes empty. 

5 Experiments 

5.1 Experimental setup 

Our training data of transition-based dependency 

trees are converted from phrasal structure trees in 

English Web Treebank (LDC2012T13) and the 

English portion of OntoNotes 4.0 (LDC2011T03) 

by the Stanford Conversion toolkit (Marneffe et 

al., 2006). It contains around 1.5M words in total 

and consist of various genres including weblogs, 

web texts, newsgroups, email, reviews, question-

answer sessions, newswires, broadcast news and 

broadcast conversations. To simulate the tran-

scribed speech text, all words in dependency trees 

are lowercased and punctuations are excluded be-

fore model training. In addition, every ten depend-

ency trees are concatenated sequentially to simu-

late a parsing result of a stream of words in the 

model training. 

There are two test data sets used in our experi-

ments. One is the English corpus of the IWSLT09 

evaluation campaign (Paul, 2009) that is the con-

versional speech text. The other is a subset of the 

TDT4 English data (LDC2005T16) which con-

sists of 200 hours of closed-captioned broadcast 

news.  

In the decoding, the beam size of both the tran-

sition-based parsing and punctuation prediction is 

set to 5. The part-of-speech tagger is our re-imple-

mentation of the work in (Collins, 2002).  

The evaluation metrics of our experiments are 

precision (prec.), recall (rec.) and F1-measure 

(F1). 

For the comparison, we also implement a base-

line method based on the CRF model. It incorpo-

rates the features of bag of words and POS tags 

shown in Table 2(a), which are commonly used in 

previous related work.  

5.2 Experimental results 

We test the performance of our method on both 

the correctly recognized texts and automatically 

recognized texts. The former data is used to eval-

uate the capability of punctuation prediction of 

our algorithm regardless of the noises from speech 

data, as our model training data come from formal 

text instead of transcribed speech data. The usage 

of the latter test data set aims to evaluate the ef-

fectiveness of our method in real applications 

where lots of substantial recognition errors could 

be contained. In addition, we also evaluate the 

quality of our transition-based parsing, as its per-

formance could have a big influence on the quality 

of punctuation prediction. 

5.2.1 Performance on correctly recognized 
text 

The evaluation of our method on correctly recog-

nized text uses 10% of IWSLT09 training set, 

which consists of 19,972 sentences from BTEC 

(Basic Travel Expression Corpus) and 10,061 sen-

tences from CT (Challenge Task). The average in-

put length is about 10 words and each input con-

tains 1.3 sentences on average. The evaluation re-

sults are presented in Table 4.  

757



 

 Measure   Middle-

Paused 

Full-stop Mixed 

Baseline 

(CRF) 

prec. 33.2% 81.5% 78.8% 

rec. 25.9% 83.8% 80.7% 

F1 29.1% 82.6% 79.8% 

 

CPP 

prec. 51% 89% 89.6% 

rec. 50.3% 93.1% 92.7% 

F1 50.6% 91% 91.1% 

 

UPP 

 

prec. 52.6% 93.2% 92% 

rec. 59.7% 91.3% 92.3% 

F1 55.9% 92.2% 92.2% 

Table 4. Punctuation prediction performance on 

correctly recognized text 

   We achieved good performance on full-stop 

punctuation compared to the baseline, which 

shows our method can efficiently process sen-

tence segmentation because each segment is de-

cided by the structure of a single parsing tree. In 

addition, the global syntactic knowledge used in 

our work help capture long range dependencies of 

punctuations. The performance of middle-paused 

punctuation prediction is fairly low between all 

methods, which shows predicting middle-paused 

punctuations is a difficult task. This is because the 

usage of middle-paused punctuations is very flex-

ible, especially in conversional data. The last col-

umn in Table 4 presents the performance of the 

pure segmentation task where the middle-paused 

and full-stop punctuations are mixed and not dis-

tinguished. The performance of our method is 

much higher than that of the baseline, which 

shows our method is good at segmentation. We 

also note that UPP yields slightly better perfor-

mance than CPP on full-stop and mixed punctua-

tion prediction, and much better performance on 

middle-paused punctuation prediction. This could 

be because the interaction of parsing and punctu-

ation prediction is closer together in UPP than in 

CPP. 

5.2.2 Performance on automatically recog-
nized text 

Table 5 shows the experimental results of punctu-

ation prediction on automatically recognized text 

from TDT4 data that is recognized using SRIâ€™s 

English broadcast news ASR system where the 

word error rate is estimated to be 18%. As the an-

notation of middle-paused punctuations in TDT4 

is not available, we can only evaluate the perfor-

mance of full-stop punctuation prediction (i.e., de-

tecting sentence boundaries). Thus, we merge 

every three sentences into one single input before 

performing full-stop prediction. The average input 

length is about 43 words. 

 

 Measure   Full-stop 

Baseline 

(CRF) 

prec. 37.7% 

rec. 60.7% 

F1 46.5% 

 

CPP 

prec. 63% 

rec. 58.6% 

F1 60.2% 

 

UPP 

 

prec. 73.9% 

rec. 51.6% 

F1 60.7% 

Table 5. Punctuation prediction performance on 

automatically recognized text 

Generally, the performance shown in Table 5 is 

not as high as that in Table 4. This is because the 

speech recognition error from ASR systems de-

grades the capability of model prediction. Another 

reason might be that the domain and style of our 

training data mismatch those of TDT4 data. The 

baseline gets a little higher recall than our method, 

which shows the baseline method tends to make 

aggressive segmentation decisions. However, 

both precision and F1 score of our method are 

much higher than the baseline. CPP has higher re-

call than UPP, but with lower precision and F1 

score. This is in line with Table 4, which consist-

ently illustrates CPP can get higher recall on full-

stop punctuation prediction for both correctly rec-

ognized and automatically recognized texts.  

5.2.3 Performance of transition-based pars-
ing 

Performance of parsing affects the quality of 

punctuation prediction in our work. In this section, 

we separately evaluate the performance of our 

transition-based parser over various domains in-

cluding the Wall Street Journal (WSJ), weblogs, 

newsgroups, answers, email messages and re-

views. We divided annotated Treebank data into 

three data sets: 90% for model training, 5% for the 

development set and 5% for the test set. The accu-

racy of our POS-tagger achieves 96.71%. The 

beam size in the decoding of both our POS-tag-

ging and parsing is set to 5. Table 6 presents the 

results of our experiments on the measures of 

UAS and LAS, where the overall accuracy is ob-

tained from a general model which is trained over 

the combination of the training data from all do-

mains.  

758



We first evaluate the performance of our transi-

tion-based parsing over texts containing punctua-

tions (TCP). The evaluation results show that our 

transition-based parser achieves state-of-the-art 

performance levels, referring to the best depend-

ency parsing results reported in the shared task of 

SANCL 2012 workshop2, although they cannot be 

compared directly due to the different training 

data and test data sets used in the experiments. 

Secondly, we evaluate our parsing model in CPP 

over the texts without punctuations (TOP). Sur-

prisingly, the performance over TOP is better than 

that over TCP. The reason could be that we 

cleaned out data noises caused by punctuations 

when preparing TOP data. These results illustrate 

that the performance of transition-based parsing in 

our method does not degrade after being inte-

grated with punctuation prediction. As a by-prod-

uct of the punctuation prediction task, the outputs 

of parsing trees can benefit the subsequent text 

processing tasks. 

 

 Data sets UAS LAS 

 

 

Texts con-

taining punc-

tuations 

(TCP) 

 

WSJ 92.6% 90.3% 

Weblogs 90.7% 88.2% 

Answers 89.4% 85.7% 

Newsgroups 90.1% 87.6% 

Reviews 90.9% 88.4% 

Email Messages 89.6% 87.1% 

Overall 90.5% 88% 

 

 

Texts with-

out punctua-

tions (TOP) 

WSJ 92.6% 91.1% 

Weblogs 92.5% 91.1% 

Answers 95% 94% 

Newsgroups 92.6% 91.2% 

Reviews 92.6% 91.2% 

Email Messages 92.9% 91.7% 

Overall 92.6% 91.2% 

Table 6. The performance of our transition-based 

parser on written texts. UAS=unlabeled attach-

ment score; LAS=labeled attachment score 

6 Conclusion and Future Work  

In this paper, we proposed a novel method for 

punctuation prediction of transcribed speech texts. 

Our approach jointly performs parsing and punc-

tuation prediction by integrating a rich set of syn-

tactic features. It can not only yield parse trees, but 

also determine sentence boundaries and predict 

punctuation symbols from a global view of the in-

                                                           
2 https://sites.google.com/site/sancl2012/home/shared-

task/results 

puts. The proposed algorithm has linear complex-

ity in the size of input, which can efficiently pro-

cess the stream of words from a purely text pro-

cessing perspective without the dependences on 

either the ASR systems or subsequent tasks. The 

experimental results show that our approach out-

performs the CRF-based method on both the cor-

rectly recognized and automatically recognized 

texts. In addition, the performance of the parsing 

over the stream of transcribed words is state-of-

the-art, which can benefit many subsequent text 

processing tasks. 

    In future work, we will try our method on other 

languages such as Chinese and Japanese, where 

Treebank data is available. We would also like to 

test the MT performance over transcribed speech 

texts with punctuation symbols inserted based on 

our method proposed in this paper.  

References 

B. Bohnet and J. Nivre. 2012. A transition-based sys-

tem for joint part-of-speech tagging and labeled 

non-projective dependency parsing. In Proc. 

EMNLP-CoNLL 2012. 

H. Christensen, Y. Gotoh, and S. Renals. 2001. Punc-

tuation annotation using statistical prosody models. 

In Proc. of ISCA Workshop on Prosody in Speech 

Recognition and Understanding. 

M. Collins. 2002. Discriminative training methods for 

hidden Markov models: Theory and experiments 

with perceptron algorithms. In Proc. EMNLPâ€™02, 

pages 1-8. 

B. Favre, R. Grishman, D. Hillard, H. Ji, D. Hakkani-

Tur, and M. Ostendorf. 2008. Punctuating speech 

for information extraction. In Proc. of ICASSPâ€™08. 

B. Favre, D. HakkaniTur, S. Petrov and D. Klein. 2008. 

Efficient sentence segmentation using syntactic fea-

tures. In Spoken Language Technologies (SLT). 

A. Gravano, M. Jansche, and M. Bacchiani. 2009. Re-

storing punctuation and capitalization in transcribed 

speech. In Proc. of ICASSPâ€™09. 

J. Hatori, T. Matsuzaki, Y. Miyao and J. Tsujii. 2011. 

Incremental joint POS tagging and dependency 

parsing in Chinese. In Proc. Of IJCNLPâ€™11. 

J. Huang and G. Zweig. 2002. Maximum entropy 

model for punctuation annotation from speech. In 

Proc. Of ICSLPâ€™02. 

759



J.H. Kim and P.C. Woodland. 2001. The use of pros-

ody in a combined system for punctuation genera-

tion and speech recognition. In Proc. of Eu-

roSpeechâ€™01. 

Y. Liu, A. Stolcke, E. Shriberg, and M. Harper. 2005. 

Using conditional random fields for sentence 

boundary detection in speech. In Proc. of ACLâ€™05. 

W. Lu and H.T. Ng. 2010. Better Punctuation Predic-

tion with Dynamic Conditional Random Fields. In 

Proc. Of EMNLPâ€™10. Pages 177-186. 

M. Marneffe, B. MacCartney, C.D. Maning. 2006. 

Generating Typed Dependency Parses from Phrase 

Structure Parses. In Proc. LRECâ€™06. 

E. Matusov, A. Mauser, and H. Ney. 2006. Automatic 

sentence segmentation and punctuation prediction 

for spoken language translation. In Proc. of 

IWSLTâ€™06. 

S. Nakamura. 2009. Overcoming the language barrier 

with speech translation technology. In Science & 

Technology Trends - Quarterly Review. No. 31. 

April 2009. 

J. Nivre. 2003. An efficient algorithm for projective de-

pendency parsing. In Proceedings of IWPT, pages 

149â€“160, Nancy, France. 

J. Nivre and M. Scholz. 2004. Deterministic depend-

ency parsing of English text. In Proc. COLINGâ€™04. 

M. Paul. 2009. Overview of the IWSLT 2009 Evalua-

tion Campaign. In Proceedings of IWSLTâ€™09. 

B. Roark, Y. Liu, M. Harper, R. Stewart, M. Lease, M. 

Snover, I. Shafran, B. Dorr, J. Hale, A. Krasnyan-

skaya, and L. Yung. 2006. Reranking for sentence 

boundary detection in conversational speech. In 

Proc. ICASSP, 2006. 

A. Stolcke and E. Shriberg, â€œAutomatic linguistic seg-

mentation of conversational speech,â€ Proc. ICSLP, 

vol. 2, 1996. 

A. Stolcke, E. Shriberg, R. Bates, M. Ostendorf, D. 

Hakkani, M. Plauche, G. Tur, and Y. Lu. 1998. Au-

tomatic detection of sentence boundaries and disflu-

encies based on recognized words. In Proc. of 

ICSLPâ€™ 98. 

Takezawa, T. Morimoto, T. Sagisaka, Y. Campbell, N. 

Iida, H. Sugaya, F. Yokoo, A. Yamamoto, Seiichi. 

1998. A Japanese-to-English speech translation sys-

tem: ATR-MATRIX.  In Proc. ICSLPâ€™98. 

Y. Zhang and J. Nivre. 2011. Transition-based De-

pendency Parsing with Rich Non-local Features. In 

Proc. of ACLâ€™11, pages 188-193. 

Y. Zhang and S. Clark. A Tale of Two Parsers: inves-

tigating and combing graph-based and transition-

based dependency parsing using beam-search. 2008. 

In Proc. of EMNLPâ€™08, pages 562-571. 

760


