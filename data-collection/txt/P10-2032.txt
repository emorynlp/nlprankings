










































Balancing User Effort and Translation Error in Interactive Machine Translation via Confidence Measures


Proceedings of the ACL 2010 Conference Short Papers, pages 173–177,
Uppsala, Sweden, 11-16 July 2010. c©2010 Association for Computational Linguistics

Balancing User Effort and Translation Error in Interactive Machine
Translation Via Confidence Measures

Jesús González-Rubio
Inst. Tec. de Informática

Univ. Politéc. de Valencia
46021 Valencia, Spain

jegonzalez@iti.upv.es

Daniel Ortiz-Martı́nez
Dpto. de Sist Inf. y Comp.
Univ. Politéc. de Valencia

46021 Valencia, Spain
dortiz@dsic.upv.es

Francisco Casacuberta
Dpto. de Sist Inf. y Comp.
Univ. Politéc. de Valencia

46021 Valencia, Spain
fcn@dsic.upv.es

Abstract

This work deals with the application of
confidence measures within an interactive-
predictive machine translation system in
order to reduce human effort. If a small
loss in translation quality can be tolerated
for the sake of efficiency, user effort can
be saved by interactively translating only
those initial translations which the confi-
dence measure classifies as incorrect. We
apply confidence estimation as a way to
achieve a balance between user effort sav-
ings and final translation error. Empiri-
cal results show that our proposal allows
to obtain almost perfect translations while
significantly reducing user effort.

1 Introduction

In Statistical Machine Translation (SMT), the
translation is modelled as a decission process. For
a given source string fJ1 = f1 . . . fj . . . fJ , we
seek for the target string eI1 = e1 . . . ei . . . eI
which maximises posterior probability:

êÎ1 = argmax
I,eI

1

Pr(eI1|f
J
1 ) . (1)

Within the Interactive-predictive Machine
Translation (IMT) framework, a state-of-the-art
SMT system is employed in the following way:
For a given source sentence, the SMT system
fully automatically generates an initial translation.
A human translator checks this translation from
left to right, correcting the first error. The SMT
system then proposes a new extension, taking the
correct prefix ei1 = e1 . . . ei into account. These
steps are repeated until the whole input sentence
has been correctly translated. In the resulting
decision rule, we maximise over all possible
extensions eIi+1 of e

i
1:

êÎi+1 = argmax
I,eI

i+1

Pr(eIi+1|e
i
1, f

J
1 ) . (2)

An implementation of the IMT famework was
performed in the TransType project (Foster et al.,
1997; Langlais et al., 2002) and further improved
within the TransType2 project (Esteban et al.,
2004; Barrachina et al., 2009).

IMT aims at reducing the effort and increas-
ing the productivity of translators, while preserv-
ing high-quality translation. In this work, we inte-
grate Confidence Measures (CMs) within the IMT
framework to further reduce the user effort. As
will be shown, our proposal allows to balance the
ratio between user effort and final translation error.

1.1 Confidence Measures

Confidence estimation have been extensively stud-
ied for speech recognition. Only recently have re-
searchers started to investigate CMs for MT (Gan-
drabur and Foster, 2003; Blatz et al., 2004; Ueffing
and Ney, 2007).

Different TransType-style MT systems use con-
fidence information to improve translation predic-
tion accuracy (Gandrabur and Foster, 2003; Ueff-
ing and Ney, 2005). In this work, we propose a fo-
cus shift in which CMs are used to modify the in-
teraction between the user and the system instead
of modify the IMT translation predictions.

To compute CMs we have to select suitable con-
fidence features and define a binary classifier. Typ-
ically, the classification is carried out depending
on whether the confidence value exceeds a given
threshold or not.

2 IMT with Sentence CMs

In the conventional IMT scenario a human trans-
lator and a SMT system collaborate in order to
obtain the translation the user has in mind. Once
the user has interactively translated the source sen-
tences, the output translations are error-free. We
propose an alternative scenario where not all the
source sentences are interactively translated by the
user. Specifically, only those source sentences

173



whose initial fully automatic translation are incor-
rect, according to some quality criterion, are in-
teractively translated. We propose to use CMs as
the quality criterion to classify those initial trans-
lations.

Our approach implies a modification of the
user-machine interaction protocol. For a given
source sentence, the SMT system generates an ini-
tial translation. Then, if the CM classifies this
translation as correct, we output it as our final
translation. On the contrary, if the initial trans-
lation is classified as incorrect, we perform a con-
ventional IMT procedure, validating correct pre-
fixes and generating new suffixes, until the sen-
tence that the user has in mind is reached.

In our scenario, we allow the final translations
to be different from the ones the user has in mind.
This implies that the output may contain errors.
If a small loss in translation can be tolerated for
the sake of efficiency, user effort can be saved by
interactively translating only those sentences that
the CMs classify as incorrect.

It is worth of notice that our proposal can be
seen as a generalisation of the conventional IMT
approach. Varying the value of the CM classifi-
cation threshold, we can range from a fully auto-
matic SMT system where all sentences are clas-
sified as correct to a conventional IMT system
where all sentences are classified as incorrect.

2.1 Selecting a CM for IMT

We compute sentence CMs by combining the
scores given by a word CM based on the IBM
model 1 (Brown et al., 1993), similar to the one
described in (Blatz et al., 2004). We modified this
word CM by replacing the average by the max-
imal lexicon probability, because the average is
dominated by this maximum (Ueffing and Ney,
2005). We choose this word CM because it can be
calculated very fast during search, which is cru-
cial given the time constraints of the IMT sys-
tems. Moreover, its performance is similar to that
of other word CMs as results presented in (Blatz
et al., 2003; Blatz et al., 2004) show. The word
confidence value of word ei, cw(ei), is given by

cw(ei) = max
0≤j≤J

p(ei|fj) , (3)

where p(ei|fj) is the IBM model 1 lexicon proba-
bility, and f0 is the empty source word.

From this word CM, we compute two sentence
CMs which differ in the way the word confidence

Spanish English

T
ra

in Sentences 214.5K
Running words 5.8M 5.2M
Vocabulary 97.4K 83.7K

D
ev

. Sentences 400
Running words 11.5K 10.1K
Perplexity (trigrams) 46.1 59.4

Te
st

Sentences 800
Running words 22.6K 19.9K
Perplexity (trigrams) 45.2 60.8

Table 1: Statistics of the Spanish–English EU cor-
pora. K and M denote thousands and millions of
elements respectively.

scores cw(ei) are combined:

MEAN CM (cM (eI1)) is computed as the geo-
metric mean of the confidence scores of the
words in the sentence:

cM (e
I
1) =

I

√

√

√

√

I
∏

i=1

cw(ei) . (4)

RATIO CM (cR(eI1)) is computed as the percent-
age of words classified as correct in the sen-
tence. A word is classified as correct if
its confidence exceeds a word classification
threshold τw.

cR(e
I
1) =

|{ei / cw(ei) > τw}|

I
(5)

After computing the confidence value, each sen-
tence is classified as either correct or incorrect, de-
pending on whether its confidence value exceeds
or not a sentence clasiffication threshold τs. If
τs = 0.0 then all the sentences will be classified
as correct whereas if τs = 1.0 all the sentences
will be classified as incorrect.

3 Experimentation

The aim of the experimentation was to study the
possibly trade-off between saved user effort and
translation error obtained when using sentence
CMs within the IMT framework.

3.1 System evaluation

In this paper, we report our results as measured
by Word Stroke Ratio (WSR) (Barrachina et al.,
2009). WSR is used in the context of IMT to mea-
sure the effort required by the user to generate her

174



 0

 20

 40

 60

 80

 100

 0  0.2  0.4  0.6  0.8  1
 0

 20

 40

 60

 80

 100
W

S
R

B
LE

U

Threshold (τs)

WSR IMT-CM
BLEU IMT-CM

WSR IMT
BLEU SMT

Figure 1: BLEU translation scores versus WSR
for different values of the sentence classification
threshold using the MEAN CM.

translations. WSR is computed as the ratio be-
tween the number of word-strokes a user would
need to achieve the translation she has in mind and
the total number of words in the sentence. In this
context, a word-stroke is interpreted as a single ac-
tion, in which the user types a complete word, and
is assumed to have constant cost.

Additionally, and because our proposal allows
differences between its output and the reference
translation, we will also present translation qual-
ity results in terms of BiLingual Evaluation Un-
derstudy (BLEU) (Papineni et al., 2002). BLEU
computes a geometric mean of the precision of n-
grams multiplied by a factor to penalise short sen-
tences.

3.2 Experimental Setup

Our experiments were carried out on the EU cor-
pora (Barrachina et al., 2009). The EU corpora
were extracted from the Bulletin of the European
Union. The EU corpora is composed of sentences
given in three different language pairs. Here, we
will focus on the Spanish–English part of the EU
corpora. The corpus is divided into training, de-
velopment and test sets. The main figures of the
corpus can be seen in Table 1.

As a first step, be built a SMT system to trans-
late from Spanish into English. This was done
by means of the Thot toolkit (Ortiz et al., 2005),
which is a complete system for building phrase-
based SMT models. This toolkit involves the esti-
mation, from the training set, of different statisti-
cal models, which are in turn combined in a log-
linear fashion by adjusting a weight for each of
them by means of the MERT (Och, 2003) proce-

 0

 20

 40

 60

 80

 100

 0  0.2  0.4  0.6  0.8  1
 0

 20

 40

 60

 80

 100

W
S

R

B
LE

U

Threshold (τs)

WSR IMT-CM (τw=0.4)
BLEU IMT-CM (τw=0.4)

WSR IMT
BLEU SMT

Figure 2: BLEU translation scores versus WSR
for different values of the sentence classification
threshold using the RATIO CM with τw = 0.4.

dure, optimising the BLEU score on the develop-
ment set.

The IMT system which we have implemented
relies on the use of word graphs (Ueffing et al.,
2002) to efficiently compute the suffix for a given
prefix. A word graph has to be generated for each
sentence to be interactively translated. For this
purpose, we used a multi-stack phrase-based de-
coder which will be distributed in the near future
together with the Thot toolkit. We discarded to
use the state-of-the-art Moses toolkit (Koehn et
al., 2007) because preliminary experiments per-
formed with it revealed that the decoder by Ortiz-
Martı́nez et al. (2005) performs better in terms of
WSR when used to generate word graphs for their
use in IMT (Sanchis-Trilles et al., 2008). More-
over, the performance difference in regular SMT is
negligible. The decoder was set to only consider
monotonic translation, since in real IMT scenar-
ios considering non-monotonic translation leads to
excessive response time for the user.

Finally, the obtained word graphs were used
within the IMT procedure to produce the refer-
ence translations in the test set, measuring WSR
and BLEU.

3.3 Results

We carried out a series of experiments ranging the
value of the sentence classification threshold τs,
between 0.0 (equivalent to a fully automatic SMT
system) and 1.0 (equivalent to a conventional IMT
system), for both the MEAN and RATIO CMs.
For each threshold value, we calculated the effort
of the user in terms of WSR, and the translation
quality of the final output as measured by BLEU.

175



src-1 DECLARACIÓN (No 17) relativa al derecho de acceso a la información
ref-1 DECLARATION (No 17) on the right of access to information
tra-1 DECLARATION (No 17) on the right of access to information

src-2 Conclusiones del Consejo sobre el comercio electrónico y los impuestos indirectos.
ref-2 Council conclusions on electronic commerce and indirect taxation.
tra-2 Council conclusions on e-commerce and indirect taxation.

src-3 participación de los paı́ses candidatos en los programas comunitarios.
ref-3 participation of the applicant countries in Community programmes.
tra-3 countries’ involvement in Community programmes.

Example 1: Examples of initial fully automatically generated sentences classified as correct by the CMs.

Figure 1 shows WSR (WSR IMT-CM) and
BLEU (BLEU IMT-CM) scores obtained varying
τs for the MEAN CM. Additionally, we also show
the BLEU score (BLEU SMT) obtained by a fully
automatic SMT system as translation quality base-
line, and the WSR score (WSR IMT) obtained by
a conventional IMT system as user effort baseline.
This figure shows a continuous transition between
the fully automatic SMT system and the conven-
tional IMT system. This transition occurs when
ranging τs between 0.0 and 0.6. This is an unde-
sired effect, since for almost a half of the possible
values for τs there is no change in the behaviour
of our proposed IMT system.

The RATIO CM confidence values depend on
a word classification threshold τw. We have car-
ried out experimentation ranging τw between 0.0
and 1.0 and found that this value can be used to
solve the above mentioned undesired effect for
the MEAN CM. Specifically, varying the value of
τw we can stretch the interval in which the tran-
sition between the fully automatic SMT system
and the conventional IMT system is produced, al-
lowing us to obtain smother transitions. Figure 2
shows WSR and BLEU scores for different val-
ues of the sentence classification threshold τs us-
ing τw = 0.4. We show results only for this value
of τw due to paper space limitations and because
τw = 0.4 produced the smoothest transition. Ac-
cording to Figure 2, using a sentence classification
threshold value of 0.6 we obtain a WSR reduction
of 20% relative and an almost perfect translation
quality of 87 BLEU points.

It is worth of notice that the final translations
are compared with only one reference, therefore,
the reported translation quality scores are clearly
pessimistic. Better results are expected using a
multi-reference corpus. Example 1 shows the
source sentence (src), the reference translation

(ref) and the final translation (tra) for three of the
initial fully automatically generated translations
that were classified as correct by our CMs, and
thus, were not interactively translated by the user.
The first translation (tra-1) is identical to the corre-
sponding reference translation (ref-1). The second
translation (tra-2) corresponds to a correct trans-
lation of the source sentence (src-2) that is differ-
ent from the corresponding reference (ref-2). Fi-
nally, the third translation (tra-3) is an example of
a slightly incorrect translation.

4 Concluding Remarks

In this paper, we have presented a novel proposal
that introduces sentence CMs into an IMT system
to reduce user effort. Our proposal entails a mod-
ification of the user-machine interaction protocol
that allows to achieve a balance between the user
effort and the final translation error.

We have carried out experimentation using two
different sentence CMs. Varying the value of
the sentence classification threshold, we can range
from a fully automatic SMT system to a conven-
tional IMT system. Empirical results show that
our proposal allows to obtain almost perfect trans-
lations while significantly reducing user effort.

Future research aims at the investigation of im-
proved CMs to be integrated in our IMT system.

Acknowledgments

Work supported by the EC (FEDER/FSE) and
the Spanish MEC/MICINN under the MIPRCV
“Consolider Ingenio 2010” program (CSD2007-
00018), the iTransDoc (TIN2006-15694-CO2-01)
and iTrans2 (TIN2009-14511) projects and the
FPU scholarship AP2006-00691. Also supported
by the Spanish MITyC under the erudito.com
(TSI-020110-2009-439) project and by the Gener-
alitat Valenciana under grant Prometeo/2009/014.

176



References

S. Barrachina, O. Bender, F. Casacuberta, J. Civera,
E. Cubel, S. Khadivi, A. Lagarda, H. Ney, J. Tomás,
and E. Vidal. 2009. Statistical approaches to
computer-assisted translation. Computational Lin-
guistics, 35(1):3–28.

J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur,
C. Goutte, A. Kulesza, A. Sanchis, and N. Ueffing.
2003. Confidence estimation for machine transla-
tion.

J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur,
C. Goutte, A. Kuesza, A. Sanchis, and N. Ueffing.
2004. Confidence estimation for machine transla-
tion. In Proc. COLING, page 315.

P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and
R. L. Mercer. 1993. The Mathematics of Statistical
Machine Translation: Parameter Estimation. Com-
putational Linguistics, 19(2):263–311.

J. Esteban, J. Lorenzo, A. Valderrábanos, and G. La-
palme. 2004. Transtype2: an innovative computer-
assisted translation system. In Proc. ACL, page 1.

G. Foster, P. Isabelle, and P. Plamondon. 1997. Target-
text mediated interactive machine translation. Ma-
chine Translation, 12:12–175.

S. Gandrabur and G. Foster. 2003. Confidence esti-
mation for text prediction. In Proc. CoNLL, pages
315–321.

P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open source toolkit

for statistical machine translation. In Proc. ACL,
pages 177–180.

P. Langlais, G. Lapalme, and M. Loranger. 2002.
Transtype: Development-evaluation cycles to boost
translator’s productivity. Machine Translation,
15(4):77–98.

F. J. Och. 2003. Minimum error rate training in statis-
tical machine translation. In Proc. ACL, pages 160–
167.

D. Ortiz, I. Garcı́a-Varea, and F. Casacuberta. 2005.
Thot: a toolkit to train phrase-based statistical trans-
lation models. In Proc. MT Summit, pages 141–148.

K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
BLEU: a method for automatic evaluation of MT.
In Proc. ACL, pages 311–318.

G. Sanchis-Trilles, D. Ortiz-Martı́nez, J. Civera,
F. Casacuberta, E. Vidal, and H. Hoang. 2008. Im-
proving interactive machine translation via mouse
actions. In Proc. EMNLP, pages 25–27.

N. Ueffing and H. Ney. 2005. Application of word-
level confidence measures in interactive statistical
machine translation. In Proc. EAMT, pages 262–
270.

N. Ueffing and H. Ney. 2007. Word-level confidence
estimation for machine translation. Comput. Lin-
guist., 33(1):9–40.

N. Ueffing, F.J. Och, and H. Ney. 2002. Generation
of word graphs in statistical machine translation. In
Proc. EMNLP, pages 156–163.

177


