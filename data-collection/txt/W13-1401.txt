










































A Tale of Two Cultures: Bringing Literary Analysis and Computational Linguistics Together


Proceedings of the Second Workshop on Computational Linguistics for Literature, pages 1–8,
Atlanta, Georgia, June 14, 2013. c©2013 Association for Computational Linguistics

A Tale of Two Cultures:
Bringing Literary Analysis and Computational Linguistics Together

Adam Hammond
Dept of English

University of Toronto
adam.hammond@utoronto.ca

Julian Brooke
Dept of Computer Science

University of Toronto
jbrooke@cs.toronto.edu

Graeme Hirst
Dept of Computer Science

University of Toronto
gh@cs.toronto.edu

Abstract

There are cultural barriers to collaborative effort
between literary scholars and computational lin-
guists. In this work, we discuss some of these
problems in the context of our ongoing research
project, an exploration of free indirect discourse
in Virginia Woolf’s To The Lighthouse, ulti-
mately arguing that the advantages of taking
each field out of its “comfort zone” justifies the
inherent difficulties.

1 Introduction

Within the field of English literature, there is a grow-
ing interest in applying computational techniques, as
evidenced by the growth of the Digital Humanities
(Siemens et al., 2004). At the same time, a subfield
in Computational Linguistics that addresses a range
of problems in the genre of literature is gaining mo-
mentum (Mani, 2013). Nevertheless, there are sig-
nificant barriers to true collaborative work between
literary and computational researchers. In this pa-
per, we discuss this divide, starting from the classic
rift between the two cultures of the humanities and
the sciences (Snow, 1959) and then focusing in on a
single aspect, the attitude of the two fields towards
ambiguity. Next, we introduce our ongoing collab-
orative project which is an effort to bridge this gap;
in particular, our annotation of Virginia Woolf’s To
the Lighthouse for free indirect discourse, i.e. mix-
tures of objective narration and subjective speech,
requires a careful eye to literary detail, and, while
novel, interacts in interesting ways with established
areas of Computational Linguistics.

2 Background

2.1 The “Two Cultures” Problem
Since the publication of C. P. Snow’s influential
The Two Cultures and the Scientific Revolution
(Snow, 1959), the phrase “the two cultures” been
used to signify the rift—perceived and generally
lamented—between scientific and humanities intel-
lectual cultures. The problem, of course, is the igno-
rance of each culture with regard to the methods and
assumptions of the other, and the resulting impos-
sibility of genuine dialogue between them, prevent-
ing them from working together to solve important
problems. Many scholars describing the recent rise
of the Digital Humanities—the area of research and
teaching concerned with the intersection of comput-
ing and humanities disciplines—have argued that it
effects a reconciliation of the two alienated spheres,
bringing scientific methodology to bear on problems
within the humanities, many of which had previ-
ously been addressed in a less-than-rigorous manner
(Hockey, 2004).

From within the discipline of English literature,
however, the application of computational meth-
ods to literary analysis has frequently been—and
continues to be—a matter of considerable contro-
versy (Hoover, 2007; Flanders, 2009). This con-
troversy arises from the perception of many tradi-
tional humanists that computational analysis, which
aims to resolve dilemmas, seeking singular truth
and hard-and-fast answers, is incompatible with the
aims of humanistic research, which is often focused
on opening up questions for debate rather than re-
solving them decisively, and often premised on the

1



idea that there are no right answers, only well- and
poorly-supported arguments. Critics have responded
to these views by arguing that the best computational
literary analysis participates in this project of open-
ing up meaning, arguing that it is not a rejection of
literary reading but rather a method for carrying it
out more efficiently and extending it to more texts
(Ramsay, 2007), and that computational modelling,
even when unsuccessful, allows for the application
of the scientific method and thus carries the poten-
tial for intellectual advancement not possible with
purely anecdotal evidence (McCarty, 2005). Despite
such counter-arguments, however, the fear remains
widespread among traditional literary scholars that
the rise of computational analysis will entail the loss
of certain sacred assumptions of humanistic inquiry.

2.2 Ambiguity Across the “Cultures”
We argue, though, that these fears are not without
basis, particularly when one considers the very dif-
ferent approaches to the question of ambiguity in
the two specific disciplines involved in our project:
English Literature and Computational Linguistics.
Here, the rift of the two cultures remains evident.

A major focus of literary scholarship since the
early twentieth century has been the semantic mul-
tiplicity of literary language. Such scholarship has
argued that literature, distinct from other forms of
discourse, may be deliberately ambiguous or poly-
semous and that literary analysis, distinct from other
analytic schools, should thus aim not to resolve am-
biguity but to describe and explore it. This was a
central insight of the early twentieth-century school,
the New Criticism, advanced in such works as
William Empson’s Seven Types of Ambiguity (Emp-
son, 1930) and Cleanth Brooks’s The Well Wrought
Urn (Brooks, 1947), which presented ambiguity and
paradox not as faults of style but as important po-
etic devices. New Criticism laid out a method of
literary analysis centred on the explication of the
complex tensions created by ambiguity and para-
dox, without any effort to resolve them. Also in
the first half of the twentieth century, but indepen-
dently, the Russian critic Mikhail Bakhtin developed
his theory of dialogism, which valorized “double-
voiced” or polyphonic works that introduce multi-
ple, competing perspectives—particularly voices—
that present conflicting ideologies (Bakhtin, 1981).

Bakhtin, who wrote his seminal work “Discourse in
the Novel” under a Stalinist sentence of exile, par-
ticularly valued works that enacted the free compe-
tition of ideologically opposed voices. In a simi-
lar spirit, but independently of Bakhtin, the German
critic Erich Auerbach described the “multi-personal
representation of consciousness”, a narrative tech-
nique in which the writer, typically the narrator of
objective facts, is pushed entirely into the back-
ground and the story proceeds by reflecting the in-
dividual consciousnesses of the characters; Auer-
bach argued that this was a defining quality of mod-
ernist (early twentieth-century) literature (Auerbach,
1953). In the second half of the twentieth century,
this critical emphasis on ambiguity and paradox de-
veloped in an extreme form into the school of de-
constructive criticism, which held a theory of the
linguistic sign according to which determinate lin-
guistic meaning is considered logically impossible.
Deconstructive literary analysis proceeds by seeking
out internal contradictions in literary texts to support
its theory of infinitely ambiguous signification.

In Computational Linguistics, by contrast, ambi-
guity is almost uniformly treated as a problem to be
solved; the focus is on disambiguation, with the as-
sumption that one true, correct interpretation exists.
In the sphere of annotation, for instance, there is
an expectation that agreement between annotators,
as measured by statistics such as kappa (Di Euge-
nio and Glass, 2004), reach levels (generally 0.67 or
higher) where disagreements can be reasonably dis-
missed as noise; the implicit assumption here is that
subjectivity is something to be minimized. The chal-
lenge of dealing with subjectivity in CL has been
noted (Alm, 2011), and indeed there are rare exam-
ples in the field where multiple interpretations have
been considered during evaluations—for instance,
work in lexical cohesion (Morris and Hirst, 2005)
and in using annotator disagreements as an indicator
that two words are of similar orientation (Taboada
et al., 2011)—but they are the exception. Work in
CL focused on literary texts tends towards aspects
of the texts which readers would not find particu-
larly ambiguous, for example identifying major nar-
rative threads (Wallace, 2012) or distinguishing au-
thor gender (Luyckx et al., 2006).

2



3 A Collaborative Research Agenda

The obvious solution to the problem of the “two
cultures”—and one that has often been proposed
(Friedlander, 2009)—is interdisciplinary collabora-
tion. But while there are many computational lin-
guists working in literary topics such as genre,
and many literary scholars performing computa-
tional analysis of literature, genuine collaboration
between the disciplines remains quite rare. Over the
past two years, we have undertaken two collabora-
tive projects—one mostly complete, one ongoing—
which aim at such genuine collaboration, and in so
doing seek to bridge the real rift between scientific
and humanities cultures.1 Each of these projects
is multi-faceted, seeking (a) to produce meaningful
research within both disciplines of Computational
Linguistics and English Literature; (b) to provide
educational experience which broadens the disci-
plinary horizons of the undergraduate students in-
volved in the projects; and (c) to provide a model
of collaborative research that will spur further such
“culture-spanning” projects.

Each of our projects was launched in the context
of a course entitled “The Digital Text” offered by the
Department of English at the University of Toronto.
The first author, whose background is in English Lit-
erature, is instructor of the course, while the sec-
ond author, a graduate student in Computer Science,
was assigned as a teaching assistant. Working to-
gether with the third author, we have designed these
projects collaboratively.

The first project, which we call “He Do the
Police in Different Voices”,2 was carried out in
2011–12 (Hammond, 2013). Focused on a “multi-
personal” poem, The Waste Land (1922) by T.S.
Eliot, it encompassed each of the three aspects of
our projects outlined above; in particular, it was mo-
tivated by a research question of interest to both dis-
ciplines: could we identify the points in The Waste
Land where the style changes, where one “voice”
gives way to another? A computational approach

1In addition, the third author was part of a separate collabo-
rative project between our departments (Le et al., 2011), though
the aim of that project was not literary analysis.

2This is a reference to Eliot’s working title for The Waste
Land, which in itself is a reference to a talented storyteller in
Our Mutual Friend by Charles Dickens; another Dickens novel
is alluded to in the title of this paper.

promised to bring added rigor as well as a degree
of objectivity to this question, which humanities
methods had proven unable to resolve in almost a
century of debate. Both because poetry is dense
in signification, and because the multiple voices in
The Waste Land are a deliberate effect achieved by
a single author rather than a disguised piecing to-
gether of the works of multiple authors, the ques-
tion provided a meaningful challenge to the com-
putational approach, an unsupervised vector-space
model which first segments by identifying points
of stylistic change (Brooke et al., 2012) and then
clusters the resulting segments together into voices
(Brooke et al., 2013).

This research project was tightly integrated into
the curriculum of “The Digital Text”. Students were
instructed in the use of the Text Encoding Initiative
(TEI) XML guidelines,3 and each of the students
provided one annotation related to voice as part of
a marked assignment. Students also participated in
an online poll in which they indicated every instance
in which they perceived a vocal switch in the poem,
and their responses were used in the construction of
a gold standard for the evaluation of our computa-
tional approach.

Once they were complete, we developed our re-
sults into a publicly accessible website.4 This web-
site promises to encourage collaboration between
literary scholars and computational linguists by ex-
plaining the project and our results in language ac-
cessible to both, and by producing a new digital edi-
tion of the poem based on our findings. Human and
computer readings of the poem are presented side-
by-side on the website, to demonstrate that each in-
terprets the poem in different ways, but that neither
of these methods is absolutely valid. Rather, we en-
courage website visitors to decide for themselves
where they believe that the vocal switches occur,
and we provide an interactive interface for divid-
ing the poem up according to their own interpreta-
tion. In addition to serving as a model of collabora-
tion between English Literature and Computational
Linguistics—and also serving as a teaching tool for
instructors of The Waste Land at any level—the site
is thus useful to us as a source of further data.

3http://www.tei-c.org/Guidelines/
4http://www.hedothepolice.org

3



4 The “Brown Stocking” Project

4.1 Free Indirect Discourse in To the
Lighthouse

Our second, ongoing project, “The Brown Stock-
ing”, focuses on a literary text deliberately chosen
for its deeply ambiguous, polysemous, dialogic na-
ture: Virginia Woolf’s (1927) To the Lighthouse
(TTL). Woolf’s novel was produced at the same time
that critical theories of ambiguity and polyvocality
were being developed, and indeed was taken as a
central example by many critics. Our project takes
its title from the final chapter of Erich Auerbach’s
Mimesis, in which Auerbach presents TTL as the
representative text of modernist literature’s “mul-
tipersonal representation of consciousness” (Auer-
bach, 1953). For Auerbach, there are two prin-
cipal distinguishing features in Woolf’s narrative
style. The first is the tendency, already noted, to “re-
flect” incidents through the subjective perspectives
of characters rather than presenting them from the
objective viewpoint of the author; thus TTL becomes
a work in which there is more than one order and in-
terpretation. Woolf’s technique not only introduces
multiple interpretations, however, but also blurs the
transitions between individual perspectives, making
it difficult to know in many instances who is speak-
ing or thinking.

Woolf achieves this double effect—multiple sub-
jective impressions combined with obscuring of the
lines separating them from the narrator and from one
another—chiefly through the narrative technique of
free indirect discourse (also known as free indirect
style). Whereas direct discourse reports the actual
words or thoughts of a character, and indirect dis-
course summarizes the thoughts or words of a char-
acter in the words of the entity reporting them, free
indirect discourse (FID) is a mixture of narrative and
direct discourse (Abrams, 1999). As in indirect dis-
course, the narrator employs third-person pronouns,
but unlike indirect discourse, the narrator includes
words and expressions that indicate subjective or
personalized aspects clearly distinct from the narra-
tor’s style. For example, in the opening sentences of
TTL:

“Yes, of course, if it’s fine tomorrow,” said Mrs.
Ramsay. “But you’ll have to be up with the
lark,” she added. To her son these words con-

veyed an extraordinary joy, as if it were settled,
the expedition were bound to take place, and
the wonder to which he had looked forward, for
years and years it seemed, was, after a night’s
darkness and a day’s sail, within touch.

we are presented with two spans of objective nar-
ration (said Mrs. Ramsay and she added) and two
passages of direct discourse, in which the narrator
introduces the actual words of Mrs. Ramsay (“Yes,
of course, if it’s fine tomorrow” and “But you’ll have
to be up with the lark”). The rest of the passage is
presented in FID, mixing together the voices of the
narrator, Mrs. Ramsay, and her son James: while the
use of third-person pronouns and the past tense and
clearly indicates the voice of the narrator, phrases
such as for years and years it seemed clearly present
a subjective perspective.

In FID’s mixing of voices, an element of uncer-
tainty is inevitably present. While we can be con-
fident of the identity of the voice speaking certain
words, it remains unclear whether other words be-
long to the narrator or a character; in this case, it
is not clear whether for years and years it seemed
presents James’s actual thoughts, Mrs. Ramsay’s
summary of her son’s thoughts, the narrator’s sum-
mary of James’s thoughts, the narrator’s summary
of Mrs. Ramsay’s summary of James’s thoughts, etc.
Abrams (1999) emphasizes uncertainty as a defining
trait of FID: the term “refers to the way, in many nar-
ratives, that the reports of what a character says and
thinks shift in pronouns, adverbs, and grammatical
mode, as we move—or sometimes hover—between
the direct narrated reproductions of these events as
they occur to the character and the indirect repre-
sentation of such events by the narrator”. FID, with
its uncertain “hovering”, is used throughout TTL;
it is the principal technical means by which Woolf
produces ambiguity, dialogism, and polysemy in the
text. It is thus the central focus of our project.

In Literary Studies, Toolan (2008) was perhaps
the first to discuss the possibility of automatic recog-
nition of FID, but his work was limited to a very
small, very informal experiment using a few a pri-
ori features, with no implementation or quantita-
tive analysis of the results. Though we are not
aware of work in Computational Linguistics that
deals with this kind of subjectivity in literature—
FID is included in the narrative annotation schema

4



of Mani (2013), but it is not given any particular
attention within that framework—there are obvious
connections with sentence-level subjectivity analy-
sis (Wilson et al., 2005) and various other stylis-
tic tasks, including authorship profiling (Argamon
et al., 2007). Since the subjective nature of these
passages is often expressed through specific lexical
choice, it would be interesting to see if sentiment
dictionaries (Taboada et al., 2011) or other stylistic
lexical resources such as dictionaries of lexical for-
mality (Brooke et al., 2010) could be useful.

4.2 Our Approach
Our project is proceeding in four stages: an initial
round of student annotation, a second round of stu-
dent annotation, computational analysis of these an-
notations, and the development of a project website.
In the first stage, we had 160 students mark up a pas-
sage of between 100–150 words in accordance with
TEI guidelines. Students were instructed to use the
TEI said element to enclose any instance of char-
acter speech, to identify the character whose speech
is being introduced, and to classify each of these in-
stances as either direct, indirect, or free indirect dis-
course and as either spoken aloud or thought silently.
Because there are often several valid ways of inter-
preting a given passage, and because we are inter-
ested in how different students respond to the same
passage, each 100–150 word span was assigned to
three or four students. This first round of annotation
focused only on the first four chapters of TTL. Raw
average agreement of the various annotations at the
level of the word was slightly less than 70%,5 and
though we hope to do better in our second round,
levels of agreement typically required are likely to
be beyond our reach due to the nature of the task.
For example, all four sudents responsible for the
passage cited above agreed on the tagging of the first
two sentences; however, two students read the third
sentence as FID mixing the voices of the narrator
and Mrs. Ramsay, and two read it as FID mixing
the voice of the narrator and James. Though they
disagree, these are both valid interpretations of the

5Since each passage was tagged by a different set of stu-
dents, we cannot apply traditional kappa measures. Raw agree-
ment overestimates success, since unlike kappa it does not
discount random agreement, which in this case varies widely
across the different kinds of annotation.

passage.
In the second round of annotation, with 160 dif-

ferent student annotators assigned slightly longer
spans of 200–300 words, we are focusing on the
final seven chapters of TTL. We have made sev-
eral minor changes to our annotation guidelines, and
two significant changes. First, we now ask that in
every span of text which students identify as FID,
they explicitly identify the words that they regard
as clearly coming from the subjective perspective
of the character. We believe this will help students
make a valid, defensible annotation, and it may also
help with the computational analysis to follow. Sec-
ond, we are also allowing embedded tags, for in-
stances of direct or indirect discourse within spans
of FID, which were confusing to students in the ini-
tial round. For instance, students would now be able
to tag the above-cited passage of as a span of FID
mixing the narrator’s and Mrs. Ramsay’s words, in-
side of which Mrs. Ramsay introduces an indirect-
discourse rendering of her son’s thoughts. Moving
from a flat to a recursive representation will natu-
rally result in additional complexity, but we believe
it is necessary to capture what is happening in the
text.

Once this second round of tagging is complete, we
will begin our computational analysis. The aim is to
see whether we can use supervised machine learn-
ing to replicate the way that second-year students
enrolled in a rigorous English literature program re-
spond to a highly complex text such as TTL. We
are interested to see whether the subjective, messy
data of the students can be used to train a useful
model, even if it is inadequate as a gold standard.
If successful, this algorithm could be deployed on
the remaining, untagged sections of TTL (i.e. ev-
erything between the first four and last seven chap-
ters) and produce meaningful readings of the text.
It would proceed by (a) identifying passages of FID
(that is, passages in which it is unclear whether a
particular word belongs to the narrator or a char-
acter); (b) making an interpretation of that passage
(hypothesizing as to which particular voices are be-
ing mixed); and (c) judging the likely validity of
this interpretation. It would seek not only to identify
spans of vocal ambiguity, but also to describe them,
as far as possible. It would thus not aim strictly
at disambiguation—at producing a right-or-wrong

5



reading of the text—but rather at producing the best
possible interpretation. The readings thus generated
could then be reviewed by an independent expert as
a form of evaluation.

Finally, we will develop an interactive website for
the project. It will describe the background and aims
of the project, present the results from the first three
stages of the project, and also include an interface
allowing visitors to the site to annotate the text for
the same features as the students (via a Javascript in-
terface, i.e. without having to manipulate the XML
markup directly). This will provide further annota-
tion data for our project, as well as giving instruc-
tors in English Literature and Digital Humanities a
resource to use in their teaching.

5 Discussion

We believe our approach has numerous benefits on
both sides of the divide. From a research perspec-
tive, the inter-disciplinary approach forces partici-
pants from both English Literature and Computa-
tional Linguistics to reconsider some of their funda-
mental disciplinary assumptions. The project takes
humanities literary scholarship out of its “comfort
zone” by introducing alien and unfamiliar method-
ologies such as machine learning, as well as by its
basic premise that FID—by definition, a moment
of uncertainty where the question of who is speak-
ing is unresolved—can be detected automatically.
Even though many of these problems can be linked
with classic Computational Linguistics research ar-
eas, the project likewise takes Computational Lin-
guistics out of its comfort zone by seeking not to
resolve ambiguity but rather to identify it and, as far
as possible, describe it. It presents an opportunity
for a computational approach to take into account a
primary insight of twentieth-century literary schol-
arship: that ambiguity and subjectivity are often de-
sirable, intentional qualities of literary language, not
problems to be solved. It promises literary scholar-
ship a method for extending time-consuming, labo-
rious human literary readings very rapidly to a vast
number of literary texts, the possible applications of
which are unclear at this early stage, but are surely
great.

While many current major projects in computer-
assisted literary analysis operate on a “big-data”

model, drawing conclusions from analysis of vast
numbers of lightly annotated texts, we see advan-
tages in our own method of beginning with a few
heavily-annotated texts and working outward. Tra-
ditional literary scholars often object that “big-data”
readings take little or no account of subjective, hu-
man responses to literary texts; likewise, they find
the broad conclusions of such projects (that the nine-
teenth century novel moves from telling to show-
ing (Heuser and Le-Khac, 2012); that Austen is
more influential than Dickens (Jockers, 2012)) dif-
ficult to test (or reconcile) with traditional literary
scholarship. The specific method we are pursuing—
taking a great number of individual human read-
ings of a complex literary text and using them as
the basis for developing a general understanding of
how FID works—promises to move literary analysis
beyond merely “subjective” readings without, how-
ever, denying the basis of all literary reading in indi-
vidual, subjective responses. Our method indeed ap-
proaches the condition of a multi-voiced modernist
literary work like TTL, in which, as Erich Auerbach
perceived, “overlapping, complementing, and con-
tradiction yield something that we might call a syn-
thesized cosmic view”. We too are building our syn-
thetic understanding out of the diverse, often contra-
dictory, responses of individual human readers.

Developing this project in an educational
context—basing our project on readings developed
by students as part of marked assignments for
“The Digital Text”—is likewise beneficial to both
cultures. It forces humanities undergraduates
out of their comfort zone by asking them to turn
their individual close readings of the text into an
explicit, machine-readable representation (in this
case, XML). Recognizing the importance of a
sharable language for expressing literary features
in machine-readable way, we have employed the
standard TEI guidelines mark-up with as few
customizations as possible, rather than developing
our own annotation language from the ground up.
The assignment asks students, however, to reflect
critically on whether such explicit languages can
ever adequately capture the polyvalent structures
of meaning in literary texts; that is, whether there
will always necessarily be possibilities that can’t
be captured in the tag set, and whether, as such, an
algorithmic process can ever really “read” literature

6



in a useful way. At the same time, this method
has potentially great benefits to the development
of such algorithmic readings, precisely by making
available machine-readable approximations of how
readers belonging to another “culture”—humanities
undergraduates—respond to a challenging literary
text. Such annotations would not be possible from
a pool of annotators trained in the sciences, but
could only come from students of the humanities
with a basic understanding of XML. We do not
believe, for example, workers on Amazon Mechan-
ical Turk could reliably be used for this purpose,
though it might be interesting to compare our
‘studentsourcing’ with traditional crowdsourcing
techniques.

Our approach also faces several important chal-
lenges. Certainly the largest is whether an algo-
rithmic criticism can be developed that could come
to terms with ambiguity. The discipline of literary
studies has long taught its students to accept what
the poet John Keats called “negative capability, that
is, when a man is capable of being in uncertainties,
mysteries, doubts, without any irritable searching af-
ter fact and reason” (Keats, 2002). Computational
analysis may simply be too fundamentally premised
on “irritable searching after fact and reason” to be
capable of “existing in uncertainty” in the manner of
many human literary readers. Even if we are able to
develop a successful algorithmic method of detect-
ing FID in Woolf, this method may not prove appli-
cable to other literary texts, which may employ the
device in highly individual manners; TTL may prove
simply too complex—and employ too much FID—
to serve as a representative sample text. At a more
practical level, even trained literature students do not
produce perfect annotations: they make errors both
in XML syntax and in their literary interpretation of
TTL, a text that proves elusive even for some spe-
cialists. Since we do not want our algorithm to base
its readings on invalid student readings (for instance,
readings that attribute speech to a character clearly
not involved in the scene), we face the challenge of
weeding out bad student readings—and we will face
the same challenge once readings begin to be sub-
mitted by visitors to the website. These diverse read-
ings do, however, also present an interesting possi-
bility, which we did not originally foresee: the de-
velopment of a reader-response “map” showing how

human readers actually interpret (and in many cases
misinterpret) complex modernist texts like TTL.

6 Conclusion

Despite the philosophical and technical chal-
lenges that face researchers in this growing multi-
disciplinary area, we are increasingly optimistic that
collaboration between computational and literary re-
searchers is not only possible, but highly desirable.
Interesting phenomena such as FID, this surprising
melding of objective and personal perspective that
is the subject of the current project, requires experts
in both fields working together to identify, annotate,
and ultimately model. Though fully resolving the
rift between our two cultures is not, perhaps, a feasi-
ble goal, we argue that even this early and tentative
collaboration has demonstrated the potential benefits
on both sides.

Acknowledgements

This work was financially supported by the So-
cial Sciences and Humanities Research Council of
Canada and the Natural Sciences and Engineering
Research Council of Canada.

References
M. H. Abrams. 1999. A Glossary of Literary Terms.

Harcourt Brace, Toronto, 7th edition.
Cecilia Ovesdotter Alm. 2011. Subjective natural lan-

guage problems: Motivations, applications, charac-
terizations, and implications. In Proceedings of the
49th Annual Meeting of the Association for Compu-
tational Linguistics: Human Language Technologies,
pages 107–112.

Shlomo Argamon, Casey Whitelaw, Paul Chase, Sob-
han Raj Hota, Navendu Garg, and Shlomo Levitan.
2007. Stylistic text classification using functional lex-
ical features. Journal of the American Society for In-
formation Science and Technology, 7:91–109.

Erich Auerbach. 1953. Mimesis: The Representation
of Reality in Western Literature. Princeton University
Press, Princeton, NJ.

Mikhail Mikhailovich Bakhtin. 1981. Discourse in
the novel. In Michael Holquist, editor, The Dialogic
Imagination: Four Essays, pages 259–422. Austin:
Univeristy of Texas Press.

Julian Brooke, Tong Wang, and Graeme Hirst. 2010. Au-
tomatic acquisition of lexical formality. In Proceed-

7



ings of the 23rd International Conference on Compu-
tational Linguistics (COLING ’10), Beijing.

Julian Brooke, Adam Hammond, and Graeme Hirst.
2012. Unsupervised stylistic segmentation of poetry
with change curves and extrinsic features. In Proceed-
ings of the 1st Workshop on Computational Literature
for Literature (CLFL ’12), Montreal.

Julian Brooke, Graeme Hirst, and Adam Hammond.
2013. Clustering voices in the Waste Land. In Pro-
ceedings of the 2nd Workshop on Computational Lit-
erature for Literature (CLFL ’13), Atlanta.

Cleanth Brooks. 1947. The Well Wrought Urn. Harcourt
Brace, New York.

Barbara Di Eugenio and Michael Glass. 2004. The kappa
statistic: a second look. Computational Linguistics,
30(1):95–101, March.

T.S. Eliot. 1971. The Waste Land. In The Complete
Poems and Plays, 1909–1950, pages 37–55. Harcourt
Brace Jovanovich, New York.

William Empson. 1930. Seven Types of Ambiguity.
Chatto and Windus, London.

Julia Flanders. 2009. Data and wisdom: Electronic edit-
ing and the quantification of knowledge. Literary and
Linguistic Computing, 24(1):53–62.

Amy Friedlander. 2009. Asking questions and build-
ing a research agenda for digital scholarship. Work-
ing Together or Apart: Promoting the Next Generation
of Digital Scholarship. Report of a Workshop Cospon-
sored by the Council on Library and Information Re-
sources and The National Endowment for the Human-
ities, March.

Adam Hammond. 2013. He do the police in different
voices: Looking for voices in The Waste Land. Sem-
inar: “Mapping the Fictional Voice” American Com-
parative Literature Association (ACLA).

Ryan Heuser and Long Le-Khac. 2012. A quantita-
tive literary history of 2,958 nineteenth-century British
novels: The semantic cohort method. Stanford Lit-
erary Lab Pamphlet No. 4. http://litlab.stanford.edu/
LiteraryLabPamphlet4.pdf .

Susan Hockey. 2004. The history of humanities com-
puting. In Ray Siemens, Susan Schreibman, and John
Unsworth, editors, A Companion to Digital Humani-
ties. Blackwell, Oxford.

David L. Hoover. 2007. Quantitative analysis and lit-
erary studies. In Ray Siemens and Susan Schreib-
man, editors, A Companion to Digital Literary Studies.
Blackwell, Oxford.

Matthew L. Jockers. 2012. Computing and visualiz-
ing the 19th-century literary genome. Presented at the
Digital Humanities Conference. Hamburg.

John Keats. 2002. Selected Letters. Oxford University
Press, Oxford.

Xuan Le, Ian Lancashire, Graeme Hirst, and Regina
Jokel. 2011. Longitudinal detection of dementia
through lexical and syntactic changes in writing: A
case study of three British novelists. Literary and Lin-
guistic Computing, 26(4):435–461.

Kim Luyckx, Walter Daelemans, and Edward Vanhoutte.
2006. Stylogenetics: Clustering-based stylistic analy-
sis of literary corpora. In Proceedings of the 5th In-
ternational Conference on Language Resources and
Evaluation (LREC ’06), Genoa, Italy.

Inderjeet Mani. 2013. Computational Modeling of Nar-
rative. Morgan & Claypool.

Willard McCarty. 2005. Humanities Computing. Pal-
grave Macmillan, New York.

Jane Morris and Graeme Hirst. 2005. The subjectivity
of lexical cohesion in text. In James G. Shanahan, Yan
Qu, and Janyce M. Wiebe, editors, Computing Attitude
and Affect in Text. Springer, Dordrecht, The Nether-
lands.

Stephen Ramsay. 2007. Algorithmic criticism. In Ray
Siemens and Susan Schreibman, editors, A Companion
to Digital Literary Studies. Blackwell, Oxford.

Ray Siemens, Susan Schreibman, and John Unsworth,
editors. 2004. A Companion to Digital Humanities.
Blackwell, Oxford.

C. P. Snow. 1959. The Two Cultures and the Scientific
Revolution. Cambridge University Press, New York.

Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly
Voll, and Manfred Stede. 2011. Lexicon-based meth-
ods for sentiment analysis. Computational Linguis-
tics, 37(2):267–307.

Michael Toolan. 2008. Narrative progression in the short
story: First steps in a corpus stylistic approach. Nar-
rative, 16(2):105–120.

Byron Wallace. 2012. Multiple narrative disentangle-
ment: Unraveling Infinite Jest. In Proceedings of the
2012 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1–10, Montréal,
Canada, June. Association for Computational Linguis-
tics.

Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-level
sentiment analysis. In Proceedings of the conference
on Human Language Technology and Empirical Meth-
ods in Natural Language Processing, HLT/EMNLP
’05, pages 347–354.

Virginia Woolf. 1927. To the Lighthouse. Hogarth, Lon-
don.

8


