










































Using Bilingual Information for Cross-Language Document Summarization


Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1546–1555,
Portland, Oregon, June 19-24, 2011. c©2011 Association for Computational Linguistics

Using Bilingual Information for Cross-Language Document              
Summarization 

 
 

Xiaojun Wan 
Institute of Compute Science and Technology, Peking University, Beijing 100871, China 

Key Laboratory of Computational Linguistics (Peking University), MOE, China 
wanxiaojun@icst.pku.edu.cn 

 
 

 
 

Abstract 

Cross-language document summarization is de-
fined as the task of producing a summary in a 
target language (e.g. Chinese) for a set of 
documents in a source language (e.g. English). 
Existing methods for addressing this task make 
use of either the information from the original 
documents in the source language or the infor-
mation from the translated documents in the 
target language. In this study, we propose to use 
the bilingual information from both the source 
and translated documents for this task. Two 
summarization methods (SimFusion and 
CoRank) are proposed to leverage the bilingual 
information in the graph-based ranking frame-
work for cross-language summary extraction. 
Experimental results on the DUC2001 dataset 
with manually translated reference Chinese 
summaries show the effectiveness of the pro-
posed methods.  

 

1 Introduction 
Cross-language document summarization is de-
fined as the task of producing a summary in a dif-
ferent target language for a set of documents in a 
source language (Wan et al., 2010). In this study, 
we focus on English-to-Chinese cross-language 
summarization, which aims to produce Chinese 
summaries for English document sets. The task is 
very useful in the field of multilingual information 
access. For example, it is beneficial for most Chi-
nese readers to quickly browse and understand 

English news documents or document sets by read-
ing the corresponding Chinese summaries.  

A few pilot studies have investigated the task in 
recent years and exiting methods make use of ei-
ther the information in the source language or the 
information in the target language after using ma-
chine translation. In particular, for the task of Eng-
lish-to-Chinese cross-language summarization, one 
method is to directly extract English summary sen-
tences based on English features extracted from the 
English documents, and then automatically trans-
late the English summary sentences into Chinese 
summary sentences. The other method is to auto-
matically translate the English sentences into Chi-
nese sentences, and then directly extract Chinese 
summary sentences based on Chinese features. The 
two methods make use of the information from 
only one language side.   

However, it is not very reliable to use only the 
information in one language, because the machine 
translation quality is far from satisfactory, and thus 
the translated Chinese sentences usually contain 
some errors and noises. For example, the English 
sentence “Many destroyed power lines are thought 
to be uninsured, as are trees and shrubs uprooted 
across a wide area.” is automatically translated 
into the Chinese sentence “许多破坏电源线被认
为是保险的，因为是连根拔起的树木和灌木，
在广泛的领域。” by using Google Translate1 , 
but the Chinese sentence contains a few translation 
errors. Therefore, on the one side, if we rely only 
on the English-side information to extract Chinese 
                                                           
1 http://translate.google.com/.  Note that the translation service 
is updated frequently and the current translation results may be 
different from that presented in this paper.  

1546



summary sentences, we cannot guarantee that the 
automatically translated Chinese sentences for sa-
lient English sentences are really salient when 
these sentences may contain many translation er-
rors and other noises. On the other side, if we rely 
only on the Chinese-side information to extract 
Chinese summary sentences, we cannot guarantee 
that the selected sentences are really salient be-
cause the features for sentence ranking based on 
the incorrectly translated sentences are not very 
reliable, either.  

In this study, we propose to leverage both the in-
formation in the source language and the informa-
tion in the target language for cross-language 
document summarization. In particular, we pro-
pose two graph-based summarization methods 
(SimFusion and CoRank) for using both English-
side and Chinese-side information in the task of 
English-to-Chinese cross-document summarization. 
The SimFusion method linearly fuses the English-
side similarity and the Chinese-side similarity for 
measuring Chinese sentence similarity. The 
CoRank method adopts a co-ranking algorithm to 
simultaneously rank both English sentences and 
Chinese sentences by incorporating mutual influ-
ences between them.  

We use the DUC2001 dataset with manually 
translated reference Chinese summaries for evalua-
tion. Experimental results based on the ROUGE 
metrics show the effectiveness of the proposed 
methods. Three important conclusions for this task 
are summarized below:  
1) The Chinese-side information is more benefi-

cial than the English-side information.  
2) The Chinese-side information and the Eng-

lish-side information can complement each 
other.  

3) The proposed CoRank method is more reli-
able and robust than the proposed SimFusion 
method. 

The rest of this paper is organized as follows: 
Section 2 introduces related work. In Section 3, we 
present our proposed methods. Evaluation results 
are shown in Section 4. Lastly, we conclude this 
paper in Section 5.  

2 Related Work 

2.1 General Document Summarization  
Document summarization methods can be extrac-
tion-based, abstraction-based or hybrid methods. 
We focus on extraction-based methods in this 
study, and the methods directly extract summary 
sentences from a document or document set by 
ranking the sentences in the document or document 
set.  

In the task of single document summarization, 
various features have been investigated for ranking 
sentences in a document, including term frequency, 
sentence position, cue words, stigma words, and 
topic signature (Luhn 1969; Lin and Hovy, 2000). 
Machine learning techniques have been used for 
sentence ranking (Kupiec et al., 1995; Amini and 
Gallinari, 2002). Litvak et al. (2010) present a lan-
guage-independent approach for extractive summa-
rization based on the linear optimization of several 
sentence ranking measures using a genetic algo-
rithm. In recent years, graph-based methods have 
been proposed for sentence ranking (Erkan and 
Radev, 2004; Mihalcea and Tarau, 2004). Other 
methods include mutual reinforcement principle 
(Zha 2002; Wan et al., 2007).  

In the task of multi-document summarization, 
the centroid-based method (Radev et al., 2004) 
ranks the sentences in a document set based on 
such features as cluster centroids, position and 
TFIDF. Machine Learning techniques have also 
been used for feature combining (Wong et al., 
2008).  Nenkova and Louis (2008) investigate the 
influences of input difficulty on summarization 
performance. Pitler et al. (2010) present a system-
atic assessment of several diverse classes of met-
rics designed for automatic evaluation of linguistic 
quality of multi-document summaries. Celikyilmaz 
and Hakkani-Tur (2010) formulate extractive 
summarization as a two-step learning problem by 
building a generative model for pattern discovery 
and a regression model for inference. Aker et al. 
(2010) propose an A* search algorithm to find the 
best extractive summary up to a given length, and 
they propose a discriminative training algorithm 
for directly maximizing the quality of the best 
summary. Graph-based methods have also been 
used to rank sentences for multi-document summa-
rization (Mihalcea and Tarau, 2005; Wan and 
Yang, 2008).  

1547



2.2 Cross-Lingual Document Summariza-
tion  

Several pilot studies have investigated the task of 
cross-language document summarization.  The ex-
isting methods use only the information in either 
language side. Two typical translation schemes are 
document translation or summary translation. The 
document translation scheme first translates the 
source documents into the corresponding docu-
ments in the target language, and then extracts 
summary sentences based only on the information 
on the target side. The summary translation scheme 
first extracts summary sentences from the source 
documents based only on the information on the 
source side, and then translates the summary sen-
tences into the corresponding summary sentences 
in the target language.  

For example Leuski et al. (2003) use machine 
translation for English headline generation for 
Hindi documents. Lim et al. (2004) propose to 
generate a Japanese summary by using Korean 
summarizer. Chalendar et al. (2005) focus on se-
mantic analysis and sentence generation techniques 
for cross-language summarization. Orasan and 
Chiorean (2008) propose to produce summaries 
with the MMR method from Romanian news arti-
cles and then automatically translate the summaries 
into English. Cross language query based summa-
rization has been investigated in (Pingali et al., 
2007), where the query and the documents are in 
different languages. Wan et al. (2010) adopt the 
summary translation scheme for the task of Eng-
lish-to-Chinese cross-language summarization. 
They first extract English summary sentences by 
using English-side features and the machine trans-
lation quality factor, and then automatically trans-
late the English summary into Chinese summary. 
Other related work includes multilingual summari-
zation (Lin et al., 2005; Siddharthan and McKe-
own, 2005), which aims to create summaries from 
multiple sources in multiple languages. 

3 Our Proposed Methods 
As mentioned in Section 1, existing methods rely 
only on one-side information for sentence ranking, 
which is not very reliable. In order to leveraging 
both-side information for sentence ranking, we 
propose the following two methods to incorporate 
the bilingual information in different ways.   

3.1 SimFusion 
This method uses the English-side information for 
Chinese sentence ranking in the graph-based 
framework. The sentence similarities in the two 
languages are fused in the method. In other words, 
when we compute the similarity value between two 
Chinese sentences, the similarity value between the 
corresponding two English sentences is used by 
linear fusion. Since sentence similarity evaluation 
plays a very important role in the graph-based 
ranking algorithm, this method can leverage both-
side information through similarity fusion.   

Formally, given the Chinese document set Dcn 
translated from an English document set, let 
Gcn=(Vcn, Ecn) be an undirected graph to reflect the 
relationships between the sentences in the Chinese 
document set. Vcn is the set of vertices and each 
vertex scni in Vcn represents a Chinese sentence. Ecn 
is the set of edges. Each edge ecnij in Ecn is associ-
ated with an affinity weight f(scni, scnj) between sen-
tences scni and scnj (i≠j). The weight is computed by 
linearly combining the similarity value simcosine(scni, 
scnj) between the Chinese sentences and the simi-
larity value simcosine(seni, senj) between the corre-
sponding English sentences. 

 
),()1(),(),( coscos

en
j

en
iine

cn
j

cn
iine

cn
j

cn
i sssimsssimssf ⋅−+⋅= λλ

 
where senj and seni are the source English sentences 
for scnj and scni. λ∈[0, 1] is a parameter to control 
the relative contributions of the two similarity val-
ues. The similarity values simcosine(scni, scnj) and 
simcosine(seni, senj) are computed by using the stan-
dard cosine measure. The weight for each term is 
computed based on the TFIDF formula. For Chi-
nese similarity computation, Chinese word seg-
mentation is performed. Here, we have f(scni, 
scnj)=f(scnj, scni) and let f(scni, scni)=0 to avoid self 
transition. We use an affinity matrix Mcn to de-
scribe Gcn with each entry corresponding to the 
weight of an edge in the graph. Mcn=(Mcnij)|Vcn|×|Vcn| 
is defined as Mcnij=f(scni,scnj). Then Mcn is normal-
ized to cnM~  to make the sum of each row equal to 1. 

Based on matrix cnM~ , the saliency score Info-
Score(scni) for sentence scni can be deduced from 
those of all other sentences linked with it and it can 
be formulated in a recursive form as in the PageR-
ank algorithm: 

1548



∑
≠

−+⋅⋅=
iall j

cn
ji

cn
j

cn
i n

MsInfoScoresInfoScore )1(~)()( μμ  

where n is the sentence number, i.e. n= |Vcn|. μ is 
the damping factor usually set to 0.85, as in the 
PageRank algorithm.  

For numerical computation of the saliency 
scores, we can iteratively run the above equation 
until convergence. 

For multi-document summarization, some sen-
tences are highly overlapping with each other, and 
thus we apply the same greedy algorithm in Wan et 
al. (2006) to penalize the sentences highly overlap-
ping with other highly scored sentences, and fi-
nally the salient and novel Chinese sentences are 
directly selected as summary sentences.  

3.2 CoRank 
This method leverages both the English-side in-
formation and the Chinese-side information in a 
co-ranking way. The source English sentences and 
the translated Chinese sentences are simultane-
ously ranked in a unified graph-based algorithm. 
The saliency of each English sentence relies not 
only on the English sentences linked with it, but 
also on the Chinese sentences linked with it. Simi-
larly, the saliency of each Chinese sentence relies 
not only on the Chinese sentences linked with it, 
but also on the English sentences linked with it. 
More specifically, the proposed method is based on 
the following assumptions: 

Assumption 1: A Chinese sentence would be 
salient if it is heavily linked with other salient Chi-
nese sentences; and an English sentence would be 
salient if it is heavily linked with other salient Eng-
lish sentences. 

Assumption 2: A Chinese sentence would be 
salient if it is heavily linked with salient English 
sentences; and an English sentence would be sali-
ent if it is heavily linked with salient Chinese sen-
tences. 

The first assumption is similar to PageRank 
which makes use of mutual “recommendations” 
between the sentences in the same language to rank 
sentences. The second assumption is similar to 
HITS if the English sentences and the Chinese sen-
tences are considered as authorities and hubs, re-
spectively. In other words, the proposed method 
aims to fuse the ideas of PageRank and HITS in a 
unified framework. The mutual influences between 

the Chinese sentences and the English sentences 
are incorporated in the method. 
   Figure 1 gives the graph representation for the 
method. Three kinds of relationships are exploited: 
the CN-CN relationships between Chinese sen-
tences, the EN-EN relationships between English 
sentences, and the EN-CN relationships between 
English sentences and Chinese sentences.  

Formally, given an English document set Den and 
the translated Chinese document set Dcn, let G=(Ven, 
Vcn, Een, Ecn, Eencn) be an undirected graph to reflect 
all the three kinds of relationships between the sen-
tences in the two document sets. Ven ={seni | 1≤i≤n} 
is the set of English sentences. Vcn={scni | 1≤i≤n} is 
the set of Chinese sentences. scni is the correspond-
ing Chinese sentence translated from seni.  n is the 
number of the sentences.  Een is the edge set to re-
flect the relationships between the English sen-
tences. Ecn is the edge set to reflect the 
relationships between the Chinese sentences. Eencn 
is the edge set to reflect the relationships between 
the English sentences and the Chinese sentences. 
Based on the graph representation, we compute the 
following three affinity matrices to reflect the three 
kinds of sentence relationships: 
 

 
Figure 1. The three kinds of sentence relationships 

 
1) Mcn=(Mcnij)n×n:  This affinity matrix aims to 

reflect the relationships between the Chinese sen-
tences. Each entry in the matrix corresponds to the 
cosine similarity between the two Chinese sen-
tences.  

⎪⎩

⎪
⎨
⎧ ≠

=
 otherwise,         

j,  if isssim
M

cn
j

cn
iinecn

ij 0

),(cos  

English Sentences 

CN-CN

EN-EN

EN-CN

Chinese sentences 

1549



 Then Mcn is normalized to cnM~  to make the 
sum of each row equal to 1. 

2) Men=(Meni,j)n×n: This affinity matrix aims to 
reflect the relationships between the English sen-
tences. Each entry in the matrix corresponds to the 
cosine similarity between the two English sen-
tences.  

⎪⎩

⎪
⎨
⎧ ≠

=
 otherwise,         

j,  if isssim
M

en
j

en
iineen

ij 0

),(cos  

Then Men is normalized to enM~  to make the 
sum of each row equal to 1. 

3) Mencn=(Mencnij)n×n: This affinity matrix aims to 
reflect the relationships between the English sen-
tences and the Chinese sentences. Each entry   
Mencnij in the matrix corresponds to the similarity 
between the English sentence seni and the Chinese 
sentence scnj. It is hard to directly compute the 
similarity between the sentences in different lan-
guages. In this study, the similarity value is com-
puted by fusing the following two similarity values: 
the cosine similarity between the sentence seni and 
the corresponding source English sentence senj for 
scnj, and the cosine similarity between the corre-
sponding translated Chinese sentence scni for seni 
and the sentence scnj. We use the geometric mean 
of the two values as the affinity weight.  

 

),(),( coscos
cn
j

cn
iine

en
j

en
iine

encn
ij sssimsssimM ×=

 
Note that we have Mencnij=Mencnji and 

Mencn=(Mencn)T. Then Mencn is normalized to encnM~  
to make the sum of each row equal to 1.  

We use two column vectors u=[u(scni)]n×1 and v 
=[v(senj)]n×1 to denote the saliency scores of the 
Chinese sentences and the English sentences, re-
spectively. Based on the three kinds of relation-
ships, we can get the following four assumptions: 

∑∝ j cnjcnjicni suMsu )(
~)(  

∑∝ i enienijenj svMsv )(
~)(  

∑∝ j enjencnjicni svMsu )(
~)(  

∑∝ i cniencnijenj suMsv )(
~)(  

After fusing the above equations, we can obtain 
the following iterative forms: 

∑∑ += j enjencnjij cnjcnjicni svMβsuMαsu )(
~)(~)(  

∑∑ += i cniencniji enienijenj suMβsvMαsv )(
~)(~)(  

And the matrix form is: 
vMuMu cn TencnT βα )~()~( +=  
uMvMv en TencnT βα )~()~( +=  

where α and β specify the relative contributions to 
the final saliency scores from the information in 
the same language and the information in the other 
language and we have α+β=1.  

For numerical computation of the saliency 
scores, we can iteratively run the two equations 
until convergence. Usually the convergence of the 
iteration algorithm is achieved when the difference 
between the scores computed at two successive 
iterations for any sentences and words falls below 
a given threshold. In order to guarantee the con-
vergence of the iterative form, u and v are normal-
ized after each iteration. 

After we get the saliency scores u for the Chi-
nese sentences, we apply the same greedy algo-
rithm for redundancy removing. Finally, a few 
highly ranked sentences are selected as summary 
sentences.  

4 Experimental Evaluation 

4.1 Evaluation Setup 
There is no benchmark dataset for English-to-
Chinese cross-language document summarization, 
so we built our evaluation dataset based on the 
DUC2001 dataset by manually translating the ref-
erence summaries. 

DUC2001 provided 30 English document sets 
for generic multi-document summarization. The 
average document number per document set was 
10. The sentences in each article have been sepa-
rated and the sentence information has been stored 
into files. Three or two generic reference English 
summaries were provided by NIST annotators for 
each document set. Three graduate students were 
employed to manually translate the reference Eng-
lish summaries into reference Chinese summaries. 
Each student manually translated one third of the 
reference summaries. It was much easier and more 
reliable to provide the reference Chinese summa-
ries by manual translation than by manual summa-
rization. 

1550



 ROUGE-2
Average_F

ROUGE-W 
Average_F

ROUGE-L 
Average_F

ROUGE-SU4 
Average_F 

Baseline(EN) 0.03723 0.05566 0.13259 0.07177 
Baseline(CN) 0.03805 0.05886 0.13871 0.07474 

SimFusion  0.04017 0.06117 0.14362 0.07645 
CoRank  0.04282 0.06158 0.14521 0.07805 

Table 1: Comparison Results 
 

 All the English sentences in the document set 
were automatically translated into Chinese sen-
tences by using Google Translate, and the Stanford 
Chinese Word Segmenter2 was used for segment-
ing the Chinese documents and summaries into 
words. For comparative study, the summary length 
was limited to five sentences, i.e. each Chinese 
summary consisted of five sentences. 

We used the ROUGE-1.5.5 (Lin and Hovy, 
2003) toolkit for evaluation, which has been 
widely adopted by DUC and TAC for automatic 
summarization evaluation. It measured summary 
quality by counting overlapping units such as the 
n-gram, word sequences and word pairs between 
the candidate summary and the reference summary. 
We showed three of the ROUGE F-measure scores 
in the experimental results: ROUGE-2 (bigram-
based), ROUGE-W (based on weighted longest 
common subsequence, weight=1.2), ROUGE-L 
(based on longest common subsequences), and 
ROUGE-SU4 (based on skip bigram with a maxi-
mum skip distance of 4). Note that the ROUGE 
toolkit was performed for Chinese summaries after 
using word segmentation.   

Two graph-based baselines were used for com-
parison.   

Baseline(EN): This baseline adopts the sum-
mary translation scheme, and it relies on the Eng-
lish-side information for English sentence ranking. 
The extracted English summary is finally auto-
matically translated into the corresponding Chinese 
summary. The same sentence ranking algorithm 
with the SimFusion method is adopted, and the 
affinity weight is computed based only on the co-
sine similarity between English sentences.   

Baseline(CN): This baseline adopts the docu-
ment translation scheme, and it relies on the Chi-
nese-side information for Chinese sentence ranking. 
The Chinese summary sentences are directly ex-
tracted from the translated Chinese documents. 
The same sentence ranking algorithm with the 
SimFusion method is adopted, and the affinity 
                                                           
2 http://nlp.stanford.edu/software/segmenter.shtml 

weight is computed based only on the cosine simi-
larity between Chinese sentences.   

For our proposed methods, the parameter val-
ues are empirically set as λ=0.8 and α=0.5. 

4.2 Results and Discussion 
Table 1 shows the comparison results for our pro-
posed methods and the baseline methods. Seen 
from the tables, Baseline(CN) performs better than 
Baseline(EN) over all the metrics. The results dem-
onstrate that the Chinese-side information is more 
beneficial than the English-side information for 
cross-document summarization, because the sum-
mary sentences are finally selected from the Chi-
nese side. Moreover, our proposed two methods 
can outperform the two baselines over all the met-
rics. The results demonstrate the effectiveness of 
using bilingual information for cross-language 
document summarization. It is noteworthy that the 
ROUGE scores in the table are not high due to the 
following two reasons: 1) The use of machine 
translation may introduce many errors and noises 
in the peer Chinese summaries; 2) The use of Chi-
nese word segmentation may introduce more 
noises and mismatches in the ROUGE evaluation 
based on Chinese words.  
    We can also see that the CoRank method can 
outperform the SimFusion method over all metrics. 
The results show that the CoRank method is more 
suitable for the task by incorporating the bilingual 
information into a unified ranking framework.  

In order to show the influence of the value of the 
combination parameter λ on the performance of the 
SimFusion method, we present the performance 
curves over the four metrics in Figures 2 through 5, 
respectively. In the figures, λ ranges from 0 to 1, 
and λ=1 means that SimFusion is the same with 
Baseline(CN), and λ=0 means that only English-
side information is used for Chinese sentence rank-
ing. We can see that when λ is set to a value larger 
than 0.5, SimFusion can outperform the two base-
lines over most metrics. The results show that λ 
can be set in a relatively wide range. Note that 

1551



λ>0.5 means that SimFusion relies more on the 
Chinese-side information than on the English-side 
information. Therefore, the Chinese-side informa-
tion is more beneficial than the English-side in-
formation.  

In order to show the influence of the value of the 
combination parameter α on the performance of the 
CoRank method, we present the performance 
curves over the four metrics in Figures 6 through 9, 
respectively. In the figures, α ranges from 0.1 to 
0.9, and a larger value means that the information 
from the same language side is more relied on, and 
a smaller value means that the information from 
the other language side is more relied on. We can 
see that CoRank can always outperform the two 
baselines over all metrics with different value of α. 
The results show that α can be set in a very wide 
range. We also note that a very large value or a 
very small value of α can lower the performance 
values. The results demonstrate that CoRank relies 
on both the information from the same language 
side and the information from the other language 
side for sentence ranking. Therefore, both the Chi-
nese-side information and the English-side infor-
mation can complement each other, and they are 
beneficial to the final summarization performance.  

Comparing Figures 2 through 5 with Figures 6 
through 9, we can further see that the CoRank 
method is more stable and robust than the Sim-
Fusion method. The CoRank method can outper-
form the SimFusion method with most parameter 
settings. The bilingual information can be better 
incorporated in the unified ranking framework of 
the CoRank method.  

Finally, we show one running example for the 
document set D59 in the DUC2001 dataset. The 
four summaries produced by the four methods are 
listed below: 

 
Baseline(EN): 周日的崩溃是 24 年来第一次乘客在涉及西

北飞机事故中丧生。有乘客和观察员的报告，这架飞机的右翼引
擎也坠毁前失败。在坠机现场联邦航空局官员表示不会揣测关于
崩溃或在飞机上的发动机评论的原因。美国联邦航空局的记录显
示，除了那些涉及的飞机坠毁，与 JT8D 涡轮路段-200 系列发动
机问题的三个共和国在过去四年的航班发生的事件。1988 年 7
月，一个联合国的 DC-10 坠毁的苏城，艾奥瓦州后，发动机在飞
行中发生外，造成 112 人。 

 
Baseline(CN): 第二，在美国历史上最严重的事故是 1987

年 8 月 16 日，坠毁，造成 156 人时，美国西北航空公司飞机上
的底特律都市机场起飞时坠毁。据美国联邦航空管理局的纪录，
麦道公司的 MD-82 飞机在 1985 年和 1986 年紧急降落后，在其两
个引擎之一是失去权力。周日的崩溃是 24 年来第一次乘客在涉

及西北飞机事故中丧生。今年 4 月，国家运输安全委员会敦促美
国联邦航空局后进行一些危险，发动机故障，飞机的一个发动机
的 200 系列 JT8D 安全调查。目前，机组人员发现了一个黑人师
谁说，他可以引导飞机在附近的人们听到了他们的区域。 

SimFusion: 第二，在美国历史上最严重的事故是 1987 年 8
月 16 日，坠毁，造成 156 人时，美国西北航空公司飞机上的底
特律都市机场起飞时坠毁。周日的崩溃是 24 年来第一次乘客在
涉及西北飞机事故中丧生。在坠机现场联邦航空局官员表示不会
揣测关于崩溃或在飞机上的发动机评论的原因。有乘客和观察员
的报告，这架飞机的右翼引擎也坠毁前失败。据美国联邦航空管
理局的纪录，麦道公司的 MD-82 飞机在 1985 年和 1986 年紧急降
落后，在其两个引擎之一是失去权力。 

CoRank : 周日的崩溃是 24 年来第一次乘客在涉及西北飞
机事故中丧生。第二，在美国历史上最严重的事故是 1987 年 8
月 16 日，坠毁，造成 156 人时，美国西北航空公司飞机上的底
特律都市机场起飞时坠毁。在坠机现场联邦航空局官员表示不会
揣测关于崩溃或在飞机上的发动机评论的原因。最严重的航空事
故不断，在美国是一个在芝加哥的美国航空公司客机 1979 年崩
溃。有乘客和观察员的报告，这架飞机的右翼引擎也坠毁前失
败。 

5 Conclusion and Future Work 
In this paper, we propose two methods (SimFusion 
and CoRank) to address the cross-language docu-
ment summarization task by leveraging the bilin-
gual information in both the source and target 
language sides. Evaluation results demonstrate the 
effectiveness of the proposed methods. The Chi-
nese-side information is validated to be more bene-
ficial than the English-side information, and the 
CoRank method is more robust than the SimFusion 
method.  
    In future work, we will investigate to use the 
machine translation quality factor to further im-
prove the fluency of the Chinese summary, as in 
Wan et al. (2010). Though our attempt to use 
GIZA++ for evaluating the similarity between 
Chinese sentences and English sentences failed, we 
will exploit more advanced measures based on sta-
tistical alignment model for cross-language simi-
larity computation. 

Acknowledgments 
This work was supported by NSFC (60873155), 
Beijing Nova Program (2008B03) and NCET 
(NCET-08-0006). We thank the three students for 
translating the reference summaries. We also thank 
the anonymous reviewers for their useful com-
ments. 

 

1552



0.03

0.032

0.034

0.036

0.038

0.04

0.042

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
λ

R
O

U
G

E-
2(

F)

SimFusion Baseline(EN) Baseline(CN)

 
Figure 2. ROUGE-2(F) vs. λ for SimFusion 

0.052
0.053
0.054
0.055
0.056
0.057
0.058
0.059
0.06

0.061
0.062

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

λ

R
O

U
G

E-
W

(F
)

SimFusion Baseline(EN) Baseline(CN)

 
Figure 3. ROUGE-W(F) vs. λ for SimFusion 

0.125
0.127
0.129
0.131
0.133
0.135
0.137
0.139
0.141
0.143
0.145

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

λ

R
O

U
G

E-
L(

F)

SimFusion Baseline(EN) Baseline(CN)

 
Figure 4. ROUGE-L(F) vs. λ for SimFusion 

0.064

0.066

0.068

0.07

0.072

0.074

0.076

0.078

0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

λ

R
O

U
G

E-
SU

4(
F)

SimFusion Baseline(EN) Baseline(CN)

 
Figure 5. ROUGE-SU4(F) vs. λ for SimFusion 

 

0.036

0.037
0.038

0.039

0.04

0.041
0.042

0.043

0.044

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

α

R
O

U
G

E-
2(

F)

CoRank Baseline(EN) Baseline(CN)

 
Figure 6. ROUGE-2(F) vs. α for CoRank 

0.055
0.056

0.057
0.058
0.059

0.06
0.061

0.062
0.063

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

α

R
O

U
G

E-
W

(F
)

CoRank Baseline(EN) Baseline(CN)

 
Figure 7. ROUGE-W(F) vs. α for CoRank 

0.13
0.132
0.134
0.136
0.138
0.14

0.142
0.144
0.146
0.148

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

α

R
O

U
G

E-
L(

F)

CoRank Baseline(EN) Baseline(CN)

 
Figure 8. ROUGE-L(F) vs. α for CoRank 

0.07
0.071
0.072
0.073
0.074
0.075
0.076
0.077
0.078
0.079

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

α

R
O

U
G

E-
SU

4(
F)

CoRank Baseline(EN) Baseline(CN)

 
Figure 9. ROUGE-SU4(F) vs. α for CoRank 

1553



References  
A. Aker, T. Cohn, and R. Gaizauskas. 2010. Multi-

document summarization using A* search and 
discriminative training. In Proceedings of 
EMNLP2010. 

M. R. Amini, P. Gallinari. 2002. The Use of Unla-
beled Data to Improve Supervised Learning for 
Text Summarization. In Proceedings of 
SIGIR2002. 

G. de Chalendar, R. Besançon, O. Ferret, G. Gre-
fenstette, and O. Mesnard. 2005. Crosslingual 
summarization with thematic extraction, syntac-
tic sentence simplification, and bilingual genera-
tion. In Workshop on Crossing Barriers in Text 
Summarization Research, 5th International Con-
ference on Recent Advances in Natural Lan-
guage Processing  (RANLP2005). 

A. Celikyilmaz and D. Hakkani-Tur. 2010. A hy-
brid hierarchical model for multi-document 
summarization. In Proceedings of ACL2010.  

G. ErKan, D. R. Radev. LexPageRank. 2004. Pres-
tige in Multi-Document Text Summarization. In 
Proceedings of EMNLP2004. 

D. Klein and C. D. Manning. 2002. Fast Exact In-
ference with a Factored Model for Natural Lan-
guage Parsing. In Proceedings of NIPS2002. 

J. Kupiec, J. Pedersen, F. Chen. 1995. A.Trainable 
Document Summarizer. In Proceedings of 
SIGIR1995. 

A. Leuski, C.-Y. Lin, L. Zhou, U. Germann, F. J. 
Och, E. Hovy. 2003. Cross-lingual C*ST*RD: 
English access to Hindi information. ACM 
Transactions on Asian Language Information 
Processing, 2(3): 245-269. 

J.-M. Lim, I.-S. Kang, J.-H. Lee. 2004. Multi-
document summarization using cross-language 
texts. In Proceedings of NTCIR-4.  

C. Y. Lin, E. Hovy. 2000. The Automated Acquisi-
tion of Topic Signatures for Text Summarization. 
In Proceedings of the 17th Conference on Com-
putational Linguistics. 

C.-Y. Lin and E.H. Hovy. 2003. Automatic 
Evaluation of Summaries Using N-gram Co-
occurrence Statistics. In Proceedings of HLT-
NAACL -03. 

C.-Y. Lin, L. Zhou, and E. Hovy. 2005. Multilin-
gual summarization evaluation 2005: automatic 
evaluation report. In Proceedings of MSE (ACL-
2005 Workshop). 

M. Litvak, M. Last, and M. Friedman. 2010. A 
new approach to improving multilingual sum-
marization using a genetic algorithm. In Pro-
ceedings of ACL2010. 

H. P. Luhn. 1969. The Automatic Creation of lit-
erature Abstracts. IBM Journal of Research and 
Development, 2(2). 

R. Mihalcea, P. Tarau. 2004. TextRank: Bringing 
Order into Texts. In Proceedings of 
EMNLP2004. 

R. Mihalcea and P. Tarau. 2005. A language inde-
pendent algorithm for single and multiple docu-
ment summarization. In Proceedings of 
IJCNLP-05. 

A. Nenkova and A. Louis. 2008. Can you summa-
rize this? Identifying correlates of input diffi-
culty for generic multi-document summarization. 
In Proceedings of ACL-08:HLT. 

A. Nenkova, R. Passonneau, and K. McKeown. 
2007. The Pyramid method: incorporating hu-
man content selection variation in summariza-
tion evaluation. ACM Transactions on Speech 
and Language Processing (TSLP), 4(2). 

C. Orasan, and O. A. Chiorean. 2008. Evaluation 
of a Crosslingual Romanian-English Multi-
document Summariser. In Proceedings of 6th 
Language Resources and Evaluation Confer-
ence (LREC2008). 

P. Pingali, J. Jagarlamudi and V. Varma. 2007. 
Experiments in cross language query focused 
multi-document summarization. In Workshop on 
Cross Lingual Information Access Addressing 
the Information Need of Multilingual Societies 
in IJCAI2007. 

E. Pitler, A. Louis, and A. Nenkova. 2010. Auto-
matic evaluation of linguistic quality in multi-
document summarization. In Proceedings of 
ACL2010.  

D. R. Radev, H. Y. Jing, M. Stys and D. Tam. 
2004. Centroid-based summarization of multiple 
documents. Information Processing and Man-
agement, 40: 919-938. 

1554



A. Siddharthan and K. McKeown. 2005. Improv-
ing multilingual summarization: using redun-
dancy in the input to correct MT errors. In 
Proceedings of HLT/EMNLP-2005. 

X. Wan, H. Li and J. Xiao. 2010. Cross-language 
document summarization based on machine 
translation quality prediction. In Proceedings of 
ACL2010.  

X. Wan, J. Yang and J. Xiao. 2006. Using cross-
document random walks for topic-focused 
multi-documetn summarization. In Proceedings 
of WI2006. 

X. Wan and J. Yang. 2008. Multi-document sum-
marization using cluster-based link analysis. In 
Proceedings of SIGIR-08. 

X. Wan, J. Yang and J. Xiao. 2007. Towards an 
Iterative Reinforcement Approach for Simulta-
neous Document Summarization and Keyword 
Extraction. In Proceedings of ACL2007.  

K.-F. Wong, M. Wu and W. Li. 2008. Extractive 
summarization using supervised and semi-
supervised learning. In Proceedings of 
COLING-08. 

H. Y. Zha. 2002. Generic Summarization and Key-
phrase Extraction Using Mutual Reinforcement 
Principle and Sentence Clustering. In Proceed-
ings of SIGIR2002. 

 

1555


