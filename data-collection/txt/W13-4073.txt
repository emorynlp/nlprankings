



















































Deep Neural Network Approach for the Dialog State Tracking Challenge


Proceedings of the SIGDIAL 2013 Conference, pages 467–471,
Metz, France, 22-24 August 2013. c©2013 Association for Computational Linguistics

Deep Neural Network Approach for the
Dialog State Tracking Challenge

Matthew Henderson, Blaise Thomson and Steve Young
Department of Engineering,

University of Cambridge, U.K.
{mh521, brmt2, sjy}@eng.cam.ac.uk

Abstract
While belief tracking is known to be im-
portant in allowing statistical dialog sys-
tems to manage dialogs in a highly robust
manner, until recently little attention has
been given to analysing the behaviour of
belief tracking techniques. The Dialogue
State Tracking Challenge has allowed for
such an analysis, comparing multiple be-
lief tracking approaches on a shared task.
Recent success in using deep learning for
speech research motivates the Deep Neu-
ral Network approach presented here. The
model parameters can be learnt by directly
maximising the likelihood of the training
data. The paper explores some aspects of
the training, and the resulting tracker is
found to perform competitively, particu-
larly on a corpus of dialogs from a system
not found in the training.

1 Introduction
Statistical dialog systems, in maintaining a distri-
bution over multiple hypotheses of the true dialog
state, are able to behave in a robust manner when
faced with noisy conditions and ambiguity. Such
systems rely on probabilistic tracking of dialog
state, with improvements in the tracking quality
being important in the system-wide performance
in a dialog system (see e.g. Young et al. (2009)).

This paper presents a Deep Neural Network
(DNN) approach for dialog state tracking which
has been evaluated in the context of the Dia-
log State Tracking Challenge (DSTC) (Williams,
2012a; Williams et al., 2013)1.

Using Deep Neural Networks allows for the
modelling of complex interactions between arbi-
trary features of the dialog. This paper shows im-
provements in using deep networks over networks

1More information on the DSTC is available at
http://research.microsoft.com/en-us/events/dstc/

with fewer hidden layers. Recent developments in
speech research have shown promising results us-
ing deep learning, motivating its use in the context
of dialog (Hinton et al., 2012; Li et al., 2013).

This paper presents a technique which solves
the task of outputting a sequence of probability
distributions over an arbitrary number of possible
values using a single neural network, by learning
tied weights and using a form of sliding window.
As the classification task is not split into multiple
sub-tasks for a given slot, the log-likelihood of the
tracker on training data can be directly maximised
using gradient ascent techniques.

The domain of the DSTC is bus route informa-
tion in the city of Pittsburgh, but the presented
technique is easily transferable to new domains,
with the learned models in fact being domain in-
dependent. No domain specific knowledge is used,
and the classifier learned does not require knowl-
edge of the set of possible values. The tracker per-
formed highly competitively in the ‘test4’ dataset,
which consists of data from a dialog system not
seen in training. This suggests the model is ca-
pable of capturing the important aspects of dia-
log in a robust manner without overtuning to the
specifics of a particular system.

Most attention in the dialog state belief tracking
literature has been given to generative Bayesian
network models (Paek and Horvitz, 2000; Thom-
son and Young, 2010). Few trackers have been
published using discriminative classifiers, a no-
table exception being Bohus and Rudnicky (2006).
An analysis by Williams (2012b) demonstrates
how such generative models can in fact degrade
belief tracking performance relative to a simple
baseline. The successful use of discriminative
models for belief tracking has recently been al-
luded to by Williams (2012a) and Li et al. (2013),
and was a prominent theme in the results of the
DSTC.

467



2 The Dialog State Tracking Challenge
This section describes the domain and method-
ology of the Dialog State Tracking Challenge
(DSTC). The Challenge uses data collected during
the course of the Spoken Dialog Challenge (Black
et al., 2011), in which participants implemented
dialog systems to provide bus route information in
the city of Pittsburgh. This provides a large cor-
pus of real phonecalls from members of the public
with real information needs.

Set Number of calls Notes
train1a 1013 Labelled training data

train1b&c 10619 Same dialog system astrain1a, but unlabelled
train2 678 Similar to train1*

train3 779 Different participant toother train sets

test1 765 Very similar to train1*and train2

test2 983 Somewhat similar totrain1* and train2
test3 1037 Very similar to train3

test4 451 System not found inany training set

Table 1: Summary of datasets in the DSTC
Table 1 summarises the data provided in the

challenge. Labelled training sets provide labels
for the caller’s true goal in each dialog for 5 slots;
route, from, to, date and time.

Participants in the DSTC were asked to report
the results of their tracker on the four test sets in
the form of a probability distribution over each
slot for each turn. Performance was determined
using a basket of metrics designed to capture dif-
ferent aspects of tracker behaviour Williams et al.
(2013). These are discussed further in Section 4.

The DNN approach described here is referred to
in the results of the DSTC as ‘team1/entry1’.

3 Model
For a given slot s at turn t in a dialog, let St, s de-
note the set of possible values for s which have oc-
curred as hypotheses in the SLU for turns ≤ t. A
tracker must report a probability distribution over
St, s ∪ {other} representing its belief of the user’s
true goal for the slot s. The probability of ‘other’
represents the probability that the user’s true goal
is yet to appear as an SLU hypothesis.

A neural network structure is defined which
gives a discrete distribution over the |St, s|+1 val-
ues, taking the turns ≤ t as input.

Figure 1 illustrates the structure used in this ap-
proach. Feature functions fi (t, v) for i = 1 . . .M

f1 (t, v) f1 (t− T + 1, v)
∑t−T

t′=0 f1 (t
′, v)

f2 (t, v) f2 (t− T + 1, v)
∑t−T

t′=0 f2 (t
′, v)

fM (t, v) fM (t− T + 1, v)
∑t−T

t′=0 fM (t
′, v)

t t− T + 1 (0 . . . t− T )

f1

f2

fM

. . .

...

h1
[
= tanh(W0f

T + b0)
]

h2
[
= tanh(W1h

T
1 + b1)

]

h3
[
= tanh(W2h

T
2 + b2)

]

E(t, v)
[
= W3h

T
3

]

Figure 1: The Neural Network structure for computing
E (t, v) ∈ R for each possible value v in the set St, s. The
vector f is a concatenation of all the input nodes.

are defined which extract information about the
value v from the SLU hypotheses and machine
actions at turn t. A simple example would be
fSLU (t, v), the SLU score that s=v was informed
at turn t. A list of the feature functions actually
used in the trial is given in Section 3.1. For nota-
tional convenience, feature functions at negative t
are defined to be zero:
∀i ∀v, t′ < 0⇒ fi (t′, v) = 0.

The input layer for a given value v is fixed in
size by choosing a window size T , such that the
feature functions are summed for turns ≤ t − T .
The input layer therefore consists of (T ×M) in-
put nodes set to fi (t′, v) for t′ = t−T+1 . . . t and
i = 1 . . .M , and M nodes set to

∑t−T
t′=0 fi (t

′, v)
for i = 1 . . .M .

A feed-forward structure of hidden layers is
chosen, which reduces to a single node denoted
E (t, v). Each hidden layer introduces a weight
matrix Wi and a bias vector bi as parameters,
which are independent of v but possibly trained
separately for each s. The equations for each layer
in the network are given in Figure 1.

The final distribution from the tracker is:

P (s = v) = eE(t, v)/Z
P (s /∈ St, s) = eB/Z

Z = eB +
∑

v′∈St, s

eE(t, v
′)

where B is a new parameter of the network, in-
dependent of v and possibly trained separately for
each slot s.

468



3.1 Feature Functions
As explained above, a feature function is a func-
tion f (t, v) which (for a given dialog) returns a
real number representing some aspect of the turn
t with respect to a possible value v. A turn con-
sists of a machine action and the subsequent Spo-
ken Language Understanding (SLU) results. The
functions explored in this paper are listed below:
1. SLU score; the score assigned by the SLU to

the user asserting s=v.
2. Rank score; 1/r where r is the rank of s=v in

the SLU n-best list, or 0 if it is not on the list.
3. Affirm score; SLU score for an affirm action

if the system just confirmed s=v.
4. Negate score; as previous but with negate.
5. Go back score; the score assigned by the SLU

to a goback action matching s=v.
6. Implicit score; 1− the score given in the SLU

to a contradictory action if the system just im-
plicitly confirmed s=v, otherwise 0.

7. User act type; a feature function for each pos-
sible user act type, giving the total score of the
user act type in the SLU. Independent of s & v.

8. Machine act type; a feature function for each
possible machine act type, giving the total num-
ber of machine acts with the type in the turn.
Independent of s & v.

9. Cant help; 1 if the system just said that it can-
not provide information on s=v, otherwise 0.

10. Slot confirmed; 1 if s=v′ was just confirmed
by the system for some v′, otherwise 0.

11. Slot requested; 1 if the value of s was just re-
quested by the system, otherwise 0.

12. Slot informed; 1 if the system just gave infor-
mation on a set of bus routes which included a
specific value of s, otherwise 0.

4 Training
The derivatives of the training data likelihood with
respect to all the parameters of the model can
be computed using back propagation, i.e. the
chain rule. Stochastic Gradient Descent with mini-
batches is used to optimise the parameters by de-
scending the negative log-likelihood in the direc-
tion of the derivatives (Bottou, 1991). Termina-
tion is triggered when performance on a held-out
development set stops improving.

Each turn t and slot s in a dialog for which
|St, s| > 0 provides a non-zero summand to the
total log-likelihood of the training data. These in-
stances may be split up by slot to train a separate
network for each slot. Alternatively the data can

be combined to learn a slot independent model.
The best approach found was to train a slot inde-
pendent model for a few epochs, and then switch
to training one model per slot (see Section 4.4).

This section presents experiments varying the
training of the model. In each case the parameters
are trained using all of the labelled training sets.
The results are reported for test4 since this system
is not found in the training data. They are therefore
unbiassed and avoid overtuning problems.

The ROC curves, accuracy, Mean Reciprocal
Rank (MRR) and l2 norm of the tracker across all
slots are reported here. (A full definition of the
metrics is found in Williams et al. (2013).) These
are computed throughout using statistics at every
turn t where |St, s| > 0 (referred to as ‘schedule
2’ in the terminology of the challenge.) Table 2
and Figure 3 in Appendix A show these metrics.
The ‘Baseline’ system (‘team0/entry1’ in the chal-
lenge), considers only the top SLU hypothesis so
far, and assigns the SLU confidence score as the
tracker probability. It does not therefore incorpo-
rate any belief tracking.
4.1 Window Size
The window size, T , was varied from 2 to 20. T
must be selected so that it is large enough to cap-
ture enough of the sequence of the dialog, whilst
ensuring sufficient data to train the weights con-
necting the inputs from the earlier turns. The re-
sults suggest that T = 10 is a good compromise.
4.2 Feature Set
The features enumerated in Section 3.1 were split
into 4 sets. F1 = {1} includes only the SLU
scores; F2 = {1, ..., 6} includes feature func-
tions which depend on the user act and the value;
F3 = {1, ..., 8} also includes the user act and ma-
chine act types; and finally F4 = {1, ..., 12} in-
cludes functions which depend on the system act
and the value. The results clearly show that adding
more and more features in this manner monotoni-
cally increases the performance of the tracker.
4.3 Structure
Some candidate structures of the hidden layers
(h1, h2, ...) were evaluated, including having no
hidden layers at all, which gives a logistic regres-
sion model. In Table 2 the structure is represented
as a list giving the size of each hidden layer in turn.

Three layers in a funnelling [20, 10, 2] configu-
ration is found to outperform the other structures.
The l2 norm is highly affected by the use of deeper
network structure, suggesting it is most useful in
tweaking the calibration of the confidence scores.

469



ROC Acc. MRR l2
Baseline

0.5841 0.7574 0.5728

Window Size
T =2 0.6679 0.8044 0.5405

5 0.6875 0.8191 0.5164
10 0.6922 0.8207 0.5331
15 0.6718 0.8107 0.5352
20 0.6817 0.8190 0.5174

Feature Set
F1 0.5495 0.7364 0.6838
F2 0.6585 0.7954 0.6631
F3 0.6823 0.8134 0.5525
F4 0.6922 0.8207 0.5331

Structure
[] 0.6751 0.8074 0.5658

[50] 0.6679 0.8046 0.5450
[20] 0.6656 0.8060 0.5394

[50, 10] 0.6645 0.8045 0.5404
[20, 2] 0.6543 0.7952 0.5514

[20, 10, 2] 0.6922 0.8207 0.5331

Initialisation
Separate 0.6907 0.8206 0.5472

Single Model 0.6779 0.8111 0.5570
Shared Init. 0.6922 0.8207 0.5331

Table 2: Results for variant trackers described in Section
4. By default, we train using the shared initialisation training
method with T = 10, all the features enumerated in Section
3.1, and 3 hidden layers of size 20, 10 and 2.

4.4 Initialisation
The three methods of training alluded to in Sec-
tion 4 were evaluated; training a model for each
slot without sharing data between slots (Separate);
training a single slot independent model (Single
Model); and training for a few epochs a slot in-
dependent model, then using this to initialise the
training of separate models (Shared Initialisation).

The method of shared initialisation appears to
be the most effective, scoring the best on accu-
racy, MRR and l2. Training in this manner is par-
ticularly beneficial for slots which are under rep-
resented in the training data, as it initiates the pa-
rameters to sensible values before going on to spe-
cialise to that particular slot.

5 Performance in the DSTC
A DNN tracker was trained for entry in the
DSTC. Training used T=10, the full feature set,
a [20, 10, 2] hidden structure and the shared ini-
tialisation training method. Other parameters such
as the learning rate and regularisation coefficient
were tweaked by analysing performance on a held
out subset of the training data. All the labelled

test1
Acc.MRR

test2
Acc.MRR

test3
Acc.MRR

test4
Acc.MRR

all
Acc.MRR

0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9

Figure 2: Accuracy and MRR of the 28 entries in the DSTC
for all slots. Boxplots show minimum, maximum, quartiles
and the median. Dark dot is location of the entry presented in
this paper (DNN system).

training data available was used. The tracker is
labelled as ‘team1/entry1’ in the DSTC.

The DNN approach performed competitively in
the challenge. Figure 2 summarises the perfor-
mance of the approach relative to all 28 entries in
the DSTC. The results are less competitive in test2
and test3 but very strong in test1 and test4.

The performance in test4, dialogs with an un-
seen system, was probably the best because the
chosen feature functions forced the learning of a
general model which was not able to exploit the
specifics of particular ASR+SLU configurations.
Features which depend on the identity of the slot-
values would have allowed better performance in
test2 and test3, allowing the model to learn dif-
ferent behaviours for each value and learn typical
confusions. It would also have been possible to ex-
ploit the system-specific data available in the chal-
lenge, such as more detailed confidence metrics
from the ASR.

For a full comparison across the entries in the
DSTC, see Williams et al. (2013). In making com-
parisons it should be noted that this team did not
alter the training for different test sets, and submit-
ted only one entry.

6 Conclusion
This paper has presented a discriminative ap-
proach for tracking the state of a dialog which
takes advantage of deep learning. While sim-
ple Gradient Ascent training was tweaked in this
paper using the ‘Shared Initialisation’ scheme, a
possible promising future direction would be to
further experiment with more recent methods for
training deep structures e.g. initialising the net-
works layer by layer (Hinton et al., 2006).

Richer feature representations of the dialog con-
tribute strongly to the performance of the model.
The feature set presented is applicable across a
broad range of slot-filling dialog domains, sug-
gesting the possibility of using the models across
domains without domain-specific training data.

470



A ROC Curves

Window Size

0.1 0.2 0.3 0.4

0.1

0.2

0.3

0.4

0.5

0.6

0.7

Feature Set

0.1 0.2 0.3 0.4

0.1

0.2

0.3

0.4

0.5

0.6

0.7

Structure

0.1 0.2 0.3 0.4

0.1

0.2

0.3

0.4

0.5

0.6

Initialisation

0.1 0.2 0.3 0.4

0.1

0.2

0.3

0.4

0.5

0.6

0.7

Figure 3: ROC (Receiver Operating Characteristic) Curves
x-axis and y-axis are false acceptance and true acceptance
respectively. Lines are annotated as per Table 2.

Acknowledgments

The authors would like to thank the organisers of
the DSTC. The principal author was funded by a
studentship from the EPSRC.

References

Alan W. Black, Susanne Burger, Alistair Conkie, He-
len Wright Hastie, Simon Keizer, Oliver Lemon,
Nicolas Merigaud, Gabriel Parent, Gabriel Schu-
biner, Blaise Thomson, Jason D. Williams, Kai Yu,
Steve Young, and Maxine Eskenazi. 2011. Spoken
dialog challenge 2010: Comparison of live and con-
trol test results. In SigDIAL.

Dan Bohus and Alex Rudnicky. 2006. A K-
hypotheses+ Other Belief Updating Model. Proc.
of the AAAI Workshop on Statistical and Empirical
Methods in Spoken Dialogue Systems.

Léon Bottou. 1991. Stochastic gradient learning in
neural networks. In Proceedings of Neuro-Nı̂mes
91, Nı̂mes, France. EC2.

Geoffrey Hinton, Simon Osindero, and Yee-Whye Teh.
2006. A Fast Learning Algorithm for Deep Belief
Nets. Neural computation.

Geoffrey Hinton, Li Deng, Dong Yu, George Dahl,
Abdel-rahman Mohamed, Navdeep Jaitly, Andrew
Senior, Vincent Vanhoucke, Patrick Nguyen, Tara
Sainath, and Brian Kingsbury. 2012. Deep neural
networks for acoustic modeling in speech recogni-
tion. Signal Processing Magazine.

Deng Li, Jinyu Li, Jui-Ting Huang, Kaisheng Yao,
Dong Yu, Frank Seide, Michael L Seltzer, Geoff
Zweig, Xiaodong He, Jason D. Williams, Yifan
Gong, and Alex Acero. 2013. Recent Advances in
Deep Learning for Speech Research at Microsoft. In
ICASSP.

Tim Paek and Eric Horvitz. 2000. Conversation as
action under uncertainty. In The Sixteenth Confer-
ence on Uncertainty in Artificial Intelligence. Mor-
gan Kaufmann.

Blaise Thomson and Steve Young. 2010. Bayesian
update of dialogue state: A POMDP framework for
spoken dialogue systems. Computer Speech & Lan-
guage.

Jason D. Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan W. Black. 2013. The Dialogue State
Tracking Challenge. In SigDIAL.

Jason D. Williams. 2012a. A belief tracking chal-
lenge task for spoken dialog systems. In NAACL
HLT 2012 Workshop on Future directions and needs
in the Spoken Dialog Community: Tools and Data.
Association for Computational Linguistics.

Jason D. Williams. 2012b. Challenges and opportu-
nities for state tracking in statistical spoken dialog
systems: Results from two public deployments. J.
Sel. Topics Signal Processing, 6(8):959–970.

Steve Young, Milica Gašić, Simon Keizer, François
Mairesse, Jost Schatzmann, Blaise Thomson, and
Kai Yu. 2009. The Hidden Information State model:
A practical framework for POMDP-based spoken
dialogue management. Computer Speech & Lan-
guage.

471


