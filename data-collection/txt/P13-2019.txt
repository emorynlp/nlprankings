



















































Joint Inference for Heterogeneous Dependency Parsing


Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 104–109,
Sofia, Bulgaria, August 4-9 2013. c©2013 Association for Computational Linguistics

Joint Inference for Heterogeneous Dependency Parsing

Guangyou Zhou and Jun Zhao
National Laboratory of Pattern Recognition

Institute of Automation, Chinese Academy of Sciences
95 Zhongguancun East Road, Beijing 100190, China

{gyzhou,jzhao}@nlpr.ia.ac.cn

Abstract

This paper is concerned with the problem
of heterogeneous dependency parsing. In
this paper, we present a novel joint infer-
ence scheme, which is able to leverage
the consensus information between het-
erogeneous treebanks in the parsing phase.
Different from stacked learning meth-
ods (Nivre and McDonald, 2008; Martins
et al., 2008), which process the depen-
dency parsing in a pipelined way (e.g., a
second level uses the first level outputs), in
our method, multiple dependency parsing
models are coordinated to exchange con-
sensus information. We conduct experi-
ments on Chinese Dependency Treebank
(CDT) and Penn Chinese Treebank (CTB),
experimental results show that joint infer-
ence can bring significant improvements
to all state-of-the-art dependency parsers.

1 Introduction

Dependency parsing is the task of building depen-
dency links between words in a sentence, which
has recently gained a wide interest in the natu-
ral language processing community and has been
used for many problems ranging from machine
translation (Ding and Palmer, 2004) to question
answering (Zhou et al., 2011a). Over the past few
years, supervised learning methods have obtained
state-of-the-art performance for dependency pars-
ing (Yamada and Matsumoto, 2003; McDonald
et al., 2005; McDonald and Pereira, 2006; Hall
et al., 2006; Zhou et al., 2011b; Zhou et al.,
2011c). These methods usually rely heavily on
the manually annotated treebanks for training the
dependency models. However, annotating syntac-

(with) (eyes) (cast) (Hongkong )

   BA                      NN                 VV                         NR

(with) (eyes) (cast) (Hongkong )

      p                       n                      v                            ns

Figure 1: Different grammar formalisms of syn-
tactic structures between CTB (upper) and CDT
(below). CTB is converted into dependency gram-
mar based on the head rules of (Zhang and Clark,
2008).

tic structure, either phrase-based or dependency-
based, is both time consuming and labor intensive.
Making full use of the existing manually annotated
treebanks would yield substantial savings in data-
annotation costs.

In this paper, we present a joint inference
scheme for heterogenous dependency parsing.
This scheme is able to leverage consensus in-
formation between heterogenous treebanks dur-
ing the inference phase instead of using individual
output in a pipelined way, such as stacked learning
methods (Nivre and McDonald, 2008; Martins et
al., 2008). The basic idea is very simple: although
heterogenous treebanks have different grammar
formalisms, they share some consensus informa-
tion in dependency structures for the same sen-
tence. For example in Figure 1, the dependency
structures actually share some partial agreements
for the same sentence, the two words “eyes” and
“Hongkong” depend on “cast” in both Chinese
Dependency Treebank (CDT) (Liu et al., 2006)
and Penn Chinese Treebank (CTB) (Xue et al.,
2005). Therefore, we would like to train the de-
pendency parsers on individual heterogenous tree-
bank and jointly parse the same sentences with
consensus information exchanged between them.

The remainder of this paper is divided as fol-

104



Treebank1 Treebank2

Parser1 Parser2

 consensus information exchange

Joint inference

test data

Figure 2: General joint inference scheme of het-
erogeneous dependency parsing.

lows. Section 2 gives a formal description of
the joint inference for heterogeneous dependency
parsing. In section 3, we present the experimental
results. Finally, we conclude with ideas for future
research.

2 Our Approach

The general joint inference scheme of heteroge-
neous dependency parsing is shown in Figure 2.
Here, heterogeneous treebanks refer to two Chi-
nese treebanks: CTB and CDT, therefore we have
only two parsers, but the framework is generic
enough to integrate more parsers. For easy expla-
nation of the joint inference scheme, we regard a
parser without consensus information as a base-
line parser, a parser incorporates consensus infor-
mation called a joint parser. Joint inference pro-
vides a framework that accommodates and coordi-
nates multiple dependency parsing models. Sim-
ilar to Li et al. (2009) and Zhu et al. (2010),
the joint inference for heterogeneous dependency
parsing consists of four components: (1) Joint In-
ference Model; (2) Parser Coordination; (3) Joint
Inference Features; (4) Parameter Estimation.

2.1 Joint Inference Model
For a given sentence x, a joint dependency parsing
model finds the best dependency parsing tree y∗

among the set of possible candidate parses Y(x)
based on a scoring function Fs:

y∗ = arg max
y∈Y(x)

Fs(x, y) (1)

Following (Li et al., 2009), we will use dk to de-
note the kth joint parser, and also use the notation
Hk(x) for a list of parse candidates of sentence
x determined by dk. The sth joint parser can be
written as:

Fs(x, y) = Ps(x, y) +
∑

k,k ̸=s
Ψk(y, Hk(x)) (2)

where Ps(x, y) is the score function of the sth
baseline model, and each Ψk(y,Hk(x)) is a partial

consensus score function with respect to dk and is
defined over y andHk(x):

Ψk(y, Hk(x)) =
∑

l

λk,lfk,l(y, Hk(x)) (3)

where each fk,l(y,Hk(x)) is a feature function
based on a consensus measure between y and
Hk(x), and λk,l is the corresponding weight pa-
rameter. Feature index l ranges over all consensus-
based features in equation (3).

2.2 Parser Coordination
Note that in equation (2), though the baseline score
function Ps(x, y) can be computed individually,
the case of Ψk(y,Hk(x)) is more complicated. It
is not feasible to enumerate all parse candidates
for dependency parsing. In this paper, we use a
bootstrapping method to solve this problem. The
basic idea is that we can use baseline models’ n-
best output as seeds, and iteratively refine joint
models’ n-best output with joint inference. The
joint inference process is shown in Algorithm 1.

Algorithm 1 Joint inference for multiple parsers
Step1: For each joint parser dk, perform inference with
a baseline model, and memorize all dependency parsing
candidates generated during inference in Hk(x);
Step2: For each candidate in Hk(x), we extract subtrees
and store them in H′k(x). First, we extract bigram-subtrees
that contain two words. If two words have a dependency
relation, we add these two words as a subtree into H′k(x).
Similarly, we can extract trigram-subtrees. Note that the
dependency direction is kept. Besides, we also store the
“ROOT” word of each candidate in H′k(x);
Step3: Use joint parsers to re-parse the sentence x with
the baseline features and joint inference features (see sub-
section 2.3). For joint parser dk, consensus-based features
of any dependency parsing candidate are computed based
on current setting of H′s(x) for all s but k. New depen-
dency parsing candidates generated by dk in re-parsing are
cached in H′′k(x);
Step4: Update all Hk(x) with H′′k(x);
Step5: Iterate from Step2 to Step4 until a preset iteration
limit is reached.

In Algorithm 1, dependency parsing candidates
of different parsers can be mutually improved. For
example, given two parsers d1 and d2 with candi-
dates H1 and H2, improvements on H1 enable d2
to improve H2, and H1 benefits from improved
H2, and so on.

We can see that a joint parser does not en-
large the search space of its baseline model, the
only change is parse scoring. By running a com-
plete inference process, joint model can be applied
to re-parsing all candidates explored by a parser.

105



Thus Step3 can be viewed as full-scale candidates
reranking because the reranking scope is beyond
the limited n-best output currently cached inHk.

2.3 Joint Inference Features

In this section we introduce the consensus-based
feature functions fk,l(y,Hk(x)) introduced in
equation (3). The formulation can be written as:

fk,l(y, Hk(x)) =
∑

y′∈Hk(x)
P (y′|dk)Il(y, y′) (4)

where y is a dependency parse of x by using parser
ds (s ̸= k), y′ is a dependency parse in Hk(x)
and P (y′|dk) is the posterior probability of depen-
dency parse y′ parsed by parser dk given sentence
x. Il(y, y′) is a consensus measure defined on y
and y′ using different feature functions.

Dependency parsing model P (y′|dk) can be
predicted by using the global linear models
(GLMs) (e.g., McDonald et al. (2005); McDonald
and Pereira (2006)). The consensus-based score
functions Il(y, y′) include the following parts:

(1) head-modifier dependencies. Each head-
modifier dependency (denoted as “edge”) is a tu-
ple t =< h, m, h → m >, so Iedge(y, y′) =∑

t∈y δ(t, y
′).

(2) sibling dependencies: Each sibling de-
pendency (denoted as “sib”) is a tuple t =<
i, h, m, h ← i → m >, so Isib(y, y′) =∑

t∈y δ(t, y
′).

(3) grandparent dependencies: Each grand-
parent dependency (denoted as “gp”) is a tuple
t =< h, i, m, h → i → m >, so Igp(y, y′) =∑

<h,i,m,h→i→m>∈y δ(t, y
′).

(4) root feature: This feature (denoted as
“root”) indicates whether the multiple depen-
dency parsing trees share the same “ROOT”, so
Iroot(y, y

′) =
∑

<ROOT>∈y δ(< ROOT >, y
′).

δ(·, ·) is a indicator function–δ(t, y′) is 1 if
t ∈ y′ and 0 otherwise, feature index l ∈
{edge, sib, gp, root} in equation (4). Note that
< h, m, h → m > and < m,h, m → h > are
two different edges.

In our joint model, we extend the baseline fea-
tures of (McDonald et al., 2005; McDonald and
Pereira, 2006; Carreras, 2007) by conjoining with
the consensus-based features, so that we can learn
in which kind of contexts the different parsers
agree/disagree. For the third-order features (e.g.,
grand-siblings and tri-siblings) described in (Koo
et al., 2010), we will discuss it in future work.

2.4 Parameter Estimation
The parameters are tuned to maximize the depen-
dency parsing performance on the development
set, using an algorithm similar to the average per-
ceptron algorithm due to its strong performance
and fast training (Koo et al., 2008). Due to lim-
ited space, we do not present the details. For more
information, please refer to (Koo et al., 2008).

3 Experiments

In this section, we describe the experiments
to evaluate our proposed approach by using
CTB4 (Xue et al., 2005) and CDT (Liu et al.,
2006). For the former, we adopt a set of head-
selection rules (Zhang and Clark, 2008) to convert
the phrase structure syntax of treebank into a de-
pendency tree representation. The standard data
split of CTB4 from Wang et al. (2007) is used. For
the latter, we randomly select 2,000 sentences for
test set, another 2,000 sentences for development
set, and others for training set.

We use two baseline parsers, one trained on
CTB4, and another trained on CDT in the ex-
periments. We choose the n-best size of 16 and
the best iteration time of four on the development
set since these settings empirically give the best
performance. CTB4 and CDT use two different
POS tag sets and transforming from one tag set
to another is difficult (Niu et al., 2009). To over-
come this problem, we use Stanford POS Tagger1

to train a universal POS tagger on the People’s
Daily corpus,2 a large-scale Chinese corpus (ap-
proximately 300 thousand sentences and 7 mil-
lion words) annotated with word segmentation and
POS tags. Then the POS tagger produces a uni-
versal layer of POS tags for both the CTB4 and
CDT. Note that the word segmentation standards
of these corpora (CTB4, CDT and People’s Daily)
slightly differs; however, we do not consider this
problem and leave it for future research.

The performance of the parsers is evaluated us-
ing the following metrics: UAS, DA, and CM,
which are defined by (Hall et al., 2006). All the
metrics except CM are calculated as mean scores
per word, and punctuation tokens are consistently
excluded.

We conduct experiments incrementally to eval-
uate the joint features used in our first-order and
second-order parsers. The first-order parser

1http://nlp.stanford.edu/software/tagger.shtml
2http://www.icl.pku.edu.cn

106



– Features CTB4 CDTUAS CM UAS CM

dep1

baseline 86.6 42.5 75.4 16.6
+ edge 88.01 (↑1.41) 44.28 (↑1.78) 77.10 (↑1.70) 17.82 (↑1.22)
+ root 87.22 (↑0.62) 43.03 (↑0.53) 75.83 (↑0.43) 16.81 (↑0.21)
+ both 88.19 (↑1.59) 44.54 (↑2.04) 77.16 (↑1.76) 17.90 (↑1.30)

CTB4 + CDT 87.32 43.08 75.91 16.89

dep2

baseline 88.38 48.81 77.52 19.70
+ edge 89.17 (↑0.79) 49.73 (↑0.92) 78.44 (↑0.92) 20.85 (↑1.15)
+ sib 88.94 (↑0.56) 49.26 (↑0.45) 78.02 (↑0.50) 20.13 (↑0.43)
+ gp 88.90 (↑0.52) 49.11 (↑0.30) 77.97 (↑0.45) 20.06 (↑0.36)

+ root 88.61 (↑0.23) 48.88 (↑0.07) 77.65 (↑0.13) 19.88 (↑0.18)
+ all 89.62 (↑1.24) 50.15 (↑1.34) 79.01 (↑1.49) 21.11 (↑1.41)

CTB4 + CDT 88.91 49.13 78.03 20.12

Table 1: Dependency parsing results on the test set with different joint inference features. Abbreviations:
dep1/dep2 = first-order parser and second-order parser; baseline = dep1 without considering any joint
inference features; +* = the baseline features conjoined with the joint inference features derived from the
heterogeneous treebanks; CTB4 + CDT = we simply concatenate the two corpora and train a dependency
parser, and then test on CTB4 and CDT using this single model. Improvements of joint models over
baseline models are shown in parentheses.

Type Systems ≤ 40 Full

D
dep2 90.86 88.38

MaltParser 87.1 85.8
Wang et al. (2007) 86.6 -

C
MSTMalt† 90.55 88.82

Martins et al. (2008)† 90.63 88.84
Surdeanu et al. (2010)† 89.40 86.63

H Zhao et al. (2009) 88.9 86.1Ours 91.48 89.62

S Yu et al. (2008) - 87.26Chen et al. (2009) 92.34 89.91
Chen et al. (2012) - 91.59

Table 2: Comparison of different approach on
CTB4 test set using UAS metric. MaltParser =
Hall et al. (2006); MSTMalt=Nivre and McDon-
ald (2008). Type D = discriminative dependency
parsers without using any external resources; C =
combined parsers (stacked and ensemble parsers);
H = discriminative dependency parsers using ex-
ternal resources derived from heterogeneous tree-
banks, S = discriminative dependency parsers us-
ing external unlabeled data. † The results on CTB4
were not directly reported in these papers, we im-
plemented the experiments in this paper.

(dep1) only incorporates head-modifier depen-
dency part (McDonald et al., 2005). The second-
order parser (dep2) uses the head-modifier and
sibling dependency parts (McDonald and Pereira,
2006), as well as the grandparent dependency
part (Carreras, 2007; Koo et al., 2008). Table 1
shows the experimental results.

As shown in Table 1, we note that adding more
joint inference features incrementally, the depen-
dency parsing performance is improved consis-

tently, for both treebanks (CTB4 or CDT). As a
final note, all comparisons between joint models
and baseline models in Table 1 are statistically sig-
nificant.3 Furthermore, we also present a base-
line method called “CTB4 + CDT” for compari-
son. This method first tags both CTB4 and CDT
with the universal POS tagger trained on the Peo-
ple’s Daily corpus, then simply concatenates the
two corpora and trains a dependency parser, and
finally tests on CTB4 and CDT using this single
model. The comparisons in Table 1 tell us that
very limited information is obtained without con-
sensus features by simply taking a union of the
dependencies and their contexts from the two tree-
banks.

To put our results in perspective, we also com-
pare our second-order joint parser with other best-
performing systems. “≤ 40” refers to the sentence
with the length up to 40 and “Full” refers to all
the sentences in test set. The results are shown
in Table 2, our approach significantly outperforms
many systems evaluated on this data set. Chen
et al. (2009) and Chen et al. (2012) reported a
very high accuracy using subtree-based features
and dependency language model based features
derived from large-scale data. Our systems did not
use such knowledge. Moreover, their technique is
orthogonal to ours, and we suspect that combin-
ing their subtree-based features into our systems
might get an even better performance. We do not
present the comparison of our proposed approach

3We use the sign test at the sentence level. All the com-
parisons are significant at p < 0.05.

107



Type Systems UAS DA

D
Duan et al. (2007) 83.88 84.36

Huang and Sagae (2010) 85.20 85.52
Zhang and Nivre (2011) 86.0 -

C Zhang and Clark (2008) - 86.21Bohnet and Kuhn (2012) 87.5 -

H Li et al. (2012) 86.44 -Ours 85.88 86.52
S Chen et al. (2009) - 86.70

Table 3: Comparison of different approaches on
CTB5 test set. Abbreviations D, C, H and S are as
in Table 2.

Treebanks #Sen # Better # NoChange # Worse
CTB4 355 74 255 26
CDT 2,000 341 1,562 97

Table 4: Statistics on joint inference output on
CTB4 and CDT development set.

with the state-of-the-art methods on CDT because
there is little work conducted on this treebank.

Some researchers conducted experiments on
CTB5 with a different data split: files 1-815 and
files 1,001-1,136 for training, files 886-931 and
1,148-1,151 for development, files 816-885 and
files 1,137-1,147 for testing. The development
and testing sets were also performed using gold-
standard assigned POS tags. We report the experi-
mental results on CTB5 test set in Table 4. Our re-
sults are better than most systems on this data split,
except Zhang and Nivre (2011), Li et al. (2012)
and Chen et al. (2009).

3.1 Additional Results
To obtain further information about how depen-
dency parsers benefit from the joint inference, we
conduct an initial experiment on CTB4 and CDT.
From Table 4, we find that out of 355 sentences on
the development set of CTB4, 74 sentences ben-
efit from the joint inference, while 26 sentences
suffer from it. For CDT, we also find that out of
2,000 sentences on the development set, 341 sen-
tences benefit from the joint inference, while 97
sentences suffer from it. Although the overall de-
pendency parsing results is improved, joint infer-
ence worsens dependency parsing result for some
sentences. In order to obtain further information
about the error sources, it is necessary to investi-
gate why joint inference gives negative results, we
will leave it for future work.

4 Conclusion and Future Work

We proposed a novel framework of joint infer-
ence, in which multiple dependency parsing mod-

els were coordinated to search for better depen-
dency parses by leveraging the consensus infor-
mation between heterogeneous treebanks. Exper-
imental results showed that joint inference signif-
icantly outperformed the state-of-the-art baseline
models.

There are some ways in which this research
could be continued. First, recall that the joint in-
ference scheme involves an iterative algorithm by
using bootstrapping. Intuitively, there is a lack of
formal guarantee. A natural avenue for further re-
search would be the use of more powerful algo-
rithms that provide certificates of optimality; e.g.,
dual decomposition that aims to develop decod-
ing algorithms with formal guarantees (Rush et
al., 2010). Second, we would like to combine our
heterogeneous treebank annotations into a unified
representation in order to make dependency pars-
ing results comparable across different annotation
guidelines (e.g., Tsarfaty et al. (2011)).

Acknowledgments

This work was supported by the National Natural
Science Foundation of China (No. 61070106, No.
61272332 and No. 61202329), the National High
Technology Development 863 Program of China
(No. 2012AA011102), the National Basic Re-
search Program of China (No. 2012CB316300),
We thank the anonymous reviewers and the prior
reviewers of ACL-2012 and AAAI-2013 for their
insightful comments. We also thank Dr. Li Cai for
providing and preprocessing the data set used in
this paper.

References
B. Bohnet and J. Kuhn. 2012. The best of both worlds-

a graph-based completion model for transition-
based parsers. In Proceedings of EACL.

X. Carreras. 2007. Experiments with a Higher-order
Projective Dependency Parser. In Proceedings of
EMNLP-CoNLL, pages 957-961.

W. Chen, D. Kawahara, K. Uchimoto, and Torisawa.
2009. Improving Dependency Parsing with Subtrees
from Auto-Parsed Data. In Proceedings of EMNLP,
pages 570-579.

W. Chen, M. Zhang, and H. Li. 2012. Utilizing depen-
dency language models for graph-based dependency
parsing models. In Proceedings of ACL.

Y. Ding and M. Palmer. 2004. Synchronous depen-
dency insertion grammars: a grammar formalism
for syntax based statistical MT. In Proceedings of

108



the Workshop on Recent Advances in Dependency
Grammar, pages 90-97.

X. Duan, J. Zhao, and B. Xu. 2007. Probabilistic Mod-
els for Action-based Chinese Dependency Parsing.
In Proceedings of ECML/PKDD.

J. M. Eisner. 2000. Bilexical Grammars and Their
Cubic-Time Parsing Algorithm. Advanced in Prob-
abilistic and Other Parsing Technologies, pages 29-
62.

J. Hall, J. Nivre, and J. Nilsson. 2006. Discriminative
Classifier for Deterministic Dependency Parsing. In
Proceedings of ACL, pages 316-323.

L. Huang and K. Sagae. 2010. Dynamic Programming
for Linear-Time Incremental Parsing. In Proceed-
ings of ACL, pages 1077-1086.

T. Koo, X. Carreras, and M. Collins. 2008. Simple
Semi-Supervised Dependency Parsing. In Proceed-
ings of ACL.

T. Koo, A. M. Rush, M. Collins, T. Jaakkola, and D.
Sontag. 2010. Dual Decomposition for Parsing with
Non-Projective Head Automata. In Proceedings of
EMNLP.

M. Li, N. Duan, D. Zhang, C.-H. Li, and M. Zhou.
2009. Collaborative Decoding: Partial Hypothesis
Re-ranking Using Translation Consensus Between
Decoders. In Proceedings of ACL, pages 585-592.

Z. Li, T. Liu, and W. Che. 2012. Exploiting multiple
treebanks for parsing with Quasi-synchronous gram-
mars. In Proceedings of ACL.

T. Liu, J. Ma, and S. Li. 2006. Building a Dependency
Treebank for Improving Chinese Parser. Journal of
Chinese Languages and Computing, 16(4):207-224.

A. F. T. Martins, D. Das, N. A. Smith, and E. P. Xing.
2008. Stacking Dependency Parsers. In Proceed-
ings of EMNLP, pages 157-166.

R. McDonald and F. Pereira. 2006. Online Learning of
Approximate Dependency Parsing Algorithms. In
Proceedings of EACL, pages 81-88.

R. McDonald, K. Crammer, and F. Pereira. 2005. On-
line Large-margin Training of Dependency Parsers.
In Proceedings of ACL, pages 91-98.

Z. Niu, H. Wang, and H. Wu. 2009. Exploiting Het-
erogeneous Treebanks for Parsing. In Proceedings
of ACL, pages 46-54.

J. Nivre and R. McDonld. 2008. Integrating Graph-
based and Transition-based Dependency Parsing. In
Proceedings of ACL, pages 950-958.

A. M. Rush, D. Sontag, M. Collins, and T. Jaakkola.
2010. On Dual Decomposition and Linear Program-
ming Relation for Natural Language Processing. In
Proceedings of EMNLP.

M. Surdeanu and C. D. Manning. 2010. Ensemble
Models for Dependency Parsing: Cheap and Good?
In Proceedings of NAACL.

R. Tsarfaty, J. Nivre, and E. Andersson. 2011. Eval-
uating Dependency Parsing: Robust and Heuristics-
Free Cross-Annotation Evaluation. In Proceedings
of EMNLP.

J.-N Wang, J-.S. Chang, and K.-Y. Su. 1994. An Au-
tomatic Treebank Conversion Algorithm for Corpus
Sharing. In Proceedings of ACL, pages 248-254.

Q. I. Wang, D. Lin, and D. Schuurmans. 2007. Sim-
ple Training of Dependency Parsers via Structured
Boosting. In Proceedings of IJCAI, pages 1756-
1762.

N. Xue, F. Xia, F.-D. Chiou, and M. Palmer. 2005.
The Penn Chinese Treebank: Phrase Structure An-
notation of a Large Corpus. Natural Language En-
gineering, 10(4):1-30.

Yamada and Matsumoto. 2003. Statistical Sependency
Analysis with Support Vector Machines. In Pro-
ceedings of IWPT, pages 195-206.

D. H. Younger. 1967. Recognition and Parsing of
Context-Free Languages in Time n3. Information
and Control, 12(4):361-379, 1967.

K. Yu, D. Kawahara, and S. Kurohashi. 2008. Chi-
nese Dependency Parsing with Large Scale Auto-
matically Constructed Case Structures. In Proceed-
ings of COLING, pages 1049-1056.

Y. Zhang and S. Clark. 2008. A Tale of Two
Parsers: Investigating and Combining Graph-based
and Transition-based Dependency Parsing Using
Beam-Search. In Proceedings of EMNLP, pages
562-571.

Y. Zhang and J. Nivre. 2011. Transition-based De-
pendency Parsing with Rich Non-local Features. In
Proceedings of ACL, pages 188-193.

H. Zhao, Y. Song, C. Kit, and G. Zhou. 2009. Cross
Language Dependency Parsing Using a Bilingual
Lexicon. In Proceedings of ACL, pages 55-63.

G. Zhou, L. Cai, J. Zhao, and K. Liu. 2011. Phrase-
Based Translation Model for Question Retrieval in
Community Question Answer Archives. In Pro-
ceedings of ACL, pages 653-662.

G. Zhou, J. Zhao, K. Liu, and L. Cai. 2011. Exploit-
ing Web-Derived Selectional Preference to Improve
Statistical Dependency Parsing. In Proceedings of
ACL, pages 1556-1565.

G. Zhou, L. Cai, K. Liu, and J. Zhao. 2011. Improving
Dependency Parsing with Fined-Grained Features.
In Proceedings of IJCNLP, pages 228-236.

M. Zhu, J. Zhu, and T. Xiao. 2010. Heterogeneous
Parsing via Collaborative Decoding. In Proceedings
of COLING, pages 1344-1352.

109


