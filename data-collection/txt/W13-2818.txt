










































Language-independent hybrid MT with PRESEMT


Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 123–130,
Sofia, Bulgaria, August 8, 2013. c©2013 Association for Computational Linguistics

Language-independent hybrid MT with PRESEMT 

 

 

George Tambouratzis Sokratis Sofianopoulos Marina Vassiliou 
ILSP, Athena R.C ILSP, Athena R.C ILSP, Athena R.C 

giorg_t@ilsp.gr s_sofian@ilsp.gr mvas@ilsp.gr 

 

 
 

 

 

 

Abstract 

The present article provides a compre-

hensive review of the work carried out 

on developing PRESEMT, a hybrid lan-

guage-independent machine translation 

(MT) methodology. This methodology 

has been designed to facilitate rapid 

creation of MT systems for uncon-

strained language pairs, setting the low-

est possible requirements on specialised 

resources and tools. Given the limited 

availability of resources for many lan-

guages, only a very small bilingual cor-

pus is required, while language model-

ling is performed by sampling a large 

target language (TL) monolingual cor-

pus. The article summarises implementa-

tion decisions, using the Greek-English 

language pair as a test case. Evaluation 

results are reported, for both objective 

and subjective metrics. Finally, main er-

ror sources are identified and directions 

are described to improve this hybrid MT 

methodology. 

1 Introduction and background 

Currently a large proportion of language-

independent MT approaches are based on the 

statistical machine translation (SMT) paradigm 

(Koehn, 2010). A main benefit of SMT is that it 

is directly amenable to new language pairs, pro-

vided appropriate training data are available for 

extracting translation and language models. The 

main obstacle to the creation of an SMT system 

is the requirement for SL-TL parallel corpora of 

a sufficient size to allow the extraction of mean-

ingful translation models. Such corpora (of the 

order of million sentences) are hard to obtain, 

particularly for less resourced languages. On the 

other hand, the translation accuracy of such sys-

tems largely depends on the quality and size of 

the bilingual corpora, as well as their relevance 

to the domain of text being translated. Even if 

such parallel corpora exist for a language pair, 

they are frequently restricted to a specific do-

main (or a narrow range of domains). As a con-

sequence, these corpora are not suitable for cre-

ating MT systems that focus on other domains. 

For this reason, in SMT, researchers are investi-

gating the extraction of information from mono-

lingual corpora, including lexical translation 

probabilities (Klementiev et al., 2012) and topic-

specific information (Su et al., 2011). 

Alternative techniques for creating MT sys-

tems using less informative but readily available 

resources have been proposed. Even if these 

methods do not provide a translation quality as 

high as SMT, their ability to develop hybrid MT 

systems with very limited specialised resources 

represents an important advantage. Such meth-

ods include automatic inference of templates for 

structural transfer from SL to TL (Caseli et al., 

2008 and Sanchez-Martinez et al., 2009). Simi-

larly, Carbonell et al. (2006) propose an MT 

method that needs no parallel text, but relies on a 

lightweight translation model utilising a full-

form bilingual dictionary and a decoder for long-

range context. Other systems using low-cost re-

sources include METIS (Dologlou et al., 2003) 

and METIS-II (Markantonatou et al., 2009; Carl 

et al., 2008), which utilise a bilingual lexicon 

123



and monolingual corpora to translate SL texts. 

METIS/METIS II, which have studied transla-

tion only towards English, employ pattern rec-

ognition algorithms to retrieve the most appro-

priate translation from a monolingual corpus. 

2 The MT methodology in brief 

The MT methodology has been developed 

within the PRESEMT (Pattern REcognition-

based Statistically Enhanced MT) project, 

funded by the European Commission (cf. 

www.presemt.eu). It comprises three stages: 

(i) pre-processing, where the input sentence is 

tagged and lemmatised 

(ii) main translation, where the actual transla-

tion output is generated and 

(iii) post-processing, where the corresponding 

tokens are generated from lemmas. 

The main translation process is split in two 

phases, namely (a) the establishment of the 

translation structure in terms of phrase order and 

(b) the definition of word order and resolution of 

lexical ambiguities at an intra-phrase level.  

In terms of resources, PRESEMT utilises a bi-

lingual lemma dictionary providing SL – TL 

lexical correspondences. It also employs an ex-

tensive TL monolingual corpus, compiled auto-

matically via web crawling (Pomikalek et al., 

2008) to generate a comprehensive phrase-based 

language model. The provision of the monolin-

gual corpus allows PRESEMT to use only a very 

small bilingual corpus for mapping the transfer 

from SL to TL sentence structures. This bilin-

gual corpus only numbers a few hundred sen-

tences, reducing reliance on costly linguistic re-

sources. The corpus is assembled from available 

parallel corpora, only replacing free translations 

with more literal ones, to allow the accurate ex-

traction of structural modifications. The parallel 

corpus coverage is not studied prior to integra-

tion in PRESEMT, which would have allowed 

an optimisation of translation performance. 

3 Extracting information from corpora 

3.1 Parallel corpus 

Initially, both the bilingual and the monolingual 

corpora are annotated
1

 so as to incorporate 

lemma and Part-of-Speech (PoS) information 

and other salient language-specific morphologi-

cal features (e.g. case, number, tense etc.). Fur-

thermore, for the TL side, a shallow parser or 

chunker (hereafter referred to as parser) is used 

to split the sentences into syntactic phrases. As 

the proposed methodology has been developed 

to maximise the use of publicly-available soft-

ware, the user is free to select any desired parser 

for the TL language. 

To avoid either an additional SL side parser or 

potential incompatibilities between the two pars-

ers, the Phrase Aligner module (PAM, Tam-

bouratzis et al., 2011) is implemented. PAM 

transfers the TL side parsing scheme, which en-

compasses lemma, tag and parsing information, 

to the SL side, based on lexical information cou-

pled with statistical data on PoS tag correspon-

dences extracted from the lexicon. The parsing 

scheme includes phrase boundaries and phrase 

labels. PAM follows a 3-step process, involving 

(a) lexicon-based alignment, (b) alignment based 

on similarity of grammatical features and PoS 

tag correspondence and (c) alignment on the 

evidence of already aligned neighbouring words. 

The SL side of the aligned corpus is subse-

quently processed by the Phrasing model genera-

tor (PMG), to create an SL phrasing model 

which will then parse sentences input for transla-

tion. The original PMG implementation (Tam-

bouratzis et al., 2011) has utilised Conditional 

Random Fields (CRF), due to the considerable 

representation capabilities of this model 

(Lafferty et al., 2001). CRF is a statistical mod-

elling method that takes context into account to 

predict labels for sequences of input samples. 

The implementation of an alternative PMG 

methodology (termed PMG-simple) based on 

template-matching principles has also been pur-

sued. PMG-simple locates phrases that match 

                                                           
1 For the annotation task readily available tools are em-

ployed. For the experiments reported here, TreeTagger 

(Schmid, 1994) has been used for the TL text processing 

and the FBT PoS tagger (Prokopidis et al., 2011) has been 

employed for the processing of the SL text.. 

124



exactly what it has seen before, based on a sim-

ple template-matching algorithm (Duda et al., 

2001). The templates used are the phrases to 

which the SL side sentences of the bilingual cor-

pus have been segmented. In contrast to CRF, 

PMG-simple implements a greedy search (Black, 

2005) without backtracking. Initially all phrases 

are positioned in an ordered list according to 

their likelihood of being accurately detected. 

Starting from the phrase with the highest likeli-

hood, PMG-simple examines if each phrase oc-

curs in the input sentence. If it does and the con-

stituent words are not part of an already estab-

lished phrase, the constituent words are marked 

as parts of this phrase and are no longer consid-

ered in the phrase-matching process. If the 

phrase pattern does not occur, the next in-line 

phrase is considered, until the table is exhausted. 

Comparative results between CRF and PMG-

simple are reported in the results section. 

3.2 Monolingual corpus 

The TL monolingual corpus is processed to ex-

tract two complementary types of information. 

The first type supports disambiguation between 

multiple possible translations, while the second 

determines the order of words in the final trans-

lation and the addition or removal of functional 

words, using a TL phrase model derived from an 

indexing based on (i) phrase type, (ii) phrase 

head lemma and (iii) phrase head PoS tag. 

The TL phrases are then organised in a hash 

map that allows the storage of multiple values 

for each key, using as a key the three aforemen-

tioned criteria. For each phrase the number of 

occurrences within the corpus is retained. Each 

hash map is stored in a separate file to minimise 

access time during translation. 

4 Translation phase 1: Structure selec-
tion 

The Structure selection phase determines the 

type and relative position of TL phrases to which 

the SL ones are translated. To achieve this, 

PRESEMT consults the SL-to-TL structural 

modifications as contained in the PAM-

processed parallel corpus. In that respect, it 

resembles EBMT (Hutchins, 2005). 

Translation phase 1 receives as input an SL 

sentence, annotated with tag & lemma informa-

tion and segmented into phrases by the PMG. A 

dynamic programming algorithm then deter-

mines for each SL side the most similar (in 

terms of phrase structure) SL sentence from the 

bilingual corpus. Similarity is calculated by tak-

ing into account structural information such as 

the phrase type, the PoS tag and case (if applica-

ble) of the phrase head and phrase functional 

head info. The phrases of the input sentence are 

then reordered to generate the translation struc-

ture by combining the phrase alignments estab-

lished by the algorithm and the SL-TL phrase 

alignment information stored in the pair of paral-

lel sentences. 

The dynamic programming algorithm com-

pares structures from the same language. The 

most similar SL structure from the bilingual cor-

pus, that will determine the TL translation struc-

ture, is thus selected purely on SL properties. 

The similarity of two sentences is calculated as a 

weighted internal product between the two sen-

tences, traversing both sentences in parallel from 

their start towards their end. The implemented 

method utilises the Smith-Waterman variant 

(Smith and Waterman, 1981).  

The last step of this phase is the translation of 

words using the bilingual lexicon.
2
 All transla-

tion alternatives are disambiguated during the 

subsequent translation phase. 

5 Translation Phase 2: Translation 
equivalent selection 

Issues resolved in the second phase are phrase-

internal and include (i) word order within each 

phrase, (ii) introduction or deletion of functional 

words and (iii) selection of the best candidate in 

the case of translation ambiguities. These are 

resolved using the phrase-based indexing of the 

TL monolingual corpus. 

For each phrase of the sentence being trans-

lated, the algorithm searches the TL phrase 

model for similar phrases. If the search is suc-

cessful, all retrieved TL phrases are compared to 

the phrase to be translated. The comparison is 

based on the words included, their tags and lem-

mas and the morphological features. 

                                                           
2 If an SL word is not included in the lexicon, it is retained 

in the translation in its original SL form. 

125



1. Retrieve the relevant phrases from the TL 

corpus based on the head word 

2. Compare the phrase with all the TL relevant 

phrases and store the one that scores the 

highest similarity score  

3. For any words that the TL model cannot 

disambiguate, use the lemma frequency 

model for selecting the best translation 

4. Return the new translated Phrase instance. 

  
Figure 1. Pseudocode for Translation equivalent 

selection 

 

For the purposes of the proposed methodol-

ogy, the stable-marriage algorithm (Gale & 

Shapley, 1962) is applied for calculating the 

similarity and aligning the words of a phrase 

pair. In comparison to other relevant algorithms, 

the Gale-Shapley algorithm, results in poten-

tially non-optimal solutions, but possesses the 

advantage of a substantially lower complexity 

and thus a reduced processing time. 

Using the most similar TL phrase and the 

word alignments generated by the stable-

marriage algorithm, word reordering, translation 

disambiguation and addition or removal of func-

tional words is performed for each phrase of the 

input sentence. The final translation is produced 

by combining all of its translated phrases. 

6 Developing new Language Pairs 

The porting of the proposed methodology to new 

language pairs is straightforward. The summary 

presented herewith is based on the creation of a 

new Greek-to-Italian language pair, and is typi-

cal of porting to new TLs. Initially, the NLP 

tools need to be selected for the new language 

(tagger & lemmatiser, shallow parser). In addi-

tion, a TL monolingual corpus and a bilingual 

lexicon need to be provided. The following steps 

are then taken: 

A. Create a java wrapper class for the Italian 
annotation tools, and provide rules for iden-

tifying heads of phrases. 

B. Tag/lemmatise and chunk the TL corpus, 
which takes less than a day. 

C. Process the chunked Italian corpus to gener-
ate the phrase model. This operation is fully 

automated and performed off-line (e.g. for a 

corpus of 100 million words, approx. 1.5 

days are needed). 

D. For the parallel corpus, train the PAM/PMG 
suite for the relevant language pair (less than 

2 hours needed). 

7 Objective Evaluation Experiments 

The evaluation results reported in this article 

focus on the Greek – English language pair. Two 

datasets have been used (a development set and 

a test set), each of which comprises 200 sen-

tences, with a length of between 7 and 40 words. 

For every sentence, exactly one reference trans-

lation has been created, by SL-language native 

speakers and then the translation correctness was 

cross-checked by TL-language native speakers. 
 

Number of sentences 200 Source web 

Reference translations 1 Language pair EL–EN 

Metrics 
MT system 

BLEU NIST Meteor TER 

PRESEMT  0.3254 6.9793 0.3880 51.5330 

METIS-2 0.1222 3.1655 0.2698 82.878 

Systran 0.2930 6.4664 0.3830 49.721 

Bing 0.4600 7.9409 0.4281 37.631 

Google 0.5544 8.8051 0.4665 29.791 

WorldLingo 0.2659 5.9978 0.3666 50.627 

Table 1. Objective metrics results for PRESEMT 

& other MT systems (development set) 

 

To objectively evaluate the translation accu-

racy, four automatic evaluation metrics have 

been chosen, namely BLEU (Papineni et al., 

2002), NIST (NIST 2002), Meteor (Denkowski 

and Lavie, 2011) and TER (Snover et al., 2006). 

When developing the MT methodology, exten-

sive evaluation was carried out at regular inter-

vals (Sofianopoulos et al., 2012). The evolution 

of translation accuracy is depicted within Figure 

2. The falling trend for TER, signifies a continu-

ously improving translation performance. The 

current results for a number of MT systems for 

the development set are reported in Table 1. 

These results show that at the current stage of 

development the proposed approach has a qual-

ity exceeding that of WorldLingo and Systran, 

but is still inferior to Google and Bing. The re-

sults are particularly promising, taking into ac-

count that the proposed methodology has been 

developed for a substantially shorter period than 

the other systems, and has no language-specific 

information injected into it. According to an er-

126



ror analysis carried out, most of the errors are 

due to the lack of syntactic information (e.g. the 

inability to distinguish between object/subject). 

Also a point which can be improved concerns 

the mapping of sentence structures from SL to 

TL. To address this, additional experiments are 

currently under way involving larger monolin-

gual corpora.  

Even without this type of knowledge, the pro-

posed methodology has shown substantial scope 

for improvement, as evidenced by the evolution 

of the objective translation metrics (cf. Figure 

2). It is expected that this trend will be continued 

in future versions of the MT system. 

 

40.0000

45.0000

50.0000

55.0000

60.0000

65.0000

May-12 Jun-12 Jul-12 Aug-12 Sep-12 Oct-12 Nov-12 Dec-12

 
Figure 2. Evolution of translation accuracy re-

flected by TER scores for the PRESEMT system 

together with the associated trend line 

 

Number of sentences 200 Source web 

Reference translations 1 Language pair EL–EN 

Metrics 
PMG type 

BLEU NIST Meteor TER 

CRF-based 0.3167 6.9127 0.3817 52.509 

PMG-simple 0.3254 6.9793 0.3880 51.533 

Table 2. Effect on PRESEMT translation accu-

racy of using the two distinct PMG variants 

 

Recent activity towards improving translation 

accuracy has focussed on the effect of using dif-

ferent PMG approaches, as summarised in sec-

tion 3. According to Table 2, an improvement in 

all four metrics is achieved using PMG-simple 

instead of CRF. For the limited training set de-

fined by the parallel corpus, PMG-simple ex-

tracts more effectively the phrasing model. An 

improvement of approx. 3% in the BLEU score 

is achieved over the CRF-based system. The 

reduction in TER is almost 2% indicating a siz-

able improvement in translation quality, while 

NIST and METEOR scores are improved by 1% 

and 1.9% respectively. 

8 Subjective Evaluation Results 

To fully evaluate translation quality, both objec-

tive and subjective evaluation have been imple-

mented. The latter type is carried out by humans 

who assess translation quality. 

Human evaluation is considered to be more 

representative of the actual MT quality (Calli-

son-Burch, et al., 2008 & 2011), though on the 

other hand it is time-consuming and laborious. 

Furthermore, it lacks objectivity (single evalua-

tors may not be consistent in assessing a given 

translation through time while two evaluators 

may yield completely different judgements on 

the same text) and must be repeated for every 

new test result.  

For the human evaluation, for each language 

pair, a total of 15 language professionals were 

recruited, who were either language profession-

als, closely associated with MT tasks, or post-

graduate university students in the area of lin-

guistics. Two types of subjective evaluation 

were carried out. The first one involves the ex-

perts grading translations generated by the PRE-

SEMT system regarding their adequacy and flu-

ency. Adequacy refers to the amount of informa-

tion from the SL text that is retained in the trans-

lation, based on a 1-5 scale of scores (with a 

score of 1 corresponding to the worst transla-

tion). Fluency measures whether the translation 

is well-formed, also on a 1-5 scale, with empha-

sis being placed on grammaticality. 

The second type of subjective evaluation in-

volves direct comparison between the transla-

tions generated by PRESEMT and by other es-

tablished MT systems over the same dataset. In 

this case, each evaluator ranks the translations of 

the different systems, these systems being pre-

sented in randomised order to ensure the de-

pendability of the feedback received. 

Subjective evaluation activities were carried 

out during two distinct periods (namely October 

and December 2012), separated by two months. 

The purpose of implementing two sessions has 

been to judge the improvement in the system 

within the intervening period. Thus, two distinct 

versions of the EL-EN MT system correspond-

ing to these two time points were used. For ref-

127



erence, the objective evaluation results obtained 

for the test sentences are listed in Table 3. In 

both cases, the CRF-based PMG was used since 

it was more mature at the time of evaluation.  

A specifically-designed platform has been de-

veloped to support subjective evaluation activi-

ties
3
. This platform has been used to (a) collect 

the human evaluators’ feedback for the different 

language pairs and (b) support the subsequent 

assessment of the results via statistical methods. 

 

Number of sentences 200 Source web 

Reference translations 1 Language pair EL–EN 

Metrics 
MT system 

BLEU NIST Meteor TER 

PRESEMT 

(phase 1) 
0.2627 6.2001 0.3329 60.0420 

PRESEMT 

(phase 2) 
0.2666 6.2061 0.3335 59.3360 

Bing 0.4793 8.1357 0.4486 35.7220 

Google 0.5116 8.4549 0.4580 32.6860 

WorldLingo 0.3019 6.3799 0.3814 46.7350 

Table 3. Objective metrics results for PRESEMT 

& other MT systems (test set) 

 

0

20

40

60

80

100

n
u

m
b

e
r 

o
f 

ca
se

s

1 2 3 4 5

Score scale

adequacy

fluency

 
Figure 3. Histogram of adequacy and fluency 

over all sentences (1st human evaluation phase) 

 

0

20

40

60

80

100

n
u

m
b

e
r 

o
f 

ca
se

s

1 2 3 4 5

Score scale

adequacy

fluency

 

Figure 4. Histogram of adequacy and fluency 

over all sentences (2
nd

 human evaluation phase) 

 

For the proposed methodology, in phase 1 rel-

atively low values of both adequacy and fluency 

                                                           
3 www.presemt.eu/presemt_eval/ 

measurements were recorded. By comparing the 

scores in the first and second evaluation phases 

(Figures 3 and 4, respectively), it can be seen 

that both adequacy and fluency histograms move 

towards higher values (notably fluency ratings 

with a score of 3 and adequacy ratings with 

scores of 3 and 4 have substantially higher fre-

quencies). This reflects improved translation 

quality in the later version of the proposed MT 

system in comparison to the earlier one.  

 

Number of sentences 200 Source web 

Reference translations 1 Language pair EL–EN 

Adequacy Fluency 
MT system 

average stdev. average stdev. 

PRESEMT 

(phase 1)  
3.08 0.27 2.17 0.27 

PRESEMT 

(phase 2) 
3.14 0.24 2.16 0.25 

Google 4.17 0.39 3.51 0.50 

Bing 3.75 0.77 3.02 0.61 

WorldLingo 3.77 0.45 3.11 0.51 

Table 4. Summary of measurements (in terms of 

average and standard deviation) for fluency and 

adequacy for various MT systems (test set) 

 

In addition, in phase 2 of subjective evalua-

tion, adequacy and fluency measurements were 

collected for the three operational systems used 

as reference systems (namely Google Translate, 

Bing and WorldLingo). These operational sys-

tems have higher adequacy and fluency values 

than PRESEMT, as indicated in Table 4. Fur-

thermore, paired t-tests have confirmed that at a 

0.99 level of significance, these three systems 

have statistically superior subjective measure-

ments to the proposed methodology. To provide 

a reference, for the same set of 200 sentences, 

objective metrics are shown in Table 3 for each 

system. As can be seen the relative order of the 

systems in the subjective evaluations (in terms 

of adequacy and fluency) is confirmed by the 

objective measurements. 

A second subjective evaluation focused on 

ranking comparatively the translations of the 

four studied MT systems. Evaluators were pre-

sented with the outputs of the four systems in 

randomized order, to conceal the identity of each 

system. The evaluators were requested to order 

the four translations from higher to lower quality 

(with 1 denoting the more accurate translation. 

128



To transform this ranking into a single score, the 

individual rankings per evaluator have been ac-

cumulated and normalized over the number of 

evaluators. Then the representative scoring has 

been defined as a weighted sum of frequency of 

a system being ranked as first, second, third and 

fourth best over all evaluators, by multiplying 

with weights of 40, 30, 20 and 10 respectively. 

The average scores of the proposed methodology 

were the lowest, followed by the ranking results 

for WorldLingo. The results of Bing and Google 

are comparable with the Google results giving 

the best results. A statistical analysis was carried 

out using paired t-tests for all six pairings of the 

four systems being studied. This has confirmed 

that the differences in subjective scores are sta-

tistically significant at a level of 0.95. 

To summarise, subjective evaluation has 

shown that the PRESEMT methodology has an 

inferior translation performance in terms of sub-

jective measurements to the three operational 

systems. This can be justified as the proposed 

methodology refrains from utilising language-

specific information as a priori grammatical 

knowledge. Inferior translations also reflect the 

much shorter development time available as well 

as the very limited amount of expensive re-

sources provided. The effect on translation qual-

ity of using pre-existing tools (to ease portability 

to new language pairs) needs to be stressed, as 

no modification of these tools was performed to 

remedy systematic shortcomings identified. For 

the newer MT versions now available, a new 

round of subjective evaluations is planned. It has 

been observed that improvements in objective 

metrics are followed by improved subjective 

evaluation performance. Thus, for these new 

versions, an improved accuracy is expected. 

9 Discussion 

In the present article the principles and imple-

mentation of a novel language-independent MT 

methodology have been presented. This meth-

odology draws on information from a large TL 

monolingual corpus and a very small bilingual 

one. The overwhelming majority of linguistic 

information is extracted in an automated manner 

using pattern recognition techniques. 

Two types of evaluation have been reported, 

these concerning objective and subjective 

evaluations. Experimental results using objective 

metrics through a period of time have indicated a 

rising trend in terms of translation quality. Also, 

it has been shown that by introducing a new 

phrasing model for the sentences to be translated 

a substantial improvement is achieved. Subjec-

tive evaluation activities have indicated a higher 

translation accuracy achieved by other MT sys-

tems. A limiting factor for the PRESEMT meth-

odology is admittedly the requirement for port-

ability to new language pairs. This leads to the 

extraction of knowledge from texts via algo-

rithmic means and the adoption of already exist-

ing linguistic tools, without modifications.  

On the other hand, subsequent versions of the 

proposed MT system have shown a trend of im-

proving translation accuracy. In this respect, ob-

jective evaluation results are promising, espe-

cially taking into account the fact that for several 

aspects, scope for improvement has been identi-

fied. This includes the revision of the structure 

selection phase, where smaller sub-sentential 

structures need to be combined to improve gen-

eralisation. In addition, improvements in the bi-

lingual corpus compilation procedure need to be 

studied. The results of these ongoing experi-

ments will be reported in the future. 

References 

Paul E. Black. 2005. Dictionary of Algorithms and 

Data Structures. U.S. National Institute of Stan-

dards and Technology (NIST). 

Chris Callison-Burch, Cameron Fordyce, Philipp 

Koehn, Christof Monz and Josh Schroeder. 2009. 

Further Meta-Evaluation of Machine Translation. 

Proceedings of the WMT-08 Workshop, Colom-

bus, Ohio. 

Chris Callison-Burch, Philip Koehn, Christof Monz, 

Omar F. Zaidan. 2011. Findings of the 

2011Workshop on Statistical Machine Translation. 

Proceedings of the 6
th

 Workshop on Statistical 

Machine Translation, Edinburgh, UK, pp. 22–64. 

Jaime Carbonell, Steve Klein, David Miller, Michael 

Steinbaum, Tomer Grassiany and Jochen Frey. 

2006. Context-Based Machine Translation. Pro-

ceedings of the 7
th

 AMTA Conference, Cam-

bridge, MA, USA, pp. 19-28. 

Michael Carl, Maite Melero, Toni Badia, Vincent 

Vandeghinste, Peter Dirix, Ineke Schuurman, 

Stella Markantonatou, Sokratis Sofianopoulos, 

129



Marina Vassiliou and Olga Yannoutsou. 2008. 

METIS-II: Low Resources Machine Translation: 

Background, Implementation, Results and Poten-

tials. Machine Translation, 22 (1-2):pp. 67-99. 

Helena M. Caseli, Maria das Graças V. Nunes and 

Mikel L. Forcada. 2008. Automatic Induction of 

Bilingual resources from aligned parallel corpora: 

Application to shallow-transfer machine transla-

tion. Machine Translation, 20:pp. 227-245. 

Michael Denkowski and Alon Lavie. 2011. Meteor 

1.3: Automatic Metric for Reliable Optimization 

and Evaluation of Machine Translation Systems. 

EMNLP 2011 Workshop on Statistical Machine 

Translation, Edinburgh, UK, pp. 85-91. 

Ioannis Dologlou, Stella Markantonatou, George 

Tambouratzis, Olga Yannoutsou, Athanasia Fourla 

and Nikos Ioannou. 2003. Using Monolingual 

Corpora for Statistical Machine Translation: The 

METIS System. Proceedings of the EAMT- CLAW 

2003 Workshop, Dublin, Ireland, pp. 61-68. 

Richard O. Duda, Peter E. Hart and David G. Scott. 

2001. Pattern Classification (2
nd

 edition). Wiley 

Interscience, New York, U.S.A. 

David Gale and Lloyd S. Shapley. 1962. College 

Admissions and the Stability of Marriage. Ameri-

can Mathematical Monthly, 69:pp. 9-14. 

John Hutchins. 2005. Example-Based Machine 

Translation: a Review and Commentary. Machine 

Translation, 19:pp. 197-211. 

Alexandre Klementiev, Ann Irvine, Chris Callison-

Burch and David Yarowsky. 2012. Toward Statis-

tical Machine Translation without Parallel Cor-

pora. Proceedings of EACL2012, Avignon, 

France, 23-25 April, pp. 130-140. 

Philip Koehn. 2010. Statistical Machine Translation. 

Cambridge University Press, Cambridge. 

John Lafferty, Andrew McCallum and Fernando 

Pereira. 2001. Conditional Random Fields: Prob-

abilistic Models for Segmenting and Labelling Se-

quence Data. Proceedings of ICML 2011, Belle-

vue, Washington, USA, pp. 282-289. 

Harry Mairson. 1992. The Stable Marriage Problem. 

The Brandeis Review, 12:1. 

Stella Markantonatou, Sokratis Sofianopoulos, Olga 

Giannoutsou and Marina Vassiliou. 2009. Hybrid 

Machine Translation for Low- and Middle- Den-

sity Languages. Language Engineering for Lesser-

Studied Languages, S. Nirenburg (ed.), IOS Press, 

pp. 243-274. 

NIST 2002. Automatic Evaluation of Machine Trans-

lation Quality Using n-gram Co-occurrences Sta-

tistics. 

Kishore Papineni, Salim Roukos, Todd Ward, and 

Wei-Jing Zhu. 2002. BLEU: A Method for Auto-

matic Evaluation of Machine Translation. Pro-

ceedings of the 40
th

 ACL Meeting, Philadelphia, 

USA, pp. 311-318. 

Jan Pomikálek and Pavel Rychlý. 2008. Detecting co-

derivative documents in large text collections. 

Proceedings of LREC2008, Marrakech, Morrocco, 

pp.1884-1887. 

Prokopis Prokopidis, Byron Georgantopoulos and 

Harris Papageorgiou. 2011. A suite of NLP tools 

for Greek. Proceedings of the 10
th

 ICGL Confer-

ence, Komotini, Greece, pp. 373-383. 

Felipe Sanchez-Martinez and Mikel L. Forcada. 

2009. Inferring Shallow-transfer Machine transla-

tion Rules from Small Parallel Corpora. Journal of 

Artificial Intelligence Research, 34:pp. 605-635. 

Helmut Schmid. 1994. Probabilistic Part-of-Speech 

Tagging Using Decision Trees. Proceedings of In-

ternational Conference on New Methods in Lan-

guage Processing, Manchester, UK, pp. 44-49. 

Temple F. Smith and Michael S. Waterman. 1981. 

Identification of Common Molecular Subse-

quences. Journal of Molecular Biology, 147:195-

197. 

Matthew Snover, Bonnie Dorr, Richard Schwartz, 

Linnea Micciulla and John Makhoul. 2006. A 

Study of Translation Edit Rate with Targeted Hu-

man Annotation. Proceedings of the 7
th

 AMTA 

Conference, Cambridge, MA, USA, pp. 223-231. 

Sokratis Sofianopoulos, Marina Vassiliou and George 

Tambouratzis. 2012. Implementing a language-

independent MT methodology. Proceedings of the 

1
st
 Workshop on Multilingual Modeling (held 

within the ACL-2012 Conference), Jeju, Republic 

of Korea, pp.1-10. 

Jinsong Su, Hua Wu, Haifeng Wang, Yidong Chen, 

Xiaodong Shi, Huailin Dong and Qun Liu. 2011. 

Translation Model Adaptation for Statistical Ma-

chine Translation with Monolingual Topic Infor-

mation. Proceedings of the 50
th

 ACL Meeting, 

Jeju, Republic of Korea, pp. 459–468. 

George Tambouratzis, Fotini Simistira, Sokratis Sofi-

anopoulos, Nikos Tsimboukakis and Marina Vas-

siliou. 2011. A resource-light phrase scheme for 

language-portable MT. Proceedings of the 15
th
 

EAMT Conference, Leuven, Belgium, pp. 185-

192. 

130


