



















































Shift-Reduce Constituency Parsing with Dynamic Programming and POS Tag Lattice


Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1030–1035,
Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics

Shift-Reduce Constituency Parsing with Dynamic Programming
and POS Tag Lattice

Haitao Mi†
†T.J. Watson Research Center

IBM
hmi@us.ibm.com

Liang Huang‡†
‡Queens College & Graduate Center

City University of New York
liang.huang.sh@gmail.com

Abstract

We present the first dynamic programming
(DP) algorithm for shift-reduce constituency
parsing, which extends the DP idea of Huang
and Sagae (2010) to context-free grammars.
To alleviate the propagation of errors from
part-of-speech tagging, we also extend the
parser to take a tag lattice instead of a fixed tag
sequence. Experiments on both English and
Chinese treebanks show that our DP parser
significantly improves parsing quality over
non-DP baselines, and achieves the best accu-
racies among empirical linear-time parsers.

1 Introduction

Incremental parsing has gained popularity in both
dependency (Nivre, 2004; Zhang and Clark, 2008)
and constituency parsing (Zhu et al., 2013; Wang
and Xue, 2014). However, the greedy or beam
search algorithms used in these parsers can only ex-
plore a tiny fraction of trees among exponentially
many candidates. To alleviate this problem, Huang
and Sagae (2010) propose a dynamic programming
(DP) algorithm, reducing the search space to a poly-
nomial size by merging equivalent states. This idea
has been extended by Kuhlmann et al. (2011) and
Cohen et al. (2011) to other dependency parsing
paradigms.

In constituency parsing, however, DP has not yet
been applied to incremental parsing, and the big-
ger search space in constituency parsing suggests a
potentially even bigger advantage by DP. However,
with unary rules and more-than-binary branchings,
constituency parsing presents challenges not found
in dependency parsing that must be addressed be-
fore applying DP. Thus, we first present an odd-even

shift-reduce constituency parser which always fin-
ishes in same number of steps, eliminating the com-
plicated asynchronicity issue in previous work (Zhu
et al., 2013; Wang and Xue, 2014), and then de-
velop dynamic programming on top of that. Sec-
ondly, to alleviate the error propagation from POS
tagging, we also extends the algorithm to take a tag-
ging sausage lattice as input, which is a compromise
between pipeline and joint approaches (Hatori et al.,
2011; Li et al., 2011; Wang and Xue, 2014).

Our DP parser achieves state-of-the-art perfor-
mances on both Chinese and English treebanks (at
90.8% on PTB and 83.9% on CTB, the latter being
the highest in literature).

2 Odd-Even Shift-Reduce CFG Parser

One major challenge in constituency parsing is
unary rules. Unlike dependency parsing where shift-
reduce always finishes in 2n−1 steps, existing incre-
mental constituency parsers (Zhu et al., 2013; Wang
and Xue, 2014) reach the goal state (full parse tree)
in different steps due to different number of unary
rules. So we propose a new, synchronized, “odd-
even” system to reach the goal in the same 4n − 2
steps. A state is notated p = 〈S,Q〉, where S is a
stack of trees ..., s1, s0, and Q is a queue of word-
tag pairs. At even steps (when step index is even)
we can choose one of the three standard actions

• sh: shift the head of Q, a word-tag pair (t, w),
onto S as a singleton tree t(w);

• rexx: combine the top two trees on the stack and
replace them with a new tree x(s1, s0), x being
the root nonterminal, headed on s0;

• rexy: similar to rexx but headed on s1;
and at odd steps we can choose two new actions:

1030



input (t1, w1) ... (tn, wn)

axiom 0 : 〈�, (t1, w1) ... (tn, wn)〉 : 0

sh
l : 〈S, (t, w)|Q〉 : c

l+1 : 〈S|t(w), Q〉 : c+csh l is even

rexx
l : 〈S|s1|s0, Q〉 : c

l+1 : 〈S|x(s1, s0), Q〉 : c+crexx
l is even

unx
l : 〈S|s0, Q〉 : c

l+1 : 〈S|x(s0), Q〉 : c+cunx l is odd

st
l : 〈S|s0, Q〉 : c

l+1 : 〈S|s0, Q〉 : c+cst l is odd

goal 2(2n− 1) : 〈s0, �〉 : c
Figure 1: Shift-reduce system, omitting rexy. c is the
model score, and csh, crexx , etc. are the action scores.

• unx : replace s0 with a new tree x(s0) with x
being the root nonterminal;

• st: no action.
Figure 1 shows the deductive system. Note that

we alternate between standard shift-reduce actions
in even steps and unary actions (unx or st) in odd
steps, and the first action must be sh, followed by a
unx or st, and followed by another sh. Continuing
this procedure, we can always achieve the goal in
2(2n− 1) steps.

In practice, we have larger than two-way rules and
multi-level unary rules, so we binarize them and col-
lapse multi-level unary rules into one level, for ex-
ample,

NP

S

VP

PPNPV

=⇒

NP+S

VP

PPVP′

NPV

Following Huang and Sagae (2010), we represent
feature templates as functions f(·, ·) on stack S and
queue Q. Table 1 shows the 43 feature templates we
use in this paper, all adopted from Zhu et al. (2013).
They are combinations of the 32 atomic features
f̃(S,Q) (e.g. s0.t and s0.c denote the head tag and

sh
l : 〈S, (t, w)|Q〉 : (c, v)

l+1 : 〈S|t(w), Q〉 : (c+csh, 0) l is even

rexx

state p:
l′ :〈S′|s′1, Q′〉 : (c′, v′)

state q:
l :〈S|s1|s0, Q〉 : (c, v)

l+1 : 〈S′|x(s′1, s0), Q〉 : (c′+v+δ, v′+v+δ)
l and l′ are even, p ∈ π(q)

unx
l : 〈S|s0, Q〉 : (c, v)

l+1 : 〈S|x(s0), Q〉 : (c+cunx , v + cunx ) l is odd

Figure 2: DP shift-reduce, omitting rexy and st. c and v
are prefix and inside scores, and δ = csh(p) + crexx(q).
State equivalence is defined below in Section 3.

syntactic category of tree s0, resp., and s0.lc.w is the
head word of its leftmost child).

3 Dynamic Programming

The key idea towards DP is the merging of equiva-
lent states, after which the stacks are organized in a
“graph-structured stack” (GSS)(Tomita, 1988). Fol-
lowing Huang and Sagae (2010), “equivalent states”
∼ in a same beam are defined by the atomic features
f̃(S,Q) and the span of s0:

〈S,Q〉 ∼ 〈S′, Q′〉
⇔ f̃(S,Q) = f̃(S′, Q′) and s0.span = s′0.span.

Similarly, for each state p, π(p) is a set of predictor
states, each of which can be combined with p in a
rexx or re

x
y action. For each action, we have differ-

ent operations on π(p). If a state pmakes a sh action
and generates a state p′, then π(p′) = {p}. If two
shifted states p′ and p′′ are equivalent, p′ ∼ p′′, we
merge π(p′) and π(p′′). If a state p makes a reduce
(rexx or re

x
y) action, p tries to combine with every

p′ ∈ π(p), and each combination generates a state r
with π(r) = π(p′). If two reduced states are equiva-
lent, we only keep one predictor states, as their pre-
dictor states are identical. If a state p fires an unx or
a st action resulting in a state u, we copy the predic-
tor states π(u) = π(p). Similar to reduce actions, if
two resulting states after applying an unx or a st ac-
tion are equivalent, we only keep the best one with
highest score (the recombined ones are only useful
for searching k-best trees).

1031



feature templates f(S,Q)
unigrams s0.t ◦ s0.c s0.w ◦ s0.c s1.t ◦ s1.c s1.w ◦ s1.c s2.t ◦ s2.c s2.w ◦ s2.c

s3.t ◦ s3.c q0.w ◦ q0.t q1.w ◦ q1.t q2.w ◦ q2.t q3.w ◦ q3.t s0.lc.w ◦ s0.lc.c
s0.rc.w ◦ s0.rc.c s0.u.w ◦ s0.u.c s1.lc.w ◦ s1.lc.c s1.rc.w ◦ s1.rc.c s1.u.w ◦ s1.u.c

bigrams s0.w ◦ s1.w s0.w ◦ s1.c s0.c ◦ s1.w s0.c ◦ s1.c s0.w ◦ q0.w s0.w ◦ q0.t
s0.c ◦ q0.w s0.c ◦ q0.t q0.w ◦ q1.w q0.w ◦ q1.t q0.t ◦ q1.w q0.t ◦ q1.t
s1.w ◦ q0.w s1.w ◦ q0.t s1.c ◦ q0.w s1.c ◦ q0.t
s0.c ◦ s0.lc.c ◦ s0.rc.c ◦ s1.c s0.c ◦ s0.lc.c ◦ s0.rc.c ◦ s1.c

trigrams s0.c ◦ s1.c ◦ s2.c s0.w ◦ s1.c ◦ s2.c s0.c ◦ s1.w ◦ q0.t
s0.c ◦ s1.c ◦ s2.w s0.c ◦ s1.c ◦ q0.t s0.w ◦ s1.c ◦ q0.t
s0.c ◦ s1.w ◦ q0.t s0.c ◦ s1.c ◦ q0.w

Table 1: All feature templates (43 templates based on 32 atomic features), taken from Zhu et al. (2013). si.c, si.w and
si.t denote the syntactic label, the head word, and the head tag of si. si.lc.w means the head word of the left child of
si. si.u.w means the head word of the unary root si. qi.w and qi.t denote the word and the tag of qi.

input (T1, w1)...(Tn, wn)

axioms 0 : 〈�, (t, w1)...(Tn, wn)({</s>}, </s>)〉 : 0,∀ t ∈ T1

sh
l : 〈S, (t, w)|(T ′, w′)|Q〉 : (c, v)

l+1 : 〈S|t(w), (t′, w′)|Q〉 : (c+csh, 0)
t′ ∈ T ′,
l is even

Figure 3: Extended shift-reduce deductive system with
tagging sausage lattice, only showing sh.

In order to compute all the scores in GSS, for each
state p, we calculate the prefix score, c, which is the
total cost of the best action sequence from the initial
state to the end of state p, and the inside score v,
which is the score since the last shift (Figure 2).

The new mechanism beyond Huang and Sagae
(2010) is the non-trivial dynamic programming
treatment of unary actions (unx and st), which is not
found in dependency parsing. Note that the score
calculation is quite different from shift in the sense
that unary actions are more like reduces.

4 Incorporating Tag Lattices

It is easy to extend our deductive system to take tag-
ging sausage lattices as input. The key difference
is that the tag t associated with each word in the
input sequence becomes a set of tags T . Thus, in
the sh action, we split the state with all the possible
tags t′ in the tagset T ′ for the second word on the
queue. Figure 3 shows the deductive system, where
we only change the sh action, input and axiom. For
simplicity reasons we only present one word look

 87.5

 88

 88.5

 89

 89.5

 90

 2  4  6  8  10  12  14  16  18

F
1

 o
n

 t
h

e
 d

e
v
 s

e
t

iteration

11th

15th

DP

non-DP

Figure 4: The learning curves of non-DP and DP parsers
on the development set. DP achieves the best perfor-
mance at 11th iteration with 89.8%, while non-DP gets
its optimal iteration at 15th with a lower F1 89.5%.

ahead (we just need to know the tag of the first word
on the queue), but in practice, we use a look ahead of
4 words (q0..q3, see Table 1), so each shift actually
splits the tagset of the 5th word on the queue (q4).

5 Experiments

We evaluate our parsers on both Penn English Tree-
bank (PTB) and Chinese Treebank (CTB). For PTB,
we use sections 02-21 as the training, section 24 as
the dev set, and section 23 as the test. For CTB,
we use the version of 5.1, articles 001-270 and 440-
1151 as the training data, articles 301-325 as the dev
set, and articles 271-300 as the test set.

Besides training with gold POS tags, we add
k-best automatic tagging results to the training
set using a MaxEnt model with ten-way jackknif-
ing (Collins, 2000). And we automatically tag the
dev and test sets with k-best tagging sequences us-

1032



 86

 86.5

 87

 87.5

 88

 88.5

 89

 89.5

 90

 16  32  48  64

F
1

 o
n

 t
h

e
 d

e
v
 s

e
t

beam size

DP train, DP test
non-DP train, non-DP test

Figure 5: The F1 curves of non-DP and DP parsers (train
and test consistently) on the dev set.

ing the MaxEnt POS tagger (at 97.1% accuracy on
English, and 94.5% on Chinese) trained on the train-
ing set. We set k to 20 for English. And we run two
sets of experiments, 1-best vs. 20-best, for Chinese
to address the tagging issue. We train our parsers us-
ing “max-violation perceptron” (Huang et al., 2012)
(which has been shown to converge much faster than
“early-update” of Collins and Roark (2004)) with
minibatch parallelization (Zhao and Huang, 2013)
on the head-out binarized and unary-collapsed train-
ing set. We finally debinarize the trees to recover the
collapsed unary rules.

We evaluate parser performance with EVALB in-
cluding labeled precision (LP), labeled recall (LR),
and bracketing F1. We use a beam size of 32, and
pick the optimal iteration number based on the per-
formances on the dev set.

Our baseline is the shift-reduce parser without
state recombination (henceforth “non-DP”), and our
dynamic programming parser (henceforth “DP”) is
the extension of the baseline.

5.1 Learning Curves and Search Quality

Figure 4 shows the learning curves on the PTB dev
set. With a same beam width, DP parser achieves a
better performance (89.8%, peaking at the 11th it-
eration) and converges faster than non-DP. Picking
the optimal iterations for DP and non-DP models,
we test each with various beam size, and plot the F1
curves in Figure 5. Again, DP is always better than
non-DP, with 0.5% difference at beam of 64.

LR LP F1 comp.
Collins (1999) 88.1 88.3 88.2 O(n5)

Charniak (2000) 89.5 89.9 89.5 O(n5) †

Carreras (2008) 90.7 91.4 91.1 O(n4) ‡

Petrov (2007) 90.1 90.2 90.1 O(n3) †

Ratnaparkhi (1997) 86.3 87.5 86.9
O(n)Sagae (2006) 87.8 88.1 87.9

Zhu (2013) 90.2 90.7 90.4
non-DP 90.3 90.4 90.3

O(n)DP 90.7 90.9 90.8

Table 2: Final Results on English (PTB) test set (sec23).
†The empirical complexities for Charniak and Petrov are
O(n2.5) andO(n2.4), resp., ‡but Carreras is exactO(n4).

LR LP F1 POS
Charniak (2000) 79.6 82.1 80.8 -

Petrov (2007) 81.9 84.8 83.3 -
Zhu (2013) 82.1 84.3 83.2 -

Wang (2014) (1-best POS) 80.3 80.0 80.1 94.0
Wang (2014) (joint) 82.9 84.2 83.6 95.5

non-DP (1-best POS) 80.7 80.5 80.6 94.5
non-DP (20-best POS) 83.3 83.2 83.2 95.5

DP (20-best POS) 83.6 84.2 83.9 95.6

Table 3: Results on Chinese (CTB) 5.1 test set.

5.2 Final Results on English

Table 2 shows the final results on the PTB test set.
The last column shows the empirical time com-
plexity. Our baseline parser achieves a competitive
score, which is higher than Berkeley even with a lin-
ear time complexity, and is comparable to Zhu et al.
(2013). Our DP parser improves the F1 score by
0.5 points over the non-DP, and achieves the best F1
score among empirical linear-time parsers.

5.3 Sausage Lattice Parsing

To alleviate the propagation of errors from POS tag-
ging, we run sausage lattice parsing on both Chinese
and English, where Chinese tagging accuracy signif-
icantly lag behind English.

Table 3 shows the F1 score and POS tagging ac-
curacy of all parsing models on the Chinese 5.1 test
set. Our MaxEnt POS tagger achieves an accuracy
of 94.5% on 1-best outputs, and an oracle score of
97.1% on 20-best results. The average number of

1033



tags for each word in the 20-best list is 1.1.
The joint tagging and parsing approach of Wang

and Xue (2014) improves the F1 score from 80.1%
to 83.6% (see lines 4 and 5). We instead use sausage
lattices, a much cheaper way. The non-DP (1-best
POS) and non-DP (20-best POS) lines show the ef-
fectiveness of using sausage lattices (+1.1 for tag-
ging and +2.6 for parsing). As Wang and Xue (2014)
is a non-DP model, it is comparable to our non-DP
results. With the help of 20-best tagging lattices, we
achieve the same tagging accuracy at 95.5%, but still
0.4 worse on the F1 score than the joint model. It
suggests that we need a larger k to catch up the gap.
But our DP model boosts the performance further to
the best score at 83.9% with a similar set of features.

The last two lines (non-DP and DP) in Table 2
show our English lattice parsing results. So we run
another baseline with the non-DP English parser on
1-best POS tags, and the baseline achieves a tagging
accuracy at 97.11 and an F1 score at 90.1. Com-
paring to the tagging accuracy (97.15) and F1 score
(90.3) of our non-DP lattice parser, sausage lattice
parsing doesn’t help the tagging accuracy, but helps
parsing a little by 0.2 points. The statistics show that
2 percent of POS tags in the lattice parsing result
are different from the baseline, and those differences
lead to a slight improvement on parsing.

6 Conclusions

In this paper, we present a dynamic programming al-
gorithm based on graph-structured stack (GSS) for
shift-reduce constituency parsing, and extend the al-
gorithm to take tagging sausage lattices as input. Ex-
periments on both English and Chinese treebanks
show that our DP parser outperforms almost all other
parsers except of Carreras et al. (2008), which runs
in a much higher time complexity.

Acknowledgment

We thank the anonymous reviewers for comments.
Haitao Mi is supported by DARPA HR0011-12-
C-0015 (BOLT), and Liang Huang is supported
by DARPA FA8750-13-2-0041 (DEFT), NSF IIS-
1449278, and a Google Faculty Research Award.
The views and findings in this paper are those of the
authors and are not endorsed by the DARPA.

References
Xavier Carreras, Michael Collins, and Terry Koo. 2008.

Tag, dynamic programming, and the perceptron for ef-
ficient, feature-rich parsing. In Proceedings of CoNLL
2008.

Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of NAACL.

Shay B. Cohen, Carlos Gómez-Rodrı́guez, and Giorgio
Satta. 2011. Exact inference for generative probabilis-
tic non-projective dependency parsing. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing.

Michael Collins and Brian Roark. 2004. Incremental
parsing with the perceptron algorithm. In Proceedings
of ACL.

Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, Univer-
sity of Pennsylvania.

Michael Collins. 2000. Discriminative reranking for nat-
ural language parsing. In Proceedings of ICML, pages
175–182.

Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and
Jun’ichi Tsujii. 2011. Incremental joint pos tagging
and dependency parsing in chinese. In IJCNLP.

Liang Huang and Kenji Sagae. 2010. Dynamic program-
ming for linear-time incremental parsing. In Proceed-
ings of ACL 2010.

Liang Huang, Suphan Fayong, and Yang Guo. 2012.
Structured perceptron with inexact search. In Proceed-
ings of NAACL.

Marco Kuhlmann, Carlos Gmez-Rodrguez, and Giorgio
Satta. 2011. Dynamic programming algorithms for
transition-based dependency parsers. In Proceedings
of ACL.

Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wen-
liang Chen, and Haizhou Li. 2011. Joint models for
chinese pos tagging and dependency parsing. In Pro-
ceedings of EMNLP, pages 1180–1191.

Joakim Nivre. 2004. Incrementality in deterministic
dependency parsing. In Incremental Parsing: Bring-
ing Engineering and Cognition Together. Workshop at
ACL-2004, Barcelona.

Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In Proceedings of HLT-
NAACL.

Adwait Ratnaparkhi. 1997. A linear observed time sta-
tistical parser based on maximum entropy models. In
Proceedings of EMNLP, pages 1–10.

Kenji Sagae and Alon Lavie. 2006. A best-first prob-
abilistic shift-reduce parser. In Proceedings of ACL
(poster).

1034



Masaru Tomita. 1988. Graph-structured stack and natu-
ral language parsing. In Proceedings of the 26th an-
nual meeting on Association for Computational Lin-
guistics, pages 249–257, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.

Zhiguo Wang and Nianwen Xue. 2014. Joint pos tag-
ging and transition-based constituent parsing in chi-
nese with non-local features. In Proceedings of ACL.

Yue Zhang and Stephen Clark. 2008. A tale of

two parsers: investigating and combining graph-based
and transition-based dependency parsing using beam-
search. In Proceedings of EMNLP.

Kai Zhao and Liang Huang. 2013. Minibatch and paral-
lelization for online large margin structured learning.
In Proceedings of NAACL 2013.

Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and
Jingbo Zhu. 2013. Fast and accurate shift-reduce con-
stituent parsing. In Proceedings of ACL 2013.

1035


