










































TURKSENT: A Sentiment Annotation Tool for Social Media


Proceedings of the 7th Linguistic Annotation Workshop & Interoperability with Discourse, pages 131–134,
Sofia, Bulgaria, August 8-9, 2013. c©2013 Association for Computational Linguistics

TURKSENT: A Sentiment Annotation Tool for Social Media

Gülşen Eryiǧit
Dep. of Computer Eng.

Istanbul Technical University
gulsen.cebiroglu@itu.edu.tr

Fatih Samet Çetin and Meltem Yanık
Dep. of Information Technology

Turkcell Global Bilgi
fatih.cetin@global-bilgi.com.tr

meltem.yanik@global-bilgi.com.tr

Tanel Temel
Dep. of Information Technology

Turkcell Global Bilgi
tanel.temel@global-bilgi.com.tr

İlyas Çiçekli
Dep. of Computer Eng.
Hacettepe University

ilyas@cs.hacettepe.edu.tr

Abstract

In this paper, we present an annotation tool
developed specifically for manual senti-
ment analysis of social media posts. The
tool provides facilities for general and tar-
get based opinion marking on different
type of posts (i.e. comparative, ironic,
conditional) with a web based UI which
supports synchronous annotation. It is
also designed as a SaaS (Software as a
Service). The tool’s outstanding features
are easy and fast annotation interface, de-
tailed sentiment levels, multi-client sup-
port, easy to manage administrative mod-
ules and linguistic annotation capabilities.

1 Introduction

Today, monitoring social media is a vital need for
companies and it has a high commercial value. So
almost all companies have social media accounts
and departments for following the social media
about their business sectors. In recent decade,
the studies on sentiment analysis has gained high
popularity and several academic (Pang and Lee,
2007; Liu, 2012) and commercial (Radian6, 2013;
Lithium, 2013) projects emerged in this field. Al-
though there are many works (Bosco et al., 2013;
Wiebe et al., 2005) on creating sentiment corpora,
up to our knowledge there are no publicly avail-
able and professional sentiment annotation tools.

A huge contact center communicates with the
customers for different trade marks on behalf
of them and provides detailed CRM1, impact

1CRM: Customer Relationship Management

and competitor analysis reports. With this pur-
pose, they employ thousands of customer rep-
resentatives among which an increasing percent-
age should deal with social media monitoring, the
new channel of communication. In such an envi-
ronment, the monitoring should be done via pro-
fessional and synchronous UIs (user interfaces)
where the performance of each human agent has
high importance. Most of the current commercial
monitoring tools leaks the following features:

- a detailed sentiment analysis interface for
feature based and comparative opinion dec-
larations,

- an effective and synchronous annotation in-
terface,

- on-demand data loading,

- linguistic annotation modules,

- detailed data analyses for corpus creation (to
be used in supervised machine learning).

The aim of our work is to fulfill all of the above
listed requirements and provide a platform for ef-
fective annotation of social media data. The tool
has the following sentiment and linguistic annota-
tion layers:

- general and target based sentiment

- text normalization

- named entity

- morphology

- syntax

The sentiment annotation module of TURK-
SENT may operate multilingually whereas the lin-
guistic annotation module is initially configured

131



specific to Turkish following the work in ITU
Treebank Annotation Tool (Eryiğit, 2007). It is
also possible to adapt this part to other languages
by plugging relevant linguistic adapters (for semi-
automatic annotation).

TURKSENT will be freely available for aca-
demic projects as a SaaS.

Figure 1: Application Flow

2 Architecture

Figure 1 gives an idea about the flow of our appli-
cation. In our system, the web data is monitored
continuously. It is first of all filtered according
to the target sector by the “sector filter” and it is
then stored in the relevant database domains. In
our system, each domain represents a workspace
which consists of the related sector data (collected
via web or uploaded manually to the system), an
administrator and a bunch of human annotators.

2.1 Sentiment Annotation

Our choice of SaaS design has the following goals:

- Platform independence (No special machine
or no special operating system)

- Accessibility (Accessible from anywhere
anytime by multiple users)

- No installation effort (Browser based appli-
cation)

- No need to deploy updates to clients

Figure 2 gives a sample sentiment annota-
tion screen-shot on an example Tweet (“Samsung
Galaxy S4’s hardware features are amazing but
software is not stable as Iphone”). The upper
half of the screen (up to the table) show the gen-
eral sentiment part which is tagged as both2 (the
ambivalent smiley). General sentiment tagging
means identifying the sentimental class regardless
of a target. In other words, extracting dominant
sentimental class of an instance. In this stage the
annotator is also expected to select an appropriate
comment category and sentence type.

The lower half is for target based sentiment an-
notation. These deep sentiments are represented
as tuples consisting of the brand, product/service,
feature and sentiment tags. For example, the first
tuple in the sample Tweet will be composed as
the following: <Samsung, Galaxy S4, hardware,
positive> which means the hardware feature of the
Samsung Brand’s product Galaxy S4 had a posi-
tive impact on the Tweet’s author.

2.2 Linguistic Annotation

Recent researches on sentiment analysis show that
it is not possible to really understand the sentiment
of a sentence without any natural language pro-
cessing (NLP). And the addition of NLP features
to these systems increases the success ratios of
the automatic analyzers dramatically. In order to
be able to prepare a sentiment corpus, being able
to annotate the focus data within the same plat-
form is an important issue. Furthermore, the web
data has severe differences when compared to for-
mal natural language text and it needs additional
preprocessing before linguistic phases. With this
need, we added a linguistic annotation interface to
our application which is basically a reimplementa-
tion and adaptation of a previous academic study
(Eryiğit, 2007) according to our needs.

In this layer, the linguistic expert annotator is
asked to first normalize the instances (i.e. mis-
spellings, exaggerations, web jargon), and then de-
termine the entities (ex: “Galaxy S4”), select the
appropriate postag categories for words and anno-
tate the syntactic parts of a post. It is also possible
to operate this layer semi-automatically by using
the pretrained linguistic tools and outputting their

2Other options are: positive, negative and neutral(no sen-
timental expression at all).

132



Figure 2: Sentiment annotation

results to the human experts and taking their cor-
rections. This speed-up procedure is only avail-
able for Turkish now, but the tool is developed as
a pluggable architecture to support further studies
on other languages. Figure 3 shows some sample
screenshots for the linguistic layer.

2.3 Administrative Operations

TURKSENT has a simple and easy-to-use admin
interface. A user who has administration rights has
the ability to perform the actions listed below:

- Creating a workspace (with a focus data and
annotator group)

- Determining the data subsets for linguistic
annotation

- Controlling/Changing the ongoing annota-
tions

- Defining configurable items (sentence types,
comment categories, product/service list, fea-
ture list, brand list)

- Defining linguistic tags (pos tags, named en-
tity types, dependency types)

3 Usability

The usability is seriously taken into account dur-
ing the design and development of our application.
The spent time per post is a high concern within
big operations. End-user software tests are accom-
plished and observed for each step. On the final
UI design, every action can be done via keyboard
without the need of mouse usage. Almost every
text areas has strong auto-completion feature in it-
self. While an annotator is working on an issue,
it is possible to deliver any idea-suggestion to the
administrator within seconds. And if an annotator
need to browse his/her previous annotations, can
easily search and find within them.

4 Conclusion

In this work, we presented a professional sen-
timent annotation tool TURKSENT which sup-
ports synchronous annotations on a web-based
platform. The study is a part of an automatic sen-
timent analysis research project. That is why, it
both aims to manually annotate the sentiments of
web posts and to create a sentiment corpus also
annotated linguistically (to be used in automatic

133



Figure 3: Linguistic Annotations

sentiment analysis). With this purpose it consists
different layers of annotation specific to web data.
It serves as a SaaS and designed as dynamic as
possible for future use on different sectors and lan-
guages.

Acknowledgment

This work is accomplished as a part of a
TUBITAK-TEYDEB (The Scientific and Tech-
nological Research Council of Turkey - Tech-
nology and Innovation Funding Programs Direc-
torate) project (grant number: 3120605) in “Turk-
cell Global Bilgi” Information Technology De-
partment. The authors want to thank Derya
Dönmez and Mehmet Osmanoğlu for design and
implementation.

References
Cristina Bosco, Viviana Patti, and Andrea Bolioli.

2013. Developing corpora for sentiment analysis
and opinion mining: the case of irony and senti-tut.
Intelligent Systems.

Gülşen Eryiğit. 2007. ITU Treebank Annotation Tool.
In Proceedings of the ACL workshop on Linguistic
Annotation (LAW 2007), Prague, 24-30 June.

Lithium. 2013. Lithium. http://www.lithium.
com/.

Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Synthesis Lectures on Human Language Tech-
nologies. Morgan and Claypool Publishers.

Bo Pang and Lillian Lee. 2007. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1-2):1–135.

Radian6. 2013. Radian 6. http://www.
salesforcemarketingcloud.com/
products/social-media-listening/.

Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005. Annotating expressions of opinions and emo-
tions in language. Language Resources and Evalu-
ation, 39(2-3):165–210.

134


