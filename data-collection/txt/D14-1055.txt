



















































Positive Unlabeled Learning for Deceptive Reviews Detection


Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 488–498,
October 25-29, 2014, Doha, Qatar. c©2014 Association for Computational Linguistics

Positive Unlabeled Learning for Deceptive Reviews Detection

Yafeng Ren Donghong Ji Hongbin Zhang
Computer School
Wuhan University

Wuhan 430072, China
{renyafeng,dhji,zhanghongbin}@whu.edu.cn

Abstract

Deceptive reviews detection has attract-
ed significant attention from both business
and research communities. However, due
to the difficulty of human labeling need-
ed for supervised learning, the problem re-
mains to be highly challenging. This pa-
per proposed a novel angle to the prob-
lem by modeling PU (positive unlabeled)
learning. A semi-supervised model, called
mixing population and individual proper-
ty PU learning (MPIPUL), is proposed.
Firstly, some reliable negative examples
are identified from the unlabeled dataset.
Secondly, some representative positive ex-
amples and negative examples are gener-
ated based on LDA (Latent Dirichlet Al-
location). Thirdly, for the remaining un-
labeled examples (we call them spy ex-
amples), which can not be explicitly iden-
tified as positive and negative, two simi-
larity weights are assigned, by which the
probability of a spy example belonging to
the positive class and the negative class
are displayed. Finally, spy examples and
their similarity weights are incorporated
into SVM (Support Vector Machine) to
build an accurate classifier. Experiments
on gold-standard dataset demonstrate the
effectiveness of MPIPUL which outper-
forms the state-of-the-art baselines.

1 Introduction

The Web has dramatically changed the way peo-
ple express themselves and interact with others,
people frequently write reviews on e-commerce
sites, forums and blogs to achieve these purpos-
es. For NLP (Natural Language Processing), these
user-generated contents are of great value in that
they contain abundant information related to peo-

ple’s opinions on certain topics. Currently, on-
line reviews on products and services are used
extensively by consumers and businesses to con-
duct decisive purchase, product design and mar-
keting strategies. Hence, sentiment analysis and
opinion mining based on product reviews have
become a popular topic of NLP (Pang and Lee,
2008; Liu, 2012). However, since reviews infor-
mation can guide people’s purchase behavior, pos-
itive reviews can result in huge economic benefit-
s and fame for organizations or individuals. This
leaves room for promoting the generation of re-
view spams. Through observations and studies of
the predecessors (Jindal and Liu, 2008; Ott et al.,
2011), review spams are divided into the following
two classes:

• Deceptive Reviews: Those deliberately mis-
lead readers by giving undeserving positive
reviews to some target objects in order to pro-
mote the objects, or by giving unjust nega-
tive reviews to some target objects in order to
damage their reputation.

• Disruptive Reviews: Those are non-reviews,
which mainly include advertisements and
other irrelevant reviews containing no opin-
ion.

Disruptive reviews pose little threat to peo-
ple, because human can easily identify and ignore
them. In this paper, we focus on the more chal-
lenging ones: deceptive reviews. Generally, de-
ceptive reviews detection is deemed to be a classi-
fication problem (Ott et al., 2011; Li et al., 2011;
Feng et al., 2012). Based on the positive and neg-
ative examples annotated by people, supervised
learning is utilized to build a classifier, and then an
unlabeled review can be predicted as deceptive re-
view or truthful one. But the work from Ott et al.
(2011) shows that human cannot identify decep-
tive reviews from their prior knowledge, which in-
dicates that human-annotated review datasets must

488



include some mislabeled examples. These exam-
ples will disturb the generation ability of the clas-
sifiers. So simple supervised learning is regarded
as unsuitable for this task.

It is difficult to come by human labeling need-
ed for supervised learning and evaluation, we can-
not obtain the datasets containing deceptive re-
views. However, we can get some truthful reviews
with high confidence by heuristic rules and prior
knowledge. Meanwhile, a lot of unlabeled reviews
are available. The problem thus is this: based on
some truthful reviews and a lot of unlabeled re-
views, can we build an accurate classifier to iden-
tify deceptive reviews.

PU (positive unlabeled) learning can be utilized
to deal with the above situation (Liu et al., 2002;
Liu et al., 2003). Different from traditional super-
vised learning, PU learning can still build an ac-
curate classifier even without the negative training
examples. Several PU learning techniques have
been applied successfully in document classifica-
tion with promising results (Zhang, 2005; Elkan
and Noto, 2008; Li et al., 2009; Xiao et al., 2011),
while they have yet to be applied in detecting de-
ceptive reviews. Here, we will study how to design
PU learning to detect deceptive reviews.

An important challenge is how to deal with
spy examples (easily mislabeled) of unlabeled re-
views, which is not easily handled by the previous
PU learning techniques. In this paper, we propose
a novel approach, mixing population and individ-
ual property PU learning (MPIPUL), by assigning
similarity weights and incorporating weights into
SVM learning phase. This paper makes the fol-
lowing contributions:

• For the first time, PU learning is defined in
the environment of identifying deceptive re-
views.

• A novel PU learning is proposed based on L-
DA and SVM.

• Experimental results demonstrate that our
proposed method outperforms the curren-
t baselines.

2 Related Work

2.1 Deceptive Reviews Detection

Spam has historically been investigated in the con-
texts of e-mail (Drucker et al., 1999; Gyongyi et
al., 2004) and the Web (Ntoulas et al., 2006). In

recent years, researchers have started to look at de-
ceptive reviews.

Jindal and Liu (2008) found that opinion s-
pam was widespread and different from e-mail
and Web spam in essence (Jindal and Liu, 2008).
They trained models using product review data,
by defining features to distinguish duplicate opin-
ion and non-duplicate based on the review tex-
t, reviewers and product information. Wu et al.
(2010) proposed an alternative strategy of popu-
larity rankings (Wu et al., 2010).

Ott et al. (2011) developed the first dataset con-
taining gold-standard deceptive reviews by crowd-
sourcing (Ott et al., 2011), and presented three su-
pervised learning methods to detect deceptive re-
views by integrating knowledge from psycholin-
guistics and computational linguistics. This gold-
standard dataset will be used in the paper. Li et al.
(2011) manually built a review dataset from their
crawled reviews (Li et al., 2011), and exploited
semi-supervised co-training algorithm to identify
deceptive reviews.

Feng et al. (2012) verified the connection be-
tween the deceptive reviews and the abnormal dis-
tributions (Feng et al., 2012a). Later, they (Feng et
al., 2012b) demonstrated that features driven from
CFG (Context Free Grammar) parsing trees con-
sistently improve the detection performance.

Mukherjee et al. (2012) proposed detect-
ing group spammers (a group of reviewers who
work collaboratively to write deceptive reviews) in
product reviews (Mukherjee et al., 2012). The pro-
posed method first used frequent itemset mining
to find a set of candidate groups. Then GSRank
was presented which can consider relationships a-
mong groups, individual reviewers and products
they reviewed to detect spammer groups. Later,
they also proposed exploiting observed reviewing
behaviors to detect opinion spammers in an unsu-
pervised Bayesian inference framework (Mukher-
jee et al., 2013).

Ren et al. (2014) assumed that there must be
some difference on language structure and sen-
timent polarity between deceptive reviews and
truthful ones (Ren et al., 2014a), then they de-
fined the features related to the review text and
used genetic algorithm for feature selection, fi-
nally they combined two unsupervised clustering
algorithm to identify deceptive reviews. Later,
they (Ren et al., 2014b) present a new approach,
from the viewpoint of correcting the mislabeled

489



examples, to find deceptive reviews. Firstly, they
partition a dataset into several subsets.Then they
construct a classifier set for each subset and s-
elect the best one to evaluate the whole dataset.
Meanwhile, error variables are defined to compute
the probability that the examples have been mis-
labeled. Finally, the mislabeled examples are cor-
rected based on two threshold schemes, majority
and non-objection.

Unlike previous studies, PU learning is imple-
mented to identify deceptive reviews.

2.2 Positive Unlabeled Learning

According to the use of the unlabeled data, PU
learning can be divided into two classes.

One family of methods built the final classifier
by using positive examples dataset and some ex-
amples of the unlabeled dataset (Liu et al., 2002;
Liu et al., 2003). The basic idea is to find a set
of reliable negative examples from the unlabeled
data firstly, and then to learn a classifier using EM
(Expectation Maximization) or SVM. The perfor-
mance is limited for neglecting the rest examples
of unlabeled dataset.

Another family of methods learned the final
classifier by using positive examples dataset and
all examples of the unlabeled dataset. Li et al.
(Li et al., 2009) studied PU learning in the data
stream environment, they proposed a PU learn-
ing LELC (PU Learning by Extracting Likely
positive and negative micro-Clusters) for docu-
ment classification, they assume that the exam-
ples close together shared the same labels. Xi-
ao et al. (Xiao et al., 2011) proposed a method,
called SPUL (similarity-based PU learning), the
local similarity-based and global similarity-based
mechanisms are proposed to generate the similar-
ity weights for the easily mislabeled examples,
respectively. Experimental results show global
SPUL generally performs better than local SPUL.

In this paper, a novel PU learning (MPIPUL) is
proposed to identify deceptive reviews.

3 Preliminary

Before we introduce the proposed method, we
briefly review SVM, which has proven to be an
effective classification algorithm (Vapnik, 1998).

Let T = {(x(1), y(1)), (x(2), y(2)), . . . , (x(|T |), y(|T |)
)} be a training set, where x(i) ∈ Rd and
y(i) ∈ {+1,−1}. SVM aims to seek an optimal
separating hyperplane wT x(i) + b = 0, the hyper-

plane can be obtained by solving the following
optimization problem:

min F (w, b, ϵi) =
1
2
||w||2 + C

|T |∑
i=1

ϵi

s.t. y(i)(wT x(i) + b) ≥ 1− ϵi, i = 1, . . . , |T |
ϵi ≥ 0, i = 1, . . . , |T |

(1)

where wT represents the transpose of w, C is a
parameter to balance the classification errors and
ϵi are variables to relax the margin constraints.
The optimal classifier can be achieved by using
the Lagrange function. For a test example x, if
wT x+b < 0, it is classified into the negative class;
otherwise, it is positive.

In the following, SVM is extended to incorpo-
rate the spy examples and their weights, such that
the spy examples can contribute differently to the
classifier construction.

4 The Proposed Method

In this section, we will introduce the proposed ap-
proach in details. In our PU learning (MPIPUL),
truthful reviews are named positive examples, and
deceptive reviews are called negative examples. P
is defined as a set which contains all positive ex-
amples. U is a set for all unlabeled examples. PU
learning aims at building a classifier using P and
U . MPIPUL adopts the following four steps:

• Step 1: Extract the reliable negative exam-
ples;

• Step 2: Compute the representative positive
and negative examples;

• Step 3: Generate the similarity weights for
the spy examples;

• Step 4: Build the final SVM classifier;
4.1 Extracting Reliable Negative Examples
Considering only positive and unlabeled examples
are available in PU learning, some negative ex-
amples need to be extracted firstly. These exam-
ples will influence the performance of the follow-
ing three steps. So high-quality negative examples
must be guaranteed. Previous works solved the
problem with the Spy technique (Liu et al., 2002)
or the Rocchio technique (Liu et al., 2003), we in-
tegrate them in order to get reliable negative ex-
amples. Let subsets NS1 and NS2 contain the

490



corresponding reliable negative examples extract-
ed by the two techniques, respectively. Examples
are considered to be a reliable negative only if both
techniques agree that they are negative. That is,
NS = NS1 ∩ NS2, where NS contains the reli-
able negative examples.

After reliable negative examples are extracted,
there are still some unlabeled examples (we call
spy examples) in set U , let subset US = U −NS,
which stores all the spy examples. It is crucial to
determine how to deal with these spy examples.

4.2 Computing Representative Positive and
Negative Examples

Generally, a classifier can be constructed to pre-
dict deceptive reviews based on the positive ex-
amples set P and the reliable negative examples
set NS. But the classifier is not accurate enough
for lacking of making full use of unlabeled dataset
U . In order to utilize spy examples in subset US,
some representative positive and negative exam-
ples are calculated firstly. Since the examples have
different styles in sentiment polarity and topic dis-
tribution, for every class, computing one repre-
sentative example is not suitable. For the posi-
tive class or the negative class, to ensure there is
a big difference between the different representa-
tive examples. This paper proposes clustering re-
liable negative examples into several groups based
on LDA (Latent Dirichlet Allocation) topic mod-
el and K-means, and then multiple representative
examples can be obtained.

LDA topic model is known as a parametric
Bayesian clustering model (Blei et al., 2003), and
assumes that each document can be represented
as the distribution of several topics, each docu-
ment is associated with common topics. LDA can
well capture the relationship between internal doc-
uments.

In our experiments based on LDA model, we
can get the topic distribution for the reliable neg-
ative examples, then some reliable negative exam-
ples which are similar in topic distribution will be
clustered into a group by K-means. Finally, these
reliable negative examples can be clustered into n
micro-clusters (NS1, NS2, . . . , NSn). Here,

n = 30 ∗ |NS|/(|US|+ |NS|) (2)
Here, according to the suggestion of previous
work (Xiao et al., 2011), we examine the impact
of the different parameter (from 10 to 60) on over-
all performance, and select the best value 30.

Based on the modified Rocchio formula (Buck-
ley et al., 1999), n representative positive exam-
ples (pk) and n negative ones (nk) can be obtained
using the following formula:

pk = α
1
|P |

|P |∑
i=1

x(i)

∥ x(i) ∥ − β
1

|NSk|
|NSk|∑
i=1

x(i)

∥ x(i) ∥

nk = α
1

|NSk|
|NSk|∑
i=1

x(i)

∥ x(i) ∥ − β
1
|P |

|P |∑
i=1

x(i)

∥ x(i) ∥
k = 1, . . . , n

(3)

According to previous works (Buckley et al.,
1994), where the value of α and β are set to 16
and 4 respectively. The research from Buckley et
al. demonstrate that this combination emphasizes
occurrences in the relevant documents as opposed
to non-relevant documents.

4.3 Generating Similarity Weights
For a spy example x, since we do not know which
class it should belong to, enforcing x to the posi-
tive class or the negative class will lead to some
mislabeled examples, which disturbs the perfor-
mance of final classifier. We represent a spy ex-
ample x using the following probability model:

{x, (p+(x), p−(x))}, p+(x) + p−(x) = 1 (4)
Where p+(x) and p−(x) are similarity weight-
s which represent the probability of x belonging
to the positive class and the negative class, re-
spectively. For example, {x, (1, 0)} means that x
is positive, while {x, (0, 1)} indicates that x is i-
dentified to be negative. For {x, (p+(x), p−(x))},
where 0 < p+(x) < 1 and 0 < p−(x) < 1, it
implies that the probability of x belonging to the
positive class and the negative class are both con-
sidered.

In this section, similarity weights are decided by
mixing global information (population property)
and local information (individual property). Then
all spy examples and their similarity weights are
incorporated into a SVM-based learning model.

4.3.1 Population Property
Population property means that the examples in
each micro-cluster share the similarity in sen-
timent polarity and topic distribution, and they
belong to the same category with a high pos-
sibility. In our framework, in order to com-
pare with the representative examples, all spy ex-
amples are firstly clustered into n micro-clusters

491



(US1, US2, . . . , USn) based on LDA and K-
means. Then, for every spy example x in one
micro-cluster USi, we tags with temporary label
by finding its most similar representative example.
Finally, we can get the similarity weights for a spy
example x in micro-cluster USi, their probability
pertaining to the positive class and negative class
can be represented by the following formula:

p pop(x) =
|positive|
|USi|

n pop(x) =
|negative|
|USi|

(5)

where |USi| represents the number of all examples
in micro-cluster USi, |positive| means the num-
ber of the examples which is called temporary pos-
itive in USi, and |negative| means the number of
the examples which is called temporary negative
in USi.

For example, Figure 1 shows the part (C1, C2,
C3, C4) of the clustering results for the spy exam-
ples based on LDA and K-means, the examples
x in C4 are assigned with weights p pop(x) =
4
9 , n pop(x) =

5
9 , the examples x in C1 are as-

signed with weights p pop(x) = 1, n pop(x) = 0.

Figure 1: Illustration of population property

The advantage of population property lies in the
fact that it considers the similar relationship be-
tween the examples, from which the same micro-
cluster are assigned the same similarity weight.
However, it cannot distinguish the difference of
examples in one micro-cluster. In fact, the simi-
larity weights of examples from the same micro-
cluster can be different, since they are located
physically different. For example, for the spy ex-
ample y and z in micro-cluster C4, it is apparent-
ly unreasonable that we assign the same similarity
weights to them. So we should join the local in-

formation (individual property) when we are com-
puting the similarity weights for a spy example.

4.3.2 Individual Property
Individual property is taken into account to mea-
sure the relationship between every spy example
and all representative ones. Specifically, for ex-
ample x, we firstly compute its similarity to each
of the representative examples, and then the prob-
ability of the example x belonging to the positive
class and negative class can be calculated using the
following formula:

p ind(x) =
∑n

k=1 sim(x, pk)∑n
k=1(sim(x, pk) + sim(x, nk))

n ind(x) =
∑n

k=1 sim(x, nk)∑n
k=1(sim(x, pk) + sim(x, nk))

(6)

In the above formula,

sim(x, y) =
x · y

||x|| · ||y||
4.3.3 Similarity Weights
A scheme mixing population and individual prop-
erty is designed to generate the similarity weights
of spy examples. Specifically, for spy example x,
their similarity weights can be obtained by the fol-
lowing formula:

p+(x) = λ · p pop(x) + (1− λ) · p ind(x)
p−(x) = λ · n pop(x) + (1− λ) · n ind(x) (7)

Where λ is a parameter to balance the informa-
tion from population property and individual prop-
erty. In the remaining section, we will examine
the impact of the parameter λ on overall perfor-
mance. Meanwhile, it can be easily proved that
p+(x) + p−(x) = 1.

4.4 Constructing SVM Classifier
After performing the third step, each spy example
x is assigned two similarity weights: p+(x) and
p−(x). In this section, we will extend the formu-
lation of SVM by incorporating the examples in
positive set P , reliable negative set NS, spy ex-
amples set US and their similarity weights into a
SVM-based learning model.

4.4.1 Primal Problem
Since the similarity weights p+(x) and p−(x) in-
dicate the probability for a spy example x belong-
ing to the positive class and the negative class, re-
spectively. The optimization formula (1) can be

492



rewritten as the following optimization problem:

min F (w, b, ϵ) =
1
2
||w||2 + C1

|P |∑
i=1

ϵi + C2·

|US|∑
j=1

p+(x(j))ϵj + C3
|US|∑
m=1

p−(x(m))ϵm

+C4
|NS|∑
n=1

ϵn

s.t. y(i)(wT x(i) + b) ≥ 1− ϵi, x(i) ∈ P
y(j)(wT x(j) + b) ≥ 1− ϵj , x(j) ∈ US

y(m)(wT x(m) + b) ≥ 1− ϵm, x(m) ∈ US
y(n)(wT x(n) + b) ≥ 1− ϵn, x(n) ∈ NS

ϵi ≥ 0, ϵj ≥ 0, ϵm ≥ 0, ϵn ≥ 0
(8)

Where C1, C2, C3 and C4 are penalty factors con-
trolling the tradeoff between the hyperplane mar-
gin and the errors, ϵi, ϵj , ϵm and ϵn are the error
terms. p+(x(j))ϵj and p−(x(m))ϵm can be consid-
ered as errors with different weights. Note that,
a bigger value of p+(x(j)) can increase the effect
of parameter ϵj , so that the corresponding example
x(j) becomes more significant towards the positive
class. In the following, we will find the dual form
to address the above optimization problem.

4.4.2 Dual Problem

Assume αi and αj are Lagrange multipliers. To
simplify the presentation, we redefine some nota-
tions as follows:

C+i =

{
C1, x

(i) ∈ P
C2p

+(x(j)), x(j) ∈ US

C−j =

{
C3p

−(x(m)), x(m) ∈ US
C4, x

(n) ∈ NS

Based on the above definitions, we let T+ =
P ∪ US, T− = US ∪ NS and T ∗ = T+ ∪ T−.
The Wolfe dual of primal formulation can be ob-
tained as follows (Appendix A for the calculation

process):

max W (α) =
|T ∗|∑
i=1

αi − 12
|T ∗|∑

i=1,j=1

αiαjy
(i)·

y(j) < x(i), x(j) >

s.t. C+i ≥ αi ≥ 0, x(i) ∈ T+
C−j ≥ αj ≥ 0, x(j) ∈ T−

|T+|∑
i=1

αi −
|T−|∑
j=1

αj = 0

(9)

where < x(i), x(j) > is the inner product of x(i)

and x(j). In order to get the better performance, we
can replace them by using kernel function ϕ(x(i))
and ϕ(x(j)), respectively. The kernel track can
convert the input space into a high-dimension fea-
ture space. It can solve the uneven distribution of
dataset and complex problem from heterogeneous
data sources, which allows data to get a better ex-
pression in the new space (Lanckriet et al., 2004;
Lee et al., 2007).

After solving the above problem, w can be ob-
tained, then b can also be obtained by using KKT
(Karush-Kuhn-Tucker) conditions. For a test ex-
ample x, if wT x+ b > 0, it belongs to the positive
class. Otherwise, it is negative.

5 Experiments

We aim to evaluate whether our proposed PU
learning can identify deceptive reviews properly.
We firstly describe the gold-standard dataset, and
then introduce the way to generate the positive
examples P and unlabeled examples U . Finally
we present human performance in gold-standard
dataset.

5.1 Datasets
There is very little progress in detection of de-
ceptive reviews, one reason is the lack of stan-
dard dataset for algorithm evaluation. The gold-
standard dataset is created based on crowdsourc-
ing platform (Ott et al., 2011), which is also adopt-
ed as the experimental dataset in this paper.

5.1.1 Deceptive Reviews
Crowdsourcing services can carry out massive da-
ta collection and annotation; it defines the task in
the network platform, and paid for online anony-
mous workers to complete the task.

493



Humans cannot be precisely distinguish decep-
tive ones from existing reviews, but they can create
deceptive reviews as one part of the dataset. Ott et
al. (2011) accomplish this work by AMT (Ama-
zon Mechanical Turk). They set 400 tasks for 20
hotels, in which each hotel gets 20 tasks. Specif-
ic task is: If you are a hotel market department
employee, for each positive review you wrote for
the benefit for hotel development, you may get one
dollar. They collect 400 deceptive reviews.

5.1.2 Truthful Reviews
For the collection of truthful reviews, they get
6977 reviews from TripAdvisor1 based on the
same 20 Chicago hotels, and remove some reviews
on the basis of the following constraints:

• Delete all non-five star reviews;
• Delete all non-English reviews;
• Delete all reviews which are less than 75

characters;

• Delete all reviews written by first-time au-
thors;

2124 reviews are gathered after filtering. 400 of
them are chosen as truthful ones for balancing the
number of deceptive reviews, as well as maintain-
ing consistent with the distribution of the length of
deceptive reviews. 800 reviews constitute whole
gold-standard dataset at last.

5.2 Experiment Setup
We conduct 10-fold cross-validation: the dataset
is randomly split into ten folds, where nine fold-
s are selected for training and the tenth fold for
test. In training dataset, it contains 360 truthful
reviews and 360 deceptive ones. This paper is in-
tended to apply PU learning to identify deceptive
reviews. We specially make the following setting:
take 20% of the truthful reviews in training set as
positive examples dataset P , all remaining truthful
and deceptive reviews in training set as the unla-
beled dataset U . Therefore, during one round of
the algorithm, the training set contains 720 exam-
ples including 72 positive examples (set P ) and
648 unlabeled examples (set U ), and the test set
contains 80 examples including 40 positive and 40
negative ones. In order to verify the stability of
the proposed method, we also experiment anoth-
er two different settings, which account for 30%

1http://www.tripadvisor.com

and 40% of the truthful reviews in training set as
positive examples dataset P respectively.

5.3 Human Performance

Human performance reflects the degree of difficul-
ty to address this task. The rationality of PU learn-
ing is closely related to human performance.

We solicit the help of three volunteer students,
who were asked to make judgments on test sub-
set (corresponding to the tenth fold of our cross-
validation experiments, contains 40 deceptive re-
views and 40 truthful reviews). Additionally, to
test the extent to which the individual human
judges are biased, we evaluate the performance of
two virtual meta-judges: one is the MAJORITY
meta-judge when at last two out of three human
judge believe the review to be deceptive, and the
other is the SKEPTIC when any human judge be-
lieves the review to be deceptive. It is apparent
from the results that human judges are not par-
ticularly effective at this task (Table 1). Inter-
annotator agreement among the three judges, com-
puted using Fleiss’ kappa, is 0.09. Landis and
Koch (Landis and Koch, 1977) suggest that s-
cores in the range (0.00, 0.20) correspond to “s-
light agreemen” between annotators. The largest
pairwise Cohen’s kappa is 0.11 between JUDGE-
1 and JUDGE-3, far below generally accepted
pairwise agreement levels. We can infer that the
dataset which are annotated by people will include
a lot of mislabeled examples. Identifying decep-
tive reviews by simply using supervised learning
methods is not appropriate. So we propose ad-
dressing this issue by using PU learning.

Table 1: Human performance
Methods Accuracy (%)

Human
JUDGE-1 57.9
JUDGE-2 55.4
JUDGE-3 61.7

META
MAJORITY 58.3
SKEPTIC 62.4

6 Results and Analysis

In order to verify the effectiveness of our proposed
method, we perform two PU learning (LELC and
SPUL) in the gold-standard dataset.

494



6.1 Experimental Results

Table 2 shows that the experimental results com-
pared with different PU learning techniques. In
Table 2, P (20%) means that we randomly select
20 percentages of truthful reviews to form the pos-
itive examples subset P . In our MPIPUL frame-
work, we set λ = 0.3. We can see that our pro-
posed method can obtain 83.91%, 85.43% and
86.69% in accuracy from different experimental
settings, respectively. Compared to the curren-
t best method (SPUL-global), the accuracy can be
improved 2.06% on average. MPUPUL can im-
prove 3.21% on average than LELC. The above
discussion shows our proposed methods consis-
tently outperform the other PU baselines.

Table 2: Accuracy on the different PU learning
Baselines P(20%) P(30%) P(40%)
LELC 81.12 82.08 83.21
SPUL-local 81.43 82.71 84.09
SPUL-global 81.89 83.24 84.73
MPIPUL (0.3) 83.91 85.43 86.69

PU learning framework in this paper can obtain
the better performance. Two factors contribute to
the improved performance. Firstly, LDA can cap-
ture the deeper information of the reviews in topic
distribution. Secondly, strategies of mixing pop-
ulation and individual property can generate the
similarity weights for spy examples, and these ex-
amples and their similarity weights are extended
into SVM, which can build a more accurate clas-
sifier.

6.2 Parameter Sensitivity

For the spy examples, the similarity weights are
generated by population property and individual
property. Should we select the more population
information or individual information? In MPIP-
UL, parameter λ is utilized to adjust this process.
So we experiment with the different value of the
parameter λ on MPUPUL performance (Figure 2).

As showed in Figure 2, for P (20%), if λ < 0.3,
the performance increases linearly, if λ > 0.3,
the performance will decrease linearly. Mean-
while, we can get the same trends for P (30%) and
P (40%). Based on the above discussion, MPIP-
UL can get the best performance when λ ≈ 0.3.

Figure 2: Algorithm performance on different pa-
rameter

7 Conclusions and Future Work

This paper proposes a novel PU learning (MPIP-
UL) technique to identify deceptive reviews based
on LDA and SVM. Firstly, the spy examples are
assigned similarity weights by integrating the in-
formation from the population property and in-
dividual property. Then the spy examples and
their similarity weights are incorporated into SVM
learning phase to build an accurate classifier. Ex-
perimental results on gold-standard dataset show
the effectiveness of our method.

In future work, we will discuss the application
of our proposed method in the massive dataset.

Acknowledgments

We are grateful to the anonymous reviewer-
s for their thoughtful comments. This work
is supported by the State Key Program of
National Natural Science Foundation of China
(Grant No.61133012), the National Natural Sci-
ence Foundation of China (Grant No.61173062,
61373108) and the National Philosophy Social
Science Major Bidding Project of China (Grant
No. 11&ZD189).

References
Alexandros Ntoulas, Marc Najork, Mark Manasse, and

Dennis Fetterly. 2006. Detecting spam web pages
through content analysis. In Proceedings of the 15th
International Conference on World Wide Web, page
83-92, Edinburgh, Scotland.

Arjun Mukherjee, Abhinav Kumar, Bing Liu, Junhui
Wang, Meichun Hsu, Malu Castellanos, and Riddhi-
man Ghosh. 2013. Spotting opinion spammers us-
ing behavioral footprints. In Proceeding of the 19th

495



ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Ming, page 632-640, Ly-
on, France.

Arjun Mukherjee, Bing Liu, and Natalie Glance. 2012.
Spotting fake reviewer groups in consumer reviews.
In Proceeding of the 21st International Conference
on World Wide Web, page 191-200, New York, US-
A.

Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Morgan & Claypool Publishers. San Rafael,
USA.

Bing Liu, Wee Sun Lee, Philip S. Yu, and Xiaoli Li.
2002. Partially supervised classification of text doc-
uments. In Proceedings of the 19th International
Conference on Machine Learning, page 387-394,
San Francisco, USA.

Bing Liu, Yang Dai, Xiaoli Li, Wee Sun Lee, and Philip
S. Yu. 2003. Building text classifiers using positive
and unlabeled examples. In Proceedings of the 3rd
IEEE International Conference on Data Ming, page
179-182, Washington, USA.

Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1-2):1-135.

Charles Elkan and Keith Noto. 2008. Learning clas-
sifiers from only positive and unlabeled data. In
Proceedings of the 14th ACM SIGKDD Internation-
al Conference on Knowledge Discovery and Data
Ming, page 213-220, Las Vegas, USA.

Chirs Buckley, Bgrard Salton, and James Allan. 1994.
The effect of adding relevance information in a rele-
vance feedback environment. In Proceedings of the
17th Annual International SIGIR Conference on Re-
search and Development Retrieval, page 292-300,
Dublin, Ireland.

David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Ma-
chine Learning Research, 3:993-1022.

Dell Zhang. 2005. A simple probabilistic approach
to learning from positive and unlabeled examples.
In Proceedings of the 5th Annual UK Workshop on
Computational Intelligence, page 83-87.

Fangtao Li, Minlie Huang, Yi Yang, and Xiaoyan
Zhu. 2011. Learning to identify review spam. In
Proceeding of the 22nd International Joint Confer-
ence on Artificial Intelligence, page 2488-2493,
Barcelona, Spain.

Fang Wu and Bernardo A. Huberman. 2010. Opinion
formation under costly express. ACM Transactions
on Intelligence System Technology, 1(5):1-13.

Gert R. G. Lanckeriet, Nello Cristianini, Peter Bartlet-
t, Laurent EI Ghaoui, and Michael I.Jordan. 2004.
Learning the kernel matrix with seim-difinit pro-
gramming. Journal of Machine Learning Research,
5:27-72.

Harris Drucker, Donghui Wu, and Vladimir N. Vap-
nik. 1999. Support vector machines for spam cate-
gorization. IEEE Transactions on Neural Networks,
10(5):1048-1054.

Kumar Ankita and Sminchisescu Cristian. 2006. Sup-
port kernel machines for object recognition. In Pro-
ceedings of the IEEE 11th International Conference
on Computer Vision, page 1-8, Rio de Janeiro, Brza-
il.

Myle Ott, Yelin Choi, Claire Caridie, and Jeffrey T.
Hancock. 2011. Finding deceptive opinion spam
by any stretch of the imagination. In Proceeding
of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
noloies, page 309-319, Portland, USA.

Nitin Jindal and Bing Liu. 2008. Opinion spam and
analysis. In Proceeding of the 1st ACM Interna-
tional Conference on Web Search and Data Mining,
page 137-142, California, USA.

Richard Landis and Gary G. Koch. 1977. The mea-
surement of observer agreement for categorical data.
Biometrics, 33(1):159-174.

Song Feng, Longfei Xing, Anupam Gogar, and Yejin
Choi. 2012. Distributional footprints of deceptive
product reviews. In Proceeding of the 6th Inter-
national AAAI Conference on WebBlogs and Social
Media, page 98-105, Dublin, Ireland.

Song Feng, Ritwik Banerjee, and Yejin Choi. 2012.
Syntactic stylometry for deception detection. In
Proceeding of the 50th Annual Meeting of the As-
sociation for Computational Linguistics, page 171-
175, Jeju Island, Korea.

Vladimir N. Vapnik. 1998. Statistical learning theory.
Springer. New York, USA.

Wanjui Lee, Sergey Verzakov, and Robert P. Duin.
2007. Kernel combination versus classifier com-
bination. In Proceedings of the 7th International
Workshop on Multiple Classifier Systems, page 22-
31, Rrague, Czech Republic.

Xiaoli Li, Philip S. Yu, Bing Liu, and See Kiong Ng.
2009. Positive unlabeled learning for data stream
classification. In Proceedings of the SIAM Inter-
national Conference on Data Ming, page 257-268,
Nevada, USA.

Yafeng Ren, Donghong Ji, Lan Yin, and Hongbin
Zhang. 2014. Finding deceptive opinion spam by
correcting the mislabled instances. Chinese Journal
of Electronics, 23(4):702-707.

Yafeng Ren, Lan Yin, and Donghong Ji. 2014. De-
ceptive reviews detection based on language struc-
ture and sentiment polarity. Journal of Frontiers of
Computer Science and Technology, 8(3):313-320.

496



Yanshan Xiao, Bing Liu, Jie Yin, Longbing Cao,
Chengqi Zhang, and Zhifeng Hao. 2011.
Similarity-based approach for positive and unla-
beled learning. In Proceeding of the 22nd Inter-
national Joint Conference on Artifical Intelligence,
page 1577-1582, Barcelona, Spain.

Zoltan Gyongyi, Hector Garcia-Molina, and Jan
Pedesen. 2004. Combating web spam web with
trustrank. In Proceedings of the 30th International
Conference on Very Large Data Bases, page 576-
587, Toronto, Canada.

Appendix A

The optimization problem is as follows:

min F (w, b, ϵ) =
1
2
||w||2 + C1

|P |∑
i=1

ϵi + C2·

|US|∑
j=1

p+(x(j))ϵj + C3
|US|∑
m=1

p−(x(m))ϵm+

C4

|NS|∑
n=1

ϵn

s.t. y(i)(wT x(i) + b) ≥ 1− ϵi, x(i) ∈ P
y(j)(wT x(j) + b) ≥ 1− ϵj , x(j) ∈ US

y(m)(wT x(m) + b) ≥ 1− ϵm, x(m) ∈ US
y(n)(wT x(n) + b) ≥ 1− ϵn, x(n) ∈ NS

ϵi ≥ 0, ϵj ≥ 0, ϵm ≥ 0, ϵn ≥ 0
(10)

We construct the Lagrangian function for the
above optimization problem, we have:

L(w, b, ϵ, α, γ) = F (w, b, ϵ) +
|P |∑
i=1

αi[−y(i)·

(wT x(i) + b) + 1− ϵi] +
|US|∑
j=1

αj [−y(j)(wT x(j)+

b) + 1− ϵj ] +
|US|∑
m=1

αm[−y(m)(wT x(m) + b) + 1

−ϵm] +
|NS|∑
n=1

αn[−y(n)(wT x(n) + b) + 1− ϵn]−

|P |∑
i=1

γiϵi −
|US|∑
j=1

γjϵj −
|US|∑
m=1

γmϵm −
|NS|∑
n=1

γnϵn

(11)

Here, the α and γ are Lagrange multipliers. To
find the dual form of the problem, we need to first

minimize L(w, b, ϵ, α, γ) with respect to w and b,
we will do by setting the derivatives of L with re-
spect to w and b to zero, we have:

∂L(w, b, ϵ, α, γ)
∂w

= w −
|P |∑
i=1

αiy
(i)x(i) −

|US|∑
j=1

αjy
(j)x(j) −

|US|∑
m=1

αmy
(m)x(m) −

|NS|∑
n=1

αny
(n)·

x(n) = 0
(12)

This implies that

w =
|P |∑
i=1

αiy
(i)x(i) +

|US|∑
j=1

αjy
(j)x(j) +

|US|∑
m=1

αm·

y(m)x(m) +
|NS|∑
n=1

αny
(n)x(n)

(13)

Here, to simplify the presentation, we redefine
some notations in the following:

T+ = P ∪ US, T− = US ∪NS, T ∗ = T+ ∪ T−

C+i =

{
C1, x

(i) ∈ P
C2p

+x(j), x(j) ∈ US

C−j =

{
C3p

−x(m), x(m) ∈ US
C4, x

(n) ∈ NS
so we obtain

w =
|T ∗|∑
i=1

αiy
(i)x(i) (14)

As for the derivative with respect to b, we obtain

∂L(w, b, ϵ, α, γ)
∂b

= −
|P |∑
i=1

αiy
(i) −

|US|∑
j=1

αjy
(j)

−
|US|∑
m=1

αmy
(m) −

|NS|∑
n=1

αny
(n) = 0

(15)

We get:
|T ∗|∑
i=1

αiy
(i) = 0 (16)

497



If we take Equation (14) and (16) back into the
Lagrangian function (Equation 11), and simplify,
we get

L(w, b, ϵ, α, γ) =
|T ∗|∑
i=1

αi − 12
|T ∗|∑
i,j=1

y(i)y(j)αi·

αj < x
(i), x(j) >

(17)

To the primal optimization formula (10), we can
obtain the following dual optimization problem:

max W (α) =
|T ∗|∑
i=1

αi − 12
|T ∗|∑

i=1,j=1

αiαjy
(i)·

y(j) < x(i), x(j) >

s.t. C+i ≥ αi ≥ 0, x(i) ∈ T+
C−j ≥ αj ≥ 0, x(j) ∈ T−

|T+|∑
i=1

αi −
|T−|∑
j=1

αj = 0

(18)

where < x(i), x(j) > is the inner product of x(i)

and x(j), we can replace them by using kernel
function ϕ(x(i)) and ϕ(x(j)), respectively.

498


