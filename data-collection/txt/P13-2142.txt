



















































Extra-Linguistic Constraints on Stance Recognition in Ideological Debates


Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 816–821,
Sofia, Bulgaria, August 4-9 2013. c©2013 Association for Computational Linguistics

Extra-Linguistic Constraints on Stance Recognition in Ideological Debates

Kazi Saidul Hasan and Vincent Ng
Human Language Technology Research Institute

University of Texas at Dallas
Richardson, TX 75083-0688

{saidul,vince}@hlt.utdallas.edu

Abstract

Determining the stance expressed by an
author from a post written for a two-
sided debate in an online debate forum
is a relatively new problem. We seek to
improve Anand et al.’s (2011) approach
to debate stance classification by model-
ing two types of soft extra-linguistic con-
straints on the stance labels of debate
posts, user-interaction constraints and ide-
ology constraints. Experimental results on
four datasets demonstrate the effectiveness
of these inter-post constraints in improv-
ing debate stance classification.

1 Introduction

While a lot of work on document-level opinion
mining has involved determining the polarity ex-
pressed in a customer review (e.g., whether a re-
view is “thumbs up” or “thumbs down”) (see Pang
and Lee (2008) and Liu (2012) for an overview
of the field), researchers have begun exploring
new opinion mining tasks in recent years. One
such task is debate stance classification: given
a post written for a two-sided topic discussed in
an online debate forum (e.g., “Should abortion be
banned?”), determine which of the two sides (i.e.,
for and against) its author is taking.

Debate stance classification is potentially more
interesting and challenging than polarity classifi-
cation for at least two reasons. First, while in po-
larity classification sentiment-bearing words and
phrases have proven to be useful (e.g., “excellent”
correlates strongly with the positive polarity), in
debate stance classification it is not uncommon to
find debate posts where stances are not expressed
in terms of sentiment words, as exemplified in Fig-
ure 1, where the author is for abortion.

Second, while customer reviews are typically
written independently of other reviews in an on-
line forum, the same is not true for debate posts. In

The fetus is simply a part of the mother’s body and she
can have an abortion because it is her human rights. Also
I take this view because every woman can face with sit-
uation when two lives are at stake and the moral obli-
gation is to save the one closest at hand — namely, that
of the mother, whose life is always more immediate than
that of the unborn child within her body. Permission for
an abortion could then be based on psychiatric consider-
ations such as prepartum depression, especially if there
is responsible psychiatric opinion that a continued preg-
nancy raises the strong probability of suicide in a clini-
cally depressed patient.

Figure 1: A sample post on abortion.

a debate forum, debate posts form threads, where
later posts often support or oppose the viewpoints
raised in earlier posts in the same thread.

Previous approaches to debate stance classifica-
tion have focused on three debate settings, namely
congressional floor debates (Thomas et al., 2006;
Bansal et al., 2008; Balahur et al., 2009; Yesse-
nalina et al., 2010; Burfoot et al., 2011), company-
internal discussions (Murakami and Raymond,
2010), and online social, political, and ideologi-
cal debates in public forums (Agrawal et al., 2003;
Somasundaran and Wiebe, 2010; Wang and Rosé,
2010; Biran and Rambow, 2011; Hasan and Ng,
2012). As Walker et al. (2012) point out, debates
in public forums differ from congressional debates
and company-internal discussions in terms of lan-
guage use. Specifically, online debaters use color-
ful and emotional language to express their points,
which may involve sarcasm, insults, and question-
ing another debater’s assumptions and evidence.
These properties can potentially make stance clas-
sification of online debates more challenging than
that of the other two types of debates.

Our goal in this paper is to improve the state-
of-the-art supervised learning approach to debate
stance classification of online debates proposed by
Anand et al. (2011), focusing in particular on ideo-
logical debates. Specifically, we hypothesize that
there are two types of soft extra-linguistic con-
straints on the stance labels of debate posts that,

816



Number “for” % of posts Average thread
Domain of posts posts (%) in a thread length

ABO 1741 54.9 75.1 4.1
GAY 1376 63.4 74.5 4.0
OBA 985 53.9 57.1 2.6
MAR 626 69.5 58.0 2.5

Table 1: Statistics of the four datasets.

if explicitly modeled, could improve a learning-
based stance classification system. We refer to
these two types of inter-post constraints as user-
interaction constraints and ideology constraints.
We show how they can be learned from stance-
annotated debate posts in Sections 4.1 and 4.2, re-
spectively.

2 Datasets

For our experiments, we collect debate posts
from four popular domains, Abortion (ABO),
Gay Rights (GAY), Obama (OBA), and Marijuana
(MAR), from an online debate forum1. All de-
bates are two-sided, so each post receives one of
two domain labels, for or against, depending on
whether the author of the post supports or opposes
abortion, gay rights, Obama, or the legalization of
marijuana.

We construct one dataset for each domain (see
Table 1 for statistics). The fourth column of the
table shows the percentage of posts in each domain
that appear in a thread. More precisely, a thread
is a tree with one or more nodes such that (1) each
node corresponds to a debate post, and (2) a post yi
is the parent of another post yj if yj is a reply to yi.
Given a thread, we can generate post sequences,
each of which is a path from the root of the thread
to one of its leaves.

3 Baseline Systems

We employ as baselines two stance classification
systems, Anand et al.’s (2011) approach and an en-
hanced version of it, as described below.

Our first baseline, Anand et al.’s approach is a
supervised method that trains a stance classifier
for determining whether the stance expressed in
a debate post is for or against the topic. Hence,
we create one training instance from each post in
the training set, using the stance it expresses as
its class label. Following Anand et al., we repre-
sent a training instance using three types of lexico-
syntactic features, which are briefly summarized
in Table 2. In our implementation, we train the

1http://www.createdebate.com/

Feature type Features
Basic Unigrams, bigrams, syntactic and POS-

generalized dependencies
Sentiment LIWC counts, opinion dependencies
Argument Cue words, repeated punctuation, context

Table 2: Anand et al.’s features.

stance classifier using SVMlight (Joachims, 1999).
After training, we can apply the classifier to clas-
sify the test instances, which are generated in the
same way as the training instances.

Related work on stance classification of con-
gressional debates has found that enforcing au-
thor constraints (ACs) can improve classification
performance (e.g., Thomas et al. (2006), Bansal et
al. (2008), Burfoot et al. (2011), Lu et al. (2012),
Walker et al. (2012)). ACs are a type of inter-
post constraints that specify that two posts written
by the same author for the same debate domain
should have the same stance. We hypothesize that
ACs could similarly be used to improve stance
classification of ideological debates, and therefore
propose a second baseline where we enhance the
first baseline with ACs. Enforcing ACs is simple.
We first use the learned stance classifier to classify
the test posts as in the first baseline, and then post-
process the labels of the test posts. Specifically,
we sum up the confidence values2 assigned to the
set of test posts written by the same author for the
same debate domain. If the sum is positive, then
we label all the posts in this set as for; otherwise
we label them as against.

4 Extra-Linguistic Constraints

In this section, we introduce two types of inter-
post constraints on debate stance classification.

4.1 User-Interaction Constraints

We call the first type of constraints user-
interaction constraints (UCs). UCs are motivated
by the observation that the stance labels of the
posts in a post sequence are not independent of
each other. Consider the post sequence in Fig-
ure 2, where each post is a response to the preced-
ing post. It shows an opening anti-abortion post
(P1), followed by a pro-abortion comment (P2),
which is in turn followed by another anti-abortion
view (P3). While this sequence contains alternat-
ing posts from opposing stances, in general there
is no hard constraint on the stance of a post given

2We use as the confidence value the signed distance of the
associated test point from the SVM hyperplane.

817



[P1: Anti-abortion] There are thousands of people who
want to take these children because they cannot have their
own. If you do not want a child, have it and put it up for
adoption. At least you will be preserving a human life rather
than killing one.

[P2: Pro-abortion] I agree that if people don’t want
their babies, they should have the choice of putting it
up for adoption. But it should not be made compulsory,
which is essentially what happens if you ban abortion.

[P3: Anti-abortion] Why should it not be made
compulsory? Those children have as much right to
live as you and I. Besides, no one loses with adop-
tion, so why wouldn’t you utilize it?

Figure 2: A sample post sequence. P2 and P3 are
replies to P1 and P2, respectively.

the preceding sequence of posts. Nevertheless, we
found that in our training data, a for (against) post
is followed by a against (for) post 80% of the time.

UCs aim to model the regularities in how users
interact with each other in a post sequence as soft
constraints. These kinds of soft constraints can be
naturally encoded as factors over adjacent posts in
a post sequence (see Kschischang et al. (2001)),
which can in turn be learned by recasting stance
classification as a sequence labeling task. In our
experiments, we seek to derive the best sequence
of stance labels for each post sequence of length ≥
1 using a Conditional Random Field (CRF) (Laf-
ferty et al., 2001).

We train the CRF model using the CRF im-
plementation in Mallet (McCallum, 2002). Each
training sequence corresponds to a post sequence.
Each post in a sequence is represented using the
same set of features as in the baselines.

After training, the resulting CRF model can be
used to assign a stance sequence to each test post
sequence. There is a caveat, however. Since a
given test post may appear in more than one se-
quence, different occurrences of it may be as-
signed different stance labels by the CRF. To deter-
mine the final stance label for the post, we average
the probabilities assigned to the for stance over all
its occurrences; if the average is ≥ 0.5, then its
final label is for; otherwise, its label is against.

4.2 Ideology Constraints

Next, we introduce our second type of inter-post
constraints, ideology constraints (ICs). ICs are
cross-domain, author-based constraints: they are
only applicable to debate posts written by the same
author in different domains. ICs model the fact
that for some authors, their stances on various is-
sues are determined in part by their ideological

values, and in particular, their stances on different
issues may be correlated. For example, someone
who opposes abortion is likely to be a conserva-
tive and has a good chance of opposing gay rights.
ICs aim to capture this kind of inter-domain corre-
lation of stances. Below we describe how we im-
plement ICs and show how they can be integrated
with ACs.

4.2.1 Implementing Ideology Constraints

We first compute a set of conditional probabil-
ities, P (stance(dq )=sd|stance(dp)=sc), where (1)
dp, dq ∈ Domains (i.e., the set of four domains),
(2) sc, sd ∈ {for, against}, and (3) dp 6= dq .
To compute P (stance(dq )=sd|stance(dp)=sc), we
(1) determine for each author a in the train-
ing set and each domain dp the stance of a
in dp (denoted by author-stance(dp ,a)), where
author-stance(dp ,a) is computed as the majority
stance labels associated with the debate posts
in the training set that a wrote for dp; and
(2) compute P (stance(dq )=sd|stance(dp)=sc) as
the ratio of

∑
a∈A Count(author-stance(dp ,a)=sc,

author-stance(dq ,a)=sd) to
∑

a∈A Count(author-
stance(dp,a)=sc), where A is the set of authors in
the training set who posted in both dp and dq. It
should be fairly easy to see that these conditional
probabilities measure the degree of correlation be-
tween the stances in different domains.

4.2.2 Inference Using ILP

Recall that in our second baseline, we employ
ACs to postprocess the output of the stance clas-
sifier simply by summing up the confidence val-
ues assigned to the posts written by the same au-
thor for the same debate domain. However, since
we now want to enforce two types of inter-post
constraints (namely, ACs and ICs), we will have
to employ a more sophisticated inference mecha-
nism. Previous work has focused on employing
graph minimum cut (MinCut) as the inference al-
gorithm. However, since MinCut suffers from the
weakness of not being able to enforce negative
constraints (i.e., two posts cannot receive the same
label) (Bansal et al., 2008), we propose to use in-
teger linear programming (ILP) as the underlying
inference mechanism. Below we show how to im-
plement ACs and ICs within the ILP framework.

Owing to space limitations, we refer the reader
to Roth and Yih (2004) for details of the ILP
framework. Briefly, ILP seeks to optimize an
objective function subject to a set of linear con-

818



straints. Below we focus on describing the ILP
program and how the ACs and ICs can be encoded.

Let Y = y1, . . . , yn be the set of debate posts.
For each yi, we create one (binary-valued) indi-
cator variable xi, which will be used in the ILP
program. Let pi = P (for|yi) be the “benefit” of
setting xi to 1, where P (for|yi) is provided by the
CRF. Consequently, after optimization, yi’s stance
is for if its xi is set to 1. We optimize the following
objective function:

max
∑

i

pixi + (1− pi)(1− xi)

subject to a set of linear constraints, which encode
the ACs and the ICs, as described below.

Implementing author constraints. If yi and yj
are composed by the same author, we ensure that
xi and xj will be assigned the same value by em-
ploying the linear constraint |xi − xj| = 0.
Implementing ideology constraints. For con-
venience, below we use the notation introduced in
Section 4.2.1, and assume that yi and yj are two
arbitrary posts written by the same author in do-
mains dp and dq, respectively.
Case 1: If P (stance(dq )=for|stance(dp)=for) ≥ t,
we want to ensure that xi=1 =⇒ xj=1.3 This can
be achieved using the constraint (1−xj) ≤ (1−xi).
Case 2: If P (stance(dq )=against|stance(dp )=against)
≥ t, we want to ensure that xi=0 =⇒ xj=0. This
can be achieved using the constraint xj ≤ xi.
Case 3: If P (stance(dq )=against|stance(dp )=for)
≥ t, we want to ensure that xi=1 =⇒ xj=0. This
can be achieved using the constraint xj ≤ (1−xi).
Case 4: If P (stance(dq )=for|stance(dp)=against)
≥ t, we want to ensure that xi=0 =⇒ xj=1. This
can be achieved using the constraint (1−xj) ≤ xi.

Two points deserve mention. First, cases 3 and
4 correspond to negative constraints, and unlike in
MinCut, they can be implemented easily in ILP.
Second, if ICs are used, one ILP program will be
created to perform inference over the debate posts
in all four domains.

5 Evaluation

5.1 Experimental Setup

Results are expressed in terms of accuracy ob-
tained via 5-fold cross validation, where accuracy

3Intuitively, if this condition is satisfied, it means that
there is sufficient evidence that the two nodes from differ-
ent domains should have the same stance, and so we convert
the soft ICs into (hard) linear constraints in ILP. Note that t is
a threshold to be tuned using development data.

System ABO GAY OBA MAR
Anand 61.4 62.6 58.1 66.9

Anand+AC 72.0 64.9 62.7 67.8
Anand+AC+UC 73.7 69.9 64.1 75.4

Anand+AC+UC+IC 74.9 70.9 72.7 75.4

Table 3: 5-fold cross-validation accuracies.

is the percentage of test instances correctly classi-
fied. Since all experiments require the use of de-
velopment data for parameter tuning, we use three
folds for model training, one fold for development,
and one fold for testing in each fold experiment.

5.2 Results

Results are shown in Table 3. Row 1 shows the
results of the Anand et al. (2011) baseline (see
Section 3) on the four datasets, obtained by train-
ing a SVM stance classifier using the SVMlight

software.4 Row 2 shows the results of the sec-
ond baseline, Anand et al.’s system enhanced with
ACs. As we can see, incorporating ACs into
Anand et al.’s system improves its performance
significantly on all datasets and yields a system
that achieves an average improvement of 4.6 ac-
curacy points.5

Next, we incorporate our first type of con-
straints, UCs, into the better of the two baselines
(i.e., the second baseline). Results of applying the
CRF for modeling UCs to the test posts and post-
processing them using the ACs are shown in row 3
of Table 3. As we can see, incorporating UCs into
the second baseline significantly improves its per-
formance and yields a system that achieves an av-
erage improvement of 3.93 accuracy points.

Finally, we incorporate our second type of con-
straints, ICs, effectively performing inference over
the CRF output using ILP with ACs and ICs as the
inter-post constraints. Results of this experiment
are shown in row 4 of Table 3. As we can see, in-
corporating the ICs significantly improves the per-
formance of the system on all but MAR and yields
a system that achieves an average improvement of
2.7 accuracy points.

Overall, our inter-post constraints yield a stance
classification system that significantly outper-
forms the better baseline on all four datasets, with
an average improvement of 6.63 accuracy points.

4For all SVM experiments, the regularization parameter C
is tuned using development data, but the remaining learning
parameters are set to their default values.

5All significance tests are paired t-tests, with p < 0.05.

819



5.3 Discussion

Next, we make some observations on the results of
applying ICs to our datasets.

First, ICs do not improve the MAR dataset. An
examination of the domains reveals the reason. We
find three pairs of ICs involving the other three do-
mains — ABO, GAY, and OBA — in our training
data. More specifically, the stances of the posts
written by an author for these three domains are
all positively co-related. In other words, if an au-
thor supports abortion, it is likely that she supports
both gay rights and Obama as well. On the other
hand, we find no co-relation between MAR and
the remaining domains. This means that no ICs
can be established between the posts in MAR and
those in the remaining domains.

Second, the improvement resulting from the ap-
plication of ICs is much larger on the OBA dataset
than on ABO and GAY. The reason can be at-
tributed to the fact that ICs exist more frequently
between OBA and ABO and between OBA and
GAY than between ABO and GAY. Specifically,
ICs are seen in all five folds of the data in the
first two pairs of domains, whereas they are seen
in only two folds in the last pair of domains.

6 Related Work

Previous work has investigated the use of extra-
linguistic constraints to improve stance classifica-
tion. Introduced by Thomas et al. (2006), ACs are
arguably the most commonly used extra-linguistic
constraints. Since then, they have been employed
and extended in different ways (see, for example,
Bansal et al. (2008), Burfoot et al. (2011), Lu et al.
(2012), and Walker et al. (2012)).

ICs are different from ACs in at least two re-
spects. First, ICs are softer than ACs, so accu-
rate modeling of ICs has to be based on stance-
annotated data. Although we employ ICs as hard
constraints (owing in part to our use of the ILP
framework), they can be used directly as soft con-
straints in other frameworks, such as MinCut. Sec-
ond, ICs are inter-domain constraints, whereas
ACs are intra-domain constraints. To our knowl-
edge, this is the first time inter-domain constraints
are employed for stance classification.

There has been work related to the modeling of
user interaction in a post sequence. Recall that be-
tween two adjacent posts in a post sequence that
have opposing stances, there exists a rebuttal link.
Walker et al. (2012) employ manually identified

rebuttal links as hard inter-post constraints dur-
ing inference. However, since automatic discov-
ery of rebuttal links is a non-trivial problem, em-
ploying gold rebuttal links substantially simplifies
the stance classification task. Lu et al. (2012), on
the other hand, predict whether a link is of type
agreement or disagreement using a bootstrapped
classifier. Anand et al. (2011) do not predict links.
Instead, hypothesizing that the content of the pre-
ceding post in a post sequence would be useful
for predicting the stance of the current post, they
employ features computed based on the preceding
post when training a stance classifier. Hence, un-
like us, they classify each post independently of
the others, whereas we classify the posts in a se-
quence in dependent relation to each other.

The ILP framework has been applied to perform
joint inference for a variety of stance prediction
tasks. Lu et al. (2012) address the task of discov-
ering opposing opinion networks, where the goal
is to partition the authors in a debate (e.g., gay
rights) based on whether they support or oppose
the given issue. To this end, they employ ILP
to coordinate different sources of information. In
our previous work on debate stance classification
(Hasan and Ng, 2012), we employ ILP to coor-
dinate the output of two classifiers: a post-stance
classifier, which determines the stance of a debate
post written for a domain (e.g., gay rights); and
a topic-stance classifier, which determines the au-
thor’s stance on each topic mentioned in her post
(e.g., gay marriage, gay adoption). In this work,
on the other hand, we train only one classifier,
but use ILP to coordinate two types of constraints,
ACs and ICs.

7 Conclusions

We examined the under-studied task of stance
classification of ideological debates. Employing
our two types of extra-linguistic constraints yields
a system that outperforms an improved version of
Anand et al.’s approach by 2.9–10 accuracy points.
While the effectiveness of ideology constraints de-
pends to some extent on the “relatedness” of the
underlying ideological domains, we believe that
the gains they offer will increase with the num-
ber of authors posting in different domains and the
number of related domains.6

6Only a small fraction of the authors posted in multiple
domains in our datasets: 12% and 5% of them posted in two
and three domains, respectively.

820



References

Rakesh Agrawal, Sridhar Rajagopalan, Ramakrishnan
Srikant, and Yirong Xu. 2003. Mining newsgroups
using networks arising from social behavior. In Pro-
ceedings of the 12th International Conference on
World Wide Web, WWW ’03, pages 529–535.

Pranav Anand, Marilyn Walker, Rob Abbott, Jean E.
Fox Tree, Robeson Bowmani, and Michael Minor.
2011. Cats rule and dogs drool!: Classifying stance
in online debate. In Proceedings of the 2nd Work-
shop on Computational Approaches to Subjectivity
and Sentiment Analysis (WASSA 2011), pages 1–9.

Alexandra Balahur, Zornitsa Kozareva, and Andrés
Montoyo. 2009. Determining the polarity and
source of opinions expressed in political debates. In
Proceedings of the 10th International Conference on
Computational Linguistics and Intelligent Text Pro-
cessing, CICLing ’09, pages 468–480.

Mohit Bansal, Claire Cardie, and Lillian Lee. 2008.
The power of negative thinking: Exploiting label
disagreement in the min-cut classification frame-
work. In Proceedings of the 22nd International
Conference on Computational Linguistics: Com-
panion volume: Posters, pages 15–18.

Or Biran and Owen Rambow. 2011. Identifying justi-
fications in written dialogs. In Proceedings of the
2011 IEEE Fifth International Conference on Se-
mantic Computing, ICSC ’11, pages 162–168.

Clinton Burfoot, Steven Bird, and Timothy Baldwin.
2011. Collective classification of congressional
floor-debate transcripts. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 1506–1515.

Kazi Saidul Hasan and Vincent Ng. 2012. Predict-
ing stance in ideological debate with rich linguistic
knowledge. In Proceedings of the 24th International
Conference on Computational Linguistics: Posters,
pages 451–460.

Thorsten Joachims. 1999. Making large-scale SVM
learning practical. In Advances in Kernel Methods -
Support Vector Learning, pages 44–56. MIT Press.

Frank Kschischang, Brendan J. Frey, and Hans-Andrea
Loeliger. 2001. Factor graphs and the sum-product
algorithm. IEEE Transactions on Information The-
ory, 47:498–519.

John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling se-
quence data. In Proceedings of the 18th Interna-
tional Conference on Machine Learning, pages 282–
289.

Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Morgan & Claypool Publishers.

Yue Lu, Hongning Wang, ChengXiang Zhai, and Dan
Roth. 2012. Unsupervised discovery of opposing
opinion networks from forum discussions. In Pro-
ceedings of the 21st ACM International Conference
on Information and Knowledge Management, CIKM
’12, pages 1642–1646.

Andrew Kachites McCallum. 2002. Mallet: A ma-
chine learning for language toolkit. http://
mallet.cs.umass.edu.

Akiko Murakami and Rudy Raymond. 2010. Support
or oppose? Classifying positions in online debates
from reply activities and opinion expressions. In
Proceedings of the 23rd International Conference on
Computational Linguistics: Posters, pages 869–875.

Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1–2):1–135.

Dan Roth and Wen-tau Yih. 2004. A linear program-
ming formulation for global inference in natural lan-
guage tasks. In Proceedings of the Eighth Confer-
ence on Computational Natural Language Learning,
pages 1–8.

Swapna Somasundaran and Janyce Wiebe. 2010. Rec-
ognizing stances in ideological on-line debates. In
Proceedings of the NAACL HLT 2010 Workshop on
Computational Approaches to Analysis and Genera-
tion of Emotion in Text, pages 116–124.

Matt Thomas, Bo Pang, and Lillian Lee. 2006. Get out
the vote: Determining support or opposition from
Congressional floor-debate transcripts. In Proceed-
ings of the 2006 Conference on Empirical Methods
in Natural Language Processing, pages 327–335.

Marilyn Walker, Pranav Anand, Rob Abbott, and Ricky
Grant. 2012. Stance classification using dialogic
properties of persuasion. In Proceedings of the 2012
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 592–596.

Yi-Chia Wang and Carolyn P. Rosé. 2010. Making
conversational structure explicit: Identification of
initiation-response pairs within online discussions.
In Human Language Technologies: The 2010 An-
nual Conference of the North American Chapter
of the Association for Computational Linguistics,
pages 673–676.

Ainur Yessenalina, Yisong Yue, and Claire Cardie.
2010. Multi-level structured models for document-
level sentiment classification. In Proceedings of the
2010 Conference on Empirical Methods in Natural
Language Processing, pages 1046–1056.

821


