



















































Learning Web Query Patterns for Imitating Wikipedia Articles


Coling 2010: Poster Volume, pages 1229–1237,
Beijing, August 2010

Learning Web Query Patterns for Imitating Wikipedia Articles

Shohei Tanaka†
tanaka@mi.ci.i.u-tokyo.ac.jp

Naokaki Okazaki‡
okazaki@is.s.u-tokyo.ac.jp

Mitsuru Ishizuka†
ishizuka@i.u-tokyo.ac.jp

†Graduate School of Information
Science and Technology

University of Tokyo

‡Interfaculty Initiative in
Information Studies
University of Tokyo

Abstract

This paper presents a novel method for ac-
quiring a set of query patterns to retrieve
documents containing important informa-
tion about an entity. Given an existing
Wikipedia category that contains the tar-
get entity, we extract and select a small
set of query patterns by presuming that
formulating search queries with these pat-
terns optimizes the overall precision and
coverage of the returned Web informa-
tion. We model this optimization prob-
lem as a weighted maximum satisfiabil-
ity (weighted Max-SAT) problem. The
experimental results demonstrate that the
proposed method outperforms other meth-
ods based on statistical measures such as
frequency and point-wise mutual informa-
tion (PMI), which are widely used in rela-
tion extraction.

1 Introduction

Wikipedia1 is useful for obtaining comprehensive
information of entities and concepts. However,
even with 3.3 million English articles, Wikipedia
does not necessarily include articles about an en-
tity and concept of interest to a user. The ultimate
goal of this study is to generate articles about an
entity of a specified category from the Web by us-
ing Wikipedia articles in the same entity category
as exemplars.

This study follows previous work of the
other authors on query-biased/focused summa-
rization (Tombros and Sanderson, 1998; Berger

1http://en.wikipedia.org/

and Mittal, 2000) for modeling the target article
generation process. In that model, when a user in-
puts an entity of interest, Web pages are retrieved
that describe the entity by issuing queries to an
information retrieval system. Using the retrieved
pages as an information source, an article (sum-
mary) can be produced specialized for the target
entity. From the application point of view, the arti-
cle should include the concepts that best describe
the target entity. In addition, articles concerning
the entities of a category should cover concepts
that are typical of the category. For example, an
article about an actor is expected to mention his
nationality, date of birth, movie credits, awards,
etc.

A great number of researchers have ad-
dressed the problem of query-focused summariza-
tion (Carbonell and Goldstein, 1998; White et
al., 2003; Dang, 2005; Daumé and Marcu, 2006;
Varadarajan and Hristidis, 2006; Fuentes et al.,
2007; Gupta et al., 2007; Wang et al., 2007; Ka-
nungo et al., 2009). However, these studies as-
sume that a document collection is provided for
the summarization systems. In other words, col-
lecting source documents that include important
concepts for the target entity is not in the scope
of these studies. For example, queries such as
“(actor) was born in,” “(actor) born on,” “(actor)
plays,” and “(actor) won” may be more suitable
than the simple query “(actor)” for obtaining con-
cepts concerning the actor.

Source documents can be collected by a simi-
lar idea in relation extraction, which extracts en-
tities having specific relations with the target en-
tity (Hearst, 1992; Brin, 1999; Agichtein and Gra-
vano, 2000; Turney, 2001; Pantel and Pennac-

1229



chiotti, 2006; Blohm et al., 2007). These stud-
ies typically use statistical measures, such as fre-
quency and point-wise mutual information (PMI),
to assess the scores of the query patterns. How-
ever, these studies cannot eliminate the redun-
dancy of concepts retrieved by a query set because
they are designed to extract entities for each rela-
tion independently. For example, the query “(ac-
tor) born on” would not be necessary if the query
“(actor) was born in” could gather documents re-
ferring to both the actor’s nationality and date of
birth.

In this paper, we propose a novel method for
acquiring a set of high-quality query patterns that
can gather source documents referring to impor-
tant concepts about a specified entity. Given a
category in which the entity is expected to be in-
cluded, we use existing Wikipedia articles in this
category to extract query patterns so that, when
used together with the entity, they can retrieve im-
portant concepts related to the entity. We then
select a small subset of query patterns that max-
imize the coverage and precision of the query re-
sult by modeling the query selection task as a
weighted maximum satisfiability (weighted Max-
SAT) problem.

2 Proposed method

First, let us define the terminology used in this
paper. An entity is a topic for which we need to
obtain an article (summary). Note that this defi-
nition is different from that used in other studies
(e.g., named entity recognition). A concept is a
noun phrase that has a specific relation to an en-
tity. A query pattern is a lexical pattern that con-
tains a slot filled by an entity. Used with an entity,
a query pattern instantiates a query that collects
related concepts. For example, “X was born in” is
a query pattern in which X is a slot. When replac-
ing X with an entity (e.g., “Dustin Hoffman”), the
query pattern instantiates a query that may return
the birthplace.

The goal of this study is, for a given entity
category (e.g., American actor), to acquire a set
of query patterns (template) for collecting related
concepts from the Web. We learn the template by
using Wikipedia articles of the category as super-
vision data. The method consists of three steps.

1. Triplet extraction identifies, for each
Wikipedia article, entity mentions, concepts,
and phrases that form a bridge between the
entity mentions and concepts. In the context
of learning query patterns from Wikipedia,
we assume that a Wikipedia article is writ-
ten for an entity. By identifying entity men-
tions and concepts in the article, we ob-
tain bridging phrases between entity men-
tions and concepts as candidates for query
patterns.

2. Pattern assessment verifies whether each
candidate query pattern can actually retrieve
concepts from the Web. This step issues
queries of the form “(entity) (pattern)” to an
information retrieval system, analyzes the re-
trieved Web pages, and examines whether
each concept is found in the same sentence
as the query expressions.

3. Pattern selection obtains a template by
choosing a small subset of patterns such that
the retrieved Web pages contain as many
kinds of concepts as possible. We also elimi-
nate query patterns that can retrieve descrip-
tions other than concepts. We formalize this
step as a weighted Max-SAT problem.

2.1 Triplet extraction
We first analyze Wikipedia articles to extract
triplets of entities, query patterns, and concepts.
Because a Wikipedia article usually describes a
single entity, we identify the entity from the ti-
tle of the article. We then search for occurrences
of the entity in the body of the article. How-
ever, we might need to resolve coreference expres-
sions because the entity might be described by a
number of surface variations. For example, the
Wikipedia article titled “Dustin Hoffman” might
refer to the entity using “he” and “Hoffman” as
well as “Dustin Hoffman”; the entity “Microsoft
Corporation” might be described by “Microsoft”
and “the company” in the article.

In general, coreference resolution is a non-
trivial NLP task. Fortunately, Wikipedia articles
are written for target entities. Therefore, we re-
place the occurrences of the following expressions
in the body with the entity name:

1230



� �
Hoffman was born in [Los Angeles], [California], the
second and youngest son of Lillian and Harry Hoffman,
a [Russian]-born father who worked as a prop supervi-
sor/set decorator at [Columbia Pictures] before becom-
ing a furniture salesman. Hoffman is from a [Jewish]
family, although he did not have a religious upbring-
ing. He graduated from [Los Angeles High School] in
1955. He enrolled at [Santa Monica College] with the
intention of studying medicine but left after a year to
join the [Pasadena Playhouse].� �

Figure 1: A snippet of a Wikipedia article about
“Dustin Hoffman.”

1. Any token (split by spaces) that appears in
the title of the article.

2. The phrase that appears the most frequently
with the four anaphoric expressions “he,”
“she,” “they,” and “the noun.”

The first rule deals with anaphoric expression
caused by an ellipsis, e.g., “Dustin Hoffman” is
referred to by “Dustin” and “Hoffman.” The
second rule resolves the coreference expressions
caused by pronouns and definite noun phrases.

After detecting the entity mentions, we identify
the concepts concerning the entity in the article.
In this study, we employ WikiLink texts (anchor
texts linked with other Wikipedia articles) that co-
occur with the entity mentions in the same sen-
tences. Finally, we identify a candidate of a query
pattern as a phrase that satisfies the following con-
ditions:

1. It consists of alphanumeric letters and hy-
phens only.

2. Its length is no longer than 6 tokens.

3. It appears between an entity mention and a
concept in a sentence.

Figure 1 shows a snippet of the Wikipedia article
about “Dustin Hoffman.” The underlined expres-
sions are identified as entity mentions; the text in
square brackets represents a WikiLink text. Be-
cause all WikiLink texts appear in sentences with
the entity mentions, we identify all expressions
with square brackets as concepts. Italic texts are
candidates of the query patterns.

Finally, we extract triplets of the form
〈Ek,Pi,C j〉 from the Wikipedia article, where

Table 1: Triplets extracted from Figure 1.
Entity Query pattern concept
Dustin Hoffman was born in Los Angeles
Dustin Hoffman was born in California
Dustin Hoffman was born in Russian
Dustin Hoffman was born in Columbia Pictures
Dustin Hoffman is from a Jewish
Dustin Hoffman graduated from Los Angeles High School
Dustin Hoffman enrolled at Santa Monica College
Dustin Hoffman enrolled at Pasadena Playhouse

Ek (k ∈ {1, ...,L}) denotes the entity, Pi (i ∈
{1, ...,M}) denotes a query pattern, and C j ( j ∈
{1, ...,N}) denotes a concept. For each concept C j
found in the Wikipedia article, we build a triplet
by setting Ek as the entity of the article and Pj
as the query pattern that precedes the concept C j.
Repeating this process for L Wikipedia articles in
the same category, we obtain triplets with M query
patterns and N concepts.

Table 1 shows the eight triplets obtained from
Figure 1. Here, it might not be clear whether
the indefinite article a is necessary in the pattern
is from a. Although we do not address this is-
sue directly in this paper, we determine the pop-
ularity and usefulness of the pattern by analyzing
Wikipedia articles in the same category. Similarly,
some concepts (e.g., Russian) are not so impor-
tant for the entity. It may be better to filter out the
concept, but we expect that errors in concept iden-
tification are negligible when selecting the query
patterns.

2.2 Pattern assessment

In this step, we verify whether each pattern Pi can
actually retrieve concepts of the entities from the
Web. More specifically, for every combination of
an entity mention Ek and a pattern Pi, we issue a
query “Ek Pi” (e.g., “Dustin Hoffman graduated
from”) to Yahoo! Search BOSS2. We download
the top 10 Web pages retrieved by each query and
examine whether any of the concepts, C j, appear
in the same sentence as the query phrase. To de-
scribe the capability of the patterns for retrieving
concepts, we introduce an m×n matrix called R,

Ri j =

{
1 (pattern Pi can retrieve concept C j)
0 (otherwise)

.

2http://developer.yahoo.com/search/boss/

1231



DVD

the News

blogs

won the Academy Award

was born in

California

Los Angeles

1 9 3 7

Dustin Hoffman

graduated from

grew up in

in

L.A. High School

Figure 2: Patterns – collected concepts graph.

Figure 2 illustrates a bipartite graph between
the patterns and concepts with R as the biadja-
cency matrix. Here, nodes with dotted lines are
expressions other than concepts but are retrieved
by the patterns. For example, the pattern “in” can
retrieve four concepts Academy Award, Califor-
nia, Los Angeles, and 1937, but it also retrieves
non-concepts such as DVD, the News, and blogs.
In other words, this pattern can retrieve sentences
with a number of concepts, but it also gathers un-
necessary sentences. Thus, we define the error
rate of pattern Pi

εi = 1−
(# sentences with concepts)

(# total sentences retrieved by Pi)
.

2.3 Pattern selection
Based on the pattern assessment in Section 2.2,
this step chooses a small set of query patterns as
the template. Let w1, ...,wm denote m Boolean (0–
1 integer) variables, each of which (wi) indicates
whether the corresponding query pattern Pi is se-
lected (1) or unselected (0). Choosing a subset of
query patterns is equivalent to assigning Boolean
values to the variables w1, ...,wm. The number of
selected patterns is ∑mi=1 wi.

Given an assignment of variables w1, ...,wm for
the query patterns, we can examine whether the
concept C j is retrieved from the patterns by using
the logical sum,

c j = w1R1 j ∨w2R2 j ∨ ...∨wmRm j =
m∨

i=1

wiRi j.

Here, c j is a Boolean (0–1) variable indicating that
concept C j is retrieved (1) or not retrieved (0) by
the template. In Figure 2, if either the “in” or “was
born in” pattern is selected, we can retrieve the
concept “1937” from the Web search.

To choose a set of query patterns, we maxi-
mize the number of concept coverages ∑nj=1 c j as
well as minimize the number of patterns selected
∑mi=1 wi and the total of the error rates of the se-
lected patterns ∑mi=1 εiwi. This is achieved by solv-
ing the following problem.
Problem 1.

Maximize
n

∑
j=1

c j −α
m

∑
i=1

wi −β
m

∑
i=1

εiwi,

subject to: c1 =
m∨

i=1

wiRi1

...

cn =
m∨

i=1

wiRin,

wi ∈ {0,1}.
Here, α and β are the parameters for control-

ling the preference of a smaller number of patterns
(α) and the preference of accurate patterns (β ).

To solve this problem, we rewrite it as a
weighted maximize satisfiability (weighted Max-
SAT) problem.

Problem 2.

Maximize
n+m

∑
k=1

λkxk

Subject to: x1 =
m∨

i=1

wiRi1 (λ1 = 1)

... (...)

xn =
m∨

i=1

wiRin (λn = 1)

xn+1 = ¬w1 (λn+1 = α +βε1)
... (...)

xn+m = ¬wm (λn+m = α +βεm)
wi ∈ {0,1}

Instead of subtracting the penalty terms from
the objective value, we give bonus weights (α +
βεi) if the pattern Pi is not selected. This is
achieved by introducing additional clauses xn+1,
..., xn+m that are satisfied by ¬w1, ..., ¬wm, respec-
tively. Therefore, the optimization process tries
to find a compromise between selecting patterns
(clauses x1, ..., xn) and rejecting patterns (clauses
xn+1, ..., xn+m). Although the complexity of the
weighted Max-SAT problem is NP-hard, we use
MiniMaxSAT (Heras et al., 2008) to solve the
problem.

1232



3 Evaluation

To verify the performance of the proposed
method, we compare the precision, coverage,
and F’-score of the information retrieval process
by using the template obtained by the proposed
method with that by three other baseline methods.

3.1 Experimental Settings

3.1.1 Data
We use articles of five categories in Wikipedia

as the data for evaluation: American actors, Ge-
netic disorders, American tennis players, Soft-
ware companies, and Operas. Among these cat-
egories, the first two (American actors, Genetic
disorders) have been commonly used as evalua-
tion data in previous research on text summariza-
tion (Sauper and Barzilay, 2009). The other three
(American tennis players, Software companies,
Operas) are categories about three distinct topics
(sport, business, entertainment).Table 2 shows in-
formation about these categories.

We divide the article set of a given category into
six subsets. We use one subset as the development
set for tuning the parameters α and β in the pro-
posed method. The remaining five subsets are the
training set and the test set, which are used for the
5-fold cross-validation. We create the template by
using the training set and evaluate it with the test
set. For evaluation of the baseline methods, we
use only the training set and the test set.

3.1.2 Baselines
Random Selection
The baseline “Random Selection” randomly se-
lects 10 query patterns from the candidate query
patterns as the template for the category.
Frequency
In this baseline method, we sort the query patterns
for each category in the order of frequency of oc-
currences in the category. We then select the top
10 frequent query patterns as the template for the
category.
PMI-Web
The baseline PMI-Web chooses the query patterns
that are the most “reliable.” Following KnowIt-
Now (Cafarella et al., 2005) and Espresso (Pan-
tel and Pennacchiotti, 2006), the “reliability” of a

Table 2: The five categories used for evaluation.
Category #Articles #Patterns #Concepts
American actors 1864 2951 10495
American tennis players 444 1039 2826
Software companies 1890 1992 5087
Genetic disorders 657 1087 2400
Operas 1425 2125 6365

Figure 3: Relation between coverage and query
pattern frequency.

pattern is defined by using the strength of the as-
sociation of the pattern with the entities and con-
cepts co-occurring with the pattern. In KnowIt-
Now and Espresso, PMI (point-wise mutual infor-
mation) is used to measure the strength of this as-
sociation. PMI is estimated with the Web search
hit counts as follows:

pmi(Ek,Pi,C j) ≈
hit(Ek,Pi,C j)

hit(Ek,Pi) ·hit(C j)
,

where hit(EkPi), hit(C j) are the Web search hit
counts for the query “Ek, Pi,” “C j”(Ek,Pi,C j is en-
tity, pattern, concept), and hit(Ek,Pi,C j) is the hit
count for the query “Ek Pi” and “C j.” The relia-
bility score of the query pattern is defined as the
following formula:

Score(Pi) =
1
|S| ∑

(Ek,C j)∈S
pmi(Ek,Pi,C j),

where S is the set of pairs of entity Ek and concept
C j co-occurring with the pattern Pi in a sentence.
The method PMI-Web chooses the top 10 patterns
that have the highest reliability scores.

3.1.3 Experiments
We use each method to generate a template and

retrieve information of the entities by using the

1233



query patterns in the template. We remove the
query patterns occurring only once in each cat-
egory from the candidate patterns because these
patterns may be too entity-specific or noisy.

Figure 3 shows the coverage of the concept re-
trieval process when we use the top N frequently
appearing patterns in the candidate pattern set. We
observe that the coverage does not reach 100%
even if we use all the query patterns. This is be-
cause some concepts cannot be retrieved by any
query pattern. Moreover, we consider a Wikilink
as a concept, even though some Wikilink texts do
not actually represent a concept.

We use query patterns that occur no less than
3 times (for American actors, American ten-
nis players, Software companies, and Operas) or
twice (for Genetic disorders) in the correspond-
ing Wikipedia articles so that the query patterns
reach 95% of the upper bound of the coverage.
This small subset comprises the final candidate
patterns. For the candidate patterns, we use the
proposed method (solving the weighted Max-SAT
problem) and the three baselines described above
to choose N query patterns.

The precision, coverage and quasi F-score (F’-
score) of the information retrieval process by each
template are defined as follows:

precision =
freq(Ek,Pi,Cj)

freq(Ek,Pi)
,coverage =

Ccollected
Ctotal

,

F ′ =
2 ·precision · coverage
precision+ coverage

,

where freq(Ek,Pi) is the frequency of the phrase
“Ek Pi” in the retrieved documents, freq(Ek,Pi,C j)
is the frequency of co-occurrence of the phrase
“Ek Pi” and “C j” in the sentences. Ctotal is the to-
tal number of distinct concepts in the data set, and
Ccollected is the number of distinct concepts which
can be collected by the template.

3.2 Result
Table 5 shows the average of the precision, cover-
age and F’ scores of the five categories when we
choose 10 query patterns (N=10). The proposed
method obtains the highest score of all methods.
Moreover, the proposed method outperforms the
baselines not only for the average of all categories,
but also for each category. This result indicates

Table 5: Performance of the templates produced
by the proposed method and the three baselines
(N=10).

Method Precision Coverage F’ score
Random 16.56 11.40 13.19
Frequency 21.43 29.29 24.40
PMI-Web 22.55 22.08 21.42
Proposed 27.34 30.77 27.95

Figure 4: Number of query patterns (N) in tem-
plate and F’ score in American tennis players.

that the proposed method is able to choose query
patterns that precisely and comprehensively col-
lect the target concepts.

Table 3 shows some example templates pro-
duced by the proposed method. In this table, the
number in the parentheses next to a pattern is the
frequency rank of the pattern. We observe that the
proposed method generates templates with two
types of query patterns: generic patterns and spe-
cific patterns. Generic patterns such as “is a”
and “is an” are patterns that can appear in every
category. These patterns cover various kinds of
concepts (high coverage), but may retrieve sen-
tences that do not describe any concept (low pre-
cision). Specific patterns, such as “has a star on
the” and “was nominated for a,” can retrieve con-
cepts that have specific relations with the entity.
Therefore, queries with specific patterns retrieve
a small number of concepts with high precision.
The proposed method chooses query patterns in
both of these types to achieve both high precision
and high coverage. Therefore, it is able to retrieve

1234



Table 3: Templates generated by the proposed method (N=10): (n) is the frequency rank.
Category Template

American actors “is an”(1), “was an”(2), “was a”(7), “graduated from”(9), “died of”(18), “has a star on the”(24),
”was nominated for a”(28), “was married to”(47), “was born on”(56), “has appeared in”(92)

American tennis players “defeated”(3), “beat”(5), “is a former”(12), “is an”(16), “graduated from”(17),
”reached the”(18), “played”(24), “of”(30), “was”(38), “won”

Software companies “is a”(1), “acquired”(3), “is”(9), “is headquartered in”(11), “was founded by”(15),
”has offices in”(22), “was”(29), “include”(36), “introduced”(41), “is an international”(41)

Genetic disorders “is a”(1), “is an”(2), “has an autosomal recessive pattern of”(3),
”has an autosomal dominant pattern of”(9), “is named after”(11), “is a form of”(13),

”is caused by”(16), “include”(18), “appears to be inherited in an”(41), “is considered an”(41)
Operas ”is an”(1), “is a”(2), “is an opera by”(17), “was”(18), “is a comic”(20), “premiered at the”(25),

”was first performed at”(31), “is the second”(38), “opera”(46), “libretto by”(62)

Table 4: Templates generated by different methods for the Opera category (N= 10).
Method Template Pre. Cov. F’

Random “was an,” “of the complete operas of the,” “was on,” “was commissioned by,” 15.79 8.12 10.73
“by,” “is,” “popular,” “for the,” “New York,” “the same name by”

Frequency “is an,” “is a,” “the,” “by,” “of the,” “in,” “and,” “of,” “was a,” “a” 16.83 27.12 20.77
PMI-Web “was created by,” “is a three act,” “premiered at the,” “was an,” “is an,” 30.25 18.29 22.80

“is an opera composed by,” “is a Hindi language,” “premiered on”
“was commissioned by,” “was first performed at the,”

Proposed “is an,” “is a,” “is an opera by,” “was,” “is a comic,” “premiered at the,” 31.18 27.28 29.10
“was first performed at,” “is the second,” “opera,” “libretto by”

various types of concepts. This implies that the
method achieves high coverage even for concepts
that cannot be retrieved by generic patterns.

The baseline Frequency obtains the second
highest F’-score. It achieves high coverage but
low precision. This is because this method
chooses high-frequency patterns that can appear
with every concept. Therefore, it is able to retrieve
concepts with high coverage. However, these pat-
terns do not retrieve specific information concern-
ing a concept. Moreover, some high-frequency
patterns, such as “the ” and ”by,” lead to sentences
that do not describe any concept.

Table 4 shows the patterns generated for the cat-
egory Opera by each method. We can observe that
the method Frequency chooses very generic pat-
terns, such as “is a,” “and,” and “the,” which are
not specific to Opera.

In contrast, the method PMI-Web achieves high
precision but low coverage. This is because
this method chooses highly reliable patterns (e.g.,
“was commissioned by”), which are strongly as-
sociated with a specific kind of concept. How-
ever, these patterns cannot retrieve a broad range
of concepts related to the target entity. This ex-
plains why the method cannot achieve high cover-

age.
Figure 4 shows the F’ scores when we vary the

number of selected query patterns (N) for the cat-
egory American tennis players. We observe that
the templates generated by the proposed method
achieve the highest F’-score at every value of N.
The maximum F’-score is 24.7, which is achieved
when N is 30. Moreover, the proposed method re-
quires only five query patterns to achieve the F’-
score of 21.4. Therefore, the proposed method
achieves a high F’-score by using only a small
number of patterns. This implies that the method
achieves high performance in a short query pro-
cessing time.

4 Related Work
Many studies have addressed the problem of pat-
tern extraction from Wikipedia (or other large cor-
pora). Filatova et al. (2006) presented an approach
for automatically extracting important word pat-
terns from a large corpus. They analyzed the BBC
corpus to extract word patterns containing verbs
that are supposed to be important for a specific
domain. Biadsy et al. (2008) described a sys-
tem for producing biographies for a given target
name. They used Wikipedia to learn the docu-
ment structures of a biography. Ye et al. (2009)

1235



explored a method for generating a series of sum-
maries of various lengths by using information
from Wikipedia.

Sauper and Barzilay (2009) proposed an ap-
proach for creating a summary of many chunks
of text that are related to an entity and retrieved
from the Web. They used Wikipedia not only
for producing the template, but also for improv-
ing the summaries. Although the target of their
work is very close to that of our study, the focus of
each study is different. They address the method
for selecting appropriate sentences for summa-
rization, whereas we consider the method for se-
lecting query patterns that can generate a compre-
hensive summary of an entity.

Various studies have addressed Web page
summarization and query-focused summarization,
from search result summarization (Kanungo et al.,
2009) to query biased summarization (Wang et al.,
2007). Furthermore, Fujii and Ishikawa (2004)
presented a method to automatically compile en-
cyclopedic knowledge from the Web.

Similar to relation extraction, the proposed
method retrieves information concerning an entity
by using query patterns. This is because query
patterns for relation extraction are also appro-
priate in sentence extraction for multi-document
summarization (Hachey, 2009). However, the re-
lation extraction task primarily obtains query pat-
terns that retrieve instances of a specific relation.
This is different from the goal of this study, which
is obtaining a set of patterns that are able to re-
trieve a large range of topics related to an entity.

5 Conclusion
We present a novel method to acquire a set of
query patterns for retrieving documents that con-
tain important information regarding an entity.
Especially, we concentrate on the method for se-
lecting query patterns that are able to compre-
hensively and precisely retrieve important con-
cepts concerning an entity. The experimental re-
sults demonstrate that the proposed method out-
performs methods based on statistical measures
such as frequency and point-wise mutual infor-
mation (PMI), which are widely used in relation
extraction.

Currently, we use the text between an entity

and a WikiLink as a candidate for a query pat-
tern. In the future, we plan to use the text between
two noun phrases as query patterns to increase the
number of candidates for the pattern selection pro-
cess. Moreover, we intend to build a text summa-
rization application based on the proposed method
to confirm that the selected pattern set is able to
generate a comprehensive summary for an entity.

References
Agichtein, Eugene and Luis Gravano. 2000. Snow-

ball: Extracting relations from large plain-text col-
lections. In Proc. of the fifth ACM conference on
Digital libraries, pages 85–94.

Berger, Adam and Vibhu O. Mittal. 2000. Query-
relevant summarization using FAQs. In Proc. of the
38th Annual Meeting on Association for Computa-
tional Linguistics, pages 294–301.

Biadsy, Fadi, Julia Hirschberg, and Elena Filatova.
2008. An unsupervised approach to biography pro-
duction using Wikipedia. In Proc. of the 46th
Annual Meeting of the Association for Computa-
tional Linguistics on Human Language Technolo-
gies, pages 807–815.

Blohm, Sebastian, Philipp Cimiano, and Egon Stemle.
2007. Harvesting relations from the Web: quantifiy-
ing the impact of filtering functions. In Proc. of the
22nd national conference on Artificial intelligence,
pages 1316–1321.

Brin, Sergey. 1999. Extracting patterns and relations
from the World Wide Web. Selected papers from
the International Workshop on The World Wide Web
and Databases, pages 172–183.

Cafarella, Michael J., Doug Downey, Stephen Soder-
land, and Oren Etzioni. 2005. KnowItNow: Fast,
scalable information extraction from the Web. In
Proc. of the conference on Human Language Tech-
nology and Empirical Methods in Natural Language
Processing, pages 563–570.

Carbonell, Jaime and Jade Goldstein. 1998. The use
of MMR, diversity-based reranking for reordering
documents and producing summaries. In Proc. of
the 21st annual international ACM SIGIR confer-
ence on Research and development in information
retrieval, pages 335–336.

Dang, Hoa Trang. 2005. Overview of DUC 2005. In
Document Understanding Conference (DUC) 2005.

Daumé, III, Hal and Daniel Marcu. 2006. Bayesian
query-focused summarization. In Proc. of the 21st

1236



International Conference on Computational Lin-
guistics and the 44th annual meeting of the Associa-
tion for Computational Linguistics, pages 305–312.

Filatova, Elena, Vasileios Hatzivassiloglou, and Kath-
leen McKeown. 2006. Automatic creation of do-
main templates. In Proc. of the 21st International
Conference on Computational Linguistics and the
44th annual meeting of the Association for Compu-
tational Linguistics, pages 207–214.

Fuentes, Maria, Enrique Alfonseca, and Horacio
Rodrı́guez. 2007. Support vector machines for
query-focused summarization trained and evaluated
on pyramid data. In Proc. of the 45th Annual Meet-
ing of the ACL on Interactive Poster and Demon-
stration Sessions, pages 57–60.

Fujii, Atsushi and Tetsuya Ishikawa. 2004. Summa-
rizing encyclopedic term descriptions on the Web.
In Proc. of the 20th international conference on
Computational Linguistics, pages 645–651.

Gupta, Surabhi, Ani Nenkova, and Dan Jurafsky.
2007. Measuring importance and query relevance
in topic-focused multi-document summarization. In
Proc. of the 45th Annual Meeting of the ACL on In-
teractive Poster and Demonstration Sessions, pages
193–196.

Hachey, Ben. 2009. Multi-document summarisation
using generic relation extraction. In Proc. of the
2009 Conference on Empirical Methods in Natural
Language Processing, pages 420–429.

Hearst, Marti A. 1992. Automatic acquisition of
hyponyms from large text corpora. In Proc. of
the 14th conference on Computational linguistics,
pages 539–545.

Heras, Federico, Javier Larrosa, and Albert Oliveras.
2008. MiniMaxSat: An efficient weighted Max-
SAT solver. Journal of Artificial Intelligence Re-
search, 31:1–32.

Kanungo, Tapas, Nadia Ghamrawi, Ki Yuen Kim, and
Lawrence Wai. 2009. Web search result summa-
rization: Title selection algorithms and user satis-
faction. In Proceeding of the 18th ACM conference
on Information and knowledge management, pages
1581–1584.

Pantel, Patrick and Marco Pennacchiotti. 2006.
Espresso: Leveraging generic patterns for automat-
ically harvesting semantic relations. In Proc. of the
21st International Conference on Computational
Linguistics and the 44th annual meeting of the Asso-
ciation for Computational Linguistics, pages 113–
120.

Sauper, Christina and Regina Barzilay. 2009. Auto-
matically generating Wikipedia articles: a structure-
aware approach. In Proc. of the Joint Conference of
the 47th Annual Meeting of the ACL and the 4th In-
ternational Joint Conference on Natural Language
Processing of the AFNLP, pages 208–216.

Tombros, Anastasios and Mark Sanderson. 1998. Ad-
vantages of query biased summaries in information
retrieval. In Proc. of the 21st annual international
ACM SIGIR conference on Research and develop-
ment in information retrieval, pages 2–10.

Turney, Peter D. 2001. Mining the Web for synonyms:
PMI-IR versus LSA on TOEFL. In Proc. of the 12th
European Conference on Machine Learning, pages
491–502.

Varadarajan, Ramakrishna and Vagelis Hristidis.
2006. A system for query-specific document sum-
marization. In Proc. of the 15th ACM international
conference on Information and knowledge manage-
ment, pages 622–631.

Wang, Changhu, Feng Jing, Lei Zhang, and Hong-
Jiang Zhang. 2007. Learning query-biased Web
page summarization. In Proc. of the sixteenth ACM
conference on information and knowledge manage-
ment, pages 555–562.

White, Ryen W., Joemon M. Jose, and Ian Ruthven.
2003. A task-oriented study on the influencing ef-
fects of query-biased summarisation in Web search-
ing. Information Processing and Management,
39(5):707–733.

Ye, Shiren, Tat-Seng Chua, and Jie Lu. 2009. Sum-
marizing definition from Wikipedia. In Proc. of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Vol-
ume 1, pages 199–207.

1237


