



















































UIO-Lien: Entailment Recognition using Minimal Recursion Semantics


Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 699–703,
Dublin, Ireland, August 23-24, 2014.

UIO-Lien: Entailment Recognition using Minimal Recursion Semantics

Elisabeth Lien
Department of Informatics
University of Oslo, Norway
elien@ifi.uio.no

Milen Kouylekov
Department of Informatics
University of Oslo, Norway
milen@ifi.uio.no

Abstract

In this paper we present our participa-
tion in the Semeval 2014 task “Evalu-
ation of compositional distributional se-
mantic models on full sentences through
semantic relatedness and textual entail-
ment”. Our results demonstrate that us-
ing generic tools for semantic analysis is a
viable option for a system that recognizes
textual entailment. The invested effort in
developing such tools allows us to build
systems for reasoning that do not require
training.

1 Introduction

Recognizing textual entailment (RTE) has been a
popular area of research in the last years. It has
appeared in a variety of evaluation campaigns as
both monolingual and multilingual tasks. A wide
variety of techniques based on different levels of
text interpretation has been used, e.g., lexical dis-
tance, dependency parsing and semantic role la-
beling (Androutsopoulos and Malakasiotis, 2010).

Our approach uses a semantic representation
formalism called Minimal Recursion Semantics
(MRS), which, to our knowledge, has not been
used extensively in entailment decision systems.
Notable examples of systems that use MRS are
Wotzlaw and Coote (2013), and Bergmair (2010).
In Wotzlaw and Coote (2013), the authors present
an entailment recognition system which combines
high-coverage syntactic and semantic text analysis
with logical inference supported by relevant back-
ground knowledge. MRS is used as an interme-
diate format in transforming the results of the lin-
guistic analysis into representations used for log-
ical reasoning. The approach in Bergmair (2010)

This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/

uses the syllogism as an approximation of natural
language reasoning. MRS is used as a step in the
translation of natural language sentences into logi-
cal formulae that are suitable for processing. Both
works describe approaches that can be adapted
to RTE, but no empirical evaluation is included
to demonstrate the potential of the proposed ap-
proaches.

In contrast to these approaches, our system
bases entailment decision directly on the MRS
representations. Graph alignment over MRS rep-
resentations forms the basis for entailment recog-
nition. If key nodes in the hypothesis MRS can be
aligned to nodes in the text MRS, this is treated as
an indicator of entailment.

This paper represents our first attempt to evalu-
ate a system based on logical-form semantic rep-
resentations in a RTE competition. Using a state-
of-the-art semantic analysis component, we have
created a generic rule-based system for recogniz-
ing textual entailment that obtains competitive re-
sults on a real evaluation dataset. Our approach
does not require training. We confront it with
a strong baseline provided by the EDITS system
(Kouylekov et al., 2011).

In Section 2 we describe the computational se-
mantics framework that forms the basis of our ap-
proach. Section 3 details our entailment system,
and in Section 4 we analyze our results from the
task evaluation.

2 Minimal Recursion Semantics

Minimal Recursion Semantics (MRS) (Copestake
et al., 2005) is a framework for computational se-
mantics which provides expressive representations
with a clear interface with syntax. MRS allows
underspecification of scope, in order to capture the
different readings of a sentence with a single MRS
representation. We use the MRS analyses that are
produced by the HPSG English Resource Gram-
mar (ERG) (Flickinger, 2000).

699



The core of an MRS representation is a mul-
tiset of relations, called elementary predications
(EPs). An EP represents a single lexeme, or gen-
eral grammatical features. Each EP has a predi-
cate symbol, and a label (also called handle) that
identifies the EPs position within the MRS struc-
ture. Each EP contains a list of numbered argu-
ments: ARG0, ARG1, etc., whose values are scopal
or non-scopal variables. The ARG0 value is called
the EP’s distinguished variable, and denotes an
event or state, or an entity.

Finally, an MRS has a set of handle constraints
which describe how the scopal arguments of the
EPs can be equated with EP labels. A constraint
hi =q hj denotes equality modulo quantifier inser-
tion. EPs are directly and indirectly linked through
handle constraints and variable sharing, and the re-
sulting MRS forms a connected graph.

In Figure 1, we see an MRS for the sentence
A woman is cutting a potato. The topmost EP,
cut v 1, has a list of three argument-value pairs:

its distinguished variable e3 denotes an event, and
the variables x6 and x9 refer to the entities filling
the agent and patient roles in the verb event. x6
and x9 are in turn the distinguished variables of
the EPs that represent a woman and a potato, re-
spectively.

3 System Description

In the following, Tsent and Hsent refer to the text
and hypothesis sentence, and Tmrs and Hmrs to
their MRS representations.

The core of our system is a rule based compo-
nent, which bases entailment decision on graph
alignment over MRS structures. An earlier ver-
sion of the system is described in Lien (2014).
The earlier version was developed on the data set
from the SemEval-2010 shared task Parser Eval-
uation using Textual Entailment (PETE) (Yuret et
al., 2010). Using no external linguistic resources,
the system output positive entailment decisions for
sentence pairs where core nodes of the Hmrs could
be aligned to nodes in Tmrs according to a set of
heuristic matching rules. The system we present
in this paper extends the earlier version by adding
support for contradiction recognition, and by us-
ing lexical relations from WordNet.

For our participation in the entailment recogni-
tion task, first, we did an analysis of the SICK trial
data. In the ENTAILMENT pairs, Hsent is a para-
phrase over the whole or part of the text sentence.

The changes from Tsent to Hsent can be syntactic
(e.g., active-passive conversion), lexical (e.g., syn-
onymy, hyponymy-hypernymy, multiword expres-
sions replaced by single word), or Tsent contains
some element that does not appear in Hsent (e.g.,
Tsent is a conjunction and Hsent one of its con-
juncts, a modifier in Tsent is left out of Hsent). In
the CONTRADICTION category, the sentences of
a pair are also basically the same or paraphrases,
and a negation or a pair of antonymous expres-
sions create the contradiction. The NEUTRAL
pairs often have a high degree of word overlap, but
Hsent cannot be inferred from Tsent. Our system
accounts for many of these characteristics.

The system bases its decision on the results of
two procedures: a) an event relation match which
searches for an alignment between the MRSs, and
b) a contradiction cue check. After running these
procedures, the system outputs

1. ENTAILMENT, if the event relation match-
ing procedure found an alignment, and no
contradiction cues were found,

2. CONTRADICTION, if contradiction cues
were found,

3. NEUTRAL, if neither of the above condi-
tions are met.

The event relation matching procedure extends
the one developed in Lien (2014) to account for
the greater lexical variation in the SICK data. The
procedure selects all the EPs in Tmrs and Hmrs
that have an event variable as their ARG0—we call
them event relations. These event relations mainly
represent verbs, verb conjunctions, adjectives, and
prepositions. For each event relation Hevent in the
hypothesis the procedure tries to find a matching
relation Tevent among the text event relations. We
say that Hevent matches Tevent if:

1. they represent the same lexeme with the
same part-of-speech, or if both are verbs and
Hevent is a synonym or hypernym of Tevent,
and

2. all their arguments match. Two event rela-
tion arguments in the same argument position
match if:

• they are the same or synonymous, or the
Hevent argument is a hypernym of the
Tevent argument, or

700



〈h1,
h4: a q〈0:1〉(ARG0 x6, RSTR h7, BODY h5),
h8: woman n 1〈2:7〉(ARG0 x6),
h2: cut v 1〈11:18〉(ARG0 e3, ARG1 x6, ARG2 x9),
h10: a q〈19:20〉(ARG0 x9, RSTR h12, BODY h11),
h13: potato n 1〈21:28〉(ARG0 x9)
{h12 =q h13, h7 =q h8, h1 =q h2 } 〉

Figure 1: MRS for A woman is cutting a potato (pair 4661, SICK trial data).

• the argument in Tevent represents a noun
phrase and the argument in Hevent is an
underspecified pronoun like somebody,
or
• the argument in Tevent is either a sco-

pal relation or a conjunction relation,
and one of its arguments matches that of
Hevent, or
• the argument in Hevent is not expressed

(i.e., it matches the Tevent argument by
default)

The matching procedure does not search for
more than one alignment between the event rela-
tions of Hmrs and Tmrs.

The contradiction cue procedure checks
whether the MRS pairs contain relations express-
ing negation. The quantifier no q rel negates
an entity (e.g., no man), whereas neg rel
denotes sentence negation. If a negation relation
appears in one but not the other MRS, we treat
this as an indicator of CONTRADICTION.

Example: Figure 1 shows the MRS analysis of
the hypothesis in the entailment pair A woman
is slicing a potato ⇒ A woman is cutting a
potato. There is only one event relation in Hmrs:
cut v 1. Tmrs is an equivalent structure with

one event relation slice v 1. Using Word-
Net, the system finds that cut v 1 is a hyper-
nym of slice v 1. Then, the system compares
the ARG1 and ARG2 values of the event relations.
The arguments match since they are the same re-
lations. There are no contradiction cues in either
of the MRSs, so the system correctly outputs EN-
TAILMENT.

If we look at the rule based component’s output
(Table 1) for the 481 of the 500 SICK trial sen-
tence pairs for which the ERG produced MRSs,
we get a picture of how well it covers the phenom-
ena in the data set:

Of the 134 ENTAILMENT pairs, 59 were para-
phrases where the variation was relatively limited

gold ENT gold CON gold NEU
sys ENT 59 0 1
sys CON 0 51 14
sys NEU 75 22 259

Table 1: Output for the system on SICK trial data.

and could be captured by looking for synonyms,
hyponyms, and treating the hypothesis as a sub-
graph of the text. The simple contradiction cue
check, which looks for negation relations, covered
51 of 73 CONTRADICTION pairs.

75 ENTAILMENT and 22 CONTRADICTION
pairs were not captured by the matching and con-
tradiction cue procedures. Almost 30% of the
ENTAILMENT pairs had word pairs whose lex-
ical relationship was not recognized using Word-
Net (e.g.: playing a guitar⇒ strumming a guitar).
In the other pairs there were alternations between
simple and more complex noun phrases (protec-
tive gear ⇒ gear used for protection), change of
part-of-speech from Tsent to Hsent for the same
meaning entities (It is raining on a walking man⇒
A man is walking in the rain); some pairs required
reasoning, and in some cases Hsent contained in-
formation not present in Tsent. In some cases, en-
tailment recognition fails because the MRS analy-
sis is not correct (e.g., misrepresentation of passive
constructions).

The contradiction cue check did not look for
antonymous words and expressions, and this ac-
counts for almost half of the missing CONTRA-
DICTION pairs. The rest contained negation,
but were misclassified either because an incorrect
MRS analysis was chosen by the parser or because
synonymous words within the scope of the nega-
tion were not recognized.

EDITS We used a backoff-system for the pairs
when the rule-based system fails to produce re-

701



System 1 2 3 4 5
Rules Only Rules Only Combined Combined Edits

Training 76.13 75.4 76.62 76.62 74.78
Test 77.0 76.35 77.12 77.14 74.79

Table 2: Submitted system accuracy on training and test set.

sults. Our choice was EDITS1 as it provides
a strong baseline system for recognizing textual
entailment (Kouylekov et al., 2011). EDITS
(Kouylekov and Negri, 2010) is an open source
package which offers a modular, flexible, and
adaptable working environment for experimenting
with the RTE task over different datasets. The
package allows to: i) create an entailment engine
by defining its basic components; ii) train this
entailment engine over an annotated RTE corpus
to learn a model and iii) use the entailment en-
gine and the model to assign an entailment judg-
ment and a confidence score to each pair of an un-
annotated test corpus.

We used two strategies for combining the rule-
based system with EDITS: Our first strategy was
to let the rule-based system classify those sentence
pairs for which the ERG could produce MRSs, and
use EDITS for the pairs were we did not have
MRSs (or processing failed due to errors in the
MRSs) . The second strategy was to mix the out-
put from both systems when they disagree. In this
case we took the ENTAILMENT decisions from
the rule-based, and EDITS contributes with CON-
TRADICTION and NEUTRAL.

4 Analysis

We have submitted the results obtained from five
system configurations. The first four used the rule-
based system as the core. The fifth was a system
obtained by training EDITS on the training set.
We use the fifth system as a strong baseline. In
the few cases in which the rule-based system did
not produce result (2% of the test set pairs) EDITS
judgments were used in the submission. In System
1 and System 2 we have used the first combination
strategy described in the end of section 3. In Sys-
tem 4 and System 5 the entailment decisions are a
combination of the results from the rule-based sys-
tem and EDITS as described in the second strategy
in the same section. The rule-based component
in System 1 and System 3 has more fine-grained

1http://edits.sf.net

Precision Recall F-Measure
Contradiction 0.8422 0.7264 0.78
Entailment 0.9719 0.4158 0.5825
Neutral 0.7241 0.9595 0.8254

Table 3: Performance of System 1.

negation rules so that no q rel is not treated as
a contradiction cue in different contexts (e.g., No
woman runs does not contradict A woman sings).
Table 2 shows the results for the five submitted
systems.

The results demonstrate that the rule-based sys-
tem can be used as a general system for recogniz-
ing textual entailment. It surpasses with 3 points
of accuracy EDITS, which is an established strong
baseline system. We are quite content with the re-
sults obtained as we did not use the training dataset
to create the rules, but only the trial dataset. The
combination of the two systems brings a slight im-
provement.

Overall the rule-based system is quite precise
as demonstrated in Table 3. The numbers in the
table correspond to System 1 but are comparable
to the other rule-based systems 2, 3 and 4. The
system achieves an excellent precision on the en-
tailment and contradiction relations. It is almost
always correct when assigning the entailment rela-
tion. And it also obtains a decent recall, correctly
assigning almost half of the entailment pairs. On
the contradiction relation the system also obtained
a decent result, capturing most of the negation
cases.

5 Conclusions

Using a state-of-the-art semantic analysis compo-
nent, we have created a generic rule-based sys-
tem for recognizing textual entailment that obtains
competitive results on a real evaluation dataset.
An advantage of our approach is that it does not
require training. The precision of the approach
makes it an excellent candidate for a system that
uses textual entailment as the core of an intelligent
search engine.

702



References
Ion Androutsopoulos and Prodromos Malakasiotis.

2010. A Survey of Paraphrasing and Textual Entail-
ment Methods. J. Artif. Intell. Res. (JAIR), 38:135–
187.

Richard Bergmair. 2010. Monte Carlo Semantics: Ro-
bust Inference and Logical Pattern Processing with
Natural Language Text. Ph.D. thesis, University of
Cambridge.

Ann Copestake, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 2005. Minimal Recursion Semantics:
An Introduction. Research on Language & Compu-
tation, 3(2):281–332.

Dan Flickinger. 2000. On Building a More Effcient
Grammar by Exploiting Types. Natural Language
Engineering, 6(1):15–28.

Milen Kouylekov and Matteo Negri. 2010. An
Open-Source Package for Recognizing Textual En-
tailment. In 48th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL 2010) ,Up-
psala, Sweden, pages 42–47.

Milen Kouylekov, Yashar Mehdad, and Matteo Negri.
2011. Is it Worth Submitting this Run? Assess your
RTE System with a Good Sparring Partner. In Pro-
ceedings of the TextInfer 2011 Workshop on Textual
Entailment, Edinburgh Scotland, pages 30–34.

Elisabeth Lien. 2014. Using Minimal Recursion Se-
mantics for Entailment Recognition. In Proceed-
ings of the Student Research Workshop at the 14th
Conference of the European Chapter of the Associ-
ation for Computational Linguistics, pages 76–84,
Gothenburg, Sweden, April.

Andreas Wotzlaw and Ravi Coote. 2013. A Logic-
based Approach for Recognizing Textual Entailment
Supported by Ontological Background Knowledge.
CoRR, abs/1310.4938.

Deniz Yuret, Aydin Han, and Zehra Turgut. 2010.
SemEval-2010 Task 12: Parser Evaluation using
Textual Entailments. In Proceedings of the 5th
International Workshop on Semantic Evaluation,
pages 51–56.

703


