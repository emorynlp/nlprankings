



















































bs,hr,srWaC - Web Corpora of Bosnian, Croatian and Serbian


Felix Bildhauer & Roland Schäfer (eds.), Proceedings of the 9th Web as Corpus Workshop (WaC-9) @ EACL 2014, pages 29–35,
Gothenburg, Sweden, April 26 2014. c©2014 Association for Computational Linguistics

{bs,hr,sr}WaC – Web corpora of Bosnian, Croatian and Serbian

Nikola Ljubešić
University of Zagreb

Ivana Lučića 3, 10000 Zagreb, Croatia
nljubesi@ffzg.hr

Filip Klubička
University of Zagreb

Ivana Lučića 3, 10000 Zagreb, Croatia
fklubick@ffzg.hr

Abstract

In this paper we present the construction
process of top-level-domain web corpora
of Bosnian, Croatian and Serbian. For
constructing the corpora we use the Spi-
derLing crawler with its associated tools
adapted for simultaneous crawling and
processing of text written in two scripts,
Latin and Cyrillic. In addition to the mod-
ified collection process we focus on two
sources of noise in the resulting corpora:
1. they contain documents written in the
other, closely related languages that can
not be identified with standard language
identification methods and 2. as most web
corpora, they partially contain low-quality
data not suitable for the specific research
and application objectives. We approach
both problems by using language mod-
eling on the crawled data only, omitting
the need for manually validated language
samples for training. On the task of dis-
criminating between closely related lan-
guages we outperform the state-of-the-art
Blacklist classifier reducing its error to a
fourth.

1 Introduction

Building web corpora for various NLP tasks has
become quite a standard approach, especially if
funding is limited and / or there is need for large
amounts of textual data.

Although off-the-shelf solutions for compiling
web corpora have emerged recently, there are still
specific challenges that have to be addressed in
most corpus construction processes. One such
challenge that we face while constructing the cor-
pora described in this paper is simultaneous us-
age of two scripts on two out of three top-level
domains (TLDs) crawled.

Additionally, there are still many open ques-
tions and possibilities for improvement in the
process of collecting data as well as data post-
processing. We address two of the latter kind –
discrimination between similar, neighboring lan-
guages that are used on all selected TLDs, and
the question of text quality in corpora collected in
such a fully automated fashion.

In the paper we present the process of building
web corpora of Bosnian, Croatian and Serbian by
crawling the .ba, .hr and .rs TLDs. The three
languages belong to the South Slavic language
branch and are very similar to each other. The
biggest differences between Croatian and Serbian
are the proto-Slavic vowel jat (Croatian čovjek
vs. Serbian čovek), way of handling proper nouns
(Croatian New York vs. Serbian Nju Jork), specific
syntactic constructions (Croatian hoću raditi vs.
Serbian hoću da radim) and a series of lexical dif-
ferences (Croatian mrkva vs. Serbian šargarepa).
Bosnian is mostly seen as a mixture of those two
and allows, beside its own lexical specificities, so-
lutions from one or both languages.1

This paper is structured as follows: in Section
2 we give an overview of related work regarding
existing (web) corpora of the languages in ques-
tion, language identification and web text quality
estimation. Section 3 shows the process of col-
lecting the three TLD corpora with emphasis on
the problem of collecting data written in various
scripts, while in Section 4 we describe the linguis-
tic annotation layers added to the corpora. Section
5 depicts our approach to discriminating between
very similar languages while in Section 6 we de-
scribe our approach to identifying documents of
low text quality, and both approaches use recently
crawled data only.

1A more thorough comparison of the three lan-
guages is available at http://en.wikipedia.org/
wiki/Comparison_of_standard_Bosnian,
_Croatian_and_Serbian

29



2 Related work

The only two South Slavic languages for which
web corpora were previously built are Croatian
and Slovene (Ljubešić and Erjavec, 2011). The
Croatian corpus presented in this paper is actually
an extension of the existing corpus, representing
its second version. hrWaC v1.0 was, until now,
the biggest available corpus of Croatian.

For Bosnian, almost no corpora are available
except the SETimes corpus2, which is a 10-
languages parallel corpus with its Bosnian side
consisting of 2.2 million words, and The Oslo
Corpus of Bosnian Texts3, which is a 1.5 mil-
lion words corpus consisting of different genres of
texts that were published in the 1990s.

For the Serbian language, until now, the largest
corpus was the SrpKor corpus4, consisting of 118
million words that are annotated with part-of-
speech information (16 tags) and lemmatized. The
corpus is available for search through an interface
for non-commercial purposes.

Until now, no large freely downloadable cor-
pora of Bosnian and Serbian were available, and
this was one of the strongest motivations for our
work.

Multiple pipelines for building web corpora
were described in many papers in the last decade
(Baroni et al., 2009; Ljubešić and Erjavec, 2011;
Schäfer and Bildhauer, 2012), but, to the best of
our knowledge, only one pipeline is freely avail-
able as a complete, ready-to-use tool: the Brno
pipeline (Suchomel and Pomikálek, 2012), con-
sisting of the SpiderLing crawler5, the Chared en-
coding detector6, the jusText content extractor7

and the Onion near-deduplicator8. Although we
have our own pipeline set up (this is the pipeline
the first versions of hrWaC and slWaC were built
with), we decided to compile these versions of
web corpora with the Brno pipeline for two rea-
sons: 1. to inspect the pipeline’s capabilities, and
2. to extend the Croatian web corpus as much as
possible by using a different crawler.

Although language identification is seen as a

2http://nlp.ffzg.hr/resources/corpora/
setimes/

3http://www.tekstlab.uio.no/Bosnian/
Corpus.html

4http://tinyurl.com/mocnzna
5http://nlp.fi.muni.cz/trac/spiderling
6https://code.google.com/p/chared/
7http://code.google.com/p/justext/
8http://code.google.com/p/onion/

solved problem by many, the recently growing in-
terest for it indicates the opposite. Recently, re-
searchers focused on improving off-the-shelf tools
for identifying many languages (Lui and Bald-
win, 2012), discriminating between similar lan-
guages where standard tools fail (Tiedemann and
Ljubešić, 2012), identifying documents written in
multiple languages and identifying the languages
in such multilingual documents (Lui et al., 2014).

Text quality in automatically constructed web
corpora is quite an underresearched topic, with the
exception of boilerplate removal / content extrac-
tion approaches that deal with this problem implic-
itly (Baroni et al., 2008; Kohlschütter et al., 2010),
but quite drastically, by removing all content that
does not conform to the criteria set. A recent ap-
proach to assessing text quality in web corpora in
an unsupervised manner (Schäfer et al., 2013) cal-
culates the weighted mean and standard deviation
of n most frequent words in a corpus sample and
measures how much a specific document deviates
from the estimated means. This approach is in its
basic idea quite similar to ours because it assumes
that most of the documents in the corpus contain
content of good quality. The main difference in
our approach is that we do not constrain ourselves
to most frequent words as features, but use char-
acter and word n-grams of all available text.

3 Corpus construction

For constructing the corpora we used the Spi-
derLing crawler9 along with its associated tools
for encoding guessing, content extraction, lan-
guage identification and near-duplicate removal
(Suchomel and Pomikálek, 2012). Seed URLs
for Bosnian and Serbian were obtained via the
Google Search API queried with bigrams of mid-
frequency terms. Those terms were obtained from
corpora that were built with focused crawls of
newspaper sites as part of our previous research
(Tiedemann and Ljubešić, 2012). For Croatian
seed URLs, we used the home pages of web do-
mains obtained during the construction of the first
version of the hrWaC corpus. The number of seed
URLs was 8,388 for bsWaC, 11,427 for srWaC
and 14,396 for hrWaC. Each TLD was crawled for
21 days with 16 cores used for document process-
ing.

Because Serbian – which is frequently used on
the Serbian and Bosnian TLDs – uses two scripts

9http://nlp.fi.muni.cz/trac/spiderling

30



– Latin and Cyrillic – we had to adjust the stan-
dard corpus construction process to cope with both
scripts. This was done by 1. building new two-
script models for encoding guessing with Chared,
2. defining stop-words used in content extraction
in both scripts and 3. transforming extracted text
from Cyrillic to Latin with serbian.py10 before
performing language identification and duplicate
removal. We kept all content of the final corpora in
the Latin script to simplify further processing, es-
pecially because linguistic annotation layers were
added with models developed for Croatian which
uses the Latin script exclusively. The information
about the amount of Cyrillic text in each document
is still preserved as an attribute of the <doc> el-
ement. Overall the percentage of documents writ-
ten >90% in the Cyrillic script was 3.2% on the
Bosnian TLD and 16.7% on the Serbian TLD.

Near-duplicate identification was performed
both on the document and the paragraph level.
The document-level near-duplicates were removed
from the corpus cutting its size in half, while
paragraph-level near-duplicates were labeled by
the neardupe binary attribute in the <p> el-
ement enabling the corpus users to decide what
level of near-duplicate removal suits their needs.

The resulting size of the three corpora (in mil-
lions of tokens) after each of the three duplicate re-
moval stages is given in Table 1. Separate numbers
are shown for the new crawl of the Croatian TLD
and the final corpus consisting of both crawls.

PHYS DOCN PARN
bsWaC 1.0 722 429 288
hrWaC new 1,779 1,134 700
hrWaC 2.0 2,686 1,910 1,340
srWaC 1.0 1,554 894 557

Table 1: Size of the corpora in Mtokens after phys-
ical duplicate (PHY), document near-duplicate
(DOCN) and paragraph near-duplicate removal
(PARN)

At this point of the corpus construction process
the <doc> element contained the following at-
tributes:

• domain – the domain the document is pub-
lished on (e.g. zkvh.org.rs)

• url – the URL of the document
10http://klaus.e175.net/code/serbian.py

• crawl_date – date the document was
crawled

• cyrillic_num – number of Cyrillic let-
ters in the document

• cyrillic_perc – percentage of letters
that are Cyrillic

4 Corpus annotation

We annotated all three corpora on the level of
lemmas, morphosyntactic description (675 tags)
and dependency syntax (15 tags). Lemmatiza-
tion was performed with the CST’s Lemmatiser11

(Jongejan and Dalianis, 2009), morphosyntactic
tagging with HunPos12 (Halácsy et al., 2007) and
dependency syntax with mate-tools13 (Bohnet,
2010). All models were trained on the Croa-
tian 90k-token annotated corpus SETimes.HR14

(Agić and Ljubešić, 2014) that we recently ex-
panded with 50k additional tokens from vari-
ous newspaper domains (at this point we call
it simply SETimes.HR+). Although the anno-
tated training corpora are Croatian, previous re-
search (Agić et al., 2013a; Agić et al., 2013b) has
shown that on this level of tagging accuracy on
in-domain test sets (lemma≈96%, morphosyntac-
tic description (MSD) ≈87%, labeled attachment
score (LAS) ≈73%), annotating Serbian text with
models trained on Croatian data produced perfor-
mance loss of only up to 3% on all three levels
of annotation, while on out-of-domain test sets
(lemma ≈92%, MSD ≈81%, LAS ≈65%) there
was no loss in accuracy.

We nevertheless performed an intervention in
the SETimes.HR+ corpus before training the mod-
els used for annotating the Bosnian and the Ser-
bian TLD corpora. Namely, on the morphosyn-
tactic level the tagsets of Croatian and Serbian
are identical, except for one subset of tags for
the future tense which is present in Serbian and
not present in Croatian. This is because Croatian
uses the complex, analytic future tense consisting
of the infinitive of the main verb and the present
tense of the auxiliary verb have (radit ćemo) while
Serbian uses both the analytic and the synthetic
form where the two words are conflated into one
(radićemo).

11https://github.com/kuhumcst/cstlemma
12https://code.google.com/p/hunpos/
13https://code.google.com/p/mate-tools/
14http://nlp.ffzg.hr/resources/corpora/

setimes-hr/

31



To enable models to correctly handle both the
analytic and synthetic form of the future tense,
we simply repeated the sentences containing the
analytic form that we automatically transformed
to the synthetic one. By annotating the bsWaC
and srWaC corpora with the models trained on
the modified SETimes.HR+ corpus, we annotated
610k word forms in srWaC and 115k word forms
in bsWaC with the synthetic future tense. Manual
inspection showed that most of the tokens actually
do represent the future tense, proving that the in-
tervention was well worth it.

The lemmatization and morphosyntactic anno-
tation of all three corpora took just a few hours
while the full dependency parsing procedure on 40
server grade cores took 25 days.

5 Language identification

Because each of the three languages of interest is
used to some extent on each of the three TLDs and,
additionally, these languages are very similar, dis-
criminating between them presented both a neces-
sity and a challenge.

In previous work on discriminating between
closely related languages, the Blacklist (BL) clas-
sifier (Tiedemann and Ljubešić, 2012) has shown
to be, on a newspaper-based test set, 100% accu-
rate in discriminating between Croatian and Ser-
bian, and 97% accurate on all three languages of
interest.

Our aim at this stage was twofold: 1. to put the
existing BL classifier on a realistic test on (noisy)
web data and 2. to propose an alternative, simple,
data-intense, but noise-resistant method which can
be used for discriminating between closely related
languages or language varieties that are predomi-
nantly used on specific sections of the Web.

Our method (LM1) uses the whole content of
each of the three TLD web corpora (so large
amounts of automatically collected, noisy data) to
build unigram-level language models. Its advan-
tage over the BL classifier is that it does not re-
quire any clean, manually prepared samples for
training. The probability estimate for each word w
given the TLD, using add-one smoothing is this:

P̂ (w|TLD) = c(w, TLD) + 1∑
wi∈V (c(wi, TLD) + 1)

(1)

where c(w, TLD) is the number of times word w
occurred on the specific TLD and V is the vocab-
ulary defined over all TLDs.

We perform classification on each document as
a maximum-a-posteriori (MAP) decision, i.e. we
choose the language of the corresponding TLD
(l ∈ TLD) that produces maximum probability
with respect to words occurring in the document
(w1...wn):

lmap = arg max
l∈TLD

∏
i=1..n

P̂ (wi|l) (2)

We should note here that our approach is identi-
cal to using the Naı̈ve Bayes classifier without the
a priori probability for each class, i.e. language.

Speaking in loose terms, what we do is that for
each document of each TLD, we identify, on the
word level, to which TLD data collection the doc-
ument corresponds best.

Because Bosnian is mostly a mixture of Croat-
ian and Serbian and actually represents a contin-
uum between those two languages, we decided
to compare the BL and the LM1 classifier on a
much more straight-forward task of discriminat-
ing between Croatian and Serbian. The results of
classifying each document with both classifiers are
given in Table 2. They show that both classifiers
agree on around 75% of decisions and that around
0.4 percent of documents from hrWaC are identi-
fied as Serbian and 1.5 percent of document from
srWaC as Croatian.

BL LM1 agreement
hrWaC 0.42% 0.3% 73.15%
srWaC 1.93 % 1.28% 80.53%

Table 2: Percentage of documents identified by
each classifier as belonging to the other language

We compared the classifiers by manually in-
specting 100 random documents per corpus where
the two classifiers were not in agreement. The re-
sults of this tool-oriented evaluation are presented
in Table 3 showing that the LM1 classifier pro-
duced the correct answer in overall 4 times more
cases than the BL classifier.

If we assume that the decisions where the two
classifiers agree are correct (and manual inspec-
tion of data samples points in that direction) we
can conclude that our simple, data-intense, noise-
resistant LM1 method cuts the BL classification
error to a fourth. We consider a more thorough
evaluation of the two classifiers, probably by pool-
ing and annotating documents that were identified

32



BL LM1 NA
hrWaC 18% 62% 20%
srWaC 10% 48% 42%

Table 3: Percentage of correct decisions of each
classifier on documents where the classifiers dis-
agreed (NA represents documents that are a mix-
ture of both languages)

as belonging to the other TLD language by some
classifier, as future work.

Due to the significant reduction in error by the
LM1 classifier, we annotated each document in the
hrWaC and srWaC corpora with the LM1 binary
hr-sr language identifier while on bsWaC we used
the LM1 ternary bs-hr-sr classifier. This decision
is based on the fact that discriminating between all
three languages is very hard even for humans and
that for most users the hr-sr discrimination on the
two corpora will be informative enough. In each
document we encoded the normalized distribution
of log-probabilities for the considered languages,
enabling the corpus user to redefine his own lan-
guage criterion.

The percentage of documents from each corpus
being identified as a specific language is given in
Table 4.

bs hr sr
bsWaC 78.0% 16.5% 5.5%
hrWaC - 99.7% 0.3%
srWaC - 1.3% 98.7%

Table 4: Distribution of identified languages
throughout the three corpora

Additional attributes added to the <doc> ele-
ment during language identification are these:

• lang – language code of the language iden-
tified by maximum-a-posteriori

• langdistr – normalized distri-
bution of log probabilities of lan-
guages taken under consideration (e.g.
bs:-0.324|hr:-0.329|sr:-0.347
for a document from bsWaC)

6 Identifying text of low quality

Finally, we tackled the problem of identifying doc-
uments of low text quality in an unsupervised
manner by assuming that most of the content of

each web corpus is of good quality and that low
quality content can be identified as data points
of lowest probability regarding language models
built on the whole data collection. We pragmati-
cally define low quality content as content not de-
sirable for a significant number of research or ap-
plication objectives.

For each TLD we calculated character n-gram
and word n-gram language models in the same
manner as in the previous section (Equation 1) for
language identification. We scored each TLD doc-
ument with each language model that was built on
that TLD. To get a probability estimate which does
not depend on the document length, we calculated
probabilities of subsequences of identical length
and computed the average of those.

We manually inspected documents with low
probability regarding character n-gram models
from level 1 to level 15 and word n-gram mod-
els from level 1 to level 5. Word n-gram mod-
els proved to be much less appropriate for cap-
turing low quality documents by lowest probabil-
ity scores than character n-gram models. Among
character n-gram models, 3-gram models were
able to identify documents with noise on the token
level while 12-gram models assigned low proba-
bilities to documents with noise above the token
level.

The most frequent types of potential noise
found in lowest scored documents in all three cor-
pora are the following:

• 3-gram models
– non-standard usage of uppercase, lower-

case and punctuation
– URL-s
– uppercase want ads
– formulas

• 12-gram models
– words split into multiple words (due to

soft hyphen usage or HTML tags inside
words)

– enumerated and bulleted lists
– uppercase want ads
– non-standard text (slang, no uppercased

words, emoticons)
– dialects
– lyric, epic, historical texts

33



The character 3-gram method has additionally
proven to be a very good estimate of text quality on
the lexical level by strongly correlating (0.74) with
the knowledge-heavy method of calculating lexi-
cal overlap of each document with a morphologi-
cal dictionary which is available for Croatian15.

An interesting finding is that word-level models
perform much worse for this task than character-
level models. We hypothesize that this is due to
feature space sparsity on the word level which is
much lower on the character level.

We decided to postpone any final decisions (like
discretizing these two variables and defining one
or two categorical ones) and therefore encoded
both log-probabilities as attributes in each doc-
ument element in the corpus leaving to the fi-
nal users to define their own cut-off criteria. To
make that decision easier, for each document and
each character n-gram method we computed the
percentage of documents in the corpus that have
an equal or lower result of that character n-gram
method. This makes removing a specific percent-
age of documents with lowest scores regarding a
method much easier.

We also computed one very simple estimate of
text quality – the percentage of characters that are
diacritics. Namely, for some tasks, like lexicon en-
richment, working on non-diacritized text is not an
option. Additionally, it is to expect that lower us-
age of diacritics points to less standard language
usage. The distribution of this text quality esti-
mate in the hrWaC corpus (all three corpora fol-
low the same pattern) is depicted in Figure 1 show-
ing that the estimate is rather normally distributed
with a small peak at value zero representing non-
diacritized documents.

In each <doc> element we finally encoded 5
attributes regarding text quality:

• 3graph – average log-probability on 100-
character sequences regarding the character
3-gram model trained on the whole TLD cor-
pus

• 3graph_cumul – percentage of documents
with equal or lower 3graph attribute value

• 12graph – same as 3graph, but computed
with the character 12-gram model

• 12graph_cumul – like 3graph_cumul,
but for the 12graph attribute

15http://bit.ly/1mRjMrP

Percentage of diacritics

Fr
eq
ue
nc
y

0.00 0.02 0.04 0.06 0.08 0.10

0
50
00
0

10
00
00

15
00
00

Figure 1: Distribution of the percentage of charac-
ters of a document being diacritics

• diacr_perc – percentage of non-
whitespace characters that are diacritics

We plan to perform extrinsic evaluation of the
three estimates of text quality on various NLP
tasks such as language modeling for statistical
machine translation, morphological lexicon induc-
tion, distributional lexicon induction of closely re-
lated languages and multi-word expression extrac-
tion.

7 Conclusion

In this paper we described the process of con-
structing three TLD corpora of Bosnian, Croatian
and Serbian.

After presenting the construction and annota-
tion process of the largest existing corpora for
each of the three languages, we focused on the
issue that all three languages are to some extent
used on all three TLDs. We presented a method
for discriminating between similar languages that
is based on unigram language modeling on the
crawled data only, which exploits the fact that the
majority of the data published on each TLD is
written in the language corresponding to that TLD.
We reduced the error of a state-of-the-art classifier
to a fourth on documents where the two classifiers
disagree on.

We dealt with the problem of identifying low
quality content as well, again using language mod-
eling on crawled data only, showing that document
probability regarding a character 3-gram model is
a very good estimate of lexical quality, while low

34



character 12-gram probabilities identify low qual-
ity documents beyond the word boundary.

We encoded a total of 12 attributes in the docu-
ment element and the paragraph-near-duplicate in-
formation in the paragraph element enabling each
user to search for and define his own criteria.

We plan on experimenting with those attributes
on various tasks, from language modeling for sta-
tistical machine translation, to extracting various
linguistic knowledge from those corpora.

Acknowledgement

The research leading to these results has re-
ceived funding from the European Union Sev-
enth Framework Programme FP7/2007-2013 un-
der grant agreement no. PIAP-GA-2012-324414
(project Abu-MaTran).

References
[Agić and Ljubešić2014] Željko Agić and Nikola

Ljubešić. 2014. The SETimes.HR linguistically
annotated corpus of Croatian. In Proceedings of
LREC 2014.

[Agić et al.2013a] Željko Agić, Nikola Ljubešić, and
Danijela Merkler. 2013a. Lemmatization and mor-
phosyntactic tagging of Croatian and Serbian. In
Proceedings of the 4th Biennial International Work-
shop on Balto-Slavic Natural Language Processing,
pages 48–57, Sofia, Bulgaria, August. Association
for Computational Linguistics.

[Agić et al.2013b] Željko Agić, Danijela Merkler, and
Daša Berović. 2013b. Parsing Croatian and Serbian
by using Croatian dependency treebanks. In Pro-
ceedings of the Fourth Workshop on Statistical Pars-
ing of Morphologically Rich Languages (SPMRL
2013).

[Baroni et al.2008] Marco Baroni, Francis Chantree,
Adam Kilgarriff, and Serge Sharoff. 2008.
Cleaneval: a competition for cleaning web pages.
In Proceedings of the Sixth International Language
Resources and Evaluation (LREC’08), Marrakech,
Morocco. European Language Resources Associa-
tion (ELRA).

[Baroni et al.2009] Marco Baroni, Silvia Bernardini,
Adriano Ferraresi, and Eros Zanchetta. 2009. The
WaCky wide web: a collection of very large linguis-
tically processed web-crawled corpora. Language
Resources and Evaluation, pages 209–226.

[Bohnet2010] Bernd Bohnet. 2010. Very high accuracy
and fast dependency parsing is not a contradiction.
In The 23rd International Conference on Computa-
tional Linguistics (COLING 2010).

[Halácsy et al.2007] Péter Halácsy, András Kornai, and
Csaba Oravecz. 2007. HunPos: an open source

trigram tagger. In Proceedings of the 45th An-
nual Meeting of the ACL on Interactive Poster and
Demonstration Sessions, ACL ’07, pages 209–212,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.

[Jongejan and Dalianis2009] Bart Jongejan and Her-
cules Dalianis. 2009. Automatic training of lemma-
tization rules that handle morphological changes in
pre-, in- and suffixes alike. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP, pages
145–153.

[Kohlschütter et al.2010] Christian Kohlschütter, Peter
Fankhauser, and Wolfgang Nejdl. 2010. Boilerplate
detection using shallow text features. In Brian D.
Davison, Torsten Suel, Nick Craswell, and Bing Liu,
editors, WSDM, pages 441–450. ACM.

[Ljubešić and Erjavec2011] Nikola Ljubešić and
Tomaž Erjavec. 2011. hrWaC and slWac: Com-
piling Web Corpora for Croatian and Slovene. In
Text, Speech and Dialogue - 14th International
Conference, TSD 2011, Pilsen, Czech Republic,
Lecture Notes in Computer Science, pages 395–402.
Springer.

[Lui and Baldwin2012] Marco Lui and Timothy Bald-
win. 2012. langid.py: An off-the-shelf language
identification tool. In ACL (System Demonstra-
tions), pages 25–30.

[Lui et al.2014] Marco Lui, Jey Han Lau, and Timothy
Baldwin. 2014. Automatic detection and language
identification of multilingual documents. Transac-
tions of the Association for Computational Linguis-
tics.

[Schäfer and Bildhauer2012] Roland Schäfer and Felix
Bildhauer. 2012. Building large corpora from the
web using a new efficient tool chain. In Proceed-
ings of the Eight International Conference on Lan-
guage Resources and Evaluation (LREC’12), Istan-
bul, Turkey. European Language Resources Associ-
ation (ELRA).

[Schäfer et al.2013] Roland Schäfer, Adrien Barbaresi,
and Felix Bildhauer. 2013. The good, the bad, and
the hazy: Design decisions in web corpus construc-
tion. In Proceedings of the 8th Web as Corpus Work-
shop (WAC8).

[Suchomel and Pomikálek2012] Vı́t Suchomel and Jan
Pomikálek. 2012. Efficient web crawling for large
text corpora. In Serge Sharoff Adam Kilgarriff, edi-
tor, Proceedings of the seventh Web as Corpus Work-
shop (WAC7), pages 39–43, Lyon.

[Tiedemann and Ljubešić2012] Jörg Tiedemann and
Nikola Ljubešić. 2012. Efficient discrimination be-
tween closely related languages. In Proceedings of
COLING 2012, pages 2619–2634, Mumbai, India.

35


