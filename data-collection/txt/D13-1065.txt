










































Two-Stage Method for Large-Scale Acquisition of Contradiction Pattern Pairs using Entailment


Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 693–703,
Seattle, Washington, USA, 18-21 October 2013. c©2013 Association for Computational Linguistics

Two-stage Method for Large-scale Acquisition of
Contradiction Pattern Pairs using Entailment

Julien Kloetzer∗ Stijn De Saeger† Kentaro Torisawa‡ Chikara Hashimoto§
Jong-Hoon Oh¶ Motoki Sano‖ Kiyonori Ohtake∗∗

Information Analysis Laboratory,
National Institute of Information and Communications Technology (NICT), Kyoto, Japan
{∗julien, † stijn, ‡ torisawa, § ch, ¶rovellia, ‖msano, ∗∗kiyonori.ohtake}@nict.go.jp

Abstract

In this paper we propose a two-stage method
to acquire contradiction relations between
typed lexico-syntactic patterns such as Xdrug
prevents Ydisease and Ydisease caused by
Xdrug . In the first stage, we train an SVM
classifier to detect contradiction pattern pairs
in a large web archive by exploiting the exci-
tation polarity (Hashimoto et al., 2012) of the
patterns. In the second stage, we enlarge the
first stage classifier’s training data with new
contradiction pairs obtained by combining the
output of the first stage’s classifier and that of
an entailment classifier. We acquired this way
750,000 typed Japanese contradiction pattern
pairs with an estimated precision of 80%. We
plan to release this resource to the NLP com-
munity.

1 Introduction

The ability to detect contradictory information in
text has many practical applications. Among those,
Murakami et al. (2009) pointed out that a contra-
diction recognition system can detect conflicts and
anomalies in large bodies of texts and flag them to
help users identify unreliable information. For ex-
ample, many Japanese web pages claim that agari-
cus prevents cancer, where agaricus is a species of
mushroom found in a variety of commercial prod-
ucts. Although this has been accepted by many
Japanese people, by Googling keywords ”agaricus”,
”promotes” and ”cancer”, we can find pages claim-
ing that ”agaricus promotes cancer”, some of which
point to a study authorized by the Japanese Min-
istry of Health, Labour and Welfare1 reporting that

1 http://www.mhlw.go.jp/topics/bukyoku/iyaku/syoku-
anzen/qa/060213-1.html

a commercial product containing agaricus promoted
cancer. Obviously, the existence of these pages casts
serious doubt on the ability of agaricus to prevent
cancer and encourages readers to dig more about this
subject.

The above example suggests that recognizing
contradictory information can guide users to a true
fact. Likewise, we believe that contradiction recog-
nition is also useful when dealing with non-factual
information that occupy most of our daily lives. For
instance, there is a big controversy recently whether
Japan should join an economic partnership agree-
ment called the Trans Pacific Partnership (TPP), and
quite serious but contradictory claims are plentiful in
the mass media and on the web, e.g., TPP will wipe
out Japan’s agricultural businesses and TPP will
strengthen Japan’s agricultural businesses. Neither
of these are facts; they are predictions that can only
be realized or disputed after the underlying decision-
making is done: joining or refusing the TPP.

Furthermore, after reading documents including
contradictory predictions, one should notice that
each of them is supported by a convincing the-
ory that has no obvious defect, e.g., “Exports of
Japan’s agricultural products will increase thanks to
the TPP” or “A large amount of low-price agricul-
tural products will be imported to Japan due to the
TPP”. Even if one of these predictions may just hap-
pen to be true because of unexpected reasons such as
minor fluctuations in the Japanese yen, we must sur-
vey such theories that support contradictory predic-
tions, conduct balanced decision-making, and pre-
pare counter measures for the expected problems af-
ter examining multiple viewpoints. Contradiction
recognition should be useful to select documents to
be surveyed.

693



Figure 1: Method workflow

We have developed a method for recog-
nizing pairs of contradictory binary patterns
such as 〈“X promotes Y”, “X prevents Y”〉 and
〈“X will wipe out Y”, “X will strengthen Y”〉. To
solve the problem described above, we can easily
develop a system that can find contradictory text
fragments from the web like “agaricus promotes
cancer” and “agaricus prevents cancer” from the
discovered contradictory pattern pairs.

Our method is a two-stage procedure with three
supervised classifiers (Fig. 1). In the first stage,
we build a classifier BASE to recognize contradic-
tions between binary patterns, and a classifier ENT
to recognize entailment. In the second stage, we
combine the contradiction pairs recognized by BASE
and the entailment pairs recognized by ENT to ex-
pand BASE’s training data and train a new contra-
diction classifier, EXP. This expansion using en-
tailment is one key idea of this work: we acquired
750,000 contradiction pairs with 80% precision us-
ing the expanded training data, more than doubling
the 285,000 pairs acquired at the same precision
level without expansion. We also demonstrate that
this result is not trivial by showing that our method
outperforms an alternative one based on Integer Lin-
ear Programming inspired by the successful entail-
ment recognition method of Berant et al. (2011).

As another technical contribution of this work, we
exploit the recently proposed semantic polarity of
excitation (Hashimoto et al., 2012) to recognize con-
tradictions between binary patterns. Hashimoto et
al. (2012) previously showed that excitation polari-
ties are useful to recognize contradictions between
phrases that consist of a noun and a predicate, such
as “promote cancer” and “prevent cancer”. While

it is trivial to extend this framework to contradic-
tions between unary patterns such as “promote X”
and “prevent X” by replacing the common nouns
in each pair with a variable, the information rep-
resented in unary patterns is often vague, and it is
unlikely that a contradiction between unary patterns
directly leads to the discovery of unreliable infor-
mation to be flagged or to a meaningful survey of
complex problems. As exemplified by the agaricus
and TPP examples, contradictions between binary
patterns that include two variables such as “X pro-
motes Y” or “X will wipe out Y” are more useful
than those between unary patterns. We also show
that it is not trivial to recognize contradictions be-
tween binary patterns using contradictions between
unary patterns.

Most works dealing with contradiction recogni-
tion up till now (Harabagiu et al., 2006; Bobrow
et al., 2007; Kawahara et al., 2008; Kawahara et
al., 2010; Ohki et al., 2011) focus on recognizing
contradictions between full sentences or documents,
not text fragments that match our relatively short
patterns (survey in Section 5). We expect that the
contradictory pattern pairs we acquired can be used
as building blocks in such full-fledged contradiction
recognition for full sentences or documents, simi-
larly to antonym pairs in Harabagiu et al. (2006).

Also, we should emphasize that our method
focuses on the most challenging part of contra-
diction recognition according to the classification
of De Marneffe et al. (2008). Since we discard
patterns with negations, an evident source of contra-
dictions like 〈“X causes Y”, “X does not cause Y”〉,
most of our output are non-trivial contradic-
tions related to high-level semantic phenomena,
e.g., contradiction pairs related to antonyms
like 〈“Xが Yを上げる”, “Xが Yを下げる”〉
(〈“X increases Y”, “X decreases Y”〉), lexical contra-
dictions like 〈“Xが Yに勝つ”, “Yが Xに勝つ”〉
(〈“X wins against Y”, “Y wins against X”〉), or
contradictions due to common-sense knowledge
like 〈“Xが Yを安心させる”, “Xが Yを裏切る”〉
(〈“X reassures Y”, “X betrays Y”〉). We believe
acquiring such contradictions in a large scale is a
valuable contribution.

The following is the outline of this paper. Sec-
tion 2 details our target and our proposed method.
Evaluation results are discussed in Section 3. Sec-

694



Figure 2: Detailed data flow

tion 4 details our features set, and Section 5 related
work. Section 6 provides a conclusion.

2 Proposed method

As showed in Figure 1, our method consists of
three supervised classifiers. Classifiers BASE and
EXP recognize contradiction relations between bi-
nary patterns, and ENT recognizes entailment rela-
tions between binary patterns. The contradiction
pairs recognized by BASE and the entailment pairs
recognized by ENT are combined to generate new
contradiction pairs, part of which are then added to
BASE training data to train the EXP classifier. Our
final output is the set of all binary pattern pairs re-
garded as contradictions by EXP. Since the depen-
dencies between these three classifiers, their distinct
sets of training data, and the two data sets to be clas-
sified (we describe those in the two sections below)
is a bit complex, we show a complete description of
the whole process in Figure 2.

The key idea is in the scheme that expands the
training data. Logically speaking, patterns p and r
are contradictory if there exists a pattern q such that
p entails q and q contradicts r. For example, since
“X causes Y” entails “X promotes Y” and “X pro-
motes Y” contradicts “X prevents Y”, then “X causes
Y” contradicts “X prevents Y”. Hence, by combin-
ing entailment and contradiction pairs, we can ob-
tain more contradiction pairs.

Following this property of contradiction relations,
we collect a set of pattern pairs {〈p, r〉} for which

there exists a pattern q such that ENT recognizes that
p entails q and BASE recognizes that q contradicts r.
Then we rank these pairs based on a novel scoring
function called Contradiction Derivation Precision
(CDP) and expand BASE training data by adding to
it the top-ranked pairs according to CDP in order to
train EXP. This ranking scheme selects highly accu-
rate contradiction pairs and prevents errors caused
by BASE and ENT from being propagated to EXP.

In the following, after defining the patterns for
which we acquire contradiction relations, we de-
scribe BASE, EXP, ENT, and our expansion scheme.

2.1 Patterns

In this work, a binary pattern is a word sequence
on the path of dependency relations connecting two
nouns in a syntactic dependency tree, like “X causes
Y”, and we say a noun pair co-occurs with a pattern
if the two nouns are connected by this pattern in the
dependency tree of a sentence in the corpus.

We focus on typed binary patterns, which place
semantic class restrictions on the noun pairs they
co-occur with, e.g., “Yorganization is in Xlocation”.
Subscripts organization and location indicate the se-
mantic classes of the X and Y slots. Since typed
patterns can distinguish between multiple senses
of ambiguous patterns, they greatly reduce errors
due to pattern ambiguity (De Saeger et al., 2009;
Schoenmackers et al., 2010; Berant et al., 2011).
We automatically induced semantic classes from our
corpus using the EM-based noun clustering algo-

695



rithm presented in Kazama and Torisawa (2008),
and clustered one million nouns into 500 rela-
tively clean semantic classes, including for example
classes of diseases and of chemical substances.

The binary patterns and their co-occurring noun
pairs were extracted from our corpus of 600 mil-
lion Japanese web pages dependency parsed with
KNP (Kurohashi and Nagao, 1994). We restricted
our patterns to the most frequent 3.9 million pat-
terns of the form “X-[case particle] Y-[case parti-
cle] predicate” such as “X-ga Y-ni aru” (“X is in Y”)
which do not contain any negation, number, symbol
or punctuation character. Based on our observation
that patterns in meaningful contradiction and entail-
ment pairs tend to share many co-occurring noun
pairs, we used as input to our classifiers the set Pall
of 792 million pattern pairs for which both patterns
share three co-occurring noun pairs.

2.2 BASE: First stage Classifier for
Contradiction

Below, we detail BASE: its training data and input
data to be classified, and some experimental results.

Our first stage classifier for contradictions, BASE,
is an SVM that uses commonsensical surface and
lexical resources based features, such as n-grams ex-
tracted from patterns, which will be detailed in Sec-
tion 4. An important point to be stressed here is
that we restricted the pattern pairs to be classified
by BASE by exploiting their excitation polarity, a
semantic orientation proposed by Hashimoto et al.
(2012). Excitation characterizes unary patterns as
excitatory, inhibitory, or neutral. Excitatory unary
patterns, such as “cause X” or “increase X”, entail
that the function, effect, purpose, or role of their ar-
gument’s referent is activated or enhanced, and in-
hibitory unary patterns, such as “prevent X” or “X
disappears”, entail that the function, effect, purpose,
or role of their argument’s referent is deactivated or
suppressed. Neutral unary patterns like “close to X”
are neither excitatory nor inhibitory.

We exploited excitation to restrict the input of
BASE. Based on the result of Hashimoto et al.
(2012) showing that two unary patterns with op-
posite polarity have a higher chance to be a con-
tradiction, we extracted from set Pall the set Popp
of binary pattern pairs that contain unary patterns
with opposite excitation polarities as sub-patterns.

〈“Y cause X”, “Y prevent X”〉 is an example of such
a pair since the unary sub-patterns “cause X” and
“prevent X” are respectively excitatory and in-
hibitory. We used here 6,470 excitation unary pat-
terns hand-labeled as either excitatory (4,882 pat-
terns) or inhibitory (1,588 patterns). Set Popp con-
tains 8 million pattern pairs with roughly 38% true
contradiction pairs, and is the input to BASE. We
will show in experiments at the end of this section
that this restriction is necessary to obtain good per-
formance for BASE. We also tried to add the excita-
tion polarities in BASE’s feature set and classify Pall,
but the performance was worse.

Training Data Another key feature of BASE is
that it is distantly supervised. We did not use
training samples that are directly manually anno-
tated. Instead we automatically generated training
data from a smaller set of (non-)contradiction unary
pattern pairs. We first prepared a set of roughly
800 unary pattern pairs hand-labeled by three human
annotators as contradictions (238 pairs) and non-
contradictions (558 pairs) using majority vote. The
inter-annotator agreement was 0.78 (Fleiss’kappa).
Inspired by Hashimoto et al. (2012), we selected
these unary pattern pairs among pairs with high dis-
tributional similarity, with and without restricting
them to having opposite excitation polarity, such as
to get a fair distribution of contradictions and non-
contradictions.

We then extracted from set Pall all 256,000 pat-
tern pairs containing a contradictory unary pattern
pair, and all 5.2 million pattern pairs containing a
non-contradictory unary pattern pair, which we re-
spectively used as positive and negative training data
(estimated 79% and 73% accuracy from 200 hand-
labeled samples). Table 1 shows some examples.

The optimal composition of training data for
BASE was determined according to preliminary ex-
periments using our development set (1,000 manu-
ally labelled samples. See Section 3.1). We trained
20 different classifiers using from 6,250 to 50,000
positive samples (4 sets) and from 12,500 to 200,000
negative samples (5 sets), doubling the amounts in
each step, for a total of 20 configurations. We could
not try a larger training data due to long training time
but we do not expect it to be a problem because the
worst performance was observed with large train-

696



Table 1: Examples of training samples for BASE obtained from unary pattern pairs
Binary pattern pair (the unary pattern pair that extracted it is underlined) Unary pattern pair label

Y も X が悪い (X is bad in Y too) - Y でも X が良い (X is good even in Y) contradiction
Y も X に向かう (Y too heads toward X) - Y も X を出る (Y too comes out of X) contradiction

X にY を 加える (add Y to X) - X をY に 入れる (insert X into Y) non-contradiction
Y も X に来る (Y too comes to X) - Y とは X に行く (go to X with Y) non-contradiction

Figure 3: Effect of the restriction using excitation

ing data (25,000 positives and 200,000 negatives;
the difference from the optimal setting was 2.3% in
average precision). The optimal training data set,
Trainbase, consists of 12,500 positives and 100,000
negatives samples as described above and is the one
we use in our experiments below and in Section 3.

Since BASE input for classification data is Popp
we also tried sampling Trainbase from Popp. We
obtained 56.27% average precision for our classi-
fier BASE, and 52.99% when restricting the source
of training data to pairs in Popp. We believe that the
difference lies in the size of the sets from which we
sampled our training data: while there are 5.46 mil-
lion binary pattern pairs in Pall with a hand-labeled
unary pattern pair in Pall, there are only 237,000
pairs in Popp. We believe this much smaller sam-
ple source lead to a lower performance because it
included much less variations of the patterns.

To train BASE and other classifiers mentioned in
this paper, we used the SVM tool TinySVM2 with
a polynomial kernel of degree 2, the setting which
showed the best performance during our preliminary
experiments.

Effect of Excitation Polarities We also empiri-
cally examined the effect of the restriction on the
patterns using excitation polarities. We used our test
set (2,000 manually annotated samples described in

2 http://chasen.org/˜taku/software/TinySVM/

Section 3.1) and 250 manually annotated samples
(majority vote from 3 annotators) from top ranked
pairs of Pall to draw precision curves for BASE over
the top 2 million binary pairs from both Popp and
Pall. In each case we assumed that pairs were dis-
tributed uniformly (i.e., with a constant interval) in
the ranked list of pairs of Popp and Pall, and com-
puted precision accordingly. Since the pairs sets
are reasonably large and were sampled randomly we
thought this was a reasonable hypothesis. The pre-
cision over Popp is higher than that over Pall with
a large margin, suggesting that the restriction using
excitation polarities is beneficial.

2.3 ENT: First stage Classifier for Entailment

ENT is an SVM classifier for entailment trained us-
ing 27,500 hand-annotated binary pattern pairs (set
Trainent, 45% of positive entailment pairs) created
for some previous work (Kloetzer et al., 2013). It es-
sentially uses the same feature set as that for BASE
with the addition of several distributional similar-
ity measures (see Section 4 below for more details).
This classifier is given all pairs of Pall as input and
scores each of them. For this study, we considered
the 44.5 million pattern pairs with a positive SVM
score as entailment pairs. Manual annotation of 200
random samples revealed that the precision of these
pairs was 63% and that the top 7.1 million pairs had
80% precision (result interpolated from the top 16%
of the annotated samples).

2.4 Second stage: Training Data Expansion
and Classifier EXP

Below, we show how we combine BASE’s top output
(hereafter C) and ENT’s top output (hereafter E) in
the second stage of our method to expand Trainbase
and train a new classifier, EXP.

The training data expansion process is based on
the following logical constraint: if a pattern p entails
a pattern q and pattern q contradicts a third pattern r,
then p must contradict r. For example, because “X

697



Table 2: Examples of triplets 〈p, q,r〉 where p entails q, q contradicts r, and hence p contradicts r
Pattern p Pattern q Pattern r X/Y examples SV M Score(p, r) CDP (p, r)

Y から X が消える Y から X が無くなる Y が X に満ちる 怒り/眼 0.3 0.98X disappears from Y X vanishes from Y Y is full of X anger/eye
Y に X を停止する Y に X を終える Y から X を始める ４月/活動 -0.3 0.61stop X in Y finish X in Y start X in Y April/activity

X は Y を示す X が Y を持つ X は Y を失う チーム/自信 0.07 0.45X shows Y X have Y X loses Y team/confidence

Algorithm 1 Training data expansion: C is the top 5%
output of BASE, E is the top output of ENT (score > 0)
1: procedure EXPAND(C, E)
2: Compute the set of expanded pairs C′ = {〈p, r〉 |

∃q : 〈p, q〉∈ E,〈q, r〉∈ C}.
3: Rank the pairs in C′ using CDP.
4: Add the N top-ranked pairs in C′ \ C as new positive

samples to Trainbase.
5: Remove incoherent negative training samples using

negative cleaning.
6: end procedure

causes Y” (pattern p) entails “X promotes Y” (pattern
q) and the latter contradicts “X prevents Y” (pattern
r), we conclude that “X causes Y” (p) contradicts
“X prevents Y” (r). We call the former contradic-
tion 〈q, r〉 a source contradiction pair, and the later
pair 〈p, r〉 an expanded contradiction pair. Based on
this idea, we combine C and E to aggressively ex-
pand Trainbase. This process is described in Al-
gorithm 1, and Table 2 shows examples of triples
〈p, q,r〉 obtained in our experiments.

Expanding pairs from C and E compounds the er-
rors made by BASE and ENT, hence it is crucial to
select a highly precise subset of the expanded pairs.
Taking the top pairs according to their SVM score
would achieve this, but since BASE already handles
correctly such pairs, they should not help much as
new training data. We therefore propose a new scor-
ing function for selecting highly precise expanded
pairs: Contradiction Derivation Precision (CDP ).

CDP was designed according to the following
assumption: a source contradiction pair that derives
correct expanded pairs with a high precision should
be reliable. Probably, all the expanded pairs derived
from such a reliable source pair will be correct and
should be included in the new training data .

In our formulation of CDP , correctness of an ex-
panded pair is judged according to the pair’s SVM
score using BASE. In other words, we regard an

expanded pair that has an SVM score above some
threshold α as a true contradiction. A source contra-
diction pair that derives true contradiction pairs with
a high precision is regarded as a reliable source con-
tradiction pair. CDP , which is defined over a ex-
panded pairs, is the maximum precision among that
of the source contradiction pairs that derive a given
expanded pair.

We first define CDPsub(q, r) over a source con-
tradiction pair 〈q, r〉 as the ratio of expanded pairs
obtained from 〈q, r〉 whose SVM score is above
threshold α. This ratio corresponds to the precision
of the expanded pairs derived from the source con-
tradiction pair 〈q, r〉.

CDPsub(q, r) =
|{〈p, r〉 ∈ Ex(q, r) | Sc(p, r) > α}|

|Ex(q, r)|

Here Ex(q, r) is the set of expanded pairs derived
from a source pair 〈q, r〉, and Sc is the SVM score
given by BASE. In our experiments, we set α = 0.46
such that pattern pairs for which BASE gives a score
over α corresponds to the top 5% of BASE’s output.
CDP (p, r) over an expanded pair is defined as fol-
lows, where Source(p, r) is the set of source con-
tradiction pairs that were derived into the expanded
pair 〈p, r〉.

CDP (p, r) = max〈q,r〉∈Source(p,r)CDPsub(q, r)

We then expand the top 5% contradictions of
BASE’s output (set C) and pattern pairs scored pos-
itively by ENT (set E), rank all expanded pairs not
already in C according to CDP, and add the top N
pairs with the highest CDP values as positives to
Trainbase to train EXP. The value of N shall be
determined empirically in later experiments using
a development set. Note that, since CDP (p, r) is
independent of 〈p, r〉’s SVM score, even pairs that
were assigned a negative score by BASE can become
highly ranked by CDP (second triplet in Table 2)

698



and be added to train EXP, hence we expect EXP to
learn something new from these pairs.

Finally, after the addition of expanded pairs, we
remove incoherent training samples. We propose to
remove from the negative training samples of EXP
any pattern pair that may conflict with the newly
added positives; we call this step negative cleaning.
Intuitively, since the content word pairs in a pattern
pair should present some of the strongest evidence
for determining the patterns (non-)contradiction sta-
tus, we remove any negative sample that shares a
content word pair with one of the added expanded
pairs. The final training data for EXP, set Trainexp,
consists of the following: (1) positive samples from
Trainbase, (2) (positive) expanded pairs, and (3)
negative training samples from Trainbase, cleaned
using negative cleaning. We confirmed in our exper-
iments that negative cleaning was necessary to train
a strong EXP classifier (details omitted for reason of
space).

After training EXP with Trainexp, we classify
Popp with EXP to produce the final output of the
whole method. Note that while this expansion pro-
cess can be re-iterated with EXP’s output, our exper-
iments failed to show any improvement with subse-
quent iterations.

3 Evaluation

This section presents our experimental results. We
describe first how we constructed test and develop-
ment data, and then report comparison results be-
tween our method and others including BASE and an
Integer Linear Programming-based (ILP) method.

3.1 Development and Test Data

We asked three human annotators to label 3,000 bi-
nary pattern pairs randomly sampled from Popp as
contradiction or non-contradiction to be used as de-
velopment (1,000 pairs) and test (2,000 pairs) sets.
We considered a pattern pair as a true contradic-
tion relation if at least two out of the three annota-
tors marked it as positive. The inter-rater agreement
score (Fleiss Kappa) was 0.523, indicating moderate
agreement (Landis and Koch, 1977). As a definition
of contradiction, we used the notion of incompati-
bility (i.e., two statements are extremely unlikely to
be simultaneously true) proposed by De Marneffe et

Figure 4: Precision of all the compared methods

al. (2008). We then say binary patterns such as “X
causes Y” and “X prevents Y” are contradictory if
the above definition holds for any noun pair that can
instantiate the patterns’ variables in the provided se-
mantic class pair.

Because our semantic classes are obtained by au-
tomatic clustering and have no meaningful labels,
we followed Szpektor et al. (2007) and provided the
annotators with three random noun pairs that co-
occur with the patterns as a proxy for the class pair.
The annotators marked a given pattern pair as posi-
tive if the contradiction relation between the patterns
held for all three noun pairs presented.

3.2 Experimental Results
Here we show how our proposed method outper-
forms baseline methods. We compare the following
four methods:

• PROPOSED: our proposed method. N , the
number of newly added positive training sam-
ples during the training data expansion pro-
cess, was set to 6,000 according to preliminary
experiments using the development set. We
tried 50 different values of N from 1,000 up to
50,000, adding 1,000 each time, and chose the
N value giving the highest average precision
against our development set (1,000 samples).

• BASE: our first stage classifier.

• PROP-SCORE: same as PROPOSED except for
the use of BASE’s SVM score instead of CDP .
N was set to 30,000 in the same way we set N
for PROPOSED.

• HAS: an adaptation of the contradiction ex-
traction method presented in Hashimoto et al.

699



(2012). For a binary pattern pair we first
extracted its unary pattern pair with opposite
polarity (or one at random in case there are
two) and scored it based on our implementa-
tion of Hashimoto et al. (2012); the score is
based on the distributional similarity between
unary patterns and an excitation score obtained
using a minimally supervised method based on
the spin model. We then scored the binary pat-
tern pair by the score of this unary pattern pair.

We ranked the pattern pairs of our test set (2,000
random pairs from set Popp) based on the score pro-
duced by each method. For each tested method we
assumed that pairs in the test set were distributed
uniformly like explained in Section 2.2. The pre-
cision curves we obtained are shown in Figure 4.

PROPOSED clearly outperformed BASE and ac-
quired around 750,000 contradiction pattern pairs
with an estimated precision of 80%, out of which
some examples are shown in Table 3. These pairs
cover 26,941 content word pairs and reduce to
272,164 untyped pairs, showing that PROPOSED
does not just acquire a handful of contradictions in
many different class pairs. Also, when matching
these pairs against an antonyms database (extracted
from the dictionary of the morphical analyzer JU-
MAN) we found that only 100,886 of these pattern
pairs contain an antonym pair, which means that
most of the extracted pairs’ contradictions are due
to more complex phenomena than simple antonymy.

With the same precision, BASE and PROP-SCORE
acquired only 285,000 pairs (covering 11,794 con-
tent word pairs) and 636,000 pairs respectively. This
implies that our two-stage method can more than
double the number of highly precise contradiction
pairs we acquire as well as increasing their vari-
ety, and that ranking expanded pairs using our scor-
ing function CDP is better than with SVM score,
though even PROP-SCORE performs better than
BASE in our setting. Finally, the poor performance
of HAS suggests that extending the Hashimoto et
al.’s framework to recognition of binary patterns is
not a trivial task.

As to why adding only 6,000 top pairs ranked
by CDP performs better than adding 30,000 pairs
ranked by SVM score, the pattern pairs added in
PROP-SCORE had high SVM scores given by BASE
and as such are already handled nicely by BASE.

Table 3: Examples of pairs acquired by PROPOSED: con-
tradiction (label +) and non-contradiction (label -)

Lab. Pattern pairs (with rank) X/Y example
Y で X が終わる - Y より X を開始する 販売/昨日

+ X finished Y - X started from Y sale/yesterday
Rank 228,039

X が Y に勝つ - Y が X に勝つ 日本/ベトナム
+ X wins against Y - Y wins against X Japan/Vietnam

Rank: 258,068
X は Y を失う - X には Y はある 人/興味

- X lose Y - Have Y in X people/interest
Rank 474,143

Y に X を無くす - Y にも X をもつ 自信/自分
+ Lose X in Y - Have X in Y too confidence/

Rank 522,534 oneself
Y は X まで落ちる - X に Y を上げる 9 位/順位

- Y falls down to X - raise Y to X 9th/ranking
Rank 538,901

X に Y が存在する - X から Y を防ぐ 中/ウイルス
+ Y exists in X - Keep Y out X inside/virus

Rank 620,430
X から Y を外す - X は Y で答える 僕/目

- Remove Y off X - X answer with Y I (or me)/eyes
Rank 652,530

Y を X から追い出す - X に Y が残る 体/疲労
+ Kick out Y from X - Y remains in X body/fatigue

Rank 697,177
Y が X を安心させる - Y が X がを裏切る 僕/彼女

+ X reassures Y - X betrays Y I/her
Rank: 749,916

Hence, we think the effect of adding a new sam-
ple from PROP-SCORE is smaller than that in PRO-
POSED, because in PROPOSED we add to the train-
ing data pattern pairs with both high and low (possi-
bly negative) SVM scores.

Finally, while the quality of the entailment pairs
plays a very important role in the assumption that
was the base of CDP , these results show that even
a simple rule such as “Use entailment pairs with
SVM score over 0 to expand contradictions before
ranking them with CDP ” is sufficient to make the
method work. Though it may be possible to design
a more complex CDP formula which takes entail-
ment score into account, we did not explore this di-
rection in this work.

Comparison with an ILP-based method Finally,
we would like to compare our method with an ILP-
based method. The interaction between contradic-
tion and entailment that forms the basis for our ex-
pansion method has a natural interpretation as an op-
timization problem. We thus compared our method
to the following ILP formulation of this interaction
inspired by Berant et al. (2011), using our test set:

700



Figure 5: Comparison between PROPOSED, BASE and
BASE+ILP on a restricted test set (1,306 samples)

(1) G = argmax
∑
p6=q

(e(p, q)−β)∗Epq +(c(p, q)−β)∗Cpq

(2) s.t. ∀p,q,r Epq + Cqr − Cpr ≤ 1
(3) ∀p,q Epq + Cpq ≤ 1
(4) ∀p,q Epq ∈ {0, 1} (5) ∀p,q Cpq ∈ {0, 1}

The objective in Equation (1) is a sum over the
weights of every pair of patterns 〈p, q〉, where Epq
indicates whether a pair 〈p, q〉 is an entailment pair
(Equation (4)), and Cpq indicates whether it is a con-
tradiction pair (Equation (5)). e(p, q) and c(p, q) are
the score given respectively by ENT and BASE, and
β is a prior defining the weight of a pair as neither
entailment nor contradiction that shall be set before
any experimentation. Equation (2) states the tran-
sitivity relation which is the basis of our expansion
method. Finally, Equation (3) states that a given pat-
tern pair cannot be a contradiction pair and an entail-
ment pair at the same time. Since our patterns are
class-dependent, we solved separate ILP instances
for each semantic class pair.

We drew a precision curve for each of BASE,
PROPOSED and BASE+ILP. To draw the curve for
BASE+ILP, we incrementally raised the sample’s
non-contradiction non-entailment prior β (more de-
tails in Berant et al. (2011)). Because of the com-
putational difficulty of ILP (NP-complete) and the
size of our data, the computation for the ILP-based
method ran out of memory on a 72GB machine for
116 class pairs out of the 1,031 that our test set cov-
ers. For this reason, we only used the 1,306 samples
of the test set covered by the remaining 915 class
pairs. We also measured the performance of BASE
and PROPOSED on the same restricted test set.

Figure 5 shows that under these conditions the
ILP-based method performance resembles BASE

and is worse than PROPOSED on all data points.
PROPOSED performs slightly worse in this setting
compared to when classifying the whole of Popp,
but this only means that its performance is good for
the 116 class pairs we ignored in this experiment.
While this comparison is only made in a restricted
setting, our expansion method still outperforms ILP
and is clearly more scalable. The ILP results could
be improved by adding more constraints (contradic-
tion is symmetric, entailment is transitive), but this
would also make the problem even more intractable
in terms of computational costs.

4 Features

In this section we present the features used in our
classifiers, which are mainly categorized into three:
surface features (i.e., those reflecting the patterns’
content itself), features based on external lexical re-
sources, and distributional similarity based features;
all features are listed in Table 4. ENT uses all the
features while BASE and EXP use all except for the
distributional similarity based ones. The optimality
of the feature sets was confirmed through ablation
tests using the development set (results omitted for
the sake of space).

Since patterns with a contradiction or entailment
relation are often superficially similar, for instance,
in case structure or inflection, we use a number of
surface features based on string similarity measures,
extending the feature sets used by Malakasiotis and
Androutsopoulos (2007) for entailment recognition.
They include bag-of-words features such as n-grams
and similarity scores concerning the bag-of-words
such as their Euclidian distance.

To complement the surface features with knowl-
edge about the content words, we used lexi-
cal databases including such as antonymy, syn-
onymy, entailment, or allography. The presence
of such word pairs is usually a good indicator of
(non-)contradiction or (non-)entailment at the pat-
tern level. More specifically, for any word pair
〈wp, wq〉 taken from a pattern pair 〈p, q〉 we mark
the presence of 〈wp, wq〉 in each of the lexical re-
sources as a binary feature. We used the Japanese
lexical resources distributed by the ALAGIN Fo-
rum3: the verb entailment database (117,000 verb

3 http://www.alagin.jp/

701



Table 4: Features summary, computed over a pair of patterns 〈p, q〉
su

rf
ac

e Similarity measures: common elements ratios, Dice coefficient, Jaccard and discounted Jaccard scores, Cosine, Euclidian, Manhattan, Levenshtein
and Jaro distances; computed over: the patterns’ 1-, 2- and 3-grams sets of: characters, morphemes, their stems & POS; content words and stems
binary feature for each of the patterns’ subtrees, 1- and 2-grams ; patterns’ lengths and length ratios

le
x.

r. entries in databases of verb entailments and non-entailments, synonyms, antonyms, allographs ; checked over: pairs of content words,
pairs of content word stems, same for the reverse pattern pair 〈q, p〉

di
s.

s.

Distributional similarity measures: Common elements ratios, Jaccard and discounted Jaccard scores, sets and sets intersection cardinality,
DIRT (Lin and Pantel, 2001), Weeds (Weeds and Weir, 2003) and Hashimoto (Hashimoto et al., 2009) scores; computed over: patterns’
co-occurring noun pairs, POS tags of those, nouns co-occurring in each variable slot, nouns co-occurring with each unary sub-patterns

ot
he

r binary feature for each semantic class pair and individual semantic classes
patterns frequency rank in the given semantic class pair

pairs; Alagin ID A-2), the databases of synonyms,
antonyms and meronyms (respectively 111,000,
5000 and 2500 pairs; Alagin ID A-9), and the al-
lographic word database (2.7 million pairs; Alagin
ID A-7). We also used the information concerning
allographic words in the dictionary of the morpho-
logical analyzer JUMAN4.

Distributional similarity values between patterns
are based on the idea that patterns that appear in
similar contexts tend to have similar meanings and
as such are useful to recognize entailment (Lin and
Pantel, 2001). We computed as features several dis-
tributional similarity measures on the sets of each
pattern’s co-occurring noun pairs and their POS
tags, of nouns co-occurring in each variable slot, and
with each of the pattern’s unary sub-patterns.

We also added a few more uncategorizable fea-
tures. See Table 4 for more details.

5 Related Work

A number of previous work dealt with the recogni-
tion of contradictions between sentences. Harabagiu
et al. (2006) proposed a contradiction detection
method that focuses on negation, antonymy and
some discourse information. Kawahara et al. (2010)
also used negations and antonyms to extract con-
trastive/contradictory statements from the web to
present users with a bird ’s-eye view of statements
about a given topic. Bobrow et al. (2007) showed
a method using logical forms with relatively precise
results. Ohki et al. (2011) proposed a method to rec-
ognize confinment, a novel semantic relation related
to both entailment and contradiction. While we do
not deal ourselves directly with sentences, we expect
that the binary pattern pairs we acquire can play a
role similar to that of basic linguistic resources such

4 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN

as antonyms and negations in these works. Closer
to our work, Ritter et al. (2008) presented a method
for detecting contradictions between functional re-
lations like “X was born in Y”, but these constitute
only a part of the semantic relations expressed by the
binary patterns we deal with in this paper.

Other works analyzed contradictions from lin-
guistic/semantic viewpoints. Voorhees (2008) ana-
lyzed the contradiction recognition-task of the RTE3
contest. Magnini and Cabrio (2010) examined rela-
tions between contradictions and textual entailment
samples. De Marneffe et al. (2008) presented a
typology of contradictions, and showed that con-
tradictions can arise from a multitude of phenom-
ena. They showed contradictions based on lexical or
world knowledge are challenging and require a high-
level understanding of language and/or the world.
As stated in the introduction, these are the types of
contradictions our method focuses on.

6 Conclusion

This paper showed how to acquire a large number of
contradiction pairs between lexico-syntactic binary
patterns by exploiting (1) the interaction between
contradiction and entailment, and (2) excitation po-
larities. In the end, we could acquire 750,000 typed
contradiction pattern pairs with an estimated 80%
precision. The resulting contradiction pairs cov-
ered ones deeply related to world knowledge such
as the pair 〈“X reassures Y”, “X betrays Y”〉. We ex-
pect our work to lead to a high level analysis of
textual information, such as flagging unreliable in-
formation or identifying important documents to be
surveyed for understanding complex social prob-
lems. We plan to release the data we acquired to
the NLP community through the ALAGIN Forum5.

5 http://www.alagin.jp/

702



References

J. Berant, I. Dagan, and J. Goldberger. 2011. Global
learning of typed entailment rules. In Proceedings of
ACL 2011, pages 610–619.

D. G. Bobrow, C. Condoravdi, R. Crouch, V. De Paiva,
L. Karttunen, T. H. King, R. Nairn, L. Price, and
A. Zaenen. 2007. Precision-focused textual inference.
In Proceedings of the ACL-PASCAL Workshop on Tex-
tual Entailment and Paraphrasing, page 16―21.

M.-C. De Marneffe, A. N. Rafferty, and C. D. Manning.
2008. Finding contradictions in text. Proceedings of
ACL 2008, page 1039―1047.

S. De Saeger, K. Torisawa, J. Kazama, K. Kuroda, and
M. Murata. 2009. Large scale relation acquisition us-
ing class dependent patterns. In Proceedings of ICDM
2009, page 764―769.

S.M. Harabagiu, A. Hickl, and V.F. Lacatusu. 2006.
Negation, contrast and contradiction in text process-
ing. In Proceedings of AAAI 2006, pages 755–762.

C. Hashimoto, K. Torisawa, K. Kuroda, S. De Saeger,
M. Murata, and J. Kazama. 2009. Large-scale verb
entailment acquisition from the web. In Proceedings
of EMNLP 2009, volume 3, page 1172―1181.

C. Hashimoto, K. Torisawa, S. De Saeger, J.-H. Oh, and
J. Kazama. 2012. Excitatory or inhibitory: A new se-
mantic orientation extracts contradiction and causality
from the web. In Proceedings of EMNLP 2012.

D. Kawahara, S. Kurohashi, and K. Inui. 2008. Grasp-
ing major statements and their contradictions toward
information credibility analysis of web contents. In
Proceedings of WI-IAT 2008, volume 1, page 393―
397.

D. Kawahara, K. Inui, and S. Kurohashi. 2010. Iden-
tifying contradictory and contrastive relations between
statements to outline web information on a given topic.
In Proceedings of COLING 2010, page 534―542.

J. Kazama and K. Torisawa. 2008. Inducing gazetteers
for named entity recognition by large-scale clustering
of dependency relations. Proceedings of ACL 2008,
page 407―415.

J. Kloetzer, S. De Saeger, K. Torisawa, M. Sano,
C. Hashimoto, and J. Gotoh. 2013. Large-scale acqui-
sition of entailment pattern pairs. In Information Pro-
cessing Society of Japan (IPSJ) Kansai-Branch Con-
vention.

S. Kurohashi and M. Nagao. 1994. KN parser: Japanese
dependency/case structure analyzer. In Proceedings
of the Workshop on Sharable Natural Language Re-
sources, page 48―55.

J. R. Landis and G. G. Koch. 1977. The measurement of
observer agreement for categorical data. Biometrics,
page 159―174.

D. Lin and P. Pantel. 2001. Dirt - discovery of inference
rules from text. In Proceedings of the ACM SIGKDD
Conference on Knowledge Discovery and Data Min-
ing, pages 323–328.

B. Magnini and E. Cabrio. 2010. Contradiction-focused
qualitative evaluation of textual entailment. In Pro-
ceedings of the Workshop on Negation and Speculation
in Natural Language Processing, page 86―94.

P. Malakasiotis and I. Androutsopoulos. 2007. Learning
textual entailment using SVMs and string similarity
measures. In Proceedings of the ACL- PASCAL Work-
shop on Textual Entailment and Paraphrasing, page 42
―47.

K. Murakami, E. Nichols, S. Matsuyoshi, A. Sumida,
S. Masuda, K. Inui, and Y. Matumoto. 2009. State-
ment map: assisting information crediblity analysis
by visualizing arguments. In Proceedings of the 3rd
workshop on Information credibility on the web, page
43―50. ACM.

M. Ohki, S. Matsuyoshi, J. Mizuno, K. Inui, E. Nichols,
K. Murakami, S. Masuda, and Y. Matsumoto. 2011.
Recognizing confinement in web texts. In the Pro-
ceedings of the Ninth International Conference on
Computational Semantics, page 215―224.

A. Ritter, D. Downey, S. Soderland, and O. Etzioni.
2008. It’s a contradiction—no, it’s not: a case study
using functional relations. In Proceedings of EMNLP
2008, pages 11–20.

S. Schoenmackers, O. Etzioni, D. S Weld, and J. Davis.
2010. Learning first-order horn clauses from web text.
In Proceedings of EMNLP 2010, page 1088―1098.

I. Szpektor, E. Shnarch, and I. Dagan. 2007. Instance-
based evaluation of entailment rule acquisition. In
Proceedings of ACL 2007, volume 45, page 456―463.

E. M. Voorhees. 2008. Contradictions and justifications:
Extensions to the textual entailment task. In Proceed-
ings of ACL 2008, page 63―71.

J. Weeds and D. Weir. 2003. A general framework for
distributional similarity. In Proceedings of EMNLP
2003, page 81―88. Association for Computational
Linguistics.

703


