










































On-line Language Model Biasing for Statistical Machine Translation


Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 445–449,
Portland, Oregon, June 19-24, 2011. c©2011 Association for Computational Linguistics

On-line Language Model Biasing for Statistical Machine Translation

Sankaranarayanan Ananthakrishnan, Rohit Prasad and Prem Natarajan
Raytheon BBN Technologies

Cambridge, MA 02138, U.S.A.
{sanantha,rprasad,pnataraj}@bbn.com

Abstract

The language model (LM) is a critical com-
ponent in most statistical machine translation
(SMT) systems, serving to establish a proba-
bility distribution over the hypothesis space.
Most SMT systems use a static LM, inde-
pendent of the source language input. While
previous work has shown that adapting LMs
based on the input improves SMT perfor-
mance, none of the techniques has thus far
been shown to be feasible for on-line sys-
tems. In this paper, we develop a novel mea-
sure of cross-lingual similarity for biasing the
LM based on the test input. We also illustrate
an efficient on-line implementation that sup-
ports integration with on-line SMT systems by
transferring much of the computational load
off-line. Our approach yields significant re-
ductions in target perplexity compared to the
static LM, as well as consistent improvements
in SMT performance across language pairs
(English-Dari and English-Pashto).

1 Introduction

While much of the focus in developing a statistical
machine translation (SMT) system revolves around
the translation model (TM), most systems do not
emphasize the role of the language model (LM). The
latter generally follows a n-gram structure and is es-
timated from a large, monolingual corpus of target
sentences. In most systems, the LM is independent
of the test input, i.e. fixed n-gram probabilities de-
termine the likelihood of all translation hypotheses,
regardless of the source input.

The views expressed are those of the author and do not reflect the official policy or position of
the Department of Defense or the U.S. Government.

Some previous work exists in LM adaptation for
SMT. Snover et al. (2008) used a cross-lingual infor-
mation retrieval (CLIR) system to select a subset of
target documents “comparable” to the source docu-
ment; bias LMs estimated from these subsets were
interpolated with a static background LM. Zhao
et al. (2004) converted initial SMT hypotheses to
queries and retrieved similar sentences from a large
monolingual collection. The latter were used to
build source-specific LMs that were then interpo-
lated with a background model. A similar approach
was proposed by Kim (2005). While feasible in off-
line evaluations where the test set is relatively static,
the above techniques are computationally expensive
and therefore not suitable for low-latency, interac-
tive applications of SMT. Examples include speech-
to-speech and web-based interactive translation sys-
tems, where test inputs are user-generated and pre-
clude off-line LM adaptation.

In this paper, we present a novel technique for
weighting a LM corpus at the sentence level based
on the source language input. The weighting scheme
relies on a measure of cross-lingual similarity evalu-
ated by projecting sparse vector representations of
the target sentences into the space of source sen-
tences using a transformation matrix computed from
the bilingual parallel data. The LM estimated from
this weighted corpus boosts the probability of rele-
vant target n-grams, while attenuating unrelated tar-
get segments. Our formulation, based on simple
ideas in linear algebra, alleviates run-time complex-
ity by pre-computing the majority of intermediate
products off-line.

Distribution Statement “A” (Approved for Public Release, Distribution Unlimited)

445



2 Cross-Lingual Similarity

We propose a novel measure of cross-lingual simi-
larity that evaluates the likeness between an arbitrary
pair of source and target language sentences. The
proposed approach represents the source and target
sentences in sparse vector spaces defined by their
corresponding vocabularies, and relies on a bilingual
projection matrix to transform vectors in the target
language space to the source language space.

Let S = {s1, . . . , sM} and T = {t1, . . . , tN} rep-
resent the source and target language vocabularies.
Let u represent the candidate source sentence in a
M -dimensional vector space, whose mth dimension
um represents the count of vocabulary item sm in the
sentence. Similarly, v represents the candidate tar-
get sentence in a N -dimensional vector space. Thus,
u and v are sparse term-frequency vectors. Tra-
ditionally, the cosine similarity measure is used to
evaluate the likeness of two term-frequency repre-
sentations. However, u and v lie in different vector
spaces. Thus, it is necessary to find a projection of
v in the source vocabulary vector space before sim-
ilarity can be evaluated.

Assuming we are able to compute a M × N -
dimensional bilingual word co-occurrence matrix Σ
from the SMT parallel corpus, the matrix-vector
product û = Σv is a projection of the target sen-
tence in the source vector space. Those source terms
of the M -dimensional vector û will be emphasized
that most frequently co-occur with the target terms
in v. In other words, û can be interpreted as a “bag-
of-words” translation of v.

The cross-lingual similarity between the candi-
date source and target sentences then reduces to the
cosine similarity between the source term-frequency
vector u and the projected target term-frequency
vector û, as shown in Equation 2.1:

S(u,v) =
1

‖u‖‖û‖
u
T
û

=
1

‖u‖‖Σv‖
u
T
Σv (2.1)

In the above equation, we ensure that both u and
û are normalized to unit L2-norm. This prevents
over- or under-estimation of cross-lingual similarity
due to sentence length mismatch.

We estimate the bilingual word co-occurrence
matrix Σ from an unsupervised, automatic word
alignment induced over the parallel training corpus
P. We use the GIZA++ toolkit (Al-Onaizan et al.,
1999) to estimate the parameters of IBM Model
4 (Brown et al., 1993), and combine the forward
and backward Viterbi alignments to obtain many-to-
many word alignments as described in Koehn et al.
(2003). The (m,n)th entry Σm,n of this matrix is
the number of times source word sm aligns to target
word tn in P.

3 Language Model Biasing

In traditional LM training, n-gram counts are evalu-
ated assuming unit weight for each sentence. Our
approach to LM biasing involves re-distributing
these weights to favor target sentences that are “sim-
ilar” to the candidate source sentence according to
the measure of cross-lingual similarity developed in
Section 2. Thus, n-grams that appear in the trans-
lation hypothesis for the candidate input will be as-
signed high probability by the biased LM, and vice-
versa.

Let u be the term-frequency representation of the
candidate source sentence for which the LM must be
biased. The set of vectors {v1, . . . ,vK} similarly
represent the K target LM training sentences. We
compute the similarity of the source sentence u to
each target sentence vj according to Equation 3.1:

ωj = S(u,vj)

=
1

‖u‖‖Σvj‖
u
T
Σvj (3.1)

The biased LM is estimated by weighting n-gram
counts collected from the jth target sentence with
the corresponding cross-lingual similarity ωj . How-
ever, this is computationally intensive because: (a)
LM corpora usually consist of hundreds of thou-
sands or millions of sentences; ωj must be eval-
uated at run-time for each of them, and (b) the
entire LM must be re-estimated at run-time from
n-gram counts weighted by sentence-level cross-
lingual similarity.

In order to alleviate the run-time complexity of
on-line LM biasing, we present an efficient method
for obtaining biased counts of an arbitrary target

446



n-gram t. We define ct =
[

c1t , . . . , c
K
t

]T
to be

the indicator-count vector where cjt is the unbi-
ased count of t in target sentence j. Let ω =
[ω1, . . . , ωK ]

T be the vector representing cross-
lingual similarity between the candidate source sen-
tence and each of the K target sentences. Then, the
biased count of this n-gram, denoted by C∗(t), is
given by Equation 3.2:

C∗(t) = cTt ω

=

K
∑

j=1

1

‖u‖‖Σvj‖
c
j
tu

T
Σvj

=
1

‖u‖
u
T

K
∑

j=1

1

‖Σvj‖
c
j
tΣvj

=
1

‖u‖
u
T
bt (3.2)

The vector bt can be interpreted as the projection
of target n-gram t in the source space. Note that bt is
independent of the source input u, and can therefore
be pre-computed off-line. At run-time, the biased
count of any n-gram can be obtained via a simple
dot product. This adds very little on-line time com-
plexity because u is a sparse vector. Since bt is tech-
nically a dense vector, the space complexity of this
approach may seem very high. In practice, the mass
of bt is concentrated around a very small number of
source words that frequently co-occur with target n-
gram t; thus, it can be “sparsified” with little or no
loss of information by simply establishing a cutoff
threshold on its elements. Biased counts and proba-
bilities can be computed on demand for specific n-
grams without re-estimating the entire LM.

4 Experimental Results

We measure the utility of the proposed LM bias-
ing technique in two ways: (a) given a parallel test
corpus, by comparing source-conditional target per-
plexity with biased LMs to target perplexity with the
static LM, and (b) by comparing SMT performance
with static and biased LMs. We conduct experi-
ments on two resource-poor language pairs commis-
sioned under the DARPA Transtac speech-to-speech
translation initiative, viz. English-Dari (E2D) and
English-Pashto (E2P), on test sets with single as well
as multiple references.

Data set E2D E2P
TM Training 138k pairs 168k pairs
LM Training 179k sentences 302k sentences
Development 3,280 pairs 2,385 pairs
Test (1-ref) 2,819 pairs 1,113 pairs
Test (4-ref) - 564 samples

Table 1: Data configuration for perplexity/SMT experi-
ments. Multi-reference test set is not available for E2D.
LM training data in words: 2.4M (Dari), 3.4M (Pashto)

4.1 Data Configuration

Parallel data were made available under the Transtac
program for both language pairs evaluated in this pa-
per. We divided these into training, held-out devel-
opment, and test sets for building, tuning, and evalu-
ating the SMT system, respectively. These develop-
ment and test sets provide only one reference trans-
lation for each source sentence. For E2P, DARPA
has made available to all program participants an
additional evaluation set with multiple (four) refer-
ences for each test input. The Dari and Pashto mono-
lingual corpora for LM training are a superset of tar-
get sentences from the parallel training corpus, con-
sisting of additional untranslated sentences, as well
as data derived from other sources, such as the web.
Table 1 lists the corpora used in our experiments.

4.2 Perplexity Analysis

For both Dari and Pashto, we estimated a static
trigram LM with unit sentence level weights that
served as a baseline. We tuned this LM by varying
the bigram and trigram frequency cutoff thresholds
to minimize perplexity on the held-out target sen-
tences. Finally, we evaluated test target perplexity
with the optimized baseline LM.

We then applied the proposed technique to es-
timate trigram LMs biased to source sentences in
the held-out and test sets. We evaluated source-
conditional target perplexity by computing the to-
tal log-probability of all target sentences in a par-
allel test corpus against the LM biased by the cor-
responding source sentences. Again, bigram and
trigram cutoff thresholds were tuned to minimize
source-conditional target perplexity on the held-out
set. The tuned biased LMs were used to compute
source-conditional target perplexity on the test set.

447



Eval set Static Biased Reduction
E2D-1ref-dev 159.3 137.7 13.5%
E2D-1ref-tst 178.3 156.3 12.3%
E2P-1ref-dev 147.3 130.6 11.3%
E2P-1ref-tst 122.7 108.8 11.3%

Table 2: Reduction in perplexity using biased LMs.

Witten-Bell discounting was used for smoothing
all LMs. Table 2 summarizes the reduction in target
perplexity using biased LMs; on the E2D and E2P
single-reference test sets, we obtained perplexity re-
ductions of 12.3% and 11.3%, respectively. This in-
dicates that the biased models are significantly better
predictors of the corresponding target sentences than
the static baseline LM.

4.3 Translation Experiments

Having determined that target sentences of a parallel
test corpus better fit biased LMs estimated from the
corresponding source-weighted training corpus, we
proceeded to conduct SMT experiments on both lan-
guage pairs to demonstrate the utility of biased LMs
in improving translation performance.

We used an internally developed phrase-based
SMT system, similar to Moses (Koehn et al., 2007),
as a test-bed for our translation experiments. We
used GIZA++ to induce automatic word alignments
from the parallel training corpus. Phrase translation
rules (up to a maximum source span of 5 words)
were extracted from a combination of forward and
backward word alignments (Koehn et al., 2003).
The SMT decoder uses a log-linear model that com-
bines numerous features, including but not limited to
phrase translation probability, LM probability, and
distortion penalty, to estimate the posterior proba-
bility of target hypotheses. We used minimum error
rate training (MERT) (Och, 2003) to tune the feature
weights for maximum BLEU (Papineni et al., 2001)
on the development set. Finally, we evaluated SMT
performance on the test set in terms of BLEU and
TER (Snover et al., 2006).

The baseline SMT system used the static trigram
LM with cutoff frequencies optimized for minimum
perplexity on the development set. Biased LMs
(with n-gram cutoffs tuned as above) were estimated
for all source sentences in the development and test

Test set BLEU 100-TER
Static Biased Static Biased

E2D-1ref-tst 14.4 14.8 29.6 30.5
E2P-1ref-tst 13.0 13.3 28.3 29.4
E2P-4ref-tst 25.6 26.1 35.0 35.8

Table 3: SMT performance with static and biased LMs.

sets, and were used to decode the corresponding in-
puts. Table 3 summarizes the consistent improve-
ment in BLEU/TER across multiple test sets and
language pairs.

5 Discussion and Future Work

Existing methods for target LM biasing for SMT
rely on information retrieval to select a comparable
subset from the training corpus. A foreground LM
estimated from this subset is interpolated with the
static background LM. However, given the large size
of a typical LM corpus, these methods are unsuitable
for on-line, interactive SMT applications.

In this paper, we proposed a novel LM biasing
technique based on linear transformations of target
sentences in a sparse vector space. We adopted a
fine-grained approach, weighting individual target
sentences based on the proposed measure of cross-
lingual similarity, and by using the entire, weighted
corpus to estimate a biased LM. We then sketched an
implementation that improves the time and space ef-
ficiency of our method by pre-computing and “spar-
sifying” n-gram projections off-line during the train-
ing phase. Thus, our approach can be integrated
within on-line, low-latency SMT systems. Finally,
we showed that biased LMs yield significant reduc-
tions in target perplexity, and consistent improve-
ments in SMT performance.

While we used phrase-based SMT as a test-bed
for evaluating translation performance, it should be
noted that the proposed LM biasing approach is in-
dependent of SMT architecture. We plan to test its
effectiveness in hierarchical and syntax-based SMT
systems. We also plan to investigate the relative
usefulness of LM biasing as we move from low-
resource languages to those for which significantly
larger parallel corpora and LM training data are
available.

448



References

Yaser Al-Onaizan, Jan Curin, Michael Jahr, Kevin
Knight, John Lafferty, Dan Melamed, Franz Josef Och,
David Purdy, Noah A. Smith, and David Yarowsky.
1999. Statistical machine translation: Final report.
Technical report, JHU Summer Workshop.

Peter E. Brown, Vincent J. Della Pietra, Stephen A.
Della Pietra, and Robert L. Mercer. 1993. The math-
ematics of statistical machine translation: parameter
estimation. Computational Linguistics, 19:263–311.

Woosung Kim. 2005. Language Model Adaptation for
Automatic Speech Recognition and Statistical Machine
Translation. Ph.D. thesis, The Johns Hopkins Univer-
sity, Baltimore, MD.

Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In NAACL
’03: Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology,
pages 48–54, Morristown, NJ, USA. Association for
Computational Linguistics.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondřej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the ACL on Inter-
active Poster and Demonstration Sessions, ACL ’07,
pages 177–180, Stroudsburg, PA, USA. Association
for Computational Linguistics.

Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In ACL ’03: Pro-
ceedings of the 41st Annual Meeting on Association
for Computational Linguistics, pages 160–167, Mor-
ristown, NJ, USA. Association for Computational Lin-
guistics.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. BLEU: A method for automatic
evaluation of machine translation. In ACL ’02: Pro-
ceedings of the 40th Annual Meeting on Association
for Computational Linguistics, pages 311–318, Mor-
ristown, NJ, USA. Association for Computational Lin-
guistics.

Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proceedings AMTA, pages 223–231, August.

Matthew Snover, Bonnie Dorr, and Richard Schwartz.
2008. Language and translation model adaptation us-
ing comparable corpora. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-

cessing, EMNLP ’08, pages 857–866, Stroudsburg,
PA, USA. Association for Computational Linguistics.

Bing Zhao, Matthias Eck, and Stephan Vogel. 2004.
Language model adaptation for statistical machine
translation with structured query models. In Proceed-
ings of the 20th international conference on Compu-
tational Linguistics, COLING ’04, Stroudsburg, PA,
USA. Association for Computational Linguistics.

449


