










































Speech Communication in the Wild


Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, page 1,
Avignon, France, April 23 - 27 2012. c©2012 Association for Computational Linguistics

Speech Communication in the Wild

Martin Cooke
Language and Speech Laboratory
University of the Basque Country

Ikerbasque (Basque Science Foundation)
m.cooke@ikerbasque.org

Abstract

Much of what we know about speech perception comes from laboratory studies with clean, canonical
speech, ideal listeners and artificial tasks. But how do interlocutors manage to communicate effec-
tively in the seemingly less-than-ideal conditions of everyday listening, which frequently involve try-
ing to make sense of speech while listening in a non-native language, or in the presence of competing
sound sources, or while multitasking? In this talk I’ll examine the effect of real-world conditions on
speech perception and quantify the contributions made by factors such as binaural hearing, visual in-
formation and prior knowledge to speech communication in noise. I’ll present a computational model
which trades stimulus-related cues with information from learnt speech models, and examine how
well it handles both energetic and informational masking in a two-sentence separation task. Speech
communication also involves listening-while-talking. In the final part of the talk I’ll describe some
ways in which speakers might be making communication easier for their interlocutors, and demon-
strate the application of these principles to improving the intelligibility of natural and synthetic speech
in adverse conditions.

1


