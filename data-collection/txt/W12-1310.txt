



















































Extraction de lexiques bilingues √† partir de Wikip√©dia


JEP-TALN-RECITAL 2012, Atelier TALAf 2012: Traitement Automatique des Langues Africaines, pages 107‚Äì117,
Grenoble, 4 au 8 juin 2012. c¬©2012 ATALA & AFCP

Extraction de lexiques bilingues √† partir de Wikip√©dia 

Rahma Sellami1  Fatiha Sadat2 Lamia Hadrich Belguith1 
(1) ANLP Research Group ‚Äì Laboratoire MIRACL 

Facult√© des Sciences Economiques et de Gestion de Sfax 
B.P. 1088, 3018 - Sfax ‚Äì TUNISIE 

(2) Universit√© du Qu√©bec √† Montr√©al, 201 av. President Kennedy, 
Montr√©al, QC, H3X 2Y3, Canada 

Rahma.Sellami@fsegs.rnu.tn, sadat.fatiha@uqam.ca, 

l.belguith@fsegs.rnu.tn 

RESUME ____________________________________________________________________________________________________________   

Avec l'int√©r√™t accru de la traduction automatique, le besoin de ressources multilingues 
comme les corpus comparables et les lexiques bilingues s‚Äôest impos√©. Ces ressources sont 
peu disponibles, surtout pour les paires de langues qui ne font pas intervenir l'anglais. 
Cet article pr√©sente notre approche sur l'extraction de lexiques bilingues pour les paires 
de langues arabe-fran√ßais et yoruba-fran√ßais √† partir de l‚Äôencyclop√©die en ligne 
Wikip√©dia. Nous exploitons la taille gigantesque et la couverture de plusieurs domaines 
des articles pour extraire deux lexiques, qui pourront √™tre exploit√©s pour d'autres 
applications en traitement automatique du langage naturel. 

ABSTRACT _________________________________________________________________________________________________________  

Bilingual lexicon extraction from Wikipedia 
With the increased interest of the machine translation, needs of multilingual resources 
such as comparable corpora and bilingual lexicon has increased. These resources are not 
available mainly for pair of languages that do not involve English. 
This paper aims to describe our approach on the extraction of bilingual lexicons for 
Arabic-French and Yoruba-French pairs of languages from the online encyclopedia, 
Wikipedia. We exploit the large scale of Wikipedia article to extract two bilingual 
lexicons that will be very useful for natural language applications.  

MOTS-CLES : Lexique bilingue, corpus comparable, Wikip√©dia, arabe-fran√ßais, yoruba-
fran√ßais. 
KEYWORDS : Bilingual lexicon, comparable corpora, Wikipedia, Arabic-French, Yoruba-
French. 
 

107



1 Introduction 

Les ressources linguistiques multilingues sont g√©n√©ralement construites √† partir de corpus 
parall√®les. Cependant, l'absence de ces corpus a incit√© les chercheurs √† exploiter d'autres 
ressources multilingues, telles que les corpus comparables : ensembles de textes dans 
diff√©rentes langues, qui ne sont pas des traductions les uns des autres (Adafre et de Rijke, 
2006), mais qui contiennent des textes partageant des caract√®res communs, tel que le 
domaine, la date de publication, etc. Car moins contrains, ils sont donc plus faciles √† 
construire que les corpus parall√®les.  
Les lexiques bilingues constituent une partie cruciale dans plusieurs applications telles 
que la traduction automatique (Och et Ney, 2003) et la recherche d‚Äôinformation 
multilingue  (Grefenstette, 1998). 
Dans cet article, nous cherchons √† exploiter l‚Äôaspect multilingue ainsi que la taille 
gigantesque de l‚Äôencyclop√©die en ligne, Wikip√©dia, comme un grand corpus comparable 
pour l'extraction de deux lexiques bilingues (arabe-fran√ßais et yoruba-fran√ßais). (Morin, 
2007) a montr√© que non seulement la taille du corpus comparable mais aussi sa qualit√© 
est importante pour l‚Äôextraction d‚Äôun dictionnaire bilingue. Nous proposons d'utiliser une 
m√©thode simple mais efficace, il s‚Äôagit d‚Äôexploiter les liens inter-langues entre les articles 
Wikip√©dia afin d'extraire des termes (simples ou compos√©s) arabes et yoruba et leurs 
traductions en fran√ßais, puis, utiliser une approche statistique pour aligner les mots des 
termes compos√©s.  
Les lexiques extraits seront utilis√©s pour l‚Äôextraction d‚Äôun corpus parall√®le √† partir de 
wikip√®dia. 
Le contenu de cet article se r√©sume comme suit. La section 2 pr√©sente un bref aper√ßu des 
travaux ant√©rieurs sur l'extraction de lexiques bilingues. La section 3 d√©crit certaines 
caract√©ristiques de Wikip√©dia que nous avons exploit√©es pour l‚Äôextraction de nos lexiques 
bilingues. La section 4 pr√©sente bri√®vement les langues arabe et yoruba. Nous 
pr√©sentons, dans la section 5, notre travail de construction des lexiques bilingues √† partir 
de Wikip√©dia. Nous √©valuons nos lexiques, dans la section 6. La section 7 conclu cet 
article et donne des pointeurs et extensions pour le futur. 

2 Etat de l‚Äôart 

Dans un premier temps, les chercheurs construisent les lexiques bilingues √† partir des 
corpus parall√®les. Mais, en raison de l'absence de ces ressources, l‚Äôexploitation des corpus 

108



comparables a attir√© l‚Äôattention de plusieurs chercheurs. (Morin et Daille, 2004) 
pr√©sentent une m√©thode pour l'extraction de terminologie bilingue √† partir d‚Äôun corpus 
comparable du domaine technique. Ils extraient les termes compos√©s dans chaque langue 
puis ils alignent ces termes au niveau mot en utilisant une m√©thode statistique exploitant 
le contexte des termes. (Otero, 2007) a cr√©e un lexique bilingue (anglais-espagnol), en se 
basant sur des informations syntaxiques et lexicales extraites √† partir d‚Äôun petit corpus 
parall√®le. (Sadat et al., 2003) ont pr√©sent√© une m√©thode hybride qui se base sur des 
informations statistiques (deux mod√®les de traduction bidirectionnels) combin√©es √† des 
informations linguistiques pour construire une terminologie anglais-japonais. (Morin et 
Prochasson, 2011) ont pr√©sent√© une m√©thode pour l'extraction d‚Äôun lexique bilingue 
sp√©cialis√© √† partir d‚Äôun corpus comparable, agr√©ment√© d‚Äôun corpus parall√®le. Ils extraient 
des phrases parall√®les √† partir du corpus comparable, puis, ils alignent ces phrases au 
niveau mots pour en extraire un lexique bilingue. (Hazem et al., 2011) proposent une 
extension de l‚Äôapproche par similarit√© inter-langue abord√©e dans les travaux pr√©c√©dents. 
Ils pr√©sentent un mod√®le inspir√© des m√©tamoteurs de recherche d‚Äôinformation. 
Dans ce qui suit, nous d√©crivons les travaux ant√©rieurs qui ont exploit√© Wikip√©dia comme 
corpus comparable pour la construction d‚Äôun lexique bilingue.  
(Adafre et de Rijke, 2006) a cr√©√© un lexique bilingue (anglais-n√©erlandais) √† partir de 
Wikipedia dans le but de l‚Äôutiliser pour la construction d'un corpus parall√®le √† partir des 
articles de Wikip√©dia.  Le lexique extrait est compos√© uniquement de titres des articles 
Wikip√©dia reli√©s par des liens inter-langues. Les auteurs ont montr√© l‚Äôefficacit√© de 
l‚Äôutilisation de ce lexique pour la construction d‚Äôun corpus parall√®le. (Bouma et al., 2006) 
ont construit un lexique bilingue pour la cr√©ation d'un syst√®me de question r√©ponse 
multilingue (fran√ßais-n√©erlandais). En outre, (Decklerck et al., 2006) ont extrait un 
lexique bilingue √† partir des liens inter-langues de Wikip√©dia. Ce lexique a √©t√© utilis√© 
pour la traduction des labels d‚Äôune ontologie. Ces travaux sont caract√©ris√©s par le fait 
qu‚Äôils exploitent uniquement les liens inter-langues de Wikip√©dia. Par contre, (Erdmann 
et al., 2008) analysent non seulement les liens inter-langues de wikip√©dia, mais 
exploitent aussi les redirections et les liens inter-wiki pour la construction d‚Äôun 
dictionnaire anglais-japonais. Les auteurs ont montr√© l‚Äôapport de l‚Äôutilisation de 
Wikip√©dia par rapport aux corpus parall√®les pour l‚Äôextraction d‚Äôun dictionnaire bilingue. 
Cet apport apparait surtout au niveau de la large couverture des termes. (Sadat et 
Terrasa, 2010) proposent une approche pour l‚Äôextraction de terminologie bilingue √† 
partir de Wikip√©dia. Cette approche consiste √† extraire d‚Äôabord des paires de termes et 

109



traductions √† partir des diff√©rents types d‚Äôinformations, des liens et des textes de 
Wikip√©dia, puis, √† utiliser des informations linguistiques afin de r√©ordonner les termes et 
leurs traductions pertinentes et ainsi √©liminer les termes cibles inutiles.  

3 Bref aper√ßu sur les langues arabe et yoruba  
3.1 La langue arabe 

L‚Äôarabe (ÿßŸÑÿπÿ±ÿ®Ÿäÿ©) est une langue originaire de la p√©ninsule Arabique. Elle est parl√©e en Asie 
et en Afrique du Nord. L‚ÄôArabe est issue du groupe m√©ridional des langues s√©mitiques. 
Elle s‚Äô√©crit de droite √† gauche tout en utilisant des lettres qui prennent des formes 
diff√©rentes suivant qu‚Äôelles soient isol√©es, au d√©but, au milieu ou √† la fin du mot.1  
La langue arabe est morphologiquement riche ce qui pose le probl√®me de l‚Äôambigu√Øt√© au 
niveau de son traitement automatique, un mot en arabe peut encapsuler la signification 
de toute une phrase (ÿß ŸÜ ÿ±ŸàŸÜ ÿ∞ŸÉ ÿ™  .(? est ce que vous souvenez de nous/ÿ£ÿ™

3.2 La langue yoruba 

Le yoruba (yor√πb√°) est une langue tonale appartenant √† la famille des langues nig√©ro-
congolaises. Le yorouba, langue maternelle d‚Äôenviron 20% de la population nig√©riane, est 
√©galement parl√© au B√©nin et au Togo. Au Nig√©ria, il est parl√© dans la plus grande partie 
des √©tats d‚ÄôOyo, Ogun, Ondo, Osun, Kwara et Lagos, et √† l‚Äôouest de l‚Äô√©tat de Kogi.  
La langue se subdivise en de nombreux dialectes. Il existe n√©anmoins aussi une langue 
standard2. 
Le yoruba s'√©crit au moyen de plusieurs alphabet fond√©es sur l‚Äôalphabet latin muni 
d‚Äôaccents pour noter les tons (dont la charge fonctionnelle est tr√®s importante), et de 
points souscrits pour noter les voyelles ouvertes. 
La voyelle est le centre de la syllabe. Le ton appara√Æt comme une caract√©ristique 
inh√©rente √† la voyelle ou √† la syllabe. Il y a autant de syllabes que de tons. Le 
symbolisme se pr√©sente comme suit : ton haut: (/), ton bas: (\), ton moyen: (-). 
Ces tons d√©terminent le sens du mot, une forme peut avoir plusieurs sens (ex. Igba/deux 
cent, Igba/calebasse, √ågba/temps, etc)3.  

                                                           
1
 http://fr.wikipedia.org/wiki/Arabe [consult√© le 26/04/2012]. 

2
 http://fr.wikipedia.org/wiki/Yoruba_(langue) [consult√© le 18/04/2012]. 

3
 http://www.africananaphora.rutgers.edu/downloads/casefiles/YorubaGS.pdf [consult√© le 

24/04/2012]. 

110



La morphologie de la langue yoruba est riche, faisant, par exemple, un large emploi 
du redoublement (ex. Eso/fruit, so/donner de fruits, j√≤/ d√©goutter , √≤jo/pluie). 

4 Caract√©ristiques de Wikip√©dia 

Lors de l'extraction de terminologies bilingues √† partir de corpus parall√®les ou 
comparables, il est difficile d'atteindre une pr√©cision et une couverture suffisantes, en 
particulier pour les mots moins fr√©quents tels que les terminologies sp√©cifiques √† un 
domaine (Erdmann, 2008). Pour notre travail de construction de lexiques bilingues, nous 
proposons d‚Äôexploiter Wikip√©dia, une ressource multilingue dont la taille est gigantesque 
et qui est en d√©veloppement continu. 
Dans ce qui suit, nous d√©crivons certaines caract√©ristiques de Wikip√©dia, ces 
caract√©ristiques font de Wikip√®dia une ressource pr√©cieuse pour l'extraction de ressources 
bilingues. 
Actuellement, Wikip√©dia contient 21 368 483 articles dont 1 221 995 articles fran√ßais, 
170771 articles en langue arabe et 29 884 articles en langue yoruba4. Ces articles 
couvrent plusieurs domaines. Nous exploitons l‚Äôaspect multilingue et gigantesque de 
cette ressource afin d‚Äôextraire des lexiques bilingues de large couverture. 
La structure de Wikip√©dia est tr√®s dense en liens ; ces liens relient soit des articles d‚Äôune 
seule langue soit des articles r√©dig√©s en langues diff√©rentes.  
Les liens Wikip√©dia peuvent √™tre class√©s en :  
- Lien inter-langue : un lien inter-langue relie deux articles en langues diff√©rentes. Un 

article a au maximum un seul lien inter-langue pour chaque langue, ce lien a comme 
syntaxe [[code de la langue cible : titre de l‚Äôarticle en langue cible]] avec ¬´ code de la 
langue cible ¬ª identifie la langue de l‚Äôarticle cible  et ¬´ titre de l‚Äôarticle en langue cible ¬ª 
identifie son titre (ex. [[yo:J√∫p√≠t√©r√¨]]). Puisque les titres des articles Wikip√©dia sont 
uniques,  la syntaxe des liens inter-langue est suffisante pour identifier les articles en 
langues cibles.  

- Redirection : une redirection  renvoie automatiquement le visiteur sur une autre 
page. La syntaxe Wikip√©dia d'une redirection est : #REDIRECTION[[page de 
destination]]. Les pages de redirection sont notamment utilis√©es pour des abr√©viations 
(ex. SNCF redirige vers Soci√©t√© Nationale des Chemins de Fer), des synonymes (ex. e-

                                                           
4
 http://meta.wikimedia.org/wiki/List_of_Wikipedias [consult√© le 01/03/2012]. 

111



mail, courriel, m√©l et messagerie √©lectronique redirigent vers courrier √©lectronique), des 
noms alternatifs (ex. Karol Wojty≈Ça redirige vers Jean-Paul II), etc. 

- Lien inter-wiki : c'est un lien vers une autre page de la m√™me instance de Wikip√©dia. 
Le texte du lien peut correspondre au titre de l'article qui constitue la cible du lien (la 
syntaxe en sera alors : [[titre de l'article]]), ou diff√©rer du titre de l'article-cible (avec 
la syntaxe suivante : [[titre de l'article|texte du lien]]). 

5 Extraction des lexiques bilingues √† partir de Wikip√©dia 
5.1 Extraction des termes 

Nous avons extrait deux lexiques bilingues en exploitant la syntaxe des liens inter-
langues de Wikip√©dia. En effet, les liens inter-langues relient deux articles en langues 
diff√©rentes dont les titres sont en traduction mutuelle. En outre, ces liens sont cr√©√©s 
par les auteurs des articles, nous supposons que les auteurs ont correctement positionn√© 
ces liens. Aussi, un article en langue source est li√© √† un seul article en langue cible, donc, 
nous n‚Äôavons pas √† g√©rer d‚Äô√©ventuels probl√®mes d‚Äôambigu√Øt√© au niveau de l‚Äôextraction des 
paires de titres.  
Nous avons t√©l√©charg√© la base de donn√©es Wikip√©dia arabe (janvier 2012)5 et yoruba 
(mars 2012)6 sous format XML et nous avons extrait 104 104 liens inter-langue arabe et 
15 345 liens inter-langue yoruba vers les articles fran√ßais. Chaque lien correspond √† une 
paire de titres arabe-fran√ßais et yoruba-fran√ßais. Certains titres sont compos√©s de termes 
simples et d‚Äôautres sont compos√©s de termes compos√©s de plusieurs mots. 

5.2 Alignement des mots 

Dans le but d‚Äôavoir un lexique compos√© uniquement des termes simples, nous avons 
proc√©der √† une √©tape d‚Äôalignement des mots. 
Cette √©tape pr√©sente plusieurs difficult√©s dont : Premi√®rement, les alignements ne sont 
pas n√©cessairement contigus : deux mots cons√©cutifs dans la phrase source peuvent √™tre 
align√©s avec deux mots arbitrairement distants de la phrase cible. On appelle ce 
ph√©nom√®ne distorsion. Deuxi√®mement, un mot en langue source peut √™tre align√© √† 
plusieurs mots en langue cible ; ce qui est d√©fini en tant que fertilit√©. 

                                                           
5 http://download.wikipedia.com/arwiki/20120114/ [consult√© le 01/03/2012]. 
6 http://dumps.wikimedia.org/yowiki/20120316/ [consult√© le 15/03/2012]. 

112



Nous avons proc√©d√© √† une √©tape d‚Äôalignement des mots des paires de titres en nous 
basant sur une approche statistique, nous avons utilis√© les mod√®les IBM [1-5] (Brown et 
al., 1993) combin√©s avec les mod√®les de Markov cach√©s HMM (Vogel et al.,1996) vu que 
ces mod√®les standard se sont av√©r√©s efficaces dans les travaux d'alignement de mots. 
Les mod√®les IBM sont des mod√®les √† base de mots, c‚Äôest-√†-dire que l‚Äôunit√© de traduction 
qui appara√Æt dans les lois de probabilit√© est le mot.  
Les cinq mod√®les IBM permettent d‚Äôestimer les probabilit√©s P(fr |ar) et P(fr |yo) de fa√ßon 
it√©rative, tel que fr est un mot fran√ßais, ar est un mot arabe et yo est un mot yoruba. 
Chaque mod√®le s‚Äôappuie sur les param√®tres estim√©s par le mod√®le le pr√©c√©dant et prend 
en compte de nouvelles caract√©ristiques telles que la distorsion, la fertilit√©, etc.  
Le mod√®le de Markov cach√© (nomm√© usuellement HMM) (Vogel et al., 1996) est une 
am√©lioration du mod√®le IBM2. Il mod√©lise explicitement la distance entre l‚Äôalignement 
du mot courant et l‚Äôalignement du mot pr√©c√©dent. 
Nous avons utilis√© l‚Äôoutil open source Giza++ (Och et Ney, 2003) qui impl√©mente ces 
mod√®les pour l‚Äôalignement des mots et nous avons extrait les  traductions candidates  √† 
partir d‚Äôune table de traductions cr√©√©e par Giza++. Chaque ligne de cette table contient 
un mot en langue arabe (ar) (respectivement yoruba (yo)), une traduction  candidate (fr) 
et un score qui calcule la probabilit√© de traduction P(fr|ar) (resp. yoruba P(fr|yo)). 
Apr√®s l‚Äô√©tape d‚Äôalignement, nous avons extrait 65 049 mots arabes et 155 348 paires de 
traductions candidates en fran√ßais. En ce qui concerne le lexique yoruba-fran√ßais, nous 
avons extrait 11 235 mots yoruba et 20 089 paires de traductions candidates en fran√ßais. 
Afin d‚Äôam√©liorer la qualit√© de nos lexiques, nous avons proc√©d√© √† une √©tape de filtrage 
qui √©limine les traductions candidates ayant un score inf√©rieur √† un seuil.  
 
 
 
 

FIGURE 1 ‚Äì Extrait de la table de traduction ar-fr 
 

 
 
 
 

FIGURE 2 ‚Äì Extrait de la table de traduction yo-fr 

R√≥m√π           Rome               0.7500 
R√≥m√π           romaine           0.33333 
al√°d√°nid√°     naturelles         1.00000 
√Äw√πj·ªç          Soci√©t√©             0.66666 
√Äw√πj·ªç          Communaut√©    0.20000 
Mathim√°t√≠k√¨ Math√©matiques 0.50000 
Copper         Cuivre              1.000 

ÿ™ÿ™ ÿ¥  Flou               1.0000000      ÿ™
ÿ™ÿ™ ÿ¥  Diffusion        0.1666667      ÿ™
ŸÑÿ±ÿ¨ÿßŸÑ  √âquipes           0.1250000      ŸÑ
ŸÑÿ±ÿ¨ÿßŸÑ  f√©minin           0.0067568      ŸÑ
ŸÑÿ±ÿ¨ÿßŸÑ  masculin         0.6690141      ŸÑ
ÿ∂ÿßÿ™ ŸÅÿßŸà  N√©gociations   1.0000000   ŸÖ
Ÿäÿßÿ™  Amazones        1.0000000  ÿ£ŸÖÿßÿ≤ŸàŸÜ
 

113



6 Evaluation 

Puisque notre int√©r√™t est centr√© sur les liens inter-langues de Wikip√©dia, les lexiques 
extraits ne contiennent pas des verbes.  
Nous avons √©valu√©, manuellement, la qualit√© de notre lexique bilingue en calculant la 
mesure de pr√©cision et en se r√©f√©rant √† un expert.  

ùëùùëüùëíùëêùëñùë†ùëñùëúùëõ =
nombre de traductions extraites correctes 

nombre de traductions extraites
 

Nous avons calcul√© la pr√©cision en se basant sur les traductions candidates de 50 mots 
arabes et yoruba et nous avons fait varier le seuil de 0 √† 1 pour en identifier la valeur 
optimale en fonction de la pr√©cision. 
La figure 3 pr√©sente les valeurs de pr√©cision des deux lexiques en variant le seuil.  
Remarquons qu‚Äôen augmentant le seuil, la pr√©cision est am√©lior√©e. Sa valeur passe de 
0.46 (avec un seuil √©gale 0) √† 0.74 (quand le seuil √©gale √† 1) pour le lexique yoruba-
fran√ßais et de 0.22 √† 0.75 pour le lexique arabe-fran√ßais. 
La figure 4 montre que la couverture du lexique fran√ßais-yoruba et presque stable, elle 
varie entre 14045 (quand le seuil √©gale √† 0) et 11184 (quand le seuil √©gale √† 1). Ces 
valeurs sont tr√®s inf√©rieures par rapport √† celles du lexique arabe-fran√ßais, ceci est d√ª 
principalement au faible nombre des articles Wikip√®dia yoruba.  
La figure 3 montre que les meilleures valeurs de pr√©cision sont atteintes √† partir d‚Äôun 
seuil √©gal √† 0.6 pour le lexique arabe-fran√ßais. Mais, remarquons dans la figure 4, qu‚Äô√† 
partir de ce seuil, la couverture du lexique est affaiblie. Ceci est expliqu√© par le fait que 
plusieurs fausses traductions ont √©t√© √©limin√©es √† partir de ce seuil. 
Les erreurs du lexique yoruba-fran√ßais sont dues principalement au fait que certains 
titres wikip√®dia sont introduits en anglais (ex. density/densit√©) et aux erreurs 
d‚Äôalignements (ex. Tanaka/Giichi).  
Les erreurs de traduction du lexique arabe-fran√ßais sont dues principalement au fait que 
certains titres arabes sont introduits en langue autre que l‚Äôarabe (ex. cv/cv), en majorit√© 
en langue anglaise. Certaines traductions candidates sont des translit√©rations et pas des 
traductions (ex. ÿßŸÜÿ™ŸÅÿßÿ∂ÿ©/Intifada). Aussi, nous avons d√©tect√© des erreurs d‚Äôalignement (ex.  
Ÿäÿ© ÿ≥ ŸÅ  diagnostique). D‚Äôautres erreurs sont dues au fait que les paires de titres des/ŸÜ
articles ne sont pas des traductions pr√©cises mais il s‚Äôagit juste de la m√™me notion  (ex. 
 .(No√´l/ÿπŸäÿØ

114



 
FIGURE 3 ‚ÄìVariation de la pr√©cision des lexiques yo-fr et ar-fr selon le seuil 

  
FIGURE 4 ‚Äì Variation de la couverture des lexiques yo-fr et ar-fr selon le seuil 

7 Conclusion 

L‚Äôexploitation de Wikip√©dia pour la construction de ressources linguistiques multilingues 
fait l‚Äôobjet de plusieurs travaux de recherches, comme la construction des corpus 
parall√®les, des lexiques multilingues et des ontologies multilingues. 
Dans cet article, nous avons d√©crit notre travail pr√©liminaire d‚Äôextraction de lexiques 
(arabe-fran√ßais et yoruba-fran√ßais) √† partir de Wikip√©dia. En effet, notre but majeur est 
d‚Äôexploiter Wikip√©dia en tant que corpus comparable pour la traduction automatique 
statistique.  
La m√©thode que nous proposons est efficace malgr√© sa simplicit√©. Il s‚Äôagit d‚Äôextraire les 
titres arabes, yorubas et fran√ßais des articles de Wikip√©dia, en se basant sur les liens 
inter-langues puis d‚Äôaligner les mots de ces titres en se basant sur une approche 
statistique. Nous avons atteint des valeurs de pr√©cision et de couverture encourageantes 
qui d√©passent respectivement 0.7 et 60 000 paires de traductions pour le lexique arabe-
fran√ßais et 0.7 et 14 000 paires de traductions pour le lexique yoruba-fran√ßais. 

0

0,1

0,2

0,3

0,4

0,5

0,6

0,7

0,8

pr√©cision ar-fr pr√©cision yo-fr

0

10000

20000

30000

40000

50000

60000

70000

couverture du lexique yo-fr couverture du lexique ar-fr

n
o

m
b

re
 d

e 
p

ai
re

s 
d

e 
tr

ad
u

ct
io

n
s

115



Comme travaux futurs, nous envisageons d‚Äô√©largir la couverture de nos lexiques en 
exploitant d‚Äôautres liens Wikip√©dia comme les redirections et les liens inter-wiki. Nous 
envisageons aussi d‚Äôutiliser ces lexiques pour l‚Äôextraction des corpus parall√®les (arabe- 
fran√ßais et yoruba-fran√ßais) √† partir de Wikip√©dia. Ces corpus seront utilis√©s au niveau de 
l‚Äôapprentissage des syst√®mes de traduction automatique statistique arabe-fran√ßais et 
yoruba-fran√ßais.  

ReÃÅfeÃÅrences 

ADAFRE, S. F. ET DE RIJKE, M. (2006). Finding Similar Sentences across Multiple Languages 
in Wikipedia. In Proceedings of the EACL Workshop on NEW TEXT Wikis and blogs and 
other dynamic text sources, pages 62‚Äì69. 

BOUMA, G., FAHMI, I., MUR, J., G. VAN NOORD, VAN DER, L., ET TIEDEMANN, J. (2006). Using 
Syntactic Knowledge for QA. In Working Notes for the Cross Language Evaluation Forum 
Workshop. 

BROWN PETER, F., PIETRA, V. J., PIETRA, S. A., ET MERCER, R. L. (1993). The Mathematics of 
Statistical Machine Translation: Parameter Estimation. IBM T.J. Watson Research Center, 
pages 264-311. 

DECLERCK, T., PEREZ, A. G., VELA, O., , Z., ET MANZANO-MACHO, D. (2006). Multilingual 
Lexical Semantic Resources for Ontology Translation. In Proceedings of International 
Conference on Language Ressources and Evaluation (LREC), pages 1492 ‚Äì 1495. 

ERDMANN, M., NAKAYAMA, K., HARA, T. ET NISHIO, S. (2008). A bilingual dictionary 
extracted from the wikipedia link structure. In Proceedings of International Conference on 
Database Systems for Advanced Applications (DASFAA) Demonstration Track, pages 380-
392. 

ERDMANN, M. (2008). Extraction of Bilingual Terminology from the Link Structure of 
Wikipedia. MSc. Thesis, Graduate School of Information Science and Engineering, Osaka 
University. 

GREFENSTETTE, G. (1998). The Problem of Cross-language Information Retrieval. Cross-
language Information Retrieval. Kluwer Academic Publishers. 

HAZEM, A., MORIN, E. ET SEBASTIAN P. S. (2011). Bilingual Lexicon Extraction from 
Comparable Corpora as Metasearch. In Proceedings of the 4th Workshop on Building and 

116



Using Comparable Corpora, pages 35‚Äì43, 49th Annual Meeting of the Association for 
Computational Linguistics, Portland, Oregon.  

MORIN, E. (2007). Synergie des approches et des ressources d√©ploy√©es pur le traitement 
de l‚Äô√©crit. Ph.D. thesis, Habilitation √† Diriger les Recherches, Universit√© de Nantes. 

MORIN, E. ET DAILLE, B. (2004). Extraction de terminologies bilingues √† partir de corpus 
comparables d‚Äôun domaine sp√©cialis√©. Traitement Automatique des Langues (TAL), pages 
103‚Äì122. 

MORIN, E. ET PROCHASSON E. (2011). Bilingual Lexicon Extraction from Comparable 
Corpora Enhanced with Parallel Corpora. In Proceedings of the 4th Workshop on Building 
and Using Comparable Corpora, pages 27‚Äì34. 

OCH, F.J. ET NEY, H. (2003). A systematic comparison of various statistical alignment 
models. Computational Linguistics, pages 19‚Äì51, March. 

OTERO, PABLO G. (2007). Learning bilingual lexicons from comparable english and 
spanish corpora. In Proceedings of Machine Translation Summit XI, pages 191‚Äì198. 

SADAT, F., YOSHIKAWA, M. ET UEMURA, S. 2003. Bilingual terminology acquisition from 
comparable corpora and phrasal translation to cross-language information retrieval. In 
Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume, 
pages 141‚Äì144. Association for Computational Linguistics. 

SADAT, F. ET TERRASSA, A. (2010). Exploitation de Wikip√©dia pour l‚ÄôEnrichissement et la 
Construction des Ressources Linguistiques. TALN 2010, Montr√©al. 

VOGEL, S., NEY H. ET C. TILLMANN (1996). HMM-based word alignment in statistical 
translation. In Preceding of the Conference on Computational Linguistics, pages 836‚Äì841, 
Morristown, NJ, USA. 

117




