



















































A Dynamic Speaker Model for Conversational Interactions


Proceedings of NAACL-HLT 2019, pages 2772â€“2785
Minneapolis, Minnesota, June 2 - June 7, 2019. cÂ©2019 Association for Computational Linguistics

2772

A Dynamic Speaker Model for Conversational Interactions

Hao Cheng Hao Fang Mari Ostendorf
University of Washington

{chenghao,hfang,ostendorf}@uw.edu

Abstract

Individual differences in speakers are reflected
in their language use as well as in their inter-
ests and opinions. Characterizing these differ-
ences can be useful in human-computer inter-
action, as well as analysis of human-human
conversations. In this work, we introduce a
neural model for learning a dynamically up-
dated speaker embedding in a conversational
context. Initial model training is unsuper-
vised, using context-sensitive language gen-
eration as an objective, with the context be-
ing the conversation history. Further fine-
tuning can leverage task-dependent supervised
training. The learned neural representation
of speakers is shown to be useful for content
ranking in a socialbot and dialog act prediction
in human-human conversations.1

1 Introduction

Representing language in context is key to improv-
ing natural language processing (NLP). There are
a variety of useful contexts, including word his-
tory, related documents, author/speaker informa-
tion, social context, knowledge graphs, visual or
situational grounding, etc. This paper addresses
the problem of modeling the speaker. Account-
ing for author/speaker variations has been shown
to be useful in many NLP tasks, including lan-
guage understanding (Hovy and SÃ¸gaard, 2015;
Volkova et al., 2013), language generation (Mirkin
et al., 2015; Li et al., 2016), human-computer di-
alog policy (Bowden et al., 2018), query comple-
tion (Jaech and Ostendorf, 2018; Shokouhi, 2013),
comment recommendation (Agarwal et al., 2011)
and more. In this work, we specifically focus on
dialogs, including both human-computer (social-
bot) and human-human conversations.

1The implementation of code is available at
https://github.com/hao-cheng/dynamic_
speaker_model.git

While many studies rely only on discrete meta-
data and/or demographic information, such infor-
mation is not always available. Thus, it is of in-
terest to learn about the speaker from the language
directly, as it relates to the personâ€™s interests and
speaking style. Motivated by the success of un-
supervised contextualized representation learning
for words and documents (Mikolov et al., 2013;
Kiros et al., 2015; McCann et al., 2017; Peters
et al., 2018; Devlin et al., 2019), our approach is to
use unsupervised learning with a neural model of
a speakerâ€™s dialog history. The model uses latent
speaker mode vectors for representing a speaker
turn as in (Cheng et al., 2017), which provides a
framework for analysis of what the model learns
about speaking style. Further, the model is struc-
tured to allow a dynamic update of the speaker
vector at each turn in a dialog, in order to capture
changes over time and improve the speaker repre-
sentation with added data.

The speaker embeddings can be used as context
in conversational language understanding tasks,
e.g., as an additional input in dialog policy predic-
tion in human-computer dialogs or in understand-
ing dialog acts in human-human dialogs. In the su-
pervised training of such tasks, the speaker model
can be fine-tuned.

This work makes two primary contributions.
First, we propose a neural model for learning dy-
namically updated speaker embeddings in conver-
sational interactions. The model training is un-
supervised, relying on only the speakerâ€™s conver-
sation history rather than meta information (e.g.,
age, gender) or audio signals which may not be
available in a privacy-sensitive situation. The
model also has a learnable component for analyz-
ing the latent modes of the speaker, which can be
helpful for aligning the learned characteristics of a
speaker with the human-interpretable factors. Sec-
ond, we use the learned dynamic speaker embed-

https://github.com/hao-cheng/dynamic_speaker_model.git
https://github.com/hao-cheng/dynamic_speaker_model.git


2773

Speaker State Tracker

ğ’‰1ğ’‰0 ğ’‰ğ‘¡ ğ’‰ğ‘¡+1

Latent Mode Analyzer

ğ’–1

Global Mode Vectors

ğ’–ğ¾
Attention

à·¥ğ’–ğ‘¡

ğ’”ğ‘¡

ğ’˜ğ‘¡,ğ‘ğ‘¡

ğ’˜ğ‘¡,1

ğ’…ğ‘¡,ğ‘ğ‘¡+1

ğ’…ğ‘¡,1

ğ’…ğ‘¡,0

ğ’˜ğ‘¡,0

ğ’˜ğ‘¡,ğ‘ğ‘¡

Speaker Language Predictor

ğ’†ğ‘¡,1

ğ’†ğ‘¡,ğ‘ğ‘¡

ğ‘¤ğ‘¡,1

</s>

Conversation-Level

Turn-Level

Figure 1: The dynamic speaker model. The speaker
state tracker operates at the conversation level. The la-
tent model analyzer and speaker language predictor op-
erate at the turn level. The figure only shows processes
in those two components for the turn t.

dings in two representative tasks in dialogs: pre-
dicting user topic decisions in socialbot dialogs,
and classifying dialog acts in human-human di-
alogs. Empirical results show that using the dy-
namic speaker embeddings significantly outper-
forms the baselines in both tasks. In the public
dialog act classification task, the proposed model
achieves the state-of-the-art results.

2 Dynamic Speaker Model

In this section, we start with an overview of the
proposed model for learning speaker embeddings
that are dynamically refined over the course of
a conversation. Details about individual compo-
nents are described in subsequent subsections.

The model is based on two motivations. First, a
speakerâ€™s utterances reflect intents, speaking style,
etc. Thus, we may build speaker embeddings
by analyzing latent modes that characterize utter-
ances in terms of such characteristics, apart from
topic-related interests a user might have. Second,
the information about a speaker is accumulated as
the conversation evolves, which allows us to grad-
ually refine and update the speaker embeddings.
The speaker embeddings can be directly used as
features or fine-tuned based on the downstream
tasks. We design the dynamic speaker model to
focus on learning cues from the speakerâ€™s utter-
ances, and leave the modeling of different speaker-
addressee interactions for supervised downstream
tasks.

The model consists of three components as il-
lustrated in Fig. 1. First, a latent mode analyzer

reads in an utterance and analyzes its latent modes.
It processes the speakerâ€™s turns independently of
each other and builds a local speaker mode vector
for each turn. To accumulate speaker information
as the conversation evolves, we build a speaker
state tracker that maintains speaker states at in-
dividual turns. At each turn, it takes two input
vectors to update the speaker state: 1) the local
speaker mode vector for the current turn from the
latent mode analyzer, and 2) the speaker state at
the previous turn from the tracker itself. Finally,
we employ a speaker language predictor to drive
the learning of the latent model analyzer and the
speaker state tracker. It reconstructs the utterance
using the corresponding speaker state. Intuitively,
the speaker language predictor models overall lin-
guistic regularities itself and uses the speaker state
to supply information related to speaker char-
acteristics. For sequence modeling in all three
components, we use the long short-term memory
(LSTM) recurrent neural network (Hochreiter and
Schmidhuber, 1997). In our experiments, the three
components are trained jointly.

2.1 Latent Mode Analyzer

At each turn t, the latent mode analyzer constructs
a local speaker mode vector uÌƒt âˆˆ Rc that captures
salient characteristics of the speakerâ€™s current ut-
terance for use in the dynamic speaker model.
First, the utterance word sequence wt,1, Â· Â· Â· , wt,Nt
is mapped to an embedding sequence, where wt,n
is represented with wt,n âˆˆ Rd according a lookup
with dictionary W âˆˆ R|V|Ã—d associated with vo-
cabulary V . Then, the latent mode analyzer goes
through two stages to construct uÌƒt.

In the first stage, a bi-directional LSTM (Bi-
LSTM), which consists of a forward LSTM and a
backward LSTM, is used to encode the word em-
bedding sequence into a fixed-size utterance sum-
mary vector st âˆˆ R2m, where m is the dimension
of the hidden layer in the forward and backward
LSTMs. Formally, the forward LSTM computes
its hidden states as eFt,n = g

F (wt,n, e
F
t,nâˆ’1) âˆˆ Rm

for n = 1, . . . , Nt, where gF (Â·, Â·) denotes the for-
ward LSTM function. The backward LSTM com-
putes its hidden states eBt,n âˆˆ Rm similarly. The
initial hidden states eFt,0 and e

B
t,Nt+1

are set to ze-
ros. The summary vector st is the concatenation
of the two final hidden states, st = [eFt,Nt , e

B
t,1].

In the second stage, the utterance summary vec-
tor st is compared with K global mode vectors



2774

u1, . . . ,uK âˆˆ Rc which are learned as part of
the model. The association score at,k between st
and uk is computed using the dot-product atten-
tion mechanism (Vaswani et al., 2017) as follows,

at,k =
exp(ã€ˆPst,Qukã€‰)âˆ‘K

kâ€²=1 exp(ã€ˆPst,Qukâ€²ã€‰)
, (1)

where P âˆˆ RcÃ—2m and Q âˆˆ RcÃ—c are learnable
weights, and ã€ˆÂ·, Â·ã€‰ indicates the dot-product of two
vectors. The local speaker mode vector is then
constructed as uÌƒt =

âˆ‘K
k=1 at,kuk.

2.2 Speaker State Tracker
The speaker state tracker provides a dynamic sum-
mary of speaker language features observed in
the conversation history, using an LSTM to en-
code the sequence of local speaker mode vec-
tors uÌƒt,1, Â· Â· Â· , uÌƒt,Nt . At turn t, this LSTM up-
dates its hidden state ht âˆˆ Rm using the local
speaker mode vector uÌƒt and its previous hidden
state htâˆ’1 âˆˆ Rm, i.e., ht = gS(uÌƒt,htâˆ’1), where
gS(Â·, Â·) is the speaker LSTM function. The hidden
state ht provides the speaker state vector at turn t.

2.3 Speaker Language Predictor
The speaker language predictor is a conditional
LSTM language model (LM) that reconstructs the
word sequence in the current turn. Language mod-
eling is a way to provide a training signal for un-
supervised learning that models the conditional
probability Pr(wt,n|wt,<n), where wt,<n denotes
all preceding words of wt,n in the turn t.

The speaker language predictor uses the same
dictionary W for word embeddings as the latent
mode analyzer to represent words at time t. The
initial hidden state dt,0 âˆˆ Rm of the LSTM is set
to tanh(Lht), where L âˆˆ RmÃ—m is a learnable
matrix and tanh(Â·) is the hyperbolic tangent func-
tion. Subsequent LSTM hidden states are com-
puted as

dt,n = g
LM (rI(wt,nâˆ’1,ht),dt,nâˆ’1),

for n = 1, . . . , Nt + 1, where rI(wt,nâˆ’1,ht) =
RIwwt,nâˆ’1 +R

I
hht is a linear transformation with

learned parameters RIw âˆˆ RmÃ—d and RIh âˆˆ
RmÃ—m, gLM (Â·, Â·) is a forward LSTM function,
and wt,0 is the word embedding for the start-of-
sentence token. By injecting the speaker state vec-
tor at every time step n in the turn t, the model
is more likely to favor directly using the speaker
state vector (vs. the word history) for predicting

the speaker language. The conditional probability
is then computed as

Pr(wt,n|wt,<n) = softmax(VrO(ht,dt,n)), (2)

where V âˆˆ R|V|Ã—m is the weight matrix, and
rO(ht,dt,n) = R

O
h ht + R

O
d dt,n is another lin-

ear function with learnable parameters ROh ,R
O
d âˆˆ

RmÃ—m. The last word wt,Nt+1 is always the end-
of-sentence token.

2.4 Model Training and Tuning

The training objective for a given conversation
is the log-likelihood

âˆ‘
t

âˆ‘
n log Pr(wt,n|wt,<n),

where the conditional probability is defined in (2).
The Adam optimizer (Kingma and Ba, 2015) is
used with a configuration of Î²1 = 0.9 and Î²2 =
0.97. The initial learning rate is set to 0.002. We
halve the learning rate at each epoch once the de-
velopment log-likelihood decreases, and terminate
the training when it decreases for the second time.
This validation protocol is used throughout the pa-
per for training the proposed model.

In our experiments, the embedding dictio-
nary W is initialized using pre-trained 300-
dimensional word embeddings (Bojanowski et al.,
2017) for words within the vocabulary of this
resource. The remaining part of W and other
model parameters are randomly initialized based
onN (0, 0.01). The mode vector dimension c is set
to 64. We tune the number of global mode vectors
K from {16, 32} and the hidden layer sizem from
{128, 160}. The final model is selected based on
the log-likelihood on the development set.

3 User Topic Decision Prediction

We first study a prediction task that estimates
whether the user engaged in a socialbot conversa-
tion would accept a suggested topic. Specifically,
we use a corpus of human-socialbot conversations
collected during the 2017 Alexa Prize competi-
tion (Ram et al., 2017) from the Sounding Board
system (Fang et al., 2018; Fang, 2019). Due to
privacy concerns, the socialbot does not have ac-
cess to any identity information about users. Also,
since each device may be used by multiple users,
the device address is not a reliable indicator of the
user ID. Therefore, the ability to profile the user
through one conversational interaction is desirable
for guiding the socialbotâ€™s dialog policy.



2775

train dev test
# conversations 19,076 6,321 6,465
# topic decisions 85,340 28,060 29,561

Table 1: Data statistics of the topic decision dataset.

3.1 Data

Each conversation begins with a greeting and ends
when the user makes a stop command. The so-
cialbot engages the user in the conversation using
a wide range of content indexed by topics, where
a topic corresponds to a noun or noun phrase that
refers to a named entity (e.g., Google) or a concept
(e.g., artificial intelligence). These topics are ex-
tracted using both constituency parsing results of
the textual content and content meta-information.
During the conversation, the socialbot sometimes
negotiates the topic with the user using an explicit
confirmation turn and records the userâ€™s binary de-
cision (accept or reject) on the topic.

In socialbot conversations, a system turn is al-
ways followed by a user turn and vice versa.
We tag system turns making explicit confirmation
about a topic and attach the corresponding binary
user decisions with them. To curate the dataset for
the topic decision prediction task, we use a total of
31,862 conversations with more than 5 user turns.
On average there are around 22 user turns per con-
versation. Not every system turn makes a topic
suggestion, and the average number of topic deci-
sions per conversation is 4.5. We randomly split
the conversations into training, development, and
test sets by 3/1/1. The data statistics are shown
in Table 1. In our experiments, we directly use the
speech recognition output of user utterances. The
vocabulary V consists of roughly 11K words that
appear at least 5 times in the training set.

3.2 Topic Decision Classifier

We use a feed-forward neural network (FFNN) to
make binary predictions (accept vs. reject) for in-
dividual topic suggestions. For each topic sugges-
tion, the FFNN takes two inputs: 1) an embedding
xtâ€² for the suggested topic at system turn tâ€², and 2)
a user embedding vector zt at user turn t. Note the
model does not have information about user turns
after the system turn tâ€² when making the predic-
tion, i.e., the user turn t appears before the system
turn tâ€².

The topic embedding xtâ€²â€™s are looked up from
the embedding dictionary learned by the FFNN.

They are initialized by averaging the embeddings
of their component words using the public pre-
trained 300-dimensional word embeddings (Bo-
janowski et al., 2017).

For the user embedding vector, we explore two
settings that use different numbers of user turns as
context. In both settings, topic decisions occurring
in the first 5 user turns are not used for evaluations.
Static User Embeddings: Motivated by the find-
ings that most user characteristics can be inferred
from initial interactions (Ravichander and Black,
2018), we derive a static user embedding vector
for a conversation using the first 5 user turns and
apply it for predicting topic decisions afterwards.
Dynamic User Embeddings: Alternatively, we
build a user embedding vector for user turn t us-
ing all previous user turns. Here, a topic decision
for system turn tâ€² is aligned with its preceding user
turn t.

In our experiments, we compare different un-
supervised models with our proposed dynamic
speaker model. For both settings, all unsupervised
models are pre-trained on all user turns in training
conversations. They are fixed when training the
FFNN classifier. The FFNN classifier is trained
with the logistic loss using the Adam optimizer
(Kingma and Ba, 2015). The training protocol is
similar to that described in Â§2.4. We tune the hid-
den layer size from {64, 128} and the number of
hidden layers from {0, 1}. The model is selected
based on the loss on the development set.

In addition, we use a user-agnostic TopicPrior
baseline. It builds a probability lookup for each
topic using its acceptance rate on the training set.
We tune a universal probability threshold for all
topics based on the development set accuracy.

In all experiments, three evaluation metrics are
used: accuracy, area under the receiver operating
characteristic curve (AUC), and normalized cross-
entropy (N-CE). N-CE is computed as the relative
cross-entropy reduction of the model over the Top-
icPrior baseline.

3.3 Experiments: Static User Embeddings

As described in Â§3.2, we use the first 5 user turns
to derive the user embedding vector for a conver-
sation. We compare our dynamic speaker model
with three other unsupervised models.
DynamicSpeakerModel: For the proposed dy-
namic speaker model, we concatenate the speaker
state vector ht and the local speaker mode vector



2776

Model Acc AUC N-CE
TopicPrior 68.8 72.5 0
UtteranceLDA 68.8 73.1 12.6
UtteranceAE 68.8 73.4 12.8
TopicDecisionEncoder 68.9 73.8 13.4
DynamicSpeakerModel 69.5 74.2 13.7

Table 2: Test set results (in %) for topic decision pre-
dictions using static user embeddings.

uÌƒt for each of the first 5 user turns. Then, we apply
the max-pooling operation over the 5 concatenated
vectors to summarize all the information. The re-
sulting vector hÌƒ is used as the user embedding vec-
tor.
UtteranceLDA: The latent Dirichlet allocation
(LDA) model (Blei et al., 2003) is trained with 16
latent groups by treating all user utterances in a
conversation as a document.2 The trained LDA
model builds a 16-dimensional probability vector
as the user embedding vector by loading the first 5
user turns as a single document.
UtteranceAE: The utterance auto-encoder model
is built upon the sequence auto-encoder (Dai and
Le, 2015). We replace the original encoder by a
BiLSTM that encodes the utterance at user turn t
into a summary vector st in the same way as the
first stage of the latent mode analyzer described in
Â§2.1. The auto-encoder is trained on all user ut-
terances in the training data, using the same train-
ing protocol described in Â§2.4. We set the hidden
layer size to 128. The user embedding vector is
constructed by applying the max-pooling opera-
tion over the summary vectors s1, . . . , s5 for the
first 5 user turns.
TopicDecisionEncoder: This model encodes the
topic decisions occurred in the first 5 user turns.
The user embedding vector is the concatenation of
two vectors. One is max-pooled from the topic
embeddings for accepted topics, and the other for
rejected topics, both include a dummy topic vector
as default. The topic embeddings are composed by
averaging the public pre-trained 300-dimensional
embeddings (Bojanowski et al., 2017) for words in
the topic.

Experiment results are summarized in Table 2.
The TopicPrior is a very strong predictor, with an

2To allow the LDA model to take into account bi-grams,
we replace the uni-gram token wi with its bi-gram (wi, wi+1)
concatenated as a single token if the bi-gram is among the top
500 frequent bi-grams.

Model Acc AUC N-CE
TopicDecisionLSTM 69.3 74.8 14.6
UtteranceAE + LSTM 69.9 75.4 15.3
DynamicSpeakerModel 72.4 79.0 20.0âˆ—

Table 3: Test set results (in %) for topic decision pre-
dictions using dynamic user embeddings. âˆ—: The im-
provement of DynamicSpeakerModel over both Top-
icDecisionLSTM and UtteranceAE + LSTM is statis-
tically significant based on both t-test and McNemarâ€™s
test (p < .001).

accuracy on par with other user embeddings. This
indicates that the popularity-based approach is a
good start for content ranking in socialbots when
there is little user information. Nevertheless, we
can still observe some improvement over the Top-
icPrior in terms of AUC and N-CE, which suggests
using information from initial interactions reduces
the uncertainty of predictions. The proposed dy-
namic speaker model performs the best among the
compared models, reducing the cross-entropy by
13.7% over the TopicPrior baseline.

3.4 Experiments: Dynamic User Embeddings
Here, we use all information accumulated before
the system turn of suggesting the topic to build the
corresponding user embedding vector. Since the
UtteranceLDA is not as effective based on static
embedding experiments, we only consider extend-
ing UtteranceAE and TopicDecisionEncoder mod-
els for comparison here.
DynamicSpeakerModel: The speaker state
tracker in our model accumulates the user infor-
mation as the conversation evolves. Thus, we
directly concatenate the speaker state vector ht
and the local speaker mode vector uÌƒt as the user
embedding vector at user turn t. Other than us-
ing more turns, this is the same DynamicSpeaker-
Model configuration as in Â§3.3.
UtteranceAE+LSTM: This model uses an LSTM
to encode the summary vector sequence derived
from the same utterance auto-encoder used in
Â§3.3. The LSTM hidden states are treated as user
embedding vectors at individual user turns.
TopicDecisionLSTM: Similarly, an LSTM is
used to encode the topic decision sequence. At
each time step, the LSTM reads the concatenation
of the topic embedding and the one-hot vector en-
coding the topic decision. We use the same topic
embeddings as the TopicDecisionEncoder in Â§3.3.
Since not every user turn is associated with a topic



2777

decision, the time steps of this LSTM are aligned
to a sequence of non-consecutive user turns. The
LSTM hidden states are treated as user embedding
vectors at corresponding user turns.

For UtteranceAE+LSTM and TopicDecision-
LSTM, the hidden layer size of the LSTM is set to
128. While the utterance auto-encoder and topic
embeddings are pre-trained, the LSTM compo-
nents are jointly learned with the FFNN for com-
posing dynamic user embeddings.

Experiment results are shown in Table 3. The
DynamicSpeakerModel performs the best. Com-
paring to results in Table 2, all three unsupervised
models outperform their static counterparts, which
suggests the advantage of using dynamic context
for predicting user topic decisions as conversation
evolves.

Statistical significance tests of the difference in
performance of two systems were conducted un-
der both the t-test using the predicted probabilities
and McNemarâ€™s test using the binary predictions.
Under both tests, the predictions from the Top-
icDecisionLSTM and the DynamicSpeakerModel
are highly signification (p < .001). Predictions
from UtteranceAE + LSTM and DynamicSpeak-
erModel are also significantly different based on
both tests (p < .001).

3.5 Qualitative Analysis

First, we manually inspect the predictions from the
TopicDecisionLSTM and DynamicSpeakerModel
used in Â§3.4 and the static baseline TopicPrior in
Â§3.3. Compared with TopicPrior, we find that Top-
icDecisionLSTM is able to utilize the semantic
relatedness between neighboring topics and cor-
responding user decisions. For example, â€œElon
Muskâ€ (the CEO) is likely to be rejected if â€œTeslaâ€
(the company) has been rejected earlier, though
both are popular topics with high acceptance rates.
In addition, it seems that the DynamicSpeaker-
Model is able to make use of user reactions. In
the anecdotal example illustrated in Table 4, the
user accepts the topic â€œArnold Schwarzeneggerâ€
which is correctly predicted by both TopicDeci-
sionLSTM and DynamicSpeakerModel, but only
the DynamicSpeakerModel correctly predicts the
rejection of â€œpoliticsâ€ later.

We then analyze what language features are
learned by latent modes in our dynamic speaker
model. For each mode, we extract top utterances
sorted by their association scores as computed in

Bot: Do you like the actor Arnold Schwarzenegger?
User: yeah before he got into politics
Bot: Super, would you like to know a fun fact about
Arnold Schwarzenegger?

â€¢ TopicDecisionLSTM: accept
â€¢ DynamicSpeakerModel: accept

User: why not sure
. . .
Bot: Iâ€™m running out of things to say about him. Do
you wanna hear some news about politics?

â€¢ TopicDecisionLSTM: accept
â€¢ DynamicSpeakerModel: reject

User: no

Table 4: A dialog snippet showing topic decision
predictions from TopicDecisionLSTM and DynamicS-
peakerModel. Topics are shown with underscores.

(1). Examples from the most representative modes
are provided in Appendix A. In brief, we find
two separate modes related to positive and nega-
tive reactions; other modes correspond to classes
of dialog acts, such as yes/no answers, topic re-
quests and conversation-closing. Within topic re-
quest modes, some involve short topic phrases
(e.g., â€œholidaysâ€) while others use complete re-
quests (e.g. â€œcan we talk about catsâ€). Along this
line, some modes are associated with relatively
terse users and others with talkative users. These
findings indicate that our model cpatures various
user characteristics that might be useful for pre-
dicting their interaction preferences.

4 Dialog Act Classification

Dialog act analysis is widely used for conversa-
tions, which identifies the illocutionary force of a
speakerâ€™s utterance following the speech act the-
ory (Austin, 1975; Searle, 1969). In this section,
we apply the proposed dynamic speaker model to
the dialog act classification task.

4.1 Data

We use the Switchboard Dialog Act Corpus
(SwDA), which has dialog act annotations on two-
party human-human speech conversations (Juraf-
sky et al., 1997; Stolcke et al., 2000). In total,
there are 1155 open-domain conversations with
manual transcripts. Following recent work, we
use 1115 conversations for training, 19 for test-
ing, and the rest 21 for development.3 The origi-
nal fine-grained dialog act labels are mapped to 42

3The training and test split files are downloaded from
https://web.stanford.edu/Ëœjurafsky/ws97/.

https://web.stanford.edu/~jurafsky/ws97/


2778

ğ’™ğ­

ğ’›ğ­âˆ’ğŸ

ğ’™ğ­âˆ’ğŸ

ğ’›ğ­

ğ’št

ğ’›ğ­âˆ’ğŸ

ğ’™ğ­âˆ’ğŸ

Speaker 
A

ğ’‰ğ›½(ğ‘¡âˆ’1)
ğµ ğ’‰ğ›½(ğ‘¡+1)

ğµ

ğ’‰ğ›¼(ğ‘¡)
ğ´

Speaker 
B

Attention
ğ’ˆ1

D
ia

lo
g 

A
ct

 V
e

ct
o

rs

ğ’ˆğ¿

à·¥ğ’ˆğ‘¡

Figure 2: The attention-based LSTM tagging model for
dialog act classification. The figure only shows the at-
tention operation for turn t. The lower two boxes rep-
resent two speaker state trackers.

classes.4 For this set of experiments, we use the
golden segmentation and manual transcripts pro-
vided in the dataset.

Motivated by the recent success of unsupervised
models (Peters et al., 2018; Devlin et al., 2019), we
also study whether the dynamic speaker model can
benefit from training on external unlabelled data.
Thus, we use speech transcripts from 5850 conver-
sations from the Fisher English Training Speech
Part 1 Transcripts (Cieri et al., 2004), which
(like Switchboard) consists of two-party human-
to-human telephone conversations but without an-
notations for dialog acts.

4.2 Dialog Act Tagging Model
We use an attention-based LSTM tagging model
for the dialog act classification. As shown in
Fig. 2, the tagging LSTM is stacked on two
speaker state trackers. Note the two trackers share
the same parameters as well as the underlying la-
tent mode analyzer and speaker language predic-
tor. They generate speaker embeddings by track-
ing corresponding speakers separately.

Let Î±(t) and Î²(t) denote the mappings from the
global turn index t to the speaker-specific turn in-
dices for speaker A and speaker B, respectively.
The mapping returns a null value if the turn t
is not associated with the corresponding speaker.
The speaker state vectors are used as the input to
the tagging LSTM for corresponding turns, i.e.,
xt = I(h

A
Î±(t),h

B
Î²(t)) where I(Â·, Â·) is a switcher that

chooses hAÎ±(t) or h
B
Î²(t) depending on whether Î±(t)

4Dialog act labels are mapped using scripts from
http://compprag.christopherpotts.net/
swda.html . Utterances labelled as â€œsegmentâ€ are merged
with corresponding previous utterance by the same speaker.

and Î²(t) return a non-null value.
The tagging LSTM also maintains a dictionary

of L dialog act vectors g1, . . . ,gL. The dialog act
probabilities yt âˆˆ RL at turn t are computed using
the dot-product attention mechanism, i.e., yt =
f(zt, [g1, . . . ,gL]), where f(Â·, Â·) is defined as in
(1), and zt is the hidden state vector of the LSTM.

The tagging LSTM computes hidden states as

zt+1 = g
DA
(
rDA(gÌƒt,xt+1), zt

)
where gÌƒt =

âˆ‘L
l=1 yt,lgl, g

DA(Â·, Â·) is the LSTM
function, and rDA(Â·, Â·) is a linear function with
learnable parameters. In this way, both the history
dialog act predictions and the utterance informa-
tion are encoded in the hidden states.

The training objective of the tagging LSTM is
the sum of the cross-entropy between the dialog
act label and the probabilities yt at each turn. The
training configuration is the same as the topic de-
cision classifier described in Â§3.2. We tune the
size of hidden states zt and dialog act embed-
dings gl from {64, 128} with arbitrary combina-
tions, and vary the number of LSTM hidden layers
from {1, 2}. The best model is selected according
to the development set accuracy.

4.3 Experiment Results

In our experiments, we compare three settings for
using the dynamic speaker model. In the pre-train
setting, the dynamic speaker model is trained on
the SwDA data without the dialog act labels. We
then freeze the model when training the tagging
LSTM. In contrast, in the pretrain + fine-tune
setting, the dynamic speaker model is fine-tuned
together with the tagging LSTM. Finally, in the
pre-train w/Fisher + fine-tune setting, the dy-
namic speaker model is pre-trained on the com-
bination of SwDA and Fisher datasets, and then
fine-tuned together with the tagging LSTM on the
SwDA dataset. For all three settings, we use the
same vocabulary V of size 21K which combines
all tokens from the SwDA training set and those
appearing at least 5 time in the Fisher corpus.

We compare our results to best published re-
sults. In (Kalchbrenner and Blunsom, 2013), a
convolutional neural network (CNN) is used to
encode utterances. A recurrent neural network
(RNN) is then applied on top of the CNN to en-
code both utterances and speaker label informa-
tion for predicting the dialog acts. Ji et al. (2016)
propose a discourse-aware RNN LM by treating

http://compprag.christopherpotts.net/swda.html
http://compprag.christopherpotts.net/swda.html


2779

Model Acc (%)
(Kalchbrenner and Blunsom, 2013) 73.9
(Tran et al., 2017a) 74.2
(Tran et al., 2017b) 74.5
(Tran et al., 2017c) 75.6
(Ji et al., 2016) 77.0
pre-train 75.6
pre-train + fine-tune 77.2
pre-train w/ Fisher + fine-tune 78.6âˆ—

Table 5: Test set accuracy for SwDA dialog act clas-
sification. âˆ—: The improvement of pre-train w/ Fisher
+ fine-tune is statistically significant over pre-train +
fine-tune based on McNemarâ€™s test (p < .001).

the dialog act as a conditional variable to the LM.
Tran et al. (2017a,b,c) focus on building hierar-
chies of RNNs to model the dialog context using
previous utterances or dialog act predictions. Re-
sults from (Lee and Dernoncourt, 2016) and (Liu
et al., 2017) are not directly comparable due to dif-
ferent experiment settings.

Experiment results are summarized in Table 5.
Our pre-train setting performs on par with previ-
ous state-of-the-art supervised models except (Ji
et al., 2016). Fine-tuning significantly improves
the performance and allows the model to achieve a
similar accuracy as (Ji et al., 2016). The best result
is achieved by pre-training the dynamic speaker
model with both SwDA and Fisher datasets. The
improvement of pre-train w/ Fisher + fine-tune is
statistically significant over pre-train + fine-tune
based on McNemarâ€™s test (p < .001). This illus-
trates the advantage of the unsupervised learning
approach for the proposed model as it can exploit
a large amount of unlabelled data.

4.4 Qualitative Analysis

We analyze the latent modes learned on SwDA us-
ing the same approach as in Â§3.5. Again, specific
examples are included in Appendix A. Overall,
there are several modes corresponding to coarse-
grained dialog acts, such as statements, questions,
agreement, backchannel and conversation-closing.
Many modes characterize statements, probably
due to their high relative frequency in the corpus.
Among the statement modes, there are two dis-
tinct groups, one containing multiple filled pauses,
such as uh, you know, well, and the other one with
because-clauses. The fact that coarse-grained dia-
log act information is partly encoded in the modes

may be helping with recognizing the dialog act.
In addition, we use the speaker gender infor-

mation available in the SwDA data to determine
whether the latent modes in the dynamic speaker
model pick up gender-related language variation.
Specific examples and statistics are included in
Appendix B. The Cohen-d score (Cohen, 1988) is
used to measure the strength of the difference be-
tween association score distributions of male vs.
female utterances for individual modes. Based
on the Cohen-d score, we identified two modes
that have a strong association with male speak-
ers, and two with female speakers. All have sig-
nificantly different (p < 0.001) distributions of
association scores for female vs. male speakers
using Mann-Whitney U test. In the top associ-
ated utterances for the male modes, we find utter-
ances with several filled pauses, which has been
found to be indicative of male speakers in pre-
vious work on Switchboard (Boulis and Osten-
dorf, 2005). The female modes are mostly agree-
ment, acknowledgement and backchannel, which
aligns with a popular sociolinguistic theory that fe-
males are more responsive (Coates, 1998). Based
on this, we conclude that some speaker gender
language variations are indeed captured by the
learned modes.

5 Related Work

As reviewed by Zukerman and Litman (2001),
user modeling for conversational systems has a
long history. The research can be tracked back to
the GRUNDY system (Rich, 1979) which catego-
rizes users in terms of hand-crafted sets of user
properties for book recommendation. Other sys-
tems have focused on different aspects of users,
e.g., the expertise level of the user in a specific
domain (Chin, 1986; Sleeman, 1985; Paris, 1987;
Hovy, 1987), the userâ€™s intent and plan (Allen
and Perrault, 1980; Carberry, 1983; Litman, 1986;
Moore and Paris, 1992), and the userâ€™s personality
(Mairesse and Walker, 2006; DeVault et al., 2014;
Fung et al., 2016; Fang et al., 2017). User model-
ing has also been employed for personalized topic
suggestion in recent Alexa Prize socialbots, using
a pre-defined mapping between personality types
and topics (Fang et al., 2017), or a conditional ran-
dom field sequence model with hand-crafted user
and context features (Ahmadvand et al., 2018).
Modeling speakers with continuous embeddings
for neural conversation models is studied in (Li



2780

et al., 2016), where the model directly learns a
dictionary of speaker embeddings. Our unsuper-
vised dynamic speaker model differs from previ-
ous work in that we build speaker embeddings
as a weighted combination of latent modes with
weights computed based on the utterance. Thus,
the model can construct embeddings for any new
users and dynamically update the embeddings as
the conversation evolves.

Speaker language variances have been ana-
lyzed by previous work and incorporated in NLP
models. PreotÌ§iuc-Pietro et al. (2016) and Jo-
hannsen et al. (2015) find that speaker-level lan-
guage variance affects lexical choices and even
syntactic structure based on psycholinguistic hy-
potheses. Speaker demographics are used to im-
prove both low-level tasks such as part-of-speech
tagging (Hovy and SÃ¸gaard, 2015) and high-level
applications such as sentiment analysis (Volkova
et al., 2013) and machine translation (Mirkin et al.,
2015). Lynn et al. (2017) introduce a continu-
ous adaptation method to include user age, gender,
personality traits and language features for person-
alizing several supervised NLP models. Different
from previous work, we study the use of speaker
embeddings learned from utterances in an unsu-
pervised fashion and analyze the possible inter-
pretability of the latent modes.

6 Conclusion

In this paper, we address the problem of mod-
eling speakers from their language using an un-
supervised approach. A dynamic speaker model
is proposed to learn speaker embeddings that are
updated as the conversation evolves. The model
achieves promising results on two representative
tasks in dialogs: user topic decision prediction
in human-socialbot conversations and dialog act
classification in human-human conversations. In
particular, we demonstrate that the model can ben-
efit from unlabelled data in the dialog act classi-
fication task, where we achieve the state-of-the-
art results. Finally, we carry out analysis on the
learned latent modes on both tasks, and find cues
that suggest the model captures speaker character-
istics such as intent, speaking style, and gender.
For future work, it could be interesting to explore
guiding some latent modes with a few examples to
pick up specific user features such as personality
traits.

Acknowledgements

We thank the anonymous reviewers for their help-
ful feedback. We also thank Trang Tran for her
feedback on the paper. This research is supported
by Amazon Alexa Fellowship and Tencent AI Lab
Rhino-Bird Gift Fund. The conclusions and find-
ings are those of the authors and do not necessarily
reflect the views of sponsors.

References
Deepak Agarwal, Bee-Chung Chen, and Bo Pang.

2011. Personalized recommendation of user com-
ments via factor models. In Proc. Conf. Empirical
Methods Natural Language Process. (EMNLP).

Ali Ahmadvand, Ingyu Choi, Harshita Sahijwani, Jus-
tus Schmidt, Mingyang Sun, Sergey Volokhin, Zi-
hao Wang, and Eugene Agichtein. 2018. Emory
IrisBot: An open-domain conversational bot for per-
sonalized information access. In Proc. Alexa Prize
2018.

James F. Allen and C. Raymond Perrault. 1980. Ana-
lyzing intention in utterances. Artificial Intelligence,
15:143â€“178.

John L. Austin. 1975. How To Do Things with Words,
2nd edition. Harvard University Press, Cambridge,
MA.

David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. J. Machine Learn-
ing Research, 3:993â€“1022.

Piotr Bojanowski, Edouard Grave, Armand Joulin, and
Tomas Mikolov. 2017. Enriching word vectors with
subword information. Transactions of the Associa-
tion for Computational Linguistics, 5:135â€“146.

Constantinos Boulis and Mari Ostendorf. 2005. A
quantitative analysis of lexical differences between
genders in telephone conversations. In Proc.
Annu. Meeting Assoc. for Computational Linguistics
(ACL), pages 435â€“442.

Kevin K. Bowden, Jiaqi Wu, Wen Cui, Juraj Juraska,
Vrindavan Harrison, Brian Schwarzmann, Nick San-
ter, and Marilyn Walker. 2018. SlugBot: Develop-
ing a computational model and framework of a novel
dialogue genre. In Proc. Alexa Prize 2018.

Sandra Carberry. 1983. Tracking user goals in an
information-seeking environment. In Proc. AAAI
Conf. Artificial Intelligence, pages 59â€“63.

Hao Cheng, Hao Fang, and Mari Ostendorf. 2017.
A factored neural network model for characteriz-
ing online discussions in vector space. In Proc.
Conf. Empirical Methods Natural Language Pro-
cess. (EMNLP), pages 2296â€“2306.

http://aclweb.org/anthology/Q17-1010
http://aclweb.org/anthology/Q17-1010
http://aclweb.org/anthology/P05-1054
http://aclweb.org/anthology/P05-1054
http://aclweb.org/anthology/P05-1054
http://aclweb.org/anthology/D17-1243
http://aclweb.org/anthology/D17-1243


2781

David N. Chin. 1986. User modeling in UC, the UNIX
consultant. In Proc. Computer Human Interactions
(CHI), pages 24â€“28.

Christopher Cieri, David Graff, Owen Kimball, Dave
Miller, and Kevin Walker. 2004. Fisher english
training speech part 1 transcripts LDC2004T19.
Web Download.

Jennifer Coates, editor. 1998. Language and gender: a
reader. Wiley-Blackwell.

Jacob Cohen. 1988. Statistical Power Analysis for
the Behavioral Sciences. Lawrence Erlbaum Asso-
ciates.

Andrew M Dai and Quoc V Le. 2015. Semi-supervised
sequence learning. In Proc. Annu. Conf. Neural In-
form. Process. Syst. (NIPS), pages 3079â€“3087.

David DeVault, Ron Artstein, Grace Benn, Teresa
Dey, Ed Fast, Alesia Gainer, Kallirroi Georgila, Jon
Gratch, Arno Hartholt, Margaux Lhommet, et al.
2014. SimSensei kiosk: A virtual human inter-
viewer for healthcare decision support. In Proc. Int.
Conf. Autonomous Agents and Multi-agent Systems,
pages 1061â€“1068.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. In Proc. Conf. North American Chapter Assoc.
for Computational Linguistics (NAACL).

Hao Fang. 2019. Building a User-Centric and Content-
Driven Socialbot. Ph.D. thesis, University of Wash-
ington.

Hao Fang, Hao Cheng, Elizabeth Clark, Ariel Holtz-
man, Maarten Sap, Mari Ostendorf, Yejin Choi, and
Noah Smith. 2017. Sounding Board â€“ University
of Washingtonâ€™s Alexa Prize submission. In Proc.
Alexa Prize.

Hao Fang, Hao Cheng, Maarten Sap, Elizabeth Clark,
Ariel Holtzman, Yejin Choi, Noah Smith, and Mari
Ostendorf. 2018. Sounding Board â€“ a user-centric
and content-driven social chatbot. In Proc. Conf.
North American Chapter Assoc. for Computational
Linguistics (NAACL) (System Demonstrations).

Pascale Fung, Anik Dey, Farhad Bin Siddique, Ruixi
Lin, Yang Yang, Yan Wan, and Ricky Ho Yin Chan.
2016. Zara the supergirl: An empathetic personal-
ity recognition system. In Proc. Conf. North Amer-
ican Chapter Assoc. for Computational Linguistics
(NAACL) (System Demonstrations).

Sepp Hochreiter and JuÌˆrgen Schmidhuber. 1997.
Long short-term memory. Neural Computation,
9(8):1735â€“1780.

Dirk Hovy and Anders SÃ¸gaard. 2015. Tagging per-
formance correlates with author age. In Proc.
Annu. Meeting Assoc. for Computational Linguistics
(ACL), pages 483â€“488.

Eduard Hovy. 1987. Generating natural language un-
der pragmatic constraints. Journal of Pragmatics,
11:689â€“710.

Aaron Jaech and Mari Ostendorf. 2018. Personalized
language model for query auto-completion. In Proc.
Annu. Meeting Assoc. for Computational Linguistics
(ACL), pages 700â€“705.

Yangfeng Ji, Gholamreza Haffari, and Jacob Eisen-
stein. 2016. A latent variable recurrent neural net-
work for discourse relation language models. In
Proc. Conf. North American Chapter Assoc. for
Computational Linguistics (NAACL), pages 332â€“
342.

Anders Johannsen, Dirk Hovy, and Anders SÃ¸gaard.
2015. Cross-lingual syntactic variation over age and
gender. In Proc. Conf. Computational Natural Lan-
guage Learning (CoNLL), pages 103â€“112.

Dan Jurafsky, Elizabeth Shriberg, , and Debra Biasca.
1997. Switchboard swbd-damsl shallow-discourse-
function annotation coders manual, draft 13. Tech-
nical report, University of Colorado, Boulder.

Nal Kalchbrenner and Phil Blunsom. 2013. Recurrent
convolutional neural networks for discourse compo-
sitionality. In Proceedings of the Workshop on Con-
tinuous Vector Space Models and their Composition-
ality, pages 119â€“126.

Diederik Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proc. Int.
Conf. Learning Representations (ICLR).

Ryan Kiros, Yukun Zhu, Ruslan R Salakhutdinov,
Richard Zemel, Raquel Urtasun, Antonio Torralba,
and Sanja Fidler. 2015. Skip-thought vectors. In
Proc. Annu. Conf. Neural Inform. Process. Syst.
(NIPS), pages 3294â€“3302.

Ji Young Lee and Franck Dernoncourt. 2016. Sequen-
tial short-text classification with recurrent and con-
volutional neural networks. In Proc. Conf. North
American Chapter Assoc. for Computational Lin-
guistics (NAACL), pages 515â€“520.

Jiwei Li, Michel Galley, Chris Brockett, Georgios P.
Spithourakis, Jianfeng Gao, and William B. Dolan.
2016. A persona-based neural conversation model.
In Proc. Annu. Meeting Assoc. for Computational
Linguistics (ACL), pages 994â€“1003.

Diane J. Litman. 1986. Linguistic coherence: a plan-
based alternative. In Proc. Annu. Meeting Assoc. for
Computational Linguistics (ACL), pages 215â€“223.

Yang Liu, Kun Han, Zhao Tan, and Yun Lei. 2017.
Using context information for dialog act classifi-
cation in dnn framework. In Proc. Conf. Empiri-
cal Methods Natural Language Process. (EMNLP),
pages 2170â€“2178.

https://catalog.ldc.upenn.edu/LDC2004T19
https://catalog.ldc.upenn.edu/LDC2004T19
http://papers.nips.cc/paper/5949-semi-supervised-sequence-learning.pdf
http://papers.nips.cc/paper/5949-semi-supervised-sequence-learning.pdf
https://arxiv.org/abs/1810.04805
https://arxiv.org/abs/1810.04805
https://arxiv.org/abs/1810.04805
http://aclweb.org/anthology/P15-2079
http://aclweb.org/anthology/P15-2079
http://aclweb.org/anthology/P18-2111
http://aclweb.org/anthology/P18-2111
http://aclweb.org/anthology/N16-1037
http://aclweb.org/anthology/N16-1037
http://aclweb.org/anthology/K15-1011
http://aclweb.org/anthology/K15-1011
http://aclweb.org/anthology/W13-3214
http://aclweb.org/anthology/W13-3214
http://aclweb.org/anthology/W13-3214
http://papers.nips.cc/paper/5950-skip-thought-vectors.pdf
http://aclweb.org/anthology/N16-1062
http://aclweb.org/anthology/N16-1062
http://aclweb.org/anthology/N16-1062
http://aclweb.org/anthology/P16-1094
http://aclweb.org/anthology/D17-1231
http://aclweb.org/anthology/D17-1231


2782

Veronica Lynn, Youngseo Son, Vivek Kulkarni, Ni-
ranjan Balasubramanian, and H. Andrew Schwartz.
2017. Human centered nlp with user-factor adap-
tation. In Proc. Conf. Empirical Methods Natural
Language Process. (EMNLP), pages 1146â€“1155.

FrancÌ§ois Mairesse and Marilyn Walker. 2006. Au-
tomatic recognition of personality in conversation.
In Proc. Conf. North American Chapter Assoc. for
Computational Linguistics (NAACL), pages 85â€“88.

Bryan McCann, James Bradbury, Caiming Xiong, and
Richard Socher. 2017. Learned in translation: Con-
textualized word vectors. In Proc. Annu. Conf. Neu-
ral Inform. Process. Syst. (NIPS), pages 6294â€“6305.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proc. Annu. Conf. Neural Inform. Process.
Syst. (NIPS), pages 3111â€“3119.

Shachar Mirkin, Scott Nowson, Caroline Brun, and
Julien Perez. 2015. Motivating personality-aware
machine translation. In Proc. Conf. Empirical Meth-
ods Natural Language Process. (EMNLP), pages
1102â€“1108.

Johanna D. Moore and Cecile Paris. 1992. Exploiting
user feedback to compensate for the unreliability of
user models. User Modeling and User-Adapted In-
teraction, 2:287â€“330.

CeÌcile L. Paris. 1987. The Use of Explicit User Models
in a Generation System for Tailoring Answers to the
Userâ€™s Level of Expertise. Ph.D. thesis, Columbia
University.

Matthew Peters, Mark Neumann, Mohit Iyyer, Matt
Gardner, Christopher Clark, Kenton Lee, and Luke
Zettlemoyer. 2018. Deep contextualized word rep-
resentations. In Proc. Conf. North American Chap-
ter Assoc. for Computational Linguistics (NAACL),
pages 2227â€“2237.

Daniel PreotÌ§iuc-Pietro, Wei Xu, and Lyle Ungar. 2016.
Discovering user attribute stylistic differences via
paraphrasing. In Proceedings of the Thirtieth AAAI
Conference on Artificial Intelligence, pages 3030â€“
3037.

Ashwin Ram, Rohit Prasad, Chandra Khatri, Anu
Venkatesh, Raefer Gabriel, Qing Liu, Jeff Nunn,
Behnam Hedayatnia, Ming Cheng, Ashish Nagar,
Eric King, Kate Bland, Amanda Wartick, Yi Pan,
Han Song, Sk Jayadevan, Gene Hwang, and Art Pet-
tigrue. 2017. Conversational AI: The science behind
the alexa prize. In Proc. Alexa Prize 2017.

Abhilasha Ravichander and Alan Black. 2018. An em-
pirical study of self-disclosure in spoken dialogue
systems. In Proc. SIGdial Meeting Discourse and
Dialogue, pages 253â€“263.

Elaine Rich. 1979. User modeling via stereotypes.
Cognitive Science, 3:329â€“354.

John R. Searle. 1969. Speech Acts: An Essay in the
Philosophy of Language. Cambridge University
Press.

Milad Shokouhi. 2013. Learning to personalize query
auto-completion. In SIGIR, pages 103â€“112. ACM.

Derek Sleeman. 1985. UMFE: A user modelling front-
end subsystem. Int. J. Man-Machine Studies, 23:71â€“
88.

Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliza-
beth Shriberg, Rebecca Bates, Daniel Jurafsky, Paul
Taylor, Rachel Martin, Carol Van Ess-Dykema, and
Marie Meteer. 2000. Dialogue act modeling for au-
tomatic tagging and recognition of conversational
speech. Computational Linguistics, 26(3):339â€“373.

Quan Hung Tran, Gholamreza Haffari, and Ingrid Zuk-
erman. 2017a. A generative attentional neural net-
work model for dialogue act classification. In Proc.
Annu. Meeting Assoc. for Computational Linguistics
(ACL), pages 524â€“529.

Quan Hung Tran, Ingrid Zukerman, and Gholamreza
Haffari. 2017b. A hierarchical neural model for
learning sequences of dialogue acts. In Proc. Euro-
pean Chapter Assoc. for Computational Linguistics
(EACL), pages 428â€“437.

Quan Hung Tran, Ingrid Zukerman, and Gholam-
reza Haffari. 2017c. Preserving distributional in-
formation in dialogue act classification. In Proc.
Conf. Empirical Methods Natural Language Pro-
cess. (EMNLP), pages 2151â€“2156.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Åukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Proc. Annu. Conf. Neural Inform. Pro-
cess. Syst. (NIPS), pages 5998â€“6008.

Svitlana Volkova, Theresa Wilson, and David
Yarowsky. 2013. Exploring demographic language
variations to improve multilingual sentiment anal-
ysis in social media. In Proc. Conf. Empirical
Methods Natural Language Process. (EMNLP),
pages 1815â€“1827.

Ingrid Zukerman and Diane Litman. 2001. Natural lan-
guage processing and user modeling. User Model-
ing and User-Adapted Interaction, 11:129â€“158.

http://aclweb.org/anthology/D17-1119
http://aclweb.org/anthology/D17-1119
http://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors.pdf
http://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
http://aclweb.org/anthology/D15-1130
http://aclweb.org/anthology/D15-1130
http://aclweb.org/anthology/N18-1202
http://aclweb.org/anthology/N18-1202
https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12421/12057
https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12421/12057
https://s3.amazonaws.com/alexaprize/2017/technical-article/alexaprize.pdf
https://s3.amazonaws.com/alexaprize/2017/technical-article/alexaprize.pdf
http://aclweb.org/anthology/W18-5030
http://aclweb.org/anthology/W18-5030
http://aclweb.org/anthology/W18-5030
http://aclweb.org/anthology/J00-3003
http://aclweb.org/anthology/J00-3003
http://aclweb.org/anthology/J00-3003
http://aclweb.org/anthology/P17-2083
http://aclweb.org/anthology/P17-2083
http://aclweb.org/anthology/E17-1041
http://aclweb.org/anthology/E17-1041
http://aclweb.org/anthology/D17-1229
http://aclweb.org/anthology/D17-1229
http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf
http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf
http://aclweb.org/anthology/D13-1187
http://aclweb.org/anthology/D13-1187
http://aclweb.org/anthology/D13-1187


2783

A Examples for Mode Analysis

For each mode, we list top associated user utter-
ances in Table 6 and Table 7 for the user topic de-
cision corpus and SwDA corpus, respectively.

For modes learned in the user topic decision
corpus, mode 4 seems to include positive reac-
tions, while mode 2 involves slightly negative re-
actions. Modes 0 and 6 are mostly yes/no answers.
Utterances associated with mode 3 are mostly con-
versation ending. Modes 9, 14, and 10 are mostly
set topic commands, differing in style. Mode 10 is
associated with complete requests (e.g., â€œletâ€™s/can
we talk about cats),â€ while mode 9 and Mode
14 involve short topic phrases (e.g., â€œholidaysâ€).
Modes 8 and 11 capture talkative users, whereas
modes 1 and 7 capture relatively terse users.

For latent modes learned in the SwDA corpus,
there are several modes corresponding to coarse-
grained dialog acts, such as statements (modes 2,
4, 6, 16, 19), questions (modes 8, 9), agreement
(modes 12, 20), backchannel (modes 0, 28), and
conversation-closing (mode 13). Among the state-
ment modes, there are two distinct groups, one
(modes 4, 6, 16, 19) containing multiple filled
pauses, such as uh, you know, well, and the other
one (mode 2) with because-clauses. The fact that
coarse-grained dialog act information is partly en-
coded in the modes may be helping with recogniz-
ing the dialog act.

B Speaker Gender Analysis

We use the speaker gender information from the
SwDA data and analyze whether latent modes
unsupervisedly learned in the dynamic speaker
model could pick up some gender language vari-
ations. First, we gather the latent mode associa-
tion scores for each of the 32 modes for all utter-
ances as computed in (1). Then we carry out the
group mean tests for individual modes to test the
associate score distributions of male vs female ut-
terances. The Cohen-d score is used to measure
the strength of the difference (Cohen, 1988). We
also compute the p-value using the Mann-Whitney
U test. Previous work has observed larger gender
language differences when the two speakers have
the same gender (Boulis and Ostendorf, 2005).
Thus, we carry out the group mean tests on the
following three sets: 1) all conversations, 2) con-
versations involving only males or females, and 3)
conversations involving both genders. The Cohen-
d scores for overall, same-gender and cross-gender

(a) all conversations

(b) same-gender conversations

(c) cross-gender conversations

Figure 3: Cohen-d scores for gender group tests. The
x-axis is the mode index. The y-axis is the Cohen-d
score, with a larger magnitude suggesting a large effect
size, and a positive value for a more female-like mode.
The red dash lines indicate the Â±0.20 threshold.

conversations are shown in Fig. 3. For each set,
we identify the most female-like mode (with the
most positive Cohen-d score) and the most male-
like mode (with the most negative Cohen-d score).
For female-like modes, modes 15 and 17 are iden-
tified in this way, whereas modes 4 and 19 are
identified for male-like modes. By examining rep-
resentative patterns in modes 15 and 17, they are
mostly backchannel, acknowledgement, or agree-
ment. For modes 4 and 19, filled pauses are preva-
lent.



2784

Mode-0
â€¢ no no no no no no go back to my alexa . . .
â€¢ no no no no letâ€™s stop talking now goodbye . . .
â€¢ no letâ€™s chat letâ€™s chat about donald trump . . .

Mode-1
â€¢ gotcha
â€¢ hiya
â€¢ possibly

Mode-2
â€¢ serious
â€¢ are you serious
â€¢ that is a paradox

Mode-3
â€¢ alexa resume pandora
â€¢ alexa connect bluetooth
â€¢ no bye bye alexa

Mode-4
â€¢ that is fascinating
â€¢ whoa
â€¢ that thatâ€™s cool

Mode-5
â€¢ i did not thatâ€™s not surprising
â€¢ i did not i did not knew that
â€¢ unfortunately

Mode-6
â€¢ somewhat
â€¢ yes yes yes yes yes
â€¢ yes i did it was on the news

Mode-7
â€¢ mhm
â€¢ ok
â€¢ fascinating

Mode-8

â€¢ yes it was very much was i saw it i i was there i choose to the dark side did you choose that
via uh right . . .
â€¢ the online selanne jungle the mighty jungle the line the jungle in the jungle the mighty jungle
the mighty jungle . . .
â€¢ no if your life was narrated by someone and the choice was either
â€¢ i was curious if you â€™d rather have your life narrated by regis philbin or by morgan freeman
â€¢ did you know the answer rogers because like a better go bike and probably i just do nâ€™t know
it was just a long time ago
â€¢ i thought bill murray was very very funny

Mode-9
â€¢ meow
â€¢ award shows
â€¢ celebrity

Mode-10
â€¢ no letâ€™s talk about butterflies
â€¢ no letâ€™s talk about snakes
â€¢ can we talk about kardashians

Mode-11

â€¢ is king kong real or is he bake but is he awesome or . . .
â€¢ that is so true the concept of pencils are really stupid and should i even exist imagine if we
have pencil do we wanna be able to write on paper so that makes you stupid
â€¢ is this randomly talking to this is the dawning alligators okay so did we get bored i donâ€™t know
you somehow or . . .

Mode-12

â€¢ do you know alexa how do you how do you know all the stuff youâ€™re an a. i.
â€¢ what what alexa what how do you talk about
â€¢ alexa do you know alexa do you know a joke today
â€¢ alexa do you tell me what you know about the new vision nuclear plant

Mode-13
â€¢ ten million
â€¢ thirty percent
â€¢ whatâ€™s p. r.

Mode-14
â€¢ dog
â€¢ dogs
â€¢ tv

Mode-15 â€¢ nowâ€¢ not now

Table 6: User utterances in socialbot conversations that have top association scores for individual latent modes.



2785

Statements

Mode-2

â€¢ cause i know there â€™s one not too far from from me here in dallas
â€¢ because they really had no idea NONVERBAL what was involved once i got home
â€¢ because like i said i worked with a lot of those
â€¢ because he left home at five thirty in the morning
â€¢ and then she would like to turn in half of the parents that drop their kids off because
of the condition the kids are in you know

Mode-4

â€¢ uh some more in interest type topics in in other countries
â€¢ uh the uh the credit union has got a deal now where you decide what you want
â€¢ well it would be lower middle class housing here
â€¢ uh the only other thing i have noticed though is that uh it seems that there â€™s been a
lot of or more empha emphasis at least in what we â€™ve been dealing with

Mode-6

â€¢ and i know that uh you know it can be freezing cold in the wintertime and hot and uh
sticky in the summertime
â€¢ it â€™s uh it â€™s uh it â€™s uh plywood uh face i guess
â€¢ but i NONVERBAL i i i think you know the biggest causes even then a lot of times
are uh uh like when i was up in boston just all the cars you know just all over the place
â€¢ and so i i it â€™s i think i to me i think uh something that â€™s going to help our medical
uh arena is for um
â€¢ you know it â€™s like it â€™s like a luxury car except that it â€™s the dodge aries NONVER-
BAL you know

Mode-16

â€¢ but uh this last ski trip they took uh she had in contracted chicken pox first
â€¢ but uh we lived in malaysia for t i in nineteen uh eighty one two three and four
â€¢ well my uh my sister lives in houston
â€¢ i i was only twenty five years old or something
â€¢ it â€™s uh uh c n n has been a welcome addition to NONVERBAL the t v scene here in
the last uh number of years

Mode-19

â€¢ uh i traded off an eighty two oldsmobile for the eighty nine mazda
â€¢ because i mean after i figured out i was getting eighty cents an hour i said bag it
â€¢ uh we have a a mazda nine twenty nine and a ford crown victoria and a little two
seater c r x.
â€¢ and uh you know i i was amazed cause i â€™d pick up a local paper and i â€™d read about
all of these you know really interesting things going on
â€¢ well a friend of mine at work here said that he tried it with his dog

Backchannel

Mode-0 â€¢ yesâ€¢ yes NONVERBAL

Mode-15
â€¢ see
â€¢ probably
â€¢ like

Mode-17 â€¢ uhâ€¢ um

Mode-18
â€¢ oh oh yeah
â€¢ oh well
â€¢ oh okay

Mode-28
â€¢ uh huh NONVERBAL
â€¢ uh huh NONVERBAL NONVERBAL
â€¢ uh huh ery faint

Agreement

Mode-12 â€¢ exactly

Mode-20

â€¢ yep ause
â€¢ definitely
â€¢ absolutely
â€¢ i agree

Quesetion

Mode-8

â€¢ are you and your roommate a similar size
â€¢ did you do the diagnosis or was it just an assumption that that â€™s probably the part
that failed
â€¢ or do you have powered you know a
â€¢ NONVERBAL what kind of a car do you have now
â€¢ did they know that all along

Mode-9

â€¢ so what do you think about uh what do you think about what you see on t v about
them like in the news or on the ads
â€¢ what do you think about what do you think about the the lower grades you know k
through seven
â€¢ so uh what do you think about our involvement in the middle east
â€¢ you are talking about p o w s or missing in actions

Conversation-closing Mode-13
â€¢ bye
â€¢ bye bye
â€¢ appreciation talking to you

Table 7: Utterances for each mode in SwDA dataset.


