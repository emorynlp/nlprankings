










































Serious Game Environments for Language and Culture Education


Proceedings of the NAACL HLT 2010: Demonstration Session, pages 29–32,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

Serious Game Environments for Language and Culture Education 

Alicia Sagae, W. Lewis Johnson, and Rebecca Row 
Alelo, Inc. 

12910 Culver Boulevard, Suite J 

Los Angeles, CA 90066, USA 
{asagae, ljhonson, rrow}@alelo.com 

 

 

 

 

 
 

Abstract 

In this demonstration we will present technol-

ogies that enable learners to engage in spoken 

conversations in foreign languages, integrat-

ing intelligent tutoring and serious game ca-

pabilities into a package that helps learners 

quickly acquire communication skills.  Con-

versational AI technologies based on the 

SAIBA framework for dialog modeling are 

realized in this 3-D game environment.  Par-

ticipants will be introduced to tools for author-

ing dialogs in this framework, and will have 

an opportunity to experience learning with 

Alelo products, including the Operational 

Language and Culture Training System 

(OLCTS). 

1 Introduction 

Alelo's language and culture education environ-

ments, including The Tactical Language and Cul-

ture Training System (TLCTS) and the Operational 

Language and Culture Training System (OLCTS), 

are AI-enhanced learning platforms that help 

learners quickly acquire communication skills in 

foreign languages and cultures.  They have been 

developed by Alelo, Inc. based on a prototype de-

veloped at the University of Southern California 

(USC).   

These environments utilize an integrated combi-

nation of intelligent tutoring system and serious 

game technologies.  Trainees work through a series 

of interactive lessons and exercises, called the Skill 

Builder, focusing on mission-oriented communica-

tion skills.  The lessons make extensive use of au-

tomated speech recognition focused on learner 

language, and provide learners with feedback on 

their performance.  Cultural notes describing cus-

toms and nonverbal gestures are integrated into the 

Skill Builder lessons.  Trainees apply their skills in 

an interactive Arcade Game, where they use spo-

ken commands in the target language to navigate a 

town grid, and in a Mission Game, where they par-

ticipate in real-time dialog with simulated local 

people in order to accomplish their mission. 

2 Systems that Impact Learners  

Five TLCTS/OLCTS training courses have been 

developed so far: Tactical Iraqi
TM

, focusing on Ira-

qi Arabic, Tactical Pashto
TM

 and Tactical Dari
TM

 

focusing on the predominant dialects spoken in 

Afghanistan, Tactical French
TM

 for Sahel Africa, 

and Operational Indonesian
TM

.  TLCTS courses are 

complete training courses, providing all of the 

training materials needed to conduct basic training 

in foreign language and culture.  For example, Tac-

tical Iraqi
TM

 includes eighteen Mission Game 

scenes, ten Arcade Game levels, and sixty-three 

Skill Builder scenes comprising over 2000 lesson 

pages.  Additional scenes and lessons are under 

development.   

While the platform imposes no limit on content 

size, the material developed so far or these systems 

typically covers 80-120 hours of training.  In-game  

reference materials, including glossaries, summa-

ries of lesson content, and grammar notes, are 

29



available both as part of the training package and 

as is a support Web site.  Manuals, comprising tu-

torials and training guidelines, help with initial 

orientation, training management, and trouble-

shooting.  The OLCTS versions of these courses 

include supplementary exercises delivered on 

handheld devices and on the web, giving trainees a 

range of platforms for "train-anywhere" access. 

TLCTS rapidly transitioned into widespread use.  

Computer labs for training with TLCTS courses 

have been established in numerous locations in the 

USA and around the world.  An estimated twenty-

five thousand US military users have trained with 

the system, and consistently rate it highly.  It has 

also been made available to service members in 

allied military forces. 

Although the Tactical Language and Culture 

concept was originally developed under military 

funding, the approach can be applied quite general-

ly to language and culture learning.  The key is that 

the courses are task-oriented: the learner has a task 

to carry out, the Skill Builder helps the learner to 

acquire the skills necessary to carry out the task, 

and the Mission Game gives the learner an oppor-

tunity to practice the task in compelling simulated 

settings. 
 

 

3 Conversational Agent Technologies 

Simulated dialogs are executed by the virtual hu-

man architecture described in (Johnson & Valente, 

2008).  The architecture adopts a variant of the 

SAIBA framework (Vilhjalmsson & Marsella, 

2005), which separates intent planning (the choice 

of what to communicate) from production of be-

lievable behavior (how to realize the communica-

tion).  An overview of the social simulation 

process is given in Figure 1.   

3.1 Rule-Driven Behavior 

Virtual human behavior is generated by a series of 

components that include explicit models of speech 

and language (for natural language understanding 

and generation) as well as behavior-mapping rules 

that implicitly reflect the subject-matter expertise 

of the rule authors.  These rules generally occur at 

the level of communicative acts (Traum & Hin-

kelman, 1992).  A simple example of such a rule, 

expressed in natural language, is shown below: 
 

IF the learner says that your home is beautiful,  

THEN reply that it is quite plain 
(1) 

Utterance
Automated

Speech
Recognizer

Interpretation
Rules

Environmental
Context

Cultural
Context

Dialog 
Context

Intent Planning

Agent

Behavior 
Interpretation

Communicative 
Act <FML>

Behavior
Generation

Translation 
Rules

Behavior 
Specification

<BML>

Behavior
Realization

Communicative 
Act <FML>

Input Processing

Conversation
Cache

Personality Model

Language Model

Culture Model

World Model
(physical/social)

Agent Models 

Input
Processing

Social Simulation
Module

Game
Engine

Simulation 
Management

Agent
Agent

Social Simulation Manager (API)

PlayerPlayer

Player Speech 
+- Gesture

Figure 1.  Dialog simulation architecture in Alelo language and culture training systems 

30



 

3.2 Collaborative Authoring 

Rules like (1) are created by a content development 

team with expertise in linguistics and cultural anth-

ropology.  This work is supported by a set of web-

based collaborative authoring tools, called Kona 

and TIDE.  Kona is used to create lesson content 

for the Skill Builder, while TIDE is a graphical 

editor used to encode dialog rules as transitions in 

a Finite State Machine.   

Kona gives authors access to a database of les-

son content, specified in XML format.  The authors 

can selectively lock and edit lessons in the data-

base, and view and edit different fields in the spe-

cification of each page in the lesson.  The author 

can edit the written descriptions of the image on 

the page, the cultural notes, and the enabling learn-

ing objectives (ELOs) covered in the page.  In oth-

er views, authors can link in images and sound 

recordings, and make notes and comments for oth-

er authors to review.  The lesson specifications are 

then automatically translated into the internal data 

format used in OLCTS, so that authors can review 

the lessons as they appear in the training applica-

tion.  

4 The Demonstration 

The demonstration will give participants an oppor-

tunity to use OLCTS, and other Alelo interactive 

language and culture training products, and learn 

about their supporting authoring tools.  It is in-

tended for people who are interested in gaining an 

in-depth understanding of AIED (artificial intelli-

gence in education) technology for serious games, 

and the development tools used to create them.  

The demo will be conducted by a presenter, who 

will give live demonstrations of the software, and 

an assistant presenter who will coach the partici-

pants in the use of the game and supporting author-

ing tools. 

 

4.1 Overview 

First, the participants will get a hands-on intro-

duction to one of the Operational Language and 

Culture courses.  Under supervision of a presenter, 

 
Figure 2.  Screen shot of a Mission Game dialog in Operational Dari

TM
 

31



the participants will learn to say a few phrases in 

the Skill Builder and use the phrases that they have 

learned in the Mission Game.  This portion can be 

tailored on the fly to the interests of participants, 

and can take from 5 to 30 minutes to complete. 

Depending on time and interest, participants 

may also have an opportunity to work with an 

OLCTS course in more depth.  They can be called 

upon to learn some basic communication skills in 

Dari and apply them in the Mission Game.  This 

will give participants a firsthand understanding of 

how each component of OLCTS supports learning, 

how the components support each other, and how 

artificial intelligence technology is applied in the 

learning experience.   

Finally, the presenter will demo some of the au-

thoring tools used to create OLCTS content.  The 

participants will propose modifications or exten-

sions to an existing OLCTS course.  The presenter 

will use the authoring tools in real time to make the 

modifications, following the recommendations of 

the participants. 

4.2 Example: Engaging in a Dialog in Opera-

tional Dari
TM

 

For a video summary of the demonstration, please 

visit http://www.alelo.com/movie_tlt-6min.html. 

The user experience in the Mission Game is one 

engaging component of this demonstration.  An 

example script for a Mission Game interaction in 

Alelo's Operational Dari
TM

 course is given in the 

following sections. 

A sample of a Mission Game screen is shown in 

Figure 2.  The player controls the figure in the cen-

ter-left.  At this point in the demonstration, the 

player has received a briefing that describes a 

communication task that he or she should accom-

plish in this exercise.  To complete the task, the 

player must engage the virtual human, or non-

player character (NPC) shown on the right.   

Organizing rebuilding operations is one example 

of such a task.  The NPC is a host-national charac-

ter in Afghanistan.  The player should check on the 

status of their shared plan for rebuilding and give 

constructive feedback.  This type of communica-

tion task can require finesse and delicacy on the 

part of the player in order to be culturally appro-

priate.  It draws on the learner's understanding and 

skill with face-saving, a prominent feature of many 

cultures worldwide. 

The learner must initiate the conversation by 

speaking into a headset-mounted microphone.  He 

or she clicks on the microphone icon, shown in 

Figure 3, speaks, then clicks on the icon again to 

indicate the end of the turn. 

 

 

 
Figure 2.  Push the microphone button to speak during a 

dialog, push again to stop. 

 

Recognized player speech is posted to a dialog his-

tory window that appears near the top of the virtual 

scene, as shown in Figure 1.  The NPC responds 

using spoken output, creating a realistic and engag-

ing practice environment.  During the dialog, the 

player may view hints that display key phrases in 

Dari.  Once the player has discussed all of the host 

national's training mistakes, the dialog ends in suc-

cess. 

 

References  

H. Vilhjalmsson and S. Marsella. "Social Performance 

Framework", in Proceedings of the AAAI Workshop 
on Modular Construction of Human-Like Intelli-

gence. 2005. 

W. L. Johnson and A. Valente. “Tactical Language and 

Culture Training Systems: Using Artificial Intelli-

gence to Teach Foreign Languages and Cultures”, in 

Proceedings of IAAI 2008. March 2008. 

David R. Traum and Elizabeth A. Hinkelman. "Conver-

sation Acts in Task-Oriented Spoken Dialogue", in 

Computational Intelligence, 8(3):575--599, 1992. 

 

32


