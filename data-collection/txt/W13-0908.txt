










































Automatic Extraction of Linguistic Metaphors with LDA Topic Modeling


Proceedings of the First Workshop on Metaphor in NLP, pages 58–66,
Atlanta, Georgia, 13 June 2013. c©2013 Association for Computational Linguistics

Automatic Extraction of Linguistic Metaphor with LDA Topic Modeling 

Ilana Heintz*, Ryan Gabbard*, Mahesh Srinivasan+, *, David Barner+, Donald S. Black*, 

 Marjorie Freedman*, Ralph Weischedel*  

 

* Raytheon BBN Technologies 

10 Moulton St,  

Cambridge MA 02139 

 

{iheintz, rgabbard,  

mfreedman, dblack, 

rweischedel}@bbn.com 

+University of California, San Diego 

5336 McGill Hall,  

9500 Gilman Drive 
La Jolla, CA 92093-0109 

 
 barner@ucsd.edu,  

mahesh.srinivasan@gmail.com  

Abstract 

We aim to investigate cross-cultural patterns 

of thought through cross-linguistic investiga-

tion of the use of metaphor.  As a first step, 

we produce a system for locating instances of 

metaphor in English and Spanish text.  In con-

trast to previous work which relies on re-

sources like syntactic parsing and WordNet, 

our system is based on LDA topic modeling, 

enabling its application even to low-resource 

languages, and requires no labeled data.  We 

achieve an F-score of 59% for English. 

1 Introduction 

Patterns in the use of metaphors can provide a 

great deal of insight into a culture. Cultural differ-

ences expressed linguistically as metaphor can play 

a role in matters as complex and important as dip-

lomatic relations.  For instance, Thornborrow 

(1993) discusses the different metaphors that are 

used in the context of security in French and Brit-

ish coverage of two major post-cold-war summit 

meetings.  Example metaphors such as “the corner-

stone of the new security structure,” “structures for 

defence and security cooperation,” and “the emerg-

ing shape of Europe,” exemplify the English use of 

the source concept structure in describing the tar-

get concept of security.  In contrast, the metaphors 

“des règles de sécurité nouvelles (new rules of se-

curity)”, “une révision fondamentale des disposi-

tions de sécurité (a fundamental revision of 

security provisions)”, and “un système de sécurité 

européen (a system of European security)” exem-

plify the French use of the more abstract source 

concept system to describe the same target concept.  

As Thornborrow notes, the implied British concep-

tion of security as “concrete, fixed, and immobile” 

contrasts deeply with the French conception of se-

curity as “a system as a series of processes.” 

Our ultimate goal is to use metaphor to further 

our knowledge of how different cultures under-

stand complex topics.  Our immediate goal in this 

paper is to create an automated system to find in-

stances of metaphor in English and Spanish text. 

Most existing work on metaphor identification 

(Fass, 1991; Martin, 1994; Peters and Peters, 2000; 

Mason, 2004; Birke and Sarkar, 2006; Gegigan et 

al., 2006; Krishnakumaran and Zhu, 2007; Shutova 

et  al., 2010; Shutova et al., 2012)
1
 has relied 

on some or all of handwritten rules, syntactic pars-

ing, and semantic databases like WordNet (Fell-

baum, 1998) and FrameNet (Baker et al., 1998).  

This limits the approaches to languages with rich 

linguistic resources.  As our ultimate goal is broad, 

cross-linguistic application of our system, we can-

not rely on resources which would be unavailable 

in resource-poor languages.  Instead, we apply 

LDA topic modeling (Blei et al., 2003b) which 

requires only an adequate amount of raw text in the 

target language.  This work is similar to Bethard et 

al. (2009), in which an SVM model is trained with 

LDA-based features to recognize metaphorical 

text. There the work is framed as a classification 

task, and supervised methods are used to label 

metaphorical and literal text.  Here, the task is one 

of recognition, and we use heuristic-based, unsu-

                                                           
1 See Shutova (2010) for a survey of existing approaches 

58



pervised methods to identify the presence of meta-

phor in unlabeled text. We hope to eliminate the 

need for labeled data which, as discussed in 

Bethard et al. (2009) and elsewhere, is very diffi-

cult to produce for metaphor recognition. 

2 Terminology 

We will refer to a particular instance of metaphori-

cal language in text as a linguistic metaphor.  

Each such metaphor talks about a target concept 

in terms of a source concept.  For example, in 

“Dems, like rats, will attack when cornered” the 

source concept is animals and the target concept is 

politicians
2
, or at a higher level, governance.  The 

abstract mapping between a source concept and a 

target concept will be referred to as a conceptual 

metaphor which is grounded by a collection of 

linguistic metaphors. 

In this work, we restrict our attention to a single 

target concept, governance.  Our definition of gov-

ernance is broad, including views of the governed 

and those who govern, institutions of government, 

laws, and political discourse.  We used a large col-

lection (see Table 1) of potential source concepts.  

Beginning with the source concepts of primary 

metaphors, which are hypothesized to be univer-

sal (Grady, 1998), we expanded our set to include 

source concepts commonly found in the scientific 

literature about metaphor, as well as those found 

by human annotators manually collecting instances 

of governance-related metaphors. 
 

Animals Fishing Plants 

Baseball Flight Race 

Body Football Religion 

Botany Gambling Sick 

Boundary Grasp Size 

Chess Health Sound 

Color Height Sports 

Combustion Light Taste 

Cooking Liquid Temperature 

Courtship Machine Texture 

Cut Maritime Theater 

Directional force Money Time of day 

Dogs Motion Toxicity 

Drug use Mythology Vehicle 

Electricity Natural disasters War 

Energy source Nuclear Weaponry 

Entry Odor Weather 

                                                           
2 “Dems”' refers to the Democratic Party, an American politi-

cal party 

Family Pathways Weight 

Farming Physical structure Wild west 

Fight Planning  

Table 1: English Source Concepts 

3 High-level system overview 

 
Figure 1: System Overview 

 

Our main hypothesis is that metaphors are likely to 

be found in sentences that exhibit evidence of both 

a source and a target concept.  The core idea of our 

system is to use LDA topics as proxies for seman-

tic concepts which may serve as the source or tar-

get for a metaphor.  For a given language, we build 

an LDA model from Wikipedia and then align its 

topics to potential source and target concepts, 

which are defined by small human-created lists of 

seed words. 

At runtime, the system first does LDA infer-

ence on our input corpus to get topic probabilities 

for each document and sentence.  The system then 

selects those sentences linked by LDA to both a 

source-aligned topic and a target-aligned topic.
3
 

For example, a sentence containing “…virtud so-
                                                           
3 This is a distant, automatic relative of the ‘directed-search’ 

technique of Martin (1994). 

59



cial para construir la democracia…”
4
 will be se-

lected because LDA strongly associates it with 

both the topic [elecciones, ministro, sucesor, …]
5
, 

aligned to the target concept governance, and the 

topic [edificio, arquitectura, torre,…]
 6

, aligned to 

the source concept physical structure.  

Next, the system identifies the words in each 

selected sentence that are strongly associated with 

each concept. In the sentence above, it marks vir-

tud and democracia as target-associated and con-

struir as source-associated. 

Next it applies two filters. First, we exclude any 

sentence with too few words that are not LDA 

stopwords, because the model's predictions may be 

very inaccurate in these cases.  Second, if the topic 

associated with the source model for a sentence is 

also a top-ranked topic for the document as a 

whole, the sentence is excluded.  The reason for 

this is that if the source concept is present through-

out the document, it is probably being used literal-

ly (see Figure 2). 

Finally, it uses previously-computed infor-

mation to determine a final score.  All linguistic 

metaphors scoring above a certain threshold are 

returned.  By varying this threshold, the user can 

vary the precision-recall tradeoff as needed. A dia-

gram of the system can be found in Figure 1. 

 
Figure 2: Even though the last sentence is relevant to the 

source concept pathways and the target concept govern-

ance, it will be correctly rejected because pathways-

aligned topics are present throughout the document. 

4 Implementation Details: Training 

Our runtime system requires as input an LDA 

model, a list of seed words for each concept, and 

an alignment between concepts and LDA topics. 

4.1 LDA Topic Model 

The topics defined by LDA topic modeling serve 

as stand-ins for the more abstractly-defined source 

and target concepts underlying the metaphors.  The 

input to training our LDA model is the full text of 

                                                           
4 social virtue to build democracy 
5 elections, minister, successor 
6 building, architecture, tower 

Wikipedia articles in the target language.  Wikipe-

dia is available in numerous languages and serves 

as a corpus of general knowledge, providing us 

with topics corresponding to a broad range of con-

cepts.  Our LDA model is trained using MALLET 

(McCallum, 2002) for 1000 iterations with 100 

topics, optimizing hyperparameters every 10 itera-

tions after a 100 iteration burn-in period. The 500 

most common tokens in the training corpus were 

used as stopwords. The result of LDA is 100 top-

ics, where each topic is a probability distribution 

over the training corpus vocabulary.  Representa-

tive words for example English topics are shown in 

Figure 3. 

 
Figure 3: Sample LDA topics with representative terms 

4.2 Concept Seed Word Lists 

For each concept  , we have a label and a small set 
of seed words representing that concept, referred to 

as     .  These lists were created by hand in Eng-
lish and then translated into Spanish by native 

speakers. The translation was not intended to be 

exact; we instructed the annotators to create the 

lists in a way that was appropriate for their lan-

guage and culture.  For instance, the football topic 

for English describes American football, but in 

Spanish, the same topic describes soccer. 

4.3 Concept-Topic Alignment 

The final input to our system is an alignment be-

tween concepts and topics, with every topic being 

mapped to at most one concept.  In addition to the 

seed lists and LDA model, this alignment process 

takes a score threshold        and a maximum 

number of alignments per source and target con-

cept    and   .  
The alignment algorithm is as follows. We 

align each topic   to the concept   with the maxi-
mum score       , which measures the concept 
terms’ summed probability in the LDA topic: 

                       .  We remove all align-

ments where                . Finally, for each 

concept, only the   highest scoring alignments 
are kept, where   may be different for source and 

Our county has many roads in bad shape.  

Thousands of our bridges are structurally 

deficient.  Congress needs to pass a new 

highway bill. 

theater stage musical miss actreess 

theory philosophy pp study scientific 

knowledge 

nfl bowl yards coach players card yard 

governor republican senate election congress 

60



target. We refer to the aligned topics for a concept 

  as     . 
Label Seed List 

Words 

Aligned Topics 

Vehicle vehicle, 

wheels, gas, 

bus 

0.035: engine, car, 

model 

0.29: railway, 

trains, train 

0.022: energy, 

gas, linear 

Animals animal, beast, 

cattle 

0.066: animals, 

animal, species 

Courtship courtship, ro-

mance, court 

None 

Governance aristocrat, bi-

partisan, citi-

zen, duke 

0.25: Election, 

elected, parliament 

0.22: Governor, 

republican, Senate 

0.14: sir, lord,  

henry 

0.13: kingdom, 

emperor, empire 

0.12: rights, legal, 

laws 
Table 2: Sample concepts, manually-created seed lists, 

and aligned topics 

A last condition on the topic-concept alignment 

is the assignment of topics to trump concepts. Our 

only trump concept in this study is war. If an LDA 

topic is aligned with both the war concept and the 

governance concept, it is removed from alignment 

with the governance concept. We do this because 

war is so tightly associated with governments that 

the alignment algorithm invariably aligns it to the 

governance topic.  However, war is also a very 

important source concept for governance meta-

phors; our choice is to suffer on recall by missing 

some governance-relevant sentences, but increase 

recall on metaphors for which the source concept is 

war. Sample topic-concept alignments are shown 

inTable 2. By inspecting the resulting alignments 

by hand, we chose the following parameter values 

for both languages:       =0.01,   =3,   =5.   

The process of defining concepts is simple and 

fast and the alignment method is inexpensive.  

Therefore, while we have not captured all possible 

source concepts in our initial list, expanding this 

list is not difficult.  We can define new source con-

cepts iteratively as we analyze metaphors that our 

extraction system misses, and we can add target 

concepts as our interests broaden. 

5 Implementation Details: Runtime 

The system receives as input a corpus of docu-

ments, their LDA decodings, the LDA decodings 

of each sentence treated as a separate document, 

and the topic-concept alignments. Each four-tuple 

          is processed independently, where   is 
the language,   is the source concept,   is the tar-
get concept, and   is the sentence. 

 

Determining Concept Relevance: Recall our 

basic intuition that a sentence relevant both to an 

LDA topic in      (termed source-relevant) and 
one in      (termed target-relevant) is potentially 
metaphorical.  The system judges a sentence   to 
be  -relevant if the probability of  -aligned topics 
in that sentence is above a threshold:       
                        , where        is an ad-

justable parameter tuned by hand.         is 0.06 in 
English and 0.05 in Spanish.        is 0.1 in both 
languages. On the source side, the system removes 

all topics in      from        and renormalizes 
before determining relevance in order to avoid pe-

nalizing sentences for having very strong evidence 

of relevance to governance in addition to providing 

evidence of relevance to a source concept.  For 

reference below, let                    (a 
measure of how strongly the sentence is associated 

with its topics) and let 

                            (the most proba-

ble  -aligned topic in the sentence). 
If   is not both source- and target-relevant, the 

system stops and the sentence is not selected. 

 

Finding Concept-Associated Words: The system 

next creates sets    of the words in   associated 
with the concept  .  Let                   .  
Then let   

  {                   , where 
      is a hand tuned parameter set to 0.1 for both 
languages. That is, any word whose probability in 

the topic is higher than a theshold is included as a 

concept-associated word in that sentence.  Let 

               and vice-versa. Note that words 
which could potentially be associated with either 

concept are associated with neither.  For reference 

below, let                      (the most 
strongly concept-associated words in the sentence) 

61



and                    (the combined 
strength of those associations).  

If   lacks words strongly associated with the 
source and target concepts (that is,    or    is 
empty), the system stops and the sentence is not 

selected. 

Filters: The system applies two filters. First,   
must have at least four words which are not LDA 

stopwords; otherwise, the LDA predictions which 

drive the system's concept-relevance judgements 

tend to be unreliable.  Second, the most likely 

source topic       must not be one of the top 10 
topics for the document as a whole, for reasons 

described above.  If either of these requirements 

fail, the system stops and the sentence is not se-

lected. 

Final Scoring: Finally, the system determines 

if  

  (  (     )  (     )            )         

where        is a hand-tuned threshold set to -10.0 

for English and -13.0 for Spanish.  This takes into 

account the strength of association between topics 

and the sentence, between the annotated words and 

the topics, and between the topics and their aligned 

concepts.  Any sentence passing this threshold is 

selected as a linguistic metaphor. 

6 Example Output 

We provide examples of both true and false posi-

tives extracted by our system.  The annotations of 

source and target-associated words in each sen-

tence are those defined as    and    above.  The 
source concept animals is used for all examples. 

1. ModeratesT we all hear are an endangeredS 
speciesS, Sen. Richard 

2. DemsT like ratsS sometimes attack when cor-
nered 

3. ObamaT 's world historical political ambitions 
crossbredS with his 

4. At least DemocraticT representativesT are 
snakeheadS fish 

5. Another whopperS from Cleveland, GOPT 
lawyer backs him up 

6. Previous post: Illinois GOPT lawmakerT ar-
rested in animalS feed bag related incident 

7. Next post: National Enquirer catfighting 
Michelle ObamaT has clawsS out for that nice 

Ann Romney 

8. Sen. Lisa MurkowskiT R AK independent 
from Alaska - thank you silly Repubs, teaS 

party her out ha  

Examples 1 through 4 are correct metaphors ex-

tracted by our system.  In each, some words related 

to the target concept governance are described us-

ing terms related to the source concept animals.  

Example 1 best represents the desired output of our 

system, such that it contains a governance- and 

animals-relevant metaphor and the terms associat-

ed with the metaphor are properly annotated. Some 

issues do arise in these true positive examples. Ex-

ample 2, while often termed a simile, is counted as 

a metaphor for our purposes.  In example 3, the 

source term is correctly annotated, but the target 

terms should be political ambitions rather than  

Obama.  It is unclear why the term snakehead but 

not the term fish in example 4 is associated with 

the source concept.  

Examples 5 through 8 represent system errors.  

In example 5, the fact that the word whopper oc-

curs frequently to describe a large animal (espe-

cially a fish) causes the sentence to be mistakenly 

identified as relevant to the source concept animal.  

The source term animal in example 6 is clearly 

relevant to the source concept, but it is being used 

literally.  The document-level source concept fil-

tering does not entirely eliminate this error class.  

While example 7 contains a metaphor and has 

some relationship to American politics, it would be 

counted as an error in our evaluations because the 

metaphor itself is not related to governance. In ex-

ample 8, we have two errors. First, tea is strongly 

present in the topic aligned to the animal concept, 

causing the sentence to be incorrectly marked as 

source-relevant. Second, because our topic model 

operates at the level of individual words, it was 

unable to recognize that tea here is part of the 

fixed, governance-related phrase tea party.
 7
 

7 Evaluation 

7.1 Collecting Evaluation Data 

We collected a domain-specific corpus in each 

language.  We curated a set of news websites and 

governance-relevant blogs in English and Spanish 

and then collected data from these websites over 

the course of several months. For each language, 

we ran our system over this corpus (all steps in 

                                                           
7 an American political movement 

62



Section 5), produced a set of linguistic metaphors 

for each topic-aligned source concept (the target 

concept was always governance), and ranked them 

by the final score (Section 4.4). Below, we will 

refer to the set of all linguistic metaphors sharing 

the same source and target concept as a conceptual 

metaphor. 

7.2 Simple Evaluation 

For this evaluation, we selected the top five exam-

ples for each conceptual metaphor.  If the same 

sentence was selected by multiple conceptual met-

aphors, it was kept for only the highest scoring 

one.  We then added enough of the highest-ranked 

unselected metaphors to create a full set of 300. 

We then added random sentences from the corpus 

that were not selected as metaphorical by the sys-

tem to bring the total to 600.  Our Spanish annota-

tors were unavailable at the time this evaluation 

took place, so we are only able to report results for 

English in this case. 

For each of these instances, two annotators 

were asked the question, “Is there a metaphor 

about governance in this example?” These annota-

tors had previous experience in identifying meta-

phors for this study, both by searching manually in 

online texts and evaluating previous versions of 

our system.  Over time we have given them feed-

back on what does and does not constitute a meta-

phor.  In this case, the annotators were given 

neither the system's concept-word association an-

notations nor the source concept associated with 

the instance.  In one way, the evaluation was gen-

erous, because any metaphor in the extracted sen-

tence would benefit precision even if it was not the 

metaphor found by our system. On the other hand, 

the same is true for the random sentences; while 

the system will only extract metaphors with source 

concepts in our list, the annotators had no such 

restriction. This causes the recall score to suffer.  

The annotation task was difficult, with a  -score of 
0.48.  The resulting scores are given in Table 3.   

The examples given in Section 5 illustrate the error 

classes found among the false positives identified 

by the human annotators. There are many cases 

where the source-concept associated terms are used 

literally rather than metaphorically, and many cas-

es where the system-found metaphor is not about 

governance.  Some text processing issues, such as 

a bug in our sentence breaking script, as well as the 

noisy nature of blog and blog comment input, 

caused some of the examples to be difficult to in-

terpret or evaluate.  

 

Annotator Precision ‘Recall’ F Kappa 

1 

2 

65 

43 

67 

60 

66 

50 
0.48 

Mean 54 64 59  
Table 3: Simple English Evaluation 

7.3 Stricter Evaluation 

Common Experimental Setup 

We did a second evaluation of both English and 

Spanish using a different paradigm.  For each lan-

guage, we selected the 250 highest-ranked linguis-

tic metaphor instances in the corpus.  Subjects on 

Amazon Mechanical Turk were shown instances 

with the system-predicted concept-associated 

words highlighted and asked if the highlighted 

words were being used metaphorically (options 

were yes and no).  Each subject was randomly 

asked about roughly a quarter of the data. 

 

We paid the subjects $10 per hour.  We added 

catch trial sentences which asked the subject to 

simply answer yes or no as a way of excluding 

those not actually reading the sentences.  Subjects 

answering these questions incorrectly were exclud-

ed (17 in English, 25 in Spanish).  

We defined the metaphoricity of an instance to 

be the fraction of subjects who answered yes for 

that instance. We define the metaphoricity of a 

conceptual metaphor as the average metaphoricity 

of its groundings among the instances in this eval-

uation set.  

 

  

63



English Results 

We restricted our subjects to those claiming to 

be native English speakers who had IP addresses 

within the U.S. and had 115 participants.  The ex-

amples were grouped into 66 conceptual meta-

phors. The mean metaphoricity of instances was 

0.41 (standard deviation=0.33).  The mean meta-

phoricity of the conceptual metaphors (Figure 4), 

was 0.39 (SD=0.26).  Although there was wide 

variance in metaphoricity across conceptual meta-

phors, it appears likely that most of the conceptual 

metaphors discovered by the system are correct: 

65% of the conceptual metaphors had metaphorici-

ty greater than 0.25, and 73% greater than 0.2. 

Given that many metaphors are conventional and 

difficult to detect in natural language (Lakoff and 

Johnson, 1980), it is possible that even in cases in 

which only a minority of subjects detected a meta-

phor, a metaphor nonetheless exists 

Spanish Results 

We restricted our subjects to those claiming to be 

native speakers of Mexican Spanish with IP ad-

dresses in the US (57) or Mexico (29).  The in-

stances were grouped into 52 conceptual meta-

phors.  The mean metaphoricity of instances was 

0.33 (SD=0.23) and for conceptual metaphors 

(Figure 4), 0.31 (SD=0.16). 60% of conceptual 

metaphors had metaphoricity greater than 0.25, and 

73% greater than 0.2.  That performance was only 

slightly lower than English is a positive indication 

of our method’s cross-linguistic potential. 

8 Discussion and Future Work 

We observed a number of problems with our ap-

proach which provide avenues for future research. 

8.1 Topics as Proxies of Primary Metaphor 
Concepts 

Many of the metaphors missed by our system were 

instances of primary metaphor, especially those 

involving movement and spatial position.  Our 

LDA approach is poorly suited to these because the 

source concepts are not well-characterized by word 

co-occurrence: words describing movement and 

spatial position do not have a strong tendency to 

co-occur with other such words, at least in Wik-

ipedia.  Augmenting our system with a separate 

 

 
 

 
Figure 4: Metaphoricity of Conceptual Metaphors for English (top) and Spanish (bottom) 

64



approach to primary metaphor would boost its per-

formance significantly. 

8.2 Topics as Proxies of Non-Primary Meta-
phor Concepts 

We found that most of our potential source con-

cepts did not correspond to any LDA topic. How-

ever, many of these, such as wild west, have fairly 

strong word co-occurrence patterns, so they plau-

sibly could be found by a different topic modeling 

algorithm.  There are two promising approaches 

here which could potentially be combined.  The 

first is to use a hierarchical LDA algorithm (Blei et 

al, 2003b) to allow concepts to align to topics with 

varying degrees of granularity, from the very gen-

eral (e.g. war) to the very specific (e.g. wild west).  

The second is to use constrained LDA approaches 

(Andrzejewski and Zhu, 2009; Hu et al., 2010) to 

attempt to force at least one topic to correspond to 

each of our seed concept lists.   

A different approach would leave behind seed 

lists entirely.  In our current approach, only about 

one third of the topics modeled by LDA are suc-

cessfully aligned with a source concept from our 

hand-made list.  However, some non-aligned LDA 

topics have properties similar to those that were 

chosen to represent source concepts.  For instance, 

the topic whose highest ranked terms are [institute, 

professor, engineering, degree] is comprised of a 

set of semantically coherent and concrete terms, 

and could be assigned a reasonably accurate label 

such as higher education.  If we were to choose 

LDA topics based on the terms’ coherence and 

concreteness (and perhaps other relevant, measura-

ble properties), then assign a label using a method 

such as that in Mei et al. (2007), we would be able 

to leverage more of the concepts in the LDA mod-

el. This would increase the recall of our system, 

and also reduce some of the confusion associated 

with incorrect labeling of concepts in linguistic and 

conceptual metaphors.  Applying Labeled LDA, as 

in Ramage et al. (2009), would be a similar ap-

proach. 

8.3 Confusion of Literal and Metaphorical 
Usage of Source Concepts 

Another major problem was the confusion between 

literal and metaphorical usage of source terms.  

This is partly addressed by our document topics 

filter, but more sophisticated use of document con-

text for this purpose would be helpful.  A similar 

filter based on contexts across the test corpus 

might be useful. 

8.4 Fixed Expressions 

Some of our errors were due to frequent fixed 

phrases which included a word strongly associated 

with a source topic, like Tea Party.  Minimum de-

scription length (MDL) phrase-finding or similar 

techniques could be used to filter these out.  Initial 

experiments performed after the evaluations dis-

cussed above show promise in this regard. Using 

the MDL algorithm (Rissanen, 1978), we devel-

oped a list of likely multi-word expressions in the 

Wikipedia corpus.  We then concatenated these 

phrases in the Wikipedia corpus before LDA mod-

eling and in the test corpus before metaphor pre-

diction.  Though we did not have time to formally 

evaluate the results, a subjective analysis showed 

fewer of these fixed phrases appearing as indica-

tors of metaphor (as words in    or   ). 

8.5 Difficulty of Annotation 

A different method of presentation of metaphors to 

the subjects, for instance with annotations marking 

where in the sentence we believed metaphor to 

exist or with a suggestion of the source concept, 

may have improved agreement and perhaps the 

system’s evaluation score. 

8.6 Summary 

We have presented a technique for linguistic and 

conceptual metaphor discovery that is cross-

linguistically applicable and requires minimal lin-

guistic resources.  Our approach of looking for 

overlapping semantic concepts allows us to find 

metaphors of any syntactic structure.  The frame-

work of our metaphor discovery technique is flexi-

ble in its ability to incorporate a wide variety of 

source and target concepts. The only linguistic re-

sources the system requires are a corpus of gen-

eral-knowledge text adequate for topic modeling 

and a small set of seed word lists. We could im-

prove our system by applying new research in au-

tomatic topic modeling, by creating new filters and 

scoring mechanisms to discriminate between literal 

and figurative word usages, and by creating train-

ing data to allow us to automatically set certain 

system parameters.   

 

65



Acknowledgements 
Supported by the Intelligence Advanced Research Pro-

jects Activity (IARPA) via Department of Defense US 

Army Research Laboratory contract number W911NF-

12-C0-0023. The U.S. Government is authorized to 

reproduce and distribute reprints for Governmental pur-

poses notwithstanding any copyright annotation there-

on.  Disclaimer: The views and conclusions contained 

herein are those of the authors and should not be inter-

preted as necessarily representing the official policies or 

endorsements, either expressed or implied, of IARPA, 

DoD/ARL, or the U.S. Government.” 

References 
David Andrzejewski and Xiaojin Zhu. 2009. Latent Di-

richlet Allocation with Topic-in-Set Knowledge. In 

Proceedings of NAACL Workshop on Semi-

Supervised Learning for NLP. 

Collin Baker, Charles Fillmore, and John Lowe. 1998. 

The Berkeley FrameNet project. In Proceedings of 

COLING-ACL. 

Stephen Bethard, Vicky Tzuyin Lai and James H. Mar-

tin.  2009. Topic Model Analysis of Metaphor Fre-

quency for Psycholinguistic Stimuli.  .  In Proc. Of 

NAACL-HLT Workshop on Computational Ap-

proaches to Linguistic Creativity. 

Julia Birke and Anoop Sarkar. 2006. A Clustering Ap-

proach for the Nearly Unsupervised Recognition of 

Nonliteral Language. In Proceedings of EACL. 

David Blei, Thomas Griffiths, Michael Jordan, and 

Joshua Tenenbaum. 2003a. Hierarchical topic models 

and the nested Chinese restaurant process. In Pro-

ceedings of NIPS. 

David Blei, Andrew Ng, and Michael Jordan. 2003b. 

Latent Dirichlet Allocation. Journal of Machine 

Learning Research, 2003(3):993–1022. 

Dan Fass. 1991. met*: A Method for Discriminating 

Metonymy and Metaphor by Computer. Computa-

tional Linguistics, 17(1):49–90. 

Christine Fellbaum. 1998. WordNet: An Electronic Lex-

ical Database. MIT Press, Cambridge, MA. 

Matt Gegigan, John Bryant, Srini Narayanan, and 

Branimir Ciric. 2006. Catching Metaphors. In Pro-

ceedings of the 3rd Workshop on Scalable Natural 

Language Understanding. 

Joseph E. Grady. 1998. Foundations of meaning: Prima-

ry metaphors and primary scenes. UMI. 

Yuenin Hu, Jordan Boyd-Graber, and Brianna Satinoff. 

2010. Interactive Topic Modeling. In Proceedings of 

ACL. 

Saisuresh Krishnakumaran and Xiaojin Zhu. 2007. 

Hunting Elusive Metaphors Using Lexical Re-

sources. In Proceedings of the Workshop on Compu-

tational Approaches to Figurative Language. 

George Lakoff and Mark Johnson. 1980. Metaphors We 

Live By. University of Chicago. 

James H. Martin. 1994. MetaBank: A knowledge-base 

of metaphoric language convention. Computational 

Intelligence, 10(2):134–149. 

Zachary Mason. 2004. CorMet: A Computational, Cor-

pus-Based Conventional Metaphor Extraction Sys-

tem. Computational Linguistics, 30(1):23–44. 

Andrew Kachites McCallum. 2002. MALLET: A Ma-

chine Learning for Language Toolkit. 

http://mallet.cs.umass.edu. 

Qiaozhu Mei, Xuehua Shen, and Chengxiang Zhai.  

Automatic Labeling of Multinomial Topic Models.  

In Proceedings of KDD ’07.  2007. 

Wim Peters and Ivonne Peters. 2000. Lexicalised Sys-

tematic Polysemy in WordNet. In Proceedings of 

LREC. 

Daniel Ramage, David Hall, Ramesh Nallapati and 

Christopher D. Manning. 2009. Labeled LDA: A su-

pervised topic model for credit attribution in multi-

labeled corpora.  In Proceedings of EMNLP. 

Jorma Rissanen.  Modeling by shortest data description. 

Automatica 14:465-471. 

Ekaterina Shutova, Lin Sun, and Anna Korhonen. 2010. 

Metaphor Identification Using Noun and Verb Clus-

tering. In Proceedings of COLING. 

Ekaterina Shutova, Simone Teufel, and Anna Korhonen. 

2012. Statistical Metaphor Processing. Computation-

al Linguistics. Uncorrected proof. 

Ekaterina Shutova. 2010. Models of metaphor in NLP. 

In Proceedings of ACL. 

Joanna Thornborrow. 1993. Metaphors of security: a 

comparison of representation in defence discourse in 

post-cold-war France and Britain. Discource & Soci-

ety, 4(1):99–119 

 

 

66


