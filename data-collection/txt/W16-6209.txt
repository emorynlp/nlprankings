



















































Learning Latent Local Conversation Modes for Predicting Comment Endorsement in Online Discussions


Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media, pages 55–64,
Austin, TX, November 1, 2016. c©2016 Association for Computational Linguistics

Learning Latent Local Conversation Modes for Predicting Community
Endorsement in Online Discussions

Hao Fang Hao Cheng Mari Ostendorf
University of Washington

{hfang,chenghao,ostendorf}@uw.edu

Abstract

Many social media platforms offer a mecha-
nism for readers to react to comments, both
positively and negatively, which in aggregate
can be thought of as community endorsement.
This paper addresses the problem of predict-
ing community endorsement in online discus-
sions, leveraging both the participant response
structure and the text of the comment. The
different types of features are integrated in a
neural network that uses a novel architecture
to learn latent modes of discussion structure
that perform as well as deep neural networks
but are more interpretable. In addition, the la-
tent modes can be used to weight text features
thereby improving prediction accuracy.

1 Introduction

Online discussion forums provide a platform for
people with shared interests (online communities) to
discuss current events and common concerns. Many
forums provide a mechanism for readers to indicate
positive/negative reactions to comments in the dis-
cussion, with up/down votes, “liking,” or indicating
whether a comment is useful. The cumulative re-
action, which we will refer to as “community en-
dorsement,” can be useful to readers for prioritizing
what they read or in gathering information for deci-
sion making. This paper introduces the task of au-
tomatically predicting the level of endorsement of
a comment based on the response structure of the
discussion and the text of the comment. To address
this task, we introduce a neural network architecture
that learns latent discussion structure (or, conversa-
tion) modes and adjusts the relative dependence on

text vs. structural cues in classification. The neural
network framework is also useful for combining text
with the disparate features that characterize the sub-
mission context of a comment, i.e. relative timing in
the discussion, response structure (characterized by
graph features), and author indexing.

The idea of conversation modes stems from the
observation that regions of a discussion can be quali-
tatively different: low vs. high activity, many partici-
pants vs. a few, etc. Points of high activity in the dis-
cussion (comments that elicit many responses) tend
to have higher community endorsement, but some
points of high activity are due to controversy. We
hypothesize that these cases can be distinguished by
the submission context, which we characterize with
a vector of graph and timing features extracted from
the local subgraph of a comment. The context vec-
tors are modeled as a weighted combination of latent
basis vectors corresponding to the different modes,
where bases are learned using the weak supervision
signal of community endorsement. We further hy-
pothesize that the nature of the submission context
impacts the relative importance of the actual text in
a comment; hence, a mode-dependent gating mecha-
nism is introduced to weight the contribution of text
features in estimating community endorsement.

The model is assessed in experiments on Red-
dit discussion forum data, using karma (the differ-
ence in numbers of up and down votes) as a proxy
for community endorsement, showing benefits from
both the latent modes and the gating. As described
further below, the prediction task differs somewhat
from prior work on popularity prediction in two re-
spects. First, the data is not constrained to control

55



for either submission context or comment/post con-
tent, but rather the goal is to learn different context
modes that impact the importance of the message.
Second, the use of the full discussion thread vs. a
limited time window puts a focus on participant in-
teraction in understanding community endorsement.

2 Related Work

The cumulative response of readers to social me-
dia and online content has been studied using a
variety of measurements, including: the volume
of comments in response to blog posts (Yano and
Smith, 2010) and news articles (Tasgkias et al.,
2009; Tatar et al., 2011), the number of Twitter
shares of news articles (Bandari et al., 2012), the
number of reshares on Facebook (Cheng et al., 2014)
and retweets on Twitter (Suh et al., 2010; Hong et
al., 2011; Tan et al., 2014; Zhao et al., 2015), and
the difference in the number of reader up and down
votes on posts and comments in Reddit discussion
forums (Lakkaraju et al., 2013; Jaech et al., 2015).
An advantage of working with the Reddit data is that
both positive and negative reactions are accounted
for, so the total (karma in Reddit) is a reasonable
proxy for community endorsement.

For all the different types of measures, a challenge
in predicting the cumulative reaction is that the cases
of most interest are at the tails of a Zipfian distribu-
tion. Various prediction tasks have been proposed
with this in mind, including regression on a log score
(Bandari et al., 2012), classification into 3-4 groups
(e.g. none, low, high) (Tasgkias et al., 2009; Hong et
al., 2011; Yano and Smith, 2010), a binary decision
as to whether the score will double given a current
score (Lakkaraju et al., 2013), and relative ranking
of comments (Tan et al., 2014; Jaech et al., 2015).
In our work, we take the approach of classification,
but use a finer grain quantization with bins automat-
ically determined by the score distribution.

The work on cumulative reaction has mostly con-
sidered two different scenarios: predicting responses
before a comment/document has been published vs.
after a limited lookahead time for extracting fea-
tures based on the initial response. While the frame-
work proposed here could handle either scenario,
the experiments reported allow the classifier to use
a longer future window, until most of the discussion

has played out. This provides insight into the dif-
ficulty of the task and illustrates that volume of re-
sponses alone does not reliably predict endorsement.

A few studies investigate language factors that
may impact popularity through carefully controlled
experiments. To tease apart the factor of content
quality, Lakkaraju et al. (2013) predict resharing
of duplicated image submissions, investigating both
the submission context (community, time of day,
resubmission statistics) and language factors. Our
work differs in that content is not controlled and the
submission context includes the response structure
and relative timing of the comment within the dis-
cussion. Tan et al. (2014) futher control the author
and temporal factors in addition to the topic of the
content, by ranking pairs of tweets with almost iden-
tical content made by the same author within a lim-
ited time window. Jaech et al. (2015) control the
temporal factor for ranking Reddit comments made
in a time-limited window and study different lan-
guage factors. Here, rather than manually control-
ling the submission context, we propose a model to
discover latent modes of submission context (rela-
tive timing, response structure) and analyze its util-
ity in predicting community endorsement. Further-
more, we study how the usefulness of language in-
formation in estimating the community endorsement
varies depending on submission context.

3 Data and Task

Data: Reddit (https://www.reddit.com)
is a discussion forum with thousands of sub-
communities organized as subreddits. Users can
initiate a tree-structured discussion thread by mak-
ing a post in a subreddit. Comments are made either
directly to the root post or to other comments within
the thread, sometimes triggering sub-discussions.
Each comment can receive upvotes and downvotes
from registered users; the difference is shown as
the karma score beside the comment. The graph
structure of a Reddit disccussion thread is shown in
Fig. 1.1In this paper, three popular subreddits are
studied: AskMen (1,057K comments), AskWomen
(814K comments), and Politics (2,180K
comments).

1Visualization obtained from https://whichlight.
github.io/reddit-network-vis.

56



Figure 1: Visualization of a Reddit discussion thread. The or-
ange node represents the root post; other nodes are comments

(size proportional to karma), which are in black unless the user

comments more than once in the thread.

Task: In many discussion forums, including the
those explored here, community endorsement (i.e.,
karma in Reddit) has a heavy-tailed Zipfian distribu-
tion, with most comments getting minimal endorse-
ment and high endorsement comments being rare.
Since the high endorsement comments are of most
interest, we do not want to treat this as a regression
problem using a mean squared error (MSE) objec-
tive.2 Instead, we quantize the karma into J + 1
discrete levels and design a task consisting of J bi-
nary classification subtasks which individually pre-
dict whether a comment has karma of at least level-j
for each level j = 1, . . . , J given the text of the com-
ment and the structure of the full discussion thread.
(All samples have karma at least level-0.)

Karma scores are quantized into 8 levels of com-
munity endorsement according to statistics com-
puted over a large collection of comments in the
subreddit. The quantization process is similar to
the head-tail break rule described in (Jiang, 2013).
First, comments with karma no more than 1 are la-
beled as level-0, indicating that these comments re-
ceive no more upvotes than downvotes.3 Then, we
compute the median karma score for the rest of the
comments, and label those with below-than-median
karma as level-1. This process is repeated through
level-6, and the remaining comments are labeled as

2A prediction error of 50 is minimal for a comment with
karma of 500 but substantial for a comment with karma of 1,
and the low karma comments dominate the overall MSE.

3The inital karma score of a comment is 1.

12

13

14

15

16

17

18

19

20

21

AskMen AskWomen Politics

Lo
g 2

(n
u

m
b

er
 o

f 
sa

m
p

le
s)

level-0 level-1 level-2 level-3 level-4 level-5 level-6 level-7

Figure 2: The data distribution for each subreddit.

level-7. The resulting data distributions are shown
in Fig. 2. Note that the quantization is subreddit de-
pendent, since the distribution and range of karma
tends to vary for different subreddits.

Evaluation metric: Since we use a quantization
scheme following a binary thresholding process, we
can compute the F1 score for each level-j subtask
(j = 1, 2, . . . , 7) by treating comments whose pre-
dicted level is lower than j as negative samples and
others as positive samples. To evaluate the overall
prediction performance, the seven F1 scores are ag-
gregated via a macro average, which effectively puts
a higher weight on the higher endorsement levels.

4 Model Description

The proposed model utilizes two kinds of infor-
mation for a comment to predict its quantized
karma: (1) the submission context encoded by a set
of graph and timing statistics, and (2) the textual
content of the comment itself. Both sources of infor-
mation are first embedded in a continuous space by a
neural network as illustrated in Fig. 3, where c ∈ RC
and d ∈ RD encode the submission context and the
textual content, respectively. As described further
below, the two vectors are transformed for use in
the final decision function to c̃, a linear combination
of latent basis vectors, and d̃, a context-dependent
weighted version of the text features.

Submission context modes: Reddit discussions
have a variety of conversation structures, includ-
ing sections involving many contributors or just a
few. Based on observations that high karma com-

57



Figure 3: Proposed model: Gray circles c and d are the pro-
jected submission context features and the encoded textual con-

tent vector, respectively. Blue boxes b1, · · · ,bK are latent ba-
sis vectors, which are learned by the neural network. Purple

diamonds a1, · · · ,aK and g represent scalers, i.e., the basis
coefficients and context-dependent gate value. Red circles c̃

and d̃ are the context embedding (i.e., a linear combination of

latent basis vectors) and the weighted text embedding, respec-

tively. The yellow circle y is the output layer. Black arrows are

connections carrying weight matrices. ⊗ and ⊕ indicate multi-
plication and element-wise addition, respectively.

ments seem to co-occur with active points of dis-
cussions, we identify a set of features to represent
the submission context of a comment, specifically
aiming to characterize relative timing of the com-
ment within the discussion, participant response to
the comment, and whether the comment author is
the original poster (see Table 1 for the full list). The
features are normalized to zero mean and unit vari-
ance based on the training set.

In this paper, instead of controlling for the sub-
mission context, we let the model learn latent modes
of submission context and examine how the learned
context modes relate to different levels of commu-
nity endorsement. The proposed model learns K la-
tent basis vectors b1, · · · ,bK ∈ RC for characteriz-
ing the submission context of a particular comment
in the discussion. Given the raw submission context
feature vector x ∈ RN , the model computes a vector
c ∈ RC as c = LReL(Px), where P ∈ RC×N is
a projection matrix, and LReL(·) is the leaky recti-
fied linear function (Mass et al., 2013) with 0.1 as
the slope of the negative part. Coefficients for these

Range Description

0/1 Whether the comment author is the user whoinitiated the thread.

Z≥0

Number of replies to the comment.
Number of comments in the subtree rooted
from the comment.
Height of the subtree rooted from the com-
ment.
Depth of the comment in the tree rooted from
the original post.

R≥0

Relative comment time (in hours) with re-
spect to the original post.
Relative comment time (in hours) with re-
spect to the parent comment.

Table 1: Features for representing the conversation structure.

K latent bases are then estimated as

ak = softmax(vT tanh(U [c; bk])),

where v ∈ RC and U ∈ RC×2C are parameters to
be learned. The final submission context embedding
is obtained as c̃ =

∑K
k=1 ak · bk ∈ RC .

The computation of basis coefficients is similar
to the attention mechanism that has been used in
the context of machine translation (Bahdanau et al.,
2015), constituency parsing (Vinyals et al., 2015),
question answering and language modeling (Weston
et al., 2015; Sukhbaatar et al., 2015). To the best
of our knowledge, this is the first attempt to use the
attention mechanism for latent basis learning.

Text embeddings: Recurrent neural networks
(RNNs) have been widely used to obtain sequence
embeddings for different applications in recent
years (Sutskever et al., 2014; Cheng et al., 2015;
Palangi et al., 2016). In this paper, we use a bi-
directional RNN to encode each sentence, and con-
catenate the hidden layers at the last time step of
each direction as the sentence embedding. For com-
ments with multiple sentences, we average the sen-
tence embeddings into a single vector as the textual
content embedding d ∈ RD.

For the t-th token in a sentence, the hidden layers
of the bi-directional RNN are computed as

h(l)t = GRU(zt,h
(l)
t−1), h

(r)
t = GRU(zt,h

(r)
t+1),

where zt ∈ RD is the token input vector, h(l)t ∈ RD
and h(r)t ∈ RD are the hidden layers for the left-
to-right and right-to-left directions, respectively, and

58



GRU(·, ·) denotes the gated recurrent unit (GRU),
which is proposed by Cho et al. (2014) as a sim-
pler alternative to the long short-term memory unit
(Hochreiter and Schmidhuber, 1997) for addressing
the vanishing gradient issue in RNNs. For consis-
tency of the model and consideration of computation
speed, we replace the hyperbolic tangent function
in the GRU with the LReL function. Although not
shown in Fig. 3, weight matrices in the bi-directional
RNN are jointly learned with all other parameters.

To generate the token input vector to the RNN,
we utilize the lemma and part-of-speech (POS) tag
of each token (obtained with the Stanford CoreNLP
toolkit (Manning et al., 2014)), in addition to its
word form. A token embedding zt ∈ RD for the
t-th token in a sentence is computed as

zt = Ewordewordt + E
posepost + E

lemmaelemmat ,

where et’s are one-hot encoding vectors for the to-
ken, and E’s are parameters to be learned. The di-
mensions of these one-hot encoding vectors are de-
termined by the size of the corresponding vocabu-
laries, which include all observed types except sin-
gletons. Thus, these embedding matrices E’s have
the same first dimension D but different second di-
mensions. This type of additive token embedding
has been used in (Botha and Blunsom, 2014; Fang
et al., 2015) to integrate various types of informa-
tion about the token. Moreover, it reduces the tuning
space since we only need to make a single decision
on the dimensionality of the token embedding.

Gating mechanism: For estimating comment
karma levels, the textual content should provide ad-
ditional information beyond the submission context.
However, we hypothesize that the usefulness of tex-
tual content may vary under different submission
contexts since structure reflects size of the reader-
ship. Therefore, we design a context-dependent gat-
ing mechanism in the proposed model to weight the
textual factors. A scalar gate value is estimated
from the submission context embedding c̃, i.e., g =
sigmoid(wT c̃), where w ∈ RC is the parameter to
be learned. The textual content embedding d ∈ RD
is scaled by the gate value g before being fed to the
output layer, i.e., d̃ = g · d.
Decision function: The estimated probability dis-
tribution y = [y0, . . . , y7] over all quantized karma

levels is computed by the softmax output layer, i.e.,
y = softmax(Q

[
c̃; d̃

]
), where Q ∈ RJ×(C+D) is

the weight matrix to be learned. The hypothesized
level for a comment is L̂ = argmaxjyj . For each
level-j subtask, both the label L and the hypothe-
sis L̂ are converted to binary values by checking the
condition whether they are no less than j.

5 Parameter Learning

To train the proposed model, each comment is
treated as an independent sample, and the objec-
tive is the maximum log-likelihood of these samples.
We use mini-batch stochastic gradient descent with
a batch size of 32, where the gradients are computed
with the back-propagation algorithm (Rumelhart et
al., 1986). Specifically, the Adam algorithm is used
(Kingma and Ba, 2015). The initial learning rate is
selected from the range of [0.0010, 0.0100], with a
step size of 0.0005, according to the log-likelhood
of the validation data at the first epoch. The learning
rate is halved at each epoch once the log-likelihood
of the validation data decreases. The whole train-
ing procedure terminates when the log-likelihood
decreases for the second time.

Each comment is treated as a data sample, and as-
signed to a partition number in {0, 1, . . . , 9} accord-
ing to the thread it belongs to. Each partition has
roughly the same number of threads. We use par-
titions 4–9 as training data, partitions 2–3 as valida-
tion data, and partitions 0–1 as test data, The training
data are shuffled at the beginning of each epoch.

As discussed in Section 3, there are many more
low-level comments than high-level comments, and
the evaluation metric effectively puts more emphasis
on high-level comments. Therefore, rather than us-
ing the full training and validation sets, we subsam-
ple the low-level comments (level-0, level-1, level-
2, level-3) such that each level has roughly the same
number of samples as level-4. Since the three sub-
reddits studied in this paper vary in their sizes, to
eliminate the factor of training data size, we use
similar amounts of training (∼90K comments) and
validation (∼30K comments) data for these subred-
dits. Note that we do not subsample the test data,
i.e., 192K for AskMen, 463K for AskWomen, and
1,167K for Politics.

59



20%

30%

40%

50%

60%

70%

80%

AskMen AskWomen Politics

level>0 leve>1 level>2 level>3 level>4 level>5 level>6

Figure 4: Individual F1 scores for the full model.

6 Experiments

In this section, we present the performance of the
proposed model and conduct contrastive experi-
ments to study model variants in two dimensions.
For the submission context features, we compare
representations obtained via feedforward neural net-
works to that obtained by a learned combination of
latent basis vectors. In terms of textual features,
we compare a model which uses no text, context-
independent text features, and a context-depending
gating mechanism. Finally, we analyze the learned
latent submission context modes, as well as context-
dependent gate values that reflect the amount of tex-
tual information used by the full model.

6.1 Model Configuration

All parameters in the neural networks except bias
terms are initialized randomly according to the
Gaussian distribution N (0, 10−2). We tune the
number of latent bases K and the number of hidden
layer neurons C and D based on the macro F1 scores
on the validation data. For the full model, the best
configuration uses K = 8, C = 32 and D = 64 for
all subreddits, except Politics where D = 32.

6.2 Main Results

The performance of the full model on individual lev-
els is presented in Fig. 4. As expected, the low-
est level comments are easier to classify. Detec-
tion of high-level comments is most reliable in the
Politics subreddit, but still difficult.

Table 2 compares models variants that only

AskMen AskWomen Politics
SubtreeSize 39.1 42.9 41.7
ConvStruct 43.9 41.4 42.0
Feedfwd-1 46.5 50.6 49.6
Feedfwd-2 46.8 50.9 49.8
Feedfwd-3 47.1 50.5 50.0
LatentModes 47.0 51.0 50.3

Table 2: Test macro F1 scores for models that do not use the
textual content information.

AskMen AskWomen Politics
No text 47.0 51.0 50.3

Un-gated 48.3 52.5 49.5
Gated 48.7 53.1 51.3

Table 3: Test macro F1 scores for models with and without the
gating mechanism. All models use latent modes to represent the

submission context information.

use the submission context features. The
SubtreeSize baseline uses a multinominal lo-
gistic regression model to predict the level accord-
ing to the subtree size feature alone, whereas the
ConvStruct uses the same model but with all
conversation structure features defined in Tabel 1.
All baselines are stronger than predicting based on
prior distributions, which has F1 scores in the 11-
17 range. The model Feedfwd-n is a feedforward
neural network with n hidden layers; it uses the sub-
mission context feature c in Fig. 3 for prediction.
The model LatentBases represents the submis-
sion context information by a linear combination of
latent bases; it uses c̃ in Fig. 3 for prediction. Com-
pared with Feedfwd-1 in terms of the number of
model parameters, Feedfwd-2, Feedfwd-3 and
LatentBases have C2, 2C2, and (2C2+K) extra
parameters, respectively. These models have simi-
lar performance, but there is a slight improvement
by increasing model capacity. While the proposed
method does not give a significant performance gain,
it leads to a more interpretable model.

Table 3 studies the effect of adding text and intro-
ducing the gating mechanism. The un-gated variant
uses d instead of d̃ for prediction. Without the gat-
ing mechanism, textual information provides signifi-
cant improvement for AskMen and AskWomen but
not for Politics. With the introduced dynamic
gating mechanism, the textual information is used
more effectively for all three subreddits.

60



level-0 level-1 level-2 level-3 level-4 level-5 level-6 level-7

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

A B C D E F G H

low medium high

(a) AskMen

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

A B C D E F G H

low medium high

(b) AskWomen

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

A B C D E F G H

low medium high

(c) Politics
Figure 5: Empirical distributions of levels for each latent mode. Modes are grouped by dominating levels, i.e., level-0 and level-1
as low, level-6 and level-7 as high, and the rest as medium. Within each cluster, the modes are sorted by the number of samples.

(a) AskMen (b) AskWomen (c) Politics
Figure 6: Visualization of learned clusters.

0

5

10

15

20

25

30

35

A B C D E F G H

low medium high

time_since_parent time_since_root subtree_height num_children

Figure 7: Mean values of four submission context features for
each latent mode of AskWomen.

6.3 Analysis

In this subsection, we analyze the learned submis-
sion context modes and the gate values that control
the amount of textual information to be used by the

model for predicting comment karma level.

Submission context modes: To study the submis-
sion context modes, we assign each comment to
a cluster according to which basis vector receives
the highest weight: argmaxk=1,...,Kak. The label
distribution for each cluster is shown in Fig. 5. It
can be observed that some clusters are dominated
by level-0 comments, and others are dominated by
level-7 comments. In Fig. 6, we visualize the learned
clusters by projecting the raw conversation struc-
ture features x to a 2-dimensional space using the t-
SNE algorithm (van der Maaten and Hinton, 2008).
For purposes of illustrating cross-domain similari-
ties, we group the clusters dominated by level-0 and
level-1 comments into a low endorsement cluster,
those dominated by level-6 and level-7 into a high
endorsement cluster, and the rest as the medium en-
dorsement cluster. It can be seen that the learned
clusters split the comments with a consistent pattern,
with the higher endorsement comments towards the

61



AskMen AskWomen Politics
medium 0.87 0.87 0.85

high 0.67 0.66 0.76

Table 4: Text gate values relative to low karma modes.

right and the low endorsement comments to the left.
In Fig. 7, we show mean values of four selected

submission context features for each latent mode
of AskWomen, where units of time are in hours.
High karma comments tend to be submitted early
in the discussion, and the number of children (di-
rect replies) is similar to or greater than the height
of its subtree (corresponding to a broad subtree).
Low and medium karma comments have a ratio of
number of children to subtree height that is less than
one. Low karma comments tend to come later in
the discussion overall (time since root) but also later
in terms of the group of responses to a parent com-
ment (time since parent). These trends hold for all
three subreddits. All subreddits have within-group
differences in the mode characteristics, particularly
the low-karma modes. For AskWomen, graph clus-
ter B corresponds to comments made at the end of a
discussion, which are more likely to be low karma
because there are fewer readers and less opportu-
nity for a new contribution. Cluster C comments
come earlier in the discussion but have small sub-
trees compared to other early comments.

Text gate: In Table 4, we show the mean gate val-
ues g for each group of latent modes. Since gate val-
ues are not comparable across subreddits due to dy-
namic range of feature values, the values shown are
scaled by the value for the low-level mode. We ob-
serve a consistent trend across all subreddits: lower
gate values for higher karma. Recall that the high
karma comments typically spawn active discussions.
Thus, a possible explanation is that users may be bi-
ased to endorse comments that others are endorsing,
making the details of the content less important.

7 Conclusion

In summary, this work has addressed the problem
of predicting community endorsement of comments
in a discussion forum using a new neural network
architecture that integrates submission context fea-
tures (including relative timing and response struc-

ture) with features extracted from the text of a com-
ment. The approach represents the submission con-
text in terms of a linear combination of latent basis
vectors that characterize the dynamic conversation
mode, which gives results similar to using a deep
network but is more interpretable. The model also
includes a dynamic gate for the text content, and
analysis shows that when response structure is avail-
able to the predictor, the content of a comment has
the most utility for comments that are not in active
regions of the discussion. These results are based
on characterizing quantized levels of karma with a
series of binary classifiers. Quantized karma predic-
tion could also be framed as an ordinal regression
task, which would involve a straightforward change
to the neural network learning objective.

This work differs from related work on popularity
prediction in that the task does not control for con-
tent of a post/comment, nor limit the time window of
the submission. With fewer controls, it is more dif-
ficult to uncover the aspects of textual content that
contribute to endorsement, but by conditioning on
submission context we can begin to understand herd
effects of endorsement. The task described here also
differs from previous work in that the full (or almost
full) discussion thread is available in extracting fea-
tures characterizing the response to the comment,
but the modeling framework would also be useful
with a limited window lookahead. The results using
the full discussion tree also show the limits of using
response volume to measure endorsement.

A limitation of this work is that the submission
context is represented only in terms of the relative
timing and graph structure in a discussion thread and
does not use the text within earlier or responding
comments. Prior work has shown that the relevance
of a comment to the preceding discussion matters
(Jaech et al., 2015), and clearly the sentiment ex-
pressed in responses should provide important cues.
Capturing these different sources of information in a
gated framework is of interest for future work.

Acknowledgments

This paper is based on work supported by the
DARPA DEFT Program. Views expressed are those
of the authors and do not reflect the official policy
or position of the Department of Defense or the U.S.
Government.

62



References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-

gio. 2015. Neural machine translation by jointly
learning to align and translate. In Proc. Int. Conf.
Learning Representations (ICLR).

Roja Bandari, Sitaram Asur, and Bernardo Huberman.
2012. The pulse of news in social media: forecasting
popularity. In Proc. Int. AAAI Conf. Web and Social
Media (ICWSM).

Jan A. Botha and Phil Blunsom. 2014. Composi-
tional morphology for word representations and lan-
guage modelling. In Proc. Int. Conf. Machine Learn-
ing (ICML).

Justin Cheng, Lada Adamic, P. Alex Dow, Jon Michael
Kleinberg, and Jure Leskovec. 2014. Can cascade
be predicted? In Proc. Int. Conf. World Wide Web
(WWW), pages 925–936.

Hao Cheng, Hao Fang, and Mari Ostendorf. 2015. Open-
domain name error detection using a multi-task RNN.
In Proc. Conf. Empirical Methods Natural Language
Process. (EMNLP).

Kyunghyun Cho, Bart van Merriënboer, Caglar Gul-
cehre, Dzmitry Bahadanau, Fethhi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014. Learning phrase
representations using RNN encoder-decoder for statis-
tical machine translation. In Proc. Conf. Empirical
Methods Natural Language Process. (EMNLP), pages
1724–1734.

Hao Fang, Mari Ostendorf, Peter Baumann, and Janet
Pierrehumbert. 2015. Exponential language modeling
using morphological features and multi-task learning.
IEEE Trans. Audio, Speech, and Language Process.,
23(12):2410–2421, December.

Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long
short-term memory. Neural Computation, 9(8):1735–
1780, November.

Liangjie Hong, Ovidiu Dan, and Brian Davison. 2011.
Predicting popular messages in Twitter. In Proc. Int.
Conf. World Wide Web (WWW), pages 57–58.

Aaron Jaech, Vicky Zayats, Hao Fang, Mari Ostendorf,
and Hannaneh Hajishirzi. 2015. Talking to the
crowd: What do people react to in online discussions?
In Proc. Conf. Empirical Methods Natural Language
Process. (EMNLP), pages 2026–2031.

Bin Jiang. 2013. Head/tail break: A new classification
scheme for data with a heavy-tailed distribution. The
Professional Geographer, 65(3):482–494.

Diederik Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proc. Int. Conf.
Learning Representations (ICLR).

Himabindu Lakkaraju, Julian McAuley, and Jure
Leskovec. 2013. What’s in a name? Understanding
the interplay between titles, content, and communities

in social media. In Proc. Int. AAAI Conf. Web and So-
cial Media (ICWSM).

Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven J. Bethard, and David McClosky.
2014. The Stanford CoreNLP natural language pro-
cessing toolkit. In Proc. Annu. Meeting Assoc. for
Computational Linguistics: System Demonstrations,
pages 55–60.

Andrew L. Mass, Awni Y. Hannun, and Andrew Y. Ng.
2013. Rectifier nonlinearities improve neural network
acoustic models. In Proc. Int. Conf. Machine Learning
(ICML).

Hamid Palangi, Li Deng, Yelong Shen, Jianfeng Gao, Xi-
aodong He, Jianshu Chen, Xinying Song, and Rabab
Ward. 2016. Deep sentence embedding using long
short-term memory networks: Analysis and appli-
cation to information retrieval. IEEE Trans. Au-
dio, Speech, and Language Process., 24(4):694–707,
April.

David E. Rumelhart, Geoffrey E. Hinton, and Ronald J.
Williams. 1986. Learning representations by back-
propogating errors. Nature, 323(6088):533–536, Oc-
tober.

B. Suh, L. Hong, P. Pirolli, and E. H. Chi. 2010. Want to
be retweeted? large scale analytics on factors impact-
ing retweet in twitter network. In Proc. IEEE Inter.
Conf. on Social Computing (SocialCom), pages 177–
184.

Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and
Rob Fergus. 2015. End-to-end memory networks.
In Proc. Annu. Conf. Neural Inform. Process. Syst.
(NIPS), pages 2431–2439.

Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.
Sequence to sequence learning with neural networks.
In Proc. Annu. Conf. Neural Inform. Process. Syst.
(NIPS), pages 3104–3112.

Chenhao Tan, Lillian Lee, and Bo Pang. 2014. The ef-
fect of wording on message propagation: Topic- and
author-controlled natural experiments on Twitter. In
Proc. Annu. Meeting Assoc. for Computational Lin-
guistics (ACL), pages 175–186.

Manos Tasgkias, Wouter Weerkamp, and Maarten de Ri-
jke. 2009. Predicting the volume of comments on on-
line news stories. In Proc. CIKM, pages 1765–1768.

Alexandru Tatar, Jeremie Leguay, Panayotis Antoniadis,
Arnaud Limbourg, Marcelo Dias de Amorim, and
Serge Fdida. 2011. Predicting the polularity of online
articles based on user comments. In Proc. Inter. Conf.
on Web Intelligence, Mining and Semantics (WIMS),
pages 67:1–67:8.

Laurens van der Maaten and Geoffrey Hinton. 2008. Vi-
sualizing data using t-SNE. Machine Learning Re-
search, 9, Nov.

63



Oriol Vinyals, Lukasz Kaiser, Terry Koo, Slav Petrov,
Ilya Sutskever, and Geoffrey Hinton. 2015. Grammar
as a foreign language. In Proc. Annu. Conf. Neural
Inform. Process. Syst. (NIPS), pages 2755–2763.

Jason Weston, Sumit Chopra, and Antoine Bordes. 2015.
Memory networks. In Proc. Int. Conf. Learning Rep-
resentations (ICLR).

Tae Yano and Noah A. Smith. 2010. What’s worthy of
comment? content and comment volume in political
blogs. In Proc. Int. AAAI Conf. Weblogs and Social
Media (ICWSM).

Qingyuan Zhao, Murat A. Erdogdu, Hera Y. He, Anand
Rajaraman, and Jure Leskovec. 2015. SEISMIC: A
self-exciting point process model for predicting Tweet
popularity. In Proc. ACM SIGKDD Conf. Knowledge
Discovery and Data Mining.

64


