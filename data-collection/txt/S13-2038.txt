










































UKP-WSI: UKP Lab Semeval-2013 Task 11 System Description


Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 212–216, Atlanta, Georgia, June 14-15, 2013. c©2013 Association for Computational Linguistics

UKP-WSI: UKP Lab Semeval-2013 Task 11 System Description

Hans-Peter Zorn† and Iryna Gurevych†‡

†Ubiquitous Knowledge Processing Lab (UKP-TUDA)
Department of Computer Science, Technische Universität Darmstadt

‡Ubiquitous Knowledge Processing Lab (UKP-DIPF)
German Institute for Educational Research and Educational Information

www.ukp.tu-darmstadt.de

Abstract

In this paper, we describe the UKP Lab sys-
tem participating in the Semeval-2013 task
“Word Sense Induction and Disambiguation
within an End-User Application”. Our ap-
proach uses preprocessing, co-occurrence ex-
traction, graph clustering, and a state-of-the-
art word sense disambiguation system. We
developed a configurable pipeline which can
be used to integrate and evaluate other com-
ponents for the various steps of the complex
task.

1 Introduction

The task “Evaluating Word Sense Induction and
Word Sense Disambiguation in an End-User Ap-
plication” of SemEval-2013 (Navigli and Vannella,
2013) aims at an extrinsic evaluation scheme for
WSI to overcome the difficulties inherent to WSI
evaluation. The task requires building a WSI sys-
tem and combining it with a WSD step to assign the
induced sentences to example instances.

Word sense disambiguation (WSD) is the task
of determining the correct meaning for an ambigu-
ous word from its context. WSD algorithms usu-
ally choose one sense out of a given set of possible
senses for each word. A resource that enumerates
possible senses for each word is called a sense in-
ventory. Manually created inventories come usually
in form of lexical semantic resources, such as Word-
Net or more specifically created inventories such as
OntoNotes (Hovy et al., 2006).

Word sense induction (WSI) on the other hand
aims to create such an inventory from a corpus in

an unsupervised manner. For each word that should
be disambiguated, a WSI algorithm creates a set of
context clusters that will be used to define and de-
scribe the senses.

We build our system upon the open-source DKPro
framework 1 and a corresponding WSD component
(upcoming).

Input for the task comes as two files. One contains
the search queries, also referred as topics. Sense in-
duction will be performed for each of those topics.
The second file contains 6400 entries from the re-
sult pages of a search engine. Each entry consists of
the title, a snippet and the URL of the corresponding
web page.

2 Related Work

One of the early approaches to WSI (Schütze, 1998)
maps words into a vector space and represents
word contexts as vector-sums and use cosine vec-
tor similarity, clustering is performed by expectation
maximization (EM) clustering. Dorow and Wid-
dows (2003) use the BNC to build a co-occurrence
graph for nouns, based on a co-occurrence fre-
quency threshold. They perform Markov cluster-
ing on this graph. Pantel and Lin (2002) proposes
a clustering approach called clustering by commit-
tee (CBC). This algorithm first selects the words
with the highest similarity based on mutual infor-
mation and then builds groups of highly connected
words called committees. It then iteratively assigns
the remaining words to one of the committee clus-
ters by comparing them to the averaged the com-

1http://code.google.com/p/dkpro-core-asl/

212



mittee feature vectors. This exploits the assumption
that two or more words together disambiguate each
other, Bordag (2006) extends on this idea by using
word triples to form non-ambiguous seed-clusters.
Many approaches use a variety of graph clustering
algorithms for WSI: Others (Klapaftis and Manand-
har, 2010) use hierarchical agglomerative clustering
on hierarchical random graphs created from word
co-occurrences. Di Marco and Navigli (2013) use
word sense induction for web search result cluster-
ing. They introduce a maximum spanning tree al-
gorithm that operates on co-occurrence graphs built
from large corpora, such as ukWaC (Baroni et al.,
2009). The system by Pedersen (2010) employs
clustering first- and second-order co-occurrences as
well as singular value decomposition on the co-
occurrence matrix, which is clustered using repeated
bisections. Jurgens (2011) employ a graph-based
community detection algorithm on a co-occurrence
graph. Distributional approaches for WSI include
LSA Apidianaki and Van de Cruys (2011) or LDA
(Brody and Lapata, 2009).

3 Our Approach

Our system consists of two independent parts. The
first is a batch process that creates database con-
taining co-occurrence statistics derived from a back-
ground corpus. The second is the actual WSI and
WSD pipeline doing the result clustering. Both parts
include identical preprocessing steps for segmenta-
tion and lemmatization.

The pipeline (Figure 1) first performs Word Sense
Induction, resulting in an induced sense inventory.
A WSD algorithm then uses this inventory to dis-
ambiguate all instances of the search query within a
web-page. A majority voting finally assigns a sense
to each result-snippet.

The sense induction algorithm is based on graph
clustering on a co-occurrence graph, similar to the
approach by Di Marco and Navigli (2013). Our ap-
proach differs from previous work in the way we
perform a greedy search for additional context and
how it combines WSI with an advanced WSD step
using lexical expansions. Moreover, we consider
our generic UIMA-based WSD and WSI system as
a useful basis for experimentation and evaluation of
WSI systems.

# words # co-occurrences
Wikipedia 3,011,397 96,979,920
ukWaC 8,687,711 441,005,478

Table 1: Size of co-occurrence databases

3.1 Preprocessing

The pipeline first reads topics and snippets. If the
web-page can be downloaded at the URL that cor-
responds to the result, it is cleaned by an HTML
parser and the plain text is appended to the snippet.
As further steps we segment and lemmatize the in-
put. We apply the same preprocessing to snippets,
queries and the corpora.

3.2 Co-occurrence Extraction

We calculate the log-likelihood ratio (LLR) (Dun-
ning, 1993) and point-wise mutual information
(PMI) (Church and Hanks, 1990) of a word pair co-
occurring at sentence level using a modified version
of the collocation statistics implemented in Apache
Mahout 2. Even when sorting the co-occurrences by
PMI, we employ a minimum support cut-off based
on the LLR, which is based on significance. All
pairs with a log-likelihood ratio < 1 are discarded.
This value is lower than the significance level of 3̃.8
we found in the literature, but because in the ex-
pand step (see algorithm 2) we require more than
two words to co-occur with the target word, we used
a lower value. We use the English Wikipedia 3 and
ukWaC (Baroni et al., 2009) as background corpus.
Table 1 gives an overview about the obtained co-
occurrence pairs.

3.3 Clustering Algorithm

The algorithm is a two-step approach that first cre-
ates an initial clustering of a graph G = (V,E)
and then improves this clustering in a second step.
The initial step (Algorithm 1) starts by retrieving the
top n = 150 most similar terms for the target word
by querying the co-occurrence database we created
in section 3.2. These represent vertices in a graph.
We then construct 4 a minimum spanning tree (mst)

2http://mahout.apache.org
3Dump from April 2011
4For all of our graph operations, we employ the igraph li-

brary for R, http://igraph.sf.net

213



Figure 1: WSI and WSD Pipeline

by inserting edges {vi, vj} from the co-occurrence
database. The weight w({vi, vj}) of each edge is
set to the inverse of the used similarity measure
dist (LLR or PMI) between those terms. The min-
imum spanning tree then is cut into subtrees be it-
eratively removing the edge with the highest edge-
betweenness (Freeman, 1977) (betweeness) until
the size of the largest component of G falls below
a threshold Sinitial.

Algorithm 1 initialClusters
V (G0)← top n most similar words to target word
w(vi, vj)← dist(termi, termj)
G← mst(G0)
V (G)← V (G) \ vtarget
while max(|C(G)|) > Sintitial do

E(G)← E(G) \ arg maxe(betweeness(e))
end while

The resulting partitioning of the graph is the start-
ing point for the second phase of the algorithm,
which we call expand/join step (Algorithm 2). Dur-
ing this step, the algorithm looks iteratively at all
clusters Csmall of size s smaller than Smax = 9 (de-
termined empirically), starting with the largest ones.
From each of these clusters, it constructs a query
to the co-occurrence database, retrieving all terms
that significantly co-occur together with all terms in
the respective cluster (querys) and with the target
word (E). This list of terms is then compared to
all clusters Clarge with |C| > s . If the normalized
intersection between one of those Clarge is above a
threshold t = 0.3 (determined empirically), we as-
sume that the Csmall represents the same sense as
the Clarge and merge those clusters. If this is not the
case for any of the larger clusters, we assume that
Csmall represents a sense of its own extend the clus-

ter by adding edges between vertices representing
the expansion terms and Csmall.

Algorithm 2 expandJoin
Require: G is a minimum spanning forest

for s = Smax → 1 do
for all Csmall(G), |Csmall| = s do

E ← querys(v1, .., vi)
for all Clarge ∈ G, |Clarge| > s do

if |Clarge ∩ E|/|Clarge| > t then
Clarge ← Clarge ∪ Csmall

else
Csmall ← Csmall ∪ E

end if
end for

end for
end for

3.4 Word Sense Disambiguation

We use the DKPro WSD framework, which imple-
ments various WSD algorithms, with the same sys-
tem configuration as reported by Miller et al. (2012).
It uses a variant of the Simplified Lesk Algorithm
(Kilgarriff et al., 2000). This algorithm measures
the overlap between a words context and the tex-
tual descriptions of senses within a machine read-
able dictionary, such as WordNet. The senses that
have been induced in the previous step are provided
to the framework as a sense inventory. Instead of
using sense descriptions, we now compute the over-
lap between the sense clusters and the context of
the target word. The WSD system expands both
the word context and the sense clusters with syn-
onyms from a distributional thesaurus (DT), similar
to Lin (1998). The DT has been created from 10M
dependency-parsed sentences of English newswire

214



Run F1 ARI RI JI # clusters avg cl. size
wacky-llr 0.5826 0.0253 0.5002 0.3394 3.6400 32.3434
wp-llr 0.5864 0.0377 0.5109 0.3177 4.1700 21.8702
wp-pmi 0.6048 0.0364 0.5050 0.2932 5.8600 30.3098

Table 2: Results for the submitted runs

from the Leipzig Corpora Collection (Biemann et
al., 2007) for word similarity5. Besides knowledge-
based WSD, the DT also has been successfully used
for improving the performance of semantic text sim-
ilarity (Bär et al., 2012). The WSD component dis-
ambiguates each instance of the search query within
the snippet and web page individually.

4 Results

The clustering was evaluated using four different
metrics as described by Di Marco and Navigli
(2013). The Rand index and its chance-adjusted
variant ARI are common cluster evaluation metrics.
The adjusted rand index gives special weight to less
frequent senses. The Jaccard index (JI) disregards
the cases where two results are assigned to differ-
ent clusters in the gold standard, therefore it is less
sensitive to the granularity of the clustering. The
F1-Measure gives more attention to the individual
clusters and how they cover the topics in the gold
standard.

We submitted several runs for different config-
urations of the co-occurrence extraction (Table 2).
Between runs, we did not modify the configuration
of the sense induction or disambiguation step. The
first run used collocations extracted from ukWaC
scored by LLR metric (wacky-llr), and two others
used Wikipedia as background corpus. One of the
WP-based runs used PMI as association metric (wp-
pmi), the other one used LLR (wp-llr). The run on
the larger ukWaC corpus scored best with regard to
the Jaccard measure, but worst in the adjusted Rand
index measure. We attribute low scores for ARI to
the fact that our system did not induce certain less
frequent senses, resulting in small average number
of clusters. The coarse grained clusters however,
have been assigned quite well by our WSD system,
as shown by relatively high Jaccard Index. For the

5The software used to create the DT is available from
http://www.jobimtext.org

WP-based runs, the clustering based on PMI pro-
duced more clusters and therefore scored higher on
the F1 measure than the LLR-based run. From an
exploratory analysis of the created clusters, we as-
sume that the WP-based runs have a higher chance
to find more rare senses in this specific task, since
the gold standard was also based on Wikipedia dis-
ambiguation pages.

5 Conclusion

We presented our word sense induction and dis-
ambiguation pipeline for search result clustering.
Our contribution is a sense induction algorithm that
incrementally retrieves more context from a co-
occurrence database and the integration of WSI and
WSD into a UIMA-based pipeline for easy experi-
mentation. The system scored best with regard to
Jaccard similarity of clusters, while performing low
especially with the adjusted rand index. We assume
that our sense granularity was too low for this task
and failed to create clusters for rare senses. This
could be improved by making the merge phase of
the induction algorithm less eager. Furthermore,
increasing the size of the background corpus, e.g.
by combining the both corpora that have been used
could increase the size of the context clusters espe-
cially for rare senses, which should further improve
the performance in these cases. We attribute the
good results with regard to the F1 and Jaccard mea-
sures also to our state-of-the-art word sense disam-
biguation step and the use of the distributional the-
saurus.

6 Acknowledgements
We thank Tristan Miller for helping us with the
DKPro WSD framework and Chris Biemann for
providing the distributional thesaurus. This work
has been supported by the Volkswagen Foundation
as part of the Lichtenberg-Professorship Program
under grant No. I/82806.

215



References
Marianna Apidianaki and Tim Van de Cruys. 2011. La-

tent Semantic Word Sense Induction and Disambigua-
tion. In ACL HLT 2011, pages 1476–1485, June.

Daniel Bär, Chris Biemann, Iryna Gurevych, and Torsten
Zesch. 2012. UKP: Computing Semantic Textual
Similarity by Combining Multiple Content Similarity
Measures. In Proceedings of First Joint Conference on
Lexical and Computational Semantics (*SEM), pages
435–440.

Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and
Eros Zanchetta. 2009. The WaCky wide web: a
collection of very large linguistically processed web-
crawled corpora. Language Resources and Evalua-
tion, 43(3):209–226, February.

Chris Biemann, Gerhard Heyer, Uwe Quasthoff, and
Matthias Richter. 2007. The Leipzig Corpora Collec-
tion - Monolingual corpora of standard size. In Pro-
ceedings of Corpus Linguistic 2007, Birmingham, UK.

Stefan Bordag. 2006. Word Sense Induction: Triplet-
Based Clustering and Automatic Evaluation. In Pro-
ceedings of the 11th Conference of the European
Chapter of the Association for Computational Linguis-
tics, pages 137–144, Trento, Italy.

Samuel Brody and Mirella Lapata. 2009. Bayesian word
sense induction. In Proceedings of the 12th Con-
ference of the European Chapter of the Association
for Computational Linguistics, EACL ’09, pages 103–
111, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.

Kenneth Ward Church and Patrick Hanks. 1990. Word
association norms, mutual information, and lexicogra-
phy. Computational Linguistics, 16(1):22–29, March.

Antonio Di Marco and Roberto Navigli. 2013. Cluster-
ing and Diversifying Web Search Results with Graph-
Based Word Sense Induction. Computational Linguis-
tics, 39(4):1–46, November.

Beate Dorow and Dominic Widdows. 2003. Discover-
ing corpus-specific word senses. In Proceedings of the
Tenth Conference on European Chapter of the Associ-
ation for Computational Linguistics - EACL ’03, vol-
ume 2, page 79, Morristown, NJ, USA, April. Associ-
ation for Computational Linguistics.

Ted Dunning. 1993. Accurate Methods for the Statistics
of Surprise and Coincidence. Computational Linguis-
tics, 19(1):61 – 74.

Linton C Freeman. 1977. A set of measures of centrality
based on betweenness. Sociometry, 40(1):35–41.

Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance
Ramshaw, and Ralph Weischedel. 2006. OntoNotes:
the 90% solution. In Proceedings of the Human Lan-
guage Technology Conference of the NAACL, Com-
panion Volume: Short Papers, NAACL-Short ’06,

pages 57–60, Stroudsburg, PA, USA. Association for
Computational Linguistics.

David Jurgens. 2011. Word Sense Induction by Commu-
nity Detection. In HLT ’11: Proceedings of the 49th
Annual Meeting of the Association for Computational
Linguistics Human Language Technologies, pages 24–
28, Portland, Oregon.

Adam Kilgarriff, Brighton England, and Joseph Rosen-
zweig. 2000. English Senseval: Report and Results.
In Proceedings of the 2nd International Conference on
Language Resources and Evaluation, Athens, Greece.

Ioannis P. Klapaftis and Suresh Manandhar. 2010. Word
sense induction & disambiguation using hierarchical
random graphs. In Proceedings of the 2010 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 745–755, Cambridge, Massachusetts,
October. Association for Computational Linguistics.

Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In Proceedings of the 36th annual
meeting on Association for Computational Linguistics,
pages 768–774, Morristown, NJ, USA, August. Asso-
ciation for Computational Linguistics.

Tristan Miller, Chris Biemann, Torsten Zesch, and Iryna
Gurevych. 2012. Using Distributional Similarity for
Lexical Expansion in Knowledge-based Word Sense
Disambiguation. In Proceedings of the 24th In-
ternational Conference on Computational Linguistics
(COLING 2012).

Roberto Navigli and Daniele Vannella. 2013. SemEval-
2013 Task 11: Evaluating Word Sense Induction &
Disambiguation within An End-User Application. In
Proceedings of the 7th International Workshop on Se-
mantic Evaluation (SemEval 2013), in conjunction
with the Second Joint Conference on Lexical and Com-
putational Semantcis (*SEM 2013), Atlanta, USA.

Patrick Pantel and Dekang Lin. 2002. Discovering word
senses from text. In Proceedings of the eighth ACM
SIGKDD international conference on Knowledge dis-
covery and data mining - KDD ’02, page 613, New
York, New York, USA, July. ACM Press.

Ted Pedersen. 2010. Duluth-WSI: SenseClusters applied
to the sense induction task of SemEval-2. In Proceed-
ings of the 5th International Workshop on Semantic
Evaluation, pages 363–366, Stroudsburg, PA, USA,
July. Association for Computational Linguistics.

Hinrich Schütze. 1998. Automatic word sense discrim-
ination. Computational Linguistics, 24(1):97–123,
March.

216


