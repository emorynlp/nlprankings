










































Identifying Opinion Holders and Targets with Dependency Parser in Chinese News Texts


Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 46–51,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

 

Identifying Opinion Holders and Targets with Dependency Parser in 
Chinese News Texts 

Bin Lu 
Department of Chinese, Translation and Linguistics & 

Language Information Sciences Research Centre 
City University of Hong Kong 

Kowloon, Hong Kong 
lubin2010@gmail.com 

Abstract 
In this paper, we propose to identify 
opinion holders and targets with 
dependency parser in Chinese news texts, 
i.e. to identify opinion holders by means of 
reporting verbs and to identify opinion 
targets by considering both opinion holders 
and opinion-bearing words. The 
experiments with NTCIR-7 MOAT’s 
Chinese test data show that our approach 
provides better performance than the 
baselines and most systems reported at 
NTCIR-7. 

1 Introduction 
In recent years, sentiment analysis, which mines 
opinions from information sources such as news, 
blogs and product reviews, has drawn much 
attention in the NLP field (Hatzivassiloglou and 
McKeown, 1997; Pang et al., 2002; Turney, 2002; 
Hu and Liu, 2004).  

An opinion expressed in a text involves different 
components, including opinion expression, opinion 
holder and target (Wilson and Wiebe, 2003). 
Opinion holder is usually an entity that holds an 
opinion, and opinion target is what the opinion is 
about (Kim and Hovy, 2006). Although there have 
been research on identifying opinion holders and 
targets in  English product reviews and news texts, 
little work has been reported on similar tasks 
involving Chinese news texts.   

In this study, we investigate how dependency 
parsing can be used to help the task on opinion 
holder/target identification in Chinese news texts. 
Three possible contributions from this study are: 1) 
we propose that the existence of reporting verbs is 
a very important feature for identifying opinion 
holders in news texts, which has not been clearly 
indicated; 2) we argue that the identification of 

opinion targets should not be done alone without 
considering opinion holders, because opinion 
holders are much easier to be identified in news 
texts and the identified holders are quite useful for 
the identification of the associated targets. Our 
approach shows encouraging performance on 
opinion holder/target identification, and the results 
are much better than the baseline results and most 
results reported in NTCIR-7 (Seki et al., 2008).  

The paper is organized as follows. Sec. 2 
introduces related work. Sec. 3 gives the linguistic 
analysis of opinion holder/target. The proposed 
approach is described in Sec. 4, followed by the 
experiments in Sec. 5. Lastly we conclude in Sec. 6. 

2 Related Work 
Although document-level sentiment analysis 
(Turney, 2002; Pang et al., 2002) can provide the 
overall polarity of the whole text, it fails to detect 
the holders and targets of the sentiment in texts.  

2.1 Opinion Holders/ Target Identification 
For opinion mining of product reviews, opinion 
holder identification is usually omitted under the 
assumption that opinion holder is the review writer; 
and opinion targets are limited to the product 
discussed and its features (Hu and Liu, 2004). But 
in news texts, opinion holders/targets are more 
diverse: all named entities and noun phrases can be 
opinion holders; while opinion targets could be 
noun phrases, verb phrases or even clauses (Kim 
and Hovy, 2006; Ruppenhofer et al. 2008).  

Bethard et al. (2004) identify opinion 
propositions and their holders by semantic parsing 
techniques. Choi et al. (2005) and Kim and Hovy 
(2005) identify only opinion holders on the MPQA 
corpus (Wilson and Wiebe, 2003). Kim and Hovy 
(2006) proposed to map the semantic frames of 
FrameNet into opinion holder and target for only 
adjectives and verbs. Kim et al. (2008) proposed to 

46



 

use syntactic structures for target identification 
without considering opinion holders. Stoyanov and 
Cardie (2008) define opinion topic and target and 
treat the task as a co-reference resolution problem. 

For the identification of opinion holders/targets 
in Chinese, there were several reports at NTCIR-7 
(Seki et al., 2008). Xu et al. (2008) proposed to use 
some heuristic rules for opinion holder/target 
identification. Ku et al. (2008) treated opinion 
holder identification as a binary classification 
problem of determining if a word was a part of an 
opinion holder. 

2.2 Chinese Dependency Parsing 
Dependency structures represent all sentence 
relationships uniformly as typed dependency 
relations between pairs of words. Some major 
dependency relations for Chinese (Ma et al., 2004) 
include 谓主  (Subject-Verb, SBV), 动动  (Verb-Object, 
VOB), 定中(Attributive-Noun, ATT), 数量 (Quantifier, 
QUN) and 结独立 构 (Independent structure, IS). 
Consider the following Chinese sentence: 

a) 俄國 外長 伊凡諾夫 說，北約 東向 擴
張是 “ 邁向 錯誤 的 方向 ” 。 

Russian Foreign Minister Ivanov said that 
NATO's eastward expansion was "Towards the 
wrong direction." 

Its dependency tree is shown in Figure1. Its head 
is the verb 說 (said), whose subject and object are 
respectively 俄国外长伊凡诺夫 (Russian Foreign 
Minister Ivanov) and the embedded clause 北約東
向擴張是“邁向錯誤 的方向” (NATO's eastward 
expansion was "towards the wrong direction.").  

3 Linguistic Analysis of Opinions 
The opinions in news text may be explicitly 
mentioned or be expressed indirectly by the types 
of words and the style of language (Wilson and 
Wiebe, 2003). Two kinds of lexical clues are 
exploited here for opinion holder/target 
identification:  

Reporting verbs: verbs indicating speech 
events; 

Opinion-bearing Words: words or phrases 
containing polarity (i.e. positive, negative or 
neutral). 

In sentence a) above, the reporting verb 說 (said) 
indicates a speech event expressing an opinion 
given by the holder 俄国 外长 伊凡诺夫 (Russian 
Foreign Minister Ivanov). Meanwhile, the opinion-

bearing word 錯 誤  (wrong) shows negative 
attitude towards the target 北 約 東 向 擴 張 
(NATO's eastward expansion).  

Therefore, we assume that a large proportion of 
holders are governed by such reporting verbs, 
while targets are usually governed by opinion-
bearing words/phrases. 

Opinion holders are usually named entities, 
including, but not limited to, person names (e.g. 經
濟學家歐爾 /economist Ol), organization names 
(e.g. 英 國 政 府 /UK government), and personal 
titles (e.g. 經 濟 學 家 /the economist). Opinion 
holders can also be common noun phrases, such as 
廠商  (companies), 兩千 名學生  (two thousand 
students). Pronouns1 can also be opinion holders, 
e.g. 他 (he), 他們 (they), 我(I). Opinion targets are 
more abstract and diverse, and could be agents, 
concrete objects, actions, events or even abstract 
ideas. In addition to noun phrases, opinion targets 
could also be verb phrases or embedded clauses.  

4 Identifying Opinion Holders/Targets  
In this section, we introduce our approach of 
identifying opinion holders/targets. We use the 
dependency parser in the HIT LTP package 
(http://ir.hit.edu.cn/) to get the dependency 
relations of the simplified Chinese sentences 
converted from the traditional Chinese ones.  

4.1 Lexical Resources 
The reporting verbs were firstly collected from the 
Chinese sample data of NTCIR-6 OAPT (Seki et 
al., 2007) in which the OPINION_OPR tag was 
used to mark them. We then use HowNet, 
WordNet and Tongyici Cilin to extend the 
reporting verbs from 68 to 308 words through 
manual synonym search. Some frequently used 
reporting verbs include 說(say), 表示(express), 認
爲(think), etc. Some of the reporting verbs could 
also convey opinions, such as 批評 (criticize), 譴
責 (condemn), 讚揚 (praise), etc. 

For opinion-bearing words/phrases, we use The 
Lexicon of Chinese Positive Words (Shi and Zhu, 
2006) and The Lexicon of Chinese Negative Words 
(Yang and Zhu, 2006), which consist of 5046 
positive items and 3499 negative ones, respectively. 
                                                           
1 The resolution of the anaphor or co-reference has not been 
dealt with yet, i.e. the identified holders of the sentence are 
assumed to be in the same form as it appears in the sentence. 

47



 

 
Figure 1. Dependency Tree for Sentence a) 

4.2 Chinese Sentence Preprocessing (SP) 
To enhance the robustness of the dependency 
parser, named entities are first recognized with a 
traditional Chinese word segmentation tool with 
access to the very large LIVAC dictionary 
(http://www.livac.org) collected from Chinese 
news published in Hong Kong and Taiwan. The 
identified named entities, as well as the collected 
reporting verbs and opinion-bearing words are 
added to the user dictionary of the HIT LTP 
package to help parsing.  

Before parsing, the parentheses enclosing only 
English words or numbers are removed in 
sentences, because the parser cannot properly 
process the parentheses which may greatly 
influence the parsing result. 

4.3 Identifying Opinion Holders with 
Reporting Verbs 

4.3.1 Holder Candidate Generation 
Two hypotheses are used to identify opinion 
holders in opinionated sentences: 1) the subject of 
reporting verbs will be the opinion holders; 2) if no 
reporting verb is found, the author could be the 
opinion holder. In addition to the two hypotheses 
above, the following heuristic rules (HR) are used: 

1) Other words having relations with reporting 
verbs 

If the subject of reporting verbs is not found in 
the sentence, we will find the word having 
relationship of ATT, VOB or IS with the reporting 
verbs, because sometimes the parser may wrongly 
marked the subject as other relations.  

2) Colon processing in Headlines 
If no reporting verbs are found in news 

headlines, we just pick up the noun before the 
colon as the target candidate in the headlines 
because the author usually replaces the reporting 
verb with a colon due to length limitation. E.g. in 
the headline 摩 根 ： 經 濟 成 長 熄 火 (Morgan: 

Economic growth has been shut down), the noun
摩 根  (Morgan) before colon is chosen as the 
opinion holder.  

3) Holder in the previous sentence  
If no opinion holder is found in the current 

clause and one holder candidate is found in the 
previous clause, we just choose the opinion holder 
of the previous clause as the holder candidate, 
because an opinion holder may express several 
ideas through consecutive sentences or clauses. 

4.3.2 Holder Candidate Expansion (EP) 

Through the procedure of candidate generation, we 
may find a holder candidate containing only one 
single word. But the holder may be a word 
sequence instead of a single word. Thus we further 
expand the holder candidates from the core head 
word by the following rules:  

1) Attributive modifier (ATT)  
E.g. in sentence a) mentioned in Sec. 2.2, the 

subject of the reporting verb 說 (said) is 伊凡諾夫
(Ivanov), which has the attributive noun 外 長 
(Foreign Minister) modified further by an 
attributive noun 俄國(Russia). Therefore, the final 
extended opinion holder would be 外長伊凡諾夫
(Russian Foreign Minister Ivanov). 

2) Quantifier modifier and 和/及 (and/or) 
E.g. the quantifier modifier 部分(some) in the 

noun phrase 部分亞洲國家 (some Asian countries) 
should be part of the opinion holder. Sometime, we 
need to extend the holder across 和/及(and/or), e.g.
蘇哈托和另外兩名軍方將領 (Suharto and two 
other army generals). 

Furthermore, time nouns, numbers and words 
only containing one Chinese character (except for 
pronouns) are removed from the candidates, as 
they are unlikely to be opinion holders. 

4.4 Identifying Opinion Targets with 
Opinion-bearing Words 

48



 

Here we propose to use automatically identified 
reporting verbs and opinion holders to help opinion 
target identification. The heuristic rules (HR) are 
as follows. 

1) If a candidate of opinion holder is 
automatically identified with a reporting verb in an 
opinionated sentence, we will try to find the 
subject in the embedded clause as the target 
candidate by the following two steps: a) Find the 
subject of the object verb of the reporting verb. E.g. 
in sentence a) in Sec. 2.2, the opinion target 北約
東 向 擴 張  (NATO's eastward expansion) is the 
subject of the verb 是  (was) in the embedded 
clause which is in turn the object of the reporting 
verb 說 (said); b) If no target candidate is found in 
step a, we try to find after the reporting verb the 
subject whose parent is an opinion-bearing word as 
the target candidate. 

2) If no target candidate is found in step 1, and 
no opinion holder is found in the sentence, we find 
the subject of the sentence as the target candidate, 
because the author may be the opinion holder and 
the target could be the subject of the sentence. 

3) If still no target candidate is found in step 2, 
we find the object in the sentence as the target 
because the object could be the opinion target in 
case there is no subject and no opinion holder. 

Target candidate expansion (EP) is similar to 
holder candidate expansion described in Sec. 4.3.2. 
If an opinion target is in the opinion holder 
candidates (we call it holder conflict, HC), we 
remove it from the target candidates, and then try 
to find another using the above procedure.  

5 Experiments 
We use the traditional Chinese test data in NTCIR-
7 MOAT (Seki et al., 2008) for our experiments. 
Out of 4465 sentences, 2174 are annotated as 
opinionated by the lenient standard, and the 
opinion holders of some opinionated sentences are 
marked as POST_AUTHOR denoting the author of 
the news article. We use the final list given by the 
organizers as the gold standard.  

Baselines for opinion holder identification:  
Baseline 1: We just use the subject of reporting 

verbs as the opinion holder, without sentence 
preprocessing described in Sec. 4.2 and any 
heuristic rules introduced in Sec. 4.3.1. 

Baseline 2: We also implement the CRF model 
for detecting opinion holders (Choi et al., 2006) by 

using CRF++. The training data is the NTCIR-6 
Chinese test data. The labels used by CRF 
comprise Holder, Parent of Holder, None (not 
holder or parent) and the features for each word in 
our implementation include: basic features (i.e. 
word, POS-tag, whether the word itself is a 
reporting verb or not), dependency features (i.e. 
parent word, POS-tag of its parent, dependency 
relation with its parent, whether its parent is a 
reporting verb) and semantic features (i.e. WSD 
entry in Tongyici Cilin, WSD entry of its parent). 

Baseline for opinion target identification:  
Baseline 1: we try to find the subject or object of 

opinion-bearing words as the targets. If both a 
subject and an object are found, we just simply 
choose the subject as the target. 

We evaluate performance using 3 measures: 
exact match (EM), head match (HM), and partial 
match (PM), similar to Choi et al. (2006). We use 
three evaluation metrics: recall (Rec), precision 
(Pre), and F1. For opinion holder identification, we 
consider two cases: 1) all opinionated sentences; 2) 
only the opinionated sentences whose opinion 
holders do not contain POST_AUTHOR. The 
metric ALL_Pre reported below is the precision in 
case 1 which is the same with recall and F1. 

5.1 Results for Opinion Holder Identification 
The results for holder identification are shown in 
Table 1, from which we can observe that our 
proposed approach significantly outperforms the 
two baseline methods, including the unsupervised 
baseline 1 and the supervised baseline 2.  

  ALL_Pre Pre Rec F1 
EM 52.4 46.8 31.6 37.8 
HM 67.1 80.2 54.2 64.7 Baseline1  PM 72.1 89.3 60.4 72.0 
EM 45.5 34.7 18.1 23.8 
HM 55.2 63.6 33.1 43.6 Baseline2 (CRF) PM 55.6 64.9 33.8 44.4 
EM 69.8 74.4 63.6 68.5 
HM 72.5 79.2 67.7 73.0 Our 

Approach PM 75.7 85.1 72.7 78.4 
Table 1. Results for Opinion Holders 

Unexpectedly, even the unsupervised baseline 1 
achieves better performance than baseline 2 (the 
CRF-based method). The possible reasons are: 1) 
the training data is not large enough to cover the 
cases in the test data, resulting in low recall of the 
CRF model; 2) the features used by the CRF model 
could be refined to improve the performance. 

49



 

Here we also evaluate the influences of the 
following three factors on the performance: 
sentences preprocessing (SP) in Sec. 4.2, holder 
expansion (EP) in Sec. 4.3.2 and the heuristic rules 
(HR) in Sec. 4.3.1. The results are shown in Figure 
2 for different combinations, in which BL refers to 
baseline 1.  

Influence of Factors

35

40
45

50
55

60

65
70

75
80

85

BL BL+SP BL+EP BL+SP+EP Our Approach
(BL+SP+EP+HR)

Approaches

F1

EM
HM
PM

 
Figure 2. Influences of Factors on Opinion Holders 

From Figure 2, we can observe that: 1) All three 
factors have positive effects on performance 
compared to baseline 1, and our approach by 
integrating all factors achieves the best 
performance; 2) SP improve the performance in 
terms of all three metrics, showing that SP 
including named entity recognition and parenthesis 
removing are useful for holder identification; 3) 
The major improvement of EP lies in EM, showing 
that the main contribution of EP is to get the exact 
opinion holders by expanding the core head noun; 
4) SP+EP+HR improves the performance in terms 
of all three metrics compared with SP+HR, 
showing the heuristic rules are useful to improve 
the performance. 

5.2 Results for Opinion Target Identification 
The results for opinion target identification are 
shown in Table 2, from which we can observe that 
our proposed approach significantly outperforms 
the baseline method. 

  Pre Rec F1 
EM 11.1 9.2 10.1 
HM 24.0 19.9 21.8 Baseline 1  PM 39.4 32.7 35.8 
EM 29.3 28.5 28.9 
HM 38.4 38.0 38.2 

Our 
Approach 

 PM 59.3 58.7 59.0 
Table 2. Results for Opinion Targets 

We also investigate the influences of the 
following four factors on the performance: 
sentence preprocessing (SP) in Sec. 4.2, target 

expansion (EP) in Sec. 4.4, holder conflict (HC), 
the heuristic rules (HR) proposed in Sec. 4.4. The 
F1s for EM, HM and PM are shown in Figure 3, in 
which BL refers to baseline 1.  

Influence of Factors

8

18

28

38

48

58

68

BL BL+SP BL+EP BL+HC BL+SP
+EP+HC

Our Approach 

Approaches

F1

EM

HM

PM

 
Figure 3. Influences of Factors on Opinion Targets 

From Figure 3, we can observe that: 1) All four 
factors have positive effects on performance 
compared to the baseline, and our approach 
integrating all the factors achieves the best 
performance; 2)  EP significantly improves F1 of 
EM without much improvement on F1 of HM or 
PM, showing that EP’s major contribution lies in 
exact match; 3) The major contribution of HC is 
the improvement of F1s of HM and PM, showing 
the automatically identified opinion holders are 
quite helpful for finding opinion targets; 4) 
SP+EP+HC improves the performance in terms of 
all three metrics; and our approach further 
improves the performance by adding HR. 

5.3 Discussion 
Here we compare our results with those reported at 
NTCIR-7 MOAT traditional Chinese test (Seki et 
al., 2008). Without considering the errors in the 
previous step, the highest F1s for opinion holder 
analysis reported by the four participants were 
respectively 82.5%, 59.9%, 50.3% and 59.5%, and 
the highest F1s for target reported by the three 
participants were respectively 60.6%, 2.1% and 
3.6%. Compared to the results at NTCIR-7, our 
performances on both opinion holder identification 
in Table 1 and that on target identification in Table 
2 seem quite encouraging even by the EM metrics.  

Consider the evaluation for opinion 
holders/targets was semi-automatic at NTCIR-7. 
We should note that although the generated 
standard had been supplemented by the 
participants’ submissions, some correct answers 
may still be missing, especially for targets since 
only three teams participated in the target 

50



 

identification task and the recalls were not high. 
Thus the performance reported in Table 1 and 2 
may be underestimated. 

Here we also give an estimate on the 
percentages of opinionated sentences containing 
both opinion holders and at least one reporting 
verb in NTCIR-6 and NTCIR-7’s traditional 
Chinese test data, which are respectively 94.5% 
and 83.9%. The high percentages show that 
reporting verbs are very common in news report.  

6 Conclusion and Future Work 
In this paper, we investigate the problem of 
identifying opinion holders/targets in opinionated 
sentences of Chinese news texts based on Chinese 
dependency parser, reporting verbs and opinion-
bearing words. Our proposed approach shows 
encouraging performance on opinion holder/target 
identification with the NTCIR-7’s traditional 
Chinese test data, and outperforms most systems 
reported at NTCIR-7 and the baseline methods 
including the CRF-based model.  

The proposed approach is highly dependent on 
dependency parser, and we would like to further 
investigate machine learning approaches (including 
the CRF model) by treating dependency structures 
as one of the linguistic features, which could be 
more robust to parsing errors. Opinion targets are 
more difficult to be identified than opinion holders, 
and deserve more attention in the NLP field, and 
we also would extend the targets to verb phrases 
and embedded clauses in addition to noun phrases. 
To explore the effectiveness of our approach with 
English data such as MPQA is another direction. 

Acknowledgements 
We acknowledge the help of our colleagues 
(Professor Benjamin K. Tsou and Mr. Jiang Tao). 

Reference 
Steven Bethard, Hong Yu, Ashley Thornton, Vasileios 

Hatzivassiloglou, and Dan Jurafsky. 2004. Automatic 
Extraction of Opinion Propositions and their Holders, 
AAAI Spring Symposium on Exploring Attitude and 
Affect in Text: Theories and Applications. 

Yejin Choi, Claire Cardie, Ellen Riloff, and Siddharth 
Patwardhan. 2005. Identifying sources of opinions 
with conditional random fields and extraction 
patterns. In Proc. of HLT/EMNLP-05. 

Vasileios Hatzivassiloglou and Kathleen McKeown. 
1997. Predicting the Semantic Orientation of 
Adjectives. In Proc. of ACL-97. 174-181. 

Minqing Hu and Bing Liu. 2004. Mining Opinion 
Features in Customer Reviews. In Proc. of AAAI-04. 

Soo-Min Kim and Eduard Hovy. 2005. Identifying 
Opinion Holders for Question Answering in Opinion 
Texts, In Proc. of AAAI-05 Workshop on Question 
Answering in Restricted Domains. Pittsburgh, PA. 

Soo-Min Kim and Eduard Hovy. 2006. Extracting 
opinions, opinion holders, and topics expressed in 
online news media text, In Proc. of ACL Workshop 
on Sentiment and Subjectivity in Text.  

Youngho Kim, Seongchan Kim, and Sung-Hyon 
Myaeng. 2008. Extracting Topic-related Opinions 
and their Targets in NTCIR-7, Proc. of NTCIR-7 
Workshop, Tokyo, Japan. 

Lun-Wei Ku, I-Chien Liu, Chia-Ying Lee, Kuan-hua 
Chen and Hsin-Hsi Chen. 2008. Sentence-Level 
Opinion Analysis by CopeOpi in NTCIR-7. In Proc. 
of NTCIR-7 Workshop. Tokyo, Japan. 

Jinshan Ma, Yu Zhang, Ting Liu and Sheng Li. 2004. A 
statistical dependency parser of Chinese under small 
training data. IJCNLP-04 Workshop: Beyond shallow 
analyses - Formalisms and statistical modeling for 
deep analyses. 

Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 
2002. Thumbs up? Sentiment classification using 
machine learning techniques. In Proc. of EMNLP-02. 

Josef Ruppenhofer, Swapna Somasundaran, Janyce 
Wiebe. 2008. Finding the Sources and Targets of 
Subjective Expressions. In Proc. of LREC 2008. 

Yohei Seki, David Kirk Evans, Lun-Wei Ku, and et al. 
2007. Overview of Opinion Analysis Pilot Task at 
NTCIR-6. Proc. of the NTCIR-6 Workshop.  

Yohei Seki, David Kirk Evans, Lun-Wei Ku, and et al. 
2008. Overview of Multilingual Opinion Analysis 
Task at NTCIR-7. Proc. of the NTCIR-7 Workshop. 
Japan. 2008. 12. 

Jilin Shi and Yinggui Zhu. 2006. The Lexicon of 
Chinese Positive Words (褒義詞詞典 ). Sichuan 
Lexicon Press. 

Veselin Stoyanov and Claire Cardie. 2008. Topic 
Identification for Fine-Grained Opinion Analysis. In 
Proc. of COLING-08. 

Peter D. Turney. 2002. Thumbs up or thumbs down? 
Semantic orientation applied to unsupervised 
classification of reviews, In Proc. of ACL-02. 

Theresa Wilson and Janyce Wiebe. 2003. Annotating 
opinions in the world press. Proc. of the 4th ACL 
SIGdial Workshop on Discourse and Dialogue 
(SIGdial-03). 

Ruifeng Xu, Kam-Fai Wong and Yunqing Xia. 2008. 
Coarse-Fine Opinion Mining - WIA in NTCIR-7 
MOAT Task. Proc. of the 7th NTCIR Workshop. 

Ling Yang and Yinggui Zhu. 2006. The Lexicon of 
Chinese Negative Words (貶義詞詞典 ). Sichuan 
Lexicon Press. 

51


