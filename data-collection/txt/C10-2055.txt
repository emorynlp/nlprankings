481

Coling 2010: Poster Volume, pages 481–489,

Beijing, August 2010

Bilingual lexicon extraction from comparable corpora using

in-domain terms

Department of Computer Science

Department of Computer Science

Azniah Ismail

University of York

Suresh Manandhar

University of York

azniah@cs.york.ac.uk

suresh@cs.york.ac.uk

Abstract

Many existing methods
for bilingual
lexicon learning from comparable corpora
are based on similarity of context vectors.
These methods suffer from noisy vectors
that greatly affect their accuracy. We
introduce a method for ﬁltering this noise
allowing highly accurate learning of
bilingual lexicons. Our method is based
on the notion of in-domain terms which
can be thought of as the most important
contextually relevant words. We provide
a method for
identifying such terms.
Our evaluation shows that the proposed
method can learn highly accurate bilin-
gual lexicons without using orthographic
features or a large initial seed dictionary.
In addition, we also introduce a method
for measuring the similarity between
two words in different languages without
requiring any initial dictionary.

Introduction

1
In bilingual lexicon extraction, the context-based
approach introduced by Rapp (1995) is widely
used (Fung, 1995; Diab and Finch, 2000; among
others). The focus has been on learning from
comparable corpora since the late 1990s (Rapp,
1999; Koehn and Knight, 2002; among others).
However, so far, the accuracy of bilingual lexi-
con extraction using comparable corpora is quite
poor especially when orthographic features are
not used. Moreover, when orthographic features
are not used, a large initial seed dictionary is es-
sential in order to acquire higher accuracy lexicon
(Koehn and Knight, 2002). This means that cur-

rent methods are not suitable when the language
pairs are not closely related or when a large initial
seed dictionary is unavailable.

When learning from comparable corpora, a
large initial seed dictionary does not necessarily
guarantee higher accuracy since the source and
target texts are poorly correlated. Thus, inducing
highly accurate bilingual lexicon from compara-
ble corpora has so far been an open problem.

In this paper, we present a method that is able
to improve the accuracy signiﬁcantly without re-
quiring a large initial bilingual dictionary. Our
approach is based on utilising highly associated
terms in the context vector of a source word.
For example, the source word powers is highly
associated with the context word delegation. We
note that, ﬁrstly, both share context terms such as
parliament and affairs. And, secondly, the trans-
lation equivalents of powers and delegation in the
target language are not only highly associated but
they also share context terms that are the trans-
lation equivalents of parliament and affairs (see
Figure 1).

2 Related work

Most of the early work in bilingual lexicon ex-
traction employ an initial seed dictionary. A large
bilingual lexicon with 10k to 20k entries is neces-
sary (Fung, 1995; Rapp, 1999).

Koehn and Knight (2002) introduce techniques
for constructing the initial seed dictionary auto-
matically. Their method is based on using identi-
cal spelling features. The accuracy of such initial
bilingual lexicon is almost 90.0 percent and can
be increased by restricting the word length (Koehn
and Knight, 2002). Koehn and Knight found ap-
proximately 1000 identical words in their German

482

Figure 1: An example of in-domain terms that co-occur in English and Spanish. The source word is
powers and the target word is poderes. The word delegation and delegacion are the highly associated
words with the source word and the target word respectively. Their in-domain terms, as shown in the
middle, can be used to map the source word in context of word delegation to its corresponding target
word in context of delegacion.

and English monolingual corpora. They expanded
the lexicon with the standard context-based ap-
proach and achieved about 25.0 percent accuracy
(Koehn and Knight, 2002).

Similar techniques were used in Haghighi et
(2008) who employ dimension reduction in
al.
the extraction method. They recorded 58.0 per-
cent as their best F1 score for the context vec-
tor approach on non-parallel comparable corpora
containing Wikipedia articles. However,
their
method scores less on comparable corpora con-
taining distinct sentences derived from the Eu-
roparl English-Spanish corpus.

3 Learning in-domain terms
In the standard context vector approach, we as-
sociate each source word and target word with
their context vectors. The source and target con-
text vectors are then compared using the initial
seed dictionary and a similarity measure. Learn-

ing from comparable corpora is particularly prob-
lematic due to data sparsity, as important context
terms may not occur in the training corpora while
some may occur but with low frequency and can
be missed. Some limitations may also be due to
the size of the initial seed dictionary being small.
The initial seed dictionary can also contribute
irrelevant or less relevant features that can mis-
lead the similarity measure especially when the
number of dimensions is large. The approach we
adopt attempts to overcome this problem.

In Figure 1, for the source word powers, dele-
gation is the highly associated word. Both powers
and delegation share common contextual terms
such as parliament and affairs. Now the transla-
tion equivalent of delegation is delegacion. For
the potential translation equivalent poderes, we
see that the common contextual terms shared by
powers and poderes are terms parlamento (par-
liament) and asuntos (affairs).

483

Figure 2: An example of English-Spanish lexicon learnt for the source word powers. On the top,
the system suggested competencias and rejected poderes when powers is associated with community,
democracy or independence. The word poderes is suggested when powers is associated with justice or
delegation.

We observe that

these common contextual
terms are simultaneously the ﬁrst-order and
second-order context terms of the target word.
They are the shared context terms of the target
word and its highly associated context term. We
deﬁne these terms as in-domain terms. These in-
domain terms can be used to map words to their
corresponding translations. The highly associated
context terms can be thought of as sense discrim-
inators that differentiate the different uses of the
target word. In Figure 2, we show how delegation
helps in selecting between the “control or inﬂu-
ence” sense of powers while rejecting the “ability
or skill” sense.

In this paper, our focus is not on sense disam-
biguation and we follow current evaluation meth-
ods for bilingual lexicon extraction. However, it is
clear that our method can be adapted for building
sense disambiguated bilingual lexicons.

Identifying highly associated words

3.1
To identify the context terms CT (WS) of a source
word WS, as in (Rapp, 1999), we use log-
likelihood ratio (LL) Dunning (1993). We choose
all words with LL > t1 where t1 is a threshold.

The highly associated words then are the top k
highest ranked context terms. In our experiments,
we only choose the top 100 highest ranked context
terms as our highly associated terms.

In order to compute the log-likelihood ratio of
target word a to co-occur with context word b, we

create a contingency table. The contingency table
contains the observed values taken from a given
corpus. An example of the contingency table is
shown in Table 1.

C[i,j]
powers
¬ powers

community ¬ community

124

1831

11779

11903

460218

462049

C(community)

C(¬ community)

1955
C(powers)
471997 C(¬ powers)

Here C[i, j] denotes the count of the number of sentences in
which i co-occurs with j.
Total corpus size: N = 473952 in the above

Table 1: Contingency table for observed values of
target word powers and context word community.

The LL value of a target word a and context

word b is given by:

LL(a, b) =

Xi∈{a,¬a},j∈{b,¬b}

2C(i, j) log

C(i, j)N
C(i) C(j)

Identifying in-domain terms

3.1.1
In our work, to ﬁnd the translation equivalent of a
source word WS, we do not use the context terms
CT (WS).
Instead, we use the in-domain terms
IDT (WS, WR). For each highly associated term

484

WR, we get different in-domain terms. Further-
more, IDT (WS, WR) is a subset of CT (WS).

The in-domain terms of WS given the context

terms WR is given by:

In the next section, we introduce a similarity
measure that operates on the context vectors in the
source language and the target language without
requiring a seed dictionary.

ID(WS, WR) = CT (WS) ∩ CT (WR)

Programme and public are some of the examples
of in-domain terms of powers given community as
the highly associated term.

3.1.2 Finding translations pairs

Note that ID(WS, WR) is an in-domain term
vector in the source language. Let WT be a
potential
Let,
tr(WR) be a translation equivalent for WR. Let
ID(WT , tr(WR)) be an in-domain term vector in
the target language.

translation equivalent for WS.

We use tr(WS|WR) to denote the translation
proposed for WS given the highly associated term
WR. We compute tr(WS|WR) using:

tr(WS|WR) =

argmax

sim(ID(WS, WR), ID(WT , tr(WR)))

WT

Our method learns translation pairs that are
conditioned on highly associated words (WR). Ta-
ble 2 provides a sample of English-Spanish lexi-
con learnt for the word power with different WR.

English

Spanish

WS

WR

tr(WR)

WT

community

comunidad

poderes

competencias

independiente

competencias

democracy

democracia

poderes

independiente

competencias

powers

independence

independencia

poderes

independiente

poderes

justice

justicia

competencias

independiente

poderes

delegation

delegacion

competencias

independiente

Sim

0.9876

0.9744

0.9501

0.9948

0.9915

0.9483

0.9939

0.9745

0.9633

0.9922

0.3450

0.9296

0.9568

0.9266

0.8408

4 Rank-binning similarity measure

Most existing methods for computing similarity
cannot be directly employed for measuring the
similarity between in-domain term context vec-
tors since each context vector is in a different lan-
guage. A bilingual dictionary can be assumed
but that greatly diminishes the practicality of the
method.

We address this by making an assumption. We
assume that the relative distributions of in-domain
context terms of translation equivalent pairs are
roughly comparable in the source language and
in the target language. For example, consider
the log-likelihood values of the in-domain terms
for the translation pair agreement-acuerdo (condi-
tioned on the highly associated term association-
associacion) given in Figure 3. We note that the
distribution of in-domain terms are comparable al-
though not identical. Thus, the distribution can be
used as a clue to derive translation pairs but we
need a method to compute similarity of the vector
of in-domain terms.

Rank-binning or rank histograms are usually
used as a diagnostic tool to evaluate the spread of
an ensemble rather than as a veriﬁcation method.
Wong (2009) use the method of rank-binning to
roughly examine performance of a system on
learning lightweight ontologies. We apply the
rank-binning procedure for measuring the similar-
ity of word pairs.

Pre-processing step:

1. Let WS be a source language word and
x1, x2, ..., xn be the set of n context terms
ranked in descending log-likelihood values
of WS (see Table 3).

2. We transform the rank values of context

terms xk into the range [0,1] using:

Table 2: A sample of translation equivalents learnt
for powers.

zk =

rank(xk) − 1

n − 1

485

CT (powers)

Context term
european

legislative

parliament

:

:

:

public

programme

representatives

n = 247

LL

rank

zk

491.33

482.19

408.26

:

:

:

16.96

15.40

15.32

1

2

3

:

:

:

245

246

247

0.00000

0.00406

0.00813

:

:

:

0.99186

0.99593

1.00000

Table 3: Some examples of transformed values of
each term in CT (powers).

In the next section, we describe the setup in-
cluding the data, the lexicon and the evaluation
used in our experiments.

5 Experimental setup
5.1 Data
For comparable text, we derive English and Span-
ish distinct sentences from the Europarl parallel
corpora. We split the corpora into three parts ac-
cording to year. We used about 500k sentences
for each language in the experiments. This ap-
proach is further explained in Ismail and Man-
andhar (2009) and is similar to Koehn and Knight
(2001) and Haghighi et al. (2008).

5.2 Pre-processing
For corpus pre-processing, we use sentence
boundary detection and tokenization on the raw
text before we clean the tags and ﬁlter stop words.
We sort and rank words in the text according to
their frequencies. For each of these words, we
compute their context term log-likelihood values.

5.3 Lexicon
In the experiment, a bilingual lexicon is required
for evaluation. We extract our evaluation lexicon
from the Word Reference2 free online dictio-
nary. This extracted bilingual lexicon has low cov-
erage.

Figure 3: Similar distribution of in-domain terms
for agreement with association and acuerdo with
asociacion.

Binning procedure
We divide the interval [0, 1] into g bins1 of equal
length. Let b1, . . . , bg denote the g bins. Then
we map the in-domain terms vector ID(WS, WR)
into the binned vector b1, . . . , bg. For each xk ∈
ID(WS, WR), this mapping is done by using the
corresponding zk from the pre-processing step.
For each bin, we count the number of different in-
domain terms that are mapped into this bin. Thus,
if the range of the ﬁrst bin b1 is [0, 0.009] then eu-
ropean, legislative, parliament are mapped into b1
i.e. b1 = 3. The bins are normalised by dividing
with | ID(WS, WR) |.
Rank binning similarity
We use Euclidean distance to compute similarity
between bins. Given, bins P = p1, . . . , pg and
Q = q1, . . . , qg, the Euclidean distance is given
by:

dist(P, Q) =vuut
gXi=1

(pi, qi)2

1We used the following formula to estimate the number

of bins:

g = 1 + 3.3 ∗ log (| ID(WS, WR) |)

2http://wordreference.com

486

5.4 Evaluation
In the experiments, we considered the task of
building a bilingual English-Spanish lexicon be-
tween the 2000 high frequency source and target
words, where we required each individual word
to have at least a hundred highly associated con-
text terms that are not part of the initial seed dic-
tionary. Different highly associated WR terms
for a given WT might derive similar (WS, WT )
In this case, we only considered one of
pairs.
the (WS, WT ) pairs.
In future work, we would
like to keep these for word sense discrimination
purposes. Note that we only considered proposed
translation pairs whose similarity values are above
a threshold t2.

We used the F1 measure to evaluate the pro-
posed lexicon against the evaluation lexicon.
If
either WS or WT in the proposed translation pairs
is not in the evaluation lexicon, we considered the
translation pairs as unknown, although the pro-
posed translation pairs are correct. Recall is de-
ﬁned as the proportion of the proposed lexicon di-
vided by the size of the lexicon and precision is
given by the number of correct translation pairs at
a certain recall value.

6 Experiments

In this section, we look into how the in-domain
context vectors affect system performance. We
also examine the potential of rank-binning simi-
larity measure.

6.1 From standard context vector to

in-domain context vector

Most research in bilingual lexicon extraction so
far has employed the standard context vector ap-
proach.
In order to explore the potential of the
in-domain context vectors, we compare the sys-
tems that use in-domain approach against systems
that use the standard approach. We also employ
different sets of seed lexicon in each system to be
used in the similarity measure:

• Lex700: contains 700 cognate pairs from a

few Learning Spanish Cognate websites3.

3such as http://www.colorincolorado.org

and http://www.language-learning-advisor.com

• Lex100: contains 100 bilingual entries of the
most frequent words in the source corpus that
have translation equivalents in the extracted
evaluation lexicon. We select the top one
hundred words in the source corpus, so that
their translation equivalents is within the ﬁrst
2000 high frequency words in the target cor-
pus.

• Lex160: contains words with similar spelling
that occur in both corpora. We used 160
word pairs with an edit distance value less
than 2, where each word is longer than 4
characters.

Models using the standard approach are de-
noted according to the size of the particular lex-
icon used in their context similarity measure,
i.e. CV-100 for using Lex100, CV-160 for using
Lex160 and CV-700 for using Lex700. We use IDT
to denote our model. We use lexicon sizes to dis-
tinguish the different variants, e.g. IDT-CV100 for
using Lex100, IDT-CV160 for using Lex160 and
IDT-CV700 for using Lex700.

With CV-700, the system achieved 52.6 per-
cent of the best F1 score. Using the same seed
dictionary, the best F1 score has increased about
20 percent points with IDT-CV700 recorded 73.1
percent. IDT-CV100 recorded about 15.0 percent
higher best F1 score than CV-100 with 80.9 and
66.4 percent respectively. Using an automatically
derived seed dictionary, IDT-CV160 yielded 70.0
percent of best F1 score while CV-160 achieved
62.4 percent. Results in Table 4 shows various
precisions px at recall values x.

Model
CV-700

CV-100

CV-160

IDT-CV700

IDT-CV100

IDT-CV160

P0.10

P0.25

P0.33

P0.50

BestF1score

58.3

52.0

68.5

83.3

80.0

90.0

61.2

53.0

56.8

90.2

75.8

80.6

64.8

47.2

48.8

82.0

66.7

73.9

55.2

44.8

48.8

66.7

69.4

69.2

52.6

66.4

62.4

73.1

80.9

70.0

Table 4: Performance of different models.

487

6.2 Similarity measure using rank-binning
We use RB to denote our model based on the
rank-binning approach. Running RB means that
no seed dictionary is involved in the similarity
measure. We also ran the similarity measure in
the IDT (IDT-RB160) by employing the derived
Lex160 for the in-domain steps.

We ran several tests using IDT-RB160 with dif-
ferent numbers of bins. The results are illustrated
in Figure 4. The IDT-RB160 yielded 63.7 percent
of best F1 score with 4 bins. However, the F1
score starts to drop from 61.1 to 53.0 percent with
6 and 8 bins respectively. With 3 and 2 bins the
IDT-RB160 yielded 63.7 and 62.0 percent of best
F1 score respectively. Using 1 bin is not be pos-
sible as all values fall under one bin. Thus, the
rank-binning similarity measure for the rest of the
experiments where RB is mentioned, refers to a 4
bins setting.

Figure 4: Performance of IDT-RB160 with differ-
ent numbers of bins.

While systems using the standard context simi-
larity measure yielded scores higher than 50.0 per-
cent of best F1, the RB achieved only 39.2 per-
cent. However, RB does not employ an initial
dictionary and does not use orthographic features.
As mentioned above, the system scored higher
when the similarity measure was used in the IDT
(i.e. IDT-RB160). Note that Lex160 is derived au-
tomatically so the approach can also be consid-
ered as unsupervised. The system performance
is slightly lower compared to the conventional

CV-160. However, IDT-CV160 outperforms both
of the systems (see Figure 5).

Figure 5: Performance of different unsupervised
models.

Overall, systems that exploit in-domain terms
yielded higher F1 scores compared to the conven-
tional context vector approach.

6.3 Comparison with CCA
Previous work in extracting bilingual lexicons
from comparable corpora generally employ the
conventional context vector approach. Haghighi
et al. (2008) focused on applying canonical cor-
relation analysis (CCA), a dimension reduction
technique, to improve the method. They were us-
ing smaller comparable corpora, taken from the
ﬁrst 50k sentences of English Europarl and the
second 50k of Spanish Europarl, and different ini-
tial seed dictionary. Hence, we tested CCA in our
experimental setup. In CV-700 setting, using CCA
yields 57.5 percent of the best F1 score compared
to 73.1 percent of the best F1 score with IDT that
we reported in Section 6.2.

7 Discussion
7.1 Potential of in-domain terms
Our experiments clearly demonstrate that the use
of in-domain terms achieves higher F1 scores
compared to conventional methods. It also shows
that our method improves upon earlier reported
dimension reduction methods. From our obser-
vation, the number of incorrect translation pairs

488

were further reduced when the context terms were
ﬁltered. Recall that the in-domain terms in the
target language were actually the shared context
terms of the target word and its highly associ-
ated context terms. Nevertheless, this approach
actually depends on the initial bilingual lexicon
in order to translate those highly associated con-
text terms into the source language. Table 5
shows some examples of most conﬁdence trans-
lation pairs proposed by the IDT-CV100.

English
principle

government

government

resources

difﬁcult

Spanish
principio

estado

gobierno

recursos

diﬁcil

sector

sector

competencia

sector

programme

programa

programme

comunidad

agreement

acuerdo

Sim score Correct?

0.9999

0.9999

0.9999

0.9999

0.9999

0.9998

0.9998

0.9998

0.9998

0.9998

Yes

No

Yes

Yes

Yes

No

Yes

Yes

No

Yes

Table 5: Some examples of most conﬁdent trans-
lation pairs proposed by IDT-CV100 ranked by
similarity scores.

7.2 Seed dictionary variation
The initial seed dictionary plays a major role in
extracting bilingual lexicon from comparable cor-
pora. There are a few different ways for us to
derive a seed dictionary. Recall that Lex700 and
Lex100, that are used in the experiments, are de-
rived using different methods. The F1 scores of
the system using Lex100 were much higher com-
pared to the system using Lex700. Thus, extend-
ing Lex100 with additional high frequency words
may provide higher accuracy.

One important reason is that all bilingual en-
tries in Lex100 occur frequently in the corpora.
Although the size of Lex700 is larger, it is not sur-
prising that most of the words never occur in the
corpora, such as volleyball and romantic. How-
ever, using Lex160 is more interesting since it is
derived automatically from the corpora, though
one should realize that the relationship between
the language pair used in the respective mono-

lingual corpora, English and Spanish, may have
largely affect the results. Thus, for other sys-
tems involving unrelated language pairs, the rank-
binning similarity measure might be a good op-
tion.

7.3 Word sense discrimination ability
As mentioned in Section 5.4, each source word
may have more than one highly associated context
term, WR. Different WR may suggest different
target words for the same source word. For exam-
ple, given the source word powers and the highly
associated word community, competencias is pro-
posed as the best translation equivalent. On the
other hand, for same source word powers, when
the highly associated word is delegation, the tar-
get word poderes is suggested.

8 Conclusion
We have developed a method to improve the F1
score in extracting bilingual lexicon from compa-
rable corpora by exploiting in-domain terms. This
method also performs well without using an ini-
tial seed dictionary. More interestingly, our work
reveals the potential of building word sense dis-
ambiguated lexicons.

References
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick
and Dan Klein. 2008. Learning bilingual lexicons
from monolingual corpora.
In ACL 2008, Colum-
bus, Ohio.

Azniah Ismail and Suresh Manandhar. 2009. Utiliz-
ing contextually relevant terms in bilingual lexicon
extraction In Workshop on Unsupervised and Min-
imally Supervised Learning of Lexical Semantics,
Boulder, Colorado.

Mona Diab and Steve Finch. 2000. A statistical word-
level translation model for comparable corpora. In
Proceedings of the Conference on Content-based
multimedia information access (RIAO).

Pascale Fung. 1995. Compiling bilingual lexicon en-
tries from a non-parallel English-Chinese corpus. In
Proceedings of the 3rd Annual Workshop on Very
Large Corpora, Boston, Massachusetts, 173-183.

Philipp Koehn and Kevin Knight. 2001. Knowledge
sources for word-level translation models. In Pro-
ceedings of the Conference on empirical method in
natural language processing (EMNLP).

489

Philipp Koehn and Kevin Knight. 2002. Learning a
translation lexicon from monolingual corpora.
In
Proceedings of the ACL 2002, Philadelphia, USA,
9-16.

Reinhard Rapp. 1995.

Identifying word translations
in non-parallel texts. In Proceedings of the ACL 33,
320-322.

Reinhard Rapp. 1999. Automatic identiﬁcation of
word translations from unrelated English and Ger-
man corpora. In Proceedings of the ACL 37, 519-
526.

Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistic, volume 19(1), 61-74.

Wilson Yiksen Wong. 2009. Learning lightweight on-
tologies from text across different domains using the
web as background knowledge. Ph.D. Thesis. Uni-
versity of Western Australia

