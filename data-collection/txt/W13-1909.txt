










































Recognizing Sublanguages in Scientific Journal Articles through Closure Properties


Proceedings of the 2013 Workshop on Biomedical Natural Language Processing (BioNLP 2013), pages 72–79,
Sofia, Bulgaria, August 4-9 2013. c©2013 Association for Computational Linguistics

Recognizing sublanguages in scientific journal articles
through closure properties

Irina P. Temnikova
Linguistic Modelling Laboratory
Bulgarian Academy of Sciences

irina.temnikova@gmail.com

K. Bretonnel Cohen
Computational Bioscience Program

University of Colorado School of Medicine
Department of Linguistics

University of Colorado at Boulder
kevin.cohen@gmail.com

Abstract

It has long been realized that sublanguages
are relevant to natural language process-
ing and text mining. However, practical
methods for recognizing or characterizing
them have been lacking. This paper de-
scribes a publicly available set of tools for
sublanguage recognition. Closure proper-
ties are used to assess the goodness of fit
of two biomedical corpora to the sublan-
guage model. Scientific journal articles
are compared to general English text, and
it is shown that the journal articles fit the
sublanguage model, while the general En-
glish text does not. A number of examples
of implications of the sublanguage char-
acteristics for natural language processing
are pointed out. The software is made pub-
licly available at [edited for anonymiza-
tion].

1 Introduction

1.1 Definitions of “sublanguage”

The notion of sublanguage has had varied defini-
tions, depending on the aspects of sublanguages
on which the authors focused. (Grishman and Kit-
tredge, 1986) focus on syntactic aspects of sub-
languages: “. . . the term suggests a subsystem of
language. . . limited in reference to a specific sub-
ject domain. In particular, each sublanguage has
a distinctive grammar, which can profitably be
described and used to solve specific language-
processing problems” (Grishman and Kittredge,
1986).

(Kittredge, 2003) focuses on the spontaneous
appearance of sublanguages in restricted domains,
where the preconditions for a sublanguage to ap-
pear are the sharing of specialized knowledge
about a restricted semantic domain and recurrent

“situations” (e.g. scientific journal articles, or dis-
charge summaries) in which domain experts com-
municate. According to (Kittredge, 2003), charac-
teristics of a sublanguage include a restricted lexi-
con, relatively small number of lexical classes, re-
stricted sentence syntax, deviant sentence syntax,
restricted word co-occurrence patterns, and differ-
ent frequencies of occurrence of words and syn-
tactic patterns from the normal language.

(McDonald, 2000) focuses on the element of re-
striction in sublanguages—the notion that they are
restricted to a specialized semantic domain, a very
“focused” audience, and “stipulated content,” with
the effect that both word choice and syntactic style
have reduced options as compared to the normal
language.

The notions of restriction that recur in these
definitions of “sublanguage” lead directly to
(McEnery and Wilson, 2001)’s notion of using
the quantification of closure properties to assess
whether or not a given sample of a genre of lan-
guage use fits the sublanguage model. Closure
refers to the tendency of a genre of language to-
wards finiteness at one or more linguistic levels.
For example, a genre of language might or might
not use a finite set of lexical items, or have a fi-
nite set of sentence structures. Notions of restric-
tion suggest that a sublanguage should tend to-
wards closure on at least some linguistic levels.
To quantify closure, we can examine relationships
between types and tokens in a corpus of the genre.
In particular, we count the number of types that
are observed as an increasing number of tokens
is examined. If a genre does not exhibit closure,
then the number of types will continue to rise con-
tinually as the number of tokens increases. On
the other hand, closure is demonstrated when the
number of types stops growing after some number
of tokens has been examined.

72



1.2 Relevance of sublanguages to natural
language processing

The relevance of sublanguages to natural language
processing has long been recognized in a vari-
ety of fields. (Hirschman and Sager, 1982) and
(Friedman, 1986) show how a sublanguage–based
approach can be used for information extraction
from clinical documents. (Finin, 1986) shows that
sublanguage characterization can be used for the
notoriously difficult problem of interpretation of
nominal compounds. (Sager, 1986) asserts a num-
ber of uses for sublanguage–oriented natural lan-
guage processing, including resolution of syntac-
tic ambiguity, definition of frames for informa-
tion extraction, and discourse analysis. (Sekine,
1994) describes a prototype application of sublan-
guages to speech recognition. (Friedman et al.,
1994) uses a sublanguage grammar to extract a va-
riety of types of structured data from clinical re-
ports. (McDonald, 2000) points out that modern
language generation systems are made effective in
large part due to the fact that they are applied to
specific sublanguages. (Somers, 2000) discusses
the relevance of sublanguages to machine trans-
lation, pointing out that many sublanguages can
make machine translation easier and some of them
can make machine translation harder. (Friedman
et al., 2001) uses a sublanguage grammar to ex-
tract structured data from scientific journal arti-
cles.

1.3 Previous work on sublanguage
recognition

Various approaches have been taken to recog-
nizing sublanguages. We posit here two sepa-
rate tasks—recognizing a sublanguage when one
is present, and determining the characteristics of
a sublanguage. Information-theoretic approaches
have a long history. (Sekine, 1994) clustered docu-
ments and then calculated the ratio of the perplex-
ity of the clustered documents to the perplexity
of a random collection of words. (Somers, 1998)
showed that texts drawn from a sublanguage cor-
pus have low weighted cumulative sums. (Stetson
et al., 2002) used relative entropy and squared chi-
square distance to identify a sublanguage of cross-
coverage notes. (Mihaila et al., 2012) looked at
distributions of named entities to identify and dif-
ferentiate between a wide variety of scientific sub-
languages.

Non-information-theoretic, more heuristic

methods have been used to identify sublanguages,
as well. In addition to the information-theoretic
measures described above, (Stetson et al., 2002)
also looked at such measures as length, incidence
of abbreviations, and ambiguity of abbreviations.
(Friedman et al., 2002) use manual analysis to
detect and characterize two biomedical sublan-
guages. (McEnery and Wilson, 2001) examine
closure properties; their approach is so central to
the topic of this paper that we will describe it in
some length separately.

(McEnery and Wilson, 2001) examined the clo-
sure properties of three linguistic aspects of their
material under study. As materials they used two
corpora that were assumed not to meet the sub-
language model—the Canadian Hansard corpus,
containing proceedings from the Canadian Parlia-
ment, and the American Printing House for the
Blind corpus, made up of works of fiction. As
a corpus that was suspected to meet the sublan-
guage model, they used a set of manuals from
IBM. All three corpora differed in size, so they
were sampled to match the size of the smallest
corpus, meaning that all experiments were done
on collections 200,000 words in size. The mate-
rials under study were evaluated for their closure
properties at three linguistic levels. At the most
basic level, they looked at lexical items—simple
word forms. The hypothesis here was that the non-
sublanguage corpora would not tend toward finite-
ness, i.e. would not reach closure. That is, if the
number of word types found was graphed as an
increasing number of tokens was examined, the
resulting line would grow continually and would
show no signs of asymptoting. In contrast, the
sublanguage corpus would eventually reach clo-
sure, i.e. would stop growing appreciably in size
as more tokens were examined.

The next level that they examined was the mor-
phosyntactic level. In particular, they looked at
the number of part-of-speech tags per lexical type.
Here the intuition was that if the lexicon of the
sublanguage is limited, then words might be co-
erced into a greater number of parts of speech.
This would be manifested by a smaller overall
number of unique word/part-of-speech tag combi-
nations. Again, we would expect to see that the
sublanguage corpus would have a smaller number
of word/part-of-speech tag combinations, as com-
pared to the non-sublanguage corpus. Graphing
the count of word type/POS tag sets on the y axis

73



and the cumulative number of tokens examined on
the x axis, we would see slower growth and lower
numbers overall.

The final level that they examined was the syn-
tactic level. In this case, parse tree types were
graphed against the number of sentences exam-
ined. The intuition here is that if the sublanguage
exhibits closure properties on the syntactic level,
then the growth of the line will slow and we will
see lower numbers overall.

(McEnery and Wilson, 2001) found the hy-
potheses regarding closure to be substantiated at
all levels. We will not reproduce their graphs,
but will summarize their findings in terms of ra-
tios. On the lexical level, they found type/token
ratios of 1:140 for the IBM manuals (the assumed
sublanguage), 1:53 for the Hansard corpus (as-
sumed not to represent a sublanguage), and 1:17
for the American Printing House for the Blind cor-
pus (also assumed not to represent a sublanguage).
The IBM manuals consist of a much smaller num-
ber of words which are frequently repeated.

At the morphosyntactic level, they found 7,594
type/POS sets in the IBM manuals, 18,817 in
the Hansard corpus, and 11,638 in the Ameri-
can Printing House for the Blind corpus–a much
smaller number in the apparent sublanguage than
in the non-sublanguage corpora. The word/part-
of-speech tag averages coincided with the ex-
pected findings given these number of types. The
averages were 3.19 for the IBM manuals, 2.45 for
the Hansard corpus, and 2.34 for the American
Printing House for the Blind corpus.

At the syntactic level, they found essentially lin-
ear growth in the number of sentence types as the
number of sentence tokens increased in the two
non-sublanguage corpora—the ratio of sentence
types to sentences in these corpora were 1:1.07 for
the Hansard corpus and 1:1.02 for the American
Printing House for the Blind corpus. In contrast,
the growth of sentence types in the IBM manu-
als was not quite linear. It grew linearly to about
12,000 sentences, asymptoted between 12,000 and
16,000, and then grew essentially linearly but at a
somewhat slower rate from 16,000 to 30,000 sen-
tences. The ratio of sentence types to sentence to-
kens in the IBM manuals was 1:1.66—markedly
higher than in the other two corpora.

1.4 Hypotheses tested in the paper
The null hypothesis is that there will be no differ-
ence in closure properties between the general En-
glish corpus and the two corpora of scientific jour-
nal articles that we examine. If the null hypothesis
is not supported, then it might be deviated from in
three ways. One is that the scientific corpora might
show a greater tendency towards closure than the
general English corpus. A second is that the gen-
eral English corpus might show a greater tendency
towards closure than the scientific corpora. A third
is that there may be no relationship between the
closure properties of the two scientific corpora, re-
gardless of the closure properties of the general
English corpus—one might show a tendency to-
wards closure, and the other not.

2 Materials and Methods

2.1 Materials
The data under examination was drawn from three
sources: the CRAFT corpus (Bada et al., 2012;
Verspoor et al., 2012), the GENIA corpus (Kim
et al., 2003), and a version of the British National
Corpus (Leech et al., 1994) re-tagged with Con-
nexor’s Machinese parser (Järvinen et al., 2004).
The CRAFT and GENIA corpora are composed
of scientific journal articles, while the British Na-
tional Corpus is a representative corpus compris-
ing many different varieties of spoken and written
English.

The CRAFT corpus is a collection of 97 full-
text journal articles from the mouse genomics do-
main. It has been annotated for a variety of lin-
guistic and semantic features; for the purposes of
this study, the relevant ones were sentence bound-
aries, tokenization, and part of speech. We used
the 70-document public release subset of the cor-
pus, which comprises about 453,377 words.

The GENIA corpus is a collection of 1,999 ab-
stracts of journal articles about human blood cell
transcription factors. Like the CRAFT corpus,
it has been annotated for a variety of linguistic
and semantic features, again including sentence
boundaries, tokenization, and part of speech. In
the mid-2000’s, the GENIA corpus was shown to
be the most popular corpus for research in biomed-
ical natural language processing (Cohen et al.,
2005). We used version 3.02 of the corpus, con-
taining about 448,843 words.

The experiment requires a corpus of general
English for comparison. For this purpose, we

74



used a subset of the British National Corpus. For
purposes of representativeness, we followed the
Brown corpus strategy of extracting the first 2,000
words from each article until a total of 453,377
words were reached (to match the size of the
CRAFT corpus).

The size of the two data sets is far more than ad-
equate for an experiment of this type—McEnery
and Wilson were able to detect closure properties
using corpora of only 200,000 words in their ex-
periments.

2.2 Methods
2.2.1 Implementation details
To determine the closure properties of arbitrary
corpora, we developed scripts that take a simple
input format into which it should be possible to
convert any annotated corpus. There are two input
file types:

• A file containing one word and its corre-
sponding part-of-speech tag per line. Part of
speech tags can consist of multiple tokens, as
they do in the BNC tag set, or of single to-
kens, as they do in most corpora. This file
format is used as the input for the lexical clo-
sure script and the word type/POS tag script.

• A file containing a sequence of part of speech
tags per line, one line per sentence. This
file format is used as input for the sentence
type closure script. We note that this is an
extremely rough representation of “syntax,”
and arguably is actually asyntactic in that it
does not represent constituent or dependency
structure at all, but also point out that it has
the advantage of being widely applicable and
agnostic as to any particular theory of syntac-
tic structure. It also increases the sensitivity
of the method to sentence type differences,
providing a stronger test of fit to the sublan-
guage model.

Two separate scripts then process one of these
input files to determine lexical, type/POS, and sen-
tence type closure properties. The output of ev-
ery script is a comma-separated-value file suitable
for importing into Excel or other applications for
producing plots. The two scripts and our scripts
for converting the BNC, CRAFT, and GENIA cor-
pora into the input file formats will be made pub-
licly available at [redacted for anonymization pur-
poses]. To apply the scripts to a new corpus, the

Figure 1: Lexical closure properties. Tick-marks
on x axis indicate increments of 50,000 tokens.

only necessary step is to write a script to convert
from the corpus’s original format to the simple for-
mat of the two input file types described above.

2.2.2 Investigating closure properties
In all three cases, the number of types, whether of
lexical items, lexical type/part-of-speech pair, or
sentence type was counted and graphed on the y
axis, versus the number of tokens that had been
observed up to that point, which was graphed on
the x axis. In the case of the lexical and type/POS
graphs, tokens were words, and in the case of the
sentence graph, “tokens” were sentences.

We then combined the lines for all three cor-
pora and observed the total size of types, the rate
of growth of the line, and whether or not there was
a tendency towards asymptoting of the growth of
the line, i.e. closure.

Our major deviation from the approach of
(McEnery and Wilson, 2001) was that rather than
parse trees, we used part-of-speech tag sequences
to represent sentence types. This is suboptimal in
that it is essentially asyntactic, and in that it ob-
scures the smoothing factor of abstracting away
from per-token parts of speech to larger syntactic
units. However, as we point out above, it has the
advantages of being widely applicable and agnos-
tic as to any particular theory of syntactic struc-
ture, as well as more sensitive to sentence type dif-
ferences.

3 Results

3.1 Lexical closure properties

Figure 1 shows the growth in number of types of
lexical items as the number of tokens of lexical
items increases. The British National Corpus data
is in blue, the CRAFT data is in red, and the GE-
NIA data is in green.

75



Figure 2: Type-part-of-speech tag closure proper-
ties. Tick-marks on x axis indicate increments of
50,000 tokens.

We note a drastic difference between the curve
for the BNC and the curves for CRAFT and GE-
NIA. The curves for CRAFT and GENIA are quite
similar to each other. Overall, the curve for the
BNC climbs faster and much farther, and is still
climbing at a fast rate after 453,377 tokens have
been examined. In contrast, the curves for CRAFT
and GENIA climb more slowly, climb much less,
and by the time about 50,000 tokens have been ex-
amined the rate of increase is much smaller. The
increase in CRAFT and GENIA does not asymp-
tote, as McEnery and Wilson observed for the IBM
corpus. However, contrasted with the results for
the BNC, there is a clear difference.

The type to token ratios for lexical items for the
corpora as a whole are shown in Table 1. As the
sublanguage model would predict, CRAFT and
GENIA have much higher ratios than BNC.

Corpus name Ratio
BNC 1: 12.650
CRAFT 1: 23.080
GENIA 1: 19.027

Table 1: Lexical type-to-token ratios.

3.2 Type/POS tag closure properties

Figure 2 shows the growth in number of type-
POS tag pairs as the number of tokens of lexical
item/POS tag pairs increases. The data from the
different corpora corresponds to the same colors
as in Figure 1.

Once again, we note a drastic difference be-
tween the curve for the BNC and the curves for
CRAFT and GENIA. If anything, the differences
are more pronounced here than in the case of the
lexical closure graph. Again, we do not see an

asymptote in the increase of the curves for CRAFT
and GENIA, but there is a clear difference when
contrasted with the results for the BNC.

The type-to-token sets ratios for the corpora as a
whole are shown in Table 2. Again, as the sublan-
guage model would predict, we see much higher
ratios in CRAFT and GENIA than in BNC.

Corpus name Ratio
BNC 1: 10.80
CRAFT 1: 19.96
GENIA 1: 18.18

Table 2: Type-to-token ratios for type/POS tags.

Because the Machinese Syntax parser was
used to obtain the part-of-speech tagging for
BNC and the Machinese Syntax parser’s tagset is
much more granular and therefore larger than the
CRAFT and GENIA tag sets, both of which are
adaptations of the Penn treebank tag set, we con-
sidered the hypothesis that the large size differ-
ences of the tag sets were the cause of the differ-
ences observed between BNC and the two corpora
of scientific journal articles. To test this hypothe-
sis, we manually mapped the BNC tag set to the
Penn treebank tag set. The result was a new BNC
list of tags, of the same number and granularity
as the CRAFT/GENIA ones (35-36 tags). Using
this mapping, the BNC part-of-speech tags were
converted to the Penn treebank tag set and the ex-
periment was re-run. The results show that there
is almost no difference between the results from
the first and the second experiments. The resulting
graph is omitted for space, but examining it one
can observe that the differences between the three
corpora in the graph are almost the same in both
graphs. The newly calculated type:tokens ratio for
BNC are also illustrative. They are highly similar
to the type-token ratio for the original tag set—
1:10.82 with the mapped data set vs. 1:10.80 with
the original, much larger tag set. This supports the
original results and demonstrates that differences
in tag set sizes do not interfere with the identifica-
tion of sublanguages.

3.3 Sentence type closure properties

Figure 3 shows the growth in number of sentence
types as the number of sentences increases. The
data from the different corpora corresponds to the
same colors as in Figure 1.

Here we see that all three corpora exhibit sim-

76



Figure 3: Sentence type closure properties. Tick-
marks on x axis indicate increments of 5,000 sen-
tences.

ilar curves—essentially linear, with nearly identi-
cal growth rates. This is a strong contrast with the
results seen in Figures 1 and 2. We suggest some
reasons for this in the Discussion section.

The ratio of sentence types to sentence tokens
for the corpora as a whole are given in Table 3.
As would be expected from the essentially linear
growth observed with token growth for all three
corpora, all three ratios are nearly 1:1.

Corpus name Ratio
BNC 1: 1.03
CRAFT 1: 1.14
GENIA 1: 1.11

Table 3: Sentence type-to-token ratios.

4 Discussion and Conclusions

The most obvious conclusion of this study is that
the null hypothesis can be rejected—the scien-
tific corpora show a greater tendency towards clo-
sure than the general English corpus. Further-
more, we observe that the two scientific corpora
behave quite similarly to each other at all three
levels. This second observation is not necessar-
ily a given. If we can consider for a moment the
notion that there might be degrees of fit to the sub-
language model, it is clear that from a content per-
spective the BNC is unlimited; the CRAFT cor-
pus is limited to mouse genomics, but not to any
particular area of mouse genomics (indeed, it con-
tains articles about development, disease, physiol-
ogy, and other topics); and GENIA is more lim-
ited than CRAFT, being restricted to the topic of
human blood cell transcription factors. If a tech-
nique for sublanguage detection were sufficiently
precise and granular, it might be possible to show a

strict ranking from BNC to CRAFT to GENIA in
terms of fit to the sublanguage model (i.e., BNC
showing no fit, and GENIA showing a greater fit
than CRAFT since its subject matter is even more
restricted). However, this does not occur—in our
data, CRAFT showed a stronger tendency towards
closure at the lexical level, while GENIA shows
a stronger tendency towards closure at the mor-
phosyntactic level. It is possible that the small dif-
ferences at those levels are not significant, and that
the two corpora show the same tendencies towards
closure overall.

One reason that the IBM manuals in the
(McEnery and Wilson, 2001) experiments showed
sentence type closure but the CRAFT and GE-
NIA corpora did not in our experiments is al-
most certainly related to sentence length. The
average length of a sentence in the IBM manu-
als is 11 words, versus 24 in the Hansard corpus
and 21 in the American Printing House for the
Blind corpus. In this respect, the scientific cor-
pora are much more like the Hansard and Ameri-
can Printing House for the Blind corpora than they
are like the IBM manuals—the average length of
a sentence in GENIA is 21.47 words, similar to
the Hansard and American Printing House for the
Blind corpora and about twice the length of sen-
tences in the IBM manuals. Similarly, the aver-
age sentence length of the CRAFT corpus is 22.27
words (twice the average sentence length of the
IBM manuals), and the average sentence length in
the BNC is 20.43 words. Longer sentences imply
greater chances for different sentence types.

Another reason for the tendency towards sen-
tence type closure in the IBM manuals, which was
not observed in CRAFT and GENIA, is the strong
possibility that they were written in a controlled
language that specifies the types of syntactic con-
structions that can be used in writing a manual,
e.g. limiting the use of passives, etc., as well as
lexical choices and limits on other options (Kuhn,
under review). There is no such official controlled
language for writing journal articles.

Finally, one reason that the CRAFT and GENIA
corpora did not show sentence type closure while
the IBM manuals did is that while McEnery and
Wilson represented sentence types as parses, we
represented them as sequences of part-of-speech
tags. Representing sentence types as parse trees
has the effect of smoothing out some variability
at the leaf node level. For this reason, our repre-

77



sentation increases the sensitivity of the method to
sentence type differences, providing a stronger test
of fit to the sublanguage model.

It has been suggested since Harris’s classic
work (Harris et al., 1989) that scientific writing
forms a sublanguage. However, it is also clear
from the work of (Stetson et al., 2002) and (Mi-
haila et al., 2012) that some putative sublanguages
are a better fit to the model than others, and to date
there has been no publicly available, repeatable
method for assessing the fit of a set of documents
to the sublanguage model. This paper presents
the first such package of software and uses it to
evaluate two corpora of scientific journal articles.
Future work will include evaluating the effects of
mapping all numbers to a fixed NUMBER token,
which might affect the tendencies towards lexi-
cal closure; evaluating the effect of the size of
tag sets on type/part-of-speech ratios, which might
affect tendencies towards type/part-of-speech clo-
sure; and seeking a way to introduce more syntac-
tic structure into the sentence type analysis with-
out losing the generality of the current approach.
We will also apply the technique to other biomed-
ical genres, such as clinical documents. There
is also an important next step to take—this work
provides a means for recognizing sublanguages,
but does not tackle the problem of determining
their characteristics. However, despite these limi-
tations, this paper presents a large step towards fa-
cilitating the study of sublanguages by providing
a quantitative means of assessing their presence.

In analyzing the results of the study, some im-
plications for natural language processing are ap-
parent. Some of these are in accord with the is-
sues for sublanguage natural language processing
pointed out in the introduction. Another is that this
work highlights the importance of both classic and
more recent work on concept recognition for sci-
entific journal articles (and other classes of sublan-
guages), such as MetaMap (Aronson, 2001; Aron-
son and Lang, 2010), ConceptMapper (Tanenblatt
et al., 2010), and the many extant gene mention
systems.

Acknowledgments

Irina Temnikova’s work on the research re-
ported in this paper was supported by the project
AComIn ”Advanced Computing for Innovation”,
grant 316087, funded by the FP7 Capacity Pro-
gramme (Research Potential of Convergence Re-

gions). Kevin Bretonnel Cohen’s work was sup-
ported by grants NIH 5R01 LM009254-07 and
NIH 5R01 LM008111-08 to Lawrence E. Hunter,
NIH 1R01MH096906-01A1 to Tal Yarkoni, NIH
R01 LM011124 to John Pestian, and NSF IIS-
1207592 to Lawrence E. Hunter and Barbara
Grimpe. The authors thank Tony McEnery and
Andrew Wilson for advice on dealing with the tag
sets.

References
Alan R. Aronson and Francois-Michel Lang. 2010. An

overview of MetaMap: historical perspective and re-
cent advances. Journal of the American Medical In-
formatics Association, 17:229–236.

A. Aronson. 2001. Effective mapping of biomedi-
cal text to the UMLS Metathesaurus: The MetaMap
program. In Proc AMIA 2001, pages 17–21.

Michael Bada, Miriam Eckert, Donald Evans, Kristin
Garcia, Krista Shipley, Dmitry Sitnikov, William
A. Baumgartner Jr., Kevin Bretonnel Cohen, Karin
Verspoor, Judith A. Blake, and Lawrence E. Hunter.
2012. Concept annotation in the craft corpus. BMC
Bioinformatics, 13(161).

K. B. Cohen, Lynne Fox, Philip V. Ogren, and
Lawrence Hunter. 2005. Corpus design for biomed-
ical natural language processing. In Proceedings of
the ACL-ISMB workshop on linking biological liter-
ature, ontologies and databases, pages 38–45. As-
sociation for Computational Linguistics.

Timothy W. Finin. 1986. Constraining the interpre-
tation of nominal compounds in a limited context.
In Ralph Grishman and Richard Kittredge, editors,
Analyzing language in restricted domains: sublan-
guage description and processing, pages 85–102.
Lawrence Erlbaum Associates.

Carol Friedman, Philip O. Anderson, John H.M.
Austin, James J. Cimino, and Stephen B. Johnson.
1994. A general natural-language text processor for
clinical radiology. Journal of the American Medical
Informatics Association, 1:161–174.

Carol Friedman, Pauline Kra, Hong Yu, Michael
Krauthammer, and Andrey Rzhetsky. 2001. GE-
NIES: a natural-language processing system for the
extraction of molecular pathways from journal arti-
cles. Bioinformatics, 17(Suppl. 1):S74–S82.

Carol Friedman, Pauline Kra, and Andrey Rzhetsky.
2002. Two biomedical sublanguages: a description
based on the theories of Zellig Harris. Journal of
Biomedical Informatics, 35:222–235.

Carol Friedman. 1986. Automatic structuring of
sublanguage information. In Ralph Grishman and
Richard Kittredge, editors, Analyzing language in

78



restricted domains: sublanguage description and
processing, pages 85–102. Lawrence Erlbaum As-
sociates.

Ralph Grishman and Richard Kittredge. 1986. Ana-
lyzing language in restricted domains: sublanguage
description and processing. Lawrence Erlbaum As-
sociates.

Zellig Harris, Michael Gottfried, Thomas Ryckman,
Anne Daladier, Paul Mattick, T.N. Harris, and Su-
sanna Harris. 1989. The form of information in
science: analysis of an immunology sublanguage.
Kluwer Academic Publishers.

Lynette Hirschman and Naomi Sager. 1982. Auto-
matic information formatting of a medical sublan-
guage. In Richard Kittredge and John Lehrberger,
editors, Sublanguage: studies of language in re-
stricted semantic domains, pages 27–80. Walter de
Gruyter.

Timo Järvinen, Mikko Laari, Timo Lahtinen, Sirkku
Paajanen, Pirkko Paljakka, Mirkka Soininen, and
Pasi Tapanainen. 2004. Robust language analy-
sis components for practical applications. In Ro-
bust and adaptive information processing for mobile
speech interfaces: DUMAS final workshop, pages
53–56.

Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and
Jun’ichi Tsujii. 2003. Genia corpus—a semanti-
cally annotated corpus for bio-textmining. Bioinfor-
matics, 19(Suppl. 1):180–182.

Richard I. Kittredge. 2003. Sublanguages and con-
trolled languages. In Ruslan Mitkov, editor, The Ox-
ford Handbook of Computational Linguistics, pages
430–447. Oxford University Press.

Tobias Kuhn. under review. Survey and classification
of controlled natural languages. Computational Lin-
guistics.

G. Leech, R. Garside, and M. Bryant. 1994. The large-
scale grammatical tagging of text: experience with
the British National Corpus. In N. Oostdijk and
P. de Haan, editors, Corpus based research into lan-
guage.

David D. McDonald. 2000. Natural language genera-
tion. In Robert Dale, Hermann Moisl, and Harold
Somers, editors, Handbood of Natural Language
Processing, pages 147–179. Marcel Dekker.

Tony McEnery and Andrew Wilson. 2001. Corpus
Linguistics. Edinburgh University Press, 2nd edi-
tion.

Claudiu Mihaila, Riza Theresa Batista-Navarro, and
Sophia Ananiadou. 2012. Analysing entity type
variation across biomedical subdomains. In Third
workshop on building and evaluating resources for
biomedical text mining, pages 1–7.

Naomi Sager. 1986. Sublanguage: linguistic phe-
nomenon, computational tool. In Ralph Grishman
and Richard Kittredge, editors, Analyzing language
in restricted domains: sublanguage description and
processing, pages 1–17. Lawrence Erlbaum Asso-
ciates.

Satoshi Sekine. 1994. A new direction for sublan-
guage nlp. In Proceedings of the international con-
ference on new methods in natural language pro-
cessing, pages 123–129.

Harold Somers. 1998. An attempt to use weighted
cusums to identify sublanguages. In NeM-
LaP3/CoNLL98: New methods in language process-
ing and computational natural language learning,
pages 131–139.

Harold Somers. 2000. Machine translation. In Robert
Dale, Hermann Moisl, and Harold Somers, editors,
Handbook of Natural Language Processing, pages
329–346. Marcel Dekker.

Peter D. Stetson, Stephen B. Johnson, Matthew Scotch,
and George Hripcsak. 2002. The sublanguage of
cross-coverage. In Proc. AMIA 2002 Annual Sym-
posium, pages 742–746.

Michael Tanenblatt, Anni Coden, and Igor Sominsky.
2010. The ConceptMapper approach to named en-
tity recognition. In Language Resources and Evalu-
ation Conference, pages 546–551.

Karin Verspoor, Kevin Bretonnel Cohen, Arrick Lan-
franchi, Colin Warner, Helen L. Johnson, Christophe
Roeder, Jinho D. Choi, Christopher Funk, Yuriy
Malenkiy, Miriam Eckert, Nianwen Xue, William
A. Baumgartner Jr., Michael Bada, Martha Palmer,
and Lawrence E. Hunter. 2012. A corpus of full-text
journal articles is a robust evaluation tool for reveal-
ing differences in performance of biomedical natu-
ral language processing tools. BMC Bioinformatics,
13(207).

79


