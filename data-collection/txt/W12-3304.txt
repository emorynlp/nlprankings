










































Query classification using topic models and support vector machine


Proceedings of the 2012 Student Research Workshop, pages 19–24,

Jeju, Republic of Korea, 8-14 July 2012. c©2012 Association for Computational Linguistics

Query classification using topic models and support vector machine

Dieu-Thu Le
University of Trento, Italy

dieuthu.le@disi.unitn.it

Raffaella Bernardi
University of Trento, Italy

bernardi@disi.unitn.it

Abstract

This paper describes a query classification
system for a specialized domain. We take as
a case study queries asked to a search engine
of an art, cultural and history library and clas-
sify them against the library cataloguing cate-
gories. We show how click-through links, i.e.,
the links that a user clicks after submitting a
query, can be exploited for extracting informa-
tion useful to enrich the query as well as for
creating the training set for a machine learn-
ing based classifier. Moreover, we show how
Topic Model can be exploited to further enrich
the query with hidden topics induced from the
library meta-data. The experimental evalua-
tions show that this system considerably out-
performs a matching and ranking classifica-
tion approach, where queries (and categories)
were also enriched with similar information.

1 Introduction

Query classification (QC) is the task of automati-
cally labeling user queries into a given target tax-
onomy. Providing query classification can help the
information providers understand users’ needs based
on the categories that the users are searching for.
The main challenges of this task come from the na-
ture of user queries, which are usually very short and
ambiguous. Since queries contain only several to a
dozen words, a QC system often requires either a
rather large training set or an enrichment of queries
with other information (Shen et al., 2006a), (Broder
et al., 2007).

This study will focus on QC in art, culture and
history domain, using the Bridgeman art library1, al-
though our framework is general enough to be used
in different domains. Manually creating a training

1http://www.bridgemanart.com/

set of queries to build a classifier in a specific do-
main is very time-consuming. In this study, we
will describe our method of automatically creating
a training set based on the click-through links and
how we build an SVM (Support Vector Machine)
classifier with the integration of enriched informa-
tion. In (Le et al., 2011), it has been shown that
click-through information and topic models are use-
ful for query enrichment when the ultimate goal is
query classification. We will follow this enrichment
step, but integrate this information into a SVM clas-
sifier instead of using matching and ranking between
queries and categories as in (Le et al., 2011).

The purpose of this paper is to determine (1)
whether the query enrichment with click-though in-
formation and hidden topics is useful for a machine
learning query classification system using SVM; and
(2) whether integrating this enriched information
into a machine learning classifier can perform bet-
ter than the matching and ranking system.

In the next section, we will briefly review the
main streams of related work in QC. In section 3,
we will describe the Bridgeman art library. Sec-
tion 4 accounts for our proposed query classifica-
tion framework. In section 5, we will present our
experiment and evaluation. Section 6 concludes by
discussing our main achievements and proposing fu-
ture work.

2 Related work

Initial studies in QC classify queries into several
different types based on the information needed by
the user. (Broder, 2002) considered three different
types of queries: informational queries, navigational
queries and transactional queries. This stream of
study focuses on the type of the queries, rather than
topical classification of the queries.

Another stream of work deals with the problem

19



of classifying queries into a more complex taxon-
omy containing different topics. Our study falls into
this second stream. To classify queries consider-
ing their meaning, some work considered only in-
formation available in queries (e.g., (Beitzel et al.,
2005) only used terms in queries). Some other work
has attempted to enrich queries with information
from external online dataset, e.g., web pages (Shen
et al., 2006a; Broder et al., 2007) and web direc-
tories (Shen et al., 2006b). Our work is similar
to their in the idea of exploiting additional dataset.
However, instead of using search engines as a way
of collecting relevant documents, we use the meta-
data of the library itself as a reference set. Further-
more, we employ topic models to analyze topics for
queries, rather than enriching queries with words se-
lected from those webpages directly as in (Shen et
al., 2006a; Broder et al., 2007).

The context of a given query can provide use-
ful information to determine its categories. Previ-
ous studies have confirmed the importance of search
context in QC. (Cao et al., 2009) considered the con-
text to be both previous queries within the same ses-
sion and pages of the clicked urls. In our approach,
we will also consider click through information to
enrich the queries and analyze topics.

In (Le et al., 2011), queries and categories are en-
riched with both information mined from the click-
through links as well as topics derived from a topic
model estimated from the library metadata. Sub-
sequently, the queries are mapped to the categories
based on their cosine similarity. Our proposed ap-
proach differs from (Le et al., 2011) in three re-
spects: (1) we enrich the queries, but not the cat-
egories (2) we employ a machine learning system
and integrate this enriched information as features to
learn an SVM classifier (3) we assume that the cate-
gory of a query is closely related to the category of
the corresponding click-through link, hence we au-
tomatically create a training data for the SVM clas-
sifier by analyzing the query log.

3 Bridgeman Art Library

Bridgeman Art Library (BAL)2 is one of the world’s
top image libraries for art, culture and history. It
contains images from over 8,000 collections and

2http://www.bridgemanart.com

more than 29,000 artists, providing a central source
of fine art for image users.

Works of art in the library have been annotated
with titles and keywords. Some of them are catego-
rized into a two-level taxonomy, a more fine-grained
classification of the Bridgeman browse menu. In our
study, we do not use the image itself but only the in-
formation associated with it, i.e., the title, keywords
and categories. We will take the 55 top-level cate-
gories from this taxonomy, which have been orga-
nized by a domain expert, as our target taxonomy.

4 Building QC using topic models and
SVM

Following (Le et al., 2011), we enrich queries both
with the information mined from the library via
click-through links and the information collected
from the library metadata via topic modeling. To
perform the query enrichment with topics derived
from the library metadata, there are several impor-
tant steps:
• Collecting and organizing the library metadata as
a reference set: the library metadata contains the in-
formation about artworks that have been annotated
by experts. To take advantage of this information
automatically, we collected all annotated artworks
and organized them by their given categories.
• Estimating a topic model for this reference set:
This step is performed using hidden topic analysis
models. In this framework, we choose to use latent
dirichlet allocation, LDA (Blei et al., 2003b).
• Analyzing topics for queries and integrating topics
into data for both the training set and new queries:
After the reference set has been analyzed using topic
models, it will be used to infer topics for queries.
The topic model will then be integrated into the data
to build a classifier.

4.1 Query enrichment via click-through links
We automatically extracted click-through links from
the query log (which provides us with the title of
the image that the user clicks) to enrich the query,
represented as a vector −→qi , with the title of one
randomly-chosen click-through associated with it.
To further exploit the click-through link, we find
the corresponding artwork and extract its keywords:
−→qi ∪
−→
ti ∪
−−→
kwi, where

−→
ti ,
−−→
kwi are the vectors of words

20



in the title and keywords respectively.

4.2 Hidden Topic Models
The underlying idea is based upon a probabilis-
tic procedure of generating a new set of artworks,
where each set refers to titles and keywords of
all artworks in a category: First, each set −→wm
= (wm,n)Nmn=1 is generated by sampling a distribu-
tion over topics

−→
ϑm from a Dirichlet distribution

(Dir(−→α )), where Nm is the number of words in
that set m. After that, the topic assignment for
each observed word wm,n is performed by sam-
pling a word place holder zm,n from a multino-
mial distribution (Mult(

−→
ϑm)). Then a word wm,n is

picked by sampling from the multinomial distribu-
tion (Mult(−→ϕ zm,n)). This process is repeated until
all K topics have been generated for the whole col-
lection.

Table 1: Generation process for LDA

•M : the total number of artwork sets
•K: the number of (hidden/latent) topics
• V : vocabulary size
• −→α ,

−→
β : Dirichlet parameters

•
−→
ϑm: topic distribution for document m
• −→ϕ k: word distribution for topic k
• Nm: the length of document m
• zm,n: topic index of nth word in document m
• wm,n: a particular word for word placeholder [m, n]
• Θ = {

−→
ϑm}Mm=1: a M ×K matrix

• Φ = {−→ϕ k}Kk=1: a K × V matrix

In order to estimate parameters for LDA (i.e.,
the set of topics and their word probabilities Φ
and the particular topic mixture of each document
Θ), different inference techniques can be used,
such as variational Bayes (Blei et al., 2003b), or
Gibbs sampling (Heinrich, 2004). In this work,
we will use Gibbs sampling following the descrip-
tion given in (Heinrich, 2004). Generally, the topic
assignment of a particular word t is computed as:
p(zi =k|−→z ¬i,−→w)=

n
(t)
k,¬i + βt

[
∑V

v=1 n
(v)
k +βv]−1

n
(k)
m,¬i + αk

[
∑K

j=1 n
(j)
m +αj ]−1

(1)

where n(t)k,¬i is the number of times the word t is
assigned to topic k except the current assignment;∑V

v=1 n
(v)
k −1 is the total number of words assigned

to topic k except the current assignment; n(k)m,¬i is the
number of words in set m assigned to topic k except

the current assignment; and
∑K

j=1 n
(j)
m − 1 is the

total number of words in set m except the current
word t. In normal cases, Dirichlet parameters −→α ,
and
−→
β are symmetric, that is, all αk (k = 1..K) are

the same, and similarly for βv (v = 1..V ).

4.3 Hidden topic analysis of the Bridgeman
metadata

The Bridgeman metadata contains information
about artworks in the library that have been anno-
tated by the librarians. We extracted titles and key-
words of each artwork, those for which we had a
query with a click-through link corresponding to it,
and grouped them together by their sub-categories.
Each group is considered as a document −→wm =
(wm,n)

Nm
n=1, with the number of total documents M

= 732 and the vocabulary size V = 136K words. In
this experiment, we fix the number of topics K =
100. We used the GibbsLDA++ implementation3 to
estimate this topic model.

4.4 Building query classifier with hidden topics
Let Q′ = {−→qi ′}i=Ni=1 be the set of all queries en-
riched via the click-through links, where each en-
riched query is −→qi ′ = −→qi ∪

−→
ti ∪

−−→
kwi. We also per-

formed Gibbs sampling for all −→qi ′ in order to esti-
mate its topic distribution

−→
ϑ i = {ϑi,1, . . . , ϑi,K}

where the probability ϑi,k of topic k in −→qi ′ is com-
puted as:

ϑi,k =
n

(k)
i + αk∑K

j=1 n
(j)
i + αj

(2)

where n(k)i is the number of words in query i as-
signed to topic k and n(j)i is the total number of
words appearing in the enriched query i.

In order to integrate the topic distribution
−→
ϑi =

{ϑi,1, . . . , ϑi,K} into the vector of words −→qi ′
= {wi,1, wi,2, . . . , wi,Ni}, following (Phan et al.,
2010), we only keep topics whose ϑi,k is larger than
a threshold cut-off and use a scale parameter to do
the discretization for topics: the number of times
topic k integrated to −→qi ′ is round(ϑi× scale). After
that, we build a Support Vector Machine classifier
using SVM light V2.204.

3http://gibbslda.sourceforge.net/
4http://svmlight.joachims.org/

21



5 Evaluation
In this section, we will describe our training set, gold
standard and the performance of our system in com-
parison with the one in (Le et al., 2011).

5.1 Training set
Manually annotating queries to create a training set
in this domain is a difficult task (e.g., it requires the
expert to search the query and look at the picture cor-
responding to the query, etc.). Therefore, we have
automatically generated a training set by exploiting
a 6-month query log as follow.

First, each query has been mapped to its click-
through information to extract the sub-category as-
sociated to the corresponding image. Then, from
this sub-category, we obtained its corresponding
top-cateogry (among the 55 we consider) as defined
in BAL taxonomy. The distribution of queries in
different categories varies quite a lot among the 55
target categories reflecting the artwork distribution
(e.g., there are many more artworks in the library be-
longing to the category “Religion and Belief” than
to the category“Costume and Fashion”). We have
preserved such distribution over the target categories
when selecting randomly the 15,490 queries to build
our training set. After removing all punctuations and
stop words, we obtained a training set containing
50,337 words in total. Each word in this set serves
as a feature for the SVM classifier.

5.2 Test set
We used the test set of 1,049 queries used in (Le et
al., 2011), which is separate from the training set.
These queries have been manually annotated by a
BAL expert (up to 3 categories per query). Note that
these queries have also been selected automatically
while preserving the distribution over the target cat-
egories observed in the 6-month query log. We call
this the “manual” gold standard. In addition, we also
made use of another gold standard obtained by map-
ping the click-through information of these queries
with their categories, similar to the way in which we
obtain the training set. We call this the “via-CT”
gold standard.

5.3 Experimental settings
To evaluate the impact of click-though information
and topics in the classifier, we designed the follow-

ing experiments, where QR is the method without
any enrichment andQR-CT -HT is with the enrich-
ment via both click-through and hidden topics.

Setting Query enrichment
QR −→q

QR-HT −→q ⊕HT
QR-CT −→q ′ = −→q + −→t +

−→
kw

QR-CT -HT −→q ′ ⊕HT
• −→q : query
• −→q ′: query enriched with click-through information
• −→t : click-through image’s title
•
−→
kw: click-through image’s keywords
•HT : hidden topics from Bridgeman metadata

Table 2: Experimental Setting

Setting
Hits

Manual GS via-CT
# 1 # 2 # 3

∑
Top 3 GS

QR 207 80 24 311 231
QR-HT 212 81 25 318 235
QR - CT 243 107 38 388 266

QR - CT - HT 289 136 49 474 323

Table 3: Results of query classification: number of cor-
rect categories found (for 1,049 queries)

Figure 1: The impact of click-through information with
matching-ranking (mr) and our approach (svm)

To answer our first research question, namely
whether click-through information and hidden top-
ics are useful for this query classifier, we examine
the number of correct categories found by the classi-
fier built both with and without the enrichment. The
results of the experiment are reported in Table 3. As
can be seen from the table, we notice that the click-
through information plays an important role. In par-

22



ticular, it increases the number of correct categories
found from 311 to 388 (compared with the manual
GS) and from 231 to 266 (using the via-CT GS).

To answer our second research question, namely
whether integrating the enriched information into a
machine learning classifier can perform better than
the matching and ranking method, we also compare
the results of our approach with the one in (Le et
al., 2011). Figure 1 shows the impact of the click-
through information for the SVM classifier (svm) in
comparison with the matching and ranking approach
(mr). Figure 2 shows the impact of the hidden topics
in both cases. We can see that in both cases our clas-
sifier outperforms the matching-ranking one con-
siderably (e.g., from 183 to 388 correct categories
found in the QR-CT-HT method).

Figure 2: The impact of hidden topics with matching-
ranking (mr) and our approach (svm)

However, in the case where we use only queries
without click-through information, we can see that
hidden topics do not bring a very strong impact (the
number of correct categories found only slightly in-
creases by 7 - using the “manual” gold standard).
The result might come from the fact that this topic
model was built from the metadata, using only click-
through information, but has not been learned with
queries.

6 Conclusion

In this study, we have presented a machine learn-
ing classifier for query classification in an art im-
age archive. Since queries are usually very short,
thus difficult to classify, we first extend them with
their click-through information. Then, these queries
are further enriched with topics learned from the

BAL metadata following (Le et al., 2011). The re-
sult from this study has confirmed again the effect
of click-through information and hidden topics in
the query classification task using SVM. We have
also described our method of automatically creat-
ing a training set based on the selection of queries
mapped to the click-through links and their corre-
sponding available categories using a 6-month query
log. The result of this study has shown a consid-
erable increase in the performance of this approach
over the matching-ranking system reported in (Le et
al., 2011).

7 Future work

For future work, we are in the process of enhancing
our experimentation in several directions:
Considering more than one click-through image
per query: In this work, we have considered only
one category per query to create the training set,
while it might be more reasonable to take into ac-
count all click-through images of a given query. In
future work, we plan to enrich the queries with either
all click-through images or with the most relevant
one instead of randomly picking one click-through
image. In many cases, a click-through link is not
necessarily related to the meaning of a query (e.g.,
when users just randomly click on an image that they
find interesting). Thus, it might be useful to filter out
those click-through images that are not relevant.
Enriching queries with top hits returned by the
BAL search engine: In the query logs, there are
many queries that do not have an associated click-
through link. Hence, we plan to exploit other en-
richment method that do not rely on those links, in
particular we will try to exploit the information com-
ing from the top returned hits given by the library
search engine.
Analyzing queries in the same session: It has been
shown in some studies (Cao et al., 2009) that analyz-
ing queries in the same session can help determine
their categories. Our next step is to enrich a new
query with the information coming from the other
previous queries in the same session.
Optimizing LDA hyperparameters and topic
number selection: Currently, we fixed the num-
ber of topics K = 100, the Dirichlet hyperparame-
ters α = 50/K = 0.5 and β = 0.1 as in (Griffiths and

23



Steyvers, 2004). In the future, we will explore ways
to optimize these input values to see the effect of dif-
ferent topic models in our query classification task.
Exploiting visual features from the BAL images:
The BAL dataset provides an interesting case study
in which we plan to further analyze images to enrich
queries with their visual features. Combining text
and visual features has drawn a lot of attention in the
IR research community. We believe that exploiting
visual features from this art archive could lead to in-
teresting results in this specific domain. A possible
approach would be extracting visual features from
the click-through images and representing them to-
gether with textual features in a joint topic distribu-
tion (e.g., (Blei et al., 2003a; Li et al., 2010)).
Comparing system with other approaches: In the
future, we plan to compare our system with other
query classification systems and similar techniques
for query expansion in general. Furthermore, the
evaluation phase has not been carried out thoroughly
since it was difficult to compare the one-class output
with the gold-standard, where the number of correct
categories per query is not fixed. In the future, we
plan to exploit the output of our multi-class classi-
fier to assign up to three categories for each query
and compute the precision at n.

Acknowledgments

This work has been partially supported by the
GALATEAS project (http://www.galateas.eu/ –
CIP-ICT PSP-2009-3-25430) funded by the Euro-
pean Union under the ICT PSP program.

References
Steven M. Beitzel, Eric C. Jensen, Ophir Frieder, and

David Grossman. 2005. Automatic web query clas-
sification using labeled and unlabeled training data. In
In Proceedings of the 28th Annual International ACM
SIGIR Conference on Research and Development in
Information Retrieval, pages 581–582. ACM Press.

David M. Blei, Michael I, David M. Blei, and Michael I.
2003a. Modeling annotated data. In In Proc. of the
26th Intl. ACM SIGIR Conference.

David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003b. Latent dirichlet allocation. J. Mach. Learn.
Res., 3:993–1022, March.

Andrei Z. Broder, Marcus Fontoura, Evgeniy
Gabrilovich, Amruta Joshi, Vanja Josifovski, and

Tong Zhang. 2007. Robust classification of rare
queries using web knowledge. In Proceedings of the
30th annual international ACM SIGIR conference on
Research and development in information retrieval,
SIGIR ’07, pages 231–238, New York, NY, USA.
ACM.

Andrei Broder. 2002. A taxonomy of web search. SIGIR
Forum, 36:3–10, September.

Huanhuan Cao, Derek Hao Hu, Dou Shen, Daxi Jiang,
Jian-Tao Sun, Enhong Chen, and Qiang Yang. 2009.
Context-aware query classification. In SIGIR’09, The
32nd Annual ACM SIGIR Conference.

Thomas L Griffiths and Mark Steyvers. 2004. Find-
ing scientific topics. Proceedings of the National
Academy of Sciences of the United States of America,
101 Suppl 1(Suppl 1):5228–5235.

Gregor Heinrich. 2004. Parameter estimation for text
analysis. Technical report.

Dieu-Thu Le, Raffaella Bernardi, and Edwin Vald. 2011.
Query classification via topic models for an art im-
age archive. In Recent Advances in Natural Language
Processing, RANLP, Bulgaria.

Li-Jia Li, Chong Wang, Yongwhan Lim, David Blei, and
Li Fei-Fei. 2010. Building and using a semantivisual
image hierarchy. In The Twenty-Third IEEE Confer-
ence on Computer Vision and Pattern Recognition, San
Francisco, CA, June.

Xuan-Hieu Phan, Cam-Tu Nguyen, Dieu-Thu Le, Le-
Minh Nguyen, Susumu Horiguchi, and Quang-Thuy
Ha. 2010. A hidden topic-based framework towards
building applications with short web documents. IEEE
Transactions on Knowledge and Data Engineering,
99(PrePrints).

Dou Shen, Rong Pan, Jian-Tao Sun, Jeffrey Junfeng Pan,
Kangheng Wu, Jie Yin, and Giang Yang. 2006a.
Query enrichment for web-query classification. ACM
Transactions on Information Systems, 24(3):320–352.

Dou Shen, Jian-Tao Sun, Qiang Yang, and Zheng Chen.
2006b. Building bridges for web query classification.
In SIGIR’06.

24


