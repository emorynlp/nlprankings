










































Parsing and Translation Algorithms Based on Weighted Extended Tree Transducers


Proceedings of the 2010 Workshop on Applications of Tree Automata in Natural Language Processing, ACL 2010, pages 19–27,
Uppsala, Sweden, 16 July 2010. c©2010 Association for Computational Linguistics

Parsing and Translation Algorithms
Based on Weighted Extended Tree Transducers

Andreas Maletti∗
Departament de Filologies Romàniques

Universitat Rovira i Virgili
Tarragona, Spain

Giorgio Satta
Department of Information Engineering

University of Padua
Padua, Italy

Abstract

This paper proposes a uniform frame-
work for the development of parsing and
translation algorithms for weighted ex-
tended (top-down) tree transducers and in-
put strings. The asymptotic time complex-
ity of these algorithms can be improved
in practice by exploiting an algorithm for
rule factorization in the above transducers.

1 Introduction

In the field of statistical machine translation, con-
siderable interest has recently been shown for
translation models based on weighted tree trans-
ducers. In this paper we consider the so-called
weighted extended (top-down) tree transducers
(WXTTs for short). WXTTs have been proposed
by Graehl and Knight (2004) and Knight (2007)
and are rooted in similar devices introduced ear-
lier in the formal language literature (Arnold and
Dauchet, 1982).

WXTTs have enough expressivity to represent
hierarchical syntactic analyses for natural lan-
guage sentences and can directly model most of
the elementary operations that rule the process
of translation between natural languages (Knight,
2007). Furthermore, the use of weights and in-
ternal states allows the encoding of statistical pa-
rameters that have recently been shown to be ex-
tremely useful in discriminating likely translations
from less plausible ones.

For an WXTT M , the parsing problem is tradi-
tionally defined for a pair of trees t and u and re-
quires as output some representation of the set of
all computations ofM that map t into u. Similarly,
the translation problem forM is defined for an in-
put tree t and requires as output some representa-
tion of the set of all computations of M mapping t

∗Financially supported by the Ministerio de Educación y
Ciencia (MEC) grant JDCI-2007-760.

into any other tree. When we deal with natural
language processing applications, however, pars-
ing and translation are most often represented on
the basis of input strings rather than trees. Some
tricks are then applied to map the problem back
to the case of input trees. As an example in the
context of machine translation, let w be some in-
put string to be translated. One can intermediately
construct a tree automaton Mw that recognizes the
set of all possible trees that have w as yield with
internal nodes from the input alphabet of M . This
automaton Mw is further transformed into a tree
transducer implementing a partial identity trans-
lation. This transducer is then composed with M
(relational composition) to obtain a transducer that
represents all translations of w. This is usually
called the ‘cascaded’ approach.

In contrast with the cascaded approach above,
which may be rather inefficient, we investigate a
more direct technique for both parsing and transla-
tion of strings based on WXTTs. We do this by ex-
tending to WXTTs the well-known BAR-HILLEL
construction defined for context-free grammars
(Bar-Hillel et al., 1964) and for weighted context-
free grammars (Nederhof and Satta, 2003). We
then derive computational complexity results for
parsing and translation of input strings on the ba-
sis of WXTTs. Finally, we develop a novel fac-
torization algorithm for WXTTs that, in practical
applications, can reduce the asymptotic complex-
ity for such problems.

2 Preliminary definitions

Let · be an associative binary operation on a set S.
If S contains an element 1 such that 1·s = s = s·1
for every s ∈ S, then (S, ·, 1) is a monoid. Such
a monoid (S, ·, 1) is commutative if the identity
s1 ·s2 = s2 ·s1 holds for all s1, s2 ∈ S. A commu-
tative semiring (S,+, ·, 0, 1) is an algebraic struc-
ture such that:
• (S,+, 0) and (S, ·, 1) are commutative

19



monoids,
• · distributes over + (from both sides), and
• s · 0 = 0 = 0 · s for every s ∈ S.

From now on, let (S,+, ·, 0, 1) be a com-
mutative semiring. An alphabet is a finite
set of symbols. A weighted string automa-
ton [WSA] (Schützenberger, 1961; Eilenberg,
1974) is a system N = (P,Γ, J, ν, F ) where
• P and Γ are alphabets of states and input

symbols, respectively,
• J, F : P → S assign initial and final weights,

respectively, and
• ν : P × Γ× P → S assigns a weight to each

transition.
The transition weight mapping ν can be under-
stood as square matrices ν(·, γ, ·) ∈ SP×P for ev-
ery γ ∈ Γ. The WSA N is deterministic if
• J(p) 6= 0 for at most one p ∈ P and
• for every p ∈ P and γ ∈ Γ there exists at

most one p′ ∈ P such that ν(p, γ, p′) 6= 0.
We now proceed with the semantics of N . We

will define the initial algebra semantics here; al-
ternative, equivalent definitions of the semantics
exist (Sakarovitch, 2009). Let w ∈ Γ∗ be an in-
put string, γ ∈ Γ, and p, p′ ∈ P be two states.
We extend ν to a mapping hν : P × Γ∗ × P → S
recursively as follows:

hν(p, ε, p
′) =

{
1 if p = p′

0 otherwise

hν(p, γw, p
′) =

∑
p′′∈P

ν(p, γ, p′′) · hν(p′′, w, p′) .

Consequently,

hν(p, uw, p
′) =

∑
p′′∈P

hν(p, u, p
′′) · hν(p′′, w, p′)

for all p, p′ ∈ P and u,w ∈ Γ∗. Then the matrix
hν(·, γ1 · · · γk, ·) equals ν(·, γ1, ·) · . . . · ν(·, γk, ·).
Thus, if the semiring operations can be performed
in constant time and access to ν(p, γ, q) is in con-
stant time for every p, q ∈ P , then for every
w ∈ Γ∗ we can compute the matrix hν(·, w, ·) in
time O(|w| · |P |3) because it can be computed by
|w| − 1 matrix multiplications.

The WSA N computes the map N : Γ∗ → S,
which is defined for every w ∈ Γ∗ by1

N(w) =
∑
p,p′∈P

J(p) · hν(p, w, p′) · F (p′) .

1We overload the symbol N to denote both the WSA and
its recognized mapping. However, the intended meaning will
always be clear from the context.

Since we will also consider individual runs,
let us recall the run semantics as well. Let
w = γ1 · · · γk ∈ Γ∗ be an input string of length k.
Then any mapping r : [0, k] → P is a run of N
on w, where [0, k] denotes the set of integers be-
tween (inclusive) 0 and k. A run can be under-
stood as a vector of states and thus we some-
times write ri instead of r(i). The weight of
such a run r, denoted by wtN (r), is defined by
wtN (r) =

∏k
i=1 ν(ri−1, γi, ri). Then

hν(p, w, p
′) =

∑
r : [0,k]→P
r0=p,rk=p

′

wtN (r)

for every p, p′ ∈ P and w ∈ Γ∗.

3 Weighted extended tree transducers

Next, we move to tree languages, for which we
need to introduce some additional notation. Let
Σ be a ranked alphabet, that is, an alphabet
whose symbols have a unique associated arity. We
write Σk to denote the set of all k-ary symbols
in Σ. We use the special nullary symbol e ∈ Σ0 to
syntactically represent the empty string ε. The set
of Σ-trees indexed by a set V , denoted by TΣ(V ),
is the smallest set satisfying both of the following
conditions:
• for every v ∈ V , the single node labeled v,

written v, is a tree of TΣ(V ),
• for every σ ∈ Σk and t1, . . . , tk ∈ TΣ(V ),

the tree with a root node labeled σ and
trees t1, . . . , tk as its k children, written
σ(t1, . . . , tk), belongs to TΣ(V ).

Throughout this paper we sometimes write σ() as
just σ. In the following, let t ∈ TΣ(V ). The set
of positions Pos(t) ⊆ N∗ of a tree t ∈ TΣ(V ) is
recursively defined as follows:

Pos(v) = {ε}
Pos(t) = {ε} ∪ {iw | 1 ≤ i ≤ k,w ∈ Pos(ti)}

for every v ∈ V , σ ∈ Σk, and t1, . . . , tk ∈ TΣ(V )
where t = σ(t1, . . . , tk). The label of t at posi-
tion w ∈ Pos(t) is denoted by t(w). The size of
the tree t ∈ TΣ is defined as |t| = |Pos(t)|. For
every w ∈ Pos(t) the subtree of t that is rooted
at w is denoted by subt(w); i.e.,

subt(ε) = t

subσ(t1,...,tk)(iw) = subti(w)

20



for every σ ∈ Σk, t1, . . . , tk ∈ TΣ(V ), 1 ≤ i ≤ k,
and w ∈ Pos(ti). Finally, the set of vari-
ables var(t) is given by

var(t) = {v ∈ V | ∃w ∈ Pos(t) : t(w) = v} .

If for every v ∈ var(t) there exists exactly one
w ∈ Pos(t) such that t(w) = v, then t is linear.

We use the fixed sets X = {xi | i ≥ 1} and
Y = {yi,j | 1 ≤ i < j} of formal variables
and the subsets Xk = {xi | 1 ≤ i ≤ k} and
Yk = {yi,j | 1 ≤ i < j ≤ k} for every k ≥ 0.
Note thatX0 = ∅. For everyH ⊆ Σ0∪X∪Y , the
H-yield of t is recursively defined by ydH(t) = t
if t ∈ H \ {e}, ydH(t) = ydH(t1) · · · ydH(tk) if
t = σ(t1, . . . , tk) with σ ∈ Σk and k ≥ 1, and
ydH(t) = ε otherwise. If H = Σ0 ∪X ∪ Y , then
we also omit the index and just write yd(t).

Let l ∈ TΣ(V ) and θ : V → TΣ(V ). Then
lθ denotes the result obtained from l by replacing
every occurrence of v ∈ V by θ(v). The k-fold
application is denoted by lθk. If lθk = lθk+1 for
some k ≥ 0, then we denote lθk by lθ∗. In addi-
tion, if V = Xk, then we write l[θ(x1), . . . , θ(xk)]
instead of lθ. We write CΣ(Xk) for the subset
of those trees of TΣ(Xk) such that every vari-
able of x ∈ Xk occurs exactly once in it. Given
t ∈ TΣ(X), we write dec(t) for the set{

(l, t1, . . . , tk)
∣∣∣ l ∈ CΣ(Xk), l[t1, . . . , tk] = t,
t1, . . . , tk ∈ TΣ(X)

}
A (linear and nondeleting) weighted extended

(top-down) tree transducer [WXTT] (Arnold and
Dauchet, 1975; Arnold and Dauchet, 1976; Lilin,
1981; Arnold and Dauchet, 1982; Maletti et al.,
2009) is a system M = (Q,Σ,∆, I, R) where
• Q is an alphabet of states,
• Σ and ∆ are ranked alphabets of input and

output symbols, respectively,
• I : Q→ S assigns initial weights, and
• R is a finite set of rules of the form

(q, l)
s→ (q1 · · · qk, r) with q, q1, . . . , qk ∈ Q,

l ∈ CΣ(Xk) and r ∈ C∆(Xk), and s ∈ S
such that {l, r} 6⊆ X .

Let us discuss the final restriction imposed on
the rules of a WXTT. Essentially, it disallows rules
of the form (q, x1)

s→ (q′, x1) with q, q′ ∈ Q and
s ∈ S. Such pure epsilon rules only change the
state and charge a cost. However, they can yield
infinite derivations (and with it infinite products
and sums) and are not needed in our applications.
The WXTT M is standard if ydX(r) = x1 · · ·xk

for every (q, l) s→ (q1 · · · qk, r) ∈ R. This restric-
tion enforces that the order of the variables is fixed
on the right-hand side r, but since the order is ar-
bitrary in the left-hand side l (and the names of the
variables are inconsequential), it can be achieved
easily without loss of generality. If there are sev-
eral rules that differ only in the naming of the vari-
ables, then their weights should be added to obtain
a single standard rule. To keep the presentation
simple, we also construct nonstandard WXTTs in
the sequel. However, we implicitly assume that
those are converted into standard WXTTs.

The semantics of a standard WXTT is in-
spired by the initial-algebra semantics for classi-
cal weighted top-down and bottom-up tree trans-
ducers (Fülöp and Vogler, 2009) [also called top-
down and bottom-up tree series transducers by En-
gelfriet et al. (2002)]. Note that our semantics
is equivalent to the classical term rewriting se-
mantics, which is presented by Graehl and Knight
(2004) and Graehl et al. (2008), for example. In
fact, we will present an equivalent semantics based
on runs later. Let M = (Q,Σ,∆, I, R) be a
WXTT. We present a definition that is more gen-
eral than immediately necessary, but the general-
ization will be useful later on. For every n ∈ N,
p1, . . . , pn ∈ Q, and L ⊆ R, we define the
mapping hp1···pnL : TΣ(Xn) × T∆(Xn) → SQ by
hp1···pnL (xi, xi)pi = 1 for every 1 ≤ i ≤ n and

hp1···pnL (t, u)q

=
∑

(l,t1,...,tk)∈dec(t)
(r,u1,...,uk)∈dec(u)
(q,l)

s→(q1···qk,r)∈L

s ·
k∏
i=1

hp1···pnL (ti, ui)qi (1)

for all remaining t ∈ TΣ(Xn), u ∈ T∆(Xn), and
q ∈ Q. Note that for each nonzero summand in (1)
one of the decompositions dec(t) and dec(u) must
be proper (i.e., either l /∈ X or r /∈ X). This
immediately yields that the sum is finite and the
recursion well-defined. The transformation com-
puted by M , also denoted by M , is the map-
ping M : TΣ × T∆ → S, which is defined by
M(t, u) =

∑
q∈Q I(q)·hR(t, u)q for every t ∈ TΣ

and u ∈ T∆.
Let us also introduce a run semantics for the

WXTT (Q,Σ,∆, I, R). The rank of a rule
ρ = (q, l)

s→ (q1 · · · qk, r) ∈ R, denoted by rk(ρ),
is rk(ρ) = k. This turns R into a ranked alphabet.
The input state of ρ is in(ρ) = q, the ith output
state is outi(ρ) = qi for every 1 ≤ i ≤ k, and

21



the weight of ρ is wt(ρ) = s. A tree r ∈ TR(X)
is called run if in(r(wi)) = outi(r(w)) for every
wi ∈ Pos(r) and 1 ≤ i ≤ rk(r(w)) such that
r(wi) ∈ R. The weight of a run r ∈ TR(X) is

wt(r) =
∏

w∈Pos(r),r(w)∈R

wt(r(w)) .

The evaluation mappings π1 : TR(X) → TΣ(X)
and π2 : TR(X) → T∆(X) are defined for every
x ∈ X , ρ = (q, l) s→ (q1 · · · qk, r) ∈ R, and
r1, . . . , rk ∈ TR(X) by π1(x) = x, π2(x) = x,
and

π1(ρ(r1, . . . , rk)) = l[π1(r1), . . . , π1(rk)]

π2(ρ(r1, . . . , rk)) = r[π2(r1), . . . , π2(rk)] .

We obtain the weighted tree transformation for ev-
ery t ∈ TΣ and u ∈ T∆ as follows2

M(t, u) =
∑

run r∈TR
t=π1(r),u=π2(r)

I(in(r(ε))) · wt(r) .

This approach is also called the bimorphism ap-
proach (Arnold and Dauchet, 1982) to tree trans-
formations.

4 Input and output restrictions of WXTT

In this section we will discuss the BAR-HILLEL
construction for the input and the output part of a
WXTT M . This construction essentially restricts
the input or output of the WXTT M to the string
language recognized by a WSA N . Contrary to
(direct or inverse) application, this construction
is supposed to yield another WXTT. More pre-
cisely, the constructed WXTT should assign to
each translation (t, u) the weight assigned to it
by M multiplied by the weight assigned by N
to the yield of t (or u if the output is restricted).
Since our WXTTs are symmetric, we will actu-
ally only need one construction. Let us quickly
establish the mentioned symmetry statement. Es-
sentially we just have to exchange left- and right-
hand sides and redistribute the states in those left-
and right-hand sides accordingly.

From now on, let M = (Q,Σ,∆, I, R) be a
WXTT.

Theorem 1. There exists a WXTT M ′ such that
M ′(u, t) = M(t, u) for every t ∈ TΣ and u ∈ T∆.

2We immediately also use M for the run semantics be-
cause the two semantics trivially coincide.

Proof. Let M ′ = (Q,∆,Σ, I, R′) be the WXTT
such that

R′ = {(q, r) s→ (w, l) | (q, l) s→ (w, r) ∈ R} .

It should be clear that M ′(u, t) = M(t, u) for ev-
ery t ∈ TΣ and u ∈ T∆.

With the symmetry established, we now only
need to present the BAR-HILLEL construction for
either the input or output side. Without loss of
generality, let us assume that M is standard. We
then choose the output side here because the order
of variables is fixed in it. Note that we sometimes
use the angled parentheses ‘〈’ and ‘〉’ instead of
parentheses for clarity.

Definition 2. Let N = (P,Γ, J, ν, F ) be a WSA
with Γ = ∆0 \ {e}. We construct the output prod-
uct Prod(M,N) = (P×Q×P,Σ,∆, I ′, R′) such
that
• I ′(〈p, q, p′〉) = J(p) · I(q) · F (p′) for every
p, p′ ∈ P and q ∈ Q,
• for every rule (q, l) s→ (q1 · · · qk, r) ∈ R and

every p0, . . . , pk, p′0, . . . , p
′
k ∈ P , let

(q′, l)
s·s0·...·sk−−−−−→ (q′1 · · · q′k, r) ∈ R′

where
– q′ = 〈p0, q, p′k〉,
– q′i = 〈p′i−1, qi, pi〉 for every 1 ≤ i ≤ k,
– yd(r) = w0x1w1 · · ·wk−1xkwk with
w0, . . . , wk ∈ Γ∗, and

– si = hν(pi, wi, p′i) for every 0 ≤ i ≤ k.

Let ρ = (q, l) s→ (q1 · · · qk, r) ∈ R. The
size of ρ is |ρ| = |l| + |r|. The size and
rank of the WXTT M are |M | =

∑
ρ∈R|ρ|

and rk(M) = maxρ∈R rk(ρ), respectively. Fi-
nally, the maximal output yield length of M , de-
noted by len(M), is the maximal length of yd(r)
for all rules (q, l) s→ (q1 · · · qk, r) ∈ R.
The size and rank of Prod(M,N) are in
O(|M | · |P |2 rk(M)+2) and rk(M), respec-
tively. We can compute Prod(M,N) in time
O(|R| · len(M) · |P |2 rk(M)+5). If N is de-
terministic, then the size of Prod(M,N) is
in O(|M | · |P |rk(M)+1) and the required time is
inO(|R| · len(M) · |P |rk(M)+1). Next, let us prove
that our BAR-HILLEL construction is actually cor-
rect.

Theorem 3. Let M and N be as in Defini-
tion 2, and let M ′ = Prod(M,N). Then
M ′(t, u) = M(t, u) ·N(yd(u)) for every t ∈ TΣ
and u ∈ T∆.

22



Proof. Let M ′ = (Q′,Σ,∆, I ′, R′). First, a sim-
ple proof shows that

hR′(t, u)〈p,q,p′〉 = hR(t, u)q · hν(p, yd(u), p′)

for every t ∈ TΣ, u ∈ T∆, q ∈ Q, and p, p′ ∈ P .
Now we can prove the main statement as follows:

M ′(t, u)

=
∑
q′∈Q′

I ′(q′) · hR′(t, u)q′

=
∑
p,p′∈P
q∈Q

I ′(〈p, q, p′〉) · hR(t, u)q · hν(p, yd(u), p′)

= M(t, u) ·N(yd(u))

for every t ∈ TΣ and u ∈ T∆.
Note that the typical property of many BAR-

HILLEL constructions, namely that a run of M
and a run of N uniquely determine a run
of Prod(M,N) and vice versa, does not hold for
our construction. In fact, a run of M and a run
of N uniquely determine a run of Prod(M,N),
but the converse does not hold. We could modify
the construction to enable this property at the ex-
pense of an exponential increase in the number of
states of Prod(M,N). However, since those re-
lations are important for our applications, we ex-
plore the relation between runs in some detail here.

To simplify the discussion, we assume, without
loss of generality, that M is standard and s = s′

for every two rules (q, l) s→ (w, r) ∈ R and
(q, l)

s′→ (w, r) ∈ R. Moreover, we assume the
symbols of Definition 2. For every r′ ∈ TR′(X),
we let base(r′) denote the run obtained from r′ by
replacing each symbol

(q′, l)
s·s0·...·sk−−−−−→ (q′1 · · · q′k, r)

by just (q, l) s→ (q1 · · · qk, r) ∈ R. Thus, we re-
place a rule (which is a symbol) of R′ by the un-
derlying rule of R. We start with a general lemma,
which we believe to be self-evident.

Lemma 4. Let r′ ∈ TR′ and n = |yd(π2(r′))|.
Then wtM ′(r′) = wtM (base(r′))·

∑
r∈R′′ wtN (r)

where R′′ is a nonempty subset of
{r : [0, n]→ P | in(r′(ε)) = 〈r0, q, rn〉}.

Let us assume that N is trim (i.e., all states are
reachable and co-reachable) and unambiguous. In
this case, for every γ1 · · · γk ∈ Γ∗ and p, p′ ∈ P
there is at most one successful run r : [0, k] → P
such that

• ν(ri−1, γi, ri) 6= 0 for every 1 ≤ i ≤ k, and
• r0 = p and rk = p′.

This immediately yields the following corollary.

Corollary 5 (of Lemma 4). Let N be trim and
unambiguous. For every r′ ∈ TR′ we have

wtM ′(r
′) = wtM (base(r

′)) · wtN (r)

for some r : [0, n]→ P with n = |yd(π2(r′))|.

We now turn to applications of the product con-
struction. We first consider the translation prob-
lem for an input string w and a WXTTM . We can
represent w as a trim and unambiguous WSA Nw
that recognizes the language {w} with weight
of 1 on each transition (which amounts to ignor-
ing the weight contribution of Nw). Then the in-
put product transducer Mw = Prod(Nw,M) pro-
vides a compact representation of the set of all
computations of M that translate the string w.
From Corollary 5 we have that the weights of
these computations are also preserved. Thus,
Mw(TΣ × T∆) =

∑
(t,u)∈TΣ×T∆ Mw(t, u) is the

weight of the set of string translations of w.
As usual in natural language processing ap-

plications, we can exploit appropriate semirings
and compute several useful statistical parameters
through Mw(TΣ × T∆), as for instance the high-
est weight of a computation, the inside probabil-
ity and the rule expectations; see (Li and Eisner,
2009) for further discussion.

One could also construct in linear time the range
tree automaton for Mw, which can be interpreted
as a parsing forest with all the weighted trees as-
signed to translations of w under M . If we fur-
ther assume thatM is unambiguous, thenMw will
also have this property, and we can apply standard
techniques to extract from Mw the highest score
computation. In machine translation applications,
the unambiguity assumption is usually met, and
avoids the so-called ‘spurious’ ambiguity, that is,
having several computations for an individual pair
of trees.

The parsing problem for input strings w and u
can be treated in a similar way, by restricting M
both to the left and to the right.

5 Rule factorization

As already discussed, the time complexity of the
product construction is an exponential function
of the rank of the transducer. Unfortunately,
it is not possible in the general case to cast a

23



WXTT into a normal form such that the rank is
bounded by some constant. This is also expected
from the fact that the translation problem for sub-
classes of WXTTs such as synchronous context-
free grammars is NP-hard (Satta and Peserico,
2005). Nonetheless, there are cases in which a
rank reduction is possible, which might result in
an improvement of the asymptotical run-time of
our construction.

Following the above line, we present here a
linear time algorithm for reducing the rank of a
WXTT under certain conditions. Similar algo-
rithms for tree-based transformation devices have
been discussed in the literature. Nesson et al.
(2008) consider synchronous tree adjoining gram-
mars; their algorithm is conceptually very sim-
ilar to ours, but computationally more demand-
ing due to the treatment of adjunction. Follow-
ing that work, we also demand here that the new
WXTT ‘preserves’ the recursive structure of the
input WXTT, as formalized below. Galley et al.
(2004) algorithm also behaves in linear time, but
deals with the different problem of tree to string
translation. Rank reduction algorithms for string-
based translation devices have also been discussed
by Zhang et al. (2006) and Gildea et al. (2006).

Recall that M = (Q,Σ,∆, I, R) is a standard
WXTT. Let M ′ = (Q′,Σ,∆, I ′, R′) be a WXTT
with Q ⊆ Q′.3 Then M ′ is a structure-preserving
factorization of M if
• I ′(q) = I(q) for every q ∈ Q and I ′(q) = 0

otherwise, and
• hp1···pnR′ (t, u)q = h

p1···pn
R (t, u)q for every

q, p1, . . . , pn ∈ Q, t ∈ TΣ(Xn), and
u ∈ T∆(Xn).

In particular, we have hR′(t, u)q = hR(t, u)q for
n = 0. Consequently, M ′ and M are equivalent
because

M ′(t, u) =
∑
q∈Q′

I ′(q) · hR′(t, u)q

=
∑
q∈Q

I(q) · hR(t, u)q = M(t, u) .

Note that the relation ‘is structure-preserving fac-
torization of’ is reflexive and transitive, and thus, a
pre-order. Moreover, in a ring (actually, additively
cancellative semirings are sufficient) it is also anti-
symmetric, and consequently, a partial order.

3Actually, an injective mapping Q → Q′ would be suffi-
cient, but since the naming of the states is arbitrary, we im-
mediately identify according to the injective mapping.

Informally, a structure-preserving factorization
ofM consists in a set of new rules that can be com-
posed to provide the original rules and preserve
their weights. We develop an algorithm for finding
a structure-preserving factorization by decompos-
ing each rule as much as possible. The algorithm
can then be iterated for all the rules in the WXTT.
The idea underlying our algorithm is very simple.
Let ρ = (q, l) s→ (q1 · · · qk, r) ∈ R be an origi-
nal rule. We look for subtrees l′ and r′ of l and r,
respectively, such that var(l′) = var(r′). The con-
dition that var(l′) = var(r′) is derived from the
fact that hq1···qkR (l

′, r′)q = 0 if var(l′) 6= var(r′).
We then split ρ into two new rules by ‘excis-
ing’ subtrees l′ and r′ from l and r, respectively.
In the remaining trees the ‘excised’ trees are re-
placed with some fresh variable. The tricky part
is the efficient computation of the pairs (wl, wr),
since in the worst case the number of such pairs
is in Θ(|l| · |r|), and naı̈ve testing of the condition
var(l′) = var(r′) takes time O(rk(ρ)).

Let us start with the formal development. Recall
the doubly-indexed set Y = {yi,j | 1 ≤ i < j}.
Intuitively speaking, the variable yi,j will
represent the set {xi, . . . , xj}. With this
intuition in mind, we define the mapping
vars : TΣ(X ∪ Y )→ N3∞ as follows:

vars(xi) = (i, i, 1)

vars(yi,j) = (i, j, j − i+ 1)

and vars(σ(t1, . . . , tk)) is

(
k

min
`=1

vars(t`)1,
k

max
`=1

vars(t`)2,
k∑
`=1

vars(t`)3)

for every i, j ∈ N with i < j, σ ∈ Σk, and
t1, . . . , tk ∈ TΣ(X ∪ Y ). Clearly, vars(t) can
be computed in time O(|t|), which also in-
cludes the computation of vars(u) for every sub-
tree u of t. In addition, vars(t)3 = |var(t)|
for all linear t ∈ TΣ(X). Finally, if
t ∈ TΣ(X), then vars(t)1 and vars(t)2 are the
minimal and maximal index i ∈ N such that
xi ∈ var(t), respectively (they are ∞ and 0,
respectively, if var(t) = ∅). For better read-
ability, we use minvar(t) and maxvar(t) for
vars(t)1 and vars(t)2, respectively.

Let ρ = (q, l) s→ (q1 · · · qk, r) ∈ R be an origi-
nal rule. In the following, we will use minvar(t),
maxvar(t), and |var(t)| freely for all subtrees t
of l and r and assume that they are precomputed,

24



which can be done in time O(|ρ|). Moreover, we
will freely use the test ‘var(t) = var(u)’ for sub-
trees t and u of l and r, respectively. This test can
be performed in constant time [disregarding the
time needed to precompute vars(t) and vars(u)]
by the equivalent test
• minvar(t) = minvar(u),
• maxvar(t) = maxvar(u),
• |var(t)| = maxvar(t)−minvar(t) + 1, and
• |var(u)| = maxvar(u)−minvar(u) + 1.
Our factorization algorithm is presented in Al-

gorithm 1. Its first two parameters hold the left-
and right-hand side (l, r), which are to be decom-
posed. The third and fourth parameter should ini-
tially be x1. To simplify the algorithm, we assume
that it is only called with left- and right-hand sides
that (i) contain the same variables and (ii) contain
at least two variables. These conditions are en-
sured by the algorithm for the recursive calls. The
algorithm returns a decomposition of (l, r) in the
form of a set D ⊆ TΣ(X ∪ Y ) × T∆(X ∪ Y )
such that var(l′) = var(r′) for every (l′, r′) ∈ D.
Moreover, all such l′ and r′ are linear. Finally, the
pairs in D can be composed (by means of point-
wise substitution at the variables of Y ) to form the
original pair (l, r).

Before we move on to formal properties of Al-
gorithm 1, let us illustrate its execution on an ex-
ample.

Example 6. We work with the left-hand side
l = σ(x1, σ(x3, x2)) and the right-hand side
r = γ(σ(x1, γ(σ(x2, x3)))). Then |var(l)| ≥ 2
and var(l) = var(r). Let us trace the call
DECOMPOSE(l, r, x1, x1). The condition in line 1
is clearly false, so we proceed with line 3. The
condition is true for i = 1, so we continue with
DECOMPOSE(l, σ(x1, γ(σ(x2, x3))), x1, γ(x1)).

This time neither the condition in line 1 nor the
condition in line 3 are true. In line 6, j is set to 1
and we initialize r′1 = x1 and r

′
2 = γ(σ(x2, x3)).

Moreover, the array h is initialized to h(1) = 1,
h(2) = 2, and h(3) = 2. Now let us discuss the
main loop starting in line 12 in more detail. First,
we consider i = 1. Since l1 = x1, the condition in
line 13 is fulfilled and we set l′1 = x1 and proceed
with the next iteration (i = 2). This time the condi-
tion of line 13 is false because l2 = σ(x3, x2) and
var(l2) = var(rh(2)) = var(r2) = {x2, x3}. Con-
sequently, j is set to 2 and l′2 = r

′
2 = y2,3. Next,

DECOMPOSE(σ(x3, x2), γ(σ(x2, x3)), x1, x1) is
processed. Let us suppose that it generates the

set D. Then we return

D ∪ {(σ(x1, y2,3), γ(σ(x1, y2,3)))} .

Finally, let us quickly discuss how the set D
is obtained. Since the condition in line 3 is
true, we have to evaluate the recursive call
DECOMPOSE(σ(x3, x2), σ(x2, x3), x1, γ(x1)).

Now, j = 2, h(2) = 1, and h(3) = 2.
Moreover, r′1 = x2 and r

′
2 = x3. In the

main loop starting in line 12, the condition of
line 13 is always fulfilled, which yields that
l′1 = x3 and l

′
2 = x2. Thus, we return

{(σ(x3, x2), γ(σ(x2, x3)))}, which is exactly the
input because decomposition completely failed.
Thus, the overall decomposition of l and r is

{(σ(x1, y2,3), γ(σ(x1, y2,3))),
(σ(x3, x2), γ(σ(x2, x3)))} ,

which, when the second pair is substituted (point-
wise) for y2,3 in the first pair, yields exactly (l, r).

Informally, the rules are obtained as follows
fromD. If all variables occur in a pair (l′, r′) ∈ D,
then the left-hand side is assigned to the original
input state. Furthermore, for every variable yi,j we
introduce a new fresh state qi,j whereas the vari-
able xi is associated to qi. In this way, we deter-
mine the states in the right-hand side.

Formally, let ρ = (q, l) s→ (q1 · · · qk, r)
be the original rule and D be the result of
DECOMPOSE(l, r, x1, x1) of Algorithm 1. In ad-
dition, for every 1 ≤ i < j ≤ k, let qρ,i,j be a new
state such that qρ,1,k = q. Let

Q′ρ = {q, q1, . . . , qk} ∪ {qρ,i,j | 1 ≤ i < j ≤ k} .

Then for every (l′, r′) ∈ D we obtain the rule

(qρ,minvar(r′),maxvar(r′), l
′)

s′→ (p1 · · · pn, r′)

where ydX∪Y (r
′) = z1 · · · zn,

s′ =

{
s if vars(r′)3 = k
1 otherwise

q′` =

{
qj if z` = xj
qρ,i,j if z` = yi,j

for every 1 ≤ ` ≤ n. The rules obtained in this
fashion are collected in R′ρ.

4 The WXTT dec(M)
is dec(M) = (Q′,Σ,∆, I ′, R′) where

4Those rules need to be normalized to obtain a standard
WXTT.

25



Algorithm 1 DECOMPOSE(l, r, l′, r′) computing the decomposition of linear l ∈ TΣ(Xk) and
r ∈ T∆(Xk) with var(l) = var(r) and |var(l)| ≥ 2.

if l = σ(l1, . . . , lm) and there exists i ∈ N is such that var(li) = var(l) then
2: return DECOMPOSE(li, r, l′[σ(l1, . . . , li−1, x1, li+1, . . . , lm)], r′[x1])

if r = δ(r1, . . . , rn) and there exists i ∈ N is such that var(ri) = var(r) then
4: return DECOMPOSE(l, ri, l′[x1], r′[δ(r1, . . . , ri−1, x1, ri+1, . . . , rn)])

let l = σ(l1, . . . , lm) and r = δ(r1, . . . , rn)
6: j = minvar(r)

for all 1 ≤ i ≤ n do
8: r′i = ri

while j ≤ maxvar(ri) do
10: h(j) = i; j = j + 1
D = ∅

12: for all 1 ≤ i ≤ m do
if |var(li)| ≤ 1 or var(li) 6= var(rh(minvar(li))) then

14: l′i = li
else

16: j = h(minvar(li))
l′i = r

′
j = yminvar(li),maxvar(li)

18: D = D ∪ DECOMPOSE(li, rj , x1, x1)
return D ∪ {(l′[σ(l′1, . . . , l′m)], r′[δ(r′1, . . . , r′n)])}

• Q′ = Q ∪
⋃
ρ∈R,rk(ρ)≥2Q

′
ρ,

• I ′(q) = I(q) for every q ∈ Q and I ′(q) = 0
otherwise, and
• R′ is

{ρ ∈ R | rk(ρ) < 2} ∪
⋃

ρ∈R,rk(ρ)≥2

R′ρ .

To measure the success of the factorization, we
introduce the following notion. The degree of M ,
denoted by deg(M), is the minimal rank of all
structure-preserving factorizations M ′ of M ; i.e.,

deg(M) = min
M ′ a structure-preserving

factorization of M

rk(M ′) .

Then the goal of this section is the efficient com-
putation of a structure-preserving factorizationM ′

of M such that rk(M ′) = deg(M).

Theorem 7. The WXTT dec(M) is a structure-
preserving factorization of M such that
rk(dec(M)) = deg(M). Moreover, dec(M) can
be computed in time O(|M |).
Proof. Let us only discuss the run-time complex-
ity shortly. Clearly, DECOMPOSE(l, r, x1, x1)
should be called once for each rule
(q, l)

s→ (q1 · · · qk, r) ∈ R. In lines 1–4 the
structure of l and r is inspected and the prop-
erties var(li) = var(l) and var(ri) = var(r)
are tested in constant time. Mind that we pre-
computed vars(l) and vars(r), which can be
done in linear time in the size of the rule. Then
each subtree ri is considered in lines 7–10 in
constant time. Finally, we consider all direct input

subtrees li in lines 12–18. The tests involving
the variables are all performed in constant time
due to the preprocessing step that computes
vars(l) and vars(r). Moreover, at most one
recursive call to DECOMPOSE is generated for
each input subtree ti. So if we implement the
union in lines 18 and 19 by a constant-time
operation (such as list concatenation, which can
be done since it is trivially a disjoint union), then
we obtain the linear time-complexity.

6 Concluding remarks

In this paper we have shown how to restrict com-
putations of WXTTs to given input and output
WSA, and have discussed the relevance of this
technique for parsing and translation applications
over input strings, resulting in the computation of
translation forests and other statistical parameters
of interest. We have also shown how to factorize
transducer rules, resulting in an asymptotic reduc-
tion in the complexity for these algorithms.

In machine translation applications transduc-
ers usually have very large sets of rules. One
should then specialize the restriction construction
in such a way that the number of useless rules
for Prod(Nw,M) is considerably reduced, result-
ing in a more efficient construction. This can be
achieved by grounding the construction of the new
rules by means of specialized strategies, as usually
done for parsing based on context-free grammars;
see for instance the parsing algorithms by Younger
(1967) or by Earley (1970).

26



References
André Arnold and Max Dauchet. 1975. Transductions

inversibles de forêts. Thèse 3ème cycle M. Dauchet,
Université de Lille.

André Arnold and Max Dauchet. 1976. Bi-
transductions de forêts. In ICALP, pages 74–86. Ed-
inburgh University Press.

André Arnold and Max Dauchet. 1982. Morphismes
et bimorphismes d’arbres. Theoret. Comput. Sci.,
20(1):33–93.

Yehoshua Bar-Hillel, Micha Perles, and Eliyahu
Shamir. 1964. On formal properties of simple
phrase structure grammars. In Yehoshua Bar-Hillel,
editor, Language and Information: Selected Essays
on their Theory and Application, chapter 9, pages
116–150. Addison Wesley.

Jay Earley. 1970. An efficient context-free parsing al-
gorithm. Commun. ACM, 13(2):94–102.

Samuel Eilenberg. 1974. Automata, Languages, and
Machines, volume 59 of Pure and Applied Math.
Academic Press.

Joost Engelfriet, Zoltán Fülöp, and Heiko Vogler.
2002. Bottom-up and top-down tree series transfor-
mations. J. Autom. Lang. Combin., 7(1):11–70.

Zoltán Fülöp and Heiko Vogler. 2009. Weighted tree
automata and tree transducers. In Manfred Droste,
Werner Kuich, and Heiko Vogler, editors, Hand-
book of Weighted Automata, EATCS Monographs on
Theoret. Comput. Sci., chapter IX, pages 313–403.
Springer.

Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What’s in a translation rule?
In Proc. HLT-NAACL, pages 273–280. Association
for Computational Linguistics.

Daniel Gildea, Giorgio Satta, and Hao Zhang. 2006.
Factoring synchronous grammars by sorting. In
Proc. CoLing/ACL, pages 279–286. Association for
Computational Linguistics.

Jonathan Graehl and Kevin Knight. 2004. Training
tree transducers. In HLT-NAACL, pages 105–112.
Association for Computational Linguistics. See
also (Graehl et al., 2008).

Jonathan Graehl, Kevin Knight, and Jonathan May.
2008. Training tree transducers. Computational
Linguistics, 34(3):391–427.

Kevin Knight. 2007. Capturing practical natural
language transformations. Machine Translation,
21(2):121–133.

Zhifei Li and Jason Eisner. 2009. First- and second-
order expectation semirings with applications to
minimum-risk training on translation forests. In
Proc. EMNLP, pages 40–51. Association for Com-
putational Linguistics.

Eric Lilin. 1981. Propriétés de clôture d’une extension
de transducteurs d’arbres déterministes. In CAAP,
volume 112 of LNCS, pages 280–289. Springer.

Andreas Maletti, Jonathan Graehl, Mark Hopkins,
and Kevin Knight. 2009. The power of ex-
tended top-down tree transducers. SIAM J. Comput.,
39(2):410–430.

Mark-Jan Nederhof and Giorgio Satta. 2003. Prob-
abilistic parsing as intersection. In Proc. IWPT,
pages 137–148. Association for Computational Lin-
guistics.

Rebecca Nesson, Giorgio Satta, and Stuart M. Shieber.
2008. Optimal k-arization of synchronous tree-
adjoining grammar. In Proc. ACL, pages 604–612.
Association for Computational Linguistics.

Jacques Sakarovitch. 2009. Rational and recognisable
power series. In Manfred Droste, Werner Kuich, and
Heiko Vogler, editors, Handbook of Weighted Au-
tomata, EATCS Monographs on Theoret. Comput.
Sci., chapter IV, pages 105–174. Springer.

Giorgio Satta and Enoch Peserico. 2005. Some
computational complexity results for synchronous
context-free grammars. In Proc. HLT-EMNLP,
pages 803–810. Association for Computational Lin-
guistics.

Marcel Paul Schützenberger. 1961. On the definition
of a family of automata. Information and Control,
4(2–3):245–270.

Daniel H. Younger. 1967. Recognition and parsing of
context-free languages in time n3. Inform. Control,
10(2):189–208.

Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Knight. 2006. Synchronous binarization for ma-
chine translation. In Proc. HLT-NAACL, pages 256–
263. Association for Computational Linguistics.

27


