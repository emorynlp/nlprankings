










































A Tree Transducer Model for Synchronous Tree-Adjoining Grammars


Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1067–1076,
Uppsala, Sweden, 11-16 July 2010. c©2010 Association for Computational Linguistics

A Tree Transducer Model for Synchronous Tree-Adjoining Grammars

Andreas Maletti
Universitat Rovira i Virgili

Avinguda de Catalunya 25, 43002 Tarragona, Spain.
andreas.maletti@urv.cat

Abstract
A characterization of the expressive power
of synchronous tree-adjoining grammars
(STAGs) in terms of tree transducers (or
equivalently, synchronous tree substitution
grammars) is developed. Essentially, a
STAG corresponds to an extended tree
transducer that uses explicit substitution in
both the input and output. This characteri-
zation allows the easy integration of STAG
into toolkits for extended tree transducers.
Moreover, the applicability of the charac-
terization to several representational and
algorithmic problems is demonstrated.

1 Introduction

Machine translation has seen a multitude of for-
mal translation models. Here we focus on syntax-
based (or tree-based) models. One of the old-
est models is the synchronous context-free gram-
mar (Aho and Ullman, 1972). It is clearly too
weak as a syntax-based model, but found use in
the string-based setting. Top-down tree transduc-
ers (Rounds, 1970; Thatcher, 1970) have been
heavily investigated in the formal language com-
munity (Gécseg and Steinby, 1984; Gécseg and
Steinby, 1997), but as argued by Shieber (2004)
they are still too weak for syntax-based machine
translation. Instead Shieber (2004) proposes syn-
chronous tree substitution grammars (STSGs) and
develops an equivalent bimorphism (Arnold and
Dauchet, 1982) characterization. This character-
ization eventually led to the rediscovery of ex-
tended tree transducers (Graehl and Knight, 2004;
Knight and Graehl, 2005; Graehl et al., 2008),
which are essentially as powerful as STSG. They
had been studied already by Arnold and Dauchet
(1982) in the form of bimorphisms, but received
little attention until rediscovered.

Shieber (2007) claims that even STSGs might
be too simple to capture naturally occuring transla-

tion phenomena. Instead Shieber (2007) suggests
a yet more powerful mechanism, synchronous
tree-adjoining grammars (STAGs) as introduced
by Shieber and Schabes (1990), that can capture
certain (mildly) context-sensitive features of natu-
ral language. In the tradition of Shieber (2004), a
characterization of the power of STAGs in terms
of bimorphims was developed by Shieber (2006).
The bimorphisms used are rather unconventional
because they consist of a regular tree language and
two embedded tree transducers (instead of two tree
homomorphisms). Such embedded tree transduc-
ers (Shieber, 2006) are particular macro tree trans-
ducers (Courcelle and Franchi-Zannettacci, 1982;
Engelfriet and Vogler, 1985).

In this contribution, we try to unify the pic-
ture even further. We will develop a tree trans-
ducer model that can simulate STAGs. It turns out
that the adjunction operation of an STAG can be
explained easily by explicit substitution. In this
sense, the slogan that an STAG is an STSG with
adjunction, which refers to the syntax, also trans-
lates to the semantics. We prove that any tree
transformation computed by an STAG can also be
computed by an STSG using explicit substitution.
Thus, a simple evaluation procedure that performs
the explicit substitution is all that is needed to sim-
ulate an STAG in a toolkit for STSGs or extended
tree transducers like TIBURON by May and Knight
(2006).

We show that some standard algorithms on
STAG can actually be run on the constructed
STSG, which often is simpler and better under-
stood. Further, it might be easier to develop new
algorithms with the alternative characterization,
which we demonstrate with a product construc-
tion for input restriction in the spirit of Neder-
hof (2009). Finally, we also present a complete
tree transducer model that is as powerful as STAG,
which is an extension of the embedded tree trans-
ducers of Shieber (2006).

1067



2 Notation

We quickly recall some central notions about trees,
tree languages, and tree transformations. For a
more in-depth discussion we refer to Gécseg and
Steinby (1984) and Gécseg and Steinby (1997). A
finite set Σ of labels is an alphabet. The set of all
strings over that alphabet is Σ∗ where ε denotes
the empty string. To simplify the presentation, we
assume an infinite set X = {x1, x2, . . . } of vari-
ables. Those variables are syntactic and represent
only themselves. In particular, they are all differ-
ent. For each k ≥ 0, we let Xk = {x1, . . . , xk}.
We can also form trees over the alphabet Σ. To
allow some more flexibility, we will also allow
leaves from a special set V . Formally, a Σ-tree
over V is either:
• a leaf labeled with an element of v ∈ Σ ∪ V ,

or
• a node that is labeled with an element of Σ

with k ≥ 1 children such that each child is a
Σ-tree over V itself.1

The set of all Σ-trees over V is denoted by TΣ(V ).
We just write TΣ for TΣ(∅). The trees in Figure 1
are, for example, elements of T∆(Y ) where

∆ = {S,NP,VP,V,DT,N}
Y = {saw, the} .

We often present trees as terms. A leaf labeled v
is simply written as v. The tree with a root node
labeled σ is written σ(t1, . . . , tk) where t1, . . . , tk
are the term representations of its k children.

A tree language is any subset of TΣ(V ) for
some alphabet Σ and set V . Given another al-
phabet ∆ and a set Y , a tree transformation is a
relation τ ⊆ TΣ(V ) × T∆(Y ). In many of our
examples we have V = ∅ = Y . Occasionally,
we also speak about the translation of a tree trans-
formation τ ⊆ TΣ × T∆. The translation of τ is
the relation {(yd(t), yd(u)) | (t, u) ∈ τ} where
yd(t), the yield of t, is the sequence of leaf labels
in a left-to-right tree traversal of t. The yield of the
third tree in Figure 1 is “the N saw the N”. Note
that the translation is a relation τ ′ ⊆ Σ∗ ×∆∗.

3 Substitution

A standard operation on (labeled) trees is substitu-
tion, which replaces leaves with a specified label
in one tree by another tree. We write t[u]A for (the

1Note that we do not require the symbols to have a fixed
rank; i.e., a symbol does not determine its number of children.

S

NP VP

V

saw

NP

NP

DT

the

N

S

NP

DT

the

N

VP

V

saw

NP

DT

the

N

t u t[u]NP

Figure 1: A substitution.

result of) the substitution that replaces all leaves
labeled A in the tree t by the tree u. If t ∈ TΣ(V )
and u ∈ T∆(Y ), then t[u]A ∈ TΣ∪∆(V ∪ Y ). We
often use the variables of X = {x1, x2, . . . } as
substitution points and write t[u1, . . . , uk] instead
of (· · · (t[u1]x1) . . . )[uk]xk .

An example substitution is shown in Figure 1.
The figure also illustrates a common problem with
substitution. Occasionally, it is not desirable to re-
place all leaves with a certain label by the same
tree. In the depicted example, we might want
to replace one ‘NP’ by a different tree, which
cannot be achieved with substitution. Clearly,
this problem is avoided if the source tree t con-
tains only one leaf labeled A. We call a tree A-
proper if it contains exactly one leaf with labelA.2

The subset CΣ(Xk) ⊆ TΣ(Xk) contains exactly
those trees of TΣ(Xk) that are xi-proper for every
1 ≤ i ≤ k. For example, the tree t of Figure 1 is
‘saw’-proper, and the tree u of Figure 1 is ‘the’-
and ‘N’-proper.

In this contribution, we will also use substitu-
tion as an explicit operator. The tree t[u]NP in
Figure 1 only shows the result of the substitution.
It cannot be infered from the tree alone, how it
was obtained (if we do not know t and u).3 To
make substitution explicit, we use the special bi-
nary symbols ·[·]A where A is a label. Those sym-
bols will always be used with exactly two chil-
dren (i.e., as binary symbols). Since this prop-
erty can easily be checked by all considered de-
vices, we ignore trees that use those symbols in a
non-binary manner. For every set Σ of labels, we
let Σ = Σ ∪ {·[·]A | A ∈ Σ} be the extended
set of labels containing also the substition sym-
bols. The substitution of Figure 1 can then be ex-

2A-proper trees are sometimes also called A-context in
the literature.

3This remains true even if we know that the participating
trees t and u are A-proper and the substitution t[u]A replac-
ing leaves labeled A was used. This is due to the fact that, in
general, the root label of u need not coincide with A.

1068



pressed as the tree ·[·]NP(t, u). To obtain t[u]NP
(the right-most tree in Figure 1), we have to evalu-
ate ·[·]NP(t, u). However, we want to replace only
one leaf at a time. Consequently, we restrict the
evaluation of ·[·]A(t, u) such that it applies only to
trees t whose evaluation is A-proper. To enforce
this restriction, we introduce an error signal ⊥,
which we assume not to occur in any set of la-
bels. Let Σ be the set of labels. Then we define
the function ·E : TΣ → TΣ ∪ {⊥} by4

σ(t1, . . . , tk)
E = σ(tE1 , . . . , t

E
k )

·[·]A(t, u)E =

{
tE[uE]A if tE is A-proper
⊥ otherwise

for every k ≥ 0, σ ∈ Σ, and t, t1, . . . , tk, u ∈ TΣ.5
We generally discard all trees that contain the er-
ror signal ⊥. Since the devices that we will study
later can also check the required A-properness us-
ing their state behavior, we generally do not dis-
cuss trees with error symbols explicitly.

4 Extended tree transducer

An extended tree transducer is a theoretical model
that computes a tree transformation. Such trans-
ducers have been studied first by Arnold and
Dauchet (1982) in a purely theoretic setting, but
were later applied in, for example, machine trans-
lation (Knight and Graehl, 2005; Knight, 2007;
Graehl et al., 2008; Graehl et al., 2009). Their
popularity in machine translation is due to Shieber
(2004), in which it is shown that extended tree
transducers are essentially (up to a relabeling) as
expressive as synchronous tree substitution gram-
mars (STSG). We refer to Chiang (2006) for an
introduction to synchronous devices.

Let us recall the formal definition. An ex-
tended tree transducer (for short: XTT)6 is a sys-
tem M = (Q,Σ,∆, I, R) where
• Q is a finite set of states,
• Σ and ∆ are alphabets of input and output

symbols, respectively,
• I ⊆ Q is a set of initial states, and
• R is a finite set of rules of the form

(q, l)→ (q1 · · · qk, r)
4Formally, we should introduce an evaluation function for

each alphabet Σ, but we assume that the alphabet can be in-
fered.

5This evaluation is a special case of a yield-mapping (En-
gelfriet and Vogler, 1985).

6Using the notions of Graehl et al. (2009) our extended
tree transducers are linear, nondeleting extended top-down
tree transducers.

qS

S

x1 VP

x2 x3

→

S’

qV

x2

qNP

x1

qNP

x3

qNP

NP

DT

the

N

boy

→

NP

N

atefl

Figure 2: Example rules taken from Graehl et al.
(2009). The term representation of the first rule
is (qS,S(x1,VP(x2, x3))) → (w,S′(x2, x1, x3))
where w = qNPqVqNP.

where k ≥ 0, l ∈ CΣ(Xk), and r ∈ C∆(Xk).
Recall that any tree of CΣ(Xk) contains each

variable of Xk = {x1, . . . , xk} exactly once. In
graphical representations of a rule

(q, l)→ (q1 · · · qk, r) ∈ R ,

we usually
• add the state q as root node of the left-hand

side7, and
• add the states q1, . . . , qk on top of the nodes

labeled x1, . . . , xk, respectively, in the right-
hand side of the rule.

Some example rules are displayed in Figure 2.
The rules are applied in the expected way (as in

a term-rewrite system). The only additional fea-
ture are the states of Q, which can be used to con-
trol the derivation. A sentential form is a tree that
contains exclusively output symbols towards the
root and remaining parts of the input headed by a
state as leaves. A derivation step starting from ξ
then consists in
• selecting a leaf of ξ with remaining input

symbols,
• matching the state q and the left-hand side l

of a rule (q, l) → (q1 · · · qk, r) ∈ R to the
state and input tree stored in the leaf, thus
matching input subtrees t1, . . . , tk to the vari-
ables x1, . . . , xk,
• replacing all the variables x1, . . . , xk in the

right-hand side r by the matched input sub-
trees q1(t1), . . . , qk(tk) headed by the corre-
sponding state, respectively, and
• replacing the selected leaf in ξ by the tree

constructed in the previous item.
The process is illustrated in Figure 3.

Formally, a sentential form of the XTT M is a
tree of SF = T∆(Q(TΣ)) where

Q(TΣ) = {q(t) | q ∈ Q, t ∈ TΣ} .
7States are thus also special symbols that are exclusively

used as unary symbols.

1069



C

qS

S

t1

VP

t2 t3

⇒

C

S’

qV

t2

qNP

t1

qNP

t3

Figure 3: Illustration of a derivation step of an
XTT using the left rule of Figure 2.

Given ξ, ζ ∈ SF, we write ξ ⇒ ζ if there ex-
ist C ∈ C∆(X1), t1, . . . , tk ∈ TΣ, and a rule
(q, l)→ (q1 · · · qk, r) ∈ R such that
• ξ = C[q(l[t1, . . . , tk])] and
• ζ = C[r[q1(t1), . . . , qk(tk)]].

The tree transformation computed by M is the re-
lation

τM = {(t, u) ∈ TΣ × T∆ | ∃q ∈ I : q(t)⇒∗ u}

where⇒∗ is the reflexive, transitive closure of⇒.
In other words, the tree t can be transformed into u
if there exists an initial state q such that we can
derive u from q(t) in several derivation steps.

We refer to Arnold and Dauchet (1982), Graehl
et al. (2008), and Graehl et al. (2009) for a more
detailed exposition to XTT.

5 Synchronous tree-adjoining grammar

XTT are a simple, natural model for tree trans-
formations, however they are not suitably ex-
pressive for all applications in machine transla-
tion (Shieber, 2007). In particular, all tree trans-
formations of XTT have a certain locality condi-
tion, which yields that the input tree and its corre-
sponding translation cannot be separated by an un-
bounded distance. To overcome this problem and
certain dependency problems, Shieber and Sch-
abes (1990) and Shieber (2007) suggest a stronger
model called synchronous tree-adjoining gram-
mar (STAG), which in addition to the substitution
operation of STSG (Chiang, 2005) also has an ad-
joining operation.

Let us recall the model in some detail. A tree-
adjoining grammar essentially is a regular tree
grammar (Gécseg and Steinby, 1984; Gécseg and

NP

DT

les

N

bonbons

N

N? ADJ

rouges

NP

DT

les

N

N

bonbons

ADJ

rouges

derived
tree

auxiliary
tree

adjunction

Figure 4: Illustration of an adjunction taken from
Nesson et al. (2008).

NP

DT

les

·[·]N?

N

N? ADJ

rouges

N

bonbons

Figure 5: Illustration of the adjunction of Figure 4
using explicit substitution.

Steinby, 1997) enhanced with an adjunction oper-
ation. Roughly speaking, an adjunction replaces a
node (not necessarily a leaf) by an auxiliary tree,
which has exactly one distinguished foot node.
The original children of the replaced node will be-
come the children of the foot node after adjunc-
tion. Traditionally, the root label and the label of
the foot node coincide in an auxiliary tree aside
from a star index that marks the foot node. For
example, if the root node of an auxiliary tree is
labeled A, then the foot node is traditionally la-
beled A?. The star index is not reproduced once
adjoined. Formally, the adjunction of the auxil-
iary tree u with root label A (and foot node la-
bel A?) into a tree t = C[A(t1, . . . , tk)] with
C ∈ CΣ(X1) and t1, . . . , tk ∈ TΣ is

C[u[A(t1, . . . , tk)]A? ] .

Adjunction is illustrated in Figure 4.
We note that adjunction can easily be expressed

using explicit substitution. Essentially, only an ad-
ditional node with the adjoined subtree is added.
The result of the adjunction of Figure 4 using ex-
plicit substitution is displayed in Figure 5.

To simplify the development, we will make
some assumptions on all tree-adjoining grammars
(and synchronous tree-adjoining grammars). A
tree-adjoining grammar (TAG) is a finite set of
initial trees and a finite set of auxiliary trees. Our

1070



S

T

c

S

a S

S? a

S

b S

S? b

S

S?

initial
tree

auxiliary
tree

auxiliary
tree

auxiliary
tree

Figure 6: A TAG for the copy string language
{wcw | w ∈ {a, b}∗} taken from Shieber (2006).

TAG do not use substitution, but only adjunction.
A derivation is a chain of trees that starts with an
initial tree and each derived tree is obtained from
the previous one in the chain by adjunction of an
auxiliary tree. As in Shieber (2006) we assume
that all adjunctions are mandatory; i.e., if an aux-
iliary tree can be adjoined, then we need to make
an adjunction. Thus, a derivation starting from an
initial tree to a derived tree is complete if no ad-
junction is possible in the derived tree. Moreover,
we assume that to each node only one adjunction
can be applied. This is easily achieved by label-
ing the root of each adjoined auxiliary tree by a
special marker. Traditionally, the root label A of
an auxiliary tree is replaced by A∅ once adjoined.
Since we assume that there are no auxiliary trees
with such a root label, no further adjunction is pos-
sible at such nodes. Another effect of this restric-
tion is that the number of operable nodes (i.e., the
nodes to which an adjunction must still be applied)
is known at any given time.8 A full TAG with our
restrictions is shown in Figure 6.

Intuitively, a synchronous tree-adjoining gram-
mar (STAG) is essentially a pair of TAGs. The
synchronization is achieved by pairing the initial
trees and the auxiliary trees. In addition, for each
such pair (t, u) of trees, there exists a bijection be-
tween the operable nodes of t and u. Such nodes in
bijection are linked and the links are preserved in
derivations, in which we now use pairs of trees as
sentential forms. In graphical representations we
often indicate this bijection with integers; i.e., two
nodes marked with the same integer are linked. A
pair of auxiliary trees is then adjoined to linked
nodes (one in each tree of the sentential form) in
the expected manner. We will avoid a formal def-
inition here, but rather present an example STAG
and a derivation with it in Figures 7 and 8. For a

8Without the given restrictions, this number cannot be de-
termined easily because no or several adjunctions can take
place at a certain node.

S1

T

c

—

S1

T

c

S

S1

a S? a

—

S

a S1

S? a

S

S?

—
S

S?

S

S1

b S? b

—

S

b S1

S? b

Figure 7: STAG that computes the translation
{(wcwR, wcw) | w ∈ {a, b}∗} where wR is the
reverse of w.

STAG G we write τG for the tree transformation
computed by G.

6 Main result

In this section, we will present our main result. Es-
sentially, it states that a STAG is as powerful as a
STSG using explicit substitution. Thus, for every
tree transformation computed by a STAG, there is
an extended tree transducer that computes a repre-
sentation of the tree transformation using explicit
substitution. The converse is also true. For every
extended tree transducer M that uses explicit sub-
stitution, we can construct a STAG that computes
the tree transformation represented by τM up to
a relabeling (a mapping that consistently replaces
node labels throughout the tree). The additional
relabeling is required because STAGs do not have
states. If we replace the extended tree transducer
by a STSG, then the result holds even without the
relabeling.

Theorem 1 For every STAG G, there exists an ex-
tended tree transducer M such that

τG = {(tE, uE) | (t, u) ∈ τM} .

Conversely, for every extended tree transducerM ,
there exists a STAG G such that the above relation
holds up to a relabeling.

6.1 Proof sketch

The following proof sketch is intended for readers
that are familiar with the literature on embedded
tree transducers, macro tree transducers, and bi-
morphisms. It can safely be skipped because we
will illustrate the relevant construction on our ex-
ample after the proof sketch, which contains the
outline for the correctness.

1071



S1

T

c

—

S1

T

c

S

S1

a S

T

c

a —

S

a S1

S

T

c

a

S

S

S1

b S

a S

T

c

a

b —

S

a S

b S1

S

S

T

c

a

b

S

S

S

S1

a S

b S

a S

T

c

a

b

a —

S

a S

b S

a S1

S

S

S

T

c

a

b

a

Figure 8: An incomplete derivation using the STAG of Figure 7.

Let τ ⊆ TΣ × T∆ be a tree transformation
computed by a STAG. By Shieber (2006) there
exists a regular tree language L ⊆ TΓ and two
functions e1 : TΓ → TΣ and e2 : TΓ → T∆ such
that τ = {(e1(t), e2(t)) | t ∈ L}. Moreover,
e1 and e2 can be computed by embedded tree
transducers (Shieber, 2006), which are particu-
lar 1-state, deterministic, total, 1-parameter, lin-
ear, and nondeleting macro tree transducers (Cour-
celle and Franchi-Zannettacci, 1982; Engelfriet
and Vogler, 1985). In fact, the converse is also true
up to a relabeling, which is also shown in Shieber
(2006). The outer part of Figure 9 illustrates these
relations. Finally, we remark that all involved con-
structions are effective.

Using a result of Engelfriet and Vogler (1985),
each embedded tree transducer can be decom-
posed into a top-down tree transducer (Gécseg
and Steinby, 1984; Gécseg and Steinby, 1997)
and a yield-mapping. In our particular case, the
top-down tree transducers are linear and nondelet-
ing homomorphisms h1 and h2. Linearity and
nondeletion are inherited from the corresponding
properties of the macro tree transducer. The prop-
erties ‘1-state’, ‘deterministic’, and ‘total’ of the
macro tree transducer ensure that the obtained top-
down tree transducer is also 1-state, determinis-
tic, and total, which means that it is a homomor-
phism. Finally, the 1-parameter property yields
that the used substitution symbols are binary (as
our substitution symbols ·[·]A). Consequently, the
yield-mapping actually coincides with our evalua-
tion. Again, this decomposition actually is a char-
acterization of embedded tree transducers. Now
the set {(h1(t), h2(t)) | t ∈ L} can be computed

h1 h2

·E ·E

τM

τ

e1 e2

Figure 9: Illustration of the proof sketch.

by an extended tree transducer M due to results
of Shieber (2004) and Maletti (2008). More pre-
cisely, every extended tree transducer computes
such a set, so that also this step is a characteri-
zation. Thus we obtain that τ is an evaluation of a
tree transformation computed by an extended tree
transducer, and moreover, for each extended tree
transducer, the evaluation can be computed (up to
a relabeling) by a STAG. The overall proof struc-
ture is illustrated in Figure 9.

6.2 Example

Let us illustrate one direction (the construction
of the extended tree transducer) on our example
STAG of Figure 7. Essentially, we just prepare all
operable nodes by inserting an explicit substitu-
tion just on top of them. The first subtree of that
substitution will either be a variable (in the left-
hand side of a rule) or a variable headed by a state
(in the right-hand side of a rule). The numbers of
the variables encode the links of the STAG. Two
example rules obtained from the STAG of Figure 7
are presented in Figure 10. Using all XTT rules
constructed for the STAG of Figure 7, we present

1072



qS

·[·]S?

x1 S

T

c

→

·[·]S?

qS

x1

S

T

c

qS

S

·[·]S?

x1 S

a S? a

→

S

a ·[·]S?

qS

x1

S

S? a

Figure 10: Two constructed XTT rules.

a complete derivation of the XTT in Figure 11 that
(up to the final step) matches the derivation of the
STAG in Figure 8. The matching is achieved by
the evaluation ·E introduced in Section 3 (i.e., ap-
plying the evaluation to the derived trees of Fig-
ure 11 yields the corresponding derived trees of
Figure 8.

7 Applications

In this section, we will discuss a few applications
of our main result. Those range from representa-
tional issues to algorithmic problems. Finally, we
also present a tree transducer model that includes
explicit substitution. Such a model might help to
address algorithmic problems because derivation
and evaluation are intertwined in the model and
not separate as in our main result.

7.1 Toolkits
Obviously, our characterization can be applied in
a toolkit for extended tree transducers (or STSG)
such as TIBURON by May and Knight (2006) to
simulate STAG. The existing infrastructure (input-
output, derivation mechanism, etc) for extended
tree transducers can be re-used to run XTTs en-
coding STAGs. The only additional overhead is
the implementation of the evaluation, which is a
straightforward recursive function (as defined in
Section 3). After that any STAG can be simulated
in the existing framework, which allows experi-
ments with STAG and an evaluation of their ex-
pressive power without the need to develop a new
toolkit. It should be remarked that some essential
algorithms that are very sensitive to the input and
output behavior (such as parsing) cannot be sim-
ulated by the corresponding algorithms for STSG.
It remains an open problem whether the close rela-
tionship can also be exploited for such algorithms.

7.2 Algorithms
We already mentioned in the previous section
that some algorithms do not easily translate from

STAG to STSG (or vice versa) with the help of
our characterization. However, many standard al-
gorithms for STAG can easily be derived from
the corresponding algorithms for STSG. The sim-
plest example is the union of two STAG. Instead
of taking the union of two STAG using the clas-
sical construction, we can take the union of the
corresponding XTT (or STSG) that simulate the
STAGs. Their union will simulate the union of the
STAGs. Such properties are especially valuable
when we simulate STAG in toolkits for XTT.

A second standard algorithm that easily trans-
lates is the algorithm computing the n-best deriva-
tions (Huang and Chiang, 2005). Clearly, the n-
best derivation algorithm does not consider a par-
ticular input or output tree. Since the derivations
of the XTT match the derivations of the STAG
(in the former the input and output are encoded
using explicit substitution), the n-best derivations
will coincide. If we are additionally interested in
the input and output trees for those n-best deriva-
tions, then we can simply evaluate the coded input
and output trees returned by n-best derivation al-
gorithm.

Finally, let us consider an algorithm that can be
obtained for STAG by developing it for XTT us-
ing explicit substitution. We will develop a BAR-
HILLEL (Bar-Hillel et al., 1964) construction for
STAG. Thus, given a STAG G and a recognizable
tree language L, we want to construct a STAG G′

such that

τG′ = {(t, u) | (t, u) ∈ τG, t ∈ L} .

In other words, we take the tree transformation τG
but additionally require the input tree to be in L.
Consequently, this operation is also called input
restriction. Since STAG are symmetric, the corre-
sponding output restriction can be obtained in the
same manner. Note that a classical BAR-HILLEL
construction restricting to a regular set of yields
can be obtained easily as a particular input restric-
tion. As in Nederhof (2009) a change of model
is beneficial for the development of such an algo-
rithm, so we will develop an input restriction for
XTT using explicit substitution.

Let M = (Q,Σ,∆, I, R) be an XTT (using ex-
plicit substitution) and G = (N,Σ, I ′, P ) be a
tree substitution grammar (regular tree grammar)
in normal form that recognizesL (i.e.,L(G) = L).
Let S = {A ∈ Σ | ·[·]A ∈ Σ}. A context is a map-
ping c : S → N , which remembers a nontermi-
nal of G for each substitution point. Given a rule

1073



qS

·[·]S?

S

·[·]S?

S

·[·]S?

S

·[·]S?

S

S?

S

a S? a

S

b S? b

S

a S? a

S

T

c
⇒

·[·]S?

qS

S

·[·]S?

S

·[·]S?

S

·[·]S?

S

S?

S

a S? a

S

b S? b

S

a S? a

S

T

c

⇒

·[·]S?

S

a ·[·]S?

qS

S

·[·]S?

S

·[·]S?

S

S?

S

a S? a

S

b S? b

S

S? a

S

T

c

⇒

·[·]S?

S

a ·[·]S?

S

b ·[·]S?

qS

S

·[·]S?

S

S?

S

a S? a

S

S? b

S

S? a

S

T

c

⇒

·[·]S?

S

a ·[·]S?

S

b ·[·]S?

S

a ·[·]S?

qS

S

S?

S

S? a

S

S? b

S

S? a

S

T

c

⇒

·[·]S?

S

a ·[·]S?

S

b ·[·]S?

S

a ·[·]S?

S

S?

S

S? a

S

S? b

S

S? a

S

T

c

Figure 11: Complete derivation using the constructed XTT rules.

(q, l) → (q1 · · · qk, r) ∈ R, a nonterminal p ∈ N ,
and a context c ∈ S, we construct new rules cor-
responding to successful parses of l subject to the
following restrictions:
• If l = ·[·]A(l1, l2) for some A ∈ Σ, then se-

lect p′ ∈ N , parse l1 in p with context c′
where c′ = c[A 7→ p′]9, and parse l2 in p′
with context c.
• If l = A? with A ∈ Σ, then p = c(A).
• Finally, if l = σ(l1, . . . , lk) for some σ ∈ Σ,

then select p → σ(p1, . . . , pk) ∈ P is a pro-
duction of G and we parse li with nontermi-
nal pi and context c for each 1 ≤ i ≤ k.

7.3 A complete tree transducer model

So far, we have specified a tree transducer model
that requires some additional parsing before it can
be applied. This parsing step has to annotate (and
correspondingly restructure) the input tree by the
adjunction points. This is best illustrated by the
left tree in the last pair of trees in Figure 8. To run
our constructed XTT on the trivially completed
version of this input tree, it has to be transformed
into the first tree of Figure 11, where the adjunc-
tions are now visible. In fact, a second un-parsing
step is required to evaluate the output.

To avoid the first additional parsing step, we
will now modify our tree transducer model such
that this parsing step is part of its semantics. This
shows that it can also be done locally (instead of
globally parsing the whole input tree). In addition,
we arrive at a tree transducer model that exactly
(up to a relabeling) matches the power of STAG,
which can be useful for certain constructions. It is
known that an embedded tree transducer (Shieber,
2006) can handle the mentioned un-parsing step.

An extended embedded tree transducer with
9c′ is the same as c except that it maps A to p′.

substitution M = (Q,Σ,∆, I, R) is simply an
embedded tree transducer with extended left-hand
sides (i.e., any number of input symbols is allowed
in the left-hand side) that uses the special sym-
bols ·[·]A in the input. Formally, let
• Q = Q0 ∪ Q1 be finite where Q0 and Q1

are the set of states that do not and do have a
context parameter, respectively,
• Σ and ∆ be ranked alphabets such that if
·[·]A ∈ Σ, then A,A? ∈ Σ,
• Q〈U〉 be such that

Q〈U〉 = {q〈u〉 | q ∈ Q1, u ∈ U} ∪
∪ {q〈〉 | q ∈ Q0} ,

• I ⊆ Q〈T∆〉, and
• R is a finite set of rules l→ r such that there

exists k ≥ 0 with l ∈ Q〈{y}〉(CΣ(Xk)) and
r ∈ Rhsk where

Rhsk := δ(Rhsk, . . . ,Rhsk) |
| q1〈Rhsk〉(x) | q0〈〉(x)

with δ ∈ ∆k, q1 ∈ Q1, q0 ∈ Q0, and x ∈ Xk.
Moreover, each variable of l (including y) is
supposed to occur exactly once in r.

We refer to Shieber (2006) for a full description
of embedded tree transducers. As seen from the
syntax, we write the context parameter y of a
state q ∈ Q1 as q〈y〉. If q ∈ Q0, then we also
write q〈〉 or q〈ε〉. In each right-hand side, such
a context parameter u can contain output symbols
and further calls to input subtrees. The semantics
of extended embedded tree transducers with sub-
stitution deviates slightly from the embedded tree
transducer semantics. Roughly speaking, not its
rules as such, but rather their evaluation are now
applied in a term-rewrite fashion. Let

SF′ := δ(SF′, . . . ,SF′) |
| q1〈SF′〉(t) | q0〈〉(t)

1074



qS〈〉

·[·]S?

x1 S

T

c

→

q〈·〉

S

T

c

x1

qS〈〉

S

S

T

c

⇒

q〈·〉

S

T

c

S

S?

Figure 12: Rule and derivation step using the rule
in an extended embedded tree transducer with sub-
stitution where the context parameter (if present)
is displayed as first child.

where δ ∈ ∆k, q1 ∈ Q1, q0 ∈ Q0, and t ∈ TΣ.
Given ξ, ζ ∈ SF′, we write ξ ⇒ ζ if there exist

C ∈ C∆(X1), t1, . . . , tk ∈ TΣ, u ∈ T∆∪{ε}, and
a rule q〈u〉(l) → r ∈ R10 with l ∈ CΣ(Xk) such
that
• ξ = C[q〈u〉(l[t1, . . . , tk]E)] and
• ζ = C[(r[t1, . . . , tk])[u]y].

Note that the essential difference to the “stan-
dard” semantics of embedded tree transducers is
the evaluation in the first item. The tree transfor-
mation computed by M is defined as usual. We
illustrate a derivation step in Figure 12, where the
match ·[·]S?(x1, S(T (c)))E = S(S(T (c))) is suc-
cessful for x1 = S(S?).

Theorem 2 Every STAG can be simulated by an
extended embedded tree transducer with substi-
tution. Moreover, every extended embedded tree
transducer computes a tree transformation that
can be computed by a STAG up to a relabeling.

8 Conclusions

We presented an alternative view on STAG us-
ing tree transducers (or equivalently, STSG). Our
main result shows that the syntactic characteri-
zation of STAG as STSG plus adjunction rules
also carries over to the semantic side. A STAG
tree transformation can also be computed by an
STSG using explicit substitution. In the light
of this result, some standard problems for STAG
can be reduced to the corresponding problems
for STSG. This allows us to re-use existing algo-
rithms for STSG also for STAG. Moreover, exist-
ing STAG algorithms can be related to the corre-
sponding STSG algorithms, which provides fur-
ther evidence of the close relationship between the
two models. We used this relationship to develop a

10Note that u is ε if q ∈ Q0.

BAR-HILLEL construction for STAG. Finally, we
hope that the alternative characterization is easier
to handle and might provide further insight into
general properties of STAG such as compositions
and preservation of regularity.

Acknowledgements

ANDREAS MALETTI was financially supported
by the Ministerio de Educación y Ciencia (MEC)
grant JDCI-2007-760.

References
Alfred V. Aho and Jeffrey D. Ullman. 1972. The The-

ory of Parsing, Translation, and Compiling. Pren-
tice Hall.

André Arnold and Max Dauchet. 1982. Morphismes
et bimorphismes d’arbres. Theoret. Comput. Sci.,
20(1):33–93.

Yehoshua Bar-Hillel, Micha Perles, and Eliyahu
Shamir. 1964. On formal properties of simple
phrase structure grammars. In Yehoshua Bar-Hillel,
editor, Language and Information: Selected Essays
on their Theory and Application, chapter 9, pages
116–150. Addison Wesley.

David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Proc.
ACL, pages 263–270. Association for Computa-
tional Linguistics.

David Chiang. 2006. An introduction to synchronous
grammars. In Proc. ACL. Association for Computa-
tional Linguistics. Part of a tutorial given with Kevin
Knight.

Bruno Courcelle and Paul Franchi-Zannettacci. 1982.
Attribute grammars and recursive program schemes.
Theoret. Comput. Sci., 17:163–191, 235–257.

Joost Engelfriet and Heiko Vogler. 1985. Macro tree
transducers. J. Comput. System Sci., 31(1):71–146.

Ferenc Gécseg and Magnus Steinby. 1984. Tree Au-
tomata. Akadémiai Kiadó, Budapest.

Ferenc Gécseg and Magnus Steinby. 1997. Tree lan-
guages. In Handbook of Formal Languages, vol-
ume 3, chapter 1, pages 1–68. Springer.

Jonathan Graehl and Kevin Knight. 2004. Training
tree transducers. In HLT-NAACL, pages 105–112.
Association for Computational Linguistics. See
also (Graehl et al., 2008).

Jonathan Graehl, Kevin Knight, and Jonathan May.
2008. Training tree transducers. Computational
Linguistics, 34(3):391–427.

1075



Jonathan Graehl, Mark Hopkins, Kevin Knight, and
Andreas Maletti. 2009. The power of extended top-
down tree transducers. SIAM Journal on Comput-
ing, 39(2):410–430.

Liang Huang and David Chiang. 2005. Better k-best
parsing. In Proc. IWPT, pages 53–64. Association
for Computational Linguistics.

Kevin Knight and Jonathan Graehl. 2005. An over-
view of probabilistic tree transducers for natural lan-
guage processing. In Proc. CICLing, volume 3406
of LNCS, pages 1–24. Springer.

Kevin Knight. 2007. Capturing practical natural
language transformations. Machine Translation,
21(2):121–133.

Andreas Maletti. 2008. Compositions of extended top-
down tree transducers. Inform. and Comput., 206(9–
10):1187–1196.

Jonathan May and Kevin Knight. 2006. TIBURON:
A weighted tree automata toolkit. In Proc. CIAA,
volume 4094 of LNCS, pages 102–113. Springer.

Mark-Jan Nederhof. 2009. Weighted parsing of trees.
In Proc. IWPT, pages 13–24. Association for Com-
putational Linguistics.

Rebecca Nesson, Giorgio Satta, and Stuart M. Shieber.
2008. Optimal k-arization of synchronous tree-
adjoining grammar. In Proc. ACL, pages 604–612.
Association for Computational Linguistics.

William C. Rounds. 1970. Mappings and grammars
on trees. Math. Systems Theory, 4(3):257–287.

Stuart M. Shieber and Yves Schabes. 1990. Syn-
chronous tree-adjoining grammars. In Proc. Com-
putational Linguistics, volume 3, pages 253–258.

Stuart M. Shieber. 2004. Synchronous grammars as
tree transducers. In Proc. TAG+7, pages 88–95.

Stuart M. Shieber. 2006. Unifying synchronous tree
adjoining grammars and tree transducers via bimor-
phisms. In Proc. EACL, pages 377–384. Association
for Computational Linguistics.

Stuart M. Shieber. 2007. Probabilistic synchronous
tree-adjoining grammars for machine translation:
The argument from bilingual dictionaries. In Proc.
Workshop on Syntax and Structure in Statistical
Translation, pages 88–95. Association for Compu-
tational Linguistics.

James W. Thatcher. 1970. Generalized2 sequential
machine maps. J. Comput. System Sci., 4(4):339–
367.

1076


