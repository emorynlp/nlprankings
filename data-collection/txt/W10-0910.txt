










































Unsupervised techniques for discovering ontology elements from Wikipedia article links


Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 78–86,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

Unsupervised techniques for discovering ontology 

elements from Wikipedia article links 

Zareen Syed Tim Finin 
University of Maryland, Baltimore County University of Maryland, Baltimore County 

1000 Hilltop Circle 1000 Hilltop Circle 

Baltimore, MD 21250, USA Baltimore, MD 21250, USA 
zarsyed1@umbc.edu finin@umbc.edu 

 
 

 

 

Abstract 

We present an unsupervised and unrestricted 

approach to discovering an infobox like on-

tology by exploiting the inter-article links 

within Wikipedia. It discovers new slots and 

fillers that may not be available in the 

Wikipedia infoboxes. Our results demonstrate 

that there are certain types of properties that 

are evident in the link structure of resources 

like Wikipedia that can be predicted with high 

accuracy using little or no linguistic analysis. 

The discovered properties can be further used 

to discover a class hierarchy. Our experiments 

have focused on analyzing people in Wikipe-

dia, but the techniques can be directly applied 

to other types of entities in text resources that 

are rich with hyperlinks.  

1 Introduction  

One of the biggest challenges faced by the Seman-

tic Web vision is the availability of structured data 

that can be published as RDF. One approach is to 

develop techniques to translate information in 

spreadsheets, databases, XML documents and 

other traditional data formats into RDF (Syed et al. 

2010). Another is to refine the technology needed 

to extract structured information from unstructured 

free text (McNamee and Dang, 2009). 

For both approaches, there is a second problem 

that must be addressed: do we start with an ontol-

ogy or small catalog of ontologies that will be used 

to encode the data or is extracting the right ontol-

ogy part of the problem. We describe exploratory 

work on a system that can discover ontological 

elements as well as data from a free text with em-

bedded hyperlinks. 

Wikipedia is a remarkable and rich online en-

cyclopedia with a wealth of general knowledge 

about varied concepts, entities, events and facts in 

the world. Its size and coverage make it a valuable 

resource for extracting information about different 

entities and concepts. Wikipedia contains both free 

text and structured information related to concepts 

in the form of infoboxes, category hierarchy and 

inter-article links. Infoboxes are the most struc-

tured form and are composed of a set of subject-

attribute-value triples that summarize or highlight 

the key features of the concept or subject of the 

article. Resources like DBpedia (Auer et al., 2007) 

and Freebase (Bollacker et al., 2007) have har-

vested this structured data and have made it avail-

able as triples for semantic querying.  

While infoboxes are a readily available source 

of structured data, the free text of the article con-

tains much more information about the entity. 

Barker et al. (2007) unified the state of the art ap-

proaches in natural language processing and 

knowledge representation in their prototype system 

for understanding free text. Text resources which 

are rich in hyperlinks especially to knowledge 

based resources (such as encyclopedias or diction-

aries) have additional information encoded in the 

form of links, which can be used to complement 

the existing systems for text understanding and 

knowledge discovery. Furthermore, systems such 

as Wikify (Mihalcea and Csomai, 2007) can be 

employed to link words in free text to knowledge 

resources like Wikipedia and thus enrich the free 

text with hyperlinks. 

We describe an approach for unsupervised on-

tology discovery from links in the free text of the 

Wikipedia articles, without specifying a relation or 

set of relations in advance. We first identify candi-

date slots and fillers for an entity, then classify en-

78



tities and finally derive a class hierarchy. We have 

evaluated our approach for the Person class, but it 

can be easily generalized to other entity types such 

as organizations, places, and products.   

The techniques we describe are not suggested 

as alternatives to natural language understanding or 

information extraction, but as a source for addi-

tional evidence that can be used to extract onto-

logical elements and relations from the kind of text 

found in Wikipedia and other heavily-linked text 

collections. This approach might be particularly 

useful in “slot fillings” tasks like the one in the 

Knowledge Base Population track (McNamee and 

Dang, 2010) at the 2009 Text Analysis Confer-

ence.  We see several contributions that this work 

has to offer: 

• Unsupervised and unrestricted ontology discov-

ery. We describe an automatic approach that 

does not require a predefined list of relations or 

training data. The analysis uses inter-article 

links in the text and does not depend on existing 

infoboxes, enabling it to suggest slots and fillers 

that do not exist in any extant infoboxes. 

• Meaningful slot labels. We use WordNet (Mil-

ler et al., 1990) nodes to represent and label 

slots enabling us to exploit WordNet’s hy-

pernym and hyponym relations as a property hi-

erarchy. 

• Entity classification and class labeling. We in-

troduce a new feature set for entity classifica-

tion, i.e. the discovered ranked slots, which per-

forms better than other feature sets extracted 

from Wikipedia. We also present an approach 

for assigning meaningful class label vectors us-

ing WordNet nodes. 

• Deriving a class hierarchy. We have developed 

an approach for deriving a class hierarchy based 

on the ranked slot similarity between classes 

and the label vectors.  

In the remainder of the paper we describe the de-

tails of the approach, mention closely related work, 

present and discuss preliminary results and provide 

some conclusions and possible next steps. 

2 Approach 

Figure 1 shows our ontology discovery framework 

and its major steps. We describe each step in the 

rest of this section.  

2.1 Discovering Candidate Slots and Fillers 

Most Wikipedia articles represent a concept, i.e., a 

generic class of objects (e.g., Musician), an indi-

vidual object (e.g., Michael_Jackson), or a generic 

relation or property (e.g., age). Inter-article links 

within Wikipedia represent relations between con-

cepts. In our approach we consider the linked con-

cepts as candidate fillers for slots related to the 

primary article/concept. There are several cases 

where the filler is subsumed by the slot label for 

example, the infobox present in the article on “Mi-

chael_Jackson” (Figure 2) mentions pop, rock and 

soul as fillers for the slot Genre and all three of 

these are a type of Genre. The Labels slot contains 

fillers such as Motown, Epic and Legacy which are 

all Record Label Companies. Based on this obser-

vation, we discover and exploit “isa” relations be-

tween fillers (linked concepts) and WordNet nodes 

to serve as candidate slot labels.  

In order to find an “isa” relation between a con-

cept and a WordNet synset we use manually cre-

ated mappings by DBpedia, which links about 

467,000 articles to synsets. However, Wikipedia 

has more than two million articles1, therefore, to 

map any remaining concepts we use the automati-

cally generated mappings available between 

WordNet synsets and Wikipedia categories 

(Ponzetto and Navigli, 2009). A single Wikipedia 

article might have multiple categories associated 

with it and therefore multiple WordNet synsets. 

Wikipedia’s category system serves more as a way 

to tag articles and facilitate navigation rather than 

                                                 
1
 This estimate is for the English version and does not 

include redirects and administrative pages such as dis-

ambiguation pages. 

 
Figure 1: The ontology discovery framework com-

prises a number of steps, including candidate slot and 

filler discovery followed by slot ranking, slot selec-

tion, entity classification, slot re-ranking, class label-

ing, and class hierarchy discovery. 

79



to categorize them. The article on Michael Jordan, 

for example, has 36 categories associated with it. 

In order to select an individual WordNet synset as 

a label for the concept’s type, we use two heuris-

tics: 

• Category label extraction. Since the first sen-

tence in Wikipedia articles usually defines the 

concept, we extract a category label from the 

first sentence using patterns based on POS tags 

similar to Kazama and Torisawa (2007). 

• Assign matching WordNet synset. We con-

sider all the WordNet synsets associated with 

the categories of the article using the category 

to WordNet mapping (Ponzetto and Navigli, 

2009) and assign the WordNet synset if any of 

the words in the synset matches with the ex-

tracted category label. We repeat the process 

with hypernyms and hyponyms of the synset 

up to three levels.  

2.2 Slot Ranking 

All slots discovered using outgoing links might not 

be meaningful, therefore we have developed tech-

niques for ranking and selecting slots. Our ap-

proach is based on the observation that entities of 

the same type have common slots. For example, 

there is a set of slots common for musical artists 

whereas, a different set is common for basketball 

players. The Wikipedia infobox templates based 

on classes also provide a set of properties or slots 

to use for particular types of entities or concepts.  

In case of people, it is common to note that 

there is a set of slots that are generalized, i.e., they 

are common across all types of persons.  Examples 

are name, born, and spouse.  There are also sets of 

specialized slots, which are generally associated 

with a given profession.  For example, the slots for 

basketball players have information for basketball 

related activities and musical artists have slots with 

music related activities. The slots for “Mi-

chael_Jordan” include Professional Team(s), NBA 

Draft, Position(s) and slots for “Michael_Jackson” 

include Genres, Instruments and Labels. 

Another observation is that people engaged in a 

particular profession tend to be linked to others 

within the same profession.  Hence the maxim “A 

man is known by the company he keeps.” For ex-

ample, basketball players are linked to other bas-

ketball players and politicians are linked to other 

politicians. We rank the slots based on the number 

of linked persons having the same slots. We gener-

ated a list of person articles in Wikipedia by get-

ting all Wikipedia articles under the Person type in 

Freebase2. We randomly select up to 25 linked per-

sons (which also link back) and extract their candi-

date slots and vote for a slot based on the number 

of times it appears as a slot in a linked person nor-

malized by the number of linked persons to assign 

a slot score.  

2.3 Entity Classification and Slot Re-Ranking 

The ranked candidate slots are used to classify en-

tities and then further ranked based on number of 

times they appear among the entities in the cluster. 

We use complete link clustering using a simple slot 

similarity function: 
 

 

 

This similarity metric for slots is computed as the 

cosine similarity between tf.idf weighted slot vec-

tors, where the slot score represents the term fre-

                                                 
2
 We found that the Freebase classification for Person 

was more extensive that DBpedia’s in the datasets avail-

able to us in early 2009. 

 

 
 

 

Figure 2.  The Wikipedia infobox 

for the Michael_Jackson article has 

a number of slots from appropriate 

infobox templates. 

 

80



quency component and the inverse document fre-

quency is based on the number of times the slot 

appears in different individuals. 

We also collapsed location expressing slots 

(country, county, state, district, island etc.) into the 

slot labeled location by generating a list of location 

words from WordNet as these slots were causing 

the persons related to same type of geographical 

location to cluster together.  

After clustering, we re-score the slots based on 

number of times they appear among the individuals 

in the cluster normalized by the cluster size. The 

output of clustering is a vector of scored slots as-

sociated with each cluster. 

2.4 Slot Selection 

The slot selection process identifies and filters out 

slots judged to be irrelevant. Our intuition is that 

specialized slots or attributes for a particular entity 

type should be somehow related to each other. For 

example, we would expect attributes like league, 

season and team for basketball players and genre, 

label, song and album for musical artists. If an at-

tribute like album appears for basketball players it 

should be discarded as it is not related to other at-

tributes. 

We adopted a clustering approach for finding 

attributes that are related to each other. For each 

pair of attributes in the slot vector, we compute a 

similarity score based on how many times the two 

attribute labels appear together in Wikipedia per-

son articles within a distance of 100 words as 

compared to the number of times they appear in 

total and weigh it using weights of the individual 

attributes in the slot vector. This metric is captured 

in the following equation, where Df is the docu-

ment frequency and wt is the attribute weight. 
 

 

Our initial experiments using single and com-

plete link clustering revealed that single link was 

more appropriate for slot selection. We got clusters 

at a partition distance of 0.9 and selected the larg-

est cluster from the set of clusters. In addition, we 

also added any attributes exceeding a 0.4 score into 

the set of selected attributes. Selected ranked slots 

for Michael Jackson are given in Table 1.   

2.5 Class Labeling 

Assigning class labels to clusters gives additional 

information about the type of entities in a cluster. 

We generate a cluster label vector for each cluster 

which represents the type of entities in the cluster. 

We compute a list of person types by taking all 

hyponyms under the corresponding person sense in 

WordNet. That list mostly contained the profes-

sions list for persons such as basketball player, 

president, bishop etc. To assign a WordNet type to 

a person in Wikipedia we matched the entries in 

the list to the words in the first sentence of the per-

son article and assigned it the set of types that 

matched. For example, for Michael Jordan the 

matching types found were basketball_player, 

businessman and player. 

We assigned the most frequent sense to the 

matching word as followed by Suchanek et al. 

(2008) and Wu and Weld (2008), which works for 

majority of the cases. We then also add all the hy-

pernyms of the matching types under the Person 

node. The vector for Michael Jordan has entries 

basketball_player, athlete, businessperson, person, 

contestant, businessman and player. After getting 

matching types and their hypernyms for all the 

members of the cluster, we score each type based 

on the number of times it occurs in its members 

normalized by the cluster size. For example for one 

of the clusters with 146 basketball players we got 

the following label vector: {player:0.97, contest-

ant:0.97, athlete:0.96, basketball_player:0.96}. To 

select an individual label for a class we can pick 

the label with the highest score (the most general-

Slot Score Fillers Example 
Musician 1.00 ray_charles, sam_cooke ...  

Album 0.99 bad_(album), ... 

Location 0.97 gary,_indiana,  chicago,  … 

Music_genre 0.90 pop_music, soul_music, ... 

Label 0.79 a&m_records, epic_records, ... 

Phonograph_ 

record 
0.67 

give_in_to_me, 

this_place_hotel … 

Act 0.59 singing 

Movie 0.46 moonwalker … 

Company 0.43 war_child_(charity), … 

Actor 0.41 stan_winston, eddie_murphy,  

Singer 0.40 britney_spears, … 

Magazine 0.29 entertainment_weekly,… 

Writing_style 0.27 hip_hop_music 

Group 0.21 'n_sync, RIAA 

Song 0.20 d.s._(song) … 
 

  Table 1: Fifteen slots were discovered for musician 

Michael Jackson along with scores and example fillers. 

81



ized label) or the most specialized label having a 

score above a given threshold. 

2.6 Discovering Class Hierarchy 

We employ two different feature sets to discover 

the class hierarchy, i.e., the selected slot vectors 

and the class label vectors and combine both func-

tions using their weighted sum. The similarity 

functions are described below. 

The common slot similarity function is the co-

sine similarity between the common slot tf.idf vec-

tors, where the slot score represents the tf and the 

idf is based on the number of times a particular slot 

appears in different clusters at that iteration. We 

re-compute the idf term in each iteration. We de-

fine the common slot tf.idf vector for a cluster as 

one where we assign a non-zero weight to only the 

slots that have non-zero weight for all cluster 

members. The label similarity function is the co-

sine similarity between the label vectors for clus-

ters.  The hybrid similarity function is a weighted 

sum of the common slot and label similarity func-

tions. Using these similarity functions we apply 

complete link hierarchical clustering algorithm to 

discover the class hierarchy. 
 

 

3 Experiments and Evaluation 

For our experiments and evaluation we used the 

Wikipedia dump from March 2008 and the DBpe-

dia infobox ontology created from Wikipedia 

infoboxes using hand-generated mappings (Auer et 

al., 2007). The Person class is a direct subclass of 

the owl:Thing class and has 21 immediate sub-

classes and 36 subclasses at the second level. We 

used the persons in different classes in DBpedia 

ontology at level two to generate data sets for ex-

periments.  

There are several articles in Wikipedia that are 

very small and have very few out-links and in-

links. Our approach is based on the out-links and 

availability of information about different related 

things on the article, therefore, in order to avoid 

data sparseness, we randomly select articles with 

greater than 100 in-links and out-links, at least 

5KB page length and having at least five links to 

entities of the same type that link back (in our case 

persons).  

We first compare our slot vector features with 

other features extracted from Wikipedia for entity 

classification task and then evaluate their accuracy. 

We then discover the class hierarchy and compare 

the different similarity functions.  

3.1 Entity Classification 

We did some initial experiments to compare our 

ranked slot features with other feature sets ex-

tracted from Wikipedia. We created a dataset com-

posed of 25 different classes of Persons present at 

level 2 in the DBpedia ontology by randomly se-

lecting 200 person articles from each class. For 

several classes we got less than 200 articles which 

fulfilled our selection criteria defined earlier. We 

generated twelve types of feature sets and evalu-

ated them using ground truth from DBpedia ontol-

ogy. 

We compare tf.idf vectors constructed using 

twelve different feature sets: (1) Ranked slot fea-

tures, where tf is the slot score; (2) Words in first 

sentence of an article; (3) Associated categories; 

(4) Assigned WordNet nodes (see section 2.2); (5) 

Associated categories tokenized into words; (6) 

Combined Feature Sets 1 to 5 (All); (7-11) Feature 

sets 7 to 11 are combinations excluding one feature 

set at a time; (12) Unranked slots where tf is 1 for 

all slots. We applied complete link clustering and 

evaluated the precision, recall and F-measure at 

different numbers of clusters ranging from one to 

100.  Table 2 gives the precision, recall and num-

ber of clusters where we got the maximum F-

measure using different feature sets. 

82



 Feature set 10 (all features except feature 2) gave 

the best F-measure i.e. 0.74, whereas, feature set 1 

(ranked slots only) gave the second best F-measure 

i.e. 0.73 which is very close to the best result. Fea-

ture set 12 (unranked slots) gave a lower F-

measure i.e. 0.61 which shows that ranking or 

weighing slots based on linked entities of the same 

type performs better for classification. 

3.2 Slot and Filler Evaluation 

To evaluate our approach to finding slot fillers, we 

focused on DBpedia classes two levels below Per-

son (e.g., Governor and FigureSkater). We ran-

domly selected 200 articles from each of these 

classes using the criteria defined earlier to avoid 

data sparseness. Classes for which fewer than 20 

articles were found were discarded. The resulting 

dataset comprised 28 classes and 3810 articles3. 

We used our ranked slots tf.idf feature set and 

ran a complete link clustering algorithm producing 

clusters at partition distance of 0.8. The slots were 

re-scored based on the number of times they ap-

peared in the cluster members normalized by the 

cluster size. We applied slot selection over the re-

scored slots for each cluster. In order to evaluate 

our slots and fillers we mapped each cluster to a 

DBpedia class based on the maximum number of 

members of a particular DBpedia class in our clus-

ter. This process predicted 124 unique properties 

for the classes.  Of these, we were able to manually 

align 46 to properties in either DBpedia or Free-

                                                 
3
 For some of the classes, fewer than the full comple-

ment of 200 articles were found. 

base for the corresponding class. We initially tried 

to evaluate the discovered slots by comparing them 

with those found in the ontologies underlying 

DBpedia and Freebase, but were able to find an 

overlap in the subject and object pairs for very few 

properties. 

We randomly selected 20 subject object pairs 

for each of the 46 properties from the correspond-

ing classes and manually judged whether or not the 

relation was correct by consulting the correspond-

No. Property Accuracy 

1 automobile_race 1.00 

2 championship 1.00 

3 expressive_style 1.00 

4 fictional_character 1.00 

5 label 1.00 

6 racetrack 1.00 

7 team_sport 1.00 

8 writing_style 1.00 

9 academic_degree 0.95 

10 album 0.95 

11 book 0.95 

12 contest 0.95 

13 election 0.95 

14 league 0.95 

15 phonograph_record 0.95 

16 race 0.95 

17 tournament 0.94 

18 award 0.90 

19 movie 0.90 

20 novel 0.90 

21 school 0.90 

22 season 0.90 

23 serial 0.90 

24 song 0.90 

25 car 0.85 

26 church 0.85 

27 game 0.85 

28 musical_instrument 0.85 

29 show 0.85 

30 sport 0.85 

31 stadium 0.85 

32 broadcast 0.80 

33 telecast 0.80 

34 hockey_league 0.75 

35 music_genre 0.70 

36 trophy 0.70 

37 university 0.65 

38 character 0.60 

39 disease 0.60 

40 magazine 0.55 

41 team 0.50 

42 baseball_club 0.45 

43 club 0.45 

44 party 0.45 

45 captain 0.30 

46 coach 0.25 

  Avg. Accuracy: 0.81 
 

Table 3: Manual evaluation of discovered properties 
 

No. Feature Set k P R F 

1 Ranked Slots  40 0.74 0.72 0.73 

2 First Sentence 89 0.07 0.53 0.12 

3 Categories 1 0.05 1.00 0.10 

4 WordNet Nodes 87 0.40 0.22 0.29 

5 (3 tokenized) 93 0.85 0.47 0.60 

6 All (1 to 5) 68 0.87 0.62 0.72 

7 (All – 5) 82 0.79 0.46 0.58 

8 (All – 4) 58 0.78 0.63 0.70 

9 (All – 3) 53 0.76 0.65 0.70 

10 (All – 2) 58 0.88 0.63 0.74 

11 (All – 1) 57 0.77 0.60 0.68 

12 (1 unranked) 34 0.57 0.65 0.61 
 

Table 2: Comparison of the precision, recall and F-

measure for different feature sets for entity classifi-

cation.  The k column shows the number of clusters 

that maximized the F score.  

 

83



ing Wikipedia articles (Table 3).  The average ac-

curacy for the 46 relations was 81%. 

3.3 Discovering Class Hierarchy 

In order to discover the class hierarchy, we took all 

of the clusters obtained earlier at partition distance 

of 0.8 and their corresponding slot vectors after 

slot selection. We experimented with different 

similarity functions and evaluated their accuracy 

by comparing the results with the DBpedia ontol-

ogy. A complete link clustering algorithm was ap-

plied using different settings of the similarity func-

tions and the resulting hierarchy compared to 

DBpedia’s Person class hierarchy. Table 4 shows 

the highest F measure obtained for Person’s imme-

diate sub-classes (L1), “sub-sub-classes” (L2) and 

the number of clusters (k) for which we got the 

highest F-measure using a particular similarity 

function. 

The highest F-measure both at level 2 (0.63) and 

level 1 (0.79) was obtained by simhyb with wc=0.2, 

wl=0.8 and also at lowest number of clusters at L1 

(k=8). The simhyb (wc=wl=0.5) and simlabel functions 

gave almost the same F-measure at both levels. 

The simcom_slot function gave better performance at 

L1 (F=0.65) than the base line simslot (F=0.55) 

which was originally used for entity clustering. 

However, both these functions gave the same F-

measure at L2 (F=0.61). 

4 Discussion  

In case of property evaluation, properties for which 

the accuracy was 60% or below include coach, 

captain, baseball_club, club, party, team and 

magazine. For the magazine property (correspond-

ing to Writer and ComicsCreator class) we ob-

served that many times a magazine name was men-

tioned in an article because it published some news 

about a person rather than that person contributing 

any article in that magazine. For all the remaining 

properties we observed that these were related to 

some sort of competition. For example, a person 

played against a team, club, coach or captain. The 

political party relation is a similar case, where arti-

cles frequently mention a politician’s party affilia-

tion as well as significant opposition parties. For 

such properties, we need to exploit additional con-

textual information to judge whether the person 

competed “for” or “against” a particular team, 

club, coach or party. Even if the accuracy for fill-

ers for such slots is low, it can still be useful to 

discover the kind of slots associated with an entity.  

We also observed that there were some cases 

where the property was related to a family member 

of the primary person such as for disease, school 

and university. Certain other properties such as 

spouse, predecessor, successor, etc. require more 

contextual information and are not directly evident 

in the link structure. However, our experiments 

show that there are certain properties that can be 

predicted with high accuracy using the article links 

only and can be used to enrich the existing infobox 

ontology or for other purposes.  

While our work has mostly experimented with 

person entities, the approach can be applied to oth-

er types as well. For example, we were able to dis-

cover software as a candidate slot for companies 

like Microsoft, Google and Yahoo!, which ap-

peared among the top three ranked slots using our 

slot ranking scheme and corresponds to the prod-

ucts slot in the infoboxes of these companies.  

For class hierarchy discovery, we have ex-

ploited the specialized slots after slot selection. 

One way to incorporate generalized slots in the 

hierarchy is to consider all slots for class members 

(without slot selection) and recursively propagate 

the common slots present at any level to the level 

above it. For example, if we find the slot team to 

be common for different types of Athletes such as 

basketball players, soccer players etc. we can 

propagate it to the Athlete class, which is one level 

higher in the hierarchy.  

5 Related Work 

Unsupervised relation discovery was initially in-

troduced by Hasegawa et al. (2004). They devel-

oped an approach to discover relations by cluster-

ing pairs of entities based on intervening words 

represented as context vectors. Shinyama and Se-

kine (2006) generated basic patterns using parts of 

text syntactically connected to the entity and then 

Similarity Function 
k 

(L=2) 

F 

(L=2) 

k 

(L=1) 

F 

(L=1) 

simslot  56 0.61 13 0.55 

simcom_slot  74 0.61 15 0.65 

simlabel  50 0.63 10 0.76 

simhyb wc=wl=0.5 59 0.63 10 0.76 

simhyb wc=0.2, wl=0.8 61 0.63 8 0.79 
 

Table 4: Evaluation results for class hierarchy predic-

tion using different similarity functions. 

84



generated a basic cluster composed of a set of 

events having the same relation. 

Several approaches have used linguistic analysis 

to generate features for supervised or un-

supervised relation extraction (Nguyen et al., 2007; 

Etzioni et al., 2008; Yan et al., 2009). Our ap-

proach mainly exploits the heavily linked structure 

of Wikipedia and demonstrates that there are sev-

eral relations that can be discovered with high ac-

curacy without the need of features generated from 

a linguistic analysis of the Wikipedia article text.  

Suchanek et al. (2008) used Wikipedia catego-

ries and infoboxes to extract 92 relations by apply-

ing specialized heuristics for each relation and in-

corporated the relations in their YAGO ontology, 

whereas our techniques do not use specialized heu-

ristics based on the type of relation.  Kylin (Weld 

et al., 2008) generated infoboxes for articles by 

learning from existing infoboxes, whereas we can 

discover new fillers for several existing slots and 

also discover new slots for infoboxes. KOG (Wu 

and Weld, 2008) automatically refined the Wiki-

pedia infobox ontology and integrated Wikipedia’s 

infobox-class schemata with WordNet. Since we 

already use the WordNet nodes for representing 

slots, it eliminates the need for several of KOG’s 

infobox refinement steps. 

While YAGO, Kylin and KOG all rely on rela-

tions present in the infoboxes, our approach can 

complement these by discovering new relations 

evident in inter-article links in Wikipedia. For ex-

ample, we could add slots like songs and albums to 

the infobox schema for Musical Artists, movies for 

the Actors infobox schema, and party for the Poli-

ticians schema. 

6 Conclusions and Future Work 

People have been learning by reading for thou-

sands of years.  The past decade, however, has 

seen a significant change in the way people read.  

The developed world now does much of its reading 

online and this change will soon be nearly univer-

sal.  Most online content is read as hypertext via a 

Web browser or custom reading device. Unlike 

text, hypertext is semi-structured information, es-

pecially when links are drawn from global name-

space, making it easy for many documents to link 

unambiguously to a common referent. 

The structured component of hypertext aug-

ments the information in its plain text and provides 

an additional source of information from which 

both people and machines can learn.  The work 

described in this paper is aimed at learning useful 

information, both about the implicit ontology and 

facts, from the links embedded in collection of hy-

pertext documents. 

Our approach is fully unsupervised and does 

not require having a pre-defined catalogue of rela-

tions. We have discovered several new slots and 

fillers that are not present in existing Wikipedia 

infoboxes and also a scheme to rank the slots based 

on linked entities of the same type. We compared 

our results with ground truth from the DBpedia 

infobox ontology and Freebase for the set of prop-

erties that were common and manually evaluated 

the accuracy of the common properties. Our results 

show that there are several properties that can be 

discovered with high accuracy from the link struc-

ture in Wikipedia and can also be used to discover 

a class hierarchy.  

We plan to explore the discovery of slots from 

non-Wikipedia articles by linking them to Wikipe-

dia concepts using existing systems like Wikify 

(Mihalcea and Csomai, 2007). Wikipedia articles 

are encyclopedic in nature with the whole article 

revolving around a single topic or concept.  Con-

sequently, linked articles are a good source of 

properties and relations. This might not be the case 

in other genres, such as news articles, that discuss 

a number of different entities and events.  One way 

to extend this work to other genres is by first de-

tecting the entities in the article and then only 

processing links in sentences that mention an entity 

to discover its properties. 

Acknowledgements 

The research described in this paper was supported 

in part by a Fulbright fellowship, a gift from Mi-

crosoft Research, NSF award IIS-0326460 and the 

Johns Hopkins University Human Language Tech-

nology Center of Excellence. 

85



 References 

Sören Auer, Christian Bizer, Georgi Kobilarov, Jens 
Lehmann and Zachary Ives. 2007. DBpedia: A nu-
cleus for a web of open data. In Proceedings of the 
6th International Semantic Web Conference: 11–15. 

Ken Barker et al. 2007. Learning by reading: A proto-
type system, performance baseline and lessons 
learned, Proceedings of the 22nd National Confer-
ence on Artificial Intelligence, AAAI Press. 

K. Bollacker, R. Cook, and P. Tufts. 2007. Freebase: A 
Shared Database of Structured General Human 
Knowledge. Proceedings of the National Conference 
on Artificial Intelligence (Volume 2): 1962-1963.  

Oren Etzioni, Michele Banko, Stephen Soderland, and 
Daniel S. Weld. 2008. Open information extraction 
from the web. Communications of the ACM 51, 12 
(December): 68-74. 

Takaaki Hasegawa, Satoshi Sekine, and Ralph Grish-
man. 2004. Discovering relations among named enti-
ties from large corpora. In Proceedings of the 42nd 
Annual Meeting of the Association for Computa-
tional Linguistics: 415-422.  

Jun’ichi Kazama and Kentaro Torisawa. 2007. Exploit-
ing Wikipedia as external knowledge for named en-
tity recognition. In Proceedings of the 2007 Joint 
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning: 698–707. 

Paul McNamee and Hoa Trang Dang. 2009. Overview 
of the TAC 2009 knowledge base population track. 
In Proceedings of the 2009 Text Analysis Confer-
ence. National Institute of Standards and Technol-
ogy, November. 

Rada Mihalcea and Andras Csomai. 2007. Wikify!: 
linking documents to encyclopedic knowledge. In 
Proceedings of the 16th ACM Conference on 
Information and Knowledge Management: 233–242.  

George A. Miller, Richard Beckwith, Christiane Fell-
baum, Derek Gross, and Katherine Miller. 1990. 
WordNet: An on-line lexical database. International 
Journal of Lexicography, 3:235–244.  

Dat P. T. Nguyen, Yutaka Matsuo, and Mitsuru Ishizu-
ka. 2007. Subtree mining for relation extraction from 
Wikipedia. In Proceedings of Human Language 
Technologies: The Annual Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics:125–128. 

Fabian M. Suchanek, Gjergji Kasneci, and Gerhard 
Weikum. 2008. Yago: A large ontology from 
Wikipedia and WordNet. Web Semantics, 6(3):203–
217. 

Zareen Syed, Tim Finin, Varish Mulwad and Anupam 
Joshi. 2010. Exploiting a Web of Semantic Data for 
Interpreting Tables, Proceedings of the Second Web 
Science Conference. 

Simone P. Ponzetto and Roberto Navigli. 2009. Large-
scale taxonomy mapping for restructuring and inte-
grating Wikipedia. In Proceedings of the Twenty-
First International Joint Conference on Artificial In-
telligence: 2083–2088.  

Yusuke Shinyama and Satoshi Sekine. 2006. Pre-emp-
tive information extraction using unrestricted relation 
discovery. In Proceedings of Human Language Tech-
nologies: The Annual Conference of the North 
American Chapter of the Association for Computa-
tional Linguistics:.  

Daniel S. Weld, Raphael Hoffmann, and Fei Wu. 2008. 
Using Wikipedia to bootstrap open information ex-
trac-tion. SIGMOD Record, 37(4): 62–68. 

Fei Wu and Daniel S. Weld. 2008. Automatically refin-
ing the Wikipedia infobox ontology. In Proceedings 
of the 17th International World Wide Web Confer-
ence, pages 635–644. 

Wikipedia. 2008. Wikipedia, the free encyclopedia. 

Yulan Yan, Naoaki Okazaki, Yutaka Matsuo, Zhenglu 
Yang, and Mitsuru Ishizuka. 2009. Unsupervised re-
lation extraction by mining Wikipedia texts using in-
formation from the web. In Proceedings of the 47th 
Annual Meeting of the Association for Computa-
tional Linguistics: Volume 2: 1021–1029.  

 

86


