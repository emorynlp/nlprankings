860

Coling 2010: Poster Volume, pages 860–868,

Beijing, August 2010

 
 
 
 

 

A Vector Space Model for Subjectivity Classification in Urdu 

aided by Co-Training 

 

Smruthi Mukund 

CEDAR 

University at Buffalo 

Rohini K. Srihari 

CEDAR 

University at Buffalo 

smukund@buffalo.edu 

rohini@cedar.buffalo.edu 

Abstract 

The  goal  of  this  work  is  to  produce  a 
classifier  that  can  distinguish  subjective 
sentences  from  objective  sentences  for 
the  Urdu  language.  The  amount  of  la-
beled data required for training automatic 
classifiers  can  be  highly  imbalanced  es-
pecially  in  the  multilingual  paradigm  as 
generating  annotations  is  an  expensive 
task.  In  this  work,  we  propose  a  co-
training  approach  for  subjectivity  analy-
sis  in  the  Urdu  language  that  augments 
the positive set (subjective set) and gene-
rates a negative set (objective set) devoid 
of all samples close to the positive ones. 
Using  the  data  set  thus  generated  for 
training,  we  conduct  experiments  based 
on SVM and VSM algorithms, and show 
that  our  modified  VSM  based  approach 
works remarkably well as a sentence lev-
el subjectivity classifier. 

1 

Introduction 

Subjectivity  tagging  involves  distinguishing 
sentences  that  express  opinions  from  sentences 
that  present  factual  information  (Banfield  1982; 
Wiebe,  1994).  A  wide  variety  of  affective 
nuances can be used while delivering a message 
pertaining  to  an  event.  Although  the  factual 
content remains the same, lexical selections and 
grammatical  choices  can  considerably  influence 
the  affective  nature  of  the  text.  Recognizing 
sentences  that  exhibit  affective  behavior  will 
require, at the least, recognizing the structure of 
the sentence and the emotion bearing words.  

that 

corpus 

contains  10,000 

To  date,  much  of  the  research  in  this  area  is 
focused  on  English.  A  variety  of  reliable 
resources 
facilitate  effective  sentiment 
analysis  and  opinion  mining,  such  as  polarity 
(Senti-WordNet 1 )  and  contextual 
lexicons 
valence shifters (Kennedy and Inkpen, 2005) are 
available  for  English.  The  MPQA  corpus  of 
10,000  sentences  (Wiebe  et  al.,  2005)  provides 
detailed  annotations  for  sources  of  opinions, 
targets, speech events and fragments that indicate 
attitudes  for  the  English  newswire  data.  The 
IMDB 
sentences 
categorized  as  subjective  and  objective  in  the 
movie  review  domain.  Clearly,  English  is  well 
supported with resources. There are other widely 
spoken  resource  poor  languages  that  are  not  as 
privileged.  When  we  consider  social  media, 
limiting our analysis to a language like English, 
however  universal,  will 
loss  of 
information.  With 
the  advent  of  virtual 
keyboards  and  extended  Unicode  support,  the 
internet  is  rapidly  getting  flooded  by  users  who 
use 
textual 
communication.  There  is  a  pressing  need  to 
perform  non-topical 
the 
multilingual paradigm. 

text  analysis 

language 

native 

their 

lead 

in 

in 

to 

is  a  precursor 

Subjectivity  analysis 

to 
numerous  applications  performing  non-topical 
text  analysis  like  sentiment  analysis,  emotion 
detection,  and  opinion  extraction  (Liu  et  al., 
2005;  Ku  et  al.,  2006;  Titov  and  McDonald, 
2008).  Creating  the  state-of-the-art  subjectivity 
classifier  using  machine  learning  techniques 
require  access  to  large  amounts  of  annotated 
data.  For  less  commonly  taught  languages  like 

                                                 
1 http://swn.isti.cnr.it/download_1.0/ 

861

 
 
 
 

Urdu,  Hindi,  Bengali,  Spanish  and  Romanian, 
the  resources  required  to  automate  subjectivity 
analysis  are  either  very  sparse  or  unavailable. 
Generating  annotated  corpus  for  subjectivity 
detection is laborious and time consuming. 

However,  several  innovative  techniques  have 
been  proposed  by  researchers  in  the  past  to 
generate annotated data and lexical resources for 
subjectivity analysis in resource poor languages. 
Mihalcea  et  al., (2007) and Banea  et  al., (2008) 
used  machine  translation  technique  to  leverage 
English  resources  for  analysis  in  Romanian  and 
Spanish  languages.  Wan  (2009)  proposed  a  co-
training  technique  that  leveraged  an  available 
English 
sentiment 
classification. Wan (2008) focused on improving 
Chinese  sentiment  analysis  by  using  both 
Chinese and English lexicons. 

for  Chinese 

corpus 

lacks 

language 

Unfortunately,  not  much  work  has  been  done 
in  the  area  of  subjectivity  analysis  for  the  Urdu 
language.  This 
annotated 
resources  required  to  generate  even  the  basic 
NLP  tools  (POS  tagger,  NE  tagger  etc.)  needed 
for text analysis. In order to facilitate subjectivity 
analysis in Urdu language, we annotated a small 
set of Urdu newswire articles for emotions (§2). 
The  sentence  level  annotations  provided  in  this 
dataset 
annotation  guidelines 
proposed  by  Wiebe  et  al.,  (2003).  Although 
tremendous  effort  was  put  into  generating  this 
corpus,  the  data  set  is  not  very  comprehensive 
and  contains  only  about  500  sentences  marked 
subjective. This is definitely insufficient to train 
a suitable subjectivity classifier.  

follow 

the 

1.1 

Issue with unbalanced data set 

data, 

generating 

A  subjectivity  classifier  is  a  binary  classifier. 
A  traditional  binary  classifier  is  trained  using 
universal  representative  sets  for  positive  and 
negative categories. But in subjectivity analysis, 
especially  for  languages  like  Urdu  that  have  no 
annotated 
universal 
representative  sets  is  extremely  difficult  and 
almost  an  impossible  task.  Assimilating  the 
negative set is especially a delicate task as the set 
should  be  carefully  pruned  of  all  the  positive 
samples.  Also,  detecting  subjectivity 
in  a 
sentence  is  highly  personalized.  Annotators  are 
sometimes  prejudiced  while  marking  samples. 
This  bias,  however  small,  produces  errors  with 
some true positive samples being unintentionally 

as 

and 

categorized 

missed 
negative. 
Traditionally,  research  in  machine  learning  has 
assumed the class distribution in the training data 
to  be  reasonably  balanced.  However,  when  the 
training  data  is  highly  imbalanced,  i.e.,  the 
number  of  positive  examples  is  very  small,  the 
performance  of  text  classification  algorithms 
such  as  linear  support  vector  machine  (SVM) 
(Brank  and  Grobelnik,  2003),  naïve  Bayes  and 
decision  trees  (Kubat  and  Matwin,  1997)  are 
adversely affected.  

In  order  to  achieve  a  balanced  training  set, 
Japkowicz  (2000)  duplicates  positive  examples 
(oversampling)  and  discards  negative  ones 
(downsizing). Kubat and Matwin (1997) discard 
all  samples  that  are  close  to  the  positive  set  to 
avoid  misclassification.  Chan  and  Stalfo  (1998) 
have  trained  several  classifiers  on  different  ba-
lanced  data  subsets,  each  constructed  to  include 
all positive training samples and a set of negative 
samples of comparable size. The predictions are 
combined through stacking.  

For the task of subjectivity analysis, especially 
in the multilingual paradigm where the data set is 
highly  unbalanced,  using  one  of  the  techniques 
proposed above will yield benefit. To the best of 
our  knowledge,  co-training  technique  has  not 
been applied before for the subjectivity detection 
task, in particular, for the Urdu language. 

1.2  Contribution 

set 

(subjective 

Our  first  contribution is inspired  by  the  work 
of  Luo  et  al.,  (2008).  We  propose  a  similar  co-
training  technique  that  helps  to  create  a  likely 
negative  set  (objective  sentences)  and  a  filtered 
positive 
sentences) 
simultaneously  from  the  unlabeled  set.  We  use 
two  learning  models  trained  using  the  linear 
SVM  algorithm  iteratively.  In  every  iteration  of 
co-training, 
likely  positive  samples  are 
filtered. The iterative process terminates when no 
more  positive  samples  are  found.  The  final 
negative set is the likely negative set, considered 
as  the  universal  representative  set  for  the  non-
subjective  category.  The  likely  positive  sample 
set  is  appended  to  the  already  existing  positive 
set (annotated set). The SVM models are trained 
using  part  of  speech,  unigrams  and  emotion 
bearing words, as features.  

the 

The second contribution of this work includes 
training  a  state-of-the-art  Vector  Space  Model 

862

 
 
 
 

show 

results 

(VSM)  for  Urdu  newswire  data  using  the  data 
sets  generated  by 
the  co-training  method. 
Experiments that use the SVM classifier are also 
performed.  The 
the 
the  proposed  VSM  based 
performance  of 
approach  helps 
state-of-the-art 
to  achieve 
sentence  level  subjectivity  classifier.  The  F-
Measure  of  the  VSM  subjectivity  classifier  is 
82.72% with 78.7% F-measure for the subjective 
class  and  86.7%  F-Measure  for  the  objective 
class.  

that 

2  Data Set 

The  data  set  used  to  generate  a  subjectivity 
classifier for Urdu newswire articles is obtained 
from  BBC  Urdu2.  The annotating  efforts  are  di-
rected towards achieving the final goal- emotion 
detection in Urdu newswire data and the annota-
tion guidelines are based on the MPQA standards 
set for English.  

The repository of articles provided by BBC is 
huge  and  needs  to  be  filtered  intelligently.  Two 
levels of filters are applied. –  date and  keyword 
search.  The  date  filter  is  applied  to  retrieve  ar-
ticles of three years, starting year 2003. The key-
word based filter consists of a set of seed words 
that  are  commonly  used  to  express  emotions  in 
Urdu -ghussa (~anger), pyar (~love) etc. Clearly, 
this list will not cover all possible linguistic ex-
pressions that express emotion and opinion. But 
it is definitely a representative of a wide range of 
phenomena that naturally occurs in text express-
ing emotions.  

The data retrieved is parsed using an in-house 
HTML parser to produce clean data. To date, we 
have  500  articles,  consisting  of  700  sentences 
annotated  for  emotions.  There  are  nearly  6000 
sentences that do not contain any emotions mak-
ing it highly unbalanced. This data set is divided 
into testing and training sets with 30% and 70% 
of the data respectively. Co-training is performed 
only on the 70% training set that consists of 470 
subjective  sentences  and  about  4000  objective 
sentences.  The  purpose  of  co-training  here  is  to 
remove samples that are close to subjective from 
the objective set and create a likely negative set. 
The samples removed are the likely positive set. 
This set of 4000 objective sentences can be con-
sidered as the un-annotated set. 
                                                 
2 http://www.bbc.co.uk/urdu/ 

3  Co-Training 

Identifying sentences that express emotions in 
Urdu newswire data is not trivial. Subjective sen-
tences  do  not  always  contain  individual  expres-
sions that indicate subjectivity. Analysis is high-
ly  dependent  on  the  contextual  information. 
Wiebe et al., (2001) reported that nearly 44% of 
sentences  in  the  MPQA  corpus  (English  news-
wire  data)  are  subjective.  In  newswire  data, 
though most facts are reported objectively, there 
are  cases  when  the  tone  of  the  sentence  is  very 
intense indicating the existence of emotion. Con-
sider Example 1. 
 
Example 1:  
Political news headline  

 >رɳɴ

، رɳʆا ɹ

 >ɳɹ  نɳ>ɹɳC ɳ ترɳɴ
@ʆ ںɳاʈ>  ʆʆɹ ɷʮ@ʄ 
[bhart ka pakstan kE sath jame mZakrat sE ankar, 

تاɷاɶʅ
 

ɿʅɳ>

 

bharty lykcr snnE kE Kwaha̱ nhy̱] 

[India  refuses  to  have  a  dialog  with  Pakistan,  In-

dians are not willing to listen to the lecture] 
Common Urdu 

 

ɳ@ʰʆا

 >@ʮ 

 ɹ نɳ>ɹɳC ʆ
 

 ɳ@د ɷ رɳʆا ɹ ʆرɳ

تɳɴ
[India refuses to talk to Pakistan] 
Clearly,  the  news  headline  is  extremely  in-
tense and strongly expresses the opinion of India 
on Pakistan. However, the statement in common 
Urdu is not as affective.  
 
Example 2: 

 روا غɳʅد >ɴ @ا ʄ@ɹ ɷʅɳɿ @ʅ ɲار یɷ@ʅ ،ɳ ʆ

 

یرɳɻʆا

@ ɻ>ɺ ی>ɼ   

[anSary nE kha “myry ray^E my̱ eamr shyl ayk 

bd dmaG awr Zdy XKS hy̱” ]                                                      

[Ansari said, “according to me Aamir Sohail is one 

crazy and stubborn man”] 

Statements in quotes that express emotions are 

subjective as shown in example 2. 

 
Consider  example  3.  Here,  identifying  the 
words  that  indicate  subjectivity  is  not  straight 
forward.  The  phrase,  “found  it  very  difficult  to 
hide his smile” is indicative of the emotion expe-
rienced by “Habib Miya”.  
 
Example 3: 

 
 ɳ>

ʄɺʅ >ɴ

 ɲʄ  ںɳ@ʅ ɴ@ɴ> @ ɷC ʄʈɻو سا  ʅʂر
@ɹ ɳCʮ ʧاɷɹʅ ʆCا هو   
[rqm  ky  as  wSwly  pr  yh  Hbyb  mya̱  kE  ly^E  bht 

mXkl t|ha kh wh apny mskrahT c|hpa sky̱]                                  

 [At  this  event  of  money  collection,  Habib  Miyan 

found it very difficult to hide his smile.]  

863

 
 
 
 

 
There  are  also  several  false  positives  that 
make  subjective  detection  hard  task.  Example  4 
is  an  objective  sentence  despite  the  usage  of 
word “pyar” ~ love, an emotion bearing word.  
 
Example 4:  

 رɳ@C ɳ@ʆ ɳ مɳʅɼʆا
 
[n|Zmam ka nya pyar ka nam anzy pRa hE] 

 اﮍC یɸʆا مɳʆ ɳ

[The new nickname for Inzaman is Inzi] 
 
Expressive  elements  in  Urdu  sentences  were 
marked with an inter-annotator agreement of 0.8 
kappa score. Though high, there still exists a bias 
that can influence classification especially when 
the number of sentences in the positive set is rel-
atively less. In order to obtain a reliable positive 
and negative set for training a learning algorithm, 
we adopt a semi-supervised learning technique of 
co-training.  Co-training  (Blum  and  Mitchell, 
1998) is similar to self-training in that it increas-
es  the  amount  of  labeled  data  by  automatically 
annotating  unlabeled  data.  The  intuition  here  is 
that  if  the  conditional  independence  assumption 
holds,  then  on  an  average  each  selected  docu-
ment  will  be  as  informative  as  a  random  docu-
ment, and the learning will progress. Co-training 
differs  from  self-training  as  it  uses  multiple 
learners to do the annotation. Each learner offers 
its  own  perspective  that  when  combined  gives 
more  information.  This  technique  is  especially 
effective  when  the  feature  space  of  a  particular 
type  of  problem  can  be  divided  into  distinct 
groups and each group contains sufficient infor-
mation to perform the annotation. In other words, 
co-training  algorithm  involves  training  two  dif-
ferent  learning  algorithms  on  two  different  fea-
ture spaces. The learning of one becomes condi-
tionally independent of the other and the predic-
tion made by each classifier is used on the unla-
beled data set to augment the training data of the 
other.  

A  traditional  co-training  classifier  is  trained 
and later applied on the same unlabeled data set. 
Theoretically  such  classifiers  are  not  likely  to 
assign  confident  labels.  In  this  work,  the  pro-
posed co-training method differs from the tradi-
tional co-training method in that the two classifi-
ers are based not on two different feature spaces 
but  on  two  different  training  data  sets  with  the 
same feature space.  

 

Figure 1: Co-Training model 

 

i and  P2

i
 and SVM2 is trained using S+N2

 
Figure  1  explains  the  overall  working  of  the 
model.  The  negative  set  (which  can  also  be  the 
unlabeled set) is split into two equal parts N1 and 
N2. S represents the positive annotated set. Two 
linear  SVM  classifiers  are  trained  iteratively  to 
purify the negative data set. SVM1 is trained us-
i data 
ing S+N1
i data set is evaluated 
sets. In every iteration i, N1
i data set is evaluated 
using SVM2 model and N2
using SVM1 model. The samples that are classi-
fied  as  positive in a  given  iteration  i are  binned 
i  respectively.  These  samples 
into  sets  P1
i data sets to create 
are removed from N1
i+1 sets that are used for training 
new N1
in the next iteration i+1. The iterations continue 
until  no  positive  samples  are  marked  by  both 
SVM1 and SVM2 models. The final set of likely 
k  and 
negatives  is  ҭ  =  N1
k  are sets created in the last  k  iteration  of  the 
N2
algorithm.  In  order  to  obtain  the  likely  positive 
k} and P2 = 
set, the final P1 = {P1
k}  sets  are  combined  and 
{P2
tested using the SVMs modeled in the last k ite-
ration of the co-training algorithm. Similar to the 
traditional  co-training  method  the  samples  that 
o) 
are marked positive by both classifiers (P1
are considered to be the likely positive set L.  

k  sets,  where  N1

2  +  ….  +  P2

2 + …. + P1

i+1 and N2

i and N2

k  +  N2

1  +  P2

1 + P1

o = P2

Several  features  are  used  to  train  the  SVM 
learning  models  used  for  co-training.  The  best 
performance  is  obtained  when  word  unigrams, 
parts  of  speech  and  likely  emotion  words  are 
used as features.  

This technique of co-training provides us with 
a  relatively  huge  set  of  likely  positive  samples 

864

 
 
 
 

(close  to  400  sentences).  Sentences  in  this  set 
were examined by the annotators and nearly 60% 
of the sentences were subjective or near subjec-
tive in nature (Example 5 and 6). 

 

Labels  R % 

P % 
Unigram 

1 
-1 

1 
-1 

74.57 
62.35 

18.64 
95.4 
Unigram+Bigram 
14.40 
98.19 

85 
61.82 

AF % 
52.63 
 

50.25 

IF % 

29.83 
75.44 

24.63 
75.87 

Table 1: Performance of the model using  

un-balanced data set3 

 

Labels  R % 
Annotated positive + likely positive + likely 

IF % 

P % 

AF % 
62.95 
 

negative 

70 
67.34 

39 
87.28 

50.09 
79.9 

Annotated positive + likely negative 

55.42 

30 
86.1 

61.2 
64.23 

40.26 
73.57 

Table 2 – Performance of the model after  

co-training method 

 

1 
-1 

1 
-1 

Table  1  shows  the  performance  of  the  SVM 
model using the unbalanced data set for training. 
Table  2  shows  the  performance  of  the  same 
model using data generated after co-training.  
 
Example 5:  
@

د ɳʆ>
ʅ ʆآ
 
 
@
@
ʆ ɷɾʆ
 
ɷ@ ʆا@
 
۔ ɳ>آ

 ںوɷɹود گʈʄ  ɳ ʆ ʆ>ʈC
  
ʄʆ@
[pwtn nE kha kh lwg dwsrw̱ ky Ank|h my̱ tnka 
dyk|h lytE hy̱ lykn apny Ank|h my̱ pRa Xhtyr an-
hy̱ n|zr nhy̱ Ata .] 

 
>ɺ اﮍC

ʅ ʆآ

 ʆCا 

 ʄ>@

 @

@

 

[Potan said people who see dust in others eyes 

never realize that it is their eyes that are filled with 
dirt.] 

The above example is a metaphor indicating 

extreme anger. 

 

Example 6: 
 
ںʈʧ@
ɴ  نا
 
@

 

>@

ʰ@ 

ɲاɷ ɲ

ʆا ʈ >ɹا هرɳɴ   ɳʆ ɳ

ɺ ʆʅ>ɷʄا ءɳɽɿ
 
ɷC  ɷ ʆɷɴ ɷC رʈط ʄʅʅ ʆʅɳɹ 
[e|ta& alrHmn XyK ka khna hE kh barh agst kw an-
hy̱ an kE byTw̱ kE samnE mkml |twr pr brhnh kr 
kE pryD kray^y gy^y] 
[etlaalrahman said that on 12th Aug they made him 
parade naked in front of his children.] 

                                                 
3 Convention used across tables -  Label 1: subjective sen-
tences Label -1: objective sentences R: Recall P: Precision 
IF: Individual F-Measure AF: Average F-Measure. 
 

Example 6 indicates extreme sad emotion. Such 
examples were found in the likely positive set. 

4  Features 

Features  that  are  commonly  used  to  train  a 
subjectivity  classifier  for  English  are  word  uni-
grams,  emotion  keywords,  part  of  speech  infor-
mation  and  noun  patterns  (Pang  et  al.,  2002). 
Due to difference in syntactic structure, vocabu-
lary and style, features that work for English may 
not work for Urdu. Also, Urdu is handicapped by 
the  lack  of  resources  required  to  perform  basic 
NLP analysis. However, it is worth exploring the 
English  feature  set  as  subjectivity  is  more  a  se-
mantic  phenomenon.  Efforts  to  generate  likely 
emotion  word  lexicons  and  subjectivity  patterns 
for  the  Urdu  language  are  underway.  The  sec-
tions  that  follow  summarize  the  experimented 
features. 

4.1  Word Unigrams 

Unigram  word  features  are  very  informative. 
Three different approaches are tried for selecting 
the unigrams. The first method involves selecting 
only  those  words  that  occur  more  than  twice  in 
the  dataset.  This  eliminates  proper  nouns  (low 
frequency  named  entities  do  not  generally  con-
tribute  towards  subjectivity  detection)  and  spel-
ling errors (Pang et al., 2002). In the second me-
thod,  only  words  that  are  adjectives  and  verbs 
along with the surrounding case markers are ac-
counted for as features. This has the advantage of 
drastically reducing the feature set. The third me-
thod involves including the nouns as well to the 
feature set. A simple list of stop words (common 
Urdu words – pronouns such as ‘us’, ‘is’, ‘aap’, 
‘un’, salutations like ‘shabba khair’, ‘aadab’ and 
honorifics  along  with  punctuations  and  special 
symbols)  are  eliminated.  The  features  are 
represented  as  Boolean  features  for  the  SVM 
model. The value is 1 if the feature word appears 
in the sentence to be classified and 0 otherwise. 
The  best  performance  is  obtained  for  the  first 
method  that  considers  all  words  with  frequency 
greater  than  2.  This  conforms  to  what  is  shown 
by  Pang  et  al.,  (2002)  for classification of  Eng-
lish movie reviews. 

4.2  Part of Speech (POS) Information 

The work done by Mukund and Srihari (2009) 
provides  suitable  POS  and  NE  tagger  for  Urdu. 

865

 
 
 
 

This  POS  tagger  is  used  to  generate  parts  of 
speech  tags  on  the  acquired  data  set  (§3).    The 
POS  tags  associated  with  adjectives,  verbs, 
common  nouns  and  auxiliary  words  are  consi-
dered and used as Boolean features for the SVM 
model. The proper noun words are normalized to 
one  common  word  “nnp”  and  are  assigned  the 
common  noun  tag.  For  the  English  language, 
when building a subjectivity classifier for review 
classification, the use of POS information did not 
benefit the system (Kennedy and Inkpen, 2006). 
However,  for  Urdu,  the  performance  of  the  co-
training  model  with  POS  information  showed 
1.2% improvement (table 3). 

4.3  Likely Emotion Lexicon 

In  order  to  facilitate  simple  keyword  based 
detection of subjectivity, access to a lexicon con-
sisting of likely emotion words is needed. Unfor-
tunately,  no  such  lexicon  is  available  off  the 
shelf  for  Urdu.  In  this  work,  an  Urdu  specific 
emotion  list  is  generated  that  contains  transla-
tions  from  the  English  emotion  list  released  by 
SemEval  (2007)  ‘Worḏet  affect  Emotion  List’. 
Words for each emotion category - sadness (sad), 
fear, joy (happy), surprise, anger and disgust are 
obtained for Urdu by using an Urdu-English dic-
tionary.  The  list  is  pruned  manually  and  cor-
rected to remove errors. Simple keyword lookup 
on  the  Urdu  annotated  corpus  has  an  emotion 
detection  rate  of  29.27%.  This  shows  that  al-
though  the  contribution  of  the  emotion  lexicon 
for subjectivity classification is not significant, it 
contains  information  which  when  used  along 
with other features aid subjectivity detection. 

4.4  Patterns 

Extracting  syntactic  patterns  contribute  to-
wards the affective orientation of a sentence (Ri-
loff  et  al.,  2003).  The  Apriori  algorithm  (Agar-
wal  and  Srikant,  1994)  for  learning  association 
rules is used here to mine the syntactic word pat-
terns commonly used in the positive and negative 
data set. The length of the candidate item set k = 
4. Starting from a small set of seed words (likely 
emotion  words)  and  the  associated  POS  tags, 
POS  sequential  patterns 
like  “adverb  verb 
verbtransitive  sentencemarker”,  “noun  noun  ca-
semarker  verbtransitive”,  etc.,  that  are  most 
commonly found in subjectivity set are extracted. 
23  patterns  that  strongly  indicate  subjectivity 

were found by this method and included as fea-
tures to train the SVM learning algorithm.  

4.5  Confidence Words 

The  confidence  word  list  positively  aids  the 
VSM  classifier  (§5).  The  words  in  the  likely 
emotion list are not the only ones that contribute 
towards  the  emotion  orientation  of  a  sentence 
and also, not all of these words contribute effec-
tively.  There  are  several  stop  words  (eliminated 
while accounting for unigrams) (esp. case mark-
ers)  that  contribute  significantly  for  categoriza-
tion.  In  order  to  identify  all  the  keywords  that 
actually contribute to subjectivity categorization, 
a  technique  proposed  by  Soucy  and  Mineau 
(2004) is used.  

The  confidence  weight  of  a  given  word  w, 
based  on  the  number  of  documents  it  is  asso-
ciated with under each category, is measured us-
ing  the  Wilson  Proportion  Estimate  (Wilson, 
1927).  In  order  to  compute  the  confidence  of  w 
for  a  specific  category,  the  number  of  positive 
and negative documents associated with w has to 
be  determined.  A  document  is  positive  if  it  be-
longs  to  that  category  and  negative  otherwise. 
Thus, two kinds of word confidence metrics are 
computed, CPOS:w and C̱EG:w as given below.  





=

 

C

POS

:
w

 

ˆ
p

POS

:
w

+

z
z
α
2/
2
n

±

z
α

2/

 

:
w

:
w

)

POS

POS

+

2
z
α

]4
nn

(
ˆ1
−
p
)n

ˆ[
p
(
1
              ………     (Eq. 1) 

2
z
α

+

2/

2/





 





z
z
α
2/
2
n

2/

ˆ
p

C

=

+

±

z
α

:
w
̱EG

:
w
̱EG

ˆ[
p
(
1
                ………    (Eq. 2) 
 
where n is the total number of positive and nega-

]4
nn

2
z
α

:
w
̱EG

:
̱EG

+

+

ˆ
p

 

 

2
z
α

2/

2/

w

(
−
1
)n

)





tive  documents, 
 is  the  ratio  of  the  num-
ber of positive documents which contain w to the 

w

:

ˆ
POSp

total  number  of  documents,  and 
 is  the 
ratio of the number of negative documents which 
contain w to the total number of documents. The 
normal distribution is used when n > 30.  

̱EG:w 

p ˆ

Note  that  equations  1  and  2  give  a  range  of 
values for CPOS:w and C̱EG:w. If the lower bound 
of  CPOS:w  is  greater  than  the  upper  bound  of 
C̱EG:w,  we  say  that  w  is  likely  to  be  a  word  in 
that category. Now, we compute the strength of a 
word Sw in a particular category as 
>
 )w:
ub(C 
POS
          

)
mPRF
          

 ;
lb(C if
 ;
otherwise

)w:NEG
          

⋅
log


0
          


       
      

(
2

Sw

=

 

866

 
 
 
 

                                                 ………  (Eq. 3) 
where mPRF is given by  

mPRF

=

lb(C

lb(C
)
POS
+
ub(C 
)

w:

POS

w:

)

w:NEG

                                                     ………   (Eq. 4) 
and  lb(…)  and  ub(…)  are  the  lower  and  upper 
bounds of their arguments, respectively. 
Equations 1 through 4 generated a very good set 
of keywords that are used as category word fea-
tures in the SVM learning model. For VSM, the 
strength  value  is  used  as  a  boost  factor  along 
with the tf-idf weight when calculating the simi-
larity score (table 3). 

5  Final Subjectivity Classifier 

Wiebe  et  al.,  (2005)  and  Pang  et  al.,  (2002) 
have shown that an SVM based approach works 
well  for  subjectivity  classification.  Riloff  et  al., 
(2003) have conducted experiments that use Bag-
Of-Words (BoW) as features to generate a Naïve 
Bayes  subjectivity  classifier  for the  MPQA  cor-
pus in  English. This  method  has  an  accuracy  of 
73.3%. Su and Markert (2008) use BoW features 
termed as lexical features on the IMDB corpus to 
generate  an  accuracy  of  60.5%.  Das  and  Ban-
dyopadhyay (2009) use a CRF based approach to 
generate a subjectivity classifier for Bengali data 
with a precision of 72.16% for news and 74.6% 
for blogs domain. The same approach has a pre-
cision of 76.08% and 79.9% on the two domains 
respectively.  Impressive  results  for  emotion  de-
tection are obtained by Danisman and Alpkocak, 
(2007)  who  use  a  VSM  based  approach.  They 
show that their approach works much better than 
a  traditional  SVM  based  approach  commonly 
used for emotion detection. 

In this work, we conduct subjectivity classifi-
cation  experiments  using  two  different  learning 
algorithms  –  linear  SVM  and  VSM.  The  best 
performance is obtained using the VSM model as 
shown in table 4. All experiments are conducted 
on  the  data  set  obtained  after  applying  the  co-
training technique.  

5.1  VSM algorithm 

The final subjectivity classifier is based on the 
VSM  approach.  Inspired  by  the  work  done  in 
“Feeler” (Danisman and Alpkocak, 2007), a sim-
ilar technique is used to train the final subjectivi-
ty classifier for Urdu. The algorithm is explained 
in  table  3.  The  similarity  metric  is  modified  to 

include  the  confidence  score  for  each  word 
(pt.5).  In  VSM,  documents  and  queries  are 
represented  as  vectors, and  the  cosine  angle  be-
tween them indicates the similarity. 

                         

1. 

 di = <w1i, w2i, …. wni> where wki is the weight of 
the  kth  term  in  document  i  ,  di  is  the  document 
vector.  wki  is  computed  using  tf-idf  weighting 
scheme. 

2.  Mj={d1,d2,…,dc}  where  Mj  is  each  class  (subjec-

3. 

tive and objective) 
 Model  vector  for  an  arbitrary  class  Ej  is  created 
by taking the mean of dj vectors  
|
∑

=

E

d

M

i

j

|

j

1
M

j

Md

∈

i

j

 

where |Mj| represents number of documents in Mj. 
4.  The  whole  system  is  represented  with  a  set  of 
model vectors, D={E1,E2,...,Es} where s represents 
the number of distinct classes to be recognized.  

5.  The  normalized  similarity  between  a  given  query 

text Q, and a class, Ej, is defined as follows: 

EQsim

(

,

)

=

j

n

∑

=
1

k

(

w

kq

+

conf

*)

E

 

kj

conf is the confidence factor applied for lexical 
terms found in the word list. 
classification result is, 
max(
VSM

arg

jEQsim

))

Q

=

(

)

(

,

Table 3: VSM Algorithm for subjectivity 

 

6. 

 

 Classification 

 

AF % 
62.95 
 

86.73 

1 
-1 

Labels  R % 

P % 

65.85 
85.58 

IF % 
Before Co-Training (all data) 
67.4 
84.44 
After Co-Training (pruned data) 
78.72 
86.73 

70.85 
83.33 

72.88 
91.29 

1 
-1 
Table 4: VSM approach, using all training data and 

85.57 
82.60 

using pruned training data (L+ҭ+true) 

 
The confidence metric (strength) for each term 
is  calculated  using  the  Wilson  proportion  esti-
mate  (§4.4)  and  added  to  the  term  score  as  the 
boost factor. Q is the test set. Model vectors are 
obtained  using  the  data  set  that  consists  of  true 
set  (annotated  positive  samples),  likely  positive 
set L and likely negative set N. Sets L and N are 
obtained  from  the  co-training  method.  The  re-
sults are shown in table 4.  
The  power  of  SVM  cannot  be  ignored.  Pang  et 
al.,  (2002)  use  SVM  to  generate  a  subjectivity 
(polarity)  classifier  for  English.  Our  second  set 
of experiments is conducted to measure the per-
formance  of  a  linear  SVM  classifier  for  subjec-
tivity  analysis  on  the  Urdu  newswire  data.  The 
data  set  used  for  training  is  the  pruned  data  set 

867

 
 
 
 

obtained after applying the co-training technique. 
The  features  used  and  the  performance  of  the 
model with each feature is documented in table 6.  

Labels  R % 

P % 

IF % 

1 
-1 

Unigrams + POS 

40.67 
88.29 

71.1 
67.74 

51.75 
76.67 

Unigrams + POS + Patterns 

AF % 
64.2 
 

65.68 

72.34 
68.69 

43.22 
88.29 

1 
-1 
Unigrams + POS + Patterns + emotion words   67.31 
1 
-1 

48.31 
85.88 

70.81 
70.09 

54.11 
77.26 

57.43 
77.19 

Table 6: SVM classifier on Urdu newswire data 

 
In  order  to  provide  a  better  understanding  of 
the power of the VSM technique, we applied this 
model  on  the  IMDB  data  set.  The  training  data 
consists  of  4000  positive  (subjective)  and  4000 
negative (objective) samples. Since the data set is 
already balanced, we skip the co-training method. 
Our aim here is to test the working of VSM clas-
sifier. The test set consists of 1000 positive and 
1000  negative  samples.  The  classification  result 
on  this  data set is shown  in  table  5. The  results 
are  comparable  to  the  state-of-the-art  perfor-
mance of English subjectivity classifier that uses 
SVM (Wiebe et al., 2005). 
P % 

Labels  R % 

IF % 

1 
-1 

Balanced training 

64 
93.18 

90.57 
71.68 

75 
81.03 

AF % 
78.01 
 

Table 5: VSM approach on IMDB data set 

6  Analysis of results 

In this work, experiments were conducted us-
ing  two  different  classification  approaches;  1. 
VSM  based  2.  SVM  based.    Results  in  table  4 
indicate that the VSM technique when combined 
with  the  modified  boost  factor  (confidence 
measure)  can  be  a  very  powerful  technique  for 
sentence  level  classification  tasks.  When  model 
vectors were constructed using the entire training 
set (highly unbalanced), the performance was at 
62%  F-Measure  with  the  subjectivity  detection 
rate of 70.85%. Post co-training, using the mod-
ified  model  vectors  obtained  from  the  pruned 
data set generated better scores. The increase in 
the recall of negative class and the increase in the 
overall  F-Measure  can  be  attributed  to  (i)  in-
crease  in  the  positive  samples  (~likely  positive 
set),  and  (ii)  cleaner  negative  set  (no  near  posi-
tive samples).  

The  results  in  table  6  for  the  SVM  classifier 
also indicate the benefits of co-training. The sub-
jectivity  classification  performance  show  posi-
tive  improvement.  Although  the  performance  of 
the SVM model is not as good as the VSM mod-
el,  addition  of  each  feature  shows  an  improve-
ment  in  the  subjectivity  recognition  rate.  This 
performance  indicates  that  the  feature  sets  ex-
plored  definitely  contain  positive  information 
necessary for accurate detection.  

The  poor  performance  of  SVM  (over  VSM) 
can be attributed to 1. lack of balanced data for 
training  a  traditional  SVM  model  and,  2.  small 
number of positive samples. In VSM the problem 
of unbalanced data set in a way is overcome by 
using  the confidence score  at  the  time  of  calcu-
lating similarity. If these factors are compensated, 
the performance of the SVM model will signifi-
cantly improve. 

7  Conclusion 

This  research  provides  interesting  insights  in 
modeling  a  subjectivity  classifier  for  Urdu 
newswire data. We show that despite Urdu being 
a  resource  poor  language,  techniques  like  co-
training and statistical techniques based on tf-idf 
and  word  unigrams  coupled  with  confidence 
measures  help  model the  state-of-the-art  subjec-
tivity classifier. We demonstrate the power of the 
co-training  technique  in  generating  likely  nega-
tive  and  positive  sets.  The  number  of  near  sub-
jective samples in the likely positive set suggests 
that  this  method  can  be  used  as  an  adaptive 
learning  technique  to enable  the  annotators  pro-
duce  more samples.  For a task  like  emotion  de-
tection,  that  requires  fine  grained  analysis,  sen-
tences need to be analyzed at the semantic level 
and this goes beyond simple keyword based ap-
proach. Our efforts are now concentrated in this 
direction. 

References 

Agrawal  R,  Srikant  R.  1994.  Fast  Algorithms  for  Mining 
Association  Rules.  In  Proc.  Of  the  Intl.  Conf  on  Very 
Large databases. Santiago, Chile. Sept. Pp. 478-499. 

Banea,  C.,  Mihalcea,  R.,  Wiebe,  J.,  and  Hassan,  S.  2008. 
Multilingual subjectivity analysis using machine transla-
tion. In Proceedings of EM̱LP-2008.  

Banfield,  A.  1982.  Unspeakable  Sentences.  Routledge  and 

Kegan Paul, Boston. 

868

 
 
 
 

Blum,  A.  and  Mitchell,  T.  1998.  Combining  labeled  and 
unlabeled  data  with  co-training.  Proceedings  of  the  ele-
venth  annual  conference  on  Computational  learning 
theory, ACM. p. 100. 

Pang, B., Lee, L., and Vaithyanathan, S. 2002. Thumbs up? 
Sentiment  classification  using  machine  learning  tech-
niques.  In  Proceedings  of  the  Conference  on  EM̱LP, 
pages 79–86. 

Brank, J., Grobelnik, M., Milic-Frayling, N., and Mladenic, 
D. 2003. Training text classifiers with SVM on very few 
positive  examples.  Technical  Report  MSR-TR-2003-34, 
Microsoft Corp. 

Chan, Philip K. and Stolfo J. Salvatore. 1998. Toward Scal-
able  Learning  with  Non-Uniform  Class  and  Cost  Distri-
butions:  A  Case  Study  in  Credit  Card  Fraud  Detection. 
Proc.  4th  Int.  Conf.  on  Knowledge  Discovery  and  Data 
Mining (KDD-98), August 27–31, 1998, New York City, 
New York, USA, pp. 164–168. AAAI Press. 

Riloff, E., Wiebe, J., and Wilson, T. 2003. Learning subjec-
tive  nouns  using  extraction  pattern  bootstrapping.  Pro-
ceedings  of  the  seventh  conference  on  ̱atural  language 
learning  at  HLT-̱AACL  2003  -  Volume  4,    Edmonton, 
Canada:  Association  for  Computational  Linguistics,  pp. 
25-32. 

Soucy, P., and Mineau, G. W. 2005. Beyond tfidf weighting 
for text categorization in the vector space model. Interna-
tional  Joint  Conference  on  Artificial  Intelligence,  Cite-
seer, p. 1130. 

Danisman,  T.,  and  Alpkocak,  A.  2008.  Feeler:  Emotion 
Classification  of  Text  Using  Vector  Space  Model.  AISB 
2008 Convention Communication, Interaction and Social 
Intelligence, p. 53. 

Su, F., and Markert. K. 2008. From words to senses: a case 
study of subjectivity recognition. Proceedings of the 22nd 
International  Conference  on  Computational  Linguistics-
Volume 1, ACL, pp. 825-832. 

Das,  A.,  and  Bandyopadhyay,  S.  2009.  Subjectivity  Detec-
tion in English and Bengali: A CRF-based Approach. Se-
venth  International  Conference  on  ̱atural  Language 
Processing (ICON 2009), December. Hyderabad, India. 

Japkowicz Nathalie. 2000. Learning from Imbalanced Data 
Sets:  A  Comparison  of  Various  Strategies.  In  ̱athalie 
Japkowicz  (ed.),  Learning  from  Imbalanced  Data  Sets: 
Papers  from  the  AAAI  Workshop  (Austin,  Texas,  Mon-
day, July 31, 2000), AAAI Press, Technical Report WS-
00-05, pp. 10–15. 

Kennedy, A, & Inkpen, D. 2005. Sentiment classification of 
movie and product reviews using contextual valence shif-
ters. In Workshop on the analysis of informal and formal 
information  exchange  during  negotiations  (FINEXIN 
2005) 

Ku,  L.  W.,  Liang,  Y.  T.,  and  Chen,  H.  H.  2006.  Opinion 
extraction, summarization and tracking in news and blog 
corpora. In Proceedings of AAAI-2006. 

Kubat,  Miroslav  and  Matwin  Stan.  1997.  Addressing  the 
curse  of  imbalanced  training  sets:  one-sided  selection. 
Proc. 14th ICML, Nashville, Tennessee, USA, July 8–12, 
1997, pp. 179–186. 

Liu,  B.,  Hu,  M.,  and  Cheng,  J.  2005.  Opinion  observer: 
Analyzing  and  comparing  opinions  on  the  web.  In  Pro-
ceedings of WWW-2005. 

Luo, N., Yuan, F., and Zuo, W. 2008. Using CoTraining and 
Semantic  Feature  Extraction  for  Positive  and  Unlabeled 
Text  Classification.  International  Seminar  on  Future  In-
formation Technology and Management Engineering. 

Mihalcea, R., Banea, C., and Wiebe, J. 2007. Learning mul-
tilingual  subjective  language  via  cross-lingual  projec-
tions. In Proceedings of ACL-2007. 

Mukund, S., and Srihari, R.K., 2009.  NE Tagging for Urdu 
based  on  Bootstrap  POS  Learning.  Third  International 
Workshop  on  Cross  Lingual  Information  Access:  Ad-
dressing  the  Information  Need  of  Multilingual  Societies 
(CLIAWS3), NAACL - 2009, Boulder, CO. 

Titov, I., and McDonald, R. 2008. A joint model of text and 
aspect  ratings  for  sentiment  summarization.  In  Proceed-
ings of ACL-08:HLT. 

Wan,  X.  2008.  Using  bilingual  knowledge  and  ensemble 
techniques  for  unsupervised  Chinese  sentiment  analysis. 
In Proceedings of EM̱LP-2008. 

Wan,  X.  2009.  Co-Training  for  Cross-Lingual  Sentiment 
Classification. In Proceedings of the Joint Conference of 
the 47th Annual Meeting of the ACL and the 4th Interna-
tional Joint Conference on ̱atural Language Processing 
of  the  AF̱LP,  Association  for  Computational  Linguis-
tics, pp. 235-243. 

Wiebe,  J.  1994.  Tracking  point  of  view  in  narrative.  Com-

putational Linguistics, 20(2):233-287. 

Weibe,  J.,  Bruce,  R.,  and  O’Hara,  T.  1999.  Development 
and use of a gold standard data set for subjectivity classi-
fications.  In  Proc. 37th  Annual Meeting  of  the  Assoc.  for 
Computational Linguistics (ACL-99). 

Wiebe,  J.,  and  Riloff,  E.  2005.  Creating  Subjective  and 
Objective  Sentence  Classifiers  from  Unannotated  Texts. 
Proceedings of the 6th International Conference on Intel-
ligent Text Processing and Computational Linguistics. 

Wiebe,  J.,  Wilson,  T.,  and  Cardie,  C.  2005.  Annotating 
expressions  of  opinions  and  emotions  in  language.  Lan-
guage  Resources  and  Evaluation,  volume  39,  issue  2-3, 
pp. 165-210. 

Wilson,  B.  Edward.  1927.  Probable  Inference,  the  Law  of 
Succession,  and  Statistical  Inference.  Journal  of  the 
American Statistical Association, Vol. 22, No. 158 (Jun., 
1927), pp. 209-212. 

 

