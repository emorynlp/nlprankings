










































Using Second-order Vectors in a Knowledge-based Method for Acronym Disambiguation


Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pages 145–153,
Portland, Oregon, USA, 23–24 June 2011. c©2011 Association for Computational Linguistics

Using Second-order Vectors in a
Knowledge-based Method for Acronym Disambiguation

Bridget T. McInnes∗

College of Pharmacy
University of Minnesota
Minneapolis, MN 55455

Ted Pedersen
Department of Computer Science

University of Minnesota
Duluth, MN 55812

Ying Liu
College of Pharmacy

University of Minnesota
Minneapolis, MN 55455

Serguei V. Pakhomov
College of Pharmacy

University of Minnesota
Minneapolis, MN 55455

Genevieve B. Melton
Institute for Health Informatics

University of Minnesota
Minneapolis, MN 55455

Abstract

In this paper, we introduce a knowledge-based
method to disambiguate biomedical acronyms
using second-order co-occurrence vectors. We
create these vectors using information about a
long-form obtained from the Unified Medical
Language System and Medline. We evaluate
this method on a dataset of 18 acronyms found
in biomedical text. Our method achieves an
overall accuracy of 89%. The results show
that using second-order features provide a dis-
tinct representation of the long-form and po-
tentially enhances automated disambiguation.

1 Introduction

Word Sense Disambiguation (WSD) is the task
of automatically identifying the appropriate sense of
a word with multiple senses. For example, the word
culture could refer to anthropological culture
(e.g., the culture of the Mayan civilization), or a
laboratory culture (e.g., cell culture).

Acronym disambiguation is the task of automat-
ically identifying the contextually appropriate long-
form of an ambiguous acronym. For example, the
acronym MS could refer to the disease Multiple Scle-
rosis, the drug Morphine Sulfate, or the state Missis-
sippi, among others. Acronym disambiguation can
be viewed as a special case of WSD, although, un-
like terms, acronyms tend to be complete phrases
or expressions, therefore collocation features are
not as easily identified. For example, the feature
rate when disambiguating the term interest, as in

∗Contact author : bthomson@umn.edu.

interest rate, may not be available. Acronyms also
tend to be noun phrases, therefore syntactic features
do not provide relevant information for the purposes
of disambiguation.

Identifying the correct long-form of an acronym
is important not only for the retrieval of information
but the understanding of the information by the re-
cipient. In general English, Park and Byrd (2001)
note that acronym disambiguation is not widely
studied because acronyms are not as prevalent in lit-
erature and newspaper articles as they are in specific
domains such as government, law, and biomedicine.

In the biomedical sublanguage domain, acronym
disambiguation is an extensively studied problem.
Pakhomov (2002) note acronyms in biomedical lit-
erature tend to be used much more frequently than in
news media or general English literature, and tend
to be highly ambiguous. For example, the Uni-
fied Medical Language System (UMLS), which in-
cludes one of the largest terminology resources in
the biomedical domain, contains 11 possible long-
forms of the acronym MS in addition to the four
examples used above. Liu et al. (2001) show that
33% of acronyms are ambiguous in the UMLS. In a
subsequent study, Liu et al. (2002a) found that 80%
of all acronyms found in Medline, a large repository
of abstracts from biomedical journals, are ambigu-
ous. Wren and Garner (2002) found that there exist
174,000 unique acronyms in the Medline abstracts
in which 36% of them are ambiguous. The authors
also estimated that the number of unique acronyms
is increasing at a rate of 11,000 per year.

Supervised and semi-supervised methods have
been used successfully for acronym disambiguation

145



but are limited in scope due to the need for sufficient
training data. Liu et al. (2004) state that an acronym
could have approximately 16 possible long-forms in
Medline but could not obtain a sufficient number of
instances for each of the acronym-long-form pairs
for their experiments. Stevenson et al. (2009) cite
a similar problem indicating that acronym disam-
biguation methods that do not require training data,
regardless if it is created manually or automatically,
are needed.

In this paper, we introduce a novel knowledge-
based method to disambiguate acronyms using
second-order co-occurrence vectors. This method
does not rely on training data, and therefore, is not
limited to disambiguating only commonly occurring
possible long-forms. These vectors are created us-
ing the first-order features obtained from the UMLS
about the acronym’s long-forms and second-order
features obtained from Medline. We show that us-
ing second-order features provide a distinct repre-
sentation of the long-form for the purposes of dis-
ambiguation and obtains a significantly higher dis-
ambiguation accuracy than using first order features.

2 Unified Medical Language System

The Unified Medical Language System (UMLS) is
a data warehouse that stores a number of distinct
biomedical and clinical resources. One such re-
source, used in this work, is the Metathesaurus.
The Metathesaurus contains biomedical and clin-
ical concepts from over 100 disparate terminol-
ogy sources that have been semi-automatically in-
tegrated into a single resource containing a wide
range of biomedical and clinical information. For
example, it contains the Systematized Nomencla-
ture of Medicine–Clinical Terms (SNOMED CT),
which is a comprehensive clinical terminology cre-
ated for the electronic exchange of clinical health
information, the Foundational Model of Anatomy
(FMA), which is an ontology of anatomical concepts
created specifically for biomedical and clinical re-
search, and MEDLINEPLUS, which is a terminol-
ogy source containing health related concepts cre-
ated specifically for consumers of health services.

The concepts in these sources can overlap. For
example, the concept Autonomic nerve exists in both
SNOMED CT and FMA. The Metathesaurus assigns

the synonymous concepts from the various sources
a Concept Unique Identifiers (CUIs). Thus both
the Autonomic nerve concepts in SNOMED CT and
FMA are assigned the same CUI (C0206250). This
allows multiple sources in the Metathesaurus to be
treated as a single resource.

Some sources in the Metathesaurus contain ad-
ditional information about the concept such as a
concept’s synonyms, its definition and its related
concepts. There are two main types of relations
in the Metathesaurus that we use: the parent/child
and broader/narrower relations. A parent/child re-
lation is a hierarchical relation between two con-
cepts that has been explicitly defined in one of the
sources. For example, the concept Splanchnic nerve
has an is-a relation with the concept Autonomic
nerve in FMA. This relation is carried forward to
the CUI level creating a parent/child relations be-
tween the CUIs C0037991 (Splanchnic nerve) and
C0206250 (Autonomic nerve) in the Metathesaurus.
A broader/narrower relation is a hierarchical relation
that does not explicitly come from a source but is
created by the UMLS editors. We use the entire
UMLS including the RB/RN and PAR/CHD rela-
tions in this work.

3 Medline

Medline (Medical Literature Analysis and Retrieval
System Online) is a bibliographic database contain-
ing over 18.5 million citations to journal articles
in the biomedical domain which is maintained by
the National Library of Medicine (NLM). The 2010
Medline Baseline, used in this study, encompasses
approximately 5,200 journals starting from 1948 and
is 73 Gigabytes; containing 2,612,767 unique uni-
grams and 55,286,187 unique bigrams. The majority
of the publications are scholarly journals but a small
number of newspapers, and magazines are included.

4 Acronym Disambiguation

Existing acronym disambiguation methods can be
classified into two categories: form-based and
context-based methods. Form-based methods, such
as the methods proposed by Taghva and Gilbreth
(1999), Pustejovsky et al. (2001), Schwartz and
Hearst (2003) and Nadeau and Turney (2005), dis-
ambiguate the acronym by comparing its letters di-

146



rectly to the initial letters in the possible long-forms
and, therefore, would have difficulties in distin-
guishing between acronyms with similar long-forms
(e.g., RA referring to Refractory anemia or Rheuma-
toid arthritis).

In contrast, context-based methods disambiguate
between acronyms based on the context in which the
acronym is used with the assumption that the context
surrounding the acronym would be different for each
of the possible long-forms. In the remainder of this
section, we discuss these types of methods in more
detail.

4.1 Context-based Acronym Disambiguation
Methods

Liu et al. (2001) and Liu et al. (2002b) introduce
a semi-supervised method in which training and
test data are automatically created by extracting ab-
stracts from Medline that contain the acronym’s
long-forms. The authors use collocations and a bag-
of-words approach to train a Naive Bayes algorithm
and report an accuracy of 97%. This method be-
gins to treat acronym disambiguation as more of a
WSD problem by looking at the context in which
the acronym exists to determine its long-form, rather
than the long-form itself. In a subsequent study, Liu
et al. (2004) explore using additional features and
machine learning algorithms and report an accuracy
of 99% using the Naive Bayes.

Joshi (2006) expands on Liu, et al’s work. They
evaluate additional machine learning algorithms us-
ing unigrams, bigrams and trigrams as features.
They found that given their feature set, SVMs ob-
tain the highest accuracy (97%).

Stevenson et al. (2009) re-recreate this dataset us-
ing the method described in Liu et al. (2001) to auto-
matically create training data for their method which
uses a mixture of linguistics features (e.g., colloca-
tions, unigrams, bigrams and trigrams) in combina-
tion with the biomedical features CUIs and Medi-
cal Subject Headings, which are terms manually as-
signed to Medline abstracts for indexing purposes.
The authors evaluate the Naive Bayes, SVM and
Vector Space Model (VSM) described by Agirre and
Martinez (2004), and report that VSM obtained the
highest accuracy (99%).

Pakhomov (2002) also developed a semi-
supervised method in which training data was

automatically created by first identifying the long-
form found in the text of clinical reports, replacing
the long-form with the acronym to use as training
data. A maximum entropy model trained and tested
on a corpus of 10,000 clinical notes achieved an
accuracy of 89%. In a subsequent study, Pakhomov
et al. (2005) evaluate obtaining training data from
three sources: Medline, clinical records and the
world wide web finding using a combination of
instances from clinical records and the web obtained
the highest accuracy.

Joshi et al. (2006) compare using the Naive
Bayes, Decision trees and SVM on ambiguous
acronyms found in clinical reports. The authors
use the part-of-speech, the unigrams and the bi-
grams of the context surrounding the acronym as
features. They evaluate their method on 7,738
manually disambiguated instances of 15 ambiguous
acronyms obtaining an accuracy of over 90% for
each acronym.

5 Word Sense Disambiguation

Many knowledge-based WSD methods have been
developed to disambiguate terms which are closely
related to the work presented in this paper. Lesk
(1986) proposes a definition overlap method in
which the appropriate sense of an ambiguous term
was determined based on the overlap between its
definition in a machine readable dictionary (MRD).
Ide and Véronis (1998) note that this work provided
a basis for most future MRD disambiguation meth-
ods; including the one presented in this paper.

Banerjee and Pedersen (2002) use the Lesk’s
overlap method to determine the relatedness be-
tween two concepts (synsets) in WordNet. They ex-
tend the method to not only include the definition
(gloss) of the two synsets in the overlap but also the
glosses of related synsets.

Wilks et al. (1990) expand upon Lesk’s method by
calculating the number of times the words in the def-
inition co-occur with the ambiguous words. In their
method, a vector is created using the co-occurrence
information for the ambiguous word and each of its
possible senses. The similarity is then calculated be-
tween the ambiguous word’s vector and each of the
sense vectors. The sense whose vector is most simi-
lar is assigned to the ambiguous word.

147



0
.3

0 0 0 0 0 0disphosphoric

g
lu

co
se

fru
cto

se

p
h

o
sp

h
o

ric

esters

ch
an

g
ed



effect

0 0 0 0 0

g
lyco

lyte

en
zym

es

co
m

b
in

ed


d
ecreases

in
ten

sity

acid


0

m
etab

o
lites

FEATURES

0 0 0 0 .2 0acid 0 0 0 .1 0 0

0 0 0 0 .5 0 0esters 0 0 0 0 0 0

0 .1 0 0 0 0 0 0 0 0 0 0 0

0 0 0 0 0 0 0

fructose

0 0 0 0 0 0

0 0 0 0 0 0 0

diphosphate

0 0 0 0 0 0isomer

0 0 0 0 0 0 0prevalent 0 0 0 0 0 0

0 .1 0 .3 .5 .2 02nd order vector for
Fructose Diphosphate

0 0 0 .1 0 0

E
xt

en
d

ed
 D

ef
in

it
io

n


fo
r 

F
ru

ct
o

se
 D

ip
h

o
sp

h
at

e

Figure 1: 2nd Order Vector for Fructose Diphosphate (FDP)

Patwardhan and Pedersen (2006) introduce a vec-
tor measure to determine the relatedness between
pairs of concepts. In this measure, a second order
co-occurrence vector is created for each concept us-
ing the words in each of the concepts definition and
calculating the cosine between the two vectors. This
method has been used in the task of WSD by calcu-
lating the relatedness between each possible sense
of the ambiguous word and its surrounding context.
The context whose sum is the most similar is as-
signed to the ambiguous word.

Second-order co-occurrence vectors were first in-
troduced by Schütze (1992) for the task of word
sense discrimination and later extended by Puran-
dare and Pedersen (2004). As noted by Pedersen
(2010), disambiguation requires a sense-inventory
in which the long-forms are known ahead of time,
where as in discrimination this information is not
known a priori.

6 Method

In our method, a second-order co-occurrence vec-
tor is created for each possible long-form of the

acronym, and the acronym itself. The appropriate
long-form of the acronym is then determined by
computing a cosine between the vector represent-
ing the ambiguous acronym and each of the vectors
representing the long-forms. The long-form whose
vector has the smallest angle between it and the
acronym vector is chosen as the most likely long-
form of the acronym.

To create a second-order vector for a long-form,
we first obtain a textual description of the long-form
in the UMLS, which we refer to as the extended defi-
nition. Each long-form, from our evaluation set, was
mapped to a concept in the UMLS, therefore, we use
the long-form’s definition plus the definition of its
parent/children and narrow/broader relations and the
terms in the long-form.

We include the definition of the related concepts
because not all concepts in the UMLS have a defini-
tion. In our evaluation dataset, not a single acronym
has a definition for each possible long-form. On
average, each extended definition contains approx-
imately 453 words. A short example of the extended
definition for the acronym FDP when referring to

148



fructose diphosphate is: “ Diphosphoric acid esters
of fructose. The fructose diphosphate isomer is most
prevalent. fructose diphosphate.”

After the extended definition is obtained, we cre-
ate the second-order vector by first creating a word
by word co-occurrence matrix in which the rows
represent the content words in the long-forms, ex-
tended definition, and the columns represent words
that co-occur in Medline abstracts with the words in
the definition. Each cell in this matrix contains the
Log Likelihood Ratio (Dunning (1993)) of the word
found in the row and the word in the column. Sec-
ond, each word in the long-forms, extended defini-
tion is replaced by its corresponding vector, as given
in the co-occurrence matrix. The centroid of these
vectors constitutes the second order co-occurrence
vector used to represent the long-form.

For example, given the example corpus contain-
ing two instances: 1) The metabolites, glucose fruc-
tose and their phosphoric acid esters are changed
due to the effect of glycolytic enzymes, and 2)
The phosphoric acid combined with metabolites de-
creases the intensity. Figure 1 shows how the
second-order co-occurrence vector is created for the
long-form fructose diphosphate using the extended
definition and features from our given corpus above.

The second-order co-occurrence vector for the
ambiguous acronym is created in a similar fashion,
only rather than using words in the extended defini-
tion, we use the words surrounding the acronym in
the instance.

Vector methods are subject to noise introduced by
features that do not distinguish between the differ-
ent long-forms of the acronym. To reduce this type
of noise, we select the features to use in the second
order co-occurrence vectors based on the following
criteria: 1) second order feature cannot be a stop-
word, and 2) second order feature must occur at least
twice in the feature extraction dataset and not occur
more than 150 times. We also experiment with the
location of the second-order feature with respect to
the first-order feature by varying the window size of
zero, four, six and ten words to the right and the left
of the first-order feature. The experiments in this
paper were conducted using CuiTools v0.15. 1

Our method is different from other context-based

1http://cuitools.sourceforge.net

acronym disambiguation methods discussed in the
related work because it does not require annotated
training data for each acronym that needs to be dis-
ambiguated. Our method differs from the method
proposed by Wilks et al. (1990) in two fundamen-
tal aspects: 1) using the extended definition of
the possible long-forms of an acronym, and 2) using
second-order vectors to represent the instance con-
taining the acronym and each of the acronym’s pos-
sible long-forms.

7 Data

7.1 Acronym Dataset

We evaluated our method on the “Abbrev” dataset 2

made available by Stevenson et al. (2009). The
acronyms and long-forms in the data were initially
presented by Liu et al. (2001). Stevenson et al.
(2009) automatically re-created this dataset by iden-
tifying the acronyms and long-forms in Medline ab-
stracts and replacing the long-form in the abstract
with its acronym. Each abstract contains approxi-
mately 216 words. The dataset consists of three sub-
sets containing 100 instances, 200 instances and 300
instances of the ambiguous acronym referred to as
Abbrev.100, Abbrev.200, Abbrev.300, respectively.
The acronyms long-forms were manually mapped to
concepts in the UMLS by Stevenson, et al.

A sufficient number of instances were not found
for each of the 21 ambiguous acronyms by Steven-
son et al. (2009). For example, “ASP” only con-
tained 71 instances and therefore not included in any
of the subsets. “ANA” and “FDP” only contained
just over 100 instances and therefore, are only in-
cluded in the Abbrev.100 subset. “ACE”, “ASP”
and “CSF” were also excluded because several of
the acronyms’ long-forms did not occur frequently
enough in Medline to create a balanced dataset.

We evaluate our method on the same subsets that
Stevenson et al. (2009) used to evaluate their super-
vised method. The average number of long-forms
per acronym is 2.6 and the average majority sense
across all subsets is 70%.

7.2 Feature Extraction Dataset

We use abstracts from Medline, containing ambigu-
ous acronym or long-form, to create the second-

2http://nlp.shef.ac.uk/BioWSD/downloads/corpora

149



order co-occurrence vectors for our method as de-
scribed in Section 6. Table 1 shows the number of
Medline abstracts extracted for the acronyms.

Acronyms # Abstracts Acronym # Abstracts
ANA 3,267 APC 11,192
BPD 3,260 BSA 10,500
CAT 44,703 CML 8,777
CMV 13,733 DIP 2,912
EMG 16,779 FDP 1,677
LAM 1,572 MAC 6,528
MCP 2,826 PCA 11,044
PCP 5,996 PEG 10,416
PVC 2,780 RSV 5,091

Table 1: Feature Extraction Data for Acronyms

8 Results

Table 2 compares the majority sense baseline and the
first-order baseline with the results obtained using
our method on the Acronym Datasets (Abbrev.100,
Abbrev.200 and Abbrev.300) using a window size
of zero, four, six and ten. Differences between the
means of disambiguation accuracy produced by var-
ious approaches were tested for statistical signifi-
cance using the pair-wise Student’s t-tests with the
significance threshold set to 0.01.

Window Abbrev
Size 100 200 300

Maj. Sense Baseline 0.70 0.70 0.70
1-order Baseline 0.57 0.61 0.61

Our Method

0 0.83 0.83 0.81
4 0.86 0.87 0.86
6 0.88 0.90 0.89

10 0.88 0.90 0.89

Table 2: Overall Disambiguation Results

The majority sense baseline is often used to evalu-
ate supervised learning algorithms and indicates the
accuracy that would be achieved by assigning the
most frequent sense (long-form) to every instance.
The results in Table 2 demonstrate that our method is
significantly more accurate than the majority sense
baseline (p ≤ 0.01).

We compare the results using second-order vec-
tors to first-order vectors. Table 2 shows that ac-
curacy of the second-order results is significantly
higher than the first-order results (p ≤ 0.01).

The results in Table 2 also show that, as the win-
dow size grows from zero to six, the accuracy of the

system increases and plateaus at a window size of
ten. There is no statistically significant difference
between using a window size of six and ten but there
is a significant difference between a window size of
zero and six, as well as four and six (p ≤ 0.01).

Acronym # Long Abbrev Abbrev Abbrev
forms 100 200 300

ANA 3 0.84
APC 3 0.88 0.87 0.87
BPD 3 0.96 0.95 0.95
BSA 2 0.95 0.93 0.92
CAT 2 0.88 0.87 0.87
CML 2 0.81 0.84 0.83
CMV 2 0.98 0.98 0.98
DIP 2 0.98 0.98
EMG 2 0.88 0.89 0.88
FDP 4 0.65
LAM 2 0.86 0.87 0.88
MAC 4 0.94 0.95 0.95
MCP 4 0.73 0.67 0.68
PCA 4 0.78 0.79 0.79
PCP 2 0.97 0.96 0.96
PEG 2 0.89 0.89 0.88
PVC 2 0.95 0.95
RSV 2 0.97 0.98 0.98

Table 3: Individual Results using a Window Size of 6.

9 Error Analysis

Table 3 shows the results obtained by our method for
the individual acronyms using a window size of six,
and the number of possible long-forms per acronym.
Of the 18 acronyms, three obtain an accuracy below
80 percent: FDP, MCP and PCA.

FPD has four possible long-forms: Fructose
Diphosphate (E1), Formycin Diphosphate (E2), Fib-
rinogen Degradation Product (E3) and Flexor Dig-
itorum Profundus (E4). The confusion matrix in
Table 4 shows that the method was unable to dis-
tinguish between the two long-forms, E1 and E2,
which are both diphosphates, nor E2 and E3.

Long-Form E1 E2 E3 E4
E1: Fructose Diphosphate
E2: Formycin Diphosphate 5 2 11 19
E3: Fibrinogen Degradation Product 4
E4: Flexor Digitorum Profundus 59

Table 4: FDP Confusion Matrix

MCP also has four possible long-forms: Multicat-
alytic Protease (E1), Metoclopramide (E2), Mono-
cyte Chemoattractant Protein (E3) and Membrane

150



Cofactor Protein (E4). The confusion matrix in Ta-
ble 5 shows that the method was not able to distin-
guish between E3 and E4, which are both proteins,
and E1, which is a protease (an enzyme that breaks
down a protein).

Long-Form E1 E2 E3 E4
E1: Multicatalytic Protease 1 5 6 1
E2: Metoclopramide 15
E3: Monocyte Chemoattractant Protein 1 3 44 11
E4: Membrane Cofactor Protein 13

Table 5: MCP Confusion Matrix

PCA has four possible long-forms: Passive Cu-
taneous Anaphylaxis (E1), Patient Controlled Anal-
gesia (E2), Principal Component Analysis (E3), and
Posterior Cerebral Artery (E4). The confusion ma-
trix in Table 6 shows that the method was not able
to distinguish between E2 and E3. Analyzing the
extended definitions of the concepts showed that E2
includes the definition to the concept Pain Manage-
ment. The words in this definition overlap with
many of the words used in E3s extended definition.

Long-Form E1 E2 E3 E4
E1:Passive Cutaneous Anaphylaxis 18 6 1
E2:Patient Controlled Analgesia 5 15
E3:Principal Component Analysis 48
E4:Posterior Cerebral Artery 7

Table 6: PCA Confusion Matrix

10 Comparison with Previous Work

Of the previously developed methods, Liu et al.
(2004) and Stevenson et al. (2009) evaluated their
semi-supervised methods on the same dataset as we
used for the current study. A direct comparison
can not be made between our method and Liu et al.
(2004) because we do not have an exact duplication
of the dataset that they use. Their results are com-
parable to Stevenson et al. (2009) with both report-
ing results in the high 90s. Our results are directly
comparable to Stevenson et al. (2009) who report
an overall accuracy of 98%, 98% and 99% on the
Abbrev.100, Abbrev.200 and Abbrev.300 datasets
respectively. This is approximately 10 percentage
points higher than our results.

The advantage of the methods proposed by
Stevenson et al. (2009) and Liu et al. (2004) is that

they are semi-supervised which have been shown to
obtain higher accuracies than methods that do not
use statistical machine learning algorithms. The dis-
advantage is that sufficient training data are required
for each possible acronym-long-form pair. Liu et
al. (2004) state that an acronym could have approxi-
mately 16 possible long-forms in Medline but a suf-
ficient number of instances for each of the acronym-
long-form pairs were not found in Medline and,
therefore, evaluated their method on 15 out of the
original 34 acronyms. Stevenson et al. (2009) cite
a similar problem in re-creating this dataset. This
shows the limitation to these methods is that a suffi-
cient number of training examples can not be ob-
tained for each acronym that needs to be disam-
biguated. The method proposed in the paper does
not have this limitation and can be used to disam-
biguate any acronym in Medline.

11 Discussion

In this paper, we presented a novel method to disam-
biguate acronyms in biomedical text using second-
order features extracted from the UMLS and Med-
line. The results show that using second-order fea-
tures provide a distinct representation of the long-
form that is useful for disambiguation.

We believe that this is because biomedical text
contains technical terminology that has a rich source
of co-occurrence information associated with them
due to their compositionality. Using second-order
information works reasonably well because when
the terms in the extended definition are broken up
into their individual words, information is not being
lost. For example, the term Patient Controlled Anal-
gesia can be understood by taking the union of the
meanings of the three terms and coming up with an
appropriate definition of the term (patient has con-
trol over their analgesia).

We evaluated various window sizes to extract the
second-order co-occurrence information from, and
found using locally occurring words obtains a higher
accuracy. This is consistent with the finding reported
by Choueka and Lusignan (1985) who conducted an
experiment to determine what size window is needed
for humans to determine the appropriate sense of an
ambiguous word.

The amount of data used to extract the second-

151



order features for each ambiguous acronym varied
depending on its occurrence in Medline. Table 1 in
Section 7.2 shows the number of abstracts in Med-
line used for each acronym. We compared the accu-
racy obtained by our method using a window size of
six on the Abbrev.100 dataset with the number of ab-
stracts in the feature extraction data. We found that
the accuracy was not correlated with the amount of
data used (r = 0.07). This confirms that it is not the
quantity but the content of the contextual informa-
tion that determines the accuracy of disambiguation.

We compared using second-order features and
first-order features showing that the second-order re-
sults obtained a significantly higher accuracy. We
believe that this is because the definitions of the pos-
sible concepts are too sparse to provide enough in-
formation to distinguish between them. This find-
ing coincides to that of Purandare and Pedersen
(2004) and Pedersen (2010) who found that with
large amounts of data, first-order vectors perform
better than second-order vectors, but second-order
vectors are a good option when large amounts of
data are not available.

The results of the error analysis indicate that
for some acronyms using the extended definition
does not provide sufficient information to make
finer grained distinctions between the long-forms.
This result also indicates that, although many long-
forms of acronyms can be considered coarse-grained
senses, this is not always the case. For example, the
analysis of MCP showed that two of its possible
long-forms are proteins which are difficult to differ-
entiate from given the context.

The results of the error analysis also show that
indicative collocation features for acronyms are not
easily identified because acronyms tend to be com-
plete phrases. For example, two of the possible
long-forms of DF are Fructose Diphosphate and
Formycin Diphosphate.

Two main limitations of this work must be men-
tioned to facilitate the interpretation of the results.
The first is the small number of acronyms and the
small number of long-forms per acronym in the
dataset; however, the acronyms in this dataset are
representative of the kinds of acronyms one would
expect to see in biomedical text. The second limita-
tion is that the dataset contains only those acronyms
whose long-forms were found in Medline abstracts.

The main goal of this paper was to determine if the
context found in the long-forms, extended definition
was distinct enough to distinguish between them us-
ing second-order vectors. For this purpose, we feel
that the dataset was sufficient although a more ex-
tensive dataset may be needed in the future for im-
proved coverage.

12 Future Work

In the future, we plan to explore three different
avenues. The first avenue is to look at obtaining
contextual descriptions of the possible long-forms
from resources other than the UMLS such as the
MetaMapped Medline baseline and WordNet. The
second avenue is limiting the features that are used
in the instance vectors. The first-order features in
the instance vector contain the words from the entire
abstract. As previously mentioned, vector methods
are subject to noise, therefore, in the future we plan
to explore using only those words that are co-located
next to the ambiguous acronym. The third avenue is
expanding the vector to allow for terms. Currently,
we use word vectors, in the future, we plan to extend
the method to use terms, as identified by the UMLS,
as features rather than single words.

We also plan to test our approach in the clinical
domain. We believe that acronym disambiguation
may be more difficult in this domain due to the in-
crease amount of long-forms as seen in the datasets
used by Joshi et al. (2006) and Pakhomov (2002).

13 Conclusions

Our study constitutes a significant step forward in
the area of automatic acronym ambiguity resolu-
tion, as it will enable the incorporation of scalable
acronym disambiguation into NLP systems used for
indexing and retrieval of documents in specialized
domains such as medicine. The advantage of our
method over previous methods is that it does not re-
quire manually annotated training for each acronym
to be disambiguated while still obtaining an overall
accuracy of 89%.

Acknowledgments

This work was supported by the National Insti-
tute of Health, National Library of Medicine Grant
#R01LM009623-01.

152



References

E. Agirre and D. Martinez. 2004. The Basque Country
University system: English and Basque tasks. In Pro-
ceedings of the 3rd ACL workshop on the Evaluation
of Systems for the Semantic Analysis of Text (SENSE-
VAL), pages 44–48.

S. Banerjee and T. Pedersen. 2002. An adapted lesk al-
gorithm for word sense disambiguation using Word-
Net. In Proceedings of the 3rd International Confer-
ence on Intelligent Text Processing and Computational
Linguistics, pages 136–145.

Y. Choueka and S. Lusignan. 1985. Disambiguation
by short contexts. Computers and the Humanities,
19(3):147–157.

T. Dunning. 1993. Accurate methods for the statistics of
surprise and coincidence. Computational Linguistics,
19(1):61–74.

N. Ide and J. Véronis. 1998. Introduction to the special
issue on word sense disambiguation: the state of the
art. Computational Linguistics, 24(1):2–40.

M. Joshi, S. Pakhomov, T. Pedersen, and C.G. Chute.
2006. A comparative study of supervised learning as
applied to acronym expansion in clinical reports. In
Proceedings of the Annual Symposium of AMIA, pages
399–403.

M. Joshi. 2006. Kernel Methods for Word Sense Disam-
biguation and Abbreviation Expansion. Master’s the-
sis, University of Minnesota.

M. Lesk. 1986. Automatic sense disambiguation using
machine readable dictionaries: how to tell a pine cone
from an ice cream cone. Proceedings of the 5th Annual
International Conference on Systems Documentation,
pages 24–26.

H. Liu, YA. Lussier, and C. Friedman. 2001. Disam-
biguating ambiguous biomedical terms in biomedical
narrative text: an unsupervised method. Journal of
Biomedical Informatics, 34(4):249–261.

H. Liu, A.R. Aronson, and C. Friedman. 2002a. A study
of abbreviations in MEDLINE abstracts. In Proceed-
ings of the Annual Symposium of AMIA, pages 464–
468.

H. Liu, S.B. Johnson, and C. Friedman. 2002b. Au-
tomatic resolution of ambiguous terms based on ma-
chine learning and conceptual relations in the UMLS.
JAMIA, 9(6):621–636.

H. Liu, V. Teller, and C. Friedman. 2004. A multi-
aspect comparison study of supervised word sense dis-
ambiguation. JAMIA, 11(4):320–331.

D. Nadeau and P. Turney. 2005. A supervised learning
approach to acronym identification. In Proceedings
of the 18th Canadian Conference on Artificial Intelli-
gence, pages 319–329.

S. Pakhomov, T. Pedersen, and C.G. Chute. 2005. Ab-
breviation and acronym disambiguation in clinical dis-
course. In Proceedings of the Annual Symposium of
AMIA, pages 589–593.

S. Pakhomov. 2002. Semi-supervised maximum en-
tropy based approach to acronym and abbreviation
normalization in medical texts. In Proceedings of
the 40th Annual Meeting on Association for Compu-
tational Linguistics, pages 160–167.

Y. Park and R.J. Byrd. 2001. Hybrid text mining for find-
ing abbreviations and their definitions. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, pages 126–133.

S. Patwardhan and T. Pedersen. 2006. Using WordNet-
based context vectors to estimate the semantic related-
ness of concepts. In Proceedings of the EACL 2006
Workshop Making Sense of Sense - Bringing Com-
putational Linguistics and Psycholinguistics Together,
pages 1–8.

T. Pedersen. 2010. The effect of different context repre-
sentations on word sense discrimination in biomedical
texts. In Proceedings of the 1st ACM International IHI
Symposium, pages 56–65.

A. Purandare and T. Pedersen. 2004. Word sense dis-
crimination by clustering contexts in vector and sim-
ilarity spaces. In Proceedings of the Conference on
Computational Natural Language Learning (CoNLL),
pages 41–48.

J. Pustejovsky, J. Castano, B. Cochran, M. Kotecki,
M. Morrell, and A. Rumshisky. 2001. Extraction and
disambiguation of acronym-meaning pairs in medline.
Unpublished manuscript.

H. Schütze. 1992. Dimensions of meaning. In Proceed-
ings of the 1992 ACM/IEEE Conference on Supercom-
puting, pages 787–796.

A.S. Schwartz and M.A. Hearst. 2003. A simple
algorithm for identifying abbreviation definitions in
biomedical text. In Proceedings of the Pacific Sym-
posium on Biocomputing (PSB), pages 451–462.

M. Stevenson, Y. Guo, A. Al Amri, and R. Gaizauskas.
2009. Disambiguation of biomedical abbreviations.
In Proceedings of the ACL BioNLP Workshop, pages
71–79.

K. Taghva and J. Gilbreth. 1999. Recognizing acronyms
and their definitions. ISRI UNLV, 1:191–198.

Y. Wilks, D. Fass, C.M. Guo, J.E. McDonald, T. Plate,
and B.M. Slator. 1990. Providing machine tractable
dictionary tools. Machine Translation, 5(2):99–154.

J.D. Wren and H.R. Garner. 2002. Heuristics for iden-
tification of acronym-definition patterns within text:
towards an automated construction of comprehensive
acronym-definition dictionaries. Methods of Informa-
tion in Medicine, 41(5):426–434.

153


