



















































UTHCCB: A report for SemEval 2014 - Task 7 Analysis of Clinical Text


Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 802–806,
Dublin, Ireland, August 23-24, 2014.

UTH_CCB: A Report for SemEval 2014 – Task 7 Analysis of Clinical 
Text  

  
 

Yaoyun Zhang1   Jingqi Wang1   Buzhou Tang2   Yonghui Wu1   Min Jiang1              
Yukun Chen3  Hua Xu1* 

1University of Texas 
School of Biomedical 
Informatics at Houston 

Houston, TX, 77030, USA 

2Harbin Institute of Technology 
Shenzhen Graduate School 
Shenzhen, 518055, China 

3Vanderbilt University 
Department of Biomedical 

Informatics 
Nashville, TN, 37240, USA 

{Yaoyun.Zhang, Yonghui.Wu, Min.Jiang, Hua.Xu} @uth.tmc.edu 
tangbuzhou@gmail.com yukun.chen@Vanderbilt.Edu 

 

 
  

 

Abstract 

This work describes the participation of the 
University of Texas Health Science Center at 
Houston (UTHealth) team on the SemEval 2014 
– Task 7 analysis of clinical text challenge. The 
task consisted of two subtasks: (1) disorder entity 
recognition,  recognizing mentions of disorder 
concepts; (2) disorder entity encoding, mapping 
each mention to a unique Concept Unique 
Identifier (CUI) defined in Unified Medical 
Language System (UMLS). We developed three 
ensemble learning approaches for recognizing 
disorder entities and a Vector Space Model based 
method for encoding. Our approaches achieved 
top rank in both subtasks, with the best F 
measure of 0.813 for entity recognition and the 
best accuracy of 74.1% for encoding, indicating 
the proposed approaches are promising. 
 

1 Introduction 
 
In recent years, clinical natural language 
processing (NLP) has received great attention for 
its critical role in unlocking information 
embedded in clinical documents. Leveraging 
such information can facilitate the secondary1 use 
of electronic health record (EHR) data to 
                                                
     This work is licensed under a Creative Commons 
Attribution 4.0 International Licence. Page numbers and 
proceedings footer are added by the organisers. Licence 
details:http://creativecommons.org/licenses/by/4.0/ 

promote clinical and translational research.  
Clinical entity recognition, which recognizes 
mentions of clinically relevant concepts (e.g., 
disorders, procedures, drugs etc.) in narratives,  
 and clinical entity encoding, which maps the 
recognized entities to concepts in standard 
vocabularies (e.g., UMLS CUI (Bodenreider, 
2004)), are among the fundamental tasks in 
clinical NLP research. 

Many systems have been developed to extract 
clinical concepts from various types of clinical 
notes in last two decades, ranging from early 
symbolic NLP systems heavily dependent on 
domain knowledge to machine learning 
algorithm based systems driven by increasingly 
available annotated clinical corpora. The 
representative systems include MedLEE 
(Friedman et al., 1994), MetaMap (Aronson and 
Lang, 2010), KnowledgeMap (Denny et al., 
2003), cTAKES (Savova et al., 2010), etc. 
Clinical NLP challenges organized by the Center 
for Informatics for Integrating Biology & the 
Beside (i2b2) have promoted research using 
machine learning algorithms to recognize clinical 
entities (Uzuner et al., 2010; Uzuner et al., 2011).  

Unlike the previous i2b2 challenges, the 
ShARe/CLEF challenge of clinical disorder 
extraction and encoding held in 2013 took the 
initiative to recognize disjoint entities, in 
addition to entities made up of consecutive words 
(Chapman et al., 2013). ShARe/CLEF challenge 
also required encoding of the disorder entities to 
Systematized Nomenclature Of Medicine 
Clinical Terms (SNOMED-CT) (using UMLS 
CUIs).  

802



In this paper, we describe our system for Task 
7 of SemEval 2014, which followed the 
requirements of 2013 ShARe/CLEF challenge. 
Our system employed ensemble learning based 
approaches for disorder entity recognition and a 
Vector Space Model (VSM) based method for 
mapping extracted entities to CUIs of SNOMED-
CT concepts. Our system was top-ranked among 
all participating teams according to evaluation by 
the organizer. 

2 Method 
Our end-to-end system for Task 7 of SemEval 
2014 consists of two components: disorder entity 
recognition and encoding. The raw clinical notes 
first went through the pre-processing modules for 
rule-based sentence boundary detection and 
tokenization. Extracted features were then used 
to train two machine learning algorithm-based 
entity recognition models, Conditional Random 
Fields (CRFs) (Lafferty et al., 2001) and 
Structural Support Vector Machines (SSVMs) 
(Tsochantaridis et al., 2005), respectively. These 
two models were ensembled with MetaMap, a 
symbolic biomedical NLP system, by three 
different approaches. Recognized entities were 
mapped to SNOWMED-CT CUIs in the 
encoding component. Detailed information of the 
components are presented in the following 
sections.  

2.1 Dataset 
The training and test sets of 2013 

ShARe/CLEF challenge were used as the 
training and development sets respectively for 
system development in SemEval 2014 Task 7. 
The training set consists of 199 notes and the 
development set has 99 notes, both of which 
were collected from four types of clinical notes 
including discharge summaries (DIS), radiology 
reports (RAD), and ECG/ECHO reports. Based 
on a pre-defined guideline, disorder entities were 
annotated for each note and then mapped to 
UMLS CUIs of SNOMED-CT concepts. 
Disorder entities not found in SNOMED-CT 
were marked as “CUI-less”. The training set 
contained 5811 disorder entities which were 
mapped to 1007 unique CUIs or CUI-less. The 
development set contained 5340 disorder entities 
mapped to 795 CUIs or CUI-less. The test set 
contained 133 notes, all of which were discharge 
summaries. As the gold-standard annotation of 
the test set is not released by the organizer, the 
detailed annotation information of the test set is 

not available. Table 1 shows the total counts of 
notes, entities and CUIs in the three datasets.  
 
Dataset Type Note Entity CUI CUI-

less 
Train ALL 199 5816 4177 1639 

ECHO 42 828 662 166 
RAD 42 555 392 163 
DIS 61 3589 2646 943 
ECG 54 193 103 90 

Dev ALL 99 5340 3619 1721 
ECHO 12 338 241 97 
RAD 12 162 126 36 
DIS 75 4840 3252 1588 
ECG 0 0 0  

Test ALL 133 - -  
DIS 133 - -  

 
Table 1. Statistics of the dataset.  

2.2 Disorder entity recognition 
The disorder entity recognition component 

consists of two modules: 1) the machine learning 
(e.g., CRF and SSVM) based named entity 
recognition (NER) module and 2) the   ensemble 
learning module. For the challenge of this year, 
we mainly focused on the second ensemble 
learning module. 

Machine learning based NER Module. This 
module was built based on our previous 
challenge participation in the 2013 ShARe/CLEF 
challenge (Tang et al., 2013). Annotated data 
were typically converted into a BIO format in 
machine learning-based NER systems. Each 
word was assigned one of the three labels: B for 
beginning of an entity, I for inside an entity, and 
O for outside of an entity. A unique challenge of 
this task is the high frequency (>10%) of disjoint 
disorders. For example, in the sentence “the left 
atrium is not moderately dilated”, the 
discontinuous phrase “left atrium…dilated” is 
defined as a disjoint disorder. Such entities could 
not be directly represented using the traditional 
BIO approach. Therefore, in addition to 
traditional BIO tags used for labeling words in 
the consecutive disorder entities, two sets of tags 
were created for disjoint entities: (1) D{B, I} was 
used to label disjoint entity words that are not 
shared by multiple concepts; and (2) H{B, I} was 
used to label head words that belonged to more 
than two disjoint concepts. Ultimately, we 
assigned one of the seven labels {B, I, O, DB, 
DI, HB, HI} to each word. A few simple rules 
were then defined to convert labeled words to 
entities (Tang et al., 2013).  

803



We exploited two state-of-the-art machine 
learning algorithms for disorder entity 
recognition, namely CRF (Lafferty et al., 2001) 
and SSVM (Tsochantaridis et al., 2005). 
CRFsuite and SVMhmm were used to implement 
CRF and SSVM respectively. 

For features, we used bag-of-word, part-of-
speech from Stanford tagger, type of notes, 
section information, word representation from 
Brown clustering (Brown et al., 1992), random 
indexing (Lund and Burgess, 1996) and semantic 
categories of words based on UMLS lookup, 
MetaMap, and cTAKES outputs. More detailed 
information of this module can be found in our 
paper for 2013 ShARe/CLEF challenge (Tang et 
al., 2013).  

One thing to note is that for word 
representation features like Brown clustering and 
random indexing, we only use the combination 
of traning and development and test datasets for 
feature extraction. The non-annotated corpus 
provided by the SemEval organizers was not 
employed currently. We do plan to pre-generate 
word clusters and random indexing using the 
provided corpus in the near future. 

Ensemble Learning Module. Three 
approaches were employed to consolidate the 
CRF-model, SSVM-model and the MetaMap 
outputs, namely machine learning classifier 
based ensemble (ensembleML), majortiy voting 
based ensemble (ensembleMV) and direct merging 
of the entity recognition results from the three 
models (ensembleDM). 

In the ensembleML approach, a binary classifier 
was trained to determine if the entities 
recognized by the CRF-model, SSVM-model and 
MetaMap were true positives. A new set of 
features were then extracted for each candidate 
entity, that included the specific models 
recognizing the entity, the entity itself, n-gram 
and word shape features of the first/last word of 
the entity. A sliding window based feature was 
extracted to check whether there was any 
recognized entity within 20 characters before the 
first and after the last word. Some features 
extracted from the first module were also 
employed. We used the open source toolkit 
Liblinear (Fan et al., 2008), to build the binary 
classifier for ensembleML. 

 

2.3 Disorder Entity Encoding 
We developed a Vector Space Model (VSM) 

based approach to find the most suitable CUI for 
a given disorder entity. The disorder entity was 

used as query and all the UMLS terms were 
treated as documents. We used the cosine-
similarity score to rank the candidate terms. For 
post-processing, if the top-ranked CUI was not a 
disorder CUI, it was replaced with ‘CUI-less’.  
‘CUI-less’ was also assigned to entities without 
any retrieved candidate CUI. 

2.4 Experiments and Evaluation 
Our system was developed and trained using 

the enlarged training set by merging the 199 
notes in the training set and the 99 notes in the 
development set. All parameters of CRF, SSVM 
and Liblinear were optimized by 10-fold cross-
validation on the enlarged training dataset. The 
performance of disorder entity recognition was 
evaluated by precision, recall and F-measure, 
which were measured in both “strict” and “re-
laxed” modes. The “strict” mode was defined as 
follows: a concept is correctly recognized if and 
only if it can be matched exactly to a disorder 
mention in the gold standard, and the “relaxed” 
mode means that a disorder mention is correctly 
recognized if it overlaps with any disorder men-
tion in the gold standard. For entity encoding, all 
participating systems were evaluated using accu-
racy, in “strict” and “relaxed” modes, as defined 
in (Suominen et al., 2013). 

3 Results 
Table 2 and Table 3 show the best performance 
of our systems in the SemEval 2014 Task 7 as 
reported by the organizers, where “P”, “R”, “F” 
denote precision, recall and F-measure 
respectively. For disorder entity recognition, the 
ensembleML based system outperformed the other 
two ensemble approaches, achieving the best F-
measure of 0.813 under “strict” criterion and was 
ranked first in the challenge. For encoding, our 
system achieved an accuracy of 0.741 by 
ensembleDM under “strict” criterion and was 
again ranked first in the challenge. 

 
 Strict Relaxed 

P R F P R F 
ensembleML 84.3 78.6 81.3 93.6 86.6 90.0 
Table 2. The disorder recognition performance 

of our system for the SemEval 2014 task 7 (%). 
 

 Accuracy 
Strict Relaxed 

ensembleDM 0.741 0.873 
Table 3. The SNOMED encoding performance 

of our system for the SemEval 2014 task 7. 
 

804



4 Discussion 
In this study, we developed an ensemble 
learning-based approach to recognize disorder 
entities and a vector space model-based method 
to encode disorders to UMLS CUIs.  Our system 
was top-ranked among all participating teams. 
However, there are still expectations for further 
improvement.  

For disorder entity recognition, directly 
merging the entity recognition results of the three 
models (ensembleDM) achieved the highest 
encoding accuracy of 0.741. This shows the great 
potential of performance enhancement by 
combining different models. However, the 
precision of ensembleDM was much lower than 
the current machine learning-based ensemble 
approach ensembleML. ensembleML improved the 
precision to 84.3%, with the lowest recall of 
78.6% among the three ensemble approaches. 
Further investigations for balancing and 
enhancing both precision and recall 
simultaneously by combining different models 
will be pursued in the follow-up studies. 

For encoding, when a disorder entity can be 
labelled with multiple CUIs in different contexts, 
a more effective disambiguation model could be 
exploited. Further, query expansion techniques 
may be helpful and worth investigating. The 
above methods should be potentially helpful to 
address the problems caused by synonyms or 
spelling variants.  

5 Conclusion 
We developed a clinical disorder recognition and 
encoding system that consists of a ensemble 
learning-based approach to recognize disorder 
entities and a vector space model-based method 
to encode the identified disorders to UMLS CUIs 
of SNOMED-CT concepts. The performance of 
our system was top-ranked in the SemEval 2014 
Task 7, indicating that our approaches are 
promising. However, further improvements are 
needed in order to enhance performance on 
concept extraction and encoding in clinical text. 

Acknowledgments 

This study is supported in part by grants from 
NLM R01LM010681, NCI 1R01CA141307, 
NIGMS 1R01GM102282 and CPRIT R1307 
(H.X).  
 
 

Reference 
Aronson, A. R., & Lang, F.-M. (2010). An overview 

of MetaMap: historical perspective and recent 
advances. Journal of the American Medical 
Informatics Association: JAMIA, 17(3), 229–236.  

Bodenreider, O. (2004). The unified medical language 
system (UMLS): integrating biomedical 
terminology. Nucleic Acids Research, 32(suppl 1), 
267–270. 

Brown, P. F., deSouza, P. V., Mercer, R. L., Pietra, V. 
J. D., & Lai, J. C. (1992). Class-Based n-gram 
Models of Natural Language. Computational 
Linguistics, 18, 467–479. 

Denny, J. C., Irani, P. R., Wehbe, F. H., Smithers, J. 
D., & Spickard, A. (2003). The KnowledgeMap 
Project: Development of a Concept-Based Medical 
School Curriculum Database. AMIA Annual 
Symposium Proceedings, 2003, 195–199. 

Fan, R.-E., Chang, K.-W., Hsieh, C.-J., Wang, X.-R., 
& Lin, C.-J. (2008). LIBLINEAR: A library for 
large linear classification. The Journal of Machine 
Learning Research, 9, 1871–1874. 

Friedman, C., Alderson, P. O., Austin, J. H., Cimino, 
J. J., & Johnson, S. B. (1994). A general natural-
language text processor for clinical radiology. 
Journal of the American Medical Informatics 
Association, 1(2), 161–174. 

Lafferty, J., McCallum, A., & Pereira, F. C. N. 
(2001). Conditional Random Fields: Probabilistic 
Models for Segmenting and Labeling Sequence 
Data. Departmental Papers (CIS).  

Lund, K., & Burgess, C. (1996). Producing high-
dimensional semantic spaces from lexical co-
occurrence. Behavior Research Methods, 
Instruments, & Computers, 28(2), 203–208.  

Savova, G. K., Masanz, J. J., Ogren, P. V., Zheng, J., 
Sohn, S., Kipper-Schuler, K. C., & Chute, C. G. 
(2010). Mayo clinical Text Analysis and 
Knowledge Extraction System (cTAKES): 
architecture, component evaluation and 
applications. Journal of the American Medical 
Informatics Association: JAMIA, 17(5), 507–513.  

Suominen, H., SalanterÃ, S., Velupillai, S., Chapman, 
W. W., Savova, G., & Elhadad, N. (2013). 
Overview of the ShARe/CLEF eHealth Evaluation 
Lab 2013. Information Access Evaluation. 
Multilinguality, Multimodality, and Visualization, 
2013, 212–231. 

Tang, B., Cao, H., Wu, Y., Jiang, M., & Xu, H. 
(2013). Recognizing and Encoding Discorder 
Concepts in Clinical Text using Machine Learning 
and Vector Space Model. Workshop of 
ShARe/CLEF eHealth Evaluation Lab 2013.  

805



Tsochantaridis, I., Joachims, T., Hofmann, T., & 
Altun, Y. (2005). Large margin methods for 
structured and interdependent output variables. 
Journal of Machine Learning Research, 6, 1453–
1484. 

Uzuner, Ã., Solti, I., & Cadag, E. (2010). Extracting 
medication information from clinical text. Journal 
of the American Medical Informatics Association, 
17(5), 514–518.  

Uzuner, Ã., South, B. R., Shen, S., & DuVall, S. L. 
(2011). 2010 i2b2/VA challenge on concepts, 
assertions, and relations in clinical text. Journal of 
the American Medical Informatics Association: 
JAMIA, 18(5), 552–556.  

 

 

806


