



















































Probabilistic Sense Sentiment Similarity through Hidden Emotions


Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 983–992,
Sofia, Bulgaria, August 4-9 2013. c©2013 Association for Computational Linguistics

Probabilistic Sense Sentiment Similarity through Hidden Emotions 

 

 

Mitra Mohtarami
1
, Man Lan

2
, and Chew Lim Tan

1
 

1
Department of Computer Science, National University of Singapore; 

2Department of Computer Science, East China Normal University 

{mitra,tancl}@comp.nus.edu.sg;mlan@cs.ecnu.edu.cn 

 

  

 

Abstract 

Sentiment Similarity of word pairs reflects the 

distance between the words regarding their 

underlying sentiments. This paper aims to in-

fer the sentiment similarity between word 

pairs with respect to their senses. To achieve 

this aim, we propose a probabilistic emotion-
based approach that is built on a hidden emo-

tional model. The model aims to predict a vec-

tor of basic human emotions for each sense of 

the words. The resultant emotional vectors are 

then employed to infer the sentiment similarity 

of word pairs. We apply the proposed ap-

proach to address two main NLP tasks, name-

ly, Indirect yes/no Question Answer Pairs in-

ference and Sentiment Orientation prediction. 

Extensive experiments demonstrate the effec-

tiveness of the proposed approach. 

1 Introduction 

Sentiment similarity reflects the distance be-

tween words based on their underlying senti-

ments. Semantic similarity measures such as La-
tent Semantic Analysis (LSA) (Landauer et al., 

1998) can effectively capture the similarity be-

tween semantically related words like "car" and 

"automobile", but they are less effective in relat-

ing words with similar sentiment orientation like 

"excellent" and "superior". For example, the fol-

lowing relations show the semantic similarity 

between some sentiment words computed by 

LSA: 

 

��:	���	�	
�	��	�, ���	����� = 0.40		 
< ���	�	
�	��	�, ����� = 0.46	 

< 	���	�����, � �� = 0.65 
Clearly, the sentiment similarity between the 

above words should be in the reversed order. In 

fact, the sentiment intensity in "excellent" is 

closer to "superior" than "good". Furthermore, 

sentiment similarity between "good" and "bad" 

should be 0. 

In this paper, we propose a probabilistic ap-

proach to detect the sentiment similarity of 

words regarding their senses and underlying sen-

timents. For this purpose, we propose to model 

the hidden emotions of word senses. We show 

that our approach effectively outperforms the 

semantic similarity measures in two NLP tasks: 

Indirect yes/no Question Answer Pairs (IQAPs) 

Inference and Sentiment Orientation (SO) pre-

diction that are described as follows: 

In IQAPs, answers do not explicitly contain 

the yes or no keywords, but rather provide con-
text information to infer the yes or no answer 

(e.g. Q: Was she the best one on that old show? 

A: She was simply funny). Clearly, the sentiment 

words in IQAPs are the pivots to infer the yes or 

no answers. We show that sentiment similarity 

between such words (e.g., here the adjectives 

best and Funny) can be used effectively to infer 

the answers. 

The second application (SO prediction) aims to 

determine the sentiment orientation of individual 

words. Previous research utilized the semantic 

relations between words obtained from WordNet 

(Hassan and Radev, 2010) and semantic similari-

ty measures (e.g. Turney and Littman, 2003) for 

this purpose. In this paper, we show that senti-

ment similarity between word pairs can be effec-

tively utilized to compute SO of words.  

The contributions of this paper are follows: 

• We propose an effective approach to predict 

the sentiment similarity between word pairs 

through hidden emotions at the sense level,  

• We show the utility of sentiment similarity 

prediction in IQAP inference and SO predic-

tion tasks, and 

• Our hidden emotional model can infer the type 

and number of hidden emotions in a corpus. 

983



2 Sentiment Similarity through Hidden 
Emotions 

As we discussed above, semantic similarity 
measures are less effective to infer sentiment 

similarity between word pairs. In addition, dif-

ferent senses of sentiment words carry different 

human emotions. In fact, a sentiment word can 

be represented as a vector of emotions with in-

tensity values from "very weak" to "very strong". 

For example, Table 1 shows several sentiment 

words and their corresponding emotion vectors 

based the following set of emotions: e = [anger, 

disgust, sadness, fear, guilt, interest, joy, shame, 

surprise]. For example, "deceive" has 0.4 and 0.5 

intensity values with respect to the emotions 

"disgust" and "sadness" with an overall -0.9 (i.e. 

-0.4-0.5) value for sentiment orientation 

(Neviarouskaya et al., 2007; Neviarouskaya et 

al., 2009).  

Word Emotional Vector SO 
e = [anger, disgust, sadness, fear, guilt, interest, joy, shame, surprise] 

Rude ['0.2', '0.4',0,0,0,0,0,0,0] -0.6 

doleful [0, 0, '0.4',0,0,0,0,0,0] -0.4 

smashed [0,0, '0.8', '0.6',0,0,0,0,0] -1.4 

shamefully [0,0,0,0,0,0,0, '0.7',0] -0.7 

deceive [0, '0.4', '0.5',0,0,0,0,0,0] -0.9 
Table  1. Sample of emotional vectors  

 

The difficulty of the sentiment similarity predic-
tion task is evident when terms carry different 

types of emotions. For instance, all the words in 

Table 1 have negative sentiment orientation, but, 

they carry different emotions with different emo-

tion vectors. For example, "rude" reflects the 

emotions "anger" and "disgust", while the word 

"doleful" only reflects the emotion "sadness". As 

such, the word "doleful" is closer to the words 

"smashed" and "deceive" involving the emotion 

"sadness" than others. We show that emotion 

vectors of the words can be effectively utilized to 

predict the sentiment similarity between them. 

Previous research shows little agreement about 

the number and types of the basic emotions 

(Ortony and Turner 1990; Izard 1971). Thus, we 

assume that the number and types of basic emo-

tions are hidden and not pre-defined and propose 
a Probabilistic Sense Sentiment Similarity 

(PSSS) approach to extract the hidden emotions 

of word senses to infer their sentiment similarity.  

3 Hidden Emotional Model  

Online review portals provide rating mechanisms 

(in terms of stars, e.g. 5- or 10-star rating) to al- 

 

Figure 1.The structure of PSSS model 

 

low users to attach ratings to their reviews. A 

rating indicates the summarized opinion of a user 

who ranks a product or service based on his feel-

ings. There are various feelings and emotions 

behind such ratings with respect to the content of 

the reviews.  

Figure 1 shows the intermediate layer of hid-
den emotions behind the ratings (sentiments) 

assigned to the documents (reviews) containing 

the words. This Figure indicates the general 

structure of our PSSS model. It shows that hid-

den emotions (ei) link the rating (rj) and the doc-

uments (dk). In this Section, we aim to employ 

ratings and the relations among ratings, docu-

ments, and words to extract the hidden emotions.  

Figure 2 illustrates a simple graphical model 

using plate representation of Figure 1. As Figures 

2 shows, the rating r from a set of ratings R= 

{r1,…,rp} is assigned to a hidden emotion set 

E={e1,…,ek}. A document d from a set of docu-

ments D= {d1,…,dN} with vocabulary set W= 

{w1,…,wM} is associated with the hidden emotion 

set.  

 

 

 

 

 

 

 

 
 

 
 

 

The model presented in Figure 2(a) has been 

explored in (Mohtarami et al., 2013) and is called 

Series Hidden Emotional Model (SHEM). This 

representation assumes that the word w is de-

pendent to d and independent to e (we refer to 

this Assumption as A1). However, in reality, a 

word w can inherit properties (e.g., emotions) 

(b): Bridged model 

Figure 1. The structure of PSSS model 

(a): Series model 

Figure 2. Hidden emotional model 

984



from the document d that contains w. Thus, we 

can assume that w is implicitly dependant on e. 

To account for this, we present Bridged Hidden 

Emotional Model (BHEM) shown in Figure 2(b). 

Our assumption, A2, in the BHEM model is as 

follows: w is dependent to both d and e.  

Considering Figure 1, we represent the entire 

text collection as a set of (w,d,r) in which each 

observation (w,d,r) is associated with a set of 

unobserved emotions. If we assume that the ob-

served tuples are independently generated, the 

whole data set is generated based on the joint 

probability of the observation tuples (w,d,r) as 

the follows (Mohtarami et al., 2013): 

" =	###$�%, �, ��&�',(,)�																																						
'()

 

=	###$�%, �, ��&�',(�&�(,)� 									�1�
'()

 

where, P(w,d,r) is the joint probability of the tu-

ple (w,d,r), and n(w,d,r) is the frequency of w in 

document d of rating r (note that n(w,d) is the 

term frequency of w in d and n(d,r) is one if r is 

assigned to d, and 0 otherwise). The joint proba-

bility for the BHEM is defined as follows con-

sidering hidden emotion e: 

- regarding class probability of the hidden emotion e 
to be assigned to the observation (w,d,r): 

	$�%, �, �� = 	+$�%, �, �|	�$�	�
-

= 

	=	+$�%, �|	�$��|	�$�	�
-

 

- regarding assumption A2 and Bayes' Rule: 

=	+$�%|�, 	�$��, 	�$��|	�
-

 

- using Bayes' Rule: 

=	+$��, 	|%�$�%�$��|	�
-

 

- regarding A2 and conditional independency: 

		=	+$��|%�$�	|%�$�%�$��|	�
-

 

		= $��|%�+$�%|	�$�	�$��|	�																																						�2�
-

 

In the bridged model, the joint probability does 
not depend on the probability P(d|e) and the 

probabilities P(w|e), P(e) and P(r|e) are un-

known, while in the SHEM model explained in 

(Mohtarami et al., 2013), the joint probability 

does not depend on P(w|e), and probabilities 

P(d|e), P(e), and P(r|e) are unknown.  

We employ Maximum Likelihood approach to 

learn the probabilities and infer the possible hid-

den emotions. The log-likelihood of the whole 

data set D in Equation (1) can be defined as fol-

lows: 
 

� = 	+++�%, ����, ��log$�%, �, ��														�3�
'()

 

Replacing P(w,d,r) by the values computed us-

ing the bridged model in Equation (2) results in: 
�
= 	+++�%, ����, ��log[$��|%�+$�%|	�$�	�$��|	�

-
]

'()
 

										�4� 
The above optimization problems are hard to 

compute due to the log of sum. Thus, Expecta-

tion-maximization (EM) is usually employed. 

EM consists of two following steps: 

1. E-step: Calculates posterior probabilities for 
hidden emotions given the words, documents 
and ratings, and 

2. M-step: Updates unknown probabilities (such 
as P(w|e) etc) using the posterior probabilities 

in the E-step. 

The steps of EM can be computed for BHEM 

model. EM of the model employs assumptions 

A2 and Bayes Rule and is defined as follows: 
E-step: 

$�	|%, �, �� = $��|	�$�	�$�%|	�∑ $��|	�$�	�$�%|	�- 																												�5� 
M-step: 

$��|	� = ∑ ∑ �%, ����, ��$�e|%, �, ��'(∑ ∑ ∑ �%, ����, �� $�e|%, �, ��'()  

														=	 ∑ �%, ��$�e|%, �, ��'∑ ∑ �%, ��$�e|%, �, ��') 																														�6� 

$�%|	� = ∑ ∑ �%, ����, ��$�e|%, �, ��()∑ ∑ ∑ �%, ����, ��$�e|%, �, ��()' 	 

															=	 ∑ �%, ��$�e|%, �, ��)∑ ∑ �%, ��$�e|%, �, ��)' 																													�7� 

$�	� = ∑ ∑ ∑ �%, ����, ��$�e|%, �, ��'()∑ ∑ ∑ ∑ �%,����, ��$�e|%, �, ��')(8  

									= 	 ∑ ∑ �%, �� $�e|%, �, ��')∑ ∑ ∑ �%, �� $�e|%, �, ��')8 																								�8� 

Note that in Equation (5), the probability 

P(e|w,d,r) does not depend on the document d. 

Also, in Equations (6)-(8) we remove the de-

pendency on document d using the following 

Equation: 

+�%, ����, �� =�%, ��
(

																					�9� 

where n(w,r) is the occurrence of w in all the 

documents in the rating r. 

The EM steps computed by the bridged model 

do not depend on the variable document d, and 

discard d from the model. The reason is that w 

bypasses d to directly associate with the hidden 

emotion e in Figure 2(b). 

985



  Similar to BHEM, the EM steps for SHEM can 

be computed by considering assumptions A1 and 

Bayes Rule as follows (Mohtarami et al., 2013): 

E-step: 

$�	|%, �, �� = $��|	�$�	�$��|	�∑ $��|	�$�	�$��|	�- 																											�10� 
M-step: 

$��|	� = ∑ ∑ �%, ����, ��$�e|%, �, ��'(∑ ∑ ∑ �%, ����, �� $�e|%, �, ��'() 										�11� 

$��|	� = ∑ ∑ �%, ����, ��$�e|%, �, ��')∑ ∑ ∑ �%, ����, �� $�e|%, �, ��')( 										�12� 

$�	� = ∑ ∑ ∑ �%, ����, �� $�e|%, �, ��'()∑ ∑ ∑ ∑ �%, ����, ��$�e|%, �, ��')(8 							�13� 
 

Finally, we construct the emotional vectors us-

ing the algorithm presented in Table 2. The algo-

rithm employs document-rating, term-document 

and term-rating matrices to infer the unknown 

probabilities. This algorithm can be used with 

both bridged or series models. Our goal is to in-

fer the emotional vector for each word w that can 

be obtained by the probability P(w|e). Note that, 

this probability can be simply computed for the 

SHEM model using P(d|e) as follows: 

$�%|	� =+$�%|��$��|	�
(

																						�14� 

3.1 Enriching Hidden Emotional Models 

We enrich our emotional model by employing 

the requirement that the emotional vectors of two 

synonym words w1 and w2 should be similar. For 

this purpose, we utilize the semantic similarity 

between each two words and create an enriched 

matrix. Equation (15) shows how we compute 

this matrix. To compute the semantic similarity 

between word senses, we utilize their synsets as 

follows: 

 

%;%< = $=�>�%;�|�>�%<�? 

	= 1|�>�%;�|	 +
1

|�>�%<�| + $=%;|%<?
|@A&�'B�|

C

|@A&�'D�|

E
				�15� 

where, syn(w) is the synset of w. Let count(wi, 

wj) be the co-occurrence of the wi and wj, and let 

count(wj) be the total word count. The probabil-

ity of wi given wj will then be P(wi|wj) = 

count(wi, wj)/ count(wj). In addition, note that 

employing the synset of the words help to obtain 

different emotional vectors for each sense of a 

word.  

The resultant enriched matrix W×W is multi-
plied to the inputs of our hidden model (matrices 

W×D	or	W×R�. Note that this takes into account  

Input: 
Series Model: Document-Rate D×R, Term-Document 

W×D 
Bridged Model: Term-Rate W×R 

Output: Emotional vectors {e1, e2, …,ek} for w 

Algorithm: 

1. Enriching hidden emotional model: 

Series Model: Update Term-Document W×D 

Bridged Model: Update Term-Rate W×R 

2. Initialize unknown probabilities:  

Series Model: Initialize P(d|e), P(r|e), and P(e), ran-
domly 

Bridged Model: Initialize P(w|e), P(r|e), and P(e) 

3. while L  has not converged to a pre-specified value do 
4. E-step;  

Series Model: estimate the value of P(e|w,d,r) in 

Equation 10  
Bridged Model: estimate the value of P(e|w,d,r) in 

Equation 5 

5. M-step;  

Series Model: estimate the values of P(r|e), P(d|e), 

and P(e) in Equations 11-13, respectively 
Bridged Model: estimate the values of P(r|e), P(w|e), 

and P(e) in Equations 6-8, respectively 

6. end while 

7. If series hidden emotional model is used then 

8.  Infer word emotional vector: estimate P(w|e) in 

Equation 14.  

9. End if 

Table  2. Constructing emotional vectors via P(w|e)  

the senses of the words as well. The learning step 

of EM is done using the updated inputs. In this 

case, the correlated words can inherit the proper-

ties of each other. For example, if wi does not 

occur in a document or rating involving another 

word (i.e., wj), the word wi can still be indirectly 

associated with the document or rating through 

the word wj. However, the distribution of the 

opinion words in documents and ratings is not 

uniform. This may decrease the effectiveness of 

the enriched matrix.  

The nonuniform distribution of opinion words 

has been also reported by Amiri et al. (2012) 

who showed that the positive words are frequent-

ly used in negative reviews. We also observed 

the same pattern in the development dataset. Fig-

ure 3 shows the overall occurrence of some posi-

tive and negative seeds in various ratings. As 

shown, in spite of the negative words, the posi-

tive words may frequently occur in both positive 

and negative documents. Such distribution of  

986



 

Figure 3. Nonuniform distribution of opinion words 

positive words can mislead the enriched model. 

To address this issue, we measure the confi-

dence of an opinion word in the enriched matrix 

as follows.  

K�L��	�	' =
�M�[�NO'P ×"O'P� − �NO'R × "O'R�]

�NO'P ×"O'P� + �NO'R ×"O'R�  
�16� 

where, NO'P (NO'R) is the frequency of w in the 
ratings 1 to 4 (7 to 10), and "O'P ("O'R) is the 
total number of documents with rating 1 to 4 (7 

to 10) that contain w. The confidence value of w 
varies from 0 to 1, and it increases if: 

• There is a large difference between the occur-

rences of w in positive and negative ratings. 

• There is a large number of reviews involving 

w in the relative ratings. 

   To improve the efficiency of enriched matrix, 

the columns corresponding to each word in the 

matrix are multiplied by its confidence value.        

4 Predicting Sentiment Similarity 

We utilize the approach proposed in (Mohtarami 

et al., 2013) to compute the sentiment similarity 

between two words. This approach compares the 

emotional vector of the given words. Let X and Y 
be the emotional vectors of two words. Equation 

(17) computes their correlation: 

�����V, W� = ∑ �V; − VX��W; − WX�
&;YZ

�− 1��[�\ 																																�17� 
where,  is number of emotional categories, V,] WX 
and �[ , �\  are the mean and standard deviation 
values of ^  and _  respectively. �����V, W� = −1 
indicates that the two vectors are completely dis-
similar, and �����V, W� = 1 indicates that the vec-
tors have perfect similarity.  

The approach makes use of a thresholding 
mechanism to estimate the proper correlation 
value to find sentimentally similar words. For 
this, as in Mohtarami et al. (2013) we utilized the 
antonyms of the words. We consider two words,  

Input: 

��`: The adjective in the question of given IQAP. 
���: The adjective in the answer of given IQAP. 
Output: answer ∈ {>	�, �, ��	�� �} 
Algorithm: 

1. if ��` or ��� are missing from our corpus then 
2.       answer=Uncertain; 
3. else if  �����`, ���� < 0 then 
4.             answer=No;  
5.        else if �����`, ���� > 0 then 
6.                   answer=yes; 

Figure 4. Sentiment similarity for IQAP inference 

%; and %< as similar in sentiment iff they satisfy 
both of the following conditions: 

1. ����=%; ,%<? > ����=%;,~%<?, � 
2. ����=%; ,%<? > ����=~%;,%<? 

where, ~%;  is antonym of %; , and ����=%; , %<? 
is obtained from Equation (17). Finally, we com-
pute the sentiment similarity (SS) as follows: 

��=%; ,%<? = 
����=%; ,%<? −f 
g����=%; ,~%<?, ����=~%;,%<?h			�18� 

Equation (18) enforces two sentimentally simi-
lar words to have weak correlation to the anto-
nym of each others. A positive value of SS(.,.) 
indicates the words are sentimentally similar and 
a negative value shows that they are dissimilar.  

5 Applications 

We explain our approach in utilizing sentiment 

similarity between words to perform IQAP infer-

ence and SO prediction tasks respectively.  

In IQAPs, we employ the sentiment similarity 

between the adjectives in questions and answers 

to interpret the indirect answers. Figure 4 shows 

the algorithm for this purpose. SS(.,.) indicates 

sentiment similarity computed by Equation (18). 

A positive SS means the words are sentimentally 

similar and thus the answer is yes. However, 

negative SS leads to a no response. 

In SO-prediction task, we aim to compute 
more accurate SO using our sentiment similarity 

method. Turney and Littman (2003) proposed a 

method in which the SO of a word is calculated 

based on its semantic similarity with seven posi-

tive words minus its similarity with seven nega-

tive words as shown in Figure 5. As the similari-
ty function, A(.,.), they employed point-wise mu-

tual information (PMI) to compute the similarity 

between the words. Here, we utilize the same 

approach, but instead of PMI we use our SS(.,.) 

measure as the similarity function. 

987



Input: 

$%����: seven words with positive SO 
i%����: seven words with negative SO 
��. , . �: similarity function, and %: a given word with 
unknown SO 

Output: sentiment orientation of w  

Algorithm: 

1. $ = �j_��%� = 
+ ��%, �%����−	 + ��%, %����

&'l)(m	n'l)(@o'l)(m	p'l)(@
 

Figure 5. SO based on the similarity function A(.,.) 

6 Evaluation and Results 

6.1 Data and Settings 

We used the review dataset employed by Maas et 
al. (2011) as the development dataset that con-
tains movie reviews with star rating from one 
star (most negative) to 10 stars (most positive). 
We exclude the ratings 5 and 6 that are more 
neutral. We used this dataset to compute all the 
input matrices in Table 2 as well as the enriched 
matrix. The development dataset contains 50k 
movie reviews and 90k vocabulary.  

We also used two datasets for the evaluation 
purpose: the MPQA (Wilson et al., 2005) and 
IQAPs (Marneffe et al., 2010) datasets. The 
MPQA dataset is used for SO prediction experi-
ments, while the IQAP dataset is used for the 
IQAP experiments. We ignored the neutral 
words in MPQA dataset and used the remaining 
4k opinion words. Also, the IQAPs dataset 
(Marneffe et al., 2010) contains 125 IQAPs and 
their corresponding yes or no labels as the 
ground truth. 

6.2 Experimental Results 

To evaluate our PSSS model, we perform exper-

iments on the SO prediction and IQAPs infer-
ence tasks. Here, we consider six emotions for 

both bridged and series models. We study the 

effect of emotion numbers in Section 7.1. Also, 

we set a threshold of 0.3 for the confidence value 

in Equation (16), i.e. we set the confidence val-

ues smaller than the threshold to 0. We explain 
the effect of this parameter in Section 7.3. 

Evaluation of SO Prediction 

We evaluate the performance of our PSSS mod-

els in the SO prediction task using the algorithm 

explained in Figure 5 by setting our PSSS as 

similarity function (A). The results on SO predic-

tion are presented in Table 3. The first and se- 

Method Precision Recall F1 

PMI 56.20 56.36 55.01 

ER 65.68 65.68 63.27 

PSSS-SHEM 68.51 69.19 67.96 

PSSS-BHEM 69.39 70.07 68.68 

Table 3. Performance on SO prediction task 

cond rows present the results of our baselines, 

PMI (Turney and Littman, 2003) and Expected 

Rating (ER) (Potts, 2011) of words respectively.  

PMI extracts the semantic similarity between 

words using their co-occurrences. As Table 3 

shows, it leads to poor performance. This is 

mainly due to the relatively small size of the de-

velopment dataset which affects the quality of 

the co-occurrence information used by the PMI.  

ER computes the expected rating of a word 

based on the distribution of the word across rat-

ing categories. The value of ER indicates the SO 

of the word. As shown in the two last rows of the 

table, the results of PSSS approach are higher 

than PMI and ER. The reason is that PSSS is 

based on the combination between sentiment 

space (through using ratings, and matrices W×R 

in BHEM, D×R in SHEM) and semantic space 

(through the input W×D in SHEM and enriched 

matrix W×W in both hidden models). However, 

the PMI employs only the semantic space (i.e., 

the co-occurrence of the words) and ER uses oc-

currence of the words in rating categories. 

Furthermore, the PSSS model achieves higher 

performance with BHEM rather than SHEM. 

This is because the emotional vectors of the 

words are directly computed from the EM steps 
of BHEM. However, the emotional vectors of 

SHEM are computed after finishing the EM steps 

using Equation (14). This causes the SHEM 

model to estimate the number and type of the 

hidden emotions with a lower performance as 

compared to BHEM, although the performances 

of SHEM and BHEM are comparable as ex-

plained in Section 7.1.  

Evaluation of IQAPs Inference  

To apply our PSSS on IQAPs inference task, we 

use it as the sentiment similarity measure in the 

algorithm explained in Figure 4. The results are 

presented in Table 4. The first and second rows 

are baselines. The first row is the result obtained 

by Marneffe et al. (2010) approach. This ap-

proach is based on the similarity between the SO 

of the adjectives in question and answer. The 

second row of Table 4 show the results of using a 

popular semantic similarity measure, PMI, as the 

sentiment similarity (SS) measure in Figure 4.  

988



Method Prec. Rec. F1 

Marneffe et al. (2010) 60.00 60.00 60.00 

PMI 60.61 58.70 59.64 

PSSS-SHEM  62.55 61.75 61.71 

PSSS-BHEM (w/o WSD) 65.90 66.11 63.74 

SS-BHEM (with WSD) 66.95 67.15 65.66 

Table 4. Performance on IQAP inference task 

The result shows that PMI is less effective to 

capture the sentiment similarity. 

Our PSSS approach directly infers yes or no 

responses using SS between the adjectives and 

does not require computing SO of the adjectives. 

In Table 4, PSSS-SHEM and PSSS-BHEM indi-

cate the results when we use our PSSS with 

SHEM and BHEM respectively. Table 4 shows 

the effectiveness of our sentiment similarity 

measure. Both models improve the performance 

over the baselines, while the bridged model leads 

to higher performance than the series model. 

Furthermore, we employ Word Sense Disam-

biguation (WSD) to disambiguate the adjectives 

in the question and its corresponding answer. For 
example, Q: … Is that true? A: This is extraor-

dinary and preposterous. In the answer, the cor-

rect sense of the extraordinary is unusual and as 

such answer no can be correctly inferred. In the 

table, (w/o WSD) is based on the first sense (most 

common sense) of the words, whereas (with 

WSD) utilizes the real sense of the words. As 

Table 4 shows, WSD increases the performance. 

WSD could have higher effect, if more IQAPs 

contain adjectives with senses different from the 

first sense. 

7 Analysis and Discussions 

7.1 Number and Types of Emotions   

In our PSSS approach, there is no limitation on 

the number and types of emotions as we assumed 

emotions are hidden. In this Section, we perform 

experiments to predict the number and type of 

hidden emotions.  

Figure 6 and 7 show the results of the hidden 

models (SHEM and BHEM) on SO prediction 

and IQAPs inference tasks respectively with dif-

ferent number of emotions. As the Figures show, 

in both tasks, SHEM achieved high performanc-
es with 11 emotions. However, BHEM achieved 

high performances with six emotions. Now, the 

question is which emotion number should be 

considered? To answer this question, we further 

study the results as follows.  

First, for SHEM, there is no significant differ-
ence between the performances with six and 11 

emotions in the SO prediction task. This is the  

 
Figure 6. Performance of BHEM and SHEM on SO 

prediction through different #of emotions 

 

 
Figure 7. Performance of BHEM and SHEM on 

IQAPs inference through different #of emotions 

same for BHEM. Also, the performances of 

SHEM on the IQAP inference task with six and 

11 emotions are comparable. However, there is a 

significant difference between the performances 

of BHEM in six and 11 emotions. So, we consid-

er the dimension in which both hidden emotional 

models present a reasonable performance over 
both tasks. This dimension is six here. 

Second, as shown in the Figures 6 and 7, in 

contrast to BHEM, the performance of SHEM 

does not considerably change with different 

number of emotions over both tasks. This is be-

cause, in SHEM, the emotional vectors of the 

words are derived from the emotional vectors of 

the documents after the EM steps, see Equation 

(14). However, in BHEM, the emotional vectors 

are directly obtained from the EM steps. Thus, 

the bridged model is more sensitive than series 

model to the number of emotions. This could 

indicate that the bridged model is more accurate 

than the series model to estimate the number of 

emotions. 

Therefore, based on the above discussion, the 

estimated number of emotions is six in our de-

velopment dataset. This number may vary using 

different development datasets. 

In addition to the number of emotions, their 

types can also be interpreted using our approach. 

To achieve this aim, we sort the words based on 

their probability values, P(w|e), with respect to  

989



 
Figure 8. Effect of synonyms & antonyms in SO pre-

diction task with different emotion numbers in BHEM 

Emotion#1 Emotion#2 Emotion#3 

excellent (1) 
magnificently(1) 

blessed (1) 
sublime (1) 

affirmation (1) 
tremendous (2) 

unimpressive (1) 
humorlessly (1) 

paltry (1) 
humiliating (1) 

uncreative (1) 
lackluster (1) 

disreputable (1) 
villian (1) 

onslaught (1) 
ugly (1) 

old (1) 
disrupt (1) 

Table 5. Sample words in three emotions 

each emotion. Then, the type of the emotions can 

be interpreted by observing the top k words in 

each emotion. For example, Table 5 shows the 

top 6 words for three out of six emotions ob-

tained for BHEM. The numbers in parentheses 

show the sense of the words. The corresponding 

emotions for these categories can be interpreted 

as "wonderful", "boring" and "disreputable", re-

spectively.  

We also observed that, in SHEM with eleven 

emotion numbers, some of the emotion catego-

ries have similar top k words such that they can 

be merged to represent the same emotion. Thus, 

it indicates that the BHEM is better than SHEM 

to estimates the number of emotions than SHEM. 

7.2 Effect of Synsets and Antonyms  

We show the important effect of synsets and an-

tonyms in computing the sentiment similarity of 

words. For this purpose, we repeat the experi-

ment for SO prediction by computing sentiment 

similarity of word pairs with and without using 

synonyms and antonyms. Figure 8 shows the 

results of obtained from BHEM. As the Figure 

shown, the highest performance can be achieved 

when synonyms and antonyms are used, while 

the lowest performance is obtained without using 

them. Note that, when the synonyms are not 

used, the entries of enriched matrix are computed 

using P(wi|wj) instead of P(syn(wi)|syn(wj)) in the 

Equation (15). Also, when the antonyms are not 

used, the Max(,) in Equation (18) is 0 and SS is 

computed using only correlation between words.  

The results show that synonyms can improve 

the performance. As Figure 8 shows, the two  

 
Figure 9. Effect of confidence values in SO prediction 

with different emotion numbers in BHEM 

highest performances are obtained when we use 

synonyms and the two lowest performances are 

achieved when we don't use synonyms. This is 

indicates that the synsets of the words can im-

prove the quality of the enriched matrix. The re-

sults also show that the antonyms can improve 

the result (compare WOSynWAnt with 

WOSynWOAnt). However, synonyms lead to 

greater improvement than antonyms (compare 

WSynWOAnt with WOSynWAnt). 

7.3 Effect of Confidence Value 

In Section 3.1, we defined a confidence value for 

each word to improve the quality of the enriched 

matrix. To illustrate the utility of the confidence 

value, we repeat the experiment for SO predic-

tion by BHEM using all the words appears in 
enriched matrix with different confidence 

thresholds. The results are shown in Figure 9, 

"w/o confidence" shows the results when we 

don’t use the confidence values, while "with con-

fidence" shows the results when use the confi-

dence values. Also, "confidence>x" indicates the 
results when we set all the confidence value 

smaller than x to 0. The thresholding helps to 

eliminate the effect of low confident words.  

As Figure 9 shows, "w/o confidence" leads to 

the lowest performance, while "with confidence" 

improves the performance with different number 

of emotions. The thresholding is also effective. 

For example, a threshold like 0.3 or 0.4 improves 

the performance. However, if a large value (e.g., 

0.6) is selected as threshold, the performance 

decreases. This is because a large threshold fil-

ters a large number of words from enriched mod-

el that decreases the effect of the enriched ma-

trix.        

7.4 Convergence Analysis 

The PSSS approach is based on the EM algo-

rithm for the BHEM (or SHEM) presented in 

Table 2. This algorithm performs a predefined 

990



number of iterations or until convergence. To 

study the convergence of the algorithm, we re-

peat our experiments for SO prediction and 

IQAPs inference tasks using BHEM with differ-

ent number of iterations. Figure 10 shows that 

after the first 15 iterations the performance does 

not change dramatically and is nearly constant 

when more than 30 iterations are performed. This 

shows that our algorithm will converge in less 

than 30 iterations for BHEM. We observed the 

same pattern in SHEM. 

7.5 Bridged Vs. Series Model  

The bridged and series models are both based on 

the hidden emotions that were developed to pre-

dict the sense sentiment similarity. Although 

their best results on the SO prediction and IQAPs 

inference tasks are comparable, they have some 

significant differences as follows: 

• BHEM is considerably faster than SHEM. The 
reason is that, the input matrix of BHEM (i.e., 

W×R) is significantly smaller than the input 

matrix of SHEM (i.e., W×D). 

•  In BHEM, the emotional vectors are directly 
computed from the EM steps. However, the 

emotional vector of a word in SHEM is com-
puted using the emotional vectors of the doc-

uments containing the word. This adds noises 

to the emotional vectors of the words.  

• BHEM gives more accurate estimation over 
type and number of emotions versus SHEM. 

The reason is explained in Section 7.1. 

8 Related Works 

Sentiment similarity has not received enough 

attention to date. Most previous works employed 

semantic similarity of word pairs to address SO 

prediction and IQAP inference tasks. Turney and 

Littman (2003) proposed to compute pair-wised 

mutual information (PMI) between a target word 

and a set of seed positive and negative words to 

infer the SO of the target word. They also uti-
lized Latent Semantic Analysis (LSA) (Landauer 

et al., 1998) as another semantic similarity meas-

ure. However, both PMI and LSA are semantic 

similarity measure. Similarly, Hassan and Radev 

(2010) presented a graph-based method for pre-

dicting SO of words. They constructed a lexical 

graph where nodes are words and edges connect 

two words with semantic similarity obtained 

from Wordnet (Fellbaum 1998). They propagat-

ed the SO of a set of seeds through this graph. 

However, such approaches did not take into ac-

count the sentiment similarity between words.  

 
Figure 10. Convergence of BHEM 

In IQAPs, Marneffe et al. (2010) inferred the 

yes/no answers using SO of the adjectives. If SO 

of the adjectives have different signs, then the 

answer conveys no, and Otherwise, if the abso-

lute value of SO for the adjective in question is 

smaller than the absolute value of the adjective in 

answer, then the answer conveys yes, and other-

wise no. In Mohtarami et al. (2012), we used two 

semantic similarity measures (PMI and LSA) for 

the IQAP inference task. We showed that meas-

uring the sentiment similarities between the ad-

jectives in question and answer leads to higher 

performance as compared to semantic similarity 

measures. 

In Mohtarami et al. (2012), we proposed an 

approach to predict the sentiment similarity of 

words using their emotional vectors. We as-

sumed that the type and number of emotions are 

pre-defined and our approach was based on this 

assumption. However, in previous research, there 

is little agreement about the number and types of 

basic emotions. Furthermore, the emotions in 

different dataset can be varied. We relaxed this 

assumption in Mohtarami et al., (2013) by con-

sidering the emotions as hidden and presented a 

hidden emotional model called SHEM. This pa-

per also consider the emotions as hidden and pre-

sents another hidden emotional model called 

BHEM that gives more accurate estimation of 

the numbers and types of the hidden emotions.   

9 Conclusion 

We propose a probabilistic approach to infer the 

sentiment similarity between word senses with 

respect to automatically learned hidden emo-

tions. We propose to utilize the correlations be-

tween reviews, ratings, and words to learn the 

hidden emotions. We show the effectiveness of 

our method in two NLP tasks. Experiments show 

that our sentiment similarity models lead to ef-

fective emotional vector construction and signif-

icantly outperform semantic similarity measures 

for the two NLP task. 

991



References  

Hadi Amiri and Tat S. Chua. 2012. Mining Slang 

and Urban Opinion Words and Phrases from 

cQA Services: An Optimization Approach. 
Proceedings of the fifth ACM international confer-

ence on Web search and data mining (WSDM). Pp. 

193-202. 

Christiane Fellbaum. 1998. WordNet: An Electron-

ic Lexical Database. Cambridge, MA: MIT 
Press. 

Ahmed Hassan and Dragomir Radev. 2010. Identify-

ing Text Polarity Using Random Walks. Pro-
ceeding in the Association for Computational Lin-

guistics (ACL). Pp: 395–403. 

Aminul Islam and Diana Inkpen. 2008. Semantic text 

similarity using corpus-based word similarity 

and string similarity. ACM Transactions on 
Knowledge Discovery from Data (TKDD). 

Carroll E. Izard. 1971. The face of emotion. New 
York: Appleton-Century-Crofts. 

Soo M. Kim and Eduard Hovy. 2004. Determining 

the sentiment of opinions. Proceeding of the 
Conference on Computational Linguistics 

(COLING). Pp: 1367–1373. 

Thomas K. Landauer, Peter W. Foltz, and Darrell 

Laham. 1998. Introduction to Latent Semantic 

Analysis. Discourse Processes. Pp: 259-284. 

Andrew L. Maas, Raymond E. Daly, Peter T. Pham, 
Dan Huang, Andrew Y. Ng, and Christopher Potts. 

2011. Learning Word Vectors for Sentiment 

Analysis. Proceeding in the Association for Com-
putational Linguistics (ACL). Pp:142-150. 

Marie-Catherine D. Marneffe, Christopher D. Man-

ning, and Christopher Potts. 2010. "Was it good? 

It was provocative." Learning the meaning of 

scalar adjectives. Proceeding in the Association 
for Computational Linguistics (ACL). Pp: 167–

176. 

Mitra Mohtarami, Hadi Amiri, Man Lan, Thanh P. 

Tran, and Chew L. Tan. 2012. Sense Sentiment 

Similarity: An Analysis. Proceeding of the Con-
ference on Artificial Intelligence (AAAI). 

Mitra Mohtarami, Man Lan, and Chew L. Tan. 2013. 

From Semantic to Emotional Space in Proba-

bilistic Sense Sentiment Analysis. Proceeding of 
the Conference on Artificial Intelligence (AAAI). 

Alena Neviarouskaya, Helmut Prendinger, and 

Mitsuru Ishizuka. 2007. Textual Affect Sensing 

for Sociable and Expressive Online Communi-

cation. Proceedings of the conference on Affective 

Computing and Intelligent Interaction (ACII). Pp: 

218-229. 

Alena Neviarouskaya, Helmut Prendinger, and 

Mitsuru Ishizuka. 2009. SentiFul: Generating a 

Reliable Lexicon for Sentiment Analysis. Pro-
ceeding of the conference on Affective Computing 
and Intelligent Interaction (ACII). Pp: 363-368. 

Andrew Ortony and Terence J. Turner. 1990. What's 

Basic About Basic Emotions. American Psycho-
logical Association. 97(3), 315-331. 

Christopher Potts, C. 2011. On the negativity of 

negation. In Nan Li and David Lutz, eds., Pro-
ceedings of Semantics and Linguistic Theory 20, 

636-659. 

Peter D. Turney and Michael L. Littman. 2003. 

Measuring Praise and Criticism: Inference of 

Semantic Orientation from Association. ACM 
Transactions on Information Systems, 21(4), 315–

346. 

Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 

2005. Recognizing contextual polarity in 

phrase-level sentiment analysis. Proceeding in 
HLT-EMNLP. Pp: 347–354. 

 

992


