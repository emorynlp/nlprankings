



















































Relation Extraction with Relation Topics


Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1426–1436,
Edinburgh, Scotland, UK, July 27–31, 2011. c©2011 Association for Computational Linguistics

Relation Extraction with Relation Topics

Chang Wang James Fan Aditya Kalyanpur David Gondek
IBM T. J. Watson Research Lab

19 Skyline Drive, Hawthorne, New York 10532
{wangchan, fanj, adityakal, dgondek}@us.ibm.com

Abstract

This paper describes a novel approach to the
semantic relation detection problem. Instead
of relying only on the training instances for
a new relation, we leverage the knowledge
learned from previously trained relation detec-
tors. Specifically, we detect a new semantic
relation by projecting the new relation’s train-
ing instances onto a lower dimension topic
space constructed from existing relation de-
tectors through a three step process. First, we
construct a large relation repository of more
than 7,000 relations from Wikipedia. Second,
we construct a set of non-redundant relation
topics defined at multiple scales from the re-
lation repository to characterize the existing
relations. Similar to the topics defined over
words, each relation topic is an interpretable
multinomial distribution over the existing re-
lations. Third, we integrate the relation topics
in a kernel function, and use it together with
SVM to construct detectors for new relations.
The experimental results on Wikipedia and
ACE data have confirmed that background-
knowledge-based topics generated from the
Wikipedia relation repository can significantly
improve the performance over the state-of-the-
art relation detection approaches.

1 Introduction

Detecting semantic relations in text is very useful
in both information retrieval and question answer-
ing because it enables knowledge bases to be lever-
aged to score passages and retrieve candidate an-
swers. To extract semantic relations from text, three
types of approaches have been applied. Rule-based

methods (Miller et al., 2000) employ a number of
linguistic rules to capture relation patterns. Feature-
based methods (Kambhatla, 2004; Zhao and Grish-
man, 2005) transform relation instances into a large
amount of linguistic features like lexical, syntactic
and semantic features, and capture the similarity be-
tween these feature vectors. Recent results mainly
rely on kernel-based approaches. Many of them fo-
cus on using tree kernels to learn parse tree struc-
ture related features (Collins and Duffy, 2001; Cu-
lotta and Sorensen, 2004; Bunescu and Mooney,
2005). Other researchers study how different ap-
proaches can be combined to improve the extraction
performance. For example, by combining tree ker-
nels and convolution string kernels, (Zhang et al.,
2006) achieved the state of the art performance on
ACE (ACE, 2004), which is a benchmark dataset for
relation extraction.

Although a large set of relations have been iden-
tified, adapting the knowledge extracted from these
relations for new semantic relations is still a chal-
lenging task. Most of the work on domain adapta-
tion of relation detection has focused on how to cre-
ate detectors from ground up with as little training
data as possible through techniques such as boot-
strapping (Etzioni et al., 2005). We take a differ-
ent approach, focusing on how the knowledge ex-
tracted from the existing relations can be reused to
help build detectors for new relations. We believe by
reusing knowledge one can build a more cost effec-
tive relation detector, but there are several challenges
associated with reusing knowledge.

The first challenge to address in this approach is
how to construct a relation repository that has suffi-

1426



cient coverage. In this paper, we introduce a method
that automatically extracts the knowledge charac-
terizing more than 7,000 relations from Wikipedia.
Wikipedia is comprehensive, containing a diverse
body of content with significant depth and grows
rapidly. Wikipedia’s infoboxes are particularly in-
teresting for relation extraction. They are short,
manually-created, and often have a relational sum-
mary of an article: a set of attribute/value pairs de-
scribing the article’s subject.

Another challenge is how to deal with overlap of
relations in the repository. For example, Wikipedia
authors may make up a name when a new relation
is needed without checking if a similar relation has
already been created. This leads to relation duplica-
tion. We refine the relation repository based on an
unsupervised multiscale analysis of the correlations
between existing relations. This method is parame-
ter free, and able to produce a set of non-redundant
relation topics defined at multiple scales. Similar to
the topics defined over words (Blei et al., 2003), we
define relation topics as multinomial distributions
over the existing relations. The relation topics ex-
tracted in our approach are interpretable, orthonor-
mal to each other, and can be used as basis relations
to re-represent the new relation instances.

The third challenge is how to use the relation top-
ics for a relation detector. We map relation instances
in the new domains to the relation topic space, re-
sulting in a set of new features characterizing the
relationship between the relation instances and ex-
isting relations. By doing so, background knowl-
edge from the existing relations can be introduced
into the new relations, which overcomes the limi-
tations of the existing approaches when the training
data is not sufficient. Our work fits in to a class of re-
lation extraction research based on “distant supervi-
sion”, which studies how knowledge and resources
external to the target domain can be used to im-
prove relation extraction. (Mintz et al., 2009; Jiang,
2009; Chan and Roth, 2010). One distinction be-
tween our approach and other existing approaches is
that we represent the knowledge from distant super-
vision using automatically constructed topics. When
we test on new instances, we do not need to search
against the knowledge base. In addition, our top-
ics also model the indirect relationship between re-
lations. Such information cannot be directly found

from the knowledge base.
The contributions of this paper are three-fold.

Firstly, we extract a large amount of training
data for more than 7,000 semantic relations from
Wikipedia (Wikipedia, 2011) and DBpedia (Auer
et al., 2007). A key part of this step is how we
handle noisy data with little human effort. Sec-
ondly, we present an unsupervised way to con-
struct a set of relation topics at multiple scales.
This step is parameter free, and results in a non-
redundant, multiscale relation topic space. Thirdly,
we design a new kernel for relation detection by
integrating the relation topics into the relation de-
tector construction. The experimental results on
Wikipedia and ACE data (ACE, 2004) have con-
firmed that background-knowledge-based features
generated from the Wikipedia relation repository
can significantly improve the performance over the
state-of-the-art relation detection approaches.

2 Extracting Relations from Wikipedia

Our training data is from two parts: relation in-
stances from DBpedia (extracted from Wikipedia
infoboxes), and sentences describing the relations
from the corresponding Wikipedia pages.

2.1 Collecting the Training Data

Since our relations correspond to Wikipedia infobox
properties, we use an approach similar to that de-
scribed in (Hoffmann et al., 2010) to collect positive
training data instances. We assume that a Wikipedia
page containing a particular infobox property is
likely to express the same relation in the text of
the page. We further assume that the relation is
most likely expressed in the first sentence on the
page which mentions the arguments of the relation.
For example, the Wikipedia page for “Albert Ein-
stein” contains an infobox property “alma mater”
with value “University of Zurich”, and the first sen-
tence mentioning the arguments is the following:
“Einstein was awarded a PhD by the University of
Zurich”, which expresses the relation. When look-
ing for relation arguments on the page, we go be-
yond (sub)string matching, and use link information
to match entities which may have different surface
forms. Using this technique, we are able to collect a
large amount of positive training instances of DBpe-

1427



dia relations.
To get precise type information for the argu-

ments of a DBpedia relation, we use the DBpedia
knowledge base (Auer et al., 2007) and the asso-
ciated YAGO type system (Suchanek et al., 2007).
Note that for every Wikipedia page, there is a cor-
responding DBpedia entry which has captured the
infobox-properties as RDF triples. Some of the
triples include type information, where the subject
of the triple is a Wikipedia entity, and the object
is a YAGO type for the entity. For example, the
DBpedia entry for the entity “Albert Einstein” in-
cludes YAGO types such as Scientist, Philosopher,
Violinist etc. These YAGO types are also linked
to appropriate WordNet concepts, providing for ac-
curate sense disambiguation. Thus, for any en-
tity argument of a relation we are learning, we ob-
tain sense-disambiguated type information (includ-
ing super-types, sub-types, siblings etc.), which be-
come useful generalization features in the relation
detection model. Given a common noun, we can
also retrieve its type information by checking against
WordNet (Fellbaum, 1998).

2.2 Extracting Rules from the Training Data
We use a set of rules together with their popular-
ities (occurrence count) to characterize a relation.
A rule representing the relations between two ar-
guments has five components (ordered): argument1
type, argument2 type, noun, preposition and verb. A
rule example of ActiveYearsEndDate relation (about
the year that a person retired) is:

person100007846|year115203791|-|in|retire.

In this example, argument1 type is per-
son100007846, argument2 type is year115203791,
both of which are from YAGO type system. The
key words connecting these two arguments are in
(preposition) and retire (verb). This rule does not
have a noun, so we use a ‘-’ to take the position of
noun. The same relation can be represented in many
different ways. Another rule example characterizing
the same relation is

person100007846|year115203791|retirement|-|announce.

This paper only considers three types of words:
noun, verb and preposition. It is straightforward to
expand or simplify the rules by including more or
removing some word types. The keywords are ex-
tracted from the shortest path on the dependency

Figure 1: A dependency tree example.

tree between the two arguments. A dependency
tree (Figure 1) represents grammatical relations be-
tween words in a sentence. We used a slot grammar
parser (McCord, 1995) to generate the parse tree of
each sentence. Note that there could be multiple
paths between two arguments in the tree. We only
take the shortest path into consideration. The pop-
ularity value corresponding to each rule represents
how many times this rule applies to the given rela-
tion in the given data. Multiple rules can be con-
structed from one relation instance, if multiple argu-
ment types are associated with the instance, or mul-
tiple nouns, prepositions or verbs are in the depen-
dency path.

2.3 Cleaning the Training Data

To find a sentence on the Wikipedia page that is
likely to express a relation in its infobox, we con-
sider the first sentence on the page that mentions
both arguments of the relation. This heuristic ap-
proach returns reasonably good results, but brings in
about 20% noise in the form of false positives, which
is a concern when building an accurate statistical re-
lation detector. To address this issue, we have devel-
oped a two-step technique to automatically remove
some of the noisy data. In the first step, we extract
popular argument types and keywords for each DB-
pedia relation from the given data, and then use the
combinations of those types and words to create ini-
tial rules. Many of the argument types and keywords
introduced by the noisy data are often not very pop-
ular, so they can be filtered out in the first step. Not
all initial rules make sense. In the second step, we

1428



check each rule against the training data to see if that
rule really exists in the training data or not. If it does
not exist, we filter it out. If a sentence does not have
a single rule passing the above procedure, that sen-
tence will be removed. Using the above techniques,
we collect examples characterizing 7,628 DBpedia
relations.

3 Learning Multiscale Relation Topics

An extra step extracting knowledge from the raw
data is needed for two reasons: Firstly, many DB-
pedia relations are inter-related. For example, some
DBpedia relations have a subclass relationship, e.g.
“AcademyAward” and “Award”; others overlap in
their scope and use, e.g., “Composer” and “Artist”;
while some are equivalent, e.g., “DateOfBirth” and
“BirthDate”. Secondly, a fairly large amount of the
noisy labels are still in the training data.

To reveal the intrinsic structure of the current DB-
pedia relation space and filter out noise, we car-
ried out a correlation analysis of relations in the
training data, resulting in a relation topic space.
Each relation topic is a multinomial distribution
over the existing relations. We adapted diffusion
wavelets (Coifman and Maggioni, 2006) for this
task. Compared to the other well-known topic ex-
traction methods like LDA (Blei et al., 2003) and
LSI (Deerwester et al., 1990), diffusion wavelets can
efficiently extract a hierarchy of interpretable topics
without any user input parameter (Wang and Ma-
hadevan, 2009).

3.1 An Overview of Diffusion Wavelets

The diffusion wavelets algorithm constructs a com-
pressed representation of the dyadic powers of a
square matrix by representing the associated matri-
ces at each scale not in terms of the original (unit
vector) basis, but rather using a set of custom gener-
ated bases (Coifman and Maggioni, 2006). Figure
2 summarizes the procedure to generate diffusion
wavelets. Given a matrix T , the QR (a modified
QR decomposition) subroutine decomposes T into
an orthogonal matrix Q and a triangular matrix R
such that T ≈ QR, where |Ti,k − (QR)i,k| < ε
for any i and k. Columns in Q are orthonormal ba-
sis functions spanning the column space of T at the
finest scale. RQ is the new representation of T with

{[φj ]φ0} = DWT (T, ε, J)
//INPUT:
//T : The input matrix.
//ε: Desired precision, which can be set to a small

number or simply machine precision.
//J : Number of levels (optional).
//OUTPUT:
//[φj ]φ0 : extended diffusion scaling functions at

scale j.

φ0 = I;
For j = 0 to J − 1 {

([φj+1]φj , [T
2j ]

φj+1
φj

)← QR([T 2
j

]
φj
φj
, ε);

[φj+1]φ0 = [φj+1]φj [φj ]φ0 ;
[T 2

j+1

]
φj+1
φj+1

= ([T 2
j

]
φj+1
φj

[φj+1]φj )
2;

}

Figure 2: Diffusion Wavelets construct multiscale repre-
sentations of the input matrix at different scales. QR is a
modified QR decomposition. J is the max step number
(this is optional, since the algorithm automatically ter-
minates when it reaches a matrix of size 1 × 1). The
notation [T ]φbφa denotes matrix T whose column space is
represented using basis φb at scale b, and row space is
represented using basis φa at scale a. The notation [φb]φa
denotes basis φb represented on the basis φa. At an arbi-
trary scale j, we have pj basis functions, and length of
each function is lj . The number of pj is determined by
the intrinsic structure of the given dataset in QR routine.
[T ]φbφa is a pb × la matrix, and [φb]φa is an la × pb matrix.

respect to the space spanned by the columns of Q
(this result is based on the matrix invariant subspace
theory). At an arbitrary level j,DWT learns the ba-
sis functions from T 2

j
using QR. Compared to the

number of basis functions spanning T 2
j
’s original

column space, we usually get fewer basis functions,
since some high frequency information (correspond-
ing to the “noise” at that level) can be filtered out.
DWT then computes T 2

j+1
using the low frequency

representation of T 2
j

and the procedure repeats.

3.2 Constructing Multiscale Relation Topics

Learning Relation Correlations

Assume we have M relations, and the ith of them
is characterized by mi <rule, popularity> pairs. We
use s(a, b) to represent the similarity between the
ath and bth relations. To compute s(a, b), we first
normalize the popularities for each relation, and then

1429



look for the rules that are shared by both relation a
and b. We use the product of corresponding pop-
ularity values to represent the similarity score be-
tween two relations with respect to each common
rule. s(a, b) is set to the sum of such scores over
all common rules. The relation-relation correlation
matrix S is constructed as follows:

S = [
s(1, 1) · · · s(1,M)
· · · · · · · · ·

s(M, 1) · · · s(M,M)
]

We have more than 200, 000 argument types, tens
of thousands of distinct nouns, prepositions, and
verbs, so we potentially have trillions of distinct
rules. One rule may appear in multiple relations.
The more rules two relations share, the more related
two relations should be. The rules shared across dif-
ferent relations offer us a novel way to model the
correlations between different relations, and further
allow us to create relation topics. The rules can also
be simplified. For example, we may treat argument1,
argument2, noun, preposition and verb separately.
This results in simple rules that only involve in one
argument type or word. The correlations between
relations are then computed only based on one par-
ticular component like argument1, noun, etc.

Theoretical Analysis
Matrix S models the correlations between rela-

tions in the training data. Once S is constructed, we
adapt diffusion wavelets (Coifman and Maggioni,
2006) to automatically extract the basis functions
spanning the original column space of S at multi-
ple scales. The key strength of the approach is that
it is data-driven, largely parameter-free and can au-
tomatically determine the number of levels of the
topical hierarchy, as well as the topics at each level.
However, to apply diffusion wavelets to S, we first
need to show that S is a positive semi-definite ma-
trix. This property guarantees that all eigenvalues
of S are ≥ 0. Depending on the way we formal-
ize the rules, the methods to validate this property
are slightly different. When we treat argument1,
argument2, noun, preposition and verb separately, it
is straightforward to see the property holds. In The-
orem 1, we show the property also holds when we
use more complicated rules (using the 5-tuple rule
in Section 2.2 as an example in the proof).

Theorem 1. S is a Positive Semi-Definite matrix.

Proof: An arbitrary rule ri is uniquely characterized
by a five tuple: argument1 type| argument2 type|
noun| preposition| verb. Since the number of dis-
tinct argument types and words are constants, the
number of all possible rules is also a constant: R.

If we treat each rule as a feature, then the set of
rules characterizing an arbitrary relation ri can be
represented as a point [p1i , · · · , p

R
i ] in a latent R di-

mensional rule space, where pji represents the popu-
larity of rule j in relation ri in the given data.

We can verify that the way to compute s(a, b) is
the same as s(a, b) =< [p1a · · · p

R
a ], [p

1
b · · · p

R
b ] >,

where < ·, · > is the cosine similarity (kernel). It
follows directly from the definition of positive semi-
definite matrix (PSD) that S is PSD (Schölkopf and
Smola, 2002).

In our approach, we construct multiscale re-
lation topics by applying DWT to decompose
S/λmax(S), where λmax(S) represents the largest
eigenvalue of S. Theorem 2 shows that this decom-
position will converge, resulting in a relation topic
hierarchy with one single topic at the top level.

Theorem 2. Let λmax(S) represent the largest
eigenvalue of matrix S, then DWT (S/λmax(S), ε)
produces a set of nested subspaces of the column
space of S, and the highest level of the resulting sub-
space hierarchy is spanned by one basis function.

Proof: From Theorem 1, we know that S is a PSD
matrix. This means λmax(S) ∈ [0,+∞) (all eigen-
values of S are non-negative). This further implies
that Λ(S)/λmax(S) ∈ [0, 1], where Λ(S) represents
any eigenvalue of S.

The idea underlying diffusion wavelets is based
on decomposing the spectrum of an input matrix
into various spectral bands, spanned by basis func-
tions (Coifman and Maggioni, 2006). Let T =
S/λmax(S). In Figure 2, we construct spectral
bands of eigenvalues, whose associated eigenvectors
span the corresponding subspaces. Define dyadic
spatial scales tj as

tj =

j∑

t=0

2t = 2j+1 − 1, j ≥ 0 .

At each spatial scale, the spectral band is defined as:

Ωj(T ) = {λ ∈ Λ(T ), λ
tj ≥ ε},

1430



where Λ(T ) represents any eigenvalue of T , and ε ∈
(0, 1) is a pre-defined threshold in Figure 2. We can
now associate with each of the spectral bands a vec-
tor subspace spanned by the corresponding eigen-
vectors:

Vj = 〈{ξλ : λ ∈ Λ(T ), λ
tj ≥ ε}〉, j ≥ 0 .

In the limit, we obtain

lim
j→∞

Vj = 〈{ξλ : λ = 1}〉

That is, the highest level of the resulting subspace
hierarchy is spanned by the eigenvector associated
with the largest eigenvalue of T .

This result shows that the multiscale analysis of
the relation space will automatically terminate at the
level spanned by one basis, which is the most popu-
lar relation topic in the training data.

3.3 High Level Explanation
We first create a set of rules to characterize each in-
put relation. Since these rules may occur in multi-
ple relations, they provide a way to model the co-
occurrence relationship between different relations.
Our algorithm starts with the relation co-occurrence
matrix and then repeatedly applies QR decomposi-
tion to learn the topics at the current level while at
the same time modifying the matrix to focus more on
low-frequency indirect co-occurrences (between re-
lations) for the next level. Running DWT is equiv-
alent to running a Markov chain on the input data
forward in time, integrating the local geometry and
therefore revealing the relevant geometric structures
of the whole data set at different scales. At scale
j, the representation of T 2

j+1
is compressed based

on the amount of remaining information and the de-
sired precision. This procedure is illustrated in Fig-
ure 3. In the resulting topic space, instances with
related relations will be grouped together. This ap-
proach may significantly help us detect new rela-
tions, since it potentially expands the information
brought in by new relation instances from making
use of the knowledge extracted from the existing re-
lation repository.

3.4 Benefits
As shown in Figure 3, the topic spaces at different
levels are spanned by a different number of basis

� ���� ���	��
������������ � � ���

�

��� � 
����
�! #"���
��$ %'& (*) + , - . /'0 1*2 3 , 4. 5637�8 , -, - 9 :

;

<�=�;

.

.

.

Figure 3: Learning Relation Topics at Multiple Scales.

functions. These numbers reveal the dimensions of
the relevant geometric structures of data at different
levels. These numbers are completely data-driven:
the diffusion wavelets approach can automatically
find the number of levels and simultaneously gen-
erate the topics at each level. Experiments show that
most multiscale topics are interpretable (due to the
sparsity of the scaling functions), such that we can
interpret the topics at different scales and select the
best scale for embedding. Compared to bootstrap-
ping approach, our approach is accumulative; that
is as the system learns more relations, it gets bet-
ter at learning new relations. Because our approach
takes advantage of the previously learned relations,
and the topic space is enriched as we learn more and
more relations.

We use diffusion wavelets (DWT) rather than
other hierarchy topic models like hLDA (Blei et
al., 2004) to extract relation topics for two rea-
sons. First, DWT is parameter free while other
models need some user-input parameters like hier-
archy level. Second, DWT is more efficient than the
other models. After the relation correlation matrix
is constructed, DWT only needs a couple of min-
utes to extract multiscale topics on a regular com-
puter. A direct experimental comparison between
DWT and hLDA can be found in (Wang and Ma-
hadevan, 2009).

1431



4 Constructing Relation Detectors with
Multiscale Relation Topics

4.1 Project Relation Instances onto Topics

When we design detectors for new relations, we
treat arg1, arg2, noun, and verb separately to
get stronger correlations between relations. We
do not directly use preposition. Any DBpe-
dia relation r ∈ {1, · · · ,M} is represented with
4 vectors rt = [rt(1), · · · , rt(Nt)], where t ∈
{arg1, arg2, noun, verb}, Nt represents the size of
the vocabulary set of the type t component in the
Wikipedia training data, and rt(j) represents the oc-
currence count of type t component in relation r. For
example, Nverb is the size of the verb vocabulary set
in the training data and rverb(j) represents the occur-
rence count of the jth verb in relation r. When a new
relation instance x is given, we extract the depen-
dency path between two arguments, and create four
vectors xt, where t ∈ {arg1, arg2, noun, verb},
following the same format as rt. The projection re-
sult of xt onto the DBpedia relation space Xt is as
follows:

Xt = [< rt(1), xt(1) >, · · · , < rt(M), xt(M) >],
where < ·, · > is the cosine similarity of two vec-
tors. At level k, the embedding of x is Ekx =
[EkXarg1

, EkXarg2
, EkXnoun , E

k
Xverb

], where EkXt =
([φk]φ0)

TXt, and [φk]φ0 is defined in Figure 2.

4.2 Design New Kernel Using Topic Features

We combine Ekx with 3 existing kernels (KArgument,
KPath and KBOW ) to create a new kernel for rela-
tion detection.
(1) KArgument matches two arguments, it returns the
number of common argument types that the input ar-
guments share.
(2) KPath matches two dependency paths. This
kernel is formally defined in (Zhao and Grishman,
2005). We extended this kernel by also matching
the common nouns, prepositions and verbs in the de-
pendency paths. We assign weight 1 to verbs, 0.5 to
nouns and prepositions.
(3) KBOW models the number of common nouns,
prepositions and verbs in the given sentences but
not in the dependency paths. Since these words are
not as important as the words inside the dependency
path, we assign weight 0.25 to them.

(4) KTFk(x, y) =< E
k
x , E

k
y >, where x, y are two

input relation instances, and < ·, · > models the co-
sine similarity of two vectors. TF stands for topic
feature.
(5) The final kernel used in this paper is

α1KArgument + α2KPath + α3KBOW + α4KTFk ,
where αi can be tuned for each individual domain.
In this paper, we set αi = 1 for i ∈ {1, 2, 3, 4}.

4.3 Algorithm to Construct Relation Detectors
1. Construct a relation repository from Wikipedia.

(a) Collect training data from Wikipedia and DB-
pedia (Section 2.1);

(b) Clean the data representing each input relation
(Section 2.2 and 2.3);

(c) Create relation correlation matrix S following
the approach described in Section 3.2, result-
ing in an M ×M matrix.

2. Create multiscale relation topics.

[φk]φ0 = DWT (S/λmax(S), ε), where DWT () is
the diffusion wavelets implementation described in
Section 3.1. [φk]φ0 are the scaling function bases
at level k represented as an M × pk matrix, k =
1, · · · , h represents the level in the topic hierarchy.
The value of pk is determined in DWT () based on
the intrinsic structure of the given dataset. Columns
of [φk]φ0 are used as relation topics at level k.

3. Construct relation detectors for new relations.

Given the training data from a new relation, project
the data onto level k of the multiscale topic hierar-
chy, where k is chosen by users (Section 4.1). Ap-
ply SVM classifiers together with our kernel (Sec-
tion 4.2) to create detectors for new relations.

5 Experimental Results

We used SVMLight (Joachims, 1999) together with
the user defined kernel setting in our approach. The
trade-off parameter between training error and mar-
gin c is 1 for all experiments. Our approach to
learn multiscale relation topics is largely parameter
free. The only parameter to be set is the precision
ε = 10−5, which is also the default value in the dif-
fusion wavelets implementation.

5.1 Learning Multiscale Relation Topics

Following the approach discussed in Section 2.1,
we collect more than 620,000 training instances for

1432



Table 1: Number of topics at different levels (DBpe-
dia Relations) under 5 different settings: use args, noun,
preposition and verb; arg1 only; arg2 only; noun only and
verb only.

Level args & words arg1 arg2 noun verb
1 7628 7628 7628 7628 7628
2 269 119 155 249 210
3 32 17 19 25 35
4 7 5 5 7 10
5 3 2 3 4 4
6 2 1 2 2 2
7 1 1 1 1

7,628 DBpedia relations. For any given topic vec-
tor v, we know it is a column vector of length M ,
where M is the size of the DBpedia relation set
and ‖v‖ = 1. The entry v[i] represents the contri-
bution of relation i to this topic. To explain the
main concept of topic v, we sort the entries on
v and print out the relations corresponding to the
top entries. These relations summarize the top-
ics in the relation repository. One topic exam-
ple is as follows: [doctoraladvisor (0.683366), doc-
toralstudents (0.113201), candidate (0.014662), academ-
icadvisors (0.008623), notablestudents (0.003829), col-
lege (0.003021), operatingsystem (0.002964), combatant
(0.002826), influences (0.002285), training (0.002148),
· · · ], where doctoraladvisor is a DBpedia relation
and 0.683366 is its contribution to the topic. The
length of this relation vector is 7,628. We only list
the top 10 relations here.

Our approach identifies 5 different topic hierar-
chies under different settings (use args, noun, prepo-
sition and verb; arg1 only; arg2 only; noun only and
verb only). The number of the topics at each level is
shown in Table 1. At the first level, each input rela-
tion is treated as a topic. At the second level, num-
bers of topics go down to reasonable numbers like
269. Finally at the top level, the number of topic is
down to 1 (Theorem 2 also proves this). We show
some topic examples under the first setting. The 3
topics at level 5 are shown in Table 2. They represent
the most popular DBpedia relation topics. Almost
all 269 topics at level 5 look semantically meaning-
ful. They nicely capture the related relations. Some
examples are in Table 3.

Table 2: 3 topics at level 5 (all word types and args).
Top 4 Relations and Their Contributions

starring 86.6%, writer 3.8%, producer 3.2%, director 1.6%
birthplace 75.3%, clubs 6.1%, deathplace 5.1%, location 4.1%

clubs 55.3%, teams 9.3%, nationalteam 6.3% college 6.0%

Table 3: Some topics at level 2 (all word types and args).
Top Relations

activeyearsenddate, careerend, finalyear, retired
commands, partof, battles, notablecommanders
occupation, shortdescription, profession, dates

influenced, schooltradition, notableideas, maininterests
destinations, end, through, posttown

prizes, award, academyawards, highlights
inflow, outflow, length, maxdepth
after, successor, endingterminus
college, almamater, education

5.2 Relation Detection on Wikipedia Data

In previous experiment, 20,000 relation instances
were held and not used to construct the topic space.
These instances are randomly selected from 100 re-
lations (200 instances from each relation). This set
is used as a benchmark to compare different rela-
tion detection approaches. In this experiment, 100
instances from each relation are used for training,
and the other 100 are for testing. In training, we try
three different settings: n = 5, 20 and 100, where n
is the size of the training set for each relation. When
we train a model for one relation, we use the train-
ing positive instances from the other 99 relations as
training negatives. For example, we use 5 training
positive instances and 5*99=495 training negatives
to train a detector for each relation.

We compare our approach against the regular
rule-based approach (Lin and Pantel, 2001) and two
other kernel-based approaches (presented in Sec-
tion 4.2) for relation detection task. The comparison
results are summarized in Table 4. The approach
using relation topics (level 2) consistently outper-
forms the other three approaches in all three settings.
When n = 5, it achieves the largest improvement
over the other three. This indicates that using re-
lation topics that integrate the knowledge extracted
from the existing relations, can significantly benefit
us when the training data is insufficient. This is rea-
sonable, since the prior knowledge becomes more
valuable in this scenario.

1433



The users can select the level that is the most ap-
propriate for their applications. In this example, we
only have alignment results at 7 levels. Choosing the
space at level 2 spanned by a couple of hundreds of
basis functions is a natural choice, since the levels
below and above this have too many or too few fea-
tures, respectively. A user can also select the most
appropriate level by checking if the related relation
topics are meaningful for their applications.

5.3 Relation Detection on ACE Data

In this experiment, we use the news domain docu-
ments of the ACE 2004 corpus (ACE, 2004) to com-
pare our approaches against the state-of-the-art ap-
proaches. This dataset includes 348 documents and
around 4400 relation instances. 7 relation types,
7 entity types, numerous relation sub-types, entity
sub-types, and mention types are defined on this
set. The task is to classify the relation instances
into one of the 7 relation types or “NONE”, which
means there is no relation. For comparison, we use
the same setting as (Zhang et al., 2006), by apply-
ing a 5-fold cross-validation. The scores reported
here are the average of all 5 folds. This is also how
the other approaches are evaluated. In this test, we
treat entity types, entity sub-types and mention types
equally as argument types. Table 5 summarizes
the performance after applying the kernels presented
in Section 4.2 incrementally, showing the improve-
ment from each individual kernel. We also com-
pare our approaches to the other state-of-the-art ap-
proaches including Convolution Tree kernel (Collins
and Duffy, 2001), Syntactic kernel (Zhao and Grish-
man, 2005), Composite kernel (linear) (Zhang et al.,
2006) and the best kernel in (Nguyen et al., 2009).
Our approach with relation topics at level 2 has the
best performance, achieving a 73.24% F-measure.
The impact of the relation topics is huge. They im-
prove the F-measure from 61.15% to 73.24%. We
also test our approach using the topics at level 3.
The performance is slightly worse than using level
2, but still better than the others.

This paper studies how relation topics extracted
from Wikipedia relation repository can help improve
relation detection performance. We do not want to
tune our approach to one particular relation detec-
tion task, like ACE 2004. In our experiments, no
parameter tuning was taken and no domain specific

heuristic rules were applied. We are aware of some
methods that could stack on our approach to further
improve the performance on ACE test. The Com-
posite kernel result in Table 5 is based on a linear
combination of the Argument kernel and Convolu-
tion Tree kernel. (Zhang et al., 2006) showed that
by carefully choosing the weight of each compo-
nent and using a polynomial expansion, they could
achieve the best performance on this data: 72.1% F-
measure. (Nguyen et al., 2009) further showed that
the performance can be improved by taking syntac-
tic and semantic structures into consideration. They
used several types of syntactic information includ-
ing constituent and dependency syntactic parse trees
to improve the state of the art approaches to 71.5%
on F-measure. Heuristic rules extracted from the
target data can also help improve the performance.
(Jiang and Zhai, 2007) reported that by taking sev-
eral heuristic rules they can improve the F-measure
of Composite Kernel to 70.4%. They also showed
that using maximum entropy classifier rather than
SVM achieved the best performance on this task:
72.9% F-measure. To the best of our knowledge, the
most recent result was reported by (Zhou and Zhu,
2011), who extended their previous work in (Zhou
et al., 2007). By using several heuristics to define
an effective portion of constituent trees, and training
the classifiers using ACE relation sub-types (rather
than on types), they achieved an impressive 75.8%
F-measure. However, as pointed out in (Nguyen et
al., 2009), such heuristics are tuned on the target re-
lation extraction task and might not be appropriate to
compare against the automatic learning approaches.
Even though we have not done any domain specific
parameter tuning or applied any heuristics, our ap-
proach still achieve significant improvements over
all approaches mentioned above except one, which
is based on heuristics extracted from the target do-
main. This also implies that by combining some of
the above ideas with relation topics, the performance
on ACE data may be further improved.

6 Conclusions

This paper proposes a novel approach to create de-
tectors for new relations integrating the knowledge
extracted from the existing relations. The contribu-
tions of this paper are three-fold. Firstly, we pro-

1434



Table 4: F-measure comparison of different approaches
over 100 DBpedia relations with 5, 20 and 100 posi-
tive examples per relation. AG: KArgument, DP: KPath,
BOW: KBOW , TFk: KTFk .

Approaches 100 20 5
Rule Based 37.70% 27.45% 13.20%

AG+ DP 73.64% 51.85% 22.95%
AG+ DP+ BOW 78.74% 62.76% 31.98%

AG+ DP+ BOW+ TF2 81.18% 68.03% 41.60%

Table 5: Performance comparison of different approaches
with SVM over the ACE 2004 data. P: Precision, R: Re-
call, F: F-measure, AG: KArgument, DP: KPath, BOW:
KBOW , TFk: KTFk .

Approaches P(%) R(%) F(%)
Convolution Tree Kernel 72.5 56.7 63.6

Composite Kernel (linear) 73.50 67.00 70.10
Syntactic Kernel 69.23 70.50 69.86

Nguyen, et al. (2009) 76.60 67.00 71.50
AG 59.56 46.22 52.02

AG + DP 64.44 54.93 59.28
AG + DP + BOW 62.00 61.19 61.15

AG + DP + BOW + TF3 69.63 76.51 72.90
AG + DP + BOW + TF2 69.15 77.88 73.24

vide an automatic way to collect training data for
more than 7,000 relations from Wikipedia and DB-
pedia. Secondly, we present an unsupervised way to
construct a set of relation topics at multiple scales.
Different from the topics defined over words, rela-
tion topics are defined over the existing relations.
Thirdly, we design a new kernel for relation detec-
tion by integrating the relation topics in the repre-
sentation of the relation instances. By leveraging
the knowledge extracted from the Wikipedia rela-
tion repository, our approach significantly improves
the performance over the state-of-the-art approaches
on ACE data. This paper makes use of all DBpedia
relations to create relation topics. It is possible that
using a subset of them (more related to the target
relations) might improve the performance. We will
explore this in future work.

Acknowledgments

We thank the reviewers for their helpful comments.
This material is based upon work supported in part
by the IBM DeepQA (Watson) project. We also
gratefully acknowledge the support of Defense Ad-

vanced Research Projects Agency (DARPA) Ma-
chine Reading Program under Air Force Research
Laboratory (AFRL) prime contract no. FA8750-09-
C-0172. Any opinions, findings, and conclusion
or recommendations expressed in this material are
those of the author(s) and do not necessarily reflect
the view of the DARPA, AFRL, or the US govern-
ment.

References

ACE. 2004. The automatic content extraction projects,
http://projects.ldc.upenn.edu/ace/.

Sören Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives. 2007.
DBpedia: A nucleus for a web of open data. In Pro-
ceedings of the 6th International Semantic Web Con-
ference, Busan, Korea, pages 11–15. Springer.

D. Blei, A. Ng, and M. Jordan. 2003. Latent Dirich-
let allocation. Journal of Machine Learning Research,
3:993–1022.

D. Blei, T. Griffiths, M. Jordan, and J. Tenenbaum. 2004.
Hierarchical topic models and the nested Chinese
restaurant process. In Proceedings of the Advances in
Neural Information Processing Systems (NIPS).

Razvan Bunescu and Raymond Mooney. 2005. A short-
est path dependency kernel for relation extraction. In
Proceedings of the Conference on Human Language
Technology and Empirical Methods in Natural Lan-
guage Processing.

Yee Seng Chan and Dan Roth. 2010. Exploiting back-
ground knowledge for relation extraction. In Proceed-
ings of the 23rd International Conference on Compu-
tational Linguistics, pages 152–160.

R. Coifman and M. Maggioni. 2006. Diffusion
wavelets. Applied and Computational Harmonic
Analysis, 21:53–94.

Michael Collins and Nigel Duffy. 2001. Convolution
kernels for natural language. In Proceedings of the
Advances in Neural Information Processing Systems
(NIPS), pages 625–632.

Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In Proceedings of
the 42nd Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 423–429.

S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Lan-
dauer, and R. Harshman. 1990. Indexing by latent se-
mantic analysis. Journal of the American Society for
Information Science, 41(6):391–407.

Oren Etzioni, Michael Cafarella, Doug Downey, Ana-
Maria Popescu, Tal Shaked, Stephen Soderland,

1435



Daniel S. Weld, and Alexander Yates. 2005. Unsuper-
vised named-entity extraction from the web: An ex-
perimental study. Artificial Intelligence, 165:91–134.

Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press.

Raphael Hoffmann, Congle Zhang, and Daniel S. Weld.
2010. Learning 5000 relational extractors. In Pro-
ceedings of the 48th Annual Meeting of the Association
for Computational Linguistics (ACL), pages 286–295.

Jing Jiang and Chengxiang Zhai. 2007. A systematic ex-
ploration of the feature space for relation extraction. In
Proceedings of the Human Language Technology Con-
ference of the North American Chapter of the Associ-
ation for Computational Linguistics, pages 113–120.

Jing Jiang. 2009. Multi-task transfer learning for
weakly-supervised relation extraction. In Proceedings
of the Joint Conference of the 47th Annual Meeting of
the Association for Computational Linguistics (ACL)
and the 4th International Joint Conference on Natural
Language Processing (IJCNLP), pages 1012–1020.

T. Joachims. 1999. Making Large-Scale SVM Learning
Practical. MIT Press.

Nanda Kambhatla. 2004. Combining lexical, syntactic,
and semantic features with maximum entropy mod-
els for extracting relations. In Proceedings of the
ACL 2004 on Interactive poster and demonstration
sessions.

Dekang Lin and Patrick Pantel. 2001. DIRT - discov-
ery of inference rules from text. In Proceedings of the
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining, pages 323–328.

Michael McCord. 1995. Slot grammar: A system
for simpler construction of practical natural language
grammars. Communications of the ACM, 38(11).

Scott Miller, Heidi Fox, Lance Ramshaw, and Ralph
Weischedel. 2000. A novel use of statistical pars-
ing to extract information from text. In Proceedings
of the 1st North American Chapter of the Association
for Computational Linguistics Conference.

Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.
2009. Distant supervision for relation extraction with-
out labeled data. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the Association for
Computational Linguistics (ACL) and the 4th Interna-
tional Joint Conference on Natural Language Process-
ing (IJCNLP), pages 1003–1011.

Truc-Vien T. Nguyen, Alessandro Moschitti, and
Giuseppe Riccardi. 2009. Convolution kernels on
constituent, dependency and sequential structures for
relation extraction. In Proceedings of the 2009 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP).

B. Schölkopf and A. J. Smola. 2002. Learning with Ker-
nels: Support Vector Machines, Regularization, Opti-
mization, and Beyond. MIT Press.

Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. YAGO: A large ontology from
Wikipedia and WordNet. Web Semantics: Science,
Services and Agents on the World Wide Web, 6(3):203–
217.

C. Wang and S. Mahadevan. 2009. Multiscale analysis
of document corpora based on diffusion models. In
Proceedings of the International Joint Conference on
Artificial Intelligence (IJCAI), pages 1592–1597.

Wikipedia. 2011. http://www.wikipedia.org/.
Min Zhang, Jie Zhang, Jian Su, and Guodong Zhou.

2006. A composite kernel to extract relations between
entities with both flat and structured features. In Pro-
ceedings of the 21st International Conference on Com-
putational Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics (ACL).

Shubin Zhao and Ralph Grishman. 2005. Extracting re-
lations with integrated information using kernel meth-
ods. In Proceedings of the 43rd Annual Meeting of
the Association for Computational Linguistics (ACL),
pages 419–426.

G. Zhou and Q. Zhu. 2011. Kernel-based semantic rela-
tion detection and classification via enriched parse tree
structure. Journal of Computer Science and Technol-
ogy, 26:45–56.

G. Zhou, M. Zhang, D. Ji, and Q. Zhu. 2007. Tree
kernel-based relation extraction with context-sensitive
structured parse tree information. In Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP).

1436


