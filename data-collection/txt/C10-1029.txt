Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 250–258,

Beijing, August 2010

250

Comparison of different algebras for inducing

the temporal structure of texts

Pascal Denis†

† Alpage Project-Team

INRIA & Université Paris 7

pascal.denis@inria.fr

Abstract

This paper investigates the impact of us-
ing different temporal algebras for learn-
ing temporal relations between events.
Speciﬁcally, we compare three interval-
based algebras: Allen (1983) algebra,
Bruce (1972) algebra, and the algebra de-
rived from the TempEval-07 campaign.
These algebras encode different granular-
ities of relations and have different infer-
ential properties. They in turn behave dif-
ferently when used to enforce global con-
sistency constraints on the building of a
temporal representation. Through various
experiments on the TimeBank/AQUAINT
corpus, we show that although the TempE-
val relation set leads to the best classiﬁca-
tion accuracy performance, it is too vague
to be used for enforcing consistency. By
contrast, the other two relation sets are
similarly harder to learn, but more use-
ful when global consistency is important.
Overall, the Bruce algebra is shown to
give the best compromise between learn-
ability and expressive power.

Introduction

1
Being able to recover the temporal relations (e.g.,
precedence, inclusion) that hold between events
and other time-denoting expressions in a docu-
ment is an essential part of natural language un-
derstanding. Success in this task has important
implications for other NLP applications, such as
text summarization, information extraction, and
question answering.

Interest for this problem within the NLP com-
munity is not new (Passonneau, 1988; Webber,
1988; Lascarides and Asher, 1993), but has been
recently revived by the creation of the TimeBank

Philippe Muller†,(cid:5)

(cid:5) IRIT

Université de Toulouse
muller@irit.fr

corpus (Pustejovsky et al., 2003), and the orga-
nization of the TempEval-07 campaign (Verhagen
et al., 2007). These have seen the development
of machine learning inspired systems (Bramsen et
al., 2006; Mani et al., 2006; Tatu and Srikanth,
2008; Chambers and Jurafsky, 2008).

Learning the temporal stucture from texts is a
difﬁcult problem because there are numerous in-
formation sources at play (in particular, seman-
tic and pragmatic ones) (Lascarides and Asher,
1993). An additional difﬁculty comes from the
fact that temporal relations have logical proper-
ties that restrict the consistent graphs that can be
built for a set of temporal entities (for instance
the transitivity of inclusion and temporal prece-
dence). Previous work do not attempt to directly
predict globally coherent temporal graphs, but in-
stead focus on the the simpler problem of label-
ing pre-selected pairs of events (i.e., a task that
directly lends itself to the use of standard classiﬁ-
cation techniques). That is, they do not consider
the problem of linking pairs of events (i.e., of de-
termining which pairs of events are related).

Given the importance of temporal reasoning
for determining the temporal structure of texts,
a natural question is how to best use it within
a machine-based learning approach. Following
(Mani et al., 2006), prior approaches exploit tem-
poral inferences to enrich the set of training in-
stances used for learning. By contrast, (Bramsen
et al., 2006) use temporal relation compositions to
provide constraints in a global inference problem
(on the slightly different task of ordering passages
in medical history records). (Tatu and Srikanth,
2008) and (Chambers and Jurafsky, 2008) com-
bine both approaches and use temporal reasoning
both during training and decoding. Interestingly,
these approaches use different inventories of re-
lations: (Mani et al., 2006) use the TimeML 13
relation set, while (Chambers and Jurafsky, 2008;

251

Bramsen et al., 2006) use subset of these relations,
namely precedence and the absence of relation.

This paper adopts a more systematic perspec-
tive and directly assesses the impact of differ-
ent relation sets (and their underlying algebras)
in terms of learning and inferential properties.
Speciﬁcally, we compare three interval-based al-
gebras for building classiﬁcation-based systems,
namely: Allen (1983)’s 13 relation algebra, Bruce
(1972)’s 7 relations algebra, and the algebra
underlying Tempeval-07 3 relations (henceforth,
TempEval algebra). We wish to determine the
best trade-off between: (i) how easy it is to learn
a given set of relations, (ii) how informative are
the representations produced by each relation set,
and (iii) how much information can be drawn from
the predicted relations using knowledge encoded
in the representation. These algebras indeed dif-
fer in the number of relations they encode, and in
turn in how expressive each of these relations is.
From a machine learning point of view of learn-
ing, it is arguably easier to learn a model that
has to decide among fewer relations (i.e., that has
fewer classes). But from a representational point
of view, it is better to predict relations that are as
speciﬁc as possible, for composing them may re-
strict the prediction to more accurate descriptions
of the situation. However, while speciﬁc relations
potentially trigger more inferences, they are also
more likely to predict inconsistent constraints. In
order to evaluate these differences, we design a set
of experiments on the Timebank/AQUAINT cor-
pus, wherein we learn precise relations and vaguer
ones, and evaluate them with respect to each other
(when a correspondence is possible).

2

brieﬂy

Section

presents

the Time-
bank/AQUAINT corpus.
In section 3, we
describe the task of temporal ordering through an
example, and discuss how it should be evaluated.
Section 4 then goes into more detail about the
different representation possibilities for temporal
relations, and some of their formal properties.
Section 5 presents our methods for building tem-
poral structures, that combines relation classiﬁers
with global constraints on whole documents.
Finally, we discuss our experimental results in
section 6.

2 The Timebank/AQUAINT corpus

Like (Mani et al., 2006) and (Chambers and Ju-
rafsky, 2008), we use the so-called OTC corpus,
a corpus of 259 documents obtained by com-
bining the Timebank corpus (Pustejovsky et al.,
2003) (we use version 1.1 of the corpus) and the
AQUAINT corpus.1 The Timebank corpus con-
sists of 186 newswire articles (and around 65, 000
words), while AQUAINT has 73 documents (and
around 40, 000 words).

Both corpora are annotated using the TimeML
scheme for
tagging eventualities (events and
states), dates/times, and their temporal relations.
Eventualities can be denoted by verbs, nouns, and
some speciﬁc constructions. The temporal rela-
tions (i.e., the so-called TLINKS) encode topolog-
ical information between the time intervals of oc-
curring eventualities. TimeML distinguishes three
types of TLINKS: event-event, event-time, and
time-time, giving rise to different subtasks. In this
paper, we will focus on predicting event-event re-
lations (see (Filatova and Hovy, 2001; Boguraev
and Ando, 2005) for work on the other tasks). The
set of temporal relations used in TLINKS mirrors
the 13 Allen relations (see next section), and in-
cludes the following six relations: before, begins,
ends, ibefore, includes, simultaneous and their in-
verses. The combined OTC corpus comprises a
total of 6, 139 annotated event-event TLINKS. We
also make use of the additional TLINKS indepen-
dently provided by (Bethard et al., 2007) for 129
of the 186 Timebank documents.

3 Task presentation and evaluation

3.1 An example
We illustrate the task of event ordering using a
small fabricated, simpliﬁed example:

the ﬁnancial crisise2,

Fortis bank investede1 in junk bonds
before
but
them during
got ride3 of most of
the crisise2bis. However,
the insti-
tution still went bankrupte4 a year
later.

1Both corpora are freely available from http://www.

timeml.org/site/timebank/timebank.html.

252

The annotation for this temporal structure would
include the following relations: e1 is temporally
before e2, e3 is temporally included in e2, and e3
is before e4. The coreference relation between e2
and e2bis implies the equality of their temporal ex-
tension. Of course all these events may in theory
be related temporally to almost any other event in
the text. Events are also anchored to temporal ex-
pressions explicitly, and this is usually considered
as a separate, much easier task. We will use this
example throughout the rest of our presentation.

3.2 Comparing temporal annotations
Due to possible inferences, there are often many
equivalent ways to express the same ordering of
events, so comparisons between annotation and
reference event-event pairs cannot rely on simple
precision/recall measures.

Consider the above example and assume the
following annotation: e1 is before e2, e3 is in-
cluded in e2, and e3 is before e3. Without going
into too much detail about the semantics of the re-
lations used, one expects annotators to agree with
the fact that it entails that e1 is before e3, among
other things. So the annotation is equivalent to a
larger set of relations. In some cases, the inferred
information is disjunctive (the relation holding be-
tween two events is a subset of possible “simple”
relations, such as “before or included”).

Nowadays, the given practice is to compute
some sort of transitive closure over the network of
constraints on temporal events (usually expressed
in the well-studied Allen algebra (Allen, 1983)),
and compute agreements over the saturated struc-
tures. Speciﬁcally, we can compare the sets of
simple temporal relations that are deduced from
it (henceforth, the “strict” metric), or measure the
agreement between the whole graphs, including
disjunctions (Verhagen et al., 2007) (henceforth,
the “relaxed” metric).2 Under this latter met-
ric, precision (resp. recall) of a prediction for a
pair of events consisting of a set S of relations
with respect to a set of relations R inferred from
the reference, is computed as |S ∩ R|/|S| (resp.
|S ∩ R|/|R|).

2Taking into account disjunctions means giving partial
credit to disjunctions approximating the reference relation
(possibly disjunctive itself), see next section.

b

e1

e1

b

b

di

di

e2

e3

e2

e3

b

b

e4

e1

e4

e1

b

e2

b

e3

e2

b

e3

di,ﬁ,o,m
e4

e4

b

Figure 1: Two non-equivalent annotations of the
same situations (left) and their transitive closure
in Allen’s algebra (right, with new relations only).
b stands for Allen’s before relation, m for meet, o
for overlap, di and ﬁ for the inverses of during and
ﬁnish, respectively.

Figure 1 illustrates the point of these “satu-
rated” representations, showing two raw annota-
tions of our example on the left (top and bottom)
and their closures on the right. The raw annota-
tions share only 2 relations (between e1 and e2,
and e3 and e4), but their transitive closures agree
also on the relations between e1 and e3, e1 and
e4, and e3 and e4. They still differ on the rela-
tion between e2 and e4, but only because one is
much more speciﬁc than the other, something that
can only be taken into account by a partial credit
scoring function.

For this example, the “strict” metric yields pre-
cision and recall scores of 5/5 and 5/6, when
comparing the top annotation against the bottom
one. By contrast, the “relaxed” metric (introduced
in the TempEval-07) yields precision and recall
scores of (5+0.2)/6 and 6/6, respectively.

We now turn to the issue of the set of relations
chosen for the task of expressing temporal infor-
mation in texts.

4 Temporal representations

Because of the inferential properties of temporal
relations, we have seen that the same situation can
be expressed in different ways, and some rela-
tions can be deduced from others. The need for

253

a precise reasoning framework has been present
in previous attempts at the task (Setzer et al.,
2006), and people have moved to a set of hand-
made rules over ad hoc relations to more widely
accepted temporal reasoning frameworks, such as
algebras of temporal relations, the most famous
being Allen’s interval algebra.

An algebra of relations can be deﬁned on any
set of relations that are mutually exclusive (two
relations cannot hold at the same time between
two entities) and exhaustive (at least one relation
must hold between two given entities). The alge-
bra starts from a set of simple, atomic, relations
U = {r1, r2, ...}, and a general relation is a sub-
set of U, interpreted as a disjunction of the rela-
tions it contains. From there, we can deﬁne union
and intersection of relations as classical set union
and intersection of the base relations they consist
of. Moreover, one can deﬁne a composition of re-
lations as follows:

(r1 ◦ r2)(x, z) ↔ ∃y r1(x, y) ∧ r2(y, z)
In words, a relation between x and z can be
computed from what is known between (x and
y) and (y and z). By computing beforehand the
n× n compositions of base relations of U, we can
compute the composition of any two general rela-
tions (because r ∩ r0 =Ø when r, r0 are basic and
r 6= r0):
{r1, r2, ...rk} ◦ {s1, s2, ...sm} =[i,j

(ri ◦ sj)

Saturating the graph of
temporal constraints
means applying these rules to all compatible pairs
of constraints in the graph and iterating until a
ﬁxpoint is reached. In Allen’s algebra there are
13 relations, determined by the different relations
that can hold between two intervals endpoints (be-
fore, equals, after). These relations are: b (be-
fore), m (meet), o (overlap), s (start), f (ﬁnish), d
(during), their inverses (bi, mi, oi, si, ﬁ, di) and =
(equal), see ﬁgure 2.3

It is important to see that a general approach
to temporal ordering of events cannot restrict it-
self to a subset of these and still use the power of
3TimeML uses somewhat different names, with obvious
mappings, except ibefore (“immediately before”) for m, and
iafter (“immediately after”) for mi.

Figure 2: Allen’s thirteen relations between two
temporal intervals

for

language expressions,

inferences to complete a situation, because com-
position of information is stable only on restricted
subsets. And using all of them means generating
numerous disjunctions of relations.
Allen relations are convenient

reason-
too precise for rep-
ing purposes, but might
resenting natural
and
that’s why recent evaluation campaigns such as
TempEval-07 have settled on vaguer representa-
tions. TempEval-07 uses three relations called be-
fore, overlaps and after, which we note bt, ot,
and bit.4 These all correspond to disjunctions
of Allen relations: {b,m}a, {o,d,s,=,f}a and its
inverse, and {bi,mi}a, respectively. These rep-
resentations can be converted to Allen relations,
over which the same inference procedures can be
applied, and then expressed back as (potentially
disjunctive) TempEval relations. They thus form
a sub-algebra of Allen’s algebra, if we add their
possible disjunctions.

In fact, starting from the base relations, only
{b,o}t, {bi,o}t, and vague (i.e., the disjunction of
all relations) can be inferred (besides the base re-
lations). This is a consequence of the stability of
so-called convex relations in Allen algebra. Note
that an even simpler schema is used in (Chambers
and Jurafsky, 2008), where only TempEval before
and after and the vague relation are used.

We propose to consider yet another set of rela-
tion, namely relations from (Bruce, 1972). These
provide an intermediate level of representation,
since they include 7 simple relations. These are

4When it is not obvious, we will use subscript symbols
to indicate the particular algebra that is used (e.g., bt is the
before relation in TempEval).

before

meets

overlaps

X

X

X

X

Y

Y

Y

finishes

Y

Y

Y

during

starts

equals

X

X

X
Y

254

also expressible as disjunctions of Allen relations;
they are: before (bb), after (bib) (with the same
semantics as TempEval’s bt and bit), equals (=b,
same as =a), includes (i, same as Allen’s {s,d,f}a),
overlaps (ob, same as oa), included (ii) and is-
overlapped (oib),
their inverse relations. The
equivalences between the three algebras is shown
table 1.

Allen
before
meet
overlaps
starts
during
ﬁnishes
overlapsi
startsi
duringi
ﬁnishesi
meeti
beforei
equals

Tempeval
before

Bruce
before
overlaps

included

is-overlapped

overlaps

includes

after
equals

after
equals

Table 1: Correspondances between temporal al-
gebras. A relation ranging over multiple cells
is equivalent to a disjunction of all the relations
within these cells.

Considering a vaguer set is arguably more ad-
equate for natural language expressions while at
the same time this speciﬁc set preserves at least
the notions of temporal order and inclusion (con-
trary to the TempEval scheme), which have strong
inferential properties: they are both transitive, and
their composition yields simple relations; over-
lap allows for much weaker inferences. Figure 3
shows part of our example from the introduction
expressed in the three cases: with Allen relations,
the most precise, with Bruce relations and Tem-
pEval relations, with dotted lines showing the ex-
tent of the vagueness of the temporal situations in
each case (with respect to the most precise Allen
description). We can see that TempEval relations
lose quickly all information that is not before or
after, while Bruce preserves inference combining
precedence and temporal inclusion.

Information can be converted from one algebra
to the other, since vaguer algebras are based on re-
lations equivalent to disjunctions in Allen algebra.
But conversion from a precise relation to a vaguer
one and back to a more precise algebra leads to

information loss. Hence on ﬁgure 3, the original
Allen relation: e3 da e2 is converted to: e3 ot e2
in TempEval, which converts back into the much
less informative: e3 {o, d, s, =, f, oi, si, ﬁ, di}a e2.
We will use these translations during our system
evaluation to have a common comparison point
between representations.

5 Models

5.1 Algebra-based classiﬁers
In order to compare the impact of the different al-
gebras described in section 4, we build three event
pair classiﬁcation models corresponding to each
relation set. The resulting Allen-based, Bruce-
based, and Tempeval-based models therefore con-
tain 13, 7, and 3 class labels, respectively.5 For
obvious sparsity issues, we did not include classes
corresponding to disjunctive relations, as there are
2|R| possible disjunctions for each relation set R.
For training our models, we experiment with 4
various conﬁgurations that correspond to ways of
expanding the set of training examples. Speciﬁ-
cally, these conﬁgurations vary in: (i) whether or
not we added the additional “Bethard relations” to
the initial OTC annotations (Bethard et al., 2007),
(ii) whether or not we applied saturation over the
set of annotated relations.

5.2 Features
Our feature set for the various models is similar
to that used by previous work, including binary
features that encode event string as well as the ﬁve
TimeML attributes and their possible values:

I-state I-

report, aspectual, state,

• aspect: none, prog, perfect, prog perfect
• class:
action, perception, occurrence
• modality: none, to, should, would, could
can, might
• polarity: positive, negative
• tense: none, present, past, future
5Our TempEval model actually has a fourth label for the
identity relation. The motivations behind the inclusion of this
extra label are: (i) this relation is linguistically motivated and
comparatively easy to learn (for a lot of instances of this rela-
tion are cases of anaphora, which are often signaled by iden-
tical strings) (ii) this relation triggers a lot of speciﬁc infer-
ences.

255

e3

e2

e1

Time

e3

e2

e1

Time

e3

e2

e1

Time

(a) Allen:
(e1bae2 ∧ e3dae2) → e1bae3

(b) Bruce:
(e1bbe2 ∧ e3dbe2) → e1bbe3

(c) Tempeval:
(e1bte2 ∧ e3ote2) → e1{bt, ot}e3

Figure 3: Comparing loss of inferential power in algebras: hard lines show the actual temporal
model, exactly expressed in Allen relations (a); dotted lines show the vagueness induced by alterna-
tive schemes, and the inference that can or cannot still be made in each algebra, (b) and (c).

Additional binary features check agreement for
same attribute (e.g., the same tense). Finally, we
add features that represent the distance between
two events (in number of sentences, and in num-
ber of intervening events). 6

5.3 Training set generation
Our generic training procedure works as follows.
For each document, we scan events in their order
of appearance in the text. We create a training
instance inst(ei,ej ) for each ordered pair of events
(ei, ej): if (ei, ej) (resp. (ej, ei)) corresponds to
an annotated relation r, then we label inst(ei,ej )
with the label r (resp. its inverse r−1).

5.4 Parameter estimation
All of these classiﬁers are maximum entropy mod-
els (Berger et al., 1996). Parameter estimation
was performed with the Limited Memory Variable
Metric algorithm (Malouf, 2002) implemented in
the Megam package.7

5.5 Decoding
We consider two different decoding procedures.
The ﬁrst one simply mirrors the training proce-
dure just described, scanning pairs of events in the
order of the text, and sending each pair to the clas-
siﬁer. The pair is then labeled with the label out-
putted by the classiﬁer (i.e., the label receiving the
6These were also encoded as binary features, and the var-
ious feature values were binned in order to avoid sparseness.
from http://www.cs.utah.edu/

7Available

~hal/megam/.

highest probability). No attempt is made to guar-
antee the consistency of the ﬁnal temporal graph.
Our second inference procedure works as fol-
lows. As in the previous method, we scan the
events in the order of the text, and create ordered
pairs of events that we then submit to the classiﬁer.
But the difference is that we saturate the graph af-
ter each classiﬁcation decision to make sure that
the graph created so far is coherent. In case where
the classiﬁer predicts a relation whose addition re-
sults in an incoherent graph, we try the next high-
est probability relation, and so on, until we ﬁnd
a coherent graph. This greedy procedure is simi-
lar to the Natural Reading Order (NRO) inference
procedure described by (Bramsen et al., 2006).

6 Experiments and results
We perform two main series of experiments for
comparing our different models. In the ﬁrst series,
we measure the accuracy of the Allen-, Bruce-
, and Tempeval-based models on predicting the
correct relation for the event-event TLINKS an-
notated in the corpus.
In the second series, we
saturate the event pair relations produced by the
classiﬁers (combined with NRO search to en-
force global coherence) and compare the pre-
dicted graphs against the saturated event-event
TLINKS.

6.1 Experiment settings
All our models are trained and tested with 5-fold
cross-validation on the OTC documents. For eval-

256

uation, we use simple accuracy for the ﬁrst se-
ries of experiments, and two “strict” and “relaxed”
precision/recall measures described in section 3
for the other series. For each type of measures,
we report scores with respect to both Allen and
TemEval relation sets. All scores are reported
using macro-averaging. Out of the 259 tempo-
ral graphs present in OTC, we found that 54 of
them were actually inconsistent when saturated;
the corresponding documents were therefore left
out of the evaluation.8 Given the rather expensive
procedure involved in the NRO decoding (saturat-
ing an inconsistent graph “erases” all relations),
we skipped 8 documents wich were much longer
than the rest, leaving us with 197 documents for
our ﬁnal experiments.

6.2 Event-event classiﬁcation
Table 2 summarizes the accuracy scores of the
different classiﬁers on the event-event TLINKS
of OTC. We only report the best conﬁguration
for each model. For the TempEval-based model,
we found that the best training setting was when
Bethard annotations were added to the original
TimeML annotations, but with no saturation.9 For
Allen and Bruce models, neither Bethard’s re-
lations nor saturation helps improve classiﬁca-
tion accuracy.
In fact, saturation degrades per-
formance, which can be explained by the fact
that saturation reinforces the bias towards already
over-represented relations.10 The best accuracy
performances are obtained by the Allen-based and
TempEval-based classiﬁers, each one performing
better in its own algebra (with 47.0% and 54.0%).
This is not surprising, since these classiﬁers were
speciﬁcally trained to optimize their respective
metrics. The Bruce-based classiﬁer is slightly bet-
ter than the Allen-based one in TempEval, but also
slightly worse than TempEval-based classiﬁer in
Allen.

8Because there is no way to trace the relation(s) respon-
sible for an inconsistency without analysing the whole set of
annotations of a text, and considering that it usually happens
on very long texts, we did not attempt to manually correct
the annotations.

9This is actually consistent with similar ﬁndings made by

(Chambers and Jurafsky, 2008).

10For instance, for Allen relations, there are roughly 50%
of before-after relations before saturation but 73% of them
after saturation.

Allen Acc. TempEval Acc.

Allen
Bruce
TempEval

47.0
N/A
N/A

48.9
49.3
54.0

Table 2: Accuracy scores for Allen, Bruce, and
TempEval classiﬁers on event-event TLINKS, ex-
pressed in Allen or TempEval algebra. Scores for
Bruce and TempEval models into Allen are left
out, since they predict (through conversion) dis-
junctive relations for all relations but equality.

Our accuracy scores for Allen, and TempEval-
based classiﬁers are somewhat lower than the ones
reported for similar systems by (Mani et al., 2006)
and (Chambers and Jurafsky, 2008), respectively.
These differences are likely to come from the fact
that: (i) (Mani et al., 2006) perform a 6-way clas-
siﬁcation, and not a 13-way classiﬁcation11, and
(ii) (Chambers and Jurafsky, 2008) use a relation
set that is even more restrictive than TempEval’s.

6.3 Saturated graphs
Table 3 summarizes the various precision/recall
scores of the graph obtained by saturating the clas-
siﬁers predictions (potentially altered by NRO)
against the event-event saturated graph. These re-
sults contrast with the accuracy results presented
in table 2: while the TempEval-based model was
the best model in classiﬁcation accuracy in Tem-
pEval, it is now outperformed by both the Allen-
and Bruce-based systems (this with or with us-
ing NRO). The best system in TempEval is actu-
ally Bruce-based system, with 52.9 and 62.8 for
the strict/relaxed metrics, respectively. The re-
sults suggest that this algebra might actually of-
fer the best trade-off between learnanility and ex-
pressive power. The use of NRO to restore global
coherence yields important gains (10 points) in
the relaxed metric for both Allen- and Bruce-
based systems (although they do not convert into
gains in the strict metric). Unsuprisingly, the
best model on the Allen set remains Allen-based
model (and this time the use of NRO results in
gains on the strict metric). Predictions without

11This is only possible because they order the event-event

pairs before submitting them to the classiﬁer.

257

System

Allen

Tempeval

RELAX

STRICT

RELAX

STRICT

R
57.5
Allen
46.0
Bruce
37.1
Tempeval
44.8
AllenN RO
46.3
BruceN RO
TempevalN RO 37.1

P
46.7
39.0
35.9
60.1
53.1
35.9

F1
51.5
42.1
36.5
51.3
49.5
36.5

R
49.6
18.0
14.0
57.2
13.9
13.9

P
56.2
44.0
44.0
62.9
45.3
44.3

F1
52.7
25.9
21.2
59.9
21.2
21.2

R
62.0
62.9
49.3
63.8
65.5
49.3

P
50.3
52.6
47.1
67.0
71.8
47.1

F1
55.5
57.3
48.2
65.3
68.5
48.2

R
50.4
50.9
21.7
45.2
46.6
21.7

P
57.1
57.0
44.2
60.6
61.1
44.2

F1
53.6
53.8
29.1
51.8
52.9
29.1

Table 3: Comparing Allen-, Bruce-, Tempeval-based classiﬁers saturated predictions on saturated event-
event graph. The N RO subscript indicates whether the system uses NRO or not. Evaluation are given
with respect to both Allen and Tempeval relation sets.

NRO yielded between 7.5 and 9% of inconsistent
saturated graphs that were ignored by the evalua-
tion, which means this impacted recall measures
only.

7 Related work

Early work on temporal ordering (Passonneau,
1988; Webber, 1988; Lascarides and Asher, 1993)
concentrated on studying the knowledge sources
at play (such as tense, aspect, lexical semantics,
rhetorical relations). The development of anno-
tated resources like the TimeBank corpus (Puste-
jovsky et al., 2003) has triggered the development
of machine learning systems (Mani et al., 2006;
Tatu and Srikanth, 2008; Chambers and Jurafsky,
2008).

More recent work uses automatic classiﬁca-
tion methods, based on the TimeBank and Ac-
quaint corpus, either as is, with inferential enrich-
ment for training (Mani et al., 2006; Chambers
et al., 2007), or supplied with the corrections of
(Bethard et al., 2007), or are restricted to selected
contexts, such as intra-sentential event relations
(Li et al., 2004; Lapata and Lascarides, 2006). All
of these assume that event pairs are preselected,
so the task is only to determine what is the most
likely relation between them. The best scores
are obtained with the added assumption that the
event-event pair can be pre-ordered (thus reduc-
ing the number of possible labels by 2).

More recently, (Bramsen et al., 2006) and sub-
sequently (Chambers and Jurafsky, 2008) pro-
pose to use an Integer Linear Programming solver

to enforce the consistency of a network of con-
straints while maximizing the score of local clas-
siﬁcation decisions. But these are restricted to the
relations BEFORE and AFTER, which have very
strong inference properties that cannot be gener-
alised to other relations. The ILP strategy is not
likely to scale up very well for richer relation sets,
for the number of possible relations between two
events (and thus the number of variables to put in
the LP solver for each pair) is the order of 2|R|
(where R is the relation set), and each transitiv-
ity constraints generates an enormous amount of
constraints.

8 Conclusion
We have investigated the role played by ontolog-
ical choices in temporal representations by com-
paring three algebras with different granularities
of relations and inferential powers. Our experi-
ments on the Timebank/AQUAINT reveal that the
TempEval relation set provides the best overall
classiﬁcation accuracy, but it provides much less
informative temporal structures, and it does not
provide enough inferences for being useful for en-
forcing consistency. By contrast, the other two
relation sets are signiﬁcantly harder to learn, but
provide more richer inferences and are therefore
more useful when global consistency is important.
Bruce’s 7 relations-based model appears to per-
form best in the TempEval evaluation, suggesting
that this algebra provides the best trade-off be-
tween learnability and expressive power.

258

of the 42nd Meeting of the Association for Compu-
tational Linguistics (ACL’04), Main Volume, pages
582–588, Barcelona, Spain, July.

Malouf, Robert. 2002. A comparison of algorithms
for maximum entropy parameter estimation. In Pro-
ceedings of the Sixth Workshop on Natural Lan-
guage Learning, pages 49–55, Taipei, Taiwan.

Mani,

Inderjeet, Marc Verhagen, Ben Wellner,
Chong Min Lee, and James Pustejovsky. 2006. Ma-
chine learning of temporal relations. In Proceedings
of the 21st International Conference on Computa-
tional Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics, pages
753–760, Sydney, Australia, July. Association for
Computational Linguistics.

Passonneau, Rebecca J. 1988. A computational model
of the semantics of tense and aspect. Computational
Linguistics, 14(2):44–60.

Pustejovsky,

James, Patrick Hanks, Roser Saurí,
Andrew See, Robert Gaizauskas, Andrea Setzer,
Dragomir Radev, Beth Sundheim, David Day, Lisa
Ferro, and Marcia Lazo. 2003. The TIMEBANK
Corpus.
In Proceedings of Corpus Linguistics,
pages 647–656, Lancaster University, UK, March.

Setzer, Andrea, Robert Gaizauskas, and Mark Hepple.
2006. The Role of Inference in the Temporal An-
notation and Analysis of Text. Language Resources
and Evaluation, 39:243–265.

Tatu, Marta and Munirathnam Srikanth. 2008. Ex-
periments with reasoning for temporal relations be-
tween events.
In Proceedings of the 22nd Inter-
national Conference on Computational Linguistics
(Coling 2008), pages 857–864, Manchester, UK,
August. Coling 2008 Organizing Committee.

Verhagen, Marc, Robert Gaizauskas, Franck Schilder,
Mark Hepple, Graham Katz, and James Puste-
jovsky. 2007. SemEval-2007 - 15: TempEval Tem-
poral Relation Identiﬁcation. In Proceedings of Se-
mEval workshop at ACL 2007, Prague, Czech Re-
public, June. Association for Computational Lin-
guistics, Morristown, NJ, USA.

Webber, Bonnie Lynn.

1988. Tense as discourse
anaphor. Computational Linguistics, 14(2):61–73.

References
Allen, James. 1983. Maintaining Knowledge about
Temporal Intervals. Communications of the ACM,
pages 832–843.

Berger, A., S. Della Pietra, and V. Della Pietra. 1996.
A maximum entropy approach to natural language
processing. Computational Linguistics, 22(1):39–
71.

Bethard, Steven, James H. Martin, and Sara Klingen-
stein. 2007. Timelines from text: Identiﬁcation of
syntactic temporal relations. In International Con-
ference on Semantic Computing, pages 11–18, Los
Alamitos, CA, USA. IEEE Computer Society.

Boguraev, Branimir and Rie Ando. 2005. TimeML-
compliant text analysis for temporal reasoning. In
Kaelbling, Leslie Pack and Fausto Giunchiglia, edi-
tors, Proceedings of IJCAI05, pages 997–1003.

Bramsen, Philip, Pawan Deshpande, Yoong Keok Lee,
and Regina Barzilay.
Inducing temporal
graphs. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Process-
ing, pages 189–198, Sydney, Australia, July. Asso-
ciation for Computational Linguistics.

2006.

Bruce, B. 1972. A model for temporal references and
its application in a question answering program. Ar-
tiﬁcial Intelligence, 3(1-3):1–25.

Chambers, Nathanael and Daniel Jurafsky.

2008.
Jointly combining implicit constraints improves
temporal ordering. In Proceedings of the 2008 Con-
ference on Empirical Methods in Natural Language
Processing, pages 698–706, Honolulu, Hawaii, Oc-
tober. Association for Computational Linguistics.

Chambers, Nathanael, Shan Wang, and Daniel Juraf-
sky. 2007. Classifying temporal relations between
events. In ACL. The Association for Computer Lin-
guistics.

Filatova, Elena and Eduard Hovy. 2001. Assigning
time-stamps to event-clauses. In Mani, I., J. Puste-
jovsky, and R Gaizauskas, editors, The Language of
Time: A Reader. Oxford University Press.

Lapata, Maria and Alex Lascarides. 2006. Learning
sentence-internal temporal relations. J. Artif. Intell.
Res. (JAIR), 27:85–117.

Lascarides, Alex and Nicholas Asher. 1993. Tem-
poral interpretation, discourse relations and com-
mon sense entailment. Linguistics and Philosophy,
16:437–493.

Li, Wenjie, Kam-Fai Wong, Guihong Cao, and Chunfa
Yuan. 2004. Applying machine learning to chi-
nese temporal relation resolution.
In Proceedings

