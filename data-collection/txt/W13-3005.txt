










































The Frobenius Anatomy of Relative Pronouns


Proceedings of the 13th Meeting on the Mathematics of Language (MoL 13), pages 41–51,
Sofia, Bulgaria, August 9, 2013. c©2013 Association for Computational Linguistics

The Frobenius Anatomy of Relative Pronouns

Stephen Clark
University of Cambridge

Computer Laboratory
sc609@cam.ac.uk

Bob Coecke
University of Oxford

Dept. of Computer Science
coecke@cs.ox.ac.uk

Mehrnoosh Sadrzadeh
Queen Mary, University of London

School of Electronic
Engineering and Computer Science

mehrnoosh.sadrzadeh@eecs.qmul.ac.uk

Abstract

This paper develops a compositional
vector-based semantics of relative pro-
nouns within a categorical framework.
Frobenius algebras are used to formalise
the operations required to model the se-
mantics of relative pronouns, including
passing information between the relative
clause and the modified noun phrase, as
well as copying, combining, and discard-
ing parts of the relative clause. We de-
velop two instantiations of the abstract se-
mantics, one based on a truth-theoretic ap-
proach and one based on corpus statistics.

1 Introduction

Ordered algebraic structures and sequent calculi
have been used extensively in Computer Science
and Mathematical Logic. They have also been
used to formalise and reason about natural lan-
guage. Lambek (1958) used the ordered alge-
bra of residuated monoids to model grammatical
types, their juxtapositions and reductions. Rela-
tional words such as verbs have implicative types
and are modelled using the residuals to the monoid
multiplication. Later, Lambek (1999) simplified
these algebras in favour of pregroups. Here, there
are no binary residual operations, but each element
of the algebra has a left and a right residual.

In terms of semantics, pregroups do not natu-
rally lend themselves to a model-theoretic treat-
ment (Montague, 1974). However, pregroups are
suited to a radically different treatment of seman-
tics, namely distributional semantics (Schütze,
1998). Distributional semantics uses vector spaces
based on contextual co-occurrences to model the
meanings of words. Coecke et al. (2010) show
how a compositional semantics can be developed
within a vector-based framework, by exploiting
the fact that vector spaces with linear maps and

pregroups both have a compact closed categor-
ical structure (Kelly and Laplaza, 1980; Preller
and Lambek, 2007). Some initial attempts at im-
plementation include Grefenstette and Sadrzadeh
(2011a) and Grefenstette and Sadrzadeh (2011b).

One problem with the distributional approach is
that it is difficult to see how the meanings of some
words — e.g. logical words such as and, or, and
relative pronouns such as who, which, that, whose
— can be modelled contextually. Our focus in this
paper is on relative pronouns in the distributional
compositional setting.

The difficulty with pronouns is that the contexts
in which they occur do not seem to provide a suit-
able representation of their meanings: pronouns
tend to occur with a great many nouns and verbs.
Hence, if one applies the contextual co-occurrence
methods of distributional semantics to them, the
result will be a set of dense vectors which do
not discriminate between different meanings. The
current state-of-the-art in compositional distribu-
tional semantics either adopts a simple method to
obtain a vector for a sequence of words, such as
adding or mutliplying the contextual vectors of
the words (Mitchell and Lapata, 2008), or, based
on the grammatical structure, builds linear maps
for some words and applies these to the vector
representations of the other words in the string
(Baroni and Zamparelli, 2010; Grefenstette and
Sadrzadeh, 2011a). Neither of these approaches
produce vectors which provide a good representa-
tion for the meanings of relative clauses.

In the grammar-based approach, one has to as-
sign a linear map to the relative pronoun, for in-
stance a map f as follows:
−−−−−−−−−−−−−→
men who like Mary = f(−−→men,−−−−−−→like Mary)

However, it is not clear what this map should be.
Ideally, we do not want it to depend on the fre-
quency of the co-occurrence of the relative pro-
noun with the relevant basis vectors. But both

41



of the above mentioned approaches rely heavily
on the information provided by a corpus to build
their linear maps. The work of Baroni and Zam-
parelli (2010) uses linear regression and approxi-
mates the context vectors of phrases in which the
target word has occurred, and the work of Grefen-
stette and Sadrzadeh (2011a) uses the sum of Kro-
necker products of the arguments of the target
word across the corpus.

The semantics we develop for relative pronouns
and clauses uses the general operations of a Frobe-
nius algebra over vector spaces (Coecke et al.,
2008) and the structural categorical morphisms of
vector spaces. We do not rely on the co-occurrence
frequencies of the pronouns in a corpus and only
take into account the structural roles of the pro-
nouns in the meaning of the clauses. The computa-
tions of the algebra and vector spaces are depicted
using string diagrams (Joyal and Street, 1991),
which depict the interactions that occur among the
words of a sentence. In the particular case of rel-
ative clauses, they visualise the role of the rela-
tive pronoun in passing information between the
clause and the modified noun phrase, as well as
copying, combining, and even discarding parts of
the relative clause.

We develop two instantiations of the abstract se-
mantics, one based on a truth-theoretic approach,
and one based on corpus statistics, where for the
latter the categorical operations are instantiated as
matrix multiplication and vector component-wise
multiplication. As a result, we will obtain the fol-
lowing for the meaning of a subject relative clause:

−−−−−−−−−−−−−→
men who like Mary = −−→men� (love×−−−→Mary)

The rest of the paper introduces the categorical
framework, including the formal definitions rel-
evant to the use of Frobenius algebras, and then
shows how these structures can be used to model
relative pronouns within the compositional vector-
based setting.

2 Compact Closed Categories and
Frobenius Algebras

This section briefly reviews compact closed cate-
gories and Frobenius algebras. For a formal pre-
sentation, see (Kelly and Laplaza, 1980; Kock,
2003; Baez and Dolan, 1995), and for an informal
introduction see Coecke and Paquette (2008).

A compact closed category has objects A,B;
morphisms f : A → B; a monoidal tensor A⊗ B

that has a unit I; and for each objectA two objects
Ar andAl together with the following morphisms:

A⊗Ar
�rA−→ I

ηrA−→ Ar ⊗A

Al ⊗A
�lA−→ I

ηlA−→ A⊗Al

These morphisms satisfy the following equalities,
sometimes referred to as the yanking equalities,
where 1A is the identity morphism on object A:

(1A ⊗ �lA) ◦ (ηlA ⊗ 1A) = 1A
(�rA ⊗ 1A) ◦ (1A ⊗ ηrA) = 1A
(�lA ⊗ 1A) ◦ (1Al ⊗ ηlA) = 1Al
(1Ar ⊗ �rA) ◦ (ηrA ⊗ 1Ar) = 1Ar

A pregroup is a partial order compact closed
category, which we refer to as Preg. This means
that the objects of Preg are elements of a par-
tially ordered monoid, and between any two ob-
jects p, q ∈ Preg there exists a morphism of type
p → q iff p ≤ q. Compositions of morphisms
are obtained by transitivity and the identities by
reflexivity of the partial order. The tensor of the
category is the monoid multiplication, and the ep-
silon and eta maps are as follows:

�rp = p · pr ≤ 1 ηrp = 1 ≤ pr · p
�lp = p

l · p ≤ 1 ηlp = 1 ≤ p · pl

Finite dimensional vector spaces and linear
maps also form a compact closed category, which
we refer to as FVect. Finite dimensional vector
spaces V,W are objects of this category; linear
maps f : V → W are its morphisms with compo-
sition being the composition of linear maps. The
tensor product V ⊗W is the linear algebraic ten-
sor product, whose unit is the scalar field of vec-
tor spaces; in our case this is the field of reals R.
As opposed to the tensor product in Preg, the ten-
sor between vector spaces is symmetric; hence we
have a naturual isomorphism V ⊗W ∼= W ⊗ V .
As a result of the symmetry of the tensor, the two
adjoints reduce to one and we obtain the following
isomorphism:

V l ∼= V r ∼= V ∗

where V ∗ is the dual of V . When the basis vectors
of the vector spaces are fixed, it is further the case
that the following isomorphism holds as well:

V ∗ ∼= V

42



Elements of vector spaces, i.e. vectors, are rep-
resented by morphisms from the unit of tensor to
their corresponding vector space; that is−→v ∈ V is
represented by the morphism R

−→v−→ V ; by linear-
ity this morphism is uniquely defined when setting
1 7→ −→v .

Given a basis {ri}i for a vector space V , the ep-
silon maps are given by the inner product extended
by linearity; i.e. we have:

�l = �r : V ∗ ⊗ V → R

given by:∑
ij

cij ψi ⊗ φj 7→
∑
ij

cij〈ψi | φj〉

Similarly, eta maps are defined as follows:

ηl = ηr : R→ V ⊗ V ∗

and are given by:

1 7→
∑
i

ri ⊗ ri

A Frobenius algebra in a monoidal category
(C,⊗, I) is a tuple (X,∆, ι, µ, ζ) where, for X
an object of C, the triple (X,∆, ι) is an internal
comonoid; i.e. the following are coassociative and
counital morphisms of C:

∆: X → X ⊗X ι : X → I

Moreover (X,µ, ζ) is an internal monoid; i.e. the
following are associative and unital morphisms:

µ : X ⊗X → X ζ : I → X

And finally the ∆ and µmorphisms satisfy the fol-
lowing Frobenius condition:

(µ⊗ 1X) ◦ (1X ⊗∆) = ∆ ◦ µ = (1X ⊗ µ) ◦ (∆⊗ 1X)

Informally, the comultiplication ∆ decomposes
the information contained in one object into two
objects, and the multiplication µ combines the in-
formation of two objects into one.

Frobenius algebras were originally introduced
in the context of representation theorems for group
theory (Frobenius, 1903). Since then, they have
found applications in other fields of mathematics
and physics, e.g. in topological quantum field the-
ory (Kock, 2003). The above general categorical
definition is due to Carboni and Walters (1987). In

what follows, we use Frobenius algebras that char-
acterise vector space bases (Coecke et al., 2008).

In the category of finite dimensional vector
spaces and linear maps FVect, any vector space V
with a fixed basis {−→vi}i has a Frobenius algebra
over it, explicitly given by:

∆ :: −→vi 7→ −→vi ⊗−→vi ι :: −→vi 7→ 1

µ :: −→vi ⊗−→vj 7→ δij−→vi ζ :: 1 7→
∑

i
−→vi

where δij is the Kronecker delta.
Frobenius algebras over vector spaces with or-

thonormal bases are moreover isometric and com-
mutative. A commutative Frobenius Algebra satis-
fies the following two conditions for σ : X⊗Y →
Y ⊗X , the symmetry morphism of (C,⊗, I):

σ ◦∆ = ∆ µ ◦ σ = µ

An isometric Frobenius Algebra is one that satis-
fies the following axiom:

µ ◦∆ = 1

The vector spaces of distributional models have
fixed orthonormal bases; hence they have isomet-
ric commutative Frobenius algebras over them.

The comultiplication ∆ of an isometric com-
mutative Frobenius Algebra over a vector space
encodes vectors of lower dimensions into vectors
of higher dimensional tensor spaces; this oper-
ation is referred to as copying. In linear alge-
braic terms, ∆(−→v ) ∈ V ⊗ V is a diagonal matrix
whose diagonal elements are weights of −→v ∈ V .
The corresponding multiplication µ encodes vec-
tors of higher dimensional tensor spaces into lower
dimensional spaces; this operation is referred to
as combining. For −→w ∈ V ⊗ V , we have that
µ(−→w ) ∈ V is a vector consisting only of the diag-
onal elements of −→w .

As a concrete example, take V to be a two di-
mensional space with basis {−→v1 ,−→v2}; then the ba-
sis of V ⊗V is {−→v1⊗−→v1 ,−→v1⊗−→v2 ,−→v2⊗−→v1 ,−→v2⊗−→v2}.
For a vector v = a−→v1 + b−→n2 in V we have:

∆(v) = ∆

(
a
b

)
=

(
a 0
0 b

)
= a−→v1⊗−→v1+b−→v2⊗−→v2

And for a matrix w = a−→v1 ⊗ −→v1 + b−→v1 ⊗ −→v2 +
c−→v2 ⊗−→v1 + d−→v2 ⊗−→v2 in V ⊗ V , we have:

µ(w) = µ

(
a b
c d

)
=

(
a
d

)
= a−→v1 + d−→v2

43



3 String Diagrams

The framework of compact closed categories and
Frobenius algebras comes with a complete di-
agrammatic calculus that visualises derivations,
and which also simplifies the categorical and vec-
tor space computations. Morphisms are depicted
by boxes and objects by lines, representing their
identity morphisms. For instance a morphism
f : A → B, and an object A with the identity ar-
row 1A : A→ A, are depicted as follows:

f

A

B

A

The tensor products of the objects and mor-
phisms are depicted by juxtaposing their diagrams
side by side, whereas compositions of morphisms
are depicted by putting one on top of the other;
for instance the object A⊗B, and the morphisms
f ⊗ g and f ◦ h, for f : A → B, g : C → D, and
h : B → C, are depicted as follows:

f

A

B D

g

C f

A

B

h

C

A B

The � maps are depicted by cups, η maps
by caps, and yanking by their composition and
straightening of the strings. For instance, the di-
agrams for �l : Al ⊗ A → I , η : I → A ⊗ Al and
(�l ⊗ 1A) ◦ (1A ⊗ ηl) = 1A are as follows:

Al

A Al
A

Al A Al = A

The composition of the � and η maps with other
morphisms is depicted as before, that is by juxta-
posing them one above the other. For instance the
diagrams for the compositions (1Bl ⊗ f) ◦ �l and
ηl ◦ (1Al ⊗ f) are as follows:

B

f

A

Bl

Al A

f

B

As for Frobenius algebras, the diagrams for the
monoid and comonoid morphisms are as follows:

(µ, ζ) (∆, ι)

with the Frobenius condition being depicted as:

= =

The defining axioms guarantee that any picture de-
picting a Frobenius computation can be reduced to
a normal form that only depends on the number of
input and output strings of the nodes, independent
of the topology. These normal forms can be sim-
plified to so-called ‘spiders’:

=

· · ·

· · ·
···

···

In the category FVect, apart from spaces V,W ,
which are objects of the category, we also have
vectors −→v ,−→w . These are depicted by their repre-
senting morphisms and as triangles with a number
of strings emanating from them. The number of
strings of a triangle denote the tensor rank of the
vector; for instance, the diagrams for−→v ∈ V,

−→
v′ ∈

V ⊗W , and
−→
v′′ ∈ V ⊗W ⊗ Z are as follows:

V W WV ZV
Application of a linear map to a vector is de-

picted using composition of their corresponding
morphisms. For instance, for f : V → W and
−→v ∈ V , the application f(−→v ) is depicted by the
composition I

−→v−→ V f−→W .

V

f

W

44



Applications of the Frobenius maps to vectors
are depicted in a similar fashion; for instance

µ(−→v ⊗ −→v ) is the composition I ⊗ I
−→v ⊗−→v−→ V ⊗

V
µ−→ V and ι(−→v ) is the composition I

−→v−→
V

ι−→ I , depicted as follows:

V V

V

V

4 Vector Space Interpretations

The grammatical structure of a language is en-
coded in the category Preg: objects are grammat-
ical types (assigned to words of the language) and
morphisms are grammatical reductions (encoding
the grammatical formation rules of the language).
For instance, the grammatical structure of the sen-
tence “Men love Mary” is encoded in the assign-
ment of types n to the noun phrases “men” and
“Mary” and nr ⊗ s⊗ nl to the verb “love”, and in
the reduction map �ln ⊗ 1s ⊗ �rn. The application
of this reduction map to the tensor product of the
word types in the sentence results in the type s:

(�ln ⊗ 1s ⊗ �rn)(n⊗ (nr ⊗ s⊗ nl)⊗ n)→ s

To each reduction map corresponds a string dia-
gram that depicts the structure of reduction:

n nrsnl n
Men love Mary

In Coecke et al. (2010) the pregroup types and
reductions are interpreted as vector spaces and lin-
ear maps, achieved via a homomorphic mapping
from Preg to FVect. Categorically speaking, this
map is a strongly monoidal functor:

F : Preg→ FVect

It assigns vector spaces to the basic types as fol-
lows:

F (1) = I F (n) = N F (s) = S

and to the compound types by monoidality as fol-
lows; for x, y objects of Preg:

F (x⊗ y) = F (x)⊗ F (y)

Monoidal functors preserve the compact structure;
that is the following holds:

F (xl) = F (xr) = F (x)∗

For instance, the interpretation of a transitive verb
is computed as follows:

F (nr ⊗ s⊗ nl) = F (nr)⊗ F (s)⊗ F (nl) =
F (n)∗ ⊗ F (s)⊗ F (n)∗ = N ⊗ S ⊗N

This interpretation means that the meaning vector
of a transitive verb is a vector in N ⊗ S ⊗N .

The pregroup reductions, i.e. the partial order
morphisms of Preg, are interpreted as linear maps:
whenever p ≤ q in Preg, we have a linear map
f≤ : F (p) → F (q). The � and η maps of Preg are
interpreted as the � and η maps of FVect. For in-
stance, the pregroup reduction of a transitive verb
sentence is computed as follows:

F (�rn ⊗ 1s ⊗ �rn) = F (�rn)⊗ F (1s)⊗ F (�ln) =
F (�n)

∗ ⊗ F (1s)⊗ F (�n)∗ = �N ⊗ 1S ⊗ �N

The distributional meaning of a sentence is ob-
tained by applying the interpretation of the pre-
group reduction of the sentence to the tensor prod-
uct of the distributional meanings of the words
in the sentence. For instance, the distributional
meaning of “Men love Mary” is as follows:

F (�rn ⊗ 1s ⊗ �ln)(
−−→
Men⊗

−−→
love⊗−−−→Mary)

This meaning is depictable via the following string
diagram:

N NSN N

Men love Mary

The next section applies these techniques to the
distributional interpretation of pronouns. The in-
terpretations are defined using: � maps, for appli-
cation of the semantics of one word to another; η
maps, to pass information around by bridging in-
termediate words; and Frobenius operations, for
copying and combining the noun vectors and dis-
carding the sentence vectors.

5 Modelling Relative Pronouns

In this paper we focus on the subject and object
relative pronouns, who(m), which and that. Ex-
amples of noun phrases with subject relative pro-
nouns are “men who love Mary”, “dog which ate
cats”. Examples of noun phrases with object rela-
tive pronouns are “men whom Mary loves”, “book

45



that John read”. In the final example, “book” is the
head noun, modified by the relative clause “that
John read”. The intuition behind the use of Frobe-
nius algebras to model such cases is the following.
In “book that John read”, the relative clause acts
on the noun (modifies it) via the relative pronoun,
which passes information from the clause to the
noun. The relative clause is then discarded, and
the modified noun is returned. Frobenius algebras
provide the machinery for all of these operations.

The pregroup types of the relative pronouns are
as follows:

nrnsln (subject)
nrnnllsl (object)

These types result in the following reductions:

nr s nl nn nr n sl n

Subject Rel-Pr Verb Object

nr s nlnn nr n nll sl
Object Rel-Pr Subject Verb

The meaning spaces of these pronouns are com-
puted using the mechanism described above:

F (nrnsln) = F (nr)⊗ F (n)⊗ F (sl)⊗ F (n)
= N ⊗N ⊗ S ⊗N

F (nrnnllsl) = F (nr)⊗ F (n)⊗ F (nll)⊗ F (sl)
= N ⊗N ⊗N ⊗ S

The semantic roles that these pronouns play are
reflected in their categorical vector space mean-
ings, depicted as follows:

Subj:

N N S N

Obj:

N N SN

with the following corresponding morphisms:
Subj: (1N ⊗ µN ⊗ ζS ⊗ 1N ) ◦ (ηN ⊗ ηN )
Obj: (1N ⊗ µN ⊗ 1N ⊗ ζS) ◦ (ηN ⊗ ηN )

The diagram of the meaning vector of the sub-
ject relative clause interacting with the head noun
is as follows:

N S N NN N NN S

Subject Rel-Pronoun Verb Object

The diagram for the object relative clause is:

N S NNN N NN S

Object Rel-Pronoun Subject Verb

These diagrams depict the flow of information in
a relative clause and the semantic role of its rel-
ative pronoun, which 1) passes information from
the clause to the head noun via the η maps; 2) acts
on the noun via the µ map; 3) discards the clause
via the ζ map; and 4) returns the modified noun
via 1N . The � maps pass the information of the
subject and object nouns to the verb and to the rel-
ative pronoun to be acted on. Note that there are
two different flows of information in these clauses:
the ones that come from the grammatical structure
and are depicted by �maps (at the bottom of the di-
agrams), and the ones that come from the semantic
role of the pronoun and are depicted by η maps (at
the top of the diagrams).

The normal forms of these diagrams are:

N S N NN

Subject Verb Object

N S N NN

Subject Verb Object

Symbolically, they correspond to the following
morphisms:

(µN ⊗ ιS ⊗ �N )
(−−−−→

Subject⊗−−→Verb⊗−−−→Object
)

(�N ⊗ ιS ⊗ µN )
(−−−−→

Subject⊗−−→Verb⊗−−−→Object
)

The simplified normal forms will become useful in
practice when calculating vectors for such cases.

6 Vector Space Instantiations

In this section we demonstrate the effect of the
Frobenius operations using two example instan-
tiations. The first — which is designed perhaps

46



as a theoretical example rather than a suggestion
for implementation — is a truth-theoretic account,
similar to Coecke et al. (2010) but also allow-
ing for degrees of truth. The second is based on
the concrete implementation of Grefenstette and
Sadrzadeh (2011a).

6.1 Degrees of Truth
Take N to be the vector space spanned by a set
of individuals {−→n i}i that are mutually orthogo-
nal. For example, −→n 1 represents the individual
Mary, −→n 25 represents Roger the dog, −→n 10 rep-
resents John, and so on. A sum of basis vec-
tors in this space represents a common noun; e.g.
−−→man =

∑
i
−→n i, where i ranges over the basis vec-

tors denoting men. We take S to be the one dimen-
sional space spanned by the single vector

−→
1 . The

unit vector spanning S represents truth value 1, the
zero vector represents truth value 0, and the inter-
mediate vectors represent degrees of truth.

A transitive verb w, which is a vector in the
space N ⊗ S ⊗N , is represented as follows:

w :=
∑
ij

−→n i ⊗ (αij
−→
1 )⊗−→n j

if −→n i w’s −→n j with degree αij , for all i, j.
Further, since S is one-dimensional with its

only basis vector being
−→
1 , the transitive verb can

be represented by the following element ofN⊗N :∑
ij

αij
−→n i⊗−→n j if −→n i w’s−→n j with degree αij

Restricting to either αij = 1 or αij = 0 provides
a 0/1 meaning, i.e. either −→n i w’s −→n j or not.
Letting αij range over the interval [0, 1] enables
us to represent degrees as well as limiting cases
of truth and falsity. For example, the verb “love”,
denoted by love, is represented by:∑
ij

αij
−→n i⊗−→n j if −→n i loves−→n jwith degreeαij

If we take αij to be 1 or 0, from the above we
obtain the following:∑

(i,j)∈Rlove

−→n i ⊗−→n j

where Rlove is the set of all pairs (i, j) such that−→n i loves −→n j .
Note that, with this definition, the sentence

space has already been discarded, and so for this

−−−−−−−−−−−−−−−−−→
Subject who Verb Object :=

(µN ⊗ �N )
(−−−−→

Subject⊗−−→Verb⊗−−−→Object
)

=

(µN ⊗ �N )

∑
k∈K

−→n k ⊗(
∑
ij

αij
−→n i⊗−→n j)⊗

∑
l∈L

−→n l


=

∑
ij,k∈K,l∈L

αijµN (
−→n k ⊗−→n i)⊗ �N (−→n j ⊗−→n l)

=
∑

ij,k∈K,l∈L
αijδki

−→n iδjl

=
∑

k∈K,l∈L
αkl
−→n k

Figure 1: Meaning computation with a subject rel-
ative pronoun

instantiation the ι map, which is the part of the
relative pronoun interpretation designed to discard
the relative clause after it has acted on the head
noun, is not required.

For common nouns
−−−−→
Subject =

∑
k∈K
−→n k and−−−→

Object =
∑

l∈L
−→n l, where k and l range over

the sets of basis vectors representing the respec-
tive common nouns, the truth-theoretic meaning of
a noun phrase modified by a subject relative clause
is computed as in Figure 1. The result is highly in-
tuitive, namely the sum of the subject individuals
weighted by the degree with which they have acted
on the object individuals via the verb. A similar
computation, with the difference that the µ and �
maps are swapped, provides the truth-theoretic se-
mantics of the object relative clause:

∑
k∈K,l∈L

αkl
−→n l

The calculation and final outcome is best under-
stood with an example.

Now only consider truth values 0 and 1. Con-
sider the noun phrase with object relative clause
“men whom Mary loves” and takeN to be the vec-
tor space spanned by the set of all people; then the
males form a subspace of this space, where the ba-
sis vectors of this subspace, i.e. men, are denoted
by −→ml, where l ranges over the set of men which
we denote byM . We set “Mary” to be the individ-
ual
−→
f 1, “men” to be the common noun

∑
l∈M
−→ml,

47



−−−−−−−−−−−−−−−→
men whom Mary loves :=

(�N ⊗ µN )

−→f 1 ⊗ ( ∑
(i,j)∈Rlove

−→
f i ⊗−→mj)⊗

∑
l∈M

−→ml


=

∑
l∈M,(i,j)∈Rlove

�N (
−→
f 1 ⊗

−→
f i)⊗ µ(−→mj ⊗−→ml)

=
∑

l∈M,(i,j)∈Rlove

δ1iδjl
−→mj

=
∑

(1,j)∈Rlove|j∈M

−→mj

Figure 2: Meaning computation for example ob-
ject relative clause

and “love” to be as follows:

∑
(i,j)∈Rlove

−→
f i ⊗−→mj

The vector corresponding to the meaning of “men
whom Mary loves” is computed as in Figure 2.
The result is the sum of the men basis vectors
which are also loved by Mary.

The second example involves degrees of truth.
Suppose we have two females Mary

−→
f 1 and Jane−→

f 2 and four men −→m1,−→m2,−→m3,−→m4. Mary loves−→m1 with degree 1/4 and −→m2 with degree 1/2; Jane
loves −→m3 with degree 1/5; and −→m4 is not loved. In
this situation, we have:

Rlove = {(1, 1), (1, 2), (2, 3)}

and the verb love is represented by:

1/4(
−→
f 1⊗−→m1)+1/2(

−→
f 1⊗−→m2)+1/5(

−→
f 2⊗−→m3)

The meaning of “men whom Mary loves” is com-
puted by substituting an α1,j in the last line of Fig-
ure 2, resulting in the men whom Mary loves to-
gether with the degrees that she loves them:

∑
(1,j)∈Rlove|j∈M

α1j
−→mj = 1/4−→m1 + 1/2−→m2

“men whom women love” is computed as fol-

lows, where W is the set of women:∑
k∈W,l∈M,(i,j)∈Rlove

αij�N (
−→
f k ⊗

−→
f i)⊗ µ(−→mj ⊗−→ml)

=
∑

k∈W,l∈M,(i,j)∈Rlove

αijδkiδjl
−→mj

=
∑

(i,j)∈Rlove|i∈W,j∈M

αij
−→mj

= 1/4−→m1 + 1/2−→m2 + 1/5−→m3

The result is the men loved by Mary or Jane to-
gether with the degrees to which they are loved.

6.2 A Concrete Instantiation
In the model of Grefenstette and Sadrzadeh
(2011a), the meaning of a verb is taken to be “the
degree to which the verb relates properties of its
subjects to properties of its object”. Clark (2013)
provides some examples showing how this is an
intuitive defintion for a transitive verb in the cat-
egorical framework. This degree is computed by
forming the sum of the tensor products of the sub-
jects and objects of the verb across a corpus, where
w ranges over instances of the verb:

verb =
∑
w

(
−→
sbj⊗−→obj)w

Denote the vector space of nouns by N ; the above
is a matrix in N ⊗ N , depicted by a two-legged
triangle as follows:

N N
The verbs of this model do not have a sentence

dimension; hence no information needs to be dis-
carded when they are used in our setting, and so no
ιmap appears in the diagram of the relative clause.
Inserting the above diagram in the diagrams of the
normal forms results in the following for the sub-
ject relative clause (the object case is similar):

N N NN

Subject Verb Object

The abstract vectors corresponding to such dia-
grams are similar to the truth-theoretic case, with
the difference that the vectors are populated from
corpora and the scalar weights for noun vectors

48



are not necessarily 1 or 0. For subject and object
noun context vectors computed from a corpus as
follows:
−−−−→
Subject =

∑
k

Ck
−→n k

−−−→
Object =

∑
l

Cl
−→n l

and the verb a linear map:

Verb =
∑
ij

Cij
−→n i ⊗−→n j

computed as above, the concrete meaning of a
noun phrase modified by a subject relative clause
is as follows:∑

kijl

CkCijClµN (
−→n k ⊗−→n i)�N (−→n j ⊗−→n l)

=
∑
kijl

CkCijClδki
−→n kδjl

=
∑
kl

CkCklCl
−→n k

Comparing this to the truth-theoretic case, we see
that the previous αkl are now obtained from a cor-
pus and instantiated to CkCklCl. To see how the
above expression represents the meaning of the
noun phrase, decompose it into the following:∑

k

Ck
−→n k �

∑
kl

CklCl
−→n l

Note that the second term of the above, which is
the application of the verb to the object, modifies
the subject via point-wise multiplication. A simi-
lar result arises for the object relative clause case.

As an example, suppose that N has two dimen-
sions with basis vectors −→n 1 and −→n 2, and consider
the noun phrase “dog that bites men”. Define the
vectors of “dog” and “men” as follows:
−→
dog = d1−→n 1+d2−→n 2 −−→men = m1−→n 1+m2−→n 2

and the matrix of “bites” by:
b11−→n 1⊗−→n 2+b12−→n 1⊗−→n 2+b21−→n 2⊗−→n 1+b22−→n 2⊗−→n 2

Then the meaning of the noun phrase becomes:
−−−−−−−−−−−−→
dog that bites men :=

d1b11m1
−→n 1 + d1b12m2−→n 1 + d2b21m1−→n 2

+ d2b22m2
−→n 2 = (d1−→n 1 + d2−→n 2)�

((b11m1 + b12m2)
−→n 1 + (b21m1 + b22m2)−→n 2)

Using matrix notation, we can decompose the sec-
ond term further, from which the application of the
verb to the object becomes apparent:(

b11 b12
b21 b22

)
×
(
m1
m2

)

Hence for the whole clause we obtain:

−→
dog� (bites×−−→men)

Again this result is highly intuitive: assuming
that the basis vectors of the noun space represent
properties of nouns, the meaning of “dog that bites
men” is a vector representing the properties of
dogs, which have been modified (via multiplica-
tion) by those properties of individuals which bite
men. Put another way, those properties of dogs
which overlap with properties of biting things get
accentuated.

7 Conclusion and Future Directions

In this paper, we have extended the compact cate-
gorical semantics of Coecke et al. (2010) to anal-
yse meanings of relative clauses in English from
a vector space point of view. The resulting vec-
tor space semantics of the pronouns and clauses
is based on the Frobenius algebraic operations on
vector spaces: they reveal the internal structure, or
what we call anatomy, of the relative clauses.

The methodology pursued in this paper and the
Frobenius operations can be used to provide se-
mantics for other relative pronouns and also other
closed-class words such as prepositions and deter-
miners. In each case, the grammatical type of the
word and a detailed analysis of the role of these
words in the meaning of the phrases in which they
occur would be needed. In some cases, it may be
necessary to introduce a linear map to represent
the meaning of the word, for instance to distin-
guish the preposition on from in.

The contribution of this paper is best demon-
strated via the string diagrammatic representations
of the vector space meanings of these clauses. A
noun phrase modified by a subject relative clause,
which before this paper was depicted as follows:

N S N NN N NN S

Subject Rel-Pronoun Verb Object

will now include the internal anatomy of its rela-
tive pronoun:

49



N S N NN N NN S

Subject Rel-Pronoun Verb Object

This internal structure shows how the information
from the noun flows through the relative pronoun
to the rest of the clause and how it interacts with
the other words. We have instantiated this vector
space semantics using truth-theoretic and corpus-
based examples.

One aspect of our example spaces which means
that they work particularly well is that the sen-
tence dimension in the verb is already discarded,
which means that the ι maps are not required (as
discussed above). Another feature is that the sim-
ple nature of the models means that the µmap does
not lose any information, even though it takes the
diagonal of a matrix and hence in general throws
information away. The effect of the ι and µ maps
in more complex representations of the verb re-
mains to be studied in future work.

On the practical side, what we offer in this paper
is a method for building appropriate vector repre-
sentations for relative clauses. As a result, when
presented with a relative clause, we are able to
build a vector for it, only by relying on the vector
representations of the words in the clause and the
grammatical role of the relative pronoun. We do
not need to retrieve information from a corpus to
be able to build a vector or linear map for the rela-
tive pronoun, neither will we end up having to dis-
card the pronoun and ignore the role that it plays in
the meaning of the clause (which was perhaps the
best option available before this paper). However,
the Frobenius approach and our claim that the re-
sulting vectors are ‘appropriate’ requires an empir-
ical evaluation. Tasks such as the term definition
task from Kartsaklis et al. (2013) (which also uses
Frobenius algebras but for a different purpose) are
an obvious place to start. More generally, the sub-
field of compositional distributional semantics is
a growing and active one (Mitchell and Lapata,
2008; Baroni and Zamparelli, 2010; Zanzotto et
al., 2010; Socher et al., 2011), for which we argue
that high-level mathematical investigations such
as this paper, and also Clarke (2008), can play a
crucial role.

Acknowledgements

We would like to thank Dimitri Kartsaklis and
Laura Rimell for helpful comments. Stephen
Clark was supported by ERC Starting Grant Dis-
CoTex (30692). Bob Coecke and Stephen Clark
are supported by EPSRC Grant EP/I037512/1.
Mehrnoosh Sadrzadeh is supported by an EPSRC
CAF EP/J002607/1.

References
J.C. Baez and J. Dolan. 1995. Higher-dimensional al-

gebra and topological quantum field theory. Journal
of Mathematical Physics, 36:6073–6105.

M. Baroni and R. Zamparelli. 2010. Nouns
are vectors, adjectives are matrices: Representing
adjective-noun constructions in semantic space. In
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP-10), Cambridge, MA.

A. Carboni and R. F. C. Walters. 1987. Cartesian bicat-
egories. I. J. Pure and Appied Algebra, 49:11–32.

S. Clark. 2013. Type-driven syntax and seman-
tics for composing meaning vectors. In Chris He-
unen, Mehrnoosh Sadrzadeh, and Edward Grefen-
stette, editors, Quantum Physics and Linguistics:
A Compositional, Diagrammatic Discourse, pages
359–377. Oxford University Press.

D. Clarke. 2008. Context-theoretic Semantics for Nat-
ural Language: An Algebraic Framework. Ph.D.
thesis, University of Sussex.

B. Coecke and E. Paquette. 2008. Introducing cat-
egories to the practicing physicist. In B. Coecke,
editor, New Structures for Physics, volume 813 of
Lecture Notes in Physics, pages 167–271. Springer.

B. Coecke, D. Pavlovic, and J. Vicary. 2008. A
new description of orthogonal bases. Mathematical
Structures in Computer Science, 1:269–272.

B. Coecke, M. Sadrzadeh, and S. Clark. 2010.
Mathematical foundations for a compositional dis-
tributional model of meaning. Linguistic Analysis,
36:345–384.

F. G. Frobenius. 1903. Theorie der hyperkomplexen
Größen. Preussische Akademie der Wissenschaften
Berlin: Sitzungsberichte der Preußischen Akademie
der Wissenschaften zu Berlin. Reichsdr.

E. Grefenstette and M. Sadrzadeh. 2011a. Experimen-
tal support for a categorical compositional distribu-
tional model of meaning. In Proceedings of Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 1394–1404.

E. Grefenstette and M. Sadrzadeh. 2011b. Experi-
menting with transitive verbs in a discocat. In Pro-
ceedings of the Workshop on Geometrical Models of
Natural Language Semantics (GEMS).

50



A. Joyal and R. Street. 1991. The Geometry of Tensor
Calculus, I. Advances in Mathematics, 88:55–112.

D. Kartsaklis, M. Sadrzadeh, S. Pulman, and B. Co-
ecke. 2013. Reasoning about meaning in nat-
ural language with compact closed categories and
frobenius algebras. In J. Chubb, A. Eskandar-
ian, and V. Harizanov, editors, Logic and Algebraic
Structures in Quantum Computing and Information,
Association for Symbolic Logic Lecture Notes in
Logic. Cambridge University Press.

G. M. Kelly and M. L. Laplaza. 1980. Coherence for
compact closed categories. Journal of Pure and Ap-
plied Algebra, 19:193–213.

J. Kock. 2003. Frobenius algebras and 2D topological
quantum field theories, volume 59 of London Mathe-
matical Society student texts. Cambridge University
Press.

J. Lambek. 1958. The Mathematics of Sentence Struc-
ture. American Mathematics Monthly, 65:154–170.

J. Lambek. 1999. Type Grammar Revisited Logical
Aspects of Computational Linguistics. In Logical
Aspects of Computational Linguistics, volume 1582
of Lecture Notes in Computer Science, pages 1–27.
Springer Berlin / Heidelberg.

J. Mitchell and M. Lapata. 2008. Vector-based models
of semantic composition. In Proceedings of ACL-
08, pages 236–244, Columbus, OH.

R. Montague. 1974. English as a formal language.
In R. H. Thomason, editor, Formal philosophy: Se-
lected Papers of Richard Montague, pages 189–223.
Yale University Press.

A. Preller and J. Lambek. 2007. Free compact 2-
categories. Mathematical Structures in Computer
Science, 17:309–340.

H. Schütze. 1998. Automatic word sense discrimina-
tion. Computational Linguistics, 24:97–123.

R. Socher, J. Pennington, E. Huang, A. Y. Ng, and
C. D. Manning. 2011. Semi-supervised recur-
sive autoencoders for predicting sentiment distribu-
tions. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, Edin-
burgh, UK.

F. M. Zanzotto, I. Korkontzelos, F. Fallucchi, and
S. Manandhar. 2010. Estimating linear models for
compositional distributional semantics. In Proceed-
ings of COLING, Beijing, China.

51


