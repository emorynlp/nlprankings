



















































APRO: All-Pairs Ranking Optimization for MT Tuning


Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1018–1023,
Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics

APRO: All-Pairs Ranking Optimization for MT Tuning

Markus Dreyer∗
SDL Research

6060 Center Drive Suite 150
Los Angeles, CA 90045

markus.dreyer@gmail.com

Yuanzhe Dong
SDL Research

6060 Center Drive Suite 150
Los Angeles, CA 90045
ydong@sdl.com

Abstract

We present APRO, a new method for machine
translation tuning that can handle large feature
sets. As opposed to other popular methods
(e.g., MERT, MIRA, PRO), which involve ran-
domness and require multiple runs to obtain a
reliable result, APRO gives the same result on
any run, given initial feature weights. APRO
follows the pairwise ranking approach of PRO
(Hopkins and May, 2011), but instead of rank-
ing a small sampled subset of pairs from the k-
best list, APRO efficiently ranks all pairs. By
obviating the need for manually determined
sampling settings, we obtain more reliable re-
sults. APRO converges more quickly than PRO
and gives similar or better translation results.

1 Introduction

Machine translation tuning seeks to find feature
weights that maximize translation quality. Recent
efforts have focused on methods that scale to large
numbers of features (Cherry and Foster, 2012), and
among these, PRO has gained popularity (Pairwise
Ranking Optimization, Hopkins and May (2011)).

PRO’s goal is to find feature weights such that the
resulting k-best list entries are ranked in the same
way that an evaluation function (e.g., BLEU, Pap-
ineni et al. (2002)) ranks them. To do this, it labels
pairs of translations for each sentence as positive or
negative, depending on the gold ranking of the two
pair elements given by BLEU. A binary classifier is
trained on these labeled examples, resulting in new
feature weights, and the procedure is iterated. This

∗Markus Dreyer is now at Amazon, Inc., Seattle, WA.

procedure would ordinarily be too expensive since
there areO(k2) pairs per sentence, where both k and
the number of sentences can be in the thousands, so
billions of training examples would be produced per
iteration. Therefore, Hopkins and May (2011) use
subsampling to consider a small percentage of all
pairs per sentence.

We present APRO (All-Pairs Ranking Optimiza-
tion), a tuning approach that, like PRO, uses pair-
wise ranking for tuning. Unlike PRO, it is not lim-
ited to optimizing a small percentage of pairs per
sentence. Based on an efficient ranking SVM for-
mulation (Airola et al. (2011), Lee and Lin (2014)),
we find, in each iteration, feature weights that min-
imize ranking errors for all pairs of translations per
sentence. This tuning method inherits all the ad-
vantages of PRO—it is scalable, effective, easy to
implement—and removes its limitations. It does not
require meta-tuning of sampling parameters since no
sampling is used; it does not need to be run multi-
ple times to obtain reliable results, like MERT (Och,
2003), PRO, MIRA (Chiang et al., 2008) and others,
since it uses global optimization and is determin-
istic given initial feature weights; and it converges
quickly.

2 Notation and Definitions

For both PRO and APRO, we use the following def-
initions: A tuning dataset contains S source sen-
tences x1, . . . , xS . Let Ys be the space of all transla-
tions of xs. It contains one or more known reference
translations ys+. Each translation y

s
i ∈ Ys has a fea-

1018



ture representation1 f(xs, ysi ), or for short, f
s
i , and

a linear classification score hsi = w
T f si , where w

is a feature weight vector. Given a source sentence
xs, a translation decoder can search (often a subset
of) Ys and return the k translations ys1, . . . , ysk with
the highest classification scores. A k-best list is the
list of ys1, . . . , y

s
k,∀s. For each translation ysi we can

obtain an evaluation score b(ysi ,y
s
+), or for short,

bsi , which can be the BLEU+1 score (Lin and Och,
2004).2 For a given source sentence xs, let (i, j) de-
note a pair of translations (ysi , y

s
j ).

3 PRO

We now describe PRO, before constrasting it with
our new approach, APRO. For each iteration t from
t = 1 . . . T , PRO performs the following steps:

1. Given current feature weights wt, obtain a k-
best list, as defined above, from the translation de-
coder. For each xs, add to its k-best entries the k-
best entries from previous iterations, so that xs now
has ks translations; the overall list is called an accu-
mulated k-best list.

2. For each source sentence xs, first sample up
to Γ candidate pairs from its translations in the k-
best list. Less similar pairs are more likely to be-
come candidate pairs. Similarity in a pair (i, j) here
means a small absolute difference dsij between b

s
i

and bsj . The most similar pairs (d
s
ij < β) are dis-

carded. Then select the Ξ least similar pairs among
the remaining candidate pairs.

3. For each pair (i, j) from the Ξ selected pairs,
add the difference vector (f si−f sj) with class label
1 if bsi > b

s
j , otherwise add it with class label −1.

Also add (f sj−f si ) with the opposite label.
4. Train any classifier on the labeled data, re-

sulting in a new weights vector w′. Set wt+1 =
Ψ·w′+(1−Ψ)·wt.

Dependencies between tuning iterations are intro-
duced by the use of accumulated k-best lists and
the interpolation of weight vectors in step 4, using
an interpolation factor Ψ. Translation quality varies
with different choices for Γ, Ξ, β, Ψ, see Figure 1.
The quality varies even when PRO is run multiple
times with the same parameters, due to the sampling

1For simplicity, we leave out nuisance variables like align-
ments, segmentations, or parse trees, from this description,
which may be part of the feature space.

2But see Nakov et al. (2013) for variants.

20.5 21.0 21.5 22.0 22.5 23.0

BLEU score on test data

0.1

0.5

1.0

Ψ
 (

in
te

rp
o
la

ti
o
n
 f

a
ct

o
r)

fa
st

e
r

co
n
v
e
rg

e
n
ce

sl
o
w

e
r

co
n
v
e
rg

e
n
ce

PRO APRO

Figure 1: PRO versus APRO (eng-swe) for 3 settings of Ψ.
PRO: 8 sampling settings per Ψ setting.4 APRO: no sam-
pling. Vertical line indicates settings from H&M (2011).
Not shown: PRO outlier with BLEU =7.9 at Ψ = 0.5.

step. Practitioners would have to perform an expen-
sive grid search multiple times to be sure to obtain
good results. APRO seeks to remedy this problem.
One could try to improve PRO by experimenting
with other pair selection heuristics; APRO circum-
vents the problem by efficiently selecting all pairs.

4 APRO

Our method APRO is, like PRO, a ranking method.
We believe that learning to rank is a suitable method
for MT tuning because it matches the test-time re-
quirements of correctly predicting the best transla-
tions or correctly ranked k-best lists of translations.

Compared to PRO, we simplify the procedure
by removing sampling and labeling steps 2 and 3,
thereby removing some of PRO’s implementation
complexity and manually set parameters. We run
only two steps, corresponding to PRO’s steps 1 and
4: In each tuning iteration, we obtain an accumu-
lated k-best list, then directly find a new w′ that min-
imizes the loss on that k-best list, which corresponds
to PRO’s running of a classifier. APRO’s classifica-
tion model is an efficient ranking SVM (Airola et al.
(2011), Lee and Lin (2014)), described as follows.

4.1 Model

For each sentence xs, we define the set of preference
pairs as the set of ordered translation pairs for which
the evaluation score prefers the first element:

Ps = {(i, j) : bsi > bsj} (1)
4PRO settings: Γ = {5k, 8k} = {small, large}, Ξ =

{50, 100} = {light, dark}, β = {.03, .05} = {no dot, dot}.

1019



Following Lee and Lin (2014), we define the loss
(or, error) of any sentence s as the sum of its pair-
wise squared hinge losses:

Lsw =
∑

(i,j)∈Ps
max(0, 1−hsi +hsj)2 (2)

That is, no loss is contributed by preference pairs
for which the classification score correctly prefers
the first element by a large-enough margin, i.e.,
hsi ≥ hsj +1; all other preference pairs contribute
some loss. We seek to find a weight vector that min-
imizes the regularized overall loss:

w′ = argmin
w

Rw+ C · 1
N

∑
s

Lsw (3)

where Rw = 12w
Tw is a Gaussian regularizer

to prevent overfitting and C a constant controlling
the relative regularization amount. We divide by
N =

∑
s ks to account for the increasing sizes of

accumulated k-best lists between tuning iterations,
which leads to increased sentence losses. If this
were not done, the relative amount of regularization
would decrease in subsequent iterations of tuning.

Any gradient-based optimization method can be
used to find w′. Since the loss is convex, the weights
we find given a particular k-best list are optimal.
This is different from PRO and Bazrafshan et al.
(2012), where the resulting weights depend on the
pairs sampled; MIRA, where they depend on the or-
der of sentences processed; and MERT, where opti-
mization is greedy and depends on initial weights.

4.2 Efficient Computation

How do we efficiently compute Lsw per sentence? In
this and the following subsection, we leave out all
sentence indices s for ease of notation; it is under-
stood that we operate on a given sentence.

A straightforward algorithm to compute Lw
would iterate over all preference pairs (i, j) ∈ P
and add up their losses (Joachims, 2002). However,
since there are O(k2) pairs per sentence, with po-
tentially thousands of sentences, this would be ex-
tremely inefficient. PRO’s solution to this problem
is subsampling. The alternative solution we apply is
to make the sums over translation pairs efficient by
carefully rearranging the terms of the sentence loss,

making use of quantities that can be precomputed ef-
ficiently (Airola et al. (2011), Lee and Lin (2014)).

Definitions. Let us define those quantities. For a
given sentence s, let the set Q contain all members
of P that contribute a positive loss to the overall loss
term:

Q = {(i, j) : (i, j) ∈ P ∧ (1−hi+hj > 0)} (4)

We also define an index notation into Q:

Qi• = {(i, j) ∈ Q,∀j} qi• = |Qi•| (5)
Q•j = {(i, j) ∈ Q, ∀i} q•j = |Q•j | (6)
ri• =

∑
(i,j)∈Qi•

hj (7)

The bullet (•) can be read as any. Example: Q•3
contains pairs ∈ Q whose second element is transla-
tion 3. qi• and q•j denote corresponding set sizes.

Rearrangement. We use these definitions to ex-
press the loss as a sum over only O(k) elements.

First, we simplify the loss expression by summing
only over elements from Q, i.e., pairs from P that
contribute a positive loss, so the max becomes un-
necessary:

Lw =
∑

(i,j)∈P
max(0, 1−hi+hj)2 (8)

=
∑

(i,j)∈Q
(1−hi+hj)2 (9)

=
∑

(i,j)∈Q
h2i−2hi+1+h2j +2hj−2hihj (10)

We then use the precomputed quantities defined
above to rewrite the sum over O(k2) pairs to a sum
over just O(k) elements:

Lw =
k∑

i=1

qi•(h2i−2hi+1)+q•i(h2i +2hi)

−2 ri• hi (11)

This step is described in detail below. Our new
formulation is simpler but equivalent to Lee and Lin

1020



(2014). Using order statistics trees (Cormen et al.,
2001), the quantities qi•, q•i, and ri• can be precom-
puted in O(k log k) time (see details in Lee and Lin
(2014)). This precomputation, together with the re-
arranged loss, allows APRO to make efficient weight
updates without having to subsample.

Detailed derivation. We explain how to derive
Equation 11 from Equation 10.
First, let us define the following equalities:∑

(1,j)∈Q
h1 = q1• ·h1∑

(2,j)∈Q
h2 = q2• ·h2

. . .
If we do not fix the first pair element to a particu-

lar value, we have:∑
(i,j)∈Q

hi =
∑

i

qi• ·hi (12)

Similarly: ∑
(j,1)∈Q

h1 = q•1 ·h1∑
(j,2)∈Q

h2 = q•2 ·h2

. . .
If we do not fix the second element of each pair to

a particular value, we have:∑
(j,i)∈Q

hi =
∑

i

q•i ·hi (13)

We split Equation 10 into separate sums and per-
form a change of variables in the second sum:

Lw =
∑

(i,j)∈Q
h2i−2hi+1+

∑
(j,i)∈Q

h2i +2hi

−2
∑

(i,j)∈Q
hihj

(14)

We introduce one more equality, where (16) fol-
lows from the definition of ri• in Equation 7:

∑
(i,j)∈Q

hihj =
∑

i

hi

 ∑
(i,j)∈Qi•

hj

 (15)

Lang. Train Dev Test
Ara-Eng 14.4M 66K 37K
Chi-Eng 142.9M 61K 29K
Eng-Swe 100.1M 21K 22K
Eng-Fra 100.0M 63K 20K
Ita-Eng 102.8M 21K 20K
Pol-Eng 90.5M 21K 19K

Table 1: Number of words in the used data sets.

=
∑

i

hi ri• (16)

We now use equalities 12, 13, and 16 to arrive at
Equation 11:

Lw =
∑

i

qi•(h2i−2hi+1)+
∑

i

q•i(h2i +2hi)

−2
∑

i

ri• hi

=
∑

i

qi•(h2i−2hi+1)+q•i(h2i +2hi)

−2ri• hi

5 Experiments

5.1 Experimental Setup

We validate APRO on 6 diverse language pairs. For
each one, we perform HMM-based word alignment
(Vogel et al., 1996) and phrase rule extraction on the
training data. We use 20 standard features, incl. 8 re-
ordering features, plus the sparse features listed for
PBTM systems in Hopkins and May (2011).5

For Ara-Eng and Chi-Eng, we use BOLT Y2 data
sets.6 For all other languages, we sample train, dev,
and test sets from in-house data. Table 1 describes
the different data set sizes. We use 5-gram LMs
trained on the target side of the training data; for
Ara-Eng and Chi-Eng, we add 2 LMs trained on En-
glish Gigaword and other sources.

We tune on dev data. In each tuning run, we use
k = 500, except for Ara-Eng (k = 1500). We use
the same weight initialization for every tuning run,
where most features are initialized to 0 and some
dense features are initialized to 1 or -1. During tun-
ing, we use case-insensitive BLEU+1. We tune for

5We use the 500 most frequent words for word pair features.
6For ara-eng, a subset of the training data was chosen whose

source side has maximum similarity to the test source side.

1021



PRO APRO
BLEU LR BLEU LR

Ara-Eng (29.3) 30.7 (0.93) 0.97 (30.3) 30.8 (0.98) 0.99
Chi-Eng (15.4) 20.8 (0.78) 0.98 (19.2) 20.8 (1.01) 0.98
Eng-Fra (30.9) 33.0 (0.95) 0.97 (32.7) 33.3 (1.00) 0.99
Eng-Swe (22.2) 22.4 (1.00) 1.01 (23.1) 23.0 (1.00) 1.00
Ita-Eng (25.6) 25.3 (1.00) 1.00 (25.2) 25.6 (1.00) 1.00
Pol-Eng (22.4) 23.0 (0.95) 0.99 (23.3) 23.3 (1.00) 0.99

Table 2: PRO versus APRO after 10 iterations (small in
parentheses) and at convergence (≤ 30 iterations). Good
results after 10 iterations indicate fast convergence. PRO:
mean over 2 runs (average BLEU standard deviation was
0.1); APRO: single run. LR: length ratio.

up to 30 iterations,7 where we reset the accumu-
lated k-best list after 10 iterations.8 For PRO, we
use Γ=5000, Ξ=50, β=0.05, Ψ=0.1, and (MegaM)
regularization strength λ=1 as described in Hopkins
and May (2011). For APRO, we use regulariza-
tion strength C=0.01 and Ψ=1, which effectively re-
moves the weight interpolation step. We repeat each
PRO tuning twice and report the mean of length ra-
tios and case-sensitive BLEU scores on test data. For
APRO, no repeated runs are necessary; it gives the
same result on any run given initial feature weights.

For APRO, we optimize using the implementa-
tion by Lee and Lin, which uses a truncated Newton
method.9

5.2 Results
We measure the runtime of PRO and APRO. For
an accumulated k-best list containing s=2,748 sen-
tences with an average ks=3,600 translation, PRO
and APRO take 13 and 8 minutes, respectively. Ta-
ble 2 shows translation quality after 10 iterations
and at convergence. We observe that APRO con-
verges quickly: After running for 10 iterations, it
gives higher BLEU scores and better length ratios
than PRO for five out of six language pairs. At con-
vergence, PRO has caught up, but for all language

7Like Hopkins and May (2011), we stop earlier when the
accumulated k-best list does not change anymore.

8This removes bad translations from early iterations and pro-
vides good initial weights for the last 20 iterations. This did not
decrease but sometimes increase final performance.

9See http://goo.gl/CVmnoZ. No change to the soft-
ware is necessary; but in each iteration it must be called with
C′ = C

N
, see Equation 3. We have also experimented with a

change to the software that scales the loss of each sentence by
the number of translation pairs for that sentence; this did not
give reliable BLEU improvements over Equation 3.

pairs APRO performs similar or better.
One of APRO’s advantages are stable results: Fig-

ure 1 compares PRO and APRO for 3 values of Ψ:
For each value, we run PRO eight times with dif-
ferent sampling settings and APRO once. We ob-
serve that the different PRO settings result in differ-
ent BLEU scores. Cherry and Foster (2012) report
that they could not find one PRO setting that worked
across all language pairs. This suggests that practi-
tioners may have to run expensive grid searches to
find optimal PRO performance; this is not necessary
with APRO. While PRO performs best with Ψ = 0.1,
APRO gets good results for Ψ=1, which is the reason
for its fast convergence (Table 2).

6 Conclusions

We have presented APRO, a new tuning method for
machine translation. Like PRO, APRO is a batch
pairwise ranking method, and as such, it inherits
PRO’s advantages of being effective, scalable to
large feature sets and easy to fit into the standard
batch MT tuning framework. We remove PRO’s
sampling step and learn a pairwise ranking over the
whole k-best list inO(k log k) time. We have shown
that PRO’s different sampling settings result in dif-
ferent final results; by removing these settings we
get more reliable results. We find that PRO’s weight
interpolation is not necessary for APRO, resulting in
faster convergence. At convergence, APRO’s trans-
lation quality was found to be similar or better than
PRO’s. APRO’s use of global optimization and the
lack of randomness lead to more stable tuning with
deterministic results.

Acknowledgments

We thank Jonathan May, Mark Hopkins, Bill Byrne,
Adria Gispert, Gonzalo Iglesias, Steve DeNeefe and
the anonymous reviewers for their valuable com-
ments and suggestions.

References
Antti Airola, Tapio Pahikkala, and Tapio Salakoski.

2011. Training linear ranking SVMs in linearithmic
time using red-black trees. Pattern Recognition Let-
ters, 32(9):1328–1336.

Marzieh Bazrafshan, Tagyoung Chung, and Daniel
Gildea. 2012. Tuning as linear regression. In Pro-

1022



ceedings of the 2012 Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, pages 543–
547. Association for Computational Linguistics.

Colin Cherry and George Foster. 2012. Batch tuning
strategies for statistical machine translation. In Pro-
ceedings of the 2012 Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, pages 427–
436. Association for Computational Linguistics.

David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and struc-
tural translation features. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, pages 224–233. Association for Compu-
tational Linguistics.

Thomas H Cormen, Charles E Leiserson, Ronald L
Rivest, Clifford Stein, et al. 2001. Introduction to
algorithms. MIT press Cambridge, 2nd edition.

Mark Hopkins and Jonathan May. 2011. Tuning as rank-
ing. In Proceedings of the 2011 Conference on Empir-
ical Methods in Natural Language Processing, pages
1352–1362. Association for Computational Linguis-
tics.

Thorsten Joachims. 2002. Optimizing search engines
using clickthrough data. In Proceedings of the eighth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 133–142.
ACM.

Ching-Pei Lee and Chih-Jen Lin. 2014. Large-scale lin-
ear RankSVM. Neural computation, 26(4):781–817.

Chin-Yew Lin and Franz Josef Och. 2004. ORANGE: a
method for evaluating automatic evaluation metrics for
machine translation. In Proceedings of Coling 2004,
pages 501–507, Geneva, Switzerland, Aug 23–Aug
27. COLING.

Preslav Nakov, Francisco Guzmán, and Stephan Vogel.
2013. A tale about PRO and monsters. In Proceed-
ings of the 51st Annual Meeting of the Association for
Computational Linguistics (Volume 2: Short Papers),
pages 12–17, Sofia, Bulgaria, August. Association for
Computational Linguistics.

Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting on Association for Computa-
tional Linguistics-Volume 1, pages 160–167. Associa-
tion for Computational Linguistics.

K. Papineni, S. Roukos, T. Ward, and W. J Zhu. 2002.
BLEU: a method for automatic evaluation of machine
translation. In Proceedings of the 40th annual meet-
ing on association for computational linguistics, pages
311–318.

Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proceedings of the 16th conference on Com-
putational linguistics-Volume 2, pages 836–841. Asso-
ciation for Computational Linguistics.

1023


