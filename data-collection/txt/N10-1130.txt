










































Why Synchronous Tree Substitution Grammars?


Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 876–884,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

Why Synchronous Tree Substitution Grammars?

Andreas Maletti
Universitat Rovira i Virgili, Departament de Filologies Romàniques

Avinguda de Catalunya 35, 43002 Tarragona, Spain
andreas.maletti@urv.cat

Abstract

Synchronous tree substitution grammars are a
translation model that is used in syntax-based
machine translation. They are investigated in
a formal setting and compared to a competi-
tor that is at least as expressive. The competi-
tor is the extended multi bottom-up tree trans-
ducer, which is the bottom-up analogue with
one essential additional feature. This model
has been investigated in theoretical computer
science, but seems widely unknown in natu-
ral language processing. The two models are
compared with respect to standard algorithms
(binarization, regular restriction, composition,
application). Particular attention is paid to the
complexity of the algorithms.

1 Introduction

Every machine translation system uses a transla-
tion model, which is a formal model that describes
the translation process. Either this system is hand-
crafted (in rule-based translation systems) or it is
trained with the help of statistical processes. Brown
et al. (1990) discuss automatically trainable transla-
tion models in their seminal paper on the latter ap-
proach. The IBM models of Brown et al. (1993) are
string-based in the sense that they base the transla-
tion decision on the words and the surrounding con-
text. In the field of syntax-based machine transla-
tion, the translation models have access to the syntax
(in the form of parse trees) of the sentences. Knight
(2007) presents a good exposition to both fields.

In this paper, we focus on syntax-based transla-
tion models, and in particular, synchronous tree sub-
stitution grammars (STSGs), or the equally pow-
erful (linear and nondeleting) extended (top-down)

tree transducers of Graehl et al. (2008). Chiang and
Knight (2006) gives a good introduction to STSGs,
which originate from the syntax-directed transla-
tion schemes of Aho and Ullman (1972) [nowadays
more commonly known as synchronous context-free
grammars]. Roughly speaking, an STSG has rules
in which a nonterminal is replaced by two trees con-
taining terminal and nonterminal symbols. In addi-
tion, the nonterminals in the two trees are linked and
a rule is only applied to linked nonterminals.

Several algorithms for STSGs have been dis-
cussed in the literature. For example, we can
• train them [see Graehl et al. (2008)],
• attempt to binarize them using the methods of

(Zhang et al., 2006; Huang et al., 2009; DeNero
et al., 2009b),
• parse them [see DeNero et al. (2009a)], or
• attempt to compose them.

However, some important algorithms are partial be-
cause it is known that the construction might not be
possible in general. This is the case, for example,
for binarization and composition.

In the theoretical computer science community,
alternative models have been explored. Such
a model is the multi bottom-up tree transducer
(MBOT) of Arnold and Dauchet (1982) and Lilin
(1981), which essentially is the bottom-up analogue
of STSGs with the additional feature that nontermi-
nals can have an arbitrary rank (the rank of a non-
terminal of an STSG can be considered to be fixed
to 1). This model is even more expressive than
STSGs, but still offers good computational proper-
ties. In this contribution, we will compare STSGs
and MBOTs with respect to some standard algo-
rithms. Generally, MBOTs offer algorithmic ben-
efits over STSG, which can be summarized as fol-

876



lows:
• Every STSG can be transformed into an equiv-

alent MBOT in linear time.
• MBOTs can be fully binarized in linear

time whereas only partial binarizations (or
asynchronous binarizations) are possible for
STSGs.
• The input language of an MBOTM can be reg-

ularly restricted in O(|M | · |S|3), whereas the
corresponding construction for an STSG M is
in O(|M | · |S|2 rk(M)+5) where rk(M) is the
maximal number of nonterminals in a rule of
the STSG M .
• MBOTs can be composed, whereas this cannot

be achieved for STSGs.
Overall, we thus conclude that, from an algorith-
mic perspective, it would be beneficial to work with
MBOTs instead of STSGs. However, the full power
of MBOTs should not be tapped because, in gen-
eral, MBOTs have the finite-copying property [see
Engelfriet et al. (1980)], which complicates the al-
gorithms for forward and backward application (see
Section 7).

2 Preliminary definitions

An alphabet is a finite set of symbols. Our weighted
devices use real-number weights, but the results
translate easily to the more general setting of com-
mutative semirings [see Golan (1999)]. A weighted
string automaton as in Schützenberger (1961) and
Eilenberg (1974) is a system (S,Γ, I, τ, F ) where
• S and Γ are alphabets of states and input sym-

bols, respectively,
• I, F : S → R assign initial and final weights,

respectively, and
• τ : S × Γ × S → R assigns a weight to each

transition.
Let w = γ1 · · · γk ∈ Γ∗ be an input string of
length k. A run on w is r : {0, . . . , k} → S. The
weight of the run r is wt(r) =

∏k
i=1 τ(ri−1, γi, ri).

The semantics of the automaton A then assigns to w
the weight

A(w) =
∑

r run on w

I(r0) · wt(r) · F (rk) .

A good introduction to weighted string automata can
be found in Mohri (2009) and Sakarovitch (2009).

To simplify the theoretical discussion, we as-
sume that each symbol that we use in trees has a
fixed rank, which determines the number of chil-
dren of each node with that label. A ranked alpha-
bet Σ =

⋃
k≥0 Σk is an alphabet whose symbols

have assigned ranks. The set Σk contains all sym-
bols of rank k. The set TΣ(V ) of Σ-trees indexed
by a set V is the smallest set such that V ⊆ TΣ(V )
and σ(t1, . . . , tk) ∈ TΣ(V ) for every σ ∈ Σk and
t1, . . . , tk ∈ TΣ(V ). The size |t| of the tree t ∈ TΣ
is the number of occurrences of symbols from Σ∪V
that appear in t. A context c is a tree of TΣ∪{�}(V ),
in which the nullary symbol � occurs exactly once.
The set of all such contexts is CΣ(V ). The tree c[t]
is obtained from c by replacing the symbol � by t.

A weighted synchronous tree substitution gram-
mar (STSG) is a system (N,Σ,∆, I, P ) where
• N is an alphabet of nonterminals,
• Σ and ∆ are ranked alphabets of input and out-

put symbols, respectively,
• I : N → R assigns initial weights, and
• P is a finite set of productions n : t a↔ u with
n ∈ N , t ∈ TΣ(N), a ∈ R, and u ∈ T∆(N)
such that

– every n′ ∈ N that occurs in t occurs ex-
actly once in u and vice versa, and

– t /∈ N or u /∈ N .
Note that our distinction between nonterminals and
terminals is rather uncommon for STSG [see Chi-
ang (2005)], but improves the generative power. We
chose the symbol “↔” because STSG productions
are symmetric. The size |n : t a↔ u| of a produc-
tion is |t| + |u|, and the size |M | of the STSG M is∑

p∈P |p|. It is a weighted tree substitution grammar
(TSG) if t = u for all productions n : t a↔ u ∈ P .
Further, it is in normal form if for every production
n : t a↔ u ∈ P there exist σ ∈ Σk, δ ∈ ∆k, and
nonterminals n1, . . . , nk, n′1, . . . , n

′
k ∈ N such that

t = σ(n1, . . . , nk) and u = δ(n′1, . . . , n
′
k). A de-

tailed exposition to STSGs and STSGs in normal
form (also called synchronous context-free gram-
mars) can be found in Chiang (2005). Further details
on TSGs can be found in Berstel and Reutenauer
(1982) and Fülöp and Vogler (2009).

Equal nonterminals in t and u of a produc-
tion n : t a↔ u ∈ P are linked. To keep the pre-
sentation simple, we assume that those links are re-

877



S

NP1 @

V NP2

↔

S

V @

NP1 NP2

S

NP

x1

@

V

x2

NP

x3

→

S

S

x2 @

x1 x3

Figure 1: STSG production (top) and corresponding
MBOT rule (bottom) where @ is an arbitrary symbol that
is introduced during binarization.

membered also in sentential forms. In addition, we
assume that N ∩ Σ = ∅. For every c, c′ ∈ CΣ(N)
and n ∈ N , let (c[n], c′[n]) a⇒ (c[t], c′[u]) if
• there is a production n : t a↔ u ∈ P , and
• the explicit (the ones replacing �) occurrences

of n in c[n] and c′[n] are linked.
Left-most derivations are defined as usual, and the
weight of a derivation D : ξ0

a1⇒ · · · ak⇒ ξk is
wt(D) =

∏k
i=1 ai. The weight assigned by the

grammar M to a pair (t, u) ∈ TΣ × T∆ is

M(t, u) =
∑
n∈N

I(n) ·
∑

D left-most derivation
from (n, n) to (t, u)

wt(D) .

The second restriction on productions ensures that
derivations are of finite length, and thus that the
sums in the definition of M(t, u) are finite.

In the following, we will use syntactic simplifica-
tions such as
• several occurrences of the same nonterminal in

a tree (disambiguated by decoration).
• symbols that are terminals (of Σ and ∆) and

nonterminals. We will print nonterminals in
italics and terminal symbols upright.
• omission of the nonterminal n (or the weight a)

of a rule n : t a↔ u if the terminal n occurs at
the root of t and u (or a = 1).
• n a→ t instead of n : t a↔ t if it is a TSG.

A sample STSG production (using those simplifica-
tions) is displayed in Figure 1. Our STSGs are es-
sentially equivalent to the (nondeleting and linear)
extended tree transducers of Graehl et al. (2008) and
Maletti et al. (2009).

@

V

x2

NP

x3

→
U

x2 x3

S

NP

x1

U

x2 x3

→

U ′

x2 @

x1 x3

U ′

x1 x2
→

S

S

x1 x2

Figure 2: Sample MBOT rules in one-symbol normal
form.

3 Multi bottom-up tree transducers

As indicated in the Introduction, we will compare
STSGs to weighted multi bottom-up tree transduc-
ers, which have been introduced by Arnold and
Dauchet (1982) and Lilin (1981). A more detailed
(and English) presentation can be found in Engel-
friet et al. (2009). Let us quickly recall the formal
definition. We use a fixed set X = {x1, x2, . . . }
of (formal) variables. For a ranked alphabet S and
L ⊆ TΣ(X) we let

S(L) = {s(t1, . . . , tk) | s ∈ Sk, t1, . . . , tk ∈ L}

and we treat elements of S(L) like elements
of TΣ∪S(X).

Definition 1 A weighted multi bottom-up tree trans-
ducer (MBOT) is a system (S,Σ,∆, F,R) where
• S, Σ, and ∆ are ranked alphabets of states, in-

put symbols, and output symbols, respectively,
• F : S1 → R assigns final weights, and
• R is a finite set of rules l a→ r where a ∈ R,
l ∈ TΣ(S(X)), and r ∈ S(T∆(X)) such that

– every x ∈ X that occurs in l occurs ex-
actly once in r and vice versa, and

– l /∈ S(X) or r /∈ S(X).
Roughly speaking, an MBOT is the bottom-up

version of an extended top-down tree transducer, in
which the states can have a rank different from 1. We
chose the symbol “→” because rules have a distin-
guished left- and right-hand side. The size |l a→ r| of

878



S

NP

t1

@

V

t2

NP

t3

⇒

S

NP

t1

U

t2 t3

⇒

U ′

t2 @

t1 t3

⇒

S

S

t2 @

t1 t3

Figure 3: Derivation using the MBOT rules of Fig. 2.

a rule is |l|+ |r|, and the size |M | of an MBOTM is∑
r∈R|r|. Again the second condition on the rules

will ensure that derivations will be finite. Let us
continue with the rewrite semantics for the MBOT
(S,Σ,∆, F,R). To simplify the presentation, we
again assume that S ∩ (Σ ∪ ∆) = ∅. We need
the concept of substitution. Let θ : X → T∆ and
t ∈ T∆(X). Then tθ is the tree obtained by replac-
ing every occurrence of x ∈ X in t by θ(x).
Definition 2 Let c ∈ CΣ(S(X)) and θ : X → T∆.
Then c[lθ] a⇒ c[rθ] if l a→ r ∈ R. The weight of a
derivation D : ξ0

a1⇒ · · · ak⇒ ξk is wt(D) =
∏k
i=1 ai.

The weight assigned by the MBOT M to a pair
(t, u) ∈ TΣ × T∆ is

M(t, u) =
∑
s∈S1

F (s) ·
∑

D left-most derivation
from t to s(u)

wt(D) .

We use the simplifications already mentioned in
the previous section also for MBOTs. Figures
1 and 2 display example rules of an MBOT. The
rules of Figure 2 are applied in a derivation in Fig-
ure 3. The first displayed derivation step uses the
context S(NP(t1),�) and any substitution θ such
that θ(x2) = t2 and θ(x3) = t3.

It is argued by Chiang (2005) and Graehl et
al. (2008) that STSGs (and extended tree trans-
ducers) have sufficient power for syntax-based ma-
chine translation. Knight (2007) presents a detailed
overview that also mentions short-comings. Since
our newly proposed device, the MBOT, should be
at least as powerful as STSGs, we quickly demon-
strate how each STSG can be coded as an MBOT.
An STSG production and the corresponding MBOT
rule are displayed in Figure 1. Since the correspon-
dence is rather trivial, we omit a formal definition.

Theorem 3 For every STSG M , an equivalent
MBOT can be constructed in time O(|M |).

4 Binarization

Whenever nondeterminism enters the playfield, bi-
narization becomes an important tool for efficiency
reasons. This is based on the simple, yet powerful
observation that instead of making 5 choices from a
space of n in one instant (represented by n5 rules),
it is more efficient (Wang et al., 2007) to make them
one-by-one (represented by 5n rules). Clearly, this
cannot always be done but positive examples exist in
abundance; e.g., binarization of context-free gram-
mars [see CHOMSKY normal form in Hopcroft and
Ullman (1979)].

Binarization of tree language devices typically
consists of two steps: (i) binarization of the involved
trees (using the auxiliary symbol @) and (ii) adjust-
ment (binarization) of the processing device to work
on (and fully utilize) the binarized trees. If success-
ful, then this leads to binarized derivation trees for
the processing device. In Figure 4 we show the bi-
narization of the trees in an STSG production. An-
other binarization of the rule of Figure 4 is displayed
in Figure 1. The binarization is evident enough, so
we can assume that all trees considered in the fol-
lowing are binarized.

The binarization in Figure 1 is unfortunate be-
cause the obtained production cannot be factor-
ized such that only two nonterminals occur in each
rule. However, the binarization of Figure 4 allows
the factorization into S(U ,NP) ↔ S(U ,NP) and
U : @(NP ,V )↔ @(V ,NP), which are fully bina-
rized productions. However, in general, STSGs (or
SCFGs or extended tree transducers) cannot be fully
binarized as shown in Aho and Ullman (1972).

Zhang et al. (2006) and Wang et al. (2007) show
the benefits of fully binarized STSGs and present a
linear-time algorithm for the binarization of binariz-
able STSGs. We show that those benefits can be
reaped for all STSGs by a simple change of model.

879



S

NP1 V NP2
↔

S

V NP1 NP2

S

@

NP1 V

NP2 ↔

S

@

V NP1

NP2

Figure 4: Binarization of trees in an STSG production.
Top: Original — Bottom: Binarized trees.

We have already demonstrated that every STSG can
be transformed into an equivalent MBOT in linear
time. Next, we discuss binarization of MBOTs.

An MBOT is in one-symbol normal form if there
is at most one input and at most one output symbol,
but at least one symbol in each rule (see Figure 2).
Raoult (1993) and Engelfriet et al. (2009) prove that
every MBOT can be transformed into one-symbol
normal form. The procedure presented there runs in
linear time in the size of the input MBOT. Conse-
quently, we can transform each STSG to an equiv-
alent MBOT in one-symbol normal form in linear
time. Finally, we note that a MBOT in one-symbol
normal form has binarized derivation trees, which
proves that we fully binarized the STSG.

Theorem 4 For every STSG M an equivalent, fully
binarized MBOT can be constructed in O(|M |).

The construction of Engelfriet et al. (2009) is il-
lustrated in Figure 2, which shows the rules of an
MBOT in one-symbol normal form. Those rules are
constructed from the unlucky binarization of Fig-
ure 1. In the next section, we show the benefit of the
full binarization on the example of the BAR-HILLEL
construction.

5 Input and output restriction

A standard construction for transformation devices
(and recognition devices alike) is the regular restric-
tion of the input or output language. This con-
struction is used in parsing, integration of a lan-
guage model, and the computation of certain metrics
[see Nederhof and Satta (2003), Nederhof and Satta
(2008), and Satta (2010) for a detailed account]. The
construction is generally known as BAR-HILLEL
construction [see Bar-Hillel et al. (1964) for the

original construction on context-free grammars].
STSGs (and extended tree transducers) are sym-

metric, so that input and output can freely be
swapped. Let M be an STSG and A a weighted
string automaton with states S. In the BAR-HILLEL
construction for M and A, the maximal rank rk(M)
of a symbol in the derivation forest ofM enters as an
exponent into the complexityO(|M | · |S|2 rk(M)+5).
Since full binarization is not possible in general, the
maximal rank cannot be limited to 2. In contrast,
full binarization is possible for MBOTs (with only
linear overhead), so let us investigate whether we
can exploit this in a BAR-HILLEL construction for
MBOTs.

Let M = (S,Σ,∆, F,R) be an MBOT in one-
symbol normal form. The symbols in Σ ∪ ∆ have
rank at most 2. Moreover, let G = (N,Σ,Σ, I, P )
be a TSG in normal form. We want to construct an
MBOT M ′ such that M ′(t, u) = M(t, u) ·G(t) for
every t ∈ TΣ and u ∈ T∆. In other words, each
input tree should be rescored according to G; in the
unweighted case this yields that the translation ofM
is filtered to the set of input trees accepted by G.

We occasionally write the pair (a, b) in angled
parentheses (‘〈’ and ‘〉’). In addition, we use the
center line ellipsis ‘· ·’ (also with decoration) like a
variable (especially for sequences).

Definition 5 The input product Prod(M,G) is the
MBOT Prod(M,G) = (S×N,Σ,∆, F ′, R′) where
• F ′(〈s, n〉) = F (s) · I(n) for every s ∈ S and
n ∈ N ,
• for every rule s(· ·) a→ s′(· ·′) ∈ R with
s, s′ ∈ S and every n ∈ N , there exists a rule

〈s, n〉(· ·) a→ 〈s′, n〉(· ·′) ∈ R′ ,

• for every rule σ(s1(· ·1), . . . , sk(· ·k))
a→ s(· ·)

in R with σ ∈ Σk and s, s1, . . . , sk ∈ S, and
every production n b→ σ(n1, . . . , nk) ∈ P , the
following rule is in R′:

σ(〈s1, n1〉(· ·1), . . . , 〈sk, nk〉(· ·k))
ab→ 〈s, n〉(· ·) .

The first type of rule (second item) does not in-
volve an input symbol, and thus the nonterminal
of G is just forwarded to the new state. Since no
step with respect to G is made, only the weight of
the rule of M is charged. The second type of rule
(third item) uses a rule of R with the input symbol σ

880



s1 s3

s1 s2 s2 s3

σ

〈s1,s3〉→σ(〈s1,s2〉,〈s2,s3〉)

s1 s2

s1 s2

σ

〈s1,s2〉→σ(〈s1,s2〉)

s1 γ s2

τ(s1, γ, s2)

〈s1,s2〉
τ(s1,γ,s2)→ γ

Figure 5: Constructing a TSG from a weighted string au-
tomaton.

and a production of P that also contains σ. The rule
and the production are executed in parallel in the re-
sulting rule and its weight is thus the product of the
weights of the original rule and production. Over-
all, this is a classical product construction, which is
similar to other product constructions such as Bor-
chardt (2004). A straightforward proof shows that
M ′(t, u) = M(t, u) · G(t) for every t ∈ TΣ and
u ∈ T∆, which proves the correctness.

Next, let us look at the complexity. The MBOT
Prod(M,G) can be obtained in time O(|M | · |G|).
Furthermore, it is known [see, for example, Maletti
and Satta (2009)] that for every weighted string au-
tomaton A with states S, we can construct a TSG G
in normal form, which has size O(|Σ| · |S|3) and
recognizes each tree of TΣ with the weight that the
automaton A assigns to its yield. The idea of this
construction is illustrated in Figure 5. Consequently,
our BAR-HILLEL construction has the well-known
complexityO(|M | · |S|3). This should be compared
to the complexity of the corresponding construction
for an STSG M , which is in O(|M | · |S|2 rk(M)+5)
where rk(M) is the maximal number of (different)
nonterminals in a production of M . Thus, the STSG
should be transformed into an equivalent MBOT in
one-symbol normal form, which can be achieved
in linear time, and the BAR-HILLEL construction
should be performed on this MBOT.

Since STSGs are symmetric, our approach can
also be applied to the output side of an STSG.
However, it should be noted that we can apply it

only to one side (the input side) of the MBOT. A
construction for the output side of the MBOT can
be defined, but it would suffer from a similarly
high complexity as already presented for STSGs.
More precisely, we expect a complexity of roughly
O(|M | · |S|2 rk(M)+2) for this construction. The
small gain is due to the one-symbol normal form and
binarization.

6 Composition

Another standard construction for transformations is
(relational) composition. Composition constructs a
translation from a language L to L′′ given transla-
tions from L to L′ and from L′ to L′′. Formally,
given transformations M ′ : TΣ × T∆ → R and
M ′′ : T∆×TΓ → R, the composition ofM ′ andM ′′
is a tranformation M ′ ;M ′′ : TΣ × TΓ → R with

(M ′ ;M ′′)(t, v) =
∑
u∈T∆

M ′(t, u) ·M ′′(u, v)

for every t ∈ TΣ and v ∈ TΓ. Mind that the sum-
mation might be infinite, but we will only consider
compositions, in which it is finite.

Unfortunately, Arnold and Dauchet (1982) show
that the composition of two transformations com-
puted by STSGs cannot necessarily be computed by
an STSG. Consequently, there cannot be a general
composition algorithm for STSGs.

Let us consider the problem of composition for
MBOTs. Essentially, we will follow the unweighted
approach of Engelfriet et al. (2009) to obtain a com-
position construction, which we present next. Let

M ′ = (S′,Σ,∆, F ′, R′) and
M ′′ = (S′′,∆,Γ, F ′′, R′′)

be MBOTs in one-symbol normal form. We ex-
tend the rewrite semantics (see Definition 2) to
trees that include symbols foreign to a MBOT. In
other words, we (virtually) extend the input and
output alphabets to contain all used symbols (in
particular also the states of another MBOT). How-
ever, since we do not extend the set of rules, the
MBOT cannot process foreign symbols. Neverthe-
less it can perform rewrite steps on known sym-
bols (or apply rules that do not contain input sym-
bols). We use ⇒R′ and ⇒R′′ for derivation steps

881



s′

s′′1

t1 · · · tm

· · · s′′k

u1 · · · un
∼=

s′〈s′′1, . . . , s′′k〉

t1 · · · tm · · · u1 · · · un

Figure 6: Identification in sentential forms.

that exclusively use rules ofR′ andR′′, respectively.
In addition, we identify s′(s′′1(· ·1), . . . , s′′k(· ·k))
with s′〈s′′1, . . . , s′′k〉(· ·1, . . . , · ·k) for s′ ∈ S′ and
s′′1, . . . , s

′′
k ∈ S′′. This identification is illustrated

in Figure 6.

Definition 6 The MBOT M ′ ;M ′′ = (S,Σ,Γ, F,R)
is such that
• for every s′ ∈ S′k and s′′1 ∈ S′′`1 , . . . , s

′′
k ∈ S′′`k

we have s′〈s′′1, . . . , s′′k〉 ∈ S`1+···+`k ,
• F (s′〈s′〉) = F ′(s′) · F ′′(s′′) for every s′ ∈ S′1

and s′′ ∈ S′′1 , and
• the rules l a→ r of R, all of which are such that

the variables in l occur in order (x1, . . . , xk)
from left-to-right, are constructed in 3 ways:

– l a⇒R′ r by a single rule of R′,
– l a⇒R′′ r by a single rule of R′′, or
– l a1⇒R′ ξ

a2⇒R′′ r with a = a1 · a2 and
the applied rule of R′ contains an output
symbol.

If a rule l a→ r can be constructed in several
ways (with exactly weight a), then the weights
of all possibilities are added for the weight of
the new rule.

Intuitively, a single rule ofR′ without output sym-
bols is used in the first type (because otherwise
r would have the wrong shape). In the second type, a
single rule of R′′ without input symbols is used. Fi-
nally, in the third type, first a rule ofR′ that produces
an output symbol of ∆ is used and then this symbol
is processed by a single rule of R′′. Note that every
rule of R′ can produce at most one output symbol
and the rules of R′′ either process none or one input
symbol due to the assumption that M ′ and M ′′ are
in one-symbol normal form. We illustrate a rule of
the first in Figure 7.

original rule:

σ

q1

x1 x2

q2

x3

a→
q

x3 x1 x2

constructed rule:

σ

q1

p1

x1 x2

p2

x3

q2

p3

x4 x5

a→

q

p3

x4 x5

p1

x1 x2

p2

x3

Figure 7: Example of a constructed rule of type 1.

The correctness proof of this construction can es-
sentially (i.e., for the unweighted case) be found in
Engelfriet et al. (2009). Before we can extend it to
the weighted case, we need to make sure that the
sum in the definition of composition is finite. We
achieve this by requiring that
• for every t ∈ TΣ and s ∈ S′1 there are finitely

many u ∈ T∆ such that t
a1⇒ · · · an⇒ s(u), or

• for every v ∈ TΓ and s ∈ S′′1 there are finitely
many u ∈ T∆ such that u

a1⇒ · · · an⇒ s(v).
In other words,M ′ may not have cyclic input ε-rules
or M ′′ may not have cyclic output ε-rules. Now we
can state the main theorem.

Theorem 7 For all MBOTs M ′ and M ′′ with the
above restriction the composition M ′ ; M ′′ of their
transformations can be computed by another MBOT.

This again shows an advantage of MBOTs. The
composition result relies essentially on the one-
symbol normal form (or full binarization), which
can always be achieved for MBOTs, but cannot for
STSGs. Consequently, MBOTs can be composed,
whereas STSGs cannot be composed in general. In-
deed, STSGs in one-symbol normal form, which can
be defined as for MBOTs, can be composed as well,
which shows that the one-symbol normal form is the
key for composition.

Finally, let us discuss the complexity of compo-
sition. Let rk(M ′) be the maximal rank of a state
in S′. Then there are
• O(|M ′| · |S′′|rk(M ′)) rules of type 1,
• O(|M ′′| · |S′′|rk(M ′)) rules of type 2, and

882



• O(|M ′| · |M ′′| · |S′′|rk(M ′)) rules of type 3.
Each rule can be constructed in linear time in the size
of the participating rules, so that we obtain a final
complexity ofO(|M ′| · |M ′′| · |S′′|rk(M ′)). Note that
ifM ′ is obtained from an STSGM (via Theorem 4),
then rk(M ′) ≤ rk(M). This shows that binarization
does not avoid the exponent for composition, but at
least enables composition in the general case. More-
over, the complexity could be slightly improved by
the observation that our construction only relies on
(i)M ′ having at most one output symbol per rule and
(ii) M ′′ having at most one input symbol per rule.

7 Forward and backward application

We might want to apply a transformation not just to
a single tree, but rather to a set of trees, which are,
in some cases, already weighted. In general, the set
of trees is given by a TSG G and we expect the re-
sult to be represented by a TSG as well. Forward
and backward application amount to computing the
image and pre-image of G under the transformation,
respectively. Since STSG are symmetric, we need to
solve only one of the problems if the transformation
is given by an STSG. The other problem can then be
solved by inverting the STSG (exchanging input and
output) and using the method for the solved prob-
lem. We chose to address forward application here.

Forward application can be reduced to the prob-
lem of computing the co-domain (or range) with the
help of a product construction for STSG, which is
similar to the one presented in Definition 5. The co-
domain codM of the tranformation computed by an
STSG M assigns to each t ∈ TΣ the weight

codM (t) =
∑
u∈T∆

M(t, u) .

This sum might not be well-defined. However, if
u /∈ N for all productions n : t a↔ u of the STSG,
then the sum is well-defined and the output-side
TSG (i.e., for every production n : t a↔ u in the
STSG there is a production n a→ u in the TSG)
computes the co-domain. The restriction “u /∈ N”
guarantees that the output side is a TSG. Overall, do-
main, co-domain, and forward and backward appli-
cations (using the product construction) can be com-
puted given such minor new requirements.

Also for transformations computed by MBOTs
we can reduce the problem of forward applica-

tion to the problem of computing the co-domain
with the help of the product construction of Defi-
nition 5. However, the co-domain of an MBOT is
not necessarily representable by a TSG, which is
not due to well-definedness problems but rather the
finite-copying property (Engelfriet et al., 1980) of
MBOTs. This property yields that the co-domain
might not be a regular tree language (or context-free
string language). Consequently, we cannot com-
pute forward or backward applications for arbitrary
MBOT. However, if the MBOT is equivalent to an
STSG (for example, because it was constructed by
the method presented before Theorem 3), then for-
ward and backward application can be computed es-
sentially as for STSG. This can be understood as
a warning. MBOT can efficiently be used (with
computational benefits) as an alternative represen-
tation for transformations computed by STSG (or
compositions of STSG). However, MBOT can also
compute transformations, of which the domain or
range cannot be represented by a TSG. Thus, if we
train MBOT directly and utilize their full expressive
power, then we might not be able to perform forward
and backward application.

In the unweighted case, backward application can
always be computed for MBOT. Moreover, it can be
decided using (Ésik, 1984) whether all forward ap-
plications can be represented by TSGs. However, for
a given specific TSG, it cannot be decided whether
the forward application is representable by a TSG,
which was proved by Fülöp (1994). A subclass
of transformations computable by MBOT (that still
contains all transformations computable by STSG),
which allows all forward and backward applications,
has been identified by Raoult (1993).

Conclusion and acknowledgement

We compared STSGs and MBOTs on several stan-
dard algorithms (binarization, regular restriction,
composition, and application). We prove that
MBOTs offer computational benefits on all men-
tioned algorithms as long as the original transforma-
tion is computable by an STSG.

The author was financially supported by the Min-
isterio de Educación y Ciencia (MEC) grants JDCI-
2007-760 and MTM-2007-63422.

883



References
Alfred V. Aho and Jeffrey D. Ullman. 1972. The Theory

of Parsing, Translation, and Compiling. Prentice Hall.
André Arnold and Max Dauchet. 1982. Morphismes

et bimorphismes d’arbres. Theoret. Comput. Sci.,
20(1):33–93.

Y. Bar-Hillel, M. Perles, and E. Shamir. 1964. On for-
mal properties of simple phrase structure grammars.
In Language and Information: Selected Essays on
their Theory and Application, pages 116–150. Addi-
son Wesley.

Jean Berstel and Christophe Reutenauer. 1982. Recog-
nizable formal power series on trees. Theoret. Com-
put. Sci., 18(2):115–148.

Björn Borchardt. 2004. A pumping lemma and decid-
ability problems for recognizable tree series. Acta Cy-
bernet., 16(4):509–544.

Peter F. Brown, John Cocke, Stephen A. Della Pietra,
Vincent J. Della Pietra, Fredrick Jelinek, John D. Laf-
ferty, Robert L. Mercer, and Paul S. Roossin. 1990. A
statistical approach to machine translation. Computa-
tional Linguistics, 16(2):79–85.

Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. Mathematics of
statistical machine translation: Parameter estimation.
Computational Linguistics, 19(2):263–311.

David Chiang and Kevin Knight. 2006. An introduction
to synchronous grammars. In Proc. ACL tutorial.

David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proc. ACL, pages
263–270.

John DeNero, Mohit Bansal, Adam Pauls, and Dan Klein.
2009a. Efficient parsing for transducer grammars. In
Proc. NAACL, pages 227–235.

John DeNero, Adam Pauls, and Dan Klein. 2009b.
Asynchronous binarization for synchronous gram-
mars. In Proc. ACL, pages 141–144.

Samuel Eilenberg. 1974. Automata, Languages, and
Machines. Academic Press.

Joost Engelfriet, Grzegorz Rozenberg, and Giora Slutzki.
1980. Tree transducers, L systems, and two-way ma-
chines. J. Comput. System Sci., 20(2):150–202.

Joost Engelfriet, Eric Lilin, and Andreas Maletti. 2009.
Extended multi bottom-up tree transducers: Composi-
tion and decomposition. Acta Inform., 46(8):561–590.

Zoltán Ésik. 1984. Decidability results concerning tree
transducers II. Acta Cybernet., 6(3):303–314.

Zoltán Fülöp and Heiko Vogler. 2009. Weighted tree au-
tomata and tree transducers. In Handbook of Weighted
Automata, chapter IX, pages 313–403. Springer.

Zoltán Fülöp. 1994. Undecidable properties of determin-
istic top-down tree transducers. Theoret. Comput. Sci.,
134(2):311–328.

Jonathan S. Golan. 1999. Semirings and their Applica-
tions. Kluwer Academic, Dordrecht.

Jonathan Graehl, Kevin Knight, and Jonathan May. 2008.
Training tree transducers. Computational Linguistics,
34(3):391–427.

John E. Hopcroft and Jeffrey D. Ullman. 1979. Intro-
duction to Automata Theory, Languages and Compu-
tation. Addison Wesley.

Liang Huang, Hao Zhang, Daniel Gildea, and Kevin
Knight. 2009. Binarization of synchronous
context-free grammars. Computational Linguistics,
35(4):559–595.

Kevin Knight. 2007. Capturing practical natu-
ral language transformations. Machine Translation,
21(2):121–133.

Eric Lilin. 1981. Propriétés de clôture d’une extension
de transducteurs d’arbres déterministes. In CAAP, vol-
ume 112 of LNCS, pages 280–289. Springer.

Andreas Maletti and Giorgio Satta. 2009. Parsing algo-
rithms based on tree automata. In Proc. IWPT, pages
1–12.

Andreas Maletti, Jonathan Graehl, Mark Hopkins, and
Kevin Knight. 2009. The power of extended top-down
tree transducers. SIAM J. Comput., 39(2):410–430.

Mehryar Mohri. 2009. Weighted automata algorithms.
In Handbook of Weighted Automata, pages 213–254.
Springer.

Mark-Jan Nederhof and Giorgio Satta. 2003. Probabilis-
tic parsing as intersection. In Proc. IWPT, pages 137–
148.

Mark-Jan Nederhof and Giorgio Satta. 2008. Compu-
tation of distances for regular and context-free prob-
abilistic languages. Theoret. Comput. Sci., 395(2–
3):235–254.

Jean-Claude Raoult. 1993. Recursively defined tree
transductions. In Proc. RTA, volume 690 of LNCS,
pages 343–357. Springer.

Jacques Sakarovitch. 2009. Rational and recognisable
power series. In Handbook of Weighted Automata,
chapter IV, pages 105–174. Springer.

Giorgio Satta. 2010. Translation algorithms by means of
language intersection. Manuscript.

Marcel Paul Schützenberger. 1961. On the definition of
a family of automata. Information and Control, 4(2–
3):245–270.

Wei Wang, Kevin Knight, and Daniel Marcu. 2007. Bi-
narizing syntax trees to improve syntax-based machine
translation accuracy. In Proc. EMNLP-CoNLL, pages
746–754.

Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Knight. 2006. Synchronous binarization for machine
translation. In Proc. NAACL-HLT, pages 256–263.

884


