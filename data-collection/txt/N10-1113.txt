










































Bitext-Based Resolution of German Subject-Object Ambiguities


Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 737–740,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

Bitext-Based Resolution of German Subject-Object Ambiguities

Florian Schwarck Alexander Fraser

Institute for Natural Language Processing

University of Stuttgart

{koehlefn,fraser}@ims.uni-stuttgart.de

Hinrich Schütze

Abstract

We present a method for disambiguating syn-

tactic subjects from syntactic objects (a fre-

quent ambiguity) in German sentences taken

from an English-German bitext. We exploit

the fact that subject and object are usually eas-

ily determined in English. We show that a

simple method disambiguates some subject-

object ambiguities in German, while making

few errors. We view this procedure as the first

step in automatically acquiring (mostly) cor-

rect labeled data. We also evaluate using it to

improve a state of the art statistical parser.

1 Introduction

Ambiguity of grammatical role is a problem when

parsing a number of natural languages. In German,

subject-object ambiguities are frequent. The sen-

tence “Die Maus jagt die Katze” “the – mouse –

chases – the – cat” exhibits such an ambiguity. Be-

cause word order is freer in German than in English,

the sentence has two possible meanings: (i) The cat

is chasing the mouse and (ii) the mouse is chasing

the cat. We exploit the fact that such ambiguities are

much less frequent in languages that possess a less

flexible syntax than German. In English, the trans-

lation of the sentence “Die Maus jagt die Katze” is

not ambiguous. If we have access to this translation,

we can use this information to disambiguate the Ger-

man sentence. The English translation is viewed as

a surrogate for both contextual knowledge from the

text and for world knowledge.

We present a method for disambiguating the sub-

ject and object roles in German sentences. We use

an English-German bitext and exploit the fact that

subject and object roles are rarely ambiguous in En-

glish. Using a new gold standard we created we

show that our method disambiguates a significant

proportion of subject-object ambiguities in German

with high precision. We view this procedure as the

first step in automatically acquiring (mostly) correct

labeled data for training a statistical disambiguator

that can be used on German text (even when no

translation is available). In addition to measuring

algorithm performance directly, we present experi-

ments on improving the disambiguation of BitPar, a

state of the art statistical parser.

2 Algorithm

Data and Word Alignment. We use the aligned

English and German sentences in Europarl (Koehn,

2005) for our experiments. The corpus contains long

and complex sentences. To establish translational

correspondence between parallel sentences we use

GIZA++ (Och and Ney, 2003). Its input is a tok-

enized parallel corpus. We lemmatized the text prior

to aligning it.

Procedure. Figure 1 shows the architecture of

our system. The boxes signify data sets, while the

lines are processes applied to the data sets. The pa-

per presents two applications. The first is the cre-

ation of a set of disambiguated German sentences

(which involves word alignments in the upper right

corner, and the use of parsers in the middle of the

graphic). We also present a reranking of the N -best

parses produced by BitPar (Schmid, 2004), a state of

the art statistical parser (bottom of the graphic).

For processing of German we chose FSPar

737



Figure 1: System Architecture

(Schiehlen, 2003), a fast shallow dependency parser.

FSPar has extensive lexical knowledge which helps

it to find subject-object ambiguities with high accu-

racy, but it does not try to resolve such ambiguities.

The key to our approach is to project syntactic

roles from English text. For English parsing we used

MINIPAR (Lin, 1998).

Based on FSPar’s analysis, all German sentences

with a subject-object ambiguity (about a third) were

selected from EuroParl. The parallel English sen-

tences were parsed with MINIPAR.

Words marked as ambiguous by FSPar were then

processed using our algorithm. If an ambiguous

German word was aligned to an English word that

MINIPAR had (unambiguously) assigned the gram-

matical role of subject or object, then the syntactic

role of the German word was defined by this infor-

mation, see Figure 2.

Figure 2: Disambiguation Algorithm

We used standard heuristics for improving word

alignment (Och and Ney, 2003; Koehn et al., 2003),

but there were many misalignments of ambiguous

German words. In order for the procedure to work,

we require that the German word to be disam-

biguated be aligned to the English subject or object.

For this reason, we implemented second guessing

based on a dictionary that lists for every German

word the 10 most frequently aligned English words

(found using the word alignment of all of Europarl).

If an ambiguous German word was either unaligned

or not aligned to the English subject or object, it was

checked whether a dictionary translation was part of

the parallel sentence and marked as subject or ob-

ject by MINIPAR. If so, this dictionary word was

used for disambiguation.

3 Evaluation

Gold Standard. We had access to a small set of

gold standard parses (Padó and Lapata, 2009), but

decided to create a larger corpus. We found that FS-

Par had acceptable performance for finding subject-

object ambiguities1. The syntactic roles of words

marked as ambiguous by FSPar were annotated.

Four annotators annotated the syntactic roles in 4000

sentences using a graphical user interface (GUI).

The GUI showed the ambiguous words in context

and gave the annotator four different subject-object

labels to choose from for each ambiguous word:

subject, object, expletive es and none. Because the

syntactic expletive “es” (English gloss: ‘it’) is fre-

quent in German, as in “es scheint zu regnen” ‘it

appears to be raining,’ we created a separate label

for expletive “es”, which is not treated as a subject.2

The statistics are shown in table 1.

1000 sentences were annotated by all four an-

notators. Inter-annotator agreement was sufficient

(κ = 0.77 on average (Carletta, 1996)).

Evaluation Measures. The output of our algo-

rithm labels each word that FSPar classified as am-

biguous with one of the three possible labels subject,

1FSPar has a very high precision in detecting subject-object

ambiguities, as can be seen in Table 1 (approximately 0.955,

the sum of two left columns divided by sum of all cells). We

tried to get an idea of recall using the smaller gold standard.

We made conservative assumptions about recall errors which

we manually checked on a small sample, details are omitted.

Using these assumptions led to an estimate for recall of 0.733,

but true recall is likely higher.
2German “es” is also frequently used as a non-expletive,

where it can take a syntactic role.

738



subj obj expl es none

Annotator1 4152 3210 115 150

Annotator2 4472 3359 92 226

Annotator3 4444 3584 42 155

Annotator4 4027 3595 9 650

Table 1: Annotator decisions on the full gold standard

DE2EN Refined GDFA Intersection

nosg

P 0.8412 0.8381 0.8353 0.8551

R 0.4436 0.3856 0.3932 0.3380

F1 0.5809 0.5282 0.5347 0.4845

sg

P 0.7404 0.7307 0.7310 0.7240

R 0.5564 0.4873 0.4946 0.4528

F1 0.6353 0.5847 0.5900 0.5571

filter-nosg

P 0.9239 0.9203 0.9192 0.9277

R 0.3940 0.3397 0.3461 0.2984

F1 0.5524 0.4962 0.5028 0.4515

filter-sg

P 0.8458 0.8358 0.8369 0.8290

R 0.4839 0.4213 0.4279 0.3898

F1 0.6156 0.5602 0.5662 0.5302

Table 2: Precision, Recall and F1 of the algorithm.

object and no decision3. We use the standard evalua-

tion metrics Precision (P , the percentage of subject

and object labelings in our hypothesis that are cor-

rect), Recall (R, the percentage of subject and ob-

ject labelings in the gold standard that are correctly

labeled in the hypothesis), and balanced F (F1).

4 Experiments

Algorithm Performance. Table 2 shows the perfor-

mance of our algorithm when evaluated against the

manual annotation4. The lines nosg, sg, filter-nosg

and filter-sg denote different configurations of the al-

gorithm: Second guessing (section 2) was (“sg”) or

was not (“nosg”) applied and filtering was (“filter”)

or was not applied. The filter increases precision by

only keeping labels of subjects and objects that oc-

cur in the default order (e.g., the subject is to the

left of the object in the main clause). As an aid to

the user, FSPar presents such a determination of de-

fault order depending on its classification of clause

type5. The columns indicate the heuristic postpro-

3If expletive es or none was annotated, the system is correct

if it does not make a decision.
4Because of problems with BitPar caused by preprocessing

for FSPar, we use 11,279 sentences of the 13,000 annotated.
5Using this determination alone results in P 0.7728 R 0.8206

F 0.7960, very high recall but low precision.

configuration P R F1

1 top-1 (no change) 0.8088 0.8033 0.8060

2 relabeling nosg 0.7998 0.8176 0.8086

3 relabeling filter-nosg 0.8229 0.8344 0.8286

4 reranking nosg 0.8082 0.8123 0.8102

5 reranking filter-nosg 0.8145 0.8143 0.8144

Table 3: Precision, Recall and F1 of changing BitPar de-

cisions, DE2EN alignment

cessing we applied to GIZA++’s alignment. DE2EN

is the 1-to-N alignment calculated using German as

the source language and English as the target lan-

guage (i.e., each English word is linked to exactly

zero or one German words).

As we see in table 2, with the most strict setup,

filter-nosg, the algorithm resolves subject-object

ambiguities with a precision of more than 92%

but the best recall is only 39.4%, obtained using

DE2EN. Second guessing increases recall but leads

to losses in precision. The best precision result with-

out the filter is 85.5%.

Improving BitPar’s Subject-Object Decisions.

For improving BitPar (which always tries to disam-

biguate subject-object), our baseline is the accuracy

of the most probable parse shown in table 3, row 1.

Using the most probable parse from BitPar, we

relabel a word “subject” or “object” if our system

indicates to do so. With the algorithm alone we are

able to improve recall (table 3, row 2). When we add

the filter both precision and recall are improved (row

3). This experiment measures the improvement pos-

sible if our syntactic role information were directly

integrated as a hard constraint into a parser (see sec-

tion 5).

We now perform a simple reranking experiment,

using BitPar’s 100-best parses. For each sentence

we choose the parse which agrees with as many of

the subject/object decisions of the algorithm as pos-

sible (once again ignoring words where the algo-

rithm chooses no decision). In case of ties in the

number of agreements, we take the most probable

parse. The results are in rows 4–5. Reranking in-

creases F1 by about 0.8%.

5 Related Work

Syntactic projection has been used to bootstrap tree-

banks in resource poor languages (Yarowsky and

739



Ngai, 2001; Hwa et al., 2005). In contrast with such

work, we are addressing subject-object ambiguity in

German. German parsers have no access to the con-

textual and world knowledge necessary to resolve

this ambiguity.

Work on projecting semantic roles (Padó and La-

pata, 2009; Fung et al., 2007) requires both syntac-

tic parsing and semantic role labeling and is con-

cerned with filling in the complete information in a

semantic frame. Our approach is simpler and con-

cerned only with syntactic disambiguation, not se-

mantic projection. We focus only on difficult cases

of subject-object ambiguity and although we do not

always make a prediction, we obtain levels of pre-

cision that projection approaches making no use of

knowledge of German syntax cannot achieve.

In bitext parsing, Burkett and Klein (2008) and

Fraser et al. (2009) used feature functions defined on

triples of (parse tree in language 1, parse tree in lan-

guage 2, word alignment), combined in a log-linear

model trained to maximize parse accuracy, requir-

ing translated treebanks. We focus only on subject-

object disambiguation in German, and annotated a

new gold standard. We work on sentences that a

partial parser has determined to be ambiguous. Fos-

sum and Knight (2008) and Huang et al. (2009) im-

prove English prepositional phrase attachment using

features from an unparsed Chinese sentence. The

latter work integrated the PP-attachment constraint

(detected from the Chinese translation) directly into

an English shift-reduce parser. As we have shown

in the labeling experiment, integrating our subject-

object disambiguation into BitPar could result in fur-

ther increases beyond 100-best reranking.

6 Conclusion

We demonstrated the utility of bitext-based disam-

biguation of grammatical roles. We automatically

created a large corpus of 164,874 disambiguated

subject-object decisions with a precision of over

92%. This corpus will be of use in future research

on syntactic role preferences and for the training

of monolingual subject-object disambiguators. We

presented a prototype application of subject-object

disambiguation through a simple reranking of the

100-best list output by BitPar, and showed a possible

further improvement if integrated in the parser. The

new gold standard, which is publicly available, will

hopefully be useful for work on both monolingual

and bitext-based disambiguation.

Acknowledgments

This work was supported by Deutsche Forschungs-

gemeinschaft grants SFB 732 and MorphoSynt.

References

David Burkett and Dan Klein. 2008. Two languages are

better than one (for syntactic parsing). In EMNLP.

Jean Carletta. 1996. Assessing agreement on classifi-

cation tasks: The kappa statistic. Computational Lin-

guistics, 22.

Victoria Fossum and Kevin Knight. 2008. Using bilin-

gual Chinese-English word alignments to resolve PP-

attachment ambiguity in English. In AMTA.

Alexander Fraser, Renjing Wang, and Hinrich Schütze.

2009. Rich bitext projection features for parse rerank-

ing. In EACL.

Pascale Fung, Zhaojun Wu, Yongsheng Yang, and Dekai

Wu. 2007. Learning bilingual semantic frames: Shal-

low semantic parsing vs. semantic role projection. In

TMI.

Liang Huang, Wenbin Jiang, and Qun Liu. 2009.

Bilingually-constrained (monolingual) shift-reduce

parsing. In EMNLP.

Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara

Cabezas, and Okan Kolak. 2005. Bootstrapping

parsers via syntactic projection across parallel texts.

Nat. Lang. Eng., 11(3).

Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.

Statistical phrase-based translation. In HLT-NAACL.

Philipp Koehn. 2005. Europarl: a parallel corpus for

statistical machine translation. InMT Summit X.

Dekang Lin. 1998. Dependency-based evaluation of

MINIPAR. InWorkshop on Eval of Parsing Systems.

Franz J. Och and Hermann Ney. 2003. A systematic

comparison of various statistical alignment models.

Computational Linguistics, 29(1).

Sebastian Padó and Mirella Lapata. 2009. Cross-lingual

annotation projection of semantic roles. Journal of Ar-

tificial Intelligence Research, 36:307–340.

Michael Schiehlen. 2003. A cascaded finite-state parser

for German. In Research Notes (EACL).

Helmut Schmid. 2004. Efficient parsing of highly am-

biguous context-free grammars with bit vectors. In

COLING.

David Yarowsky and Grace Ngai. 2001. Inducing multi-

lingual POS taggers and NP bracketers via robust pro-

jection across aligned corpora. In NAACL.

740


