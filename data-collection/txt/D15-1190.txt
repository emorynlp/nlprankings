



















































Large-Scale Acquisition of Entailment Pattern Pairs by Exploiting Transitivity


Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1649–1655,
Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.

Large-Scale Acquisition of Entailment Pattern Pairs by Exploiting
Transitivity

Julien Kloetzer∗ Kentaro Torisawa‡ Chikara Hashimoto§ Jong-Hoon Oh¶
Information Analysis Laboratory,

National Institute of Information and Communications Technology (NICT), Kyoto, Japan
{∗julien, ‡ torisawa, § ch, ¶rovellia}@nict.go.jp

Abstract
We propose a novel method for acquiring
entailment pairs of binary patterns on a
large-scale. This method exploits the tran-
sitivity of entailment and a self-training
scheme to improve the performance of an
already strong supervised classifier for en-
tailment, and unlike previous methods that
exploit transitivity, it works on a large-
scale. With it we acquired 138.1 million
pattern pairs with 70% precision with such
non-trivial lexical substitution as “use Y
to distribute X”→“X is available on Y”
whose extraction is considered difficult.
This represents 50.4 million more pattern
pairs (a 57.5% increase) than what our
supervised baseline extracted at the same
precision.

1 Introduction

Recognizing textual entailment (Geffet and Da-
gan, 2005; Androutsopoulos and Malakasiotis,
2009; Zanzotto et al., 2009; Berant et al., 2011) is
an important task for many NLP applications, such
as relation extraction (Romano et al., 2006) or
question-answering (Harabagiu and Hickl, 2006).
Text L entails text R if the information written
in the latter can be deduced from the information
written in the former. As building blocks to rec-
ognize entailment relations between texts, numer-
ous works have focused on recognizing entailment
relations between patterns, such as “grew up in
X”→“lived in X” or “X grew up in Y”→“X lived in
Y” (Lin and Pantel, 2001; Weeds and Weir, 2003a;
Hashimoto et al., 2009; Berant et al., 2011; Kloet-
zer et al., 2013b).

We propose in this paper a method for ac-
quiring on a very large-scale, entailment pairs of

Quantity of training data Average
precision

Baseline plus 5,000 training data samples 49.0%
Baseline: 83,800 training data samples 48.8%
Baseline minus 10,000 training data samples 48.5%
Baseline minus 20,000 training data samples 47.8%

Table 1: Average precision for baseline method
with various amounts of training data

such class-dependent binary patterns as “under-
went Xexam on Ydate”→“Xexam carried out on
Ydate”. Our starting point is a supervised baseline
trained with 83,800 manually labeled pattern pairs
detailed in Kloetzer et al. (2013b). Its top 205 mil-
lion output pairs have an estimated 80% precision,
but this baseline’s performance is saturated. Ta-
ble 1 shows the baseline’s average precision when
varying its amount of hand-labeled training data.
Since the average precision only improves slightly
with additional training data, the investment in
hand-labeling additional training data is difficult
to justify.

To improve our baseline further, we exploit the
transitivity property of entailment to automatically
generate new features for it. The entailment is
transitive; if we detect that L entails C and C en-
tails R, we can infer an entailment relation be-
tween L and R even if no such relation was de-
tected beforehand. Based on this idea, we pro-
pose a self-training scheme that works in the fol-
lowing way. For pattern pair 〈P ,Q〉, we use the
baselines output to find all the chains of patterns
from P to Q that are linked by entailment rela-
tions, which we call transitivity paths, and encode
the information related to them as new features to
judge the validity of pair 〈P ,Q〉. Our expectation
is that even if our supervised baseline fails to judge
〈P ,Q〉 as an entailment pair, the existence of paths

1649



from P to Q that are comprised of pairs judged as
entailments by our baseline might strongly suggest
that P entails Q; hence, adding our new features to
the baseline should help it make better decisions
based on the information encoded in the features.
This self-training approach is the first that encodes
the information contained in transitivity paths as
features for a classifier, and as such it differs from
previous state-of-the-art methods that exploit tran-
sitivity to extract new pairs using Integer Linear
Programming (Berant et al., 2011) or that auto-
generate training data (Kloetzer et al., 2013a).

From a corpus of 600 million web pages, we
show that our proposed method extracted 217.8
million entailment pairs in Japanese with 80% pre-
cision1, which is a 6% increase over the 205.3
million pairs output by our baseline with identi-
cal precision. It also extracted 138.1 million en-
tailment pairs with 70% precision with non-trivial
lexical substitution (generally deemed difficult to
extract), which is a 50.4 million pair increase
(57.5% size improvement) over the 87.7 million
pairs output by our baseline with the same preci-
sion. These include such pairs as “use X to dis-
tribute Y”→“Y is available on X”, “underwent X
on Y”→“X carried out on Y”, “start X at Y”→“Y’s
X” or “attach X to Y”→“put X on Y”. Even though
we only present results for the Japanese language,
we believe that our method should be applicable to
other languages as well. This is because none of
the few language dependent features of our classi-
fier are strictly needed by the baseline or our pro-
posed method, and its performance boost is unre-
lated to these features.

2 Related Works

The task of recognizing entailment between texts
has been proposed by Dagan et al. (2006) and in-
tensively researched (Malakasiotis and Androut-
sopoulos, 2007; Szpektor et al., 2004; Androut-
sopoulos and Malakasiotis, 2009; Dagan et al.,
2009; Hashimoto et al., 2009; Berant et al.,
2011) using a various range of techniques, includ-
ing Integer Linear Programming (Berant et al.,
2011), machine learning with SVMs (Malakasio-
tis and Androutsopoulos, 2007), and probabilis-
tic models (Wang and Manning, 2010; Shnarch
et al., 2011). Entailment recognizer or entail-
ment data sets have been used in such fields
as relation extraction (Romano et al., 2006) and

1Examples are given in English for convenience

question-answering (Harabagiu and Hickl, 2006;
Tanaka et al., 2013). In this work, we are inter-
ested into recognizing entailment between syntac-
tic patterns, which can then be used as building
blocks in a complete entailment recognition sys-
tem (Shnarch et al., 2011). Recognizing entail-
ment between patterns has generally been stud-
ied using unsupervised techniques (Szpektor et
al., 2004; Hashimoto et al., 2009; Weeds and
Weir, 2003b), although we showed that supervised
techniques naturally obtain stronger performance
(Kloetzer et al., 2013b).

The two works that are most closely related to
our work are Berant et al. (2011) and Kloetzer et
al. (2013a), both of which exploit transitivity to
improve the result of a baseline classifier. Berant
et al. (2011) proposed an entailment recognition
method for binary patterns that exploits Integer
Linear Programming techniques (ILP) to expand
the results of an SVM classifier. This method en-
codes into an ILP problem an entailment graph,
which is a valued graph where nodes and edges re-
spectively represent patterns and their entailment
relations, and the values equal the SVM classi-
fiers score output. The problems variables EPQ ∈
{0, 1} indicate whether pattern pairs (here, 〈P ,Q〉)
have an entailment relation, and the goal is to max-
imize the sum of the scores of the pairs selected
as entailment relations {〈P,Q〉|EPQ = 1}. In
(Kloetzer et al., 2013a), we proposed a contradic-
tion acquisition method that uses a training data
expansion scheme; it automatically generates new
contradictions by exploiting transitivity and adds
the highest scoring contradictions based on a novel
score (CDP) to the training data of the original
classifier. The score is based on the assumption
that if pair 〈P ,Q〉, when chained by transitivity to
other pairs 〈Q,Ri〉, generally leads to correct en-
tailment pairs 〈P ,Ri〉, then all pairs 〈P ,Ri〉 should
be correct entailment pairs. Although this work
was designed for contradiction recognition, it is
easily adapted to entailment.

3 Target Data and Baseline Classifiers

Target Pattern Pairs We extracted our binary
patterns from the TSUBAKI corpus (Shinzato et
al., 2008) of 600 million Japanese web pages. Bi-
nary patterns are defined as sequences of words on
the path of dependency relations connecting two
nouns in a sentence and have two variables. “use Y
to distribute X” and “X is available on Y” are such

1650



binary patterns. Like previous works (De Saeger
et al., 2009; Berant et al., 2011; Kloetzer et al.,
2013a), we pose restrictions on the noun-pairs
that co-occur with each pattern using word classes
to disambiguate their various potential meanings:
“Xbook by Yauthor” and “Xbuilding by Ylocation”.
We used the EM-based noun clustering algorithm
presented inKazama and Torisawa (2008) to clas-
sify one million nouns into 500 semantic classes.
Our target set, to which we apply all of our classi-
fiers, is set Σ of around 11 billion class-dependent
pattern pairs for which both patterns share at least
three co-occurring noun-pairs.

Baseline Classifier Our baseline classifier
(BASE) is an SVM classifier trained with about
83,800 binary pattern pairs that were hand-labeled
as entailment (25,436 pairs, 30.4% of the total)
or non-entailment (58,361 pairs). We trained
the classifier using SVMlight software2 with a
polynomial kernel of degree 2.

Following previous work (Kloetzer et al.,
2013b), we used three types of features in BASE:
surface features indicate clues like the presence
of n-grams or measure the string overlap between
two patterns; database features exploit existing
language resources; and distributional similar-
ity scores measure the patterns’ semantic similar-
ity based on the nouns that co-occur with them.
See Kloetzer et al. (2013b) for more details about
BASE s features.

4 Proposed Method

Our method consists of the following three steps:

Step 1 Chain together the entailment pairs pro-
vided by our baseline classifier BASE to
form transitivity paths; if P → Q and Q →
R, then create path P → Q → R.

Step 2 Train new classifiers with features that en-
code the information contained in the transi-
tivity paths obtained in Step 1.

Step 3 Combine the output of these classifiers
with that of baseline classifier BASE.

Figure 1 shows an overview of our method, and
we describe its details in the following sections.

2http://svmlight.joachims.org/

Figure 1: Overview of proposed method

4.1 Step 1: Transitivity Paths
We generate chains of entailment pairs (or tran-
sitivity paths) in the following way. First, we
extract from the output of the baseline classifier
BASE set E(θ) of the pattern pairs for which
BASE returns a score over given threshold θ:
E(θ) = {〈P,Q〉 ∈ Σ|SBASE(P,Q) ≥ θ}, where
SBASE(P,Q) is the score returned by BASE for
pattern pair 〈P ,Q〉. The higher θ is, the greater the
precision of the pairs in E(θ) should be. Then by
chaining the entailment pairs from E(θ) together,
we build sets of transitivity paths composed of two
entailment pairs Tr(θ, 1) for θ ∈ {0,−∞} and of
three entailment pairs Tr(θ, 2) for θ = 0. Since
additional chaining is computationally expensive,
we stopped at paths that consist of three pairs.

4.2 Step 2: Training New Classifiers
In this step, we train new classifiers by adding
new features to BASE. The training data, the
classifier software, and the settings are the same
as for BASE. For given pattern pair 〈P ,R〉,
Path(P,R, θ,N) is the set of all the transitivity
paths in Tr(θ, N) that lead to pair 〈P ,R〉. We en-
code the information contained in these paths in
three new feature sets.

Before explaining these three new feature sets,
we define three scoring functions for the transi-
tivity paths to assess their quality; the MinScore
of a path is the minimum of scores returned by
BASE for each pair in the path, and ArScore and
GeoScore are the arithmetic and geometric aver-
ages of the scores returned by BASE for each pair
in the path. Each of the three feature sets is com-
puted for each of the three scoring functions, but
we just mention MinScore in our explanations due
to space limitations.

Feature set 1: scores of top-ranked paths Here
we select the top ten paths of Path(P,R, θ,N)
ranked by MinScore and use as features a new vec-

1651



tor that consists of the following values: (1) the
MinScore of each path and (2) the scores returned
by BASE for each of the pairs in the ten paths.
When there are fewer than ten paths, the missing
features are set to 0.

Feature set 2: BASE features of the pairs in the
highest ranking transitivity paths Here we se-
lect the transitivity path of Path(P,R, θ,N) with
the highest MinScore and use the BASE feature
values for each pair in the transitivity path as a new
feature vector for pair 〈P ,R〉.
Feature set 3: score distribution Given thresh-
old α, we count the number of paths whose Min-
Score exceeds α. By varying α from lower
bound low to upper bound up, we derive vec-
tor [|{p ∈ Path(P,R, θ,N)|MinScore(p) ≥
α}|]α∈{low,low+β,low+2∗β,...,up} and use it as a new
feature vector for pair 〈P ,R〉. We set β = 0.1 and
low and up such that the score values returned by
BASE are bounded by low and up.

4.3 Step 3: Optimization and Weighted Sum
Classifier Combination

The final output of our method combines the out-
puts of BASE and two new classifiers: (1) a classi-
fier with new features computed with 1-step tran-
sitivity paths (N = 1), and (2) another with new
features computed with up to 2-step transitivity
paths (N ∈ {1, 2}). We then use a weighted
sum and compute score SPROPOSED(P,Q) =∑

i ni ∗ Si(P,Q) for each pair 〈P ,Q〉. Si repre-
sents the scores of the respective classifiers, and
we set n0 + n1 + n2 = 100 (ni are all natural
numbers).

For each potential combination of three weights
ni, we computed the average precision returned
by our method on DEV, our development set, and
selected for our final output the weight combina-
tion that gave the best average precision on DEV.
The final classifiers weights obtained in our ex-
periments were 62 for BASE, 30 for the classifier
with 1-step transitivity features, and 8 for the one
with the 1- and 2-step transitivity features.

Using the same method, we also performed ab-
lation tests to remove the features that harmed the
classifiers and ensured that every proposed new
feature set and every scoring function were useful.

Finally, we confirmed that using a weighted
sum for our proposed method returned higher av-
erage precision than Stacking (Wolpert, 1992),

Figure 2: Precision curves for PROPOSED and
baseline methods for non-similar pairs

which is a more standard combination method, or
than using the output of any of the new classifiers
alone.

5 Experiments

In this section, we evaluate our proposed method
in a large-scale setting and compare it to BASE
and to state-of-the-art methods based on ILP (Be-
rant et al., 2011) and automatic training data ex-
pansion (Kloetzer et al., 2013a). We also indicate
that our method shows the best performance gain
for pattern pairs with non-trivial lexical substitu-
tions, which are more difficult to acquire.

Evaluation Method For our evaluation, we pre-
pared test set TEST of 15,000 pattern pairs ran-
domly sampled from Σ (our target set of 11 bil-
lion pairs). The pairs were annotated by three hu-
mans (not the authors) who voted to settle labeling
discrepancies. We also prepared development set
DEV of 5, 000 pattern pairs from Σ for tuning our
method. The Kappa score was 0.55 for the anno-
tation of these two sets.

We measured the performance of each method
by computing its average precision (Manning and
Schütze, 1999) on the TEST set. We used the av-
erage precision instead of the traditional F-value
because the latters value greatly varies depend-
ing on where the classification boundary is drawn,
even for similar rankings. We also drew precision
curves for each method using the same TEST set.

Proposed Methods Performance We first show
the performance of PROPOSED (our proposed
method) and BASE (the baseline classifier). As
another baseline, we consider BASE +DEV where
the 5,000 samples of the DEV set were added to
the BASE training data. We show the average pre-
cision for each of these three classifiers and the

1652



Classifier Average Million pairs
precision at 80% prec.

PROPOSED 50.64% 217.8
BASE + DEV 48.96% 202.4

BASE 48.79% 205.3
ILP N/A 205.2
CDP 48.42% 198.0

Table 2: Average precision and entailment pairs
obtained (in millions) for proposed method, base-
line classifiers, and state-of-the-art methods

Classifier Av. precision Av. precision
(similar) (non-similar)

PROPOSED 78.73% 39.53%
BASE + DEV 77.72% 37.24%

BASE 77.85% 36.98%

Table 3: Average precision for similar and non-
similar pairs

number of pairs obtained at 80% precision in Ta-
ble 2. We also show the performance of these
classifiers over similar pattern pairs (both patterns
share a content word) and non-similar pairs (they
do not share a content word) in Table 3.

As mentioned in the introduction, BASE +DEV
shows that the addition of 5,000 hand-labeled sam-
ples to the training data of BASE (a 6% increase)
only improves the average precision performance
by 0.17%. Our proposed method, on the other
hand, exploits the same 5,000 new annotated sam-
ples for tuning its parameters and obtains a 1.85%
gain of average precision. Using PROPOSED, we
acquired 217.8 million pattern pairs with 80% pre-
cision, an improvement of 6.0% over BASE.

As shown in Table 3, BASE s performance is
much lower for non-similar pairs like “use Y to
distribute X”→“X is available on Y”, which have
non-trivial lexical substitutions and are more dif-
ficult to acquire than similar pairs. This is also
where PROPOSED obtains the biggest gain in
performance: an average precision of 39.53 com-
pared to 36.98 for BASE. We show the preci-
sion curves we obtained when ranking the non-
similar pairs with BASE and PROPOSED in
Fig. 2. PROPOSED acquired 138.1 million non-
similar pairs at 70% precision, which is an in-
crease of 50.4 million pairs (a 57.5% size im-
provement) compared to BASE with the same pre-
cision. We believe that the strong performance of
BASE for similar entailment pairs helped it dis-
cover, through transitivity, the variations of non-
similar entailment pairs it could already detect.

Comparison to State-of-the-art Methods We
also compared PROPOSED with two state-of-
the-art methods that exploit transitivity: the ILP-
based method of Berant et al. (2011) (ILP) and
the training data expansion method we proposed
in Kloetzer et al. (2013a) (CDP). The latter, which
was initially designed for acquiring contradiction
pairs, was adapted to acquire entailment for com-
parison purposes. The results of this compari-
son are summarized in Table 2, and the precision
curves for these two methods as well over non-
similar pairs are shown in Fig. 2. Our proposed
method is the only one that provides stable im-
provement in our large-scale setting; at best, the
other two just slightly outperform BASE. We be-
lieve that our feature encoding provides more in-
formation to the classifier than the raw scores in
the transitivity paths that are exploited by the other
state-of-the-art methods, and as such strengthens
the performance.

As for explaining the poor performance of the
state-of-the-art methods, ILP is unfortunately not
tractable for big problems; our ILP solver failed to
solve 82% of the independent problems we fed it
due to insufficient memory even on 64-Gb mem-
ory machines, making ILP just slightly better than
BASE. Our pattern graph is also sparser than that
in Berant et al. (2011), and as such ILP might
not be completely efficient. But we assume that
even if we had used the graphs whole closure, the
ILP problem instances would have become even
less tractable, resulting in performance that only
slightly exceeds BASE. As for CDP, since our
baseline classifier already has more than 80,000
hand-annotated samples as training data, the addi-
tion of automatically generated training samples is
actually harmful.

6 Conclusion

In this work, we proposed a method that exploits
the transitivity relation of entailment in a self-
training scheme and combines classifiers with a
weighted sum. In our large-scale setting, our
method outperforms state-of-the-art methods that
are also based on a transitivity approach, includ-
ing an ILP-based method. Using our proposed
method, we acquired 217.8 million Japanese en-
tailment pairs with 80% precision and 138.1 mil-
lion non-trivial pairs with 70% precision. We are
considering an extrinsic evaluation for these data
such as the RTE test in future research.

1653



References
Ion Androutsopoulos and Prodromos Malakasiotis.

2009. A survey of paraphrasing and textual entail-
ment methods. arXiv preprint arXiv:0912.3747.

Jonathan Berant, Ido Dagan, and Jacob Goldberger.
2011. Global learning of typed entailment rules. In
Proceedings of ACL 2011, pages 610–619.

Ido Dagan, Oren Glickman, and Bernardo Magnini.
2006. The pascal recognising textual entailment
challenge. In Machine learning challenges. evalu-
ating predictive uncertainty, visual object classifica-
tion, and recognising tectual entailment, pages 177–
190. Springer.

Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan
Roth. 2009. Recognizing textual entailment: Ratio-
nal, evaluation and approaches. Natural Language
Engineering, 15(4):1–17.

Stijn De Saeger, Kentaro Torisawa, Jun’ichi Kazama,
Kow Kuroda, and Masaki Murata. 2009. Large
scale relation acquisition using class dependent pat-
terns. In Proceedings of ICDM 2009, pages 764–
769.

Maayan Geffet and Ido Dagan. 2005. The distribu-
tional inclusion hypotheses and lexical entailment.
In Proceedings of the 43rd Annual Meeting on Asso-
ciation for Computational Linguistics, pages 107–
114. Association for Computational Linguistics.

Sanda Harabagiu and Andrew Hickl. 2006. Methods
for using textual entailment in open-domain ques-
tion answering. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
the 44th annual meeting of the Association for Com-
putational Linguistics, pages 905–912. Association
for Computational Linguistics.

Chikara Hashimoto, Kentaro Torisawa, Kow Kuroda,
Stijn De Saeger, Masaki Murata, and Jun’ichi
Kazama. 2009. Large-scale verb entailment ac-
quisition from the web. In Proceedings of EMNLP
2009, volume 3, pages 1172–1181.

Junichi Kazama and Kentaro Torisawa. 2008. Induc-
ing gazetteers for named entity recognition by large-
scale clustering of dependency relations. Proceed-
ings of ACL 2008, pages 407–415.

Julien Kloetzer, Stijn De Saeger, Kentaro Tori-
sawa, Chikara Hashimoto, Jong-Hoon Oh, Kiyonori
Ohtake, and Motoki Sano. 2013a. Two-stage
method for large-scale acquisition of contradiction
pattern pairs using entailment. In Proceedings of the
2013 Conference on Empirical Methods in Natural
Language Processing, pages 693–703.

Julien Kloetzer, Stijn De Saeger, Kentaro Torisawa,
Motoki Sano, Chikara Hashimoto, and Jun Gotoh.
2013b. Large-scale acquisition of entailment pattern
pairs. In Information Processing Society of Japan
(IPSJ) Kansai-Branch Convention.

Dekang Lin and Patrick Pantel. 2001. Dirt - discovery
of inference rules from text. In Proceedings of the
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining, pages 323–328.

Prodromos Malakasiotis and Ion Androutsopoulos.
2007. Learning textual entailment using SVMs and
string similarity measures. In Proceedings of the
ACL- PASCAL Workshop on Textual Entailment and
Paraphrasing, pages 42–47.

Christopher D Manning and Hinrich Schütze. 1999.
Foundations of statistical natural language process-
ing. MIT press.

Lorenza Romano, Milen Kouylekov, Idan Szpektor,
and Ido Dagan. 2006. Investigating a generic
paraphrase-based approach for relation extraction.
In Proceedings of EACL, pages 409–416.

Keiji Shinzato, Tomohide Shibata, Daisuke Kawahara,
Chikara Hashimoto, and Sadao Kurohashi. 2008.
TSUBAKI: an open search engine infrastructure for
developing new information access methodology.
Proceedings of IJCNLP2008.

Eyal Shnarch, Jacob Goldberger, and Ido Dagan. 2011.
A probabilistic modeling framework for lexical en-
tailment. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies: short papers
- Volume 2, HLT ’11, pages 558–563, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.

Idan Szpektor, Hristo Tanev, Ido Dagan, Bonaventura
Coppola, et al. 2004. Scaling web-based acquisition
of entailment relations. In Proceedings of EMNLP,
volume 4, pages 41–48.

Masahiro Tanaka, Stijn De Saeger, Kiyonori Ohtake,
Chikara Hashimoto, Makoto Hijiya, Hideaki Fujii,
and Kentaro Torisawa. 2013. Wisdom2013: A
large-scale web information analysis system. In
Sixth International Joint Conference on Natural
Language Processing, pages 58–61.

Mengqiu Wang and Christopher D Manning. 2010.
Probabilistic tree-edit models with structured latent
variables for textual entailment and question an-
swering. In Proceedings of the 23rd International
Conference on Computational Linguistics, COLING
’10, pages 1164–1172, Beijing, China. Association
for Computational Linguistics. ACM ID: 1873912.

Julie Weeds and David Weir. 2003a. A general frame-
work for distributional similarity. In Proceedings of
EMNLP 2003, pages 81–88. Association for Com-
putational Linguistics.

Julie Weeds and David Weir. 2003b. A general frame-
work for distributional similarity. In Proceedings of
the 2003 conference on Empirical methods in natu-
ral language processing, pages 81–88. Association
for Computational Linguistics.

1654



David H Wolpert. 1992. Stacked generalization. Neu-
ral networks, 5(2):241–259.

Fabio Massimo Zanzotto, Marco Pennacchiotti, and
Alessandro Moschitti. 2009. A machine learning
approach to textual entailment recognition. Natural
Language Engineering, 15(04):551–582.

1655


