



















































A Coarse-Grained Model for Optimal Coupling of ASR and SMT Systems for Speech Translation


Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1902–1907,
Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.

A Coarse-Grained Model for Optimal Coupling of ASR and SMT Systems
for Speech Translation

Gaurav Kumar 1, Graeme Blackwood 2, Jan Trmal 1, Daniel Povey 1, Sanjeev Khudanpur 1
1 CLSP & HLTCOE, Johns Hopkins University, Baltimore, MD, USA

2IBM T. J. Watson Research Center, Yorktown Heights, NY, USA
{gkumar6, dpovey1, khudanpur}@jhu.edu, blackwood@us.ibm.com

Abstract

Speech translation is conventionally car-
ried out by cascading an automatic speech
recognition (ASR) and a statistical ma-
chine translation (SMT) system. The hy-
potheses chosen for translation are based
on the ASR system’s acoustic and lan-
guage model scores, and typically opti-
mized for word error rate, ignoring the in-
tended downstream use: automatic trans-
lation. In this paper, we present a coarse-
to-fine model that uses features from the
ASR and SMT systems to optimize this
coupling. We demonstrate that several
standard features utilized by ASR and
SMT systems can be used in such a model
at the speech-translation interface, and we
provide empirical results on the Fisher
Spanish-English speech translation cor-
pus.

1 Introduction

Speech translation is the process of translating
speech in the source language to text or speech
in the target language. This process is typically
structured as a three step pipeline. Step one in-
volves training an Automatic Speech Recognition
(ASR) system to transcribe speech to text in the
source language. Step two involves extracting an
appropriate form of the ASR output to translate.
We will refer to this step as the Speech-Translation
interface. In the simplest scenario, the ASR 1-
best output can be used as the source text to trans-
late. It may be useful to consider alternative ASR
hypotheses and these take the form of an N -best
list or a word-lattice. An N -best list can be in-
cluded easily into the tuning and the decoding pro-
cess of a statistical machine translation (SMT) sys-
tem (Zhang et al., 2004). Several researchers have
proposed solutions to incorporating lattices and

confusion networks in this process (Saleem et al.,
2004; Matusov et al., 2005; Bangalore and Ric-
cardi, 2000; Dyer et al., 2008a; Bertoldi and Fed-
erico, 2005; Quan et al., 2005; Mathias and Byrne,
2006; Bertoldi et al., 2007). Word lattice input to
SMT for tuning and decoding increases the com-
plexity of the decoding process because of the ex-
ponential number of alternatives that are present.
Finally, step three involves training and tuning a
Statistical Machine Translation (SMT) system and
decoding the output extracted through the speech
translation interface.

This paper presents a featurized model which
performs the job of hypothesis selection from the
outputs of the ASR system for the input to the
SMT system. Our motivation is as follows:

1. Using downstream information : Hypoth-
esis selection for the input to the SMT sys-
tem should be done jointly by the ASR and
the SMT systems. That is, there may exist
hypotheses that a trained SMT system may
find easier to translate and produce better
translations for than the ones that are deemed
best based on the ASR acoustic and language
model scores. Incorporation of knowledge
from the downstream process (translation) is
vital to selecting translation options, and sub-
sequently producing better translations.

2. Coarse-to-fine grained decoding : An in-
termediate model which acts as an interface
and is a weak (coarse) version of the down-
stream process may be able to select better
hypotheses. In effect, a weak translation de-
coder can be used as the interface to estimate
the expected translation quality of an ASR
hypothesis. This method of hypothesis se-
lection should be able to incorporate features
from the ASR and the SMT system.

3. Phrase units vs. word units : When a phrase
based SMT system is used for translation,

1902



optimization for hypothesis selection at the
Speech-Translation interface should be con-
ducted using phrases as the basic unit instead
of words.

2 Coarse-to-Fine Speech Translation

In this section, we describe the featurized model
(coarse-grain MT decoder) for hypothesis selec-
tion that uses information from the ASR and SMT
systems (impedance matching). We assume the
presence of ASR and SMT systems that have been
trained separately. In addition to creating almost
no disruption in the traditional pipeline approach,
this allows us to incorporate local gains from each
system. To elaborate, our methods avoid joint op-
timization of the ASR and the SMT system with
respect to a translation metric (Vidal, 1997; Ney,
1999), which is not feasible for larger datasets.
Also, considering the dearth of speech translation
training datasets, this method allows independent
training of the ASR and SMT systems on data cre-
ated only for ASR training and parallel data for
SMT. We start by introducing the formal machin-
ery that will be used and by presenting a simple
example to motivate the model. The complete fea-
turized model follows this exposition.

Let Σ and Γ be alphabets of words and phrases
respectively in the source language. Using these,
we can define the following finite state machines:

1. Word Lattice (L) : A finite state accep-
tor that accepts word-sequences in the source
language ( L : Σ∗ → Σ∗). This represents
the unpruned ASR word lattice output in our
model (Figure 1a).

2. Phrase segmentation Transducer (S) : A
cyclic finite state transducer that transduces
a sequence of words to phrases in the source
language (S : Σ∗ → Γ∗). This is built from
the source side of the phrase table. Each
path represents one source side phrase in the
phrase table. Traversing a path is equivalent
to consuming the words in a phrase and pro-
ducing the phrase as a token (Figure 1b).

3. Weighted word lattice (L̃ASR) : A weighted
version of L (L̃ASR : Σ∗ → Σ∗/R+). We
use the subscript to denote the nature/source
of the weights.

4. Phrase acceptor (W̃MT ) : A finite state ac-
ceptor that accepts source phrases in the SMT

(a) (b)

(c)

Figure 1: A toy example for producing a phrase
length weighted phrase lattice. (a) An unweighted
word lattice. (b) A phrase segmentation trans-
ducer which transduces words to phrases and has
a weight of one per path. Each path is a source
phrase in the phrase table. (c) A phrase lat-
tice produced by composing the word lattice and
phrase segmentation transducer.

system’s phrase table (W̃MT : Γ → Γ/R).
It is weighted by features derived from the
SMT system.

5. Phrase lattice (P) : The result of the com-
position of a word lattice (acceptor) with the
phrase segmentation transducer (P : Σ∗ →
Γ∗). This represents all possible phrase seg-
mentations of all the ASR hypotheses in the
word lattice.

P = det(min(L ◦ S))
We will represent weighted versions of P as
P̃ASR/MT with subscripts to denote the ori-
gin of the weights (Figure 1c).

2.1 A simple model : Maximum Spanning
Phrases

We motivate our model with this fairly simple
scenario. Suppose that we believe that if our
SMT input could be covered by longer source side
phrases1, we would produce better translations.
This may be viewed as a tiling problem where the
tiles are the source phrases in the phrase table and
the goal is to select the ASR hypothesis that re-
quires the least number of phrases to cover2. To
achieve this using our existing machinery, we cre-
ate S̃, a weighted version of S (Figure 1 (b)), such

1In phrase based translation, target translations are pro-
duced for each possible span of the input sentence allowed by
the phrase table. Translation of a longer source side phrase
produces fewer translation options and may be more reliable
given sufficient occurrences in the training data.

2It may be useful to incorporate a brevity penalty here,
since this approach has a strong bias towards selecting shorter
hypotheses. We will use other features to counter this bias in
the following sections.

1903



that

w(δ(S̃)) =
{

0 : π1(δ(S)) ∈ Σ and π2(δ(S)) = �
1 : π2(δ(S)) ∈ Γ and π1(δ(S)) = �

where δ(S̃) is an edge in S̃ and π1 and π2 are the in-
put and output projections respectively. Using this
segmentation transducer and an unweighted word
lattice, L (Figure : 1 (a)), we produce a phrase
lattice P̃MT . Assuming the weights are in the log-
semiring, the weight of a path δ(P̃ )∗ in P̃MT is

w(δ(P̃ )∗) =
∑

δ(P̃ )∈δ(P̃ )∗
w(δ(P̃ ))

Figure 1(c) shows an example of this phrase lat-
tice. Weights in the phrase lattice follow the same
definition as the weights in the segmentation trans-
ducer. Hence, the weight of a path in the phrase
lattice is simply the number of phrases used to
cover this path. The shortest path 3 in the phrase
lattice P̃MT , corresponds to the hypothesis we
were looking for. This simple example, demon-
strates how we may be able to use SMT features
(source phrase length in this case) to select hy-
potheses from the phrase lattice.

2.2 A general featurized model for
hypothesis selection

We now present a general framework in which
hypothesis selection can be carried out using
knowledge (features) from the ASR and the
SMT system. As described earlier, this form of
‘impedance’ matching allows us to select hypothe-
ses from an unpruned ASR word lattice for which
the SMT system is more likely to find good trans-
lations. Incorporating ASR weights also ensures
that we take into account what the ASR system
considers to be good hypotheses. We start with
the previously discussed idea of a phrase lattice,
using weights from the ASR system only. That is,

P̃ASR = det(min(L̃ASR ◦ S))
Now, we use the weighted phrase acceptor W̃MT
to bring in the SMT features 4. Composing this
with the weighted phrase lattice, we get

P̃ASR,MT = det(min(P̃ASR ◦ (W̃MT )∗)
3To compute the shortest path, we switch from the log to

the tropical semiring (A semiring with ordinary addition as
the multiplication operator and max as the addition operator).

4Alternatively, we may have introduced the weights in the
segmentation transducer itself. This separate machine is in-
troduced for efficient training of this model.

where (W̃MT )∗ is the Kleene closure of (W̃MT ).
We assume that the edge weights are in the log-
semiring. Hence, after these two compositions, the
edge weights in P̃ASR,MT can be represented as

w(δ(P̃ASR,MT )) =
∑
j

βjfj,ASR +
∑
k

γkfk,MT

=
∑
i

λifi

where δ(P̃ASR,MT ) is an edge in P̃ASR,MT , β, γ are
feature weights, fASR and fMT are features from
the ASR and SMT system respectively. This form
represents a log-linear model (our features are al-
ready assumed to be in log-space). where fi is any
feature and λi is the corresponding feature weight.
We may now extract the one-best,N -best or lattice
input for the SMT system from P̃ASR,MT .

2.2.1 A discussion about related techniques
1. Decoding (Translation) : Our model closely

resembles a featurized finite-state transducer
based translation model. If we replace the
output alphabet of the acceptor (W̃MT )∗ with
the target side phrases, we will actually get
output in the target language. Even though
this model does not explicity include reorder-
ing, the coarse-grained decoder has access
to information that can enable better deci-
sions about which hypotheses are better for
the downstream process (translation).

2. Lattice Decoding : (Dyer et al., 2008b) sug-
gests passing the entire word lattice to the
SMT system. However, even if these lattices
are not pruned, a beam based decoder might
not consider hypotheses that our model may
produce through coarse-grained decoding.

3. Language model re-scoring : One may use a
bigger source language model to re-score the
ASR lattice (or an N -best list). This how-
ever, does not consider any SMT features in
re-scoring. With our model, we can simply
use this as an additional feature.

2.2.2 Training
Training the hypothesis selection model can be
carried out using standard methods for log linear
models on a held-out set. This also requires decod-
ing (translation) of a deepN -best list derived from
the held-out set. The objective of training then
simply becomes maximization of the translation

1904



quality given any metric that provides sentence
level scores. Each time our model produces a hy-
pothesis, its score can be looked up from the pre-
translated N -best list. Also, whenever the weights
are updated, the only structures that need to be re-
built are W̃ ∗MT and P̃ASR,MT

5.

2.2.3 Features
We use the following features in our implementa-
tion of this model. However, any relevant ASR
and SMT feature may be readily added to this
model.

1. ASR scores : We incorporate the ASR acous-
tic (AM) and language (LM) model scores as
one combined feature.

fASR = LM + α ∗AM
Here, LM,AM are negative log-
probabilities and α is the acoustic scaling
parameter chosen to minimize ASR word
error rate.

2. Source phrase count : As described in sec-
tion 2.1, this feature may be used to cap-
ture the intuition that using a fewer number
of phrases to cover the input sentence may
produce better translations.

3. Length normalized phrase unigram prob-
ability : We may use a phrase LM feature
by incorporating phrase n-gram probabilities
(normalized) by length.

funi(fj) =

 freq(fj)∑
k

freq(fk)

len(fj)

where fj is a source side phrase in the phrase
table.

4. Phrase translation entropy : For each
source side phrase pj , we may have multiple
translations (ei) in the phrase table with dif-
ferent translation probabilities (p(ei|fj)). A
simple entropy measure can be used as a fea-
ture to estimate the confidence that the SMT
system has in translating fj .

ftr(pj) = Htr(E|pj)
= −

∑
i

ptr(ei|fj) log ptr(ei|fj)

5This requires the use of one ASR feature, addressed in
the “Features” section

5. Lexical translation entropy : Similarly, we
can use an entropy measure based on the lex-
ical translation probability as a feature.

flex(pj) = Hlex(E|pj)
= −

∑
i

plex(ei|fj) log plex(ei|fj)

3 Results

We use the Fisher and Callhome Spanish-English
Speech Translation Corpus (Post et al., 2013) for
our experiments. This Fisher dataset consists of
819 transcribed and translated telephone conver-
sations. The corpus is split into a training, dev
and two test sets (dev-2 and test). We use the dev
set for training the feature weights of the proposed
model.
We use the Kaldi speech recognition tools (Povey
et al., 2011) to build our Spanish ASR systems.
Our state-of-the-art ASR system is the p-norm
DNN system of (Zhang et al., 2014). The word-
error-rates on the dev and test sets of the Fisher
dataset (dev, dev-2, test) are 29.80%, 29.79% and
25.30% respectively.
For the SMT system, we use the phrase based
translation system of Moses (Koehn et al., 2007)
with sparse features. The system is trained and
tuned on the train and dev partitions of the Fisher
dataset respectively. The BLEU scores of the MT
output for the the dev-2 and the test partitions are
65.38% and 62.91% respectively. While decoding
the ASR output, we tune on the 1-best ASR output
for the dev partition. With this modified system,
the BLEU scores for the ASR 1-best output of the
dev2 and the test partitions are 40.06% and 40.4%
respectively. We use this system as the baseline
for our experiments (Table 1).
We note that if we were to use the lattice oracle6

from our ASR system as input to the SMT system,
we get a BLEU score of 46.59% for the dev2 par-
tition of the Fisher dataset. This indicates that the
best gain (+BLEU) that an oracle lattice reranker
could get is only 6.53%.

To tune the weights of the coarse decoder, we
decode 500-best ASR outputs for the tuning set
with the SMT system. This maps each ASR hy-
pothesis to a target language translation. An OOV
feature was added to handle words that were not
seen by the SMT system. The tuning process was
then carried out so as to maximize the BLEU with

6Path in the lattice that has the least word error rate.

1905



Experiment BLEU (dev2) BLEU (test)
Transcripts 65.4% 62.9%
Lattice Oracle 46.59% 46.17%
ASR 1-best 40.06% 40.4%
Coarse decoder 40.26% 40.46%

Table 1: Performance when using the coarse de-
coder interface compared to the the decoding the
human transcripts, the ASR 1-best or the lattice
oracle (the path in the ASR lattice with the least
WER : not available during test time.)

respect to the reference translation of the ASR hy-
pothesis selected by the coarse grained decoder.
We used ZMERT (Zaidan, 2009) for tuning which
was configured to expect a 300-best list from the
decoder at every iteration using the Fisher dev set.
15 iterations of tuning were carried out for each
experiment. We then use the tuned weight vec-
tor to decode the Fisher-dev2 and the Fisher-test
set using our coarse grained decoder. We extract
the one-best output and use it as input to the pre-
trained SMT system (description in the preceding
section). Table 1 reports the results achieved the
featurized coarse grained decoder.

4 Conclusions

We present a coarse-to-fine featurized model
which acts as the interface between ASR and SMT
systems. By utilizing information from the up-
stream (ASR) and the downstream (SMT) sys-
tems, this model makes more informed decisions
about which hypotheses from the ASR word lat-
tice may result in better translation results. More-
over, the model takes the form of a coarse finite
state transducer based translation decoder which
imitates the downstream system. This enables it to
estimate translation quality even before the com-
plete SMT system is used for decoding. Finally,
the proposed model is featurized and may accept
any weight from the ASR and SMT system that are
deemed useful for optimizing translation quality.

The Spanish Fisher corpus is one of a few con-
versational speech translation datasets available,
and we start with a strong baseline system. We
therefore persevere with the experimental setup
described above, even though the maximum (ora-
cle) improvement by any rescoring method is only
6.5% BLEU, as noted above. This partially ex-
plains the small gains reported here, and suggests
that this method should be evaluated further on an-

other corpus, e.g. the Egyptian Arabic translation
dataset, with greater headroom for improvement.

Acknowledgments

This work was partially supported by NSF
award No

¯
IIS 0963898 and DARPA contracts

No
¯

HR0011-12-C-0015 and HR0011-51-6285.
The U.S. Government is authorized to reproduce
and distribute reprints for Governmental purposes
notwithstanding any copyright annotation thereon.
The views and conclusions contained herein are
those of the authors and should not be interpreted
as necessarily representing the official policies
or endorsements, either expressed or implied, of
NSF, DARPA or the U.S. Government.

1906



References
Srinivas Bangalore and Giuseppe Riccardi. 2000.

Finite-state models for lexical reordering in spoken
language translation. In Proceedings of the Sixth
International Conference on Spoken Language Pro-
cessing, pages 422–425.

N. Bertoldi and Marcello Federico. 2005. A new de-
coder for spoken language translation based on con-
fusion networks. In Proceedings of the IEEE Work-
shop on Automatic Speech Recognition and Under-
standing, pages 86–91.

N. Bertoldi, R. Zens, and Marcello Federico. 2007.
Speech translation by confusion network decoding.
In Proceedings of the IEEE International Confer-
ence in Acoustics, Speech and Signal Processing,
volume IV, pages 1297–1300.

Christopher Dyer, Smaranda Muresan, and Philip
Resnik. 2008a. Generalizing word lattice transla-
tion. In Proceedings of ACL-08: HLT, pages 1012–
1020, Columbus, Ohio, June. Association for Com-
putational Linguistics.

Christopher Dyer, Smaranda Muresan, and Philip
Resnik. 2008b. Generalizing word lattice transla-
tion. 2008/02//.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondřej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ’07, pages 177–180, Stroudsburg, PA, USA.
Association for Computational Linguistics.

L. Mathias and W. Byrne. 2006. Statistical phrase-
based speech translation. In Proceedings of the
IEEE International Conference in Acoustics, Speech
and Signal Processing, volume I, pages 561–564.

Evgeny Matusov, Stephan Kanthak, and Hermann Ney.
2005. On the integration of speech recognition and
statistical machine translation. In Proceedings of the
9th European Conference on Speech Communica-
tion and Technology, pages 3177–3180.

Hermann Ney. 1999. Speech translation: coupling of
recognition and translation. In Proceedings of the
IEEE International Conference in Acoustics, Speech
and Signal Processing, volume 1, pages 517–520,
March.

Matt Post, Gaurav Kumar, Adam Lopez, Damianos
Karakos, Chris Callison-Burch, and Sanjeev Khu-
danpur. 2013. General lattice decoding for im-
proved speech-to-text translation with the Fisher and
Callhome Spanish-English speech translation cor-
pus. Proceedings of the International Workshop on
Spoken Language Translation.

Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas
Burget, Ondrej Glembek, Nagendra Goel, Mirko
Hannemann, Petr Motlicek, Yanmin Qian, Petr
Schwarz, Jan Silovsky, Georg Stemmer, and Karel
Vesely. 2011. The Kaldi speech recognition
toolkit. In IEEE 2011 Workshop on Automatic
Speech Recognition and Understanding, December.

Vu H Quan, Marcello Federico, and Mauro Cettolo.
2005. Integrated n-best re-ranking for spoken lan-
guage translation. In Proceedings of the 9th Eu-
ropean Conference on Speech Communication and
Technology, pages 3181–3184.

Shirin Saleem, Szu-Chen Jou, Stephan Vogel, and
Tanja Schultz. 2004. Using word lattice information
for a tighter coupling in speech translation systems.
In Proceedings of the International Conference on
Spoken Language Processing, pages 41–44.

Enrique Vidal. 1997. Finite-state speech-to-speech
translation. In Proceedings of the IEEE Interna-
tional Conference in Acoustics, Speech and Signal
Processing, volume 1, pages 111–114, April.

Omar F. Zaidan. 2009. Z-MERT: A fully configurable
open source tool for minimum error rate training of
machine translation systems. The Prague Bulletin of
Mathematical Linguistics, 91:79–88.

Ruiqiang Zhang, Genichiro Kikui, Hirofumi Ya-
mamoto, Taro Watanabe, Frank Soong, and Wai Kit
Lo. 2004. A unified approach in speech-to-speech
translation: integrating features of speech recogni-
tion and machine translation. In Proceedings of
the 20th international conference on Computational
Linguistics.

Xiaohui Zhang, Jan Trmal, Daniel Povey, and San-
jeev Khudanpur. 2014. Improving deep neural net-
work acoustic models using generalized maxout net-
works. In IEEE International Conference on Acous-
tics, Speech and Signal Processing, ICASSP 2014,
Florence, Italy, May 4-9, 2014, pages 215–219.

1907


