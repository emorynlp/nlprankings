










































The Unified Annotation of Syntax and Discourse in the Copenhagen Dependency Treebanks


Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 127–131,
Uppsala, Sweden, 15-16 July 2010. c©2010 Association for Computational Linguistics

The unified annotation of syntax and discourse
in the Copenhagen Dependency Treebanks

Matthias Buch-Kromann Iørn Korzen

Center for Research and Innovation in Translation and Translation Technology
Copenhagen Business School

Abstract

We propose a unified model of syntax and dis-
course in which text structure is viewed as a 
tree structure augmented with anaphoric rela-
tions  and  other  secondary  relations.  We  de-
scribe how the model accounts  for discourse 
connectives  and  the  syntax-discourse-seman-
tics interface. Our model is dependency-based, 
ie, words are the basic building blocks in our 
analyses.  The  analyses  have  been  applied 
cross-linguistically in the Copenhagen Depen-
dency  Treebanks,  a  set  of  parallel  treebanks 
for Danish, English, German, Italian, and Spa-
nish which are currently being annotated with 
respect  to  discourse,  anaphora,  syntax,  mor-
phology, and translational equivalence. 

1 Introduction

The Copenhagen Dependency Treebanks, CDT, 
consist of five parallel open-source treebanks for 
Danish, English, German, Italian, and Spanish.1 
The treebanks are  annotated manually  with re-
spect  to  syntax,  discourse,  anaphora,  morpho-
logy, as well as translational equivalence (word 
alignment) between the Danish source text and 
the target texts in the four other languages. 

The treebanks build on the syntactic annota-
tion  in  the  100,000-word  Danish  Dependency 
Treebank  (Kromann  2003)  and  Danish-English 
Parallel  Dependency  Treebank  (Buch-Kromann 
et al. 2007). Compared to these treebanks, which 
are  only  annotated  for  syntax  and  word  align-
ment,  the new treebanks are also annotated for 
discourse,  anaphora,  and  morphology,  and  the 
syntax annotation has been revised with a much 
more fine-grained set of adverbial relations and a 
number  of  other  adjustments.  The  underlying 
Danish  PAROLE  text  corpus  (Keson  and 
Norling-Christensen  1998)  consists  of  a  broad 
mixture of 200-250 word excerpts from general-
purpose texts.2 The texts were translated into the 
1The treebanks, the annotation manual, and the relation hier-
archy can be downloaded from the web site:
http://code.google.com/p/copenhagen-dependency-treebank
2In practice, the use of text excerpts has not been a problem 
for our discourse annotation: we mainly annotate text ex-

other languages by professional translators who 
had the target language as their native language.

The final treebanks are planned to consist of 
approximately 480 fully annotated parallel texts 
for Danish and English, and a subset of approx-
imately  300  fully  annotated  parallel  texts  for 
German, Italian, and Spanish, with a total of ap-
proximately 380,000 (2·100,000 + 3·60,000) an-
notated word or punctuation tokens  in  the five 
treebanks  in  total.  So  far,  the  annotators  have 
made complete draft annotations for 67% of the 
texts for syntax, 40% for word alignments, 11% 
for discourse and anaphora, and 3% for morpho-
logy. The annotation will be completed in 2010.

In this paper, we focus on how the CDT tree-
banks are annotated with respect  to syntax and 
discourse,  and largely ignore  the  annotation  of 
anaphora, morphology, and word alignments. In 
sections 2 and 3, we present the syntax and dis-
course annotation in the CDT. In section 4, we 
present our account of discourse connectives. In 
section 5, we briefly discuss the syntax-discour-
se-semantics  interface,  and  some  criticisms 
against tree-based theories of discourse. 

2 The syntax annotation of the CDT

The syntactic annotation of the CDT treebanks is 
based on the linguistic principles outlined in the 
dependency  theory  Discontinuous  Grammar 
(Buch-Kromann 2006) and the syntactic annota-
tion  principles  described  in  Kromann  (2003), 
Buch-Kromann et al. (2007), and Buch-Kromann 
et al (2009). All linguistic relations are represen-
ted as  directed labelled relations between words 
or morphemes. The model operates with a prima-
ry dependency tree structure in which each word 
or morpheme is assumed to act as a complement 
or adjunct to another word or morpheme, called 
the  governor (or  head), except for the top node 

cerpts  that  have a  coherent discourse structure,  which in-
cludes 80% of the excerpts in our text corpus.  Moreover, 
given the upper limit on the corpus size that we can afford 
to annotate, small text excerpts allow our corpus to have a 
diversity in text type and genre that may well offset the the-
oretical disadvantage of working with reduced texts.

127



of the sentence or unit, typically the finite verb. 
This structure is augmented with secondary rela-
tions,  e.g.,  between  non-finite  verb  forms  and 
their  subjects,  and  in  antecedent-anaphor  rela-
tions.  Primary  relations  are  drawn  above  the 
nodes and secondary below, all with directed ar-
rows pointing from governor to dependent. The 
relation label is written at the arrow tip, or in the 
middle of the arrow if a word has more than one 
incoming arrow. 

Figure 1. Primary dependency tree (top) and sec-
ondary relations (bottom) for the sentence “It had 

forced her to give up all she had worked for”.

An example is given in Figure 1 above. Here, the 
arrow from “had2” to “It1” identifies “It” as the 
subject of “had”, and the arrow from “forced3” to 
“to5” identifies the phrase headed by “to” as the 
prepositional object of “forced”. Every word de-
fines a unique phrase consisting of the words that 
can be reached from the head word by following 
the downward arrows in the primary tree.3 For 
example,  in  Figure  1,  “worked11”  heads  the 
phrase “worked11 for12”, which has a secondary 
noun  object  nobj  in  “all8”;  “had10”  heads  the 
phrase  “she9 had10 worked11 for12”;  and  “It1” 
heads  the  phrase  “It1”.  Examples  of  secondary 
dependencies  include  the  coreferential  relation 
between “her4” and “she9”, and the anaphoric re-
lation in Figure 2.  Part-of-speech functions are 
written in capital letters under each word. The in-
ventory of relations is described in detail in our 
annotation manual (posted on the CDT web site).

Dependency arrows are  allowed to  cross,  so 
discontinuous word orders such as topicalisations 
and  extrapositions  do  not  require  special  treat-
ment.  This is  exemplified by the discontinuous 
dependency tree in Figure 2, in which the relat-
ive clause headed by “was7” has been extraposed 
from the direct object and placed after the time 
adverbial “today5”.4

3Because  of  this  isomorphism between  phrases  and  head 
words,  a dependency tree can always be represented as a 
phrase-structure  tree  in  which every phrase  has  a  unique 
lexical head; the resulting phrase-structure tree is allowed to 
contain crossing branches.
4In our current syntax annotation, we analyze the initial con-
nective or conjunction as the head of the subordinate clause; 

Figure 2. Primary dependency tree and second-
ary relations for the sentence “We discussed a 
book today which was written by Chomsky”. 

Buch-Kromann (2006) provides a detailed theory 
of how the dependency structure can be used to 
construct a word-order structure which provides 
fine-grained control over the linear order of the 
sentence,  and  how  the  dependency  structure 
provides an interface to compositional semantics 
by determining a unique functor-argument struc-
ture given a particular modifier scope (ie, a spe-
cification of the order in which the adjuncts are 
applied in the meaning construction).5 

3 The discourse annotation of the CDT 

Just like sentence structures can be seen as de-
pendency structures that link up the words and 
morphemes  within  a  sentence  (or,  more  preci-
sely, the phrases headed by these words), so dis-
course structures can be viewed as dependency 
structures that link up the words and morphemes 
within an entire discourse. In Figures 1 and 2, the 
top  nodes  of  the  analysed  sentences  (the  only 
words  without  incoming  arrows)  are  the  finite 
verbs  “had2” and “discussed2” respectively, and 
these are shown in boldface. Basically, the CDT 
discourse annotation consists in linking up each 
such sentence top node with its nucleus (under-
stood as the unique word within another sentence 
that  is  deemed  to  govern  the  relation)  and  la-
belling the relations between the two nodes. 

The inventory of discourse relations in CDT is 
described in the CDT manual. It borrows heavily 
from other  discourse  frameworks,  in  particular 
Rhetorical  Structure  Theory,  RST  (Mann  and 
Thompson,  1987;  Tabaoda  and  Mann,  2006; 
Carlson  et  al,  2001)  and  the  Penn  Discourse 
Treebank,  PDTB  (Webber  2004;  Dinesh  et  al., 
2005,  Prasad  et  al.,  2007,  2008),  as  well  as 
(Korzen,  2006,  2007),  although  the  inventory 
had  to  be  extended  to  accommodate  the  great 

in relative clauses, the relative verb functions as the head, 
i.e., the arrow goes from “a (book)” to “was (written)”.
5In terms of their formal semantics, complements function 
as arguments to their governor, whereas adjuncts function as 
modifiers; i.e., semantically, the governor (type X) acts as 
an argument with the modifier (type X/X) as its functor.

128



variety  of  text  types  in  the  CDT  corpus  other 
than news stories. The inventory allows relation 
names to be formed as disjunctions or conjunc-
tions of  simple relation names,  to specify mul-
tiple relations or ambiguous alternatives. 

One  of  the  most  important  differences  be-
tween the CDT framework and other discourse 
frameworks lies in the way texts are segmented. 
In particular, CDT uses words as the basic build-
ing blocks in the discourse structure, while most 
other discourse frameworks use clauses as their 
atomic  discourse  units,  including  RST,  PDTB, 
GraphBank  (Wolf  and  Gibson,  2005),  and  the 
Pottsdam  Commentary  Corpus,  PCC  (Stede 
2009).6 This allows the nucleus and satellite in a 
discourse  relation  to  be  identified  precisely  by 
means of their head words, as in the example (1) 
below from the CDT corpus, where the second 
paragraph is analyzed as an elaboration of the de-
verbal noun phrase “their judgment” (words that 
are included in our condensed CDT analysis in 
Figure  4  are  indicated  with  boldface  and  sub-
scripted with numbers that identify them):
6As noted by Carlson and Marcu (2001), the boundary be-
tween  syntax  and  discourse  is  rather  unclear:  the  same 
meaning can be expressed in a continuum of ways that ran-
ge from clear discourse constructions (“He laughed.  That 
annoyed me.”) to clear syntactic constructions (“His laugh 
annoyed me.”). Moreover, long discourse units may func-
tion  as  objects  of  attribution  verbs  in  direct  or  indirect 
speech, or as parenthetical remarks embedded within an oth-
erwise normal sentence. CDT's use of words as basic build-
ing blocks,  along with a primary tree structure that  spans 
syntax and discourse, largely eliminates these problems.

(1) Two convicted executives of the July 6 Bank ap­
pealed1 their2 judgment  on  the  spot  from  the 
Copenhagen Municipal Court with a demand for 
acquittal. The prosecuting authority has3 also re-
served the possibility of appeal.

The chairman of the board received4 a year in 
jail and a fine of DKK one million for fraudulent 
abuse of authority […]. The bank’s director  re­
ceived5 6  months  in  jail  and  a  fine of  DKK 
90,000. (Text 0531)

The full CDT analysis of (1) is given in Figure 3, 
a more readable condensed version in Figure 4. 
The  last  sentence  of  the  first  paragraph,  “The 
prosecuting authority has3 also reserved the pos-
sibility of appeal”, is a conjunct to the first sen-
tence, and its top node “has3” is linked to the top 
node of the first sentence, “appealed1”. The slash 
after a relation name indicates an explicit or im-
plicit discourse connective used by the annotat-
ors to support their choice of relation type. 

As  in  CDT's  syntax annotation,  the  primary 
syntax and discourse relations must form a tree 
that spans all the words in the text, possibly sup-
plemented  by  secondary  relations  that  encode 
anaphoric relations and other secondary depen-
dencies. Apart from this, CDT does not place any 
restrictions on the relations; in particular, a word 

Figure 4. Condensed version of Figure 3.

Figure 3. The full CDT analysis of (1) wrt. syntax, discourse, and anaphora.  

129



may  function  as  nucleus  for  several  different 
satellites, discourse relations may join non-adja-
cent clauses, and are allowed to cross; and sec-
ondary  discourse  relations  are  used  to  account 
for the distinction between story line level  and 
speech level in attributions. 

4 Discourse connectives

Discourse connectives play a prominent role in 
PDTB, and inspire the analysis of connectives in 
CDT. However, there are important  differences 
in analysis, which affect the way discourse struc-
tures are construed. In a construction of the form 
“X C Y” where  X and  Y are clauses and  C is a 
discourse  connective  (such  as  “because”,  “sin-
ce”, “when”), three dependency analyses suggest 
themselves, as summarized in Table 5.

Head Conjunction Marker

Syntax

Semantics C'(X',Y') [C'(Y')] (X') [Y'(C')] (X')

Table 5. Three analyses of discourse connectives.

When analyzed as the head of the construction, 
C takes X and Y as its (discourse) complements; 
semantically, the meaning  C'  of  C acts as func-
tor,  and the meanings  X',Y'  of  X,Y act as argu-
ments of  C'.  When analyzed as a subordinating 
conjunction, C subcategorizes for Y and modifies 
X;  semantically,  C'  computes  a  meaning  C'(Y') 
from  Y',  which acts as functor with  X'  as argu-
ment. Finally, analyzed as a marker,  C modifies 
Y which in turn modifies  X; semantically,  Y' se-
lects its meaning  Y'(C')  based on the marker  C' 
(i.e., the marker merely helps disambiguate  Y'); 
Y'(C') then acts as functor with argument X'. 

The three  analyses  are  markedly different  in 
terms  of  their  headedness,  but  quite  similar  in 
terms of their semantics. CDT opts for the mark-
er analysis, with the obvious benefit that there is 
no need to postulate the presence of a phonetic-
ally  empty  head  for  implicit  connectives.  This 
analysis also implies that since discourse markers 
always modify the satellite, explicit and implicit 
discourse markers can be used to determine the 
discourse relation and its direction. 

It is interesting that almost all theories of dis-
course structure, including RST, PDTB, Graph-
Bank, PCC, and the dependency-based discourse 
analysis  proposed by Mladová (2008),  seem to 
analyze connectives as heads  – even in the case 
where  C+Y is an adverbial clause modifying X, 

where virtually all mainstream theories of syntax 
opt  for  one of  the  two other  analyses.  Perhaps 
current  theories  of  discourse  structure  perceive 
discourse structure as a semantic rather than syn-
tactic structure. In any case, it  is not clear that 
this is the most fruitful analysis. A clear distinc-
tion  between  syntactic  structure  and  semantic 
structure has proved crucial to the understanding 
of headedness in syntax (e.g. Croft 1995, Man-
ning 1995), and it is one of the hardwon insights 
of syntax that semantic centrality or prominence 
is not directly reflected in the syntactic surface 
structure.  Something  similar  might  be  true  for 
discourse structure as well.

5 Syntax­discourse­semantics interface

CDT models discourse structure as a primary de-
pendency tree supplemented by secondary rela-
tions. We believe that a tree-based view of dis-
course  provides  many important  benefits,  most 
importantly a clear interface to syntax and com-
positional semantics. There has been several at-
tempts to refute the tree hypothesis on empirical 
grounds,  though,  including  Wolf  and  Gibson 
(2005), Prasad et al (2005), Lee et al (2008), and 
Stede (2009),  who have  put  forward important 
criticisms.  Our  framework  addresses  many  of 
these  objections,  including  the  many  problems 
related to attribution verbs,  which do require a 
complicated  treatment  in  our  framework  with 
secondary dependencies. A full discussion of this 
topic is, however, beyond the scope of this paper.

6 Conclusion

In this paper, we have presented  a dependency-
based view of  discourse  and syntax annotation 
where the syntax and discourse relations in a text 
form a primary dependency tree structure linking 
all the words in the text, supplemented by ana-
phoric relations and other secondary dependen-
cies. The framework forms the basis for the an-
notation  of  syntax,  discourse,  and  anaphora  in 
the Copenhagen Dependency Treebanks.  In fu-
ture  papers,  we will  address  some of  the criti-
cisms  that  have  been  raised  against  tree-based 
theories of discourse. 

7 Acknowledgments

This  work  was  supported  by  a  grant  from the 
Danish  Research  Council  for  the  Humanities. 
Thanks to Bonnie Webber, Henrik Høeg Müller, 
Per Anker Jensen, Peter Colliander, and our three 
reviewers for their valuable commments. 

130



References 

Matthias Buch-Kromann 2006.  Discontinuous Gram­
mar. A dependency­based model of human parsing 
and language learning. Copenhagen: Copenhagen 
Business School.

Matthias  Buch-Kromann,  Iørn  Korzen,  and  Henrik 
Høeg Müller. 2009. Uncovering the ‘lost’ structure 
of  translations  with  parallel  treebanks. Copen­
hagen Studies in Language 38: 199-224.

Matthias  Buch-Kromann,  Jürgen  Wedekind,  and 
Jakob  Elming.  2007.  The  Copenhagen  Danish-
English Dependency  Treebank v.  2.0.  http://code.-
google.com/p/copenhagen-dependency-treebank

Lynn  Carlson  and  Daniel  Marcu.  2001.  Discourse 
Tagging Reference Manual.  ISI Technical  Report 
ISI-TR-545.

Lynn Carlson, Daniel Marcu, and Mary Ellen Okur-
owski. 2001. Building a Discourse-Tagged Corpus 
in the Framework of Rhetorical Structure Theory. 
In  Proc.  of  the  2nd  SIGdial  Workshop  on  Dis­
course  and  Dialogue.  Association  for  Computa-
tional Linguistics: 1-10.

William Croft.  1995. What's  a  head?  In J.  Rooryck 
and L. Zaring (eds.). Phrase Structure and the Lex­
icon. Kluwer. 

Nikhil  Dinesh,  Alan  Lee, Eleni  Miltsakaki,  Rashmi 
Prasad, Aravind Joshi, and Bonnie Webber. 2005. 
Attribution and the (Non-)Alignment of Syntactic 
and Discourse Arguments of Connectives. Proc. of  
the Workshop on Frontiers in Corpus Annotation 
II: Pie in the Sky, pp. 29-36.

Britt  Keson and Ole Norling-Christensen. 1998. PA-
ROLE-DK. The Danish Society for Language and 
Literature.

Iørn Korzen. 2006. Endocentric and Exocentric Lan-
guages  in  Translation.  Perspectives:  Studies  in  
Translatology, 13 (1): 21-37.

Iørn Korzen. 2007. Linguistic typology, text structure 
and appositions. In I. Korzen, M. Lambert, H. Vas-
siliadou. Langues d’Europe, l’Europe des langues.  
Croisements linguistiques. Scolia 22: 21-42.

Matthias T. Kromann. 2003. The Danish Dependency 
Treebank and the DTAG treebank tool. In Proc. of  
Treebanks and Linguistic Theories (TLT 2003), 14­
15 November, Växjö. 217–220.

Alan Lee, Rashmi Prasad, Aravind Joshi, and Bonnie 
Webber 2008. Departures from Tree Structures in 
Discourse:  Shared  Arguments  in  the  Penn  Dis-
course Treebank. Proceedings of the Constraints in  
Discourse III Workshop.

Willliam C.  Mann and  Sandra  A.  Thompson 1987. 
Rhetorical Structure Theory. A Theory of Text  
Organization. ISI: Information Sciences Institute, 
Los Angeles, CA, ISI/RS-87-190, 1-81. 

Christopher D. Manning. 1995. Dissociating functor-
argument  structure from surface  phrase  structure: 
the relationship of HPSG Order Domains to LFG. 
Ms., Carnegie Mellon University.

Lucie Mladová,  Šarka Zikánová, and Eva Hajičová. 
2008.  From  Sentence  to  Discourse:  Building  an 
Annotation Scheme for Discourse Based on Prague 
Dependency Treebank. In  Proc. 6th International  
Conference  on  Language Resources  and  Evalua­
tion (LREC 2008).

Rashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh, Alan 
Lee,  Aravind  Joshi,  Livio  Robaldo,  and  Bonnie 
Webber. 2007. The Penn Discourse TreeBank 2.0. 
Annotation  Manual.  The  PDTB Research  Group. 
http://  www.seas.upenn.edu/~pdtb/PDTBAPI/pdtb-anno  -  
tation-manual.pdf

Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie 
Webber. 2008. The Penn Discourse TreeBank 2.0. 
In Proc. 6th Int. Conf. on Language Resources and 
Evaluation, Marrakech, Morocco.

Manfred  Stede.  2008.  Disambiguating  Rhetorical 
Structure.  Research  on  Language  and  Computa­
tion (6), pp. 311-332.. 

Maite Taboada and William C. Mann. 2006a. Rhetori-
cal  Structure  Theory:  looking  back  and  moving 
ahead. Discourse Studies 8/3/423.

Maite Taboada and William C. Mann. 2006b. Appli-
cations of  Rhetorical Structure Theory.  Discourse 
Studies 8/4/567. http://dis.sagepub.com

Bonnie  Webber.  2004.  D-LTAG:  extending  lexical-
ized TAG to discourse. Cognitive Science 28: 751-
779.

Bonnie Webber. 2006. Accounting for Discourse Re-
lation: Constituency and Dependency. M. Dalrym-
ple (ed.).  Festschrift for Ron Kaplan. CSLI Publi-
cations.

Florian Wolf and Edward Gibson 2005. Representing 
Discourse  Coherence:  A  Corpus-Based  Study. 
Computational Linguistics 31(2), 249-287.

131


