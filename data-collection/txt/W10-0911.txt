










































Machine Reading at the University of Washington


Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 87–95,
Los Angeles, California, June 2010. c©2010 Association for Computational Linguistics

Machine Reading at the University of Washington

Hoifung Poon, Janara Christensen, Pedro Domingos, Oren Etzioni, Raphael Hoffmann,

Chloe Kiddon, Thomas Lin, Xiao Ling, Mausam, Alan Ritter, Stefan Schoenmackers,

Stephen Soderland, Dan Weld, Fei Wu, Congle Zhang

Department of Computer Science & Engineering

University of Washington

Seattle, WA 98195

{hoifung,janara,pedrod,etzioni,raphaelh,chloe,tlin,xiaoling,mausam,

aritter,stef,soderland,weld,wufei,clzhang}@cs.washington.edu

Abstract

Machine reading is a long-standing goal of AI

and NLP. In recent years, tremendous progress

has been made in developing machine learning

approaches for many of its subtasks such as

parsing, information extraction, and question

answering. However, existing end-to-end so-

lutions typically require substantial amount of

human efforts (e.g., labeled data and/or man-

ual engineering), and are not well poised for

Web-scale knowledge acquisition. In this pa-

per, we propose a unifying approach for ma-

chine reading by bootstrapping from the easi-

est extractable knowledge and conquering the

long tail via a self-supervised learning pro-

cess. This self-supervision is powered by joint

inference based on Markov logic, and is made

scalable by leveraging hierarchical structures

and coarse-to-fine inference. Researchers at

the University of Washington have taken the

first steps in this direction. Our existing work

explores the wide spectrum of this vision and

shows its promise.

1 Introduction

Machine reading, or learning by reading, aims to

extract knowledge automatically from unstructured

text and apply the extracted knowledge to end tasks

such as decision making and question answering. It

has been a major goal of AI and NLP since their

early days. With the advent of the Web, the billions

of online text documents contain virtually unlimited

amount of knowledge to extract, further increasing

the importance and urgency of machine reading.

In the past, there has been a lot of progress in

automating many subtasks of machine reading by

machine learning approaches (e.g., components in

the traditional NLP pipeline such as POS tagging

and syntactic parsing). However, end-to-end solu-

tions are still rare, and existing systems typically re-

quire substantial amount of human effort in manual

engineering and/or labeling examples. As a result,

they often target restricted domains and only extract

limited types of knowledge (e.g., a pre-specified re-

lation). Moreover, many machine reading systems

train their knowledge extractors once and do not

leverage further learning opportunities such as ad-

ditional text and interaction with end users.

Ideally, a machine reading system should strive to

satisfy the following desiderata:

End-to-end: the system should input raw text, ex-

tract knowledge, and be able to answer ques-

tions and support other end tasks;

High quality: the system should extract knowledge

with high accuracy;

Large-scale: the system should acquire knowledge

at Web-scale and be open to arbitrary domains,

genres, and languages;

Maximally autonomous: the system should incur

minimal human effort;

Continuous learning from experience: the

system should constantly integrate new infor-

mation sources (e.g., new text documents) and

learn from user questions and feedback (e.g.,

via performing end tasks) to continuously

improve its performance.

These desiderata raise many intriguing and chal-

lenging research questions. Machine reading re-

search at the University of Washington has explored

87



a wide spectrum of solutions to these challenges and

has produced a large number of initial systems that

demonstrated promising performance. During this

expedition, an underlying unifying vision starts to

emerge. It becomes apparent that the key to solving

machine reading is to:

1. Conquer the long tail of textual knowledge via

a self-supervised learning process that lever-

ages data redundancy to bootstrap from the

head and propagates information down the long

tail by joint inference;

2. Scale this process to billions of Web documents

by identifying and leveraging ubiquitous struc-

tures that lead to sparsity.

In Section 2, we present this vision in detail, iden-

tify the major dimensions these initial systems have

explored, and propose a unifying approach that sat-

isfies all five desiderata. In Section 3, we reivew

machine reading research at the University of Wash-

ington and show how they form synergistic effort

towards solving the machine reading problem. We

conclude in Section 4.

2 A Unifying Approach for Machine

Reading

The core challenges to machine reading stem from

the massive scale of the Web and the long-tailed dis-

tribution of textual knowledge. The heterogeneous

Web contains texts that vary substantially in subject

matters (e.g., finance vs. biology) and writing styles

(e.g., blog posts vs. scientific papers). In addition,

natural languages are famous for their myraid vari-

ations in expressing the same meaning. A fact may

be stated in a straightforward way such as “kale con-

tains calcium”. More often though, it may be stated

in a syntactically and/or lexically different way than

as phrased in an end task (e.g., “calcium is found in

kale”). Finally, many facts are not even stated ex-

plicitly, and must be inferred from other facts (e.g.,

“kale prevents osteoporosis” may not be stated ex-

plicitly but can be inferred by combining facts such

as “kale contains calcium” and “calcium helps pre-

vent osteoporosis”). As a result, machine reading

must not rely on explicit supervision such as manual

rules and labeled examples, which will incur pro-

hibitive cost in the Web scale. Instead, it must be

able to learn from indirect supervision.

�
�
��
�
��
��

	�
�����

��������������
��

�

�
�������������

Figure 1: A unifying vision for machine reading: boot-

strap from the head regime of the power-law distribu-

tion of textual knowledge, and conquer the long tail in

a self-supervised learning process that raises certainty on

sparse extractions by propagating information via joint

inference from frequent extractions.

A key source of indirect supervision is meta

knowledge about the domains. For example, the

TextRunner system (Banko et al., 2007) hinges on

the observation that there exist general, relation-

independent patterns for information extraction. An-

other key source of indirect supervision is data re-

dundancy. While a rare extracted fact or inference

pattern may arise by chance of error, it is much less

likely so for the ones with many repetitions (Downey

et al., 2010). Such highly-redundant knowledge can

be extracted easily and with high confidence, and

can be leveraged for bootstrapping. For knowledge

that resides in the long tail, explicit forms of redun-

dancy (e.g., identical expressions) are rare, but this

can be circumvented by joint inference. For exam-

ple, expressions that are composed with or by sim-

ilar expressions probably have the same meaning;

the fact that kale prevents osteoporosis can be de-

rived by combining the facts that kale contains cal-

cium and that calcium helps prevent osteoporosis via

a transitivity-through inference pattern. In general,

joint inference can take various forms, ranging from

simple voting to shrinkage in a probabilistic ontol-

ogy to sophisticated probabilistic reasoning based

on a joint model. Simple ones tend to scale bet-

ter, but their capability in propagating information

is limited. More sophisticated methods can uncover

implicit redundancy and propagate much more in-

88



formation with higher quality, yet the challenge is

how to make them scale as well as simple ones.

To do machine reading, a self-supervised learning

process, informed by meta knowledege, stipulates

what form of joint inference to use and how. Effec-

tively, it increases certainty on sparse extractions by

propagating information from more frequent ones.

Figure 1 illustrates this unifying vision.

In the past, machine reading research at the Uni-

versity of Washington has explored a variety of so-

lutions that span the key dimensions of this uni-

fying vision: knowledge representation, bootstrap-

ping, self-supervised learning, large-scale joint in-

ference, ontology induction, continuous learning.

See Section 3 for more details. Based on this ex-

perience, one direction seems particularly promising

that we would propose here as our unifying approach

for end-to-end machine reading:

Markov logic is used as the unifying framework for

knowledge representation and joint inference;

Self-supervised learning is governed by a joint

probabilistic model that incorporates a small

amount of heuristic knowledge and large-scale

relational structures to maximize the amount

and quality of information to propagate;

Joint inference is made scalable to the Web by

coarse-to-fine inference.

Probabilistic ontologies are induced from text to

guarantee tractability in coarse-to-fine infer-

ence. This ontology induction and popula-

tion are incorporated into the joint probabilistic

model for self-supervision;

Continuous learning is accomplished by combin-

ing bootstrapping and crowdsourced content

creation to synergistically improve the reading

system from user interaction and feedback.

A distinctive feature of this approach is its empha-

sis on using sophisticated joint inference. Recently,

joint inference has received increasing interest in

AI, machine learning, and NLP, with Markov logic

(Domingos and Lowd, 2009) being one of the lead-

ing unifying frameworks. Past work has shown that

it can substantially improve predictive accuracy in

supervised learning (e.g., (Getoor and Taskar, 2007;

Bakir et al., 2007)). We propose to build on these ad-

vances, but apply joint inference beyond supervised

learning, with labeled examples supplanted by indi-

rect supervision.

Another distinctive feature is that we propose

to use coarse-to-fine inference (Felzenszwalb and

McAllester, 2007; Petrov, 2009) as a unifying

framework to scale inference to the Web. Es-

sentially, coarse-to-fine inference leverages the

sparsity imposed by hierarchical structures that

are ubiquitous in human knowledge (e.g., tax-

onomies/ontologies). At coarse levels (top levels in

a hierarchy), ambiguities are rare (there are few ob-

jects and relations), and inference can be conducted

very efficiently. The result is then used to prune un-

promising refinements at the next level. This process

continues down the hierarchy until decision can be

made. In this way, inference can potentially be sped

up exponentially, analogous to binary tree search.

Finally, we propose a novel form of continuous

learning by leveraging the interaction between the

system and end users to constantly improve the per-

formance. This is straightforward to do in our ap-

proach given the self-supervision process and the

availability of powerful joint inference. Essentially,

when the system output is applied to an end task

(e.g., answering questions), the feedback from user

is collected and incorporated back into the system

as a bootstrap source. The feedback can take the

form of explicit supervision (e.g., via community

content creation or active learning) or indirect sig-

nals (e.g., click data and query logs). In this way,

we can bootstrap an online community by an initial

machine reading system that provides imperfect but

valuable service in end tasks, and continuously im-

prove the quality of system output, which attracts

more users with higher degree of participation, thus

creating a positive feedback loop and raising the ma-

chine reading performance to a high level that is dif-

ficult to attain otherwise.

3 Summary of Progress to Date

The University of Washington has been one of the

leading places for machine reading research and has

produced many cutting-edge systems, e.g., WIEN

(first wrapper induction system for information ex-

traction), Mulder (first fully automatic Web-scale

question answering system), KnowItAll/TextRunner

(first systems to do open-domain information extrac-

89



tion from the Web corpus at large scale), Kylin (first

self-supervised system for Wikipedia-based infor-

mation extraction), UCR (first unsupervised corefer-

ence resolution system that rivals the performance of

supervised systems), Holmes (first Web-scale joint

inference system), USP (first unsupervised system

for semantic parsing).

Figure 2 shows the evolution of the major sys-

tems; dashed lines signify influence in key ideas

(e.g., Mulder inspires KnowItAll), and solid lines

signify dataflow (e.g., Holmes inputs TextRunner tu-

ples). These systems span a wide spectrum in scal-

ability (assessed by speed and quantity in extrac-

tion) and comprehension (assessed by unit yield of

knowledge at a fixed precision level). At one ex-

treme, the TextRunner system is highly scalable, ca-

pable of extracting billions of facts, but it focuses on

shallow extractions from simple sentences. At the

other extreme, the USP and LOFT systems achieve

much higher level of comprehension (e.g., in a task

of extracting knowledge from biomedical papers and

answering questions, USP obtains more than three

times as many correct answers as TextRunner, and

LOFT obtains more than six times as many correct

answers as TextRunner), but are much less scalable

than TextRunner.

In the remainder of the section, we review the

progress made to date and identify key directions for

future work.

3.1 Knowledge Representation and Joint

Inference

Knowledge representations used in these systems

vary widely in expressiveness, ranging from sim-

ple ones like relation triples (<subject, relation,

object>; e.g., in KnowItAll and TextRunner), to

clusters of relation triples or triple components (e.g.,

in SNE, RESOLVER), to arbitrary logical formulas

and their clusters (e.g., in USP, LOFT). Similarly,

a variety forms of joint inference have been used,

ranging from simple voting to heuristic rules to so-

phisticated probabilistic models. All these can be

compactly encoded in Markov logic (Domingos and

Lowd, 2009), which provides a unifying framework

for knowledge representation and joint inference.

Past work at Washington has shown that in su-

pervised learning, joint inference can substantially

improve predictive performance on tasks related to

machine reading (e.g., citation information extrac-

tion (Poon and Domingos, 2007), ontology induc-

tion (Wu and Weld, 2008), temporal information

extraction (Ling and Weld, 2010)). In addition, it

has demonstrated that sophisticated joint inference

can enable effective learning without any labeled

information (UCR, USP, LOFT), and that joint in-

ference can scale to millions of Web documents by

leveraging sparsity in naturally occurring relations

(Holmes, Sherlock), showing the promise of our uni-

fying approach.

Simpler representations limit the expressiveness

in representing knowledge and the degree of sophis-

tication in joint inference, but they currently scale

much better than more expressive ones. A key direc-

tion for future work is to evaluate this tradeoff more

thoroughly, e.g., for each class of end tasks, to what

degree do simple representations limit the effective-

ness in performing the end tasks? Can we automate

the choice of representations to strike the best trade-

off for a specific end task? Can we advance joint

inference algorithms to such a degree that sophisti-

cated inference scales as well as simple ones?

3.2 Bootstrapping

Past work at Washington has identified and lever-

aged a wide range of sources for bootstrapping. Ex-

amples include Wikipedia (Kylin, KOG, IIA, WOE,

WPE), Web lists (KnowItAll, WPE), Web tables

(WebTables), Hearst patterns (KnowItAll), heuristic

rules (TextRunner), semantic role labels (SRL-IE),

etc.

In general, potential bootstrap sources can be

broadly divided into domain knowledge (e.g., pat-

terns and rules) and crowdsourced contents (e.g., lin-

guistic resources, Wikipedia, Amazon Mechanical

Turk, the ESP game).

A key direction for future work is to combine

bootstrapping with crowdsourced content creation

for continuous learning. (Also see Subsection 3.6.)

3.3 Self-Supervised Learning

Although the ways past systems conduct self-

supervision vary widely in detail, they can be di-

vided into two broad categories. One uses heuristic

rules that exploit existing semi-structured resources

to generate noisy training examples for use by su-

pervised learning methods and with cotraining (e.g.,

90



�������

��	


�����

�	����	�

�������

�	���

����� �	�

����������

����

��	���

��	

 �� ��!��
	

����

���"#�$���

#�%�& �����"'

���� ���� ���� ���� �������� ����

��$�($�&

�)�*��

���

 +�

��+����(���

���*�	

����

Figure 2: The evolution of major machine reading systems at the University of Washington. Dashed lines signify

influence and solid lines signify dataflow. At the top are the years of publications. ShopBot learns comparison-

shopping agents via self-supervision using heuristic knowledge (Doorenbos et al., 1997); WIEN induces wrappers

for information extraction via self-supervision using joint inference to combine simple atomic extractors (Kushmerick

et al., 1997); Mulder answers factoid questions by leveraging redundancy to rank candidate answers extracted from

multiple search query results (Kwok et al., 2001); KnowItAll conducts open-domain information extraction via self-

supervision bootstrapping from Hearst patterns (Etzioni et al., 2005); Opine builds on KnowItAll and mines product

reviews via self-supervision using joint inference over neighborhood features (Popescu and Etzioni, 2005); Kylin pop-

ulates Wikipedia infoboxes via self-supervision bootstrapping from existing infoboxes (Wu and Weld, 2007); LEX

conducts Web-scale name entity recognition by leveraging collocation statistics (Downey et al., 2007a); REALM

improves sparse open-domain information extraction via relational clustering and language modeling (Downey et al.,

2007b); RESOLVER performs entity and relation resolution via relational clustering (Yates and Etzioni, 2007); Tex-

tRunner conducts open-domain information extraction via self-supervision bootstrapping from heuristic rules (Banko

et al., 2007); AuContraire automatically identifies contradictory statements in a large web corpus using functional re-

lations (Ritter et al., 2008); HOLMES infers new facts from TextRunner output using Markov logic (Schoenmackers

et al., 2008); KOG learns a rich ontology by combining Wikipedia infoboxes with WordNet via joint inference using

Markov Logic Networks (Wu and Weld, 2008), shrinkage over this ontology vastly improves the recall of Kylin’s

extractors; UCR performs state-of-the-art unsupervised coreference resolution by incorporating a small amount of

domain knowledge and conducting joint inference among entity mentions with Markov logic (Poon and Domingos,

2008b); SNE constructs a semantic network over TextRunner output via relational clustering with Markov logic (Kok

and Domingos, 2008); WebTables conducts Web-scale information extraction by leveraging HTML table structures

(Cafarella et al., 2008); IIA learns from infoboxes to filter open-domain information extraction toward assertions that

are interesting to people (Lin et al., 2009); USP jointly learns a semantic parser and extracts knowledge via recursive

relational clustering with Markov logic (Poon and Domingos, 2009); LDA-SP automatically infers a compact repre-

sentation describing the plausible arguments for a relation using an LDA-Style model and Bayesian Inference (Ritter

et al., 2010); LOFT builds on USP and jointly performs ontology induction, population, and knowledge extraction via

joint recursive relational clustering and shrinkage with Markov logic (Poon and Domingos, 2010); OLPI improves the

efficiency of lifted probabilistic inference and learning via coarse-to-fine inference based on type hierarchies (Kiddon

and Domingos, 2010). SHERLOCK induces new inference rules via relational learning (Schoenmackers et al., 2010);

SRL-IE conducts open-domain information extraction by bootstrapping from semantic role labels, PrecHybrid is a

hybrid version between SRL-IE and TextRunner, which given a budget of computation time does better than either

system (Christensen et al., 2010); WOE builds on Kylin and conducts open-domain information extraction (Wu and

Weld, 2010); WPE learns 5000 relational extractors by bootstrapping from Wikipedia and using Web lists to generate

dynamic, relation-specific lexicon features (Hoffmann et al., 2010).

91



TextRunner, Kylin, KOG, WOE, WPE). Another

uses unsupervised learning and often takes a partic-

ular form of relational clustering (e.g., objects asso-

ciated with similar relations tend to be the same and

vice versa, as in REALM, RESOLVER, SNE, UCR,

USP, LDA-SP, LOFT, etc.).

Some distinctive types of self-supervision in-

clude shrinkage based on an ontology (KOG,

LOFT, OLPI), probabilistic inference via hand-

crafted or learned inference patterns (Holmes, Sher-

lock), and cotraining using relation-specific and

relation-independent (open) extraction to reinforce

semantic coherence (Wu et al., 2008).

A key direction for future work is to develop a

unifying framework for self-supervised learning by

combining the strengths of existing methods and

overcoming their limitations. This will likely take

the form of a new learning paradigm that combines

existing paradigms such as supervised learning, rela-

tional clustering, semi-supervised learning, and ac-

tive learning into a unifying learning framework that

synergistically leverages diverse forms of supervi-

sion and information sources.

3.4 Large-Scale Joint Inference

To apply sophisticated joint inference in machine

reading, the major challenge is to make it scal-

able to billions of text documents. A general solu-

tion is to identify and leverage ubiquitous problem

structures that lead to sparsity. For example, order

of magnitude reduction in both memory and infer-

ence time can be achieved for relational inference

by leveraging the fact that most relational atoms are

false, which trivially satisfy most relational formulas

(Singla and Domingos, 2006; Poon and Domingos,

2008a); joint inference with naturally occurring tex-

tual relations can scale to millions of Web pages by

leveraging the fact that such relations are approxi-

mately functional (Schoenmackers et al., 2008).

More generally, sparsity arises from hierarchical

structures (e.g., ontologies) that are naturally exhib-

ited in human knowledge, and can be leveraged to

do coarse-to-fine inference (OLPI).

The success of coarse-to-fine inference hinges on

the availability and quality of hierarchical structures.

Therefore, a key direction for future work is to auto-

matically induce such hierarchies. (Also see next

subsection.) Moreover, given the desideratum of

continuous learning from experience, and the speedy

evolution of the Web (new contents, formats, etc.),

it is important that we develop online methods for

self-supervision and joint inference. For example,

when a new text document arrives, the reading sys-

tem should not relearn from scratch, but should iden-

tify only the relevant pieces of knowledge and con-

duct limited-scoped inference and learning accord-

ingly.

3.5 Ontology Induction

As mentioned in previous subsections, ontologies

play an important role in both self-supervision

(shrinkage) and large-scale inference (coarse-to-fine

inference). A distinctive feature in our unifying ap-

proach is to induce probabilistic ontologies, which

can be learned from noisy text and support joint

inference. Past systems have explored two differ-

ent approaches to probabilistic ontology induction.

One approach is to bootstrap from existing onto-

logical structures and apply self-supervision to cor-

rect the erroneous nodes and fill in the missing ones

(KOG). Another approach is to integrate ontology

induction with hierarchical smoothing, and jointly

pursue unsupervised ontology induction, population

and knowledge extraction (LOFT).

A key direction for future work is to combine

these two paradigms. As case studies in ontology

integration, prior research has devised probabilistic

schema mappings and corpus-based matching algo-

rithms (Doan, 2002; Madhavan, 2005; Dong et al.,

2007), and has automatically constructed mappings

between the Wikipedia infobox “ontology” and the

Freebase ontology. This latter endeavor illustrated

the complexity of the necessary mappings: a simple

attribute in one ontology may correspond to a com-

plex relational view in the other, comprising three

join operations; searching for such matches yields

a search space with billions of possible correspon-

dences for just a single attribute.

Another key direction is to develop general meth-

ods for inducing multi-facet, multi-inheritance on-

tologies. Although single-inheritance, tree-like hier-

archies are easier to induce and reason with, natu-

rally occurring ontologies generally take the form of

a lattice rather than a tree.

92



3.6 Continuous Learning

Early work at Washington proposed to construct

knowledge bases by mass collaboration (Richard-

son and Domingos, 2003). A key challenge is to

combine inconsistent knowledge sources of varying

quality, which motivated the subsequent develop-

ment of Markov logic. While this work did not do

machine reading, its emphasis on lifelong learning

from user feedback resonates with our approach on

continuous learning.

Past work at Washington has demonstrated the

promise of our approach. For example, (Banko and

Etzioni, 2007) automated theory formation based on

TextRunner extractions via a lifelong-learning pro-

cess; (Hoffmann et al., 2009) show that the pairing

of Kylin and community content creation benefits

both by sharing Wikipedia edits; (Soderland et al.,

2010) successfully adapted the TextRunner open-

domain information extraction system to specific do-

mains via active learning.

Our approach also resonates with the never-

ending learning paradigm for “Reading the Web”

(Carlson et al., 2010). In future work, we intend to

combine our approach with related ones to enable

more effective continuous learning from experience.

4 Conclusion

This paper proposes a unifying approach to ma-

chine reading that is end-to-end, large-scale, maxi-

mally autonomous, and capable of continuous learn-

ing from experience. At the core of this approach

is a self-supervised learning process that conquers

the long tail of textual knowledge by propagating in-

formation via joint inference. Markov logic is used

as the unifying framework for knowledge represen-

tation and joint inference. Sophisticated joint in-

ference is made scalable by coarse-to-fine inference

based on induced probabilistic ontologies. This uni-

fying approach builds on the prolific experience in

cutting-edge machine reading research at the Uni-

versity of Washington. Past results demonstrate its

promise and reveal key directions for future work.

5 Acknowledgement

This research was partly funded by ARO grant

W911NF-08-1-0242, AFRL contract FA8750-09-

C-0181, DARPA contracts FA8750-05-2-0283,

FA8750-07-D-0185, HR0011-06-C-0025, HR0011-

07-C-0060, NBCH-D030010 and FA8750-09-C-

0179, NSF grants IIS-0803481 and IIS-0534881,

and ONR grant N00014-08-1-0670 and N00014-08-

1-0431, the WRF / TJ Cable Professorship, a gift

from Google, and carried out at the University of

Washington’s Turing Center. The views and con-

clusions contained in this document are those of the

authors and should not be interpreted as necessarily

representing the official policies, either expressed or

implied, of ARO, DARPA, NSF, ONR, or the United

States Government.

References

G. Bakir, T. Hofmann, B. B. Schölkopf, A. Smola,

B. Taskar, S. Vishwanathan, and (eds.). 2007. Pre-

dicting Structured Data. MIT Press, Cambridge, MA.

M. Banko and O. Etzioni. 2007. Strategies for lifelong

knowledge extraction from the web. In Proceedings of

the Sixteenth International Conference on Knowledge

Capture, British Columbia, Canada.

Michele Banko, Michael J. Cafarella, Stephen Soderland,

Matt Broadhead, and Oren Etzioni. 2007. Open in-

formation extraction from the web. In Proceedings of

the Twentieth International Joint Conference on Artifi-

cial Intelligence, pages 2670–2676, Hyderabad, India.

AAAI Press.

Michael J. Cafarella, Jayant Madhavan, and Alon Halevy.

2008. Web-scale extraction of structured data. SIG-

MOD Record, 37(4):55–61.

Andrew Carlson, Justin Betteridge, Richard C. Wang, Es-

tevam R. Hruschka Jr., and Tom M. Mitchell. 2010.

Coupled semi-supervised learning for information ex-

traction. In Proceedings of the Third ACM Interna-

tional Conference on Web Search and Data Mining.

Janara Christensen, Mausam, Stephen Soderland, and

Oren Etzioni. 2010. Semantic role labeling for open

information extraction. In Proceedings of the First In-

ternational Workshop on Formalisms and Methodol-

ogy for Learning by Reading.

Anhai Doan. 2002. Learning to Map between Structured

Representations of Data. Ph.D. thesis, University of

Washington.

Pedro Domingos and Daniel Lowd. 2009. Markov

Logic: An Interface Layer for Artificial Intelligence.

Morgan & Claypool, San Rafael, CA.

Xin Dong, Alon Halevy, and Cong Yu. 2007. Data inte-

gration with uncertainty. VLDB Journal.

Robert B. Doorenbos, Oren Etzioni, and Daniel S. Weld.

1997. A scalable comparison-shopping agent for the

world-wide web. In Proceedings of AGENTS-97.

93



Doug Downey, Matthew Broadhead, and Oren Etzioni.

2007a. Locating complex named entities in web text.

In Proceedings of the Twentieth International Joint

Conference on Artificial Intelligence.

Doug Downey, Stefan Schoenmackers, and Oren Etzioni.

2007b. Sparse information extraction: Unsupervised

language models to the rescue. In Proceedings of

the Forty Fifth Annual Meeting of the Association for

Computational Linguistics.

Doug Downey, Oren Etzioni, and Stephen Soderland.

2010. Analysis of a probabilistic model of redundancy

in unsupervised information extraction. In Artificial

Intelligence.

Oren Etzioni, Michael Cafarella, Doug Downey, Ana-

Maria Popescu, Tal Shaked, Stephen Soderland,

Daniel S. Weld, and Alexander Yates. 2005. Unsuper-

vised named-entity extraction from the web: An exper-

imental study. Artificial Intelligence, 165(1):91–134.

Pedro F. Felzenszwalb and David McAllester. 2007. The

generalized A* architecture. Journal of Artificial In-

telligence Research, 29.

Lise Getoor and Ben Taskar, editors. 2007. Introduction

to Statistical Relational Learning. MIT Press, Cam-

bridge, MA.

Raphael Hoffmann, Saleema Amershi, Kayur Patel, Fei

Wu, James Fogarty, and Daniel S. Weld. 2009.

Amplifying community content creation using mixed-

initiative information extraction. In Proceedings of

CHI-09.

Raphael Hoffmann, Congle Zhang, and Daniel S. Weld.

2010. Learning 5000 relational extractors. In submis-

sion.

Chloe Kiddon and Pedro Domingos. 2010. Ontological

lifted probabilistic inference. In submission.

Stanley Kok and Pedro Domingos. 2008. Extracting se-

mantic networks from text via relational clustering. In

Proceedings of the Nineteenth European Conference

on Machine Learning, pages 624–639, Antwerp, Bel-

gium. Springer.

Nicholas Kushmerick, Daniel S. Weld, and Robert

Doorenbos. 1997. Wrapper induction for information

extraction. In Proceedings of the Fifteenth Interna-

tional Joint Conference on Artificial Intelligence.

Cody Kwok, Oren Etzioni, and Daniel S. Weld. 2001.

Scaling question answering to the web. In Proceed-

ings of the Tenth International Conference on World

Wide Web.

Thomas Lin, Oren Etzioni, and James Fogarty. 2009.

Identifying interesting assertions from the web. In

Proceedings of the Eighteenth Conference on Informa-

tion and Knowledge Management.

Xiao Ling and Daniel S. Weld. 2010. Temporal infor-

mation extraction. In Proceedings of the Twenty Fifth

National Conference on Artificial Intelligence.

Jayant Madhavan. 2005. Using known schemas and

mappings to construct new semantic mappings. Ph.D.

thesis, University of Washington.

Slav Petrov. 2009. Coarse-to-Fine Natural Language

Processing. Ph.D. thesis, Department of Computer

Science, University of Berkeley.

Hoifung Poon and Pedro Domingos. 2007. Joint infer-

ence in information extraction. In Proceedings of the

Twenty Second National Conference on Artificial In-

telligence, pages 913–918, Vancouver, Canada. AAAI

Press.

Hoifung Poon and Pedro Domingos. 2008a. A general

method for reducing the complexity of relational in-

ference and its application to mcmc. In Proceedings

of the Twenty Third National Conference on Artificial

Intelligence, pages 1075–1080, Chicago, IL. AAAI

Press.

Hoifung Poon and Pedro Domingos. 2008b. Joint un-

supervised coreference resolution with Markov logic.

In Proceedings of the 2008 Conference on Empirical

Methods in Natural Language Processing, pages 649–

658, Honolulu, HI. ACL.

Hoifung Poon and Pedro Domingos. 2009. Unsuper-

vised semantic parsing. In Proceedings of the 2009

Conference on Empirical Methods in Natural Lan-

guage Processing, pages 1–10, Singapore. ACL.

Hoifung Poon and Pedro Domingos. 2010. Unsuper-

vised ontological induction from text. In submission.

Ana-Maria Popescu and Oren Etzioni. 2005. Extract-

ing product features and opinions from reviews. In

Proceedings of the Joint Conference on Human Lan-

guage Technology and Empirical Methods in Natural

Language Processing.

Matt Richardson and Pedro Domingos. 2003. Building

large knowledge bases by mass collaboration. In Pro-

ceedings of the Second International Conference on

Knowledge Capture, pages 129–137, Sanibel Island,

FL. ACM Press.

Alan Ritter, Doug Downey, Stephen Soderland, and Oren

Etzioni. 2008. It’s a contradiction – no, it’s not: A

case study using functional relations. In Proceedings

of the 2008 Conference on Empirical Methods in Nat-

ural Language Processing.

Alan Ritter, Mausam, and Oren Etzioni. 2010. A latent

dirichlet allocation method for selectional preferences.

In submission.

Stefan Schoenmackers, Oren Etzioni, and Daniel S.

Weld. 2008. Scaling textual inference to the web.

In Proceedings of the 2008 Conference on Empirical

Methods in Natural Language Processing.

Stefan Schoenmackers, Jesse Davis, Oren Etzioni, and

Daniel S. Weld. 2010. Learning first-order horn

clauses from web text. In submission.

94



Parag Singla and Pedro Domingos. 2006. Memory-

efficient inference in relational domains. In Proceed-

ings of the Twenty First National Conference on Arti-

ficial Intelligence.

Stephen Soderland, Brendan Roof, Bo Qin, Mausam, and

Oren Etzioni. 2010. Adapting open information ex-

traction to domain-specific relations. In submission.

Fei Wu and Daniel S. Weld. 2007. Automatically se-

mantifying wikipedia. In Proceedings of the Sixteenth

Conference on Information and Knowledge Manage-

ment, Lisbon, Portugal.

Fei Wu and Daniel S. Weld. 2008. Automatically refin-

ing the wikipedia infobox ontology. In Proceedings

of the Seventeenth International Conference on World

Wide Web, Beijing, China.

Fei Wu and Daniel S. Weld. 2010. Open information

extraction using wikipedia. In submission.

Fei Wu, Raphael Hoffmann, and Daniel S. Weld. 2008.

Information extraction from Wikipedia: Moving down

the long tail. In Proceedings of the Fourteenth

ACM SIGKDD International Conference on Knowl-

edge Discovery and Data Mining, Las Vegas, NV.

Alexander Yates and Oren Etzioni. 2007. Unsupervised

resolution of objects and relations on the web. In Pro-

ceedings of Human Language Technology (NAACL).

95


