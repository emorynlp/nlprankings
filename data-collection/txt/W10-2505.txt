










































Transforming Lexica as Trees


Proceedings of the 2010 Workshop on Applications of Tree Automata in Natural Language Processing, ACL 2010, pages 37–45,
Uppsala, Sweden, 16 July 2010. c©2010 Association for Computational Linguistics

Transforming Lexica as Trees

Mark-Jan Nederhof
University of St Andrews
North Haugh, St Andrews

KY16 9SX
Scotland

Abstract

We investigate the problem of structurally
changing lexica, while preserving the in-
formation. We present a type of lexicon
transformation that is complete on an in-
teresting class of lexica. Our work is mo-
tivated by the problem of merging one or
more lexica into one lexicon. Lexica, lexi-
con schemas, and lexicon transformations
are all seen as particular kinds of trees.

1 Introduction

A standard for lexical resources, called Lexical
Markup Framework (LMF), has been developed
under the auspices of ISO (Francopoulo et al.,
2006). At its core is the understanding that most
information represented in a lexicon is hierarchi-
cal in nature, so that it can be represented as a
tree. Although LMF also includes relations be-
tween nodes orthogonal to the tree structure, we
will in this paper simplify the presentation by
treating only purely tree-shaped lexica.

There is a high demand for tools supporting the
merger of a number of lexica. A few examples
of papers that express this demand are Chan Ka-
Leung and Wu (1999), Jing et al. (2000), Mona-
chini et al. (2004) and Ruimy (2006). A typical
scenario is the following. The ultimate goal of
a project is the creation of a single lexicon for a
given language. In order to obtain the necessary
data, several field linguists independently gather
lexical resources. Despite efforts to come to agree-
ments before the start of the field work, there will
generally be overlap in the scope of the respec-
tive resources and there are frequently inconsis-
tencies both in the lexical information itself and
in the form in which information is represented.

In the latter case, the information needs to be re-
structured as part of the process of creating a sin-
gle lexicon.

We have developed a model of the merging pro-
cess, and experiments with an implementation are
underway. The actions performed by the tool are
guided by a linguist, but portions of the work may
also be done purely mechanically, if this is so
specified by the user. The purpose of the present
paper is to study one aspect of the adequacy of
the model, namely the restructuring of informa-
tion, with one input lexicon and one output lexi-
con. This corresponds to a special use of our tool,
which may in general produce one output lexicon
out of any number of input lexica.

As our lexica are trees, the use of well-
established techniques such as term unification
(Lloyd, 1984) and tree transduction (Fülöp and
Vogler, 1998) seem obvious candidates for so-
lutions to our problem. Also technologies such
as XSL (Harold and Means, 2004) and XQuery
(Walmsley, 2007) spring to mind. We have chosen
a different approach however, which, as we will
show, has favourable theoretical properties.

The structure of this paper is as follows. The
type of lexicon that we consider is formalized in
Section 2, and lexicon transformations are dis-
cussed in Section 3. Section 4 shows that the pro-
posed type of lexicon transformation suffices to
map all ‘reasonable’ lexica to one another, as long
as they contain the same information. Conditions
under which transformations preserve information
are discussed in Section 5. A brief overview of an
implementation is given in Section 6.

2 Lexica and their structures

In this section, we formalize the notions of lexica,
lexicon structures, and their meanings, abstracting

37



away from details that are irrelevant to the discus-
sion that follows.

A lexicon schema S is a tuple (A,C, T ), where
A is a finite set of attributes, C is a finite set of
components (A ∩ C = ∅), and T is a labelled,
unordered tree such that:

• each leaf node is labelled by an element from
A,

• each non-leaf node is labelled by an element
from C , and

• each element from A∪C occurs exactly once.

A lexicon L is a tuple (A,V,C, t), where A is
as above, V is a set of values, C is as above, and t
is a labelled, unordered tree such that:

• each leaf node is labelled by an element from
A× V ,

• each non-leaf node is labelled by an element
from C ,

• if a leaf node with a label of the form (a, v1)
has a parent labelled c, then each leaf node
with a label of the form (a, v2) has a parent
labelled c, and

• if a non-leaf node labelled c1 has a parent la-
belled c2, then each non-leaf node labelled c1
has a parent labelled c2.

Due to the last two constraints, we may compare
lexica and lexicon schemata. In order to simplify
this comparison, we will assume that in a lexicon,
A and C only contain elements that occur in t.
This is without loss of generality, as unused ele-
ments of A and C can be omitted. We will also
assume that t contains at least two nodes, so that
the root is not a leaf.

We say a lexicon L = (AL, V, CL, t) is an in-
stance of lexicon schema S = (AS , CS , T ) if
AL ⊆ AS , CL ⊆ CS , and furthermore:

• the label of the root of t equals the label of
the root of T ,

• if a leaf node of t with a label of the form
(a, v1) has a parent labelled c, then the leaf
node of T labelled a has a parent labelled c,
and

• if a non-leaf node of t labelled c1 has a par-
ent labelled c2, then the non-leaf node of T
labelled c1 has a parent labelled c2.

Lexicon

lang Entry

Key

lemma pos

Meaning

gloss example

Figure 1: A lexicon schema S.

Examples of a lexicon schema and a lexicon are
given in Figures 1 and 2. For the sake of succinct-
ness, an attribute-value pair such as (example, ’Er
ist mit dem Zug gefahren’) is commonly separated
by =, and where it is required for graphical rea-
sons, the value may be drawn beneath the attribute,
stretched out vertically.

On a number of occasions in the constructions
and proofs that follow, it is convenient to assume
that the root node of a lexicon schema has exactly
one child. If this does not hold, as in the run-
ning example, we may introduce an artificial root
node labelled by an artificial component, denoted
by ‘$’, which has the conceptual root node as only
child. We will refer to the lexicon schema that
results as an extended lexicon schema. (Cf. the
theory of context-free grammars, which are often
extended with a new start symbol.) As a conse-
quence, a lexicon that is an instance of an extended
lexicon schema may, in pathological cases, have
several nodes that are labelled by the conceptual
root component of the schema.

The components in lexicon schemata and lexica
provide a means of structuring sets of attributes, or
sets of attribute-value pairs respectively, into tree-
shaped forms. The discussion that follows will
treat components and structure as secondary, and
will take attributes and attribute-value pairs as the
primary carriers of information.

A lexicon base B is a tuple (A,V, I), where A
and V are as above, and I is a finite non-empty set
of items, each of which is a partial function from
A to V , defined on at least one attribute. Such
partial functions will also be represented as non-
empty sets of attribute-value pairs, in which each
attribute occurs at most once.

38



Lexicon

lang=German Entry

Key

lemma
=
fahren

pos
=
V

Meaning

gloss
=
drive

example
=
Ein
Fahrrad
fahren

Meaning

gloss
=
go

example
=
Er
ist
mit
dem
Zug
gefahren

Entry

Key

lemma
=
Fahrrad

pos
=
N

Meaning

gloss
=
bicycle

example
=
Ein
Fahrrad
fahren

example
=
Mein
Fahrrad
hat
einen
Platten

Figure 2: A lexicon L that is an instance of S from Figure 1.

Let L = (A,V,C, t) be a lexicon, where r is the
root of t. Its base, denoted by B(L), is (A,V, I)
with I = I(r), where the function I on nodes n of
the lexicon is defined as follows.

• For a leaf node n labelled by the attribute-
value pair (a, v), I(n) = {{(a, v)}}. In
words, the set I(n) contains only one item,
which is a partial function mapping attribute
a to value v.

• For a non-leaf node n, assume that m differ-
ent components or attributes d1, . . . , dm oc-
cur among the children. (Each element d is
either a component or an attribute.) Let Nj
(1 ≤ j ≤ m) be the set of children of n
labelled by dj if dj is a component or by
(dj , v), some value v, if dj is an attribute.
Then:

I(n) =

{ι1 ∪ · · · ∪ ιm | n1 ∈ N1, . . . , nm ∈ Nm,

ι1 ∈ I(n1), . . . , ιm ∈ I(nm)}.

Note that by the definition of lexica and of N1, . . . ,
Nm, no attribute may occur both in ιi and in ιj if
i 6= j. This means that ι1 ∪ · · · ∪ ιm is a partial
function as required.

For the lexicon of the running example, the base
is:

{ {lang=German, lemma=fahren, pos=V,
gloss=drive,
example=Ein Fahrrad fahren},
{lang=German, lemma=fahren, pos=V,
gloss=go,
example=Er ist mit dem Zug gefahren},

{lang=German, lemma=Fahrrad, pos=N,
gloss=bicycle,
example=Ein Fahrrad fahren},
{lang=German, lemma=Fahrrad, pos=N,

gloss=bicycle,
example=Mein Fahrrad hat einen Platten} }.

There are many different lexica however that share
the same base. This is illustrated by Figure 3. We
see that the information is presented in an entirely
different fashion, with a focus on the examples.

In a lexicon such as that in Figure 2, there may
be nodes labelled ’Meaning’ without any children
corresponding to attribute ’example’. This means
that there would be items ι in B(L) such that
ι(example) is undefined. For some of the con-
structions and proofs below, it is convenient to cir-
cumvent this complication, by assuming special
’null’ values for absent leaf nodes for attributes.
As a result, we may treat an item as a complete
function rather than as a partial function on the do-
main A.

There is a certain resemblance between the base
of a lexicon and the disjunctive normal form of a
logical expression, the attribute-value pairs taking
the place of propositional variables, and the items

39



Phrasebook

lang=German Phrase

example
=
Ein
Fahrrad
fahren

Word

lemma
=
fahren

pos
=
V

gloss
=
drive

Word

lemma
=
Fahrrad

pos
=
N

gloss
=
bicycle

Phrase

example
=
Er
ist
mit
dem
Zug
gefahren

Word

lemma
=
fahren

pos
=
V

gloss
=
go

Phrase

example
=
Mein
Fahrrad
hat
einen
Platten

Word

lemma
=
Fahrrad

pos
=
N

gloss
=
bicycle

Figure 3: A lexicon L′ with the same base as the one in Figure 2.

taking the place of conjunctions. Thus our seman-
tic interpretation of lexica is such that two siblings
in the tree are regarded as alternatives (disjunc-
tion) if their labels contain the same attribute or
component, and they are regarded as joint infor-
mation (conjunction) if their labels contain distinct
attributes or components.

Theorem 1 For each lexicon base B =
(AB , V, I) and for each lexicon schema S =
(AS , C, T ) with AB ⊆ AS , there is a lexicon L
that is an instance of S and whose base is B.

Proof Assume the root r of T has only one child
r′. (Otherwise, make S extended first.) Let T ′ be
the subtree of T at r′. For each item ι ∈ I , create
a copy of T ′, denoted by tι. At each leaf node of
tι, supplement the label a with the corresponding
value from ι if any; if a does not occur in ι, then
remove the leaf node from tι. (If the parent of a
removed leaf node has no other children, then also
remove the parent, etc.) Create a root node, with
the same label as r, the children of which are the
roots of the respective tι. Let the resulting tree be
called t. The requirements of the theorem are now
satisfied by L = (AB , V, C, t).

3 Lexicon transformations

As we have seen, the information contained in one
lexicon base may be rendered in different struc-
tural forms, in terms of lexica. The structure of a
lexicon is isolated from its content by means of a

lexicon schema. In this section we will address the
question how we may formalize transformations
from one lexicon schema S1 to lexicon schema S2,
or more precisely, from one class of lexica that are
instances of S1 to another class of lexica that are
instances of S2. In fact, for the sake of the defini-
tions below, we assume that the input to a transfor-
mation is not a lexicon but its base, which contains
all the necessary information. (That the actual im-
plementation mentioned in Section 1 may often
avoid expansion to the base need not concern us
here.)

A lexicon transformation R is a tuple (A,C, τ),
where A is a finite set of attributes as before, C
is a finite set of components as before, and τ is a
labelled, unordered tree such that:

• each leaf node is labelled by an element from
A,

• the root node is labelled by an element from
C ,

• each internal node is either labelled by an el-
ement from C , or by a subset of A,

• each element from A∪C occurs exactly once
as a label by itself,

• each element from A occurs exactly once in
a label that is a subset of A, and

• each node ν labelled by a set {a1, . . . , ak}
⊆ A has exactly one child, which is labelled

40



by an element from A ∪ C , and the leaves
labelled a1, . . . , ak are each descendants of
ν.

A lexicon transformation is very similar to a lex-
icon schema, except for the extra nodes labelled
by sets A′ ⊆ A of attributes, which we refer to
as restrictors. Such a node indicates that for the
purpose of the subtree, one should commit to par-
ticular subsets of the input lexicon base. Each such
subset is determined by a choice of a fixed value
for each attribute in A′.

As an example, consider the lexicon transfor-
mations in Figure 4(a) and (b). If we omit the
nodes labelled by restrictors, then we obtain a lex-
icon schema. In the case of (b), this is the lexi-
con schema in Figure 1. In Figure 4(a), the node
labelled {example} means that the transforma-
tion takes one non-empty subset of the base for
each possible value of attribute ’example’. For
each subset, one node labelled ’Phrase’ is gener-
ated in the target lexicon. At the node labelled
{lemma,pos}, the subset of the base is further re-
stricted, and for each combination of a value of
’lemma’ and a value of ’pos’ in the current sub-
set of items, a node labelled ’Word’ is generated.
If the base contains several glosses for one choice
of ’example’, ’lemma’ and ’pos’, each such gloss
leads to a separate leaf node.

The meaning of a lexicon transformation is for-
mally expressed in Figure 5. A call lexicon(ν, I ′),
where ν is a node of τ and I ′ is a subset of I from
the input lexicon base B = (A,V, I), returns a set
of nodes. The function is recursive, in that the
value of lexicon(ν, I ′) is expressed in terms of val-
ues of lexicon(ν ′, I ′′) for child nodes ν ′ of ν and
subsets I ′′ of I ′. The main purpose is the computa-
tion of lexicon(ρ, I), where ρ is the root of τ . As ρ
is labelled by an element from C , lexicon(ρ, I) is
by definition a singleton set {r}, with r becoming
the root of the resulting lexicon.

Note that the placement of restrictors is criti-
cal. For example, if we were to move up the re-
strictor {gloss} in Figure 4(b) to merge with the
restrictor {lemma,pos}, this would result in one
entry for each combination of ’lemma’, ’pos’ and
’gloss’, and in each entry there would be at most
one meaning. It is not apparent that such a choice
would be less appropriate than the choice we made
in Figures 2 and 4(b). However, if we were to
move down the node labelled {gloss} to become a
child of the node labelled ’Meaning’ and a parent

Phrasebook

{lang}

lang

{example}

Phrase

example {lemma, pos}

Word

lemma pos {gloss}

gloss

(a)

Lexicon

{lang}

lang

{lemma, pos}

Entry

Key

lemma pos

{gloss}

Meaning

gloss {example}

example

(b)

Figure 4: Two lexicon transformations: (a) is ca-
pable of mapping the base of lexicon L (Figure 2)
to lexicon L′ (Figure 3), and (b) is capable of the
reverse mapping.

of the leaf node labelled ’gloss’, then we would
lose the coupling between glosses and examples,
which seems undesirable. This observation under-
lies much of the development in Section 5.

4 Completeness

Next, we investigate whether the lexicon transfor-
mations as we defined them are powerful enough
to produce ’reasonable’ lexica starting from a lex-
icon base. As unreasonable, we reject those lexica
that contain information that cannot be expressed
in terms of a base. This concerns siblings in the
tree with the same component label. How many
siblings with the same component should be gen-
erated can be deduced from the base, provided we
may assume that there is a combination of attribute
values that distinguishes one sibling from another.

41



lexicon(ν, I ′) :
if the label of ν is a ∈ A

let v be the (only) value such that ∃ι ∈ I ′[ι(a) = v]
create a new node n with label (a, v)
return {n}

else if the label of ν is c ∈ C
let the children of ν be ν1, . . . , νm
create a new node n with label c and children

⋃

1≤i≤m

lexicon(νi, I
′)

return {n}
else if the label of ν is A′ = {a1, . . . , ak} ⊆ A

let the only child of ν be ν ′

let I be the set of all I ′′ such that there is a combination of
v1, . . . , vk ∈ V with I ′′ = {ι ∈ I ′ | ι(a1) = v1, . . . , ι(ak) = vk} 6= ∅

return
⋃

I′′∈I lexicon(ν
′, I ′′)

Figure 5: The meaning of a lexicon transformation, as a recursive function. The return value is a set of
nodes that are created. The main application is lexicon(ρ, I), where ρ is the root of τ and I is taken from
the input lexicon base.

We call such a combination of attributes a key.
Formally, a key mapping for a lexicon schema

(A,C, T ) is a function f that maps each compo-
nent from C to a subset of A, subject to the fol-
lowing restrictions. Let c be a component and let
n be the node of T that is labelled by c. Then for
each attribute a in key f(c), the leaf node of T that
is labelled by a should be a descendant of n. The
component that occurs as label of the root of T is
always mapped to the empty set of attributes, and
may be ignored in the following discussion.

Let lexicon L = (AL, V, CL, t) be an instance of
schema S = (AS , CS , T ). We say that L satisfies
the key mapping f for S if:

1. among the leaves, there is no pair of distinct
siblings in t with identical labels, and

2. for each maximal set {n1, . . . , nm} of sib-
lings in t labelled by the same component c,
with f(c) = {a1, . . . , ak}, we have that for
each i (1 ≤ i ≤ m), there is a distinct combi-
nation of values v1, . . . , vk ∈ V such that:

I(ni) = {ι ∈
⋃

1≤j≤m

I(nj) | ι(a1) = v1, . . . ,
ι(ak) = vk}.

The second condition states that the total set of
items coming from all siblings with the same label
c is partitioned on the basis of distinct combina-
tions of values for attributes from the key, and the
subsets of the partition come from the respective
siblings.

Returning to the running example, the lexicon L
in Figure 2 satisfies the key mapping f given by:

f(Lexicon) = ∅
f(Entry) = {lemma,pos}
f(Key) = ∅
f(Meaning) = {gloss}

A different key mapping exists for the lexicon L′

in Figure 3.
If n1 and n2 are two distinct nodes in the tree

T of schema S, with labels c1 and c2, respec-
tively, then we may assume that f(c1) and f(c2)
are disjoint, for the following reason. Suppose that
the intersection of f(c1) and f(c2) includes an at-
tribute a, then n1 must be a descendant of n2 or
vice versa, because the leaf labelled a must be a
descendant of both n1 and n2. Assume that n1 is a
descendant of n2. As the base is already restricted
at n1 to items ι with ι(a) = v, for certain v, a
may be omitted from f(c2) without changing the
semantics of the key mapping. This observation is
used in the construction in the proof of the follow-
ing.

Theorem 2 Let lexicon L = (AL, V, CL, t) be an
instance of schema S = (AS , CS , T ), satisfying
key mapping f . Then there is a lexicon transfor-
mation that maps B(L) to L.

Proof The required lexicon transformation is
constructed out of T and f . We insert an ad-
ditional restrictor node just above each non-leaf
node labelled c, and as the restrictor we take f(c).

42



(If f(c) = ∅, we may abstain from adding a restric-
tor node.) If an attribute a does not occur in f(c),
for any c ∈ CS , then we add a restrictor node with
set {a} just above the leaf node labelled a. The
result is the tree τ of a lexicon transformation R =
(AS , CS , τ).

It is now straightforward to prove that R maps
B(L) to L, by induction on the height of T , on
the basis of the close similarity between the struc-
ture of T and the structure of τ , and the close link
between the chosen restrictors and the keys from
which they were constructed.

For the running example, the construction in the
proof above leads to the transformation in Fig-
ure 4(b).

Theorem 2 reveals the conditions under which
the structure of a lexicon can be retrieved from
its base, by means of a transformation. Simulta-
neously, it shows the completeness of the type of
lexicon transformation that we proposed. If a lexi-
con L is given, and if an alternative lexicon L′ with
B(L′) = B(L) exists that is an instance of some
schema S and that is ‘reasonable’ in the sense that
it satisfies a key mapping for S, then L′ can be ef-
fectively constructed from L by the derived trans-
formation.

5 Consistency

We now investigate the conditions under which
a lexicon transformation preserves the base. The
starting point is the observation at the end of Sec-
tion 3, where we argued that if a restrictor is cho-
sen too low in the tree τ relative to other restric-
tors, then some necessary dependence between at-
tribute values is lost. Note that the proof of Theo-
rem 1 suggests that having only one restrictor with
all attributes at the root of the tree always pre-
serves the base, but the result would be unsatis-
factory in practice.

For a set A of attributes, we define an indepen-
dence system D as a set of triples (A1, A2, A3)
where A1, A2, A3 ⊆ A and A1 ∩ A2 = ∅. We
pronounce (A1, A2, A3) ∈ D as ’A1 and A2 are
independent under A3’. It should be noted that A3
may overlap with A1 and with A2.

We say a lexicon base (A,V, I) satisfies D if
for each (A1, A2, A3) ∈ D with A1 = {a1,1,
. . . a1,k1}, A2 = {a2,1, . . . a2,k2}, A3 = {a3,1,
. . . a3,k3}, and for each combination of values v1,1,

. . . , v1,k1 , v2,1, . . . , v2,k2 , v3,1, . . . , v3,k3 , we have:

∃ι ∈ I[ι(a1,1) = v1,1 ∧ . . . ∧ ι(a1,k1) = v1,k1 ∧
ι(a3,1) = v3,1 ∧ . . . ∧ ι(a3,k3) = v3,k3] ∧

∃ι ∈ I[ι(a2,1) = v2,1 ∧ . . . ∧ ι(a2,k2) = v2,k2 ∧
ι(a3,1) = v3,1 ∧ . . . ∧ ι(a3,k3) = v3,k3]

=⇒
∃ι ∈ I[ι(a1,1) = v1,1 ∧ . . . ∧ ι(a1,k1) = v1,k1 ∧

ι(a2,1) = v2,1 ∧ . . . ∧ ι(a2,k2) = v2,k2 ∧
ι(a3,1) = v3,1 ∧ . . . ∧ ι(a3,k3) = v3,k3].

The intuition is that as long as the values for A3 are
fixed, allowable combinations of values for A1 ∪
A2 in I can be found by looking at A1 and A2
individually.

We say that a lexicon transformation R =
(A,C, τ) is allowed by an independence system
D if the following condition is satisfied for each
node ν in τ that is labelled by a component c and
a node ν ′ that is its child: Let A1 be the set of at-
tributes at leaves that are descendants of ν ′, and
let A2 be the set of attributes at leaves that are de-
scendants of the other children of ν. Let A3 be
the union of the restrictors at ancestors of ν. Now
(A1, A2, A3) should be in D.

Theorem 3 If a lexicon base B = (A,V, I) satis-
fies an independence system D, if a lexicon trans-
formation R is allowed by D, and if R maps B to
lexicon L, then B(L) = B.

The proof by induction on the height of τ is
fairly straightforward but tedious.

In the running example, there are a num-
ber of triples in D but most are trivial, such
as (∅, {gloss, example}, {lemma,pos}).
Another triple in D is ({lang},
{lemma,pos, gloss, example}, ∅), but only
because we assume in this example that one
lexicon is designed for one language only. In
general, there will be more interesting indepen-
dency, typically if a lexical entry consists of a
number of unconnected units, for example one
explaining syntactic usage of a word, another
explaining semantic usage, and another presenting
information on etymology.

The implication of Theorem 3 is that transfor-
mations between lexica preserve the information
that they represent, as long as the transforma-
tions respect the dependencies between sets of at-
tributes. Within these bounds, an attribute a may
be located in a restrictor in τ anywhere between
the root node and the leaf node labelled a.

43



6 Implementation

The mathematical framework in this paper mod-
els a restricted case of merging and restructuring
a number of input lexica. An implementation was
developed as a potential new module of LEXUS,
which is a web-based tool for manipulating lexi-
cal resources, as described by Kemps-Snijders et
al. (2006).

The restriction considered here involves only
one input lexicon, and we have abstracted away
from a large number of features present in the ac-
tual implementation, among which are provisions
to interact with the user, to access external linguis-
tic functions (e.g. morphological operations), and
to rename attributes. These simplifications have
allowed us to isolate one essential and difficult
problem of lexicon merging, namely how to carry
over the underlying information from one lexicon
to another, in spite of possible significant differ-
ences in structure.

The framework considered here assumes that
during construction of the target lexicon, the infor-
mation present in the source lexicon is repeatedly
narrowed down by restrictors, as explained in Sec-
tion 3. Each restrictor amounts to a loop over all
combinations of the relevant attribute values from
the currently considered part of the source lexicon.

Let us consider a path from the root of the lexi-
con transformation to a leaf, which may comprise
several restrictors. The number of combinations of
attribute values considered is bounded by an expo-
nential function on the total number of attributes
contained in those restrictors. Motivated by this
consideration, we have chosen to regard a lexicon
transformation as if its input were an expanded
form of the source lexicon, or in other words, a
lexicon base.

However, in terms of the actual implementation,
the discussed form of restrictors must be seen as a
worst case, which is able to realize some of the
most invasive types of restructuring. Next to re-
strictors that select combinations of attribute val-
ues, our lexicon transformations also allow prim-
itives that each represent a loop over all nodes of
the presently considered part of the source lexi-
con that are labelled by a chosen component or
attribute. By using only such primitives, the time
complexity remains polynomial in the size of the
input lexicon and the size of the input lexicon
transformation. This requires an implementation
that does not expand the information contained in

a source lexicon in terms of a lexicon base. A
full description of the implementation would go
beyond the context of this paper.

7 Conclusions

We have introduced a class of lexicon transfor-
mations, and have shown interesting completeness
and consistency properties.

The restrictors in our lexicon transformations
are able to repeatedly narrow down the informa-
tion contained in the source lexicon based on at-
tribute values, while constructing the target lexi-
con from the top down. Existing types of tree ma-
nipulations, such as tree transducers, do not pos-
sess the ability to repeatedly narrow down a set
of considered nodes scattered throughout a source
structure, and therefore seem to be incapable of
expressing types of lexicon transformations allow-
ing the completeness results we have seen in this
paper.

One could in principle implement our lexicon
transformations in terms of technologies such as
XQuery and XSLT, but only in the sense that
these formalisms are Turing complete. Our restric-
tors do not have a direct equivalent in these for-
malisms, which would make our type of lexicon
transformation cumbersome to express in XQuery
or XSLT. At the same time, their Turing complete-
ness makes XQuery and XSLT too powerful to
be of practical use for the specification of lexicon
transformations.

A tentative conclusion seems to be that our class
of lexicon transformations has useful properties
not shared by a number of existing theories involv-
ing tree manipulations. This justifies further study.

Acknowledgements

This work was done while the author was em-
ployed at the Max Planck Institute for Psycholin-
guistics. The work was motivated by suggestions
from Peter Wittenburg and Marc Kemps-Snijders,
whose input is gratefully acknowledged.

References

D. Chan Ka-Leung and D. Wu. 1999. Automati-
cally merging lexicons that have incompatible part-
of-speech categories. In Joint SIGDAT Conference
on Empirical Methods in Natural Language Pro-
cessing and Very Large Corpora, pages 247–257,
University of Maryland, USA, June.

44



G. Francopoulo, N. Bel, M. George, N. Calzolari,
M. Monachini, M. Pet, and C. Soria. 2006. Lexi-
cal markup framework (LMF) for NLP multilingual
resources. In Proceedings of the Workshop on Mul-
tilingual Language Resources and Interoperability,
pages 1–8, Sydney, Australia, July.

Z. Fülöp and H. Vogler. 1998. Syntax-Directed Se-
mantics: Formal Models Based on Tree Transduc-
ers. Springer, Berlin.

E.R. Harold and W.S. Means. 2004. XML in a Nut-
shell. O’Reilly.

H. Jing, Y. Dahan Netzer, M. Elhadad, and K.R. McK-
eown. 2000. Integrating a large-scale, reusable lex-
icon with a natural language generator. In Proceed-
ings of the First International Conference on Nat-
ural Language Generation, pages 209–216, Mitzpe
Ramon, Israel, June.

M. Kemps-Snijders, M.-J. Nederhof, and P. Witten-
burg. 2006. LEXUS, a web-based tool for manip-
ulating lexical resources. In LREC 2006: Fifth In-
ternational Conference on Language Resources and
Evaluation, Proceedings, pages 1862–1865.

J.W. Lloyd. 1984. Foundations of Logic Programming.
Springer-Verlag.

M. Monachini, F. Calzolari, M. Mammini, S. Rossi,
and M. Ulivieri. 2004. Unifying lexicons in view
of a phonological and morphological lexical DB. In
LREC 2004: Fourth International Conference on
Language Resources and Evaluation, pages 1107–
1110, Lisbon, Portugal, May.

N. Ruimy. 2006. Merging two ontology-based lexi-
cal resources. In LREC 2006: Fifth International
Conference on Language Resources and Evaluation,
Proceedings, pages 1716–1721.

P. Walmsley. 2007. XQuery. O’Reilly.

45


