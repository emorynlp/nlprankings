










































On the Parameterized Complexity of Linear Context-Free Rewriting Systems


Proceedings of the 13th Meeting on the Mathematics of Language (MoL 13), pages 21–29,
Sofia, Bulgaria, August 9, 2013. c©2013 Association for Computational Linguistics

On the Parameterized Complexity of
Linear Context-Free Rewriting Systems

Martin Berglund
Umeå University, Sweden

mbe@cs.umu.se

Henrik Björklund
Umeå University, Sweden
henrikb@cs.umu.se

Frank Drewes
Umeå University, Sweden
drewes@cs.umu.se

Abstract

We study the complexity of uniform mem-
bership for Linear Context-Free Rewriting
Systems, i.e., the problem where we are
given a string w and a grammar G and are
asked whether w ∈ L(G). In particular,
we use parameterized complexity theory
to investigate how the complexity depends
on various parameters. While we focus
primarily on rank and fan-out, derivation
length is also considered.

1 Introduction

Linear Context-Free Rewriting Systems (LCFRS)
were introduced by Vijay-Shanker et al. (1987)
with the purpose of capturing the syntax of nat-
ural language.1 It is one of several suggested ways
of capturing Joshi’s concept of mildly context-
sensitive languages (Joshi, 1985). As such, it
strengthens the expressive power of context-free
grammars, while avoiding the full computational
complexity of context-sensitive grammars.

One of the defining features of mildly context-
sensitive languages is that they should be decid-
able in polynomial time. This is indeed true for ev-
ery language that can be generated by an LCFRS.
Unlike the case for context-free grammars, how-
ever, the universal or uniform membership prob-
lem for LCFRSs, where both the grammar and
the string in question are considered as input, is
known to be PSPACE-complete (Kaji et al., 1992),
making a polynomial time solution very improba-
ble.

The best known algorithms for the problem
have a running time of O(|G| · |w|f ·(r+1)), where
G is the grammar, w is the string, f is the fan-out
and r is the rank of the grammar (Seki et al., 1991;
Burden and Ljunglöf, 2005; Boullier, 2004). (For

1Seki et al. (1991) independently suggested the nearly
identical Multiple Context-Free Grammars.

a definition of fan-out and rank, see Section 2.)
Unlike the rank of a context-free grammar, the fan-
out and rank of an LCFRS cannot in general be re-
duced to some fixed constant. Increasing the fan-
out always gives more generative power, as does
increasing the rank while keeping the fan-out fixed
(Satta, 1998). The rank can be reduced to two, but
at the price of an exponential increase in the fan-
out.

Research into algorithms for LCFRS parsing
that are efficient enough for practical use is quite
active. For example, algorithms for restricted
cases are being studied, e.g., by Gómez-Rodrı́guez
et al. (2010), as well as rank reduction, primarily
in special cases, where the fan-out is not affected;
see, e.g., Sagot and Satta (2010).

This article is a first step towards a finer com-
putational complexity analysis of the membership
problem for LCFRSs. Specifically it asks the
question “could there exist an algorithm for the
uniform LCFRS membership problem whose run-
ning time is a fixed polynomial in |w| times an ar-
bitrary function in f and r?” By employing pa-
rameterized complexity theory, we show that such
an algorithm is very unlikely to be found. Fix-
ing the rank of the grammar to one, the mem-
bership problem, parameterized by the fan-out, is
W[SAT]-hard. Fixing the fan-out to two and tak-
ing the rank as the parameter, the problem is W[1]-
hard. Finally, if the fan-out, rank, and derivation
length are included in the parameter, the problem
is W[1]-complete. These results help guide future
work, suggesting other types of parameters and
grammar restrictions that may yield more favor-
able complexity results.

2 Preliminaries

For n ∈ N, we write [n] for {1, . . . , n} and [n]0
for {0} ∪ [n]. Given an alphabet Σ we write Σ∗
for all strings over Σ and Σ+ for all non-empty
strings. The empty string is denoted by ε.

21



2.1 Linear context-free rewriting systems
Let Σ be an alphabet, x1, . . . , xn variables, and
w1, . . . , wk strings over Σ such that

w1 · · ·wk = α0 · xπ(1) · α1 · · ·xπ(n) · αn

for some permutation π and some strings
α0, . . . , αn ∈ Σ∗. Then define f as a function
over tuples of strings such that

f((x1, . . .), . . . , (. . . , xn)) = (w1, . . . , wk).

A function is linear regular if and only if it
can be described in this way. For example
f((x1), (x2)) = (a, bx2x1c) is linear regular, and
f((aaa), (bc)) = (a, bbcaaac).
Definition 2.1. A Linear Context-Free Rewriting
System is a tupleG = (N,Σ, F,R, S), whereN is
an alphabet of nonterminals, where each A ∈ N
has an associated fan-out #(A); S ∈ N is the
initial nonterminal with #(S) = 1; Σ is an al-
phabet of terminals; F is a set of linear regu-
lar functions; and R is a set of rules of the form
A → g(B1, . . . , Bn), where A,B1, . . . , Bn ∈ N
and g is a function in F of type

(Σ∗)#(B1) × · · · × (Σ∗)#(Bn) → (Σ∗)#(A).

For rules A → g(), where g has arity 0 and
g() = (α1, . . . , α#(A)), we often simply write
A→ (α1, . . . , α#(A)).

The rank of a rule is the number of nontermi-
nals on the right-hand side. The rank of G is the
maximal rank of any rule in R. The fan-out of G
is the maximal fan-out of any nonterminal in N .

The language generated by a nonterminal A is a
set of n-tuples, where n = #(A).
Definition 2.2. Let G = (N,Σ, F,R, S) be
a linear context-free rewriting system. Let
LA ⊆ (Σ∗)#(A) denote the tuples that a nontermi-
nal A ∈ N can generate. This is the smallest set
such that if A → f(B1, . . . , Bn) is in R then, for
all bi ∈ LBi where i ∈ [n], f(b1, . . . , bn) ∈ LA.
The language of G is L(G) = LS .

For i ∈ N, we write i-LCFRS for the class of
all LCFRSs of rank at most i and LCFRS(i) for
the class of all LCFRSs of fan-out at most i. We
also write i-LCFRS(j) for i-LCFRS∩LCFRS(j).

2.2 Parameterized complexity theory
We only reproduce the most central definitions of
parameterized complexity theory. For a more thor-
ough treatment, we refer the reader to (Downey
and Fellows, 1999; Flum and Grohe, 2006).

A parameterized problem is a language
L ⊆ Σ∗ × N, where Σ is a finite alphabet. The
second component is called the parameter. An al-
gorithm for L is fixed-parameter tractable if there
is a computable function f and a polynomial p
such that for every (x, k) ∈ Σ∗×N, the algorithm
decides in time f(k) · p(|x|) whether (x, k) ∈ L.
The problem of deciding L is fixed-parameter
tractable if there is such an algorithm. If so, L
belongs to the class FPT.

A parameterized problem L ⊆ Σ∗ × N
is fpt-reducible to another parameterized prob-
lem K ⊆ Γ∗ × N if there is a mapping
R : Σ∗ × N→ Γ∗ × N such that

1. for all (x, k) ∈ Σ∗ × N, we have (x, k) ∈ L
if and only if R(x, k) ∈ K,

2. there is a computable function f and a poly-
nomial p such that R(x, k) can be computed
in time f(k) · p(|x|), and

3. there is a computable function g such that for
every (x, k) ∈ Σ∗ × N, if R(x, k) = (y, k′),
then k′ ≤ g(k).

Note that several parameters may be combined
into one by taking their maximum (or sum).

The most commonly used hierarchy of parame-
terized complexity classes is the following.

FPT ⊆W[1] ⊆W[2] ⊆ · · · ⊆
⊆W[SAT] ⊆W[P] ⊆ XP

The classes W[1],. . . ,W[P] are defined using cir-
cuits or, alternatively, logic. None of the inclu-
sions is known to be strict, except that FPT is a
strict subclass of XP. It is widely believed, how-
ever, that each of them is strict. The class XP is
the class of all parameterized problems for which
there is a computable function f such that every
instance (x, k) can be decided in time |x|f(k).

2.3 Problems of interest

We know from Kaji et al. (1992) that the universal
membership problem for 1-LCFRSs is PSPACE-
complete. Satta (1992) has further shown that
LCFRS(2)-MEMBERSHIP is NP-hard.

We study the following decision problems,
where the symbol P is used to indicate what the
parameter is:

• P-LCFRS(j)-MEMBERSHIP, where j ∈ N
is the membership problem for LCFRS(j),
parameterized by the rank.

22



• i-LCFRS(P)-MEMBERSHIP, where i ∈ N
is the membership problem for i-LCFRS, pa-
rameterized by the fan-out.
• P-LCFRS(P)-MEMBERSHIP is the mem-

bership problem for LCFRS parameterized
by the rank and the fan-out.
• SHORT P-LCFRS(P)-DERIVATION is the

membership problem for LCFRS parameter-
ized by the rank, the fan-out, and the deriva-
tion length.

Since there are algorithms that solve the member-
ship problem for LCFRSs with rank r and fan-out
t and string w in time |w|(r+1)t (see, e.g., (Seki
et al., 1991; Burden and Ljunglöf, 2005; Boul-
lier, 2004)), we can immediately conclude that
P-LCFRS(P)-MEMBERSHIP, as well as every
other parameterized membership problem men-
tioned above, belongs to XP.

3 Fixed rank grammars

The following theorem establishes a lower bound
for 1-LCFRSs parameterized by the fan-out.

Theorem 3.1. 1-LCFRS(P)-MEMBERSHIP is
W[SAT]-hard.

The proof of Theorem 3.1 is by reduction from
WEIGHTED MONOTONE SATISFIABILITY. Be-
fore we get into the actual proof, we discuss some
properties of this problem.

Definition 3.1. A monotone Boolean formula is a
Boolean formula that contains only conjunctions,
disjunctions, and variables. In particular, there are
no negations. An instance of WEIGHTED MONO-
TONE SATISFIABILITY is a pair (φ, k), where φ
is a monotone Boolean formula and k ∈ N. The
question is whether φ has a satisfying assignment
of weight k, i.e., an assignment that sets exactly
k of the variables that occur in φ to true. The pa-
rameter is k. WEIGHTED MONOTONE SATISFIA-
BILITY is W[SAT]-complete (Abrahamson et al.,
1993; Abrahamson et al., 1995; Downey and Fel-
lows, 1999).

We can view a monotone Boolean formula φ
as an unranked tree, where the root node corre-
sponds to the top level clause and the leaves corre-
spond to bottom level clauses, i.e., variable occur-
rences. The set pos(φ) of positions of φ is defined
as usual, consisting of strings of natural numbers
that indicate how to navigate to the clauses in a
tree representation of φ. We denote each subclause
of φ by Cs, where s ∈ pos(φ) is its position. Thus

φ = (((x1 ∧ (x2 ∨ x3)) ∨ x3 ∨ (x3 ∧ x4))∧
∧x2 ∧ ((x1 ∧ (x2 ∨ x4)) ∨ (x1 ∧ x3)))

Cε

C1

C11
C111

C112
C1121

C1122C12

C13
C131

C132
C2

C3

C31
C311

C312
C3121

C3122

C32
C321

C322

Figure 1: A formula φ and its tree representa-
tion. Conjunctive clauses are round and disjunc-
tive rectangular. For example, C111 is the leftmost
occurrence of x1 and C13 the clause (x3 ∧ x4).

Cε denotes the whole of φ, while, e.g., Cijl is the
lth clause of the jth clause of the ith clause of φ.
See Figure 1 for an example. We use C for the set
of all clauses of φ and C∧, C∨, and CVar for the
sets of conjunctive, disjunctive, and bottom level
clauses, respectively. For all c ∈ CVar let Var(c)
denote the variable in c, and let Var(φ) denote the
set of all variables in φ.

Given a monotone Boolean formula φ and a
variable assignment ρ : Var(φ) → B, we de-
fine a verification tour for φ and ρ. Such a tour
moves through the tree representation of φ, start-
ing at the root node, and verifies that ρ satis-
fies φ. To this end, we first define the function
Next : pos(φ) → pos(φ) ∪ {True} as follows.
For the root clause let Next(ε) = True . For all
si ∈ pos(φ), where s ∈ N∗ and i ∈ N, if Cs ∈ C∧
and s(i + 1) ∈ pos(φ) let Next(si) = s(i + 1),
otherwise let Next(si) = Next(s).

A verification tour over φ, given a variable as-
signment ρ is constructed by the following proce-
dure. Set the initial position p = ε, then
• If Cp ∈ C∧ set p ← p1 (i.e., go to the first

subclause).
• If Cp ∈ C∨ set p ← pi for any i (i.e. non-

deterministically pick a subclause).
• IfCp ∈ CVar verify that ρ(Var(Cp)) = true .

If so, set p ← Next(p) and repeat. Other-
wise, the verification tour fails.

A verification tour succeeds if it reaches True .

23



The following lemma can be proved by straight-
forward induction on the structure of φ.

Lemma 3.2. If a verification tour for φ and vari-
able assignment ρ succeeds, then ρ satisfies φ.

We are now ready to prove Theorem 3.1.

Proof of Theorem 3.1. Let (φ, k) be an instance of
WEIGHTED MONOTONE SATISFIABILITY. Let
{x1, . . . , xn} be the variables that appear in φ. In
particular, n is the number of distinct variables.
Let m be the number of bottom level clauses.

Intuitively, the LCFRS we will construct will
guess a weight k variable assignment ρ and then
simulate a verification tour for φ and ρ.

Basically, we will use one nonterminal per
clause and use the structure of the grammar to sim-
ulate a verification tour. In order to verify that the
necessary bottom level clauses can all be satisfied
through the same k true variables, we will use the
input string to be parsed. The string w will con-
sist of bracketed sequences of m copies of each of
the n variables, i.e., w = [xm1 ] · · · [xmn ]. To un-
derstand the construction of the grammar, please
keep in mind that the only derivations that matter
are those generating this particular input string.

The grammar will guess which k variables
should be set to true and disregard the other vari-
ables. Technically, this is done by first letting a
nonterminal F generate a tuple of k + 1 strings
s0, . . . , sk such that each si consists of zero or
more of the bracketed sequences of variables to
be disregarded. The rest of the grammar generates
exactly k bracketed sequences that will be inter-
leaved with s0, . . . , sk. During the generation of
these k bracketed sequences it is nondeterministi-
cally verified that the corresponding truth assign-
ment satisfies φ.

We use the following set of nonterminals:

{S, F} ∪ {Cs | s ∈ pos(φ) ∪ {True}}

For S, there is only one rule: S → fS(F ). The
function fS places brackets around the k vari-
ables that are guessed to be true, represented by
the strings t1, . . . , tk, and interleaves them with
the remaining variables, represented by the strings
s0, . . . , sk:

fS(s0, . . . , sk, t1, . . . , tk) = (s0[t1]s1 · · · [tk]sk)

The nonterminal F has rules F → fF,i,j(F ) for
all i ∈ [n] and j ∈ [k]0. These rules produce the
bracketed sequences of copies of the variables xi

to be disregarded, as can be seen from the corre-
sponding function:

fF,i,j(s0, . . . , sk, t1, . . . , tk) =

(s0, . . . , sj [x
m
i ], . . . , sk, t1, . . . , tk)

Moreover, there is a single rule

F → fF (Cε)

with

fF (t1, . . . , tk) = (ε, . . . , ε, t1, . . . , tk)

The rules for the nonterminals that represent
clauses differ according to the type of the clause,
i.e., if the nonterminal represents a conjunctive
clause, a disjunctive clause, or a variable. For each
conjunctive clause Cs there is exactly one rule,
representing a move to its first subclause. Here,
fid is the identity function.

Cs → fid (Cs1)

For every disjunctive clause Cs and every i such
that Csi is a subclause of Cs there is one rule.

Cs → fid (Csi)

For every bottom level clause, i.e., Cs ∈ CVar ,
every i ∈ [k] and every j ∈ [m] there is one rule.

Cs → fs,i,j(CNext(s))

Intuitively, such a rule corresponds to producing j
copies of the variable of clause Cs in component i
of the tuple and moving on to the next clause that
should be visited in a verification tour. This can be
seen from the corresponding function.

fs,i,j(t1, . . . , tk) = (t1, . . . ,Var(Cs)
jti, . . . , tk)

The reason that the function produces j copies of
the variable, rather than just one, is that it is un-
known beforehand how many times a bottom level
clause that represents that particular variable will
be visited. Thus the number of copies to be pro-
duced has to be guessed nondeterministically in
order to make sure that a total of m copies of each
variable set to true are eventually produced.

If there is a weight k satisfying assignment,
there will also be a verification tour that even-
tually reaches True when Next is called (by
Lemma 3.2). The single rule forCTrue simply pro-
duces a k-tuple of empty strings.

24



The reduction is polynomial and the fan-out of
the resulting grammar is 2k+1. Thus it is an FPT-
reduction. It remains to argue that the grammar
can produce w if and only if φ has a satisfying
assignment of weight k.

We first note that whatever tuple is derived from
F , the first k + 1 entries in the tuple consist of
bracketed sequences of the form [xml ]. If the
grammar can produce w, it follows that the tuple
(t1, . . . , tk) produced from Cε must be such that
each ti equalsm copies of the same variable name.

Any successful derivation of a string by the
grammar corresponds to a verification tour of φ
and the variable assignment that sets the variables
that appear in (t1, . . . , tk) to true and all other vari-
ables to false. Thus φ has a satisfying assignment
of weight k.

For the other direction, assume that φ has a sat-
isfying assignment of weight k. Then the grammar
can guess this assignment and a corresponding
successful verification tour, thus producingw.

Note that Theorem 3.1 can easily be strength-
ened to grammars with a binary terminal alphabet.
It is enough to represent each variable name by
a bitstring of length dlog2(m)e in the above re-
duction. We also note that Theorem 3.1 immedi-
ately implies that P-LCFRS(P)-MEMBERSHIP
is W[SAT]-hard.

4 Fixed fan-out grammars

We next turn to the case where the fan-out is fixed
to two, while the rank is treated as a parameter.

Theorem 4.1. P-LCFRS(2)-MEMBERSHIP is
W[1]-hard.

Proof. We reduce from k-CLIQUE, the problem of
deciding whether a given graph has a clique of size
k, with k as the parameter. This problem is known
to be W[1]-complete (Flum and Grohe, 2006). Let
G = (V,E) be an undirected graph. We assume,
without loss of generality, that V = {1, . . . , n}
and that an edge connecting nodes i, j ∈ V is rep-
resented as the ordered pair (i, j) such that i < j,
i.e., E ⊆ {(i, j) ∈ V × V | i < j}. To find out
whether G has a clique of size k we construct an
instance of the membership problem for LCFRSs.

The input alphabet is Σ = {0, 1}. Construct the
input string as

w = 0n10n10n1 · · · 10n︸ ︷︷ ︸
(3k + 2)(k − 1)/2 ones

.

The nonterminals are N = {A,E,C, S}, with S
being the initial nonterminal. The rules are the fol-
lowing.
{A→ 0i | i ∈ {1, . . . , n}}.
{E → 0n−i10n−j | (i, j) ∈ E}.
{C → (0i, 0n−i10i) | i ∈ {1, . . . , n}}.
Handling S is a bit more complex. Let

φ = k(k−1)/2, the number of edges in a k-clique.
Then the unique rule for S is:

S → f(E, . . . , E︸ ︷︷ ︸
φ

, C, . . . , C︸ ︷︷ ︸
2φ

, A, . . . , A︸ ︷︷ ︸
2k

).

Now we need to define f . Consider the following
application of f .

f(e1, . . . , eφ, (c1, ĉ1), . . . , (cφ, ĉφ),

(d1, d̂1), . . . , (dφ, d̂φ), a1, . . . , a2k).

The application above evaluates to the string

c1e1d11c2e2d21 · · ·
· · · 1cφeφdφ1a1θ1a21a3θ2a41s1a2k−1θka2k.

The substrings θ1 through θk are left to be de-
fined, and will contain all the ĉ and d̂ arguments
in a careful configuration derived from the struc-
ture of a clique. Let (π1, π′1), . . . , (πφ, π

′
φ) be the

lexicographically sorted sequence of edges in a
k-clique with nodes numbered 1 through k. For
example, (π1, π′1) = (1, 2), (π2, π

′
2) = (1, 3),

(πk, π
′
k) = (2, 3), and (πφ, π

′
φ) = (k − 1, k).

Then, for each l, find the longest subsequences
i1, . . . , ip and j1, . . . , jq of 1, . . . , φ for which
πi1 = · · · = πip = l and π′j1 = · · · = πjq = l, and
let θl = ĉi1 · · · ĉip d̂j1 · · · d̂jq .

This construction is simpler than it may at first
appear. Basically, the clique is found by generat-
ing k(k− 1)/2 copies of E, each of which will be
placed so that it has no choice but to generate an
edge in a k-clique. Looking at the first part of the
string, each 1cleldl1 must generate a string of the
form 10n10n1: el will generate some 0n−i10n−j ,
were (i, j) is an edge in G, which forces cl to gen-
erate 0i and dl to generate 0j . The trick is that cl
and dl yield the first string in a pair generated by
an instance of C. The other string in the pair de-
scribes the same number as the first, but in such
a way that it can be carefully placed in the lat-
ter part of the derivation string, thus forcing other
instances of the C nonterminal to pick the same

25



node (number of zeros) to generate. These are
then placed in such a way that the edges picked by
the instances of E all belong to the same clique.
For example, for k = 3 the result of f will
be c1e1d11c2e2d21c3e3d31a1c1c2a21c3d11d2d3,
where the latter part ensures that c1 and c2 have
to pick the same node (lowest-numbered node in
the clique), as do c3 and d1, and d2 and d3.

5 Short derivations

In this section, we consider the length of deriva-
tions as an additional parameter. As usual, the
length of a derivation is the number of derivation
steps it consists of. (In a derivation of an LCFRS
(N,Σ, F,R, S), this is the same as the number of
applications of functions in F .)

Let G = (N,Σ, F,R, S) be an LCFRS in the
following. Consider the following problem:

Definition 5.1. An instance of the SHORT P-
LCFRS(P) DERIVATION problem consists of a
LCFRS G, some w ∈ Σ∗ and a constant d ∈ N.
The question asked is: can w be derived by G in
at most d steps? The parameter is k = d + r + f
where r is the maximum rank and f the maximum
fanout.

Lemma 5.1. SHORT P-LCFRS(P) DERIVA-
TION is W[1]-hard.

Proof. The W[1]-hardness of the problem follows
immediately from the reduction in the proof of
Theorem 4.1, since k-Clique is reduced to an in-
stance of LCFRS membership with O(k2) deriva-
tion steps, rank O(k2), and fixed fan-out.

We next demonstrate that SHORT P-
LCFRS(P) DERIVATION is in W[1] (and is
therefore W[1]-complete) by reducing to SHORT
CONTEXT-SENSITIVE DERIVATION, shown to
be W[1]-complete by Downey et al. (1994).
Let H = (NH ,ΣH , RH , SH) be an arbitrary
context-sensitive grammar in the following. A
context-sensitive grammar has nonterminals,
terminals and a starting nonterminal just like a
LCFRS, but the rules are of the form α → β for
strings α, β ∈ (ΣH ∪NH)∗ where 0 < |α| ≤ |β|.
A derivation starts with the string SH . A string
w · α · w′ can be turned into w · β · w′ in one
derivation step if (α, β) ∈ RH .
Definition 5.2. An instance of the SHORT
CONTEXT-SENSITIVE DERIVATION problem
consists of a context-sensitive grammar H , a

string w ∈ Σ∗H , and a constant dH ∈ N. The
question is: can w be derived by H in at most dH
steps? The parameter is dH .

We are now ready to prove membership in W[1]
by a FPT-reduction from (G,w, d) to (H,w, dH).

Lemma 5.2. The SHORT P-LCFRS(P)
DERIVATION problem is in W[1].

Proof. We can restrict ourselves to the case where
no nonterminal appears twice in a right-hand side
of any rule in G. This is because, e.g., a rule
of the form A → f(B,B) can be turned into
A → f(B,B′), using a fresh copy B′ of B that
has the same rules asB (except for having the left-
hand side B′ rather than B). Note that this modifi-
cation does not affect the parameter, and increases
the size of the grammar only polynomially.

The complete reduction is somewhat lengthy,
but the core intuition is very simple. The string
is kept the same, and a context-sensitive gram-
mar H is constructed such that L(H) = L(G).
H simulates G by maintaining a string serializa-
tion of the current “configuration” of G, walking
through the whole string rewriting the appropriate
non-terminal for every rule application in G. A
configuration of G can be viewed in this way,

aa • b • • • b • ba

A B A

where the derivation has, so far, generated some
terminal symbols (the lower-case letters), two in-
stances of the non-terminal A and one instance of
B. The configuration keeps track of where the
symbols generated by the non-terminals should
go in the string, so #(A) = 2, #(B) = 1,
and if (c, d) ∈ LA and e ∈ LB this derivation
can generate the final string aacbeddbcba. These
intermediary configurations are in H serialized
into strings of nonterminals, with a “nonterminal
marker” symbol in each position where a non-
terminal is referred to (i.e., H generates a symbol
stating “the ith string generated by instance j of
the nonterminal A goes here”). H then operates
like a Turing machine. A special nonterminal, the
rewriting head, picks a rule from G to apply, and
walks through the string replacing the nonterminal
markers that are affected by that rule. This proce-
dure is then repeated d times.

We start by illustrating the principles of the re-
duction by an example. Consider the grammar

26



�Pr1,1→2XS,1,1� =⇒ �XA,1,2XA,2,2Pr1,1→2� =⇒ �XA,1,2XA,2,2R� =⇒ �XA,1,2RXA,2,2� =⇒
�RXA,1,2XA,2,2� =⇒ �Pr2,2→3XA,1,2XA,2,2�

∗
=⇒ �XA,1,3XB,1,3XA,2,3B2,3R�

∗
=⇒

�Pr2,3→4XA,1,3XB,1,3XA,2,3XB,2,3�
∗

=⇒ �XA,1,4XB,1,4XB,1,3XA,2,3XB,2,4XB,2,3R�
∗

=⇒
�Pr6,3→1XA,1,4XB,1,4XB,1,3XA,2,3XB,2,4XB,2,3�

∗
=⇒ �Pr3,4→1XA,1,4XB,1,4bXA,2,3XB,2,4b�

∗
=⇒

�Pr5,4→1aXB,1,4baXB,2,4b�
∗

=⇒ �aabaabR� ∗=⇒ aabaab

Figure 2: A derivation in the context-sensitive grammar constructed to simulate an LCFRS. All steps in
the application of the first rule, r1 = S → f(A), are given, the rest is abbreviated.

G = ({S,A,B}, {a, b}, F,R, S) where F is

{f(x, y) = xy, ha() = (a, a), hb() = (b, b),
g((x, y), (x′, y′)) = (xx′, yy′)},

and R contains the following

r1 = S → f(A) r2 = A→ g(A,B)
r3 = A→ ha() r4 = A→ hb()
r5 = B → ha() r6 = B → hb()

Notice that L(G) = {ww | w ∈ {a, b}+}. We
now describe how H is constructed by the reduc-
tion, after which the more general description fol-
lows. A derivation in G starts with the nontermi-
nal S and must then apply r1. H is constructed
to start with the string �Pr1,1→2XS,1,1� (all these
symbols are nonterminals, H has the same termi-
nal alphabet as G). The symbols � and � mark
the beginning and end of the string. The nonter-
minal XS,1,1 is a “nonterminal marker” and de-
notes the location where the first string generated
by instance 1 of the nonterminal S is to be placed.
Since #(S) = 1 the first string is the only string
generated from S. The last subscript, the instance
number, is there to differentiate markers belong-
ing to different instances of the same nonterminal.
The rewriting head non-deterministically picks an
instance number for a round of rewriting (single
rule application) from a pool sufficiently large to
differentiate between the maximal number of non-
terminals (since the rank of G is at most k, no
more than k2 nonterminals can be generated in k
rule applications). Pr1,1→2 is the “rewriting head”,
the anchor for rule applications. The subscripts on
P determines that it will apply the rule r1, rewrit-
ing nonterminal markers corresponding to the left
hand side nonterminal of r1 which have instance
number 1. Applying the rule may create new non-
terminal markers, all of which get the instance
number 2, also determined by the subscript.

That is, the rules for Pr1,i→j in H will
be Pr1,i→jXS,1,i → XA,1,jXA,2,jPr1,i→j , for

i, j ∈ [2k2], and Pr1,i→jx → xPr1,i→j for all
other x 6= �. Pr5,i→jXB,1,i → aPr5,i→j is an-
other example of a rule corresponding to rule r5
of G. When a rewriting head hits � it is replaced
by a nonterminal R which reverses through the
string (with rules of the form xR → Rx for all
x 6= �), after which a new rewriting head is non-
deterministically picked using one of the rules in
{�R → �Pr,i→j | r ∈ R, i, j ∈ [2k2]}, after
which the string is rewritten once more. Finally,
there are rules � → ε, � → ε and R → ε, to
remove all nonterminals once rewriting has termi-
nated. A derivation is demonstrated in Figure 2.

By induction on the length of derivations, one
can show that L(H) = L(G). Now we need to
modify the construction slightly to ensure that H
can simulate d steps of G in dH steps.

Limiting steps in G. Construct a SHORT
P-LCFRS(P) DERIVATION instance (G′, w, d)
from (G,w, d) whereG′ is such that it cannot per-
form more than d derivation steps. Let

N ′ = {Ai | A ∈ N, i ∈ [d]},

and let

Ai → f(Bj1 , Cj2 , . . .) ∈ R′

for all A → f(B,C, . . .) ∈ R, i ∈ [d] and
j1 + j2 + · · · = i− 1. Then G′ = (N ′,Σ, R′, S1).
This reduction is somewhat heavy-handed, but is
in FPT since it leaves k unchanged and each rule
is replaced by less than kk rules (since d and the
rank of the grammar are part of the parameter k).

Deferring terminals. A problem in completing
the reduction from (G,w, d) to (H,w, dH) is that
the number of terminal symbolsG generates is not
in its parameter k. For example, G may contain
a rule like A → a · · · a, for an arbitrary num-
ber of as. Applying this rule may make the in-
termediary string H is operating on too long for
it to complete rewriting in dH steps. This can

27



easily be fixed by a polynomial-time rewriting of
H . For any rule w → w′ in H such that w′ con-
tains at least one terminal, replace every maximal
substring α ∈ Σ∗ by a new nonterminal Tα, a
“terminal place-holder”.The rewriting head P and
reversal nonterminal R just walk over the place-
holders without changing them. Now add the rule
Tα → α for each Tα. For example, where a
rewriting head inH might have replacedXA,1,1 by
abcXB,1,1baXB,2,1cc it will now instead replace it
by TabcXB,1,1TbaXB,2,1Tcc, and can defer replac-
ing the place-holder nonterminals until the end.

Completing the reduction. Now we are ready
to put all the pieces together. Given the SHORT
P-LCFRS(P) DERIVATION instance (G,w, d),
apply the limiting steps reduction to construct
(G′, w, d′). Apply the rewriting construction to
G to get the context-sensitive grammar H . Now
L(H) equals the language G can generate in d
steps. Apply the deferring terminals construction
to H to get H ′. All that remains is to calcu-
late dH , the number of steps that H ′ may take.
For an FPT-reduction this number may only de-
pend on the parameter k of (G′, w, d′). Picking
dH = k

5+103 is sufficient. Each rule inG′ gener-
ates less than k nonterminals (since the maximum
rank is at most k), each of which will generate
at most k markers in the derivation in H ′ (since
the fanout is at most k). The rule may in addi-
tion generate (k + 1)k terminal place-holders (the
k2 nonterminal markers and string ends separating
maximal terminal substrings). After k rule appli-
cations, without replacing terminal placeholders,
the intermediary string in a derivation in H is less
than k(k2+(k+1)k)+3 symbols long. Simulating
a rule application in H ′ entails walking the string
twice (forward and then reversing), and k rules are
applied, giving 2k(k(k2+(k+1)k)+3) steps. An-
other k(k+ 1) + 3 steps at the end replace the ter-
minal place-holders and remove markers and the
rewriting head. Adding things up we arrive at a
polynomial of degree 4 that can be rounded up to
k5 + 103.

Theorem 5.3. SHORT P-LCFRS(P) DERIVA-
TION is W[1]-hard.

Proof. This combines Lemmas 5.1 and 5.2.

The result of Theorem 5.3 also trivially applies
to another natural choice of parameters, the depth

of acyclic LCFRS, since they can naturally only
take a limited number of derivation steps.
Definition 5.3. A LCFRS is acyclic of depth d if d
is the smallest integer such that there is a function
φ : N → [d] such that for all A→ f(B1, . . . , Bn)
in R and i ∈ [n] it holds that φ(A) < φ(Bi).
Corollary. The membership problem for acyclic
LCFRS where the rank, fan-out, and depth are
taken as the parameter is W[1]-complete.

6 Discussion

We have shown that the 1-LCFRS(P)-
MEMBERSHIP problem is W[SAT]-hard, but
we have no upper bound, except for the trivial
XP membership. A conjecture of Pietrzak (2003)
may help explain the difficulty of finding such
an upper bound. It states that any parameterized
problem that has a property that Pietrzak calls
additive is either in FPT or not in W[P]. Basically,
additivity says that any number of instances,
sharing a parameter value, can in polynomial time
be combined into one big instance, with the same
parameter. While 1-LCFRS(P)-MEMBERSHIP
is not additive, it has subproblems that are. This
means that if Pietrzak’s conjecture is true (and
FPT 6= W[P]), then 1-LCFRS(P)-MEMBERSHIP
cannot belong to W[P].

While our results are mostly intractability re-
sults, we see them as a first step towards a more
finely grained understanding of the complexity of
LCFRS parsing. Ruling out simple parameteri-
zation by fan-out or rank as a road towards effi-
cient algorithms lets us focus on other possibili-
ties. Many possible parameterizations remain un-
explored. In particular, we conjecture that param-
eterizing by string length yields FPT membership.
In the search for features that can be used in algo-
rithm development, it may also be useful to inves-
tigate other formalisms, such as e.g., hypergraph
replacement and tree-walking transducers.

Acknowledgments

We acknowledge the support of the Swedish Re-
search Council grant 621-2011-6080.

References
K. A. Abrahamson, R. G. Downey, and M. R. Fellows.

1993. Fixed-parameter intractability II (Extended
abstract). In Proceedings of the 10th Annual Sym-
posium on Theoretical Aspects of Computer Science
(STACS’93), pages 374–385.

28



K. A. Abrahamson, R. G. Downey, and M. R. Fellows.
1995. Fixed-parameter tractability and complete-
ness IV: On completeness for W[P] and PSPACE-
analogues. Annals of Pure and Applied Logic,
73:235–276.

P. Boullier. 2004. Range concatenation grammars.
In New Developments in Parsing Technology, pages
269–289. Kluwer Academic Publishers.

H. Burden and P. Ljunglöf. 2005. Parsing linear
context-free rewriting systems. In Proceedings of
9th International Workshop on Parsing Technolo-
gies.

R. G. Downey and M. R. Fellows. 1999. Parameter-
ized Complexity. Springer-Verlag.

R. G. Downey, M. R. Fellows, B. M. Kapron, M. T.
Hallett, and H. T. Wareham. 1994. The parameter-
ized complexity of some problems in logic and lin-
guistics. In Logical Foundations of Computer Sci-
ence, pages 89–100. Springer.

J. Flum and M. Grohe. 2006. Parameterized Complex-
ity Theory. Springer-Verlag.

C. Gómez-Rodrı́guez, M. Kuhlmann, and G. Satta.
2010. Efficient parsing of well-nested linear
context-free rewriting systems. In Human Language
Technologies: The 2010 Annual Conference of the
North American Chapter of the ACL, pages 276–
284.

A. Joshi. 1985. Tree adjoining grammars: How much
context-sensitivity is required to provide reasonable
structural descriptions. In Natural Language Pars-
ing, pages 206–250. Cambridge University Press.

Y. Kaji, R. Nakanisi, H. Seki, and T. Kasami. 1992.
The universal recognition problem for multiple
context-free grammars and for linear context-free
rewriting systems. IEICE Transactions on Informa-
tion and Systems, E75-D(1):78–88.

K. Pietrzak. 2003. A conjecture on the parameterized
hierarchy. Notes on a talk given at Dagstuhl Seminar
03311. Unpublished manuscript.

B. Sagot and G. Satta. 2010. Optimal rank reduction
for linear context-free rewriting systems with fan-
out two. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics
(ACL’10), pages 525–533.

G. Satta. 1992. Recognition of linear context-free
rewriting systems. In Proceedings of the 30th An-
nual Meeting of the Association for Computational
Linguistics (ACL’92), pages 89–95.

G. Satta. 1998. Trading independent for synchronized
parallelism in finite copying parallel rewriting sys-
tems. J. Computer and System Sciences, 56(1):27–
45.

H. Seki, T. Matsumura, M. Fujii, and T. Kasami. 1991.
On multiple context-free grammars. Theoretical
Computer Science, 88(2):191–229.

K. Vijay-Shanker, D. J. Weir, and A. K. Joshi. 1987.
Characterizing structural descriptions produced by
various grammatical formalisms. In Proceedings of
the 25th Meeting of the Association for Computa-
tional Linguists (ACL’87), pages 104–111.

29


